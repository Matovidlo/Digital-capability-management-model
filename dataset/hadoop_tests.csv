Summary,Issue key,Issue id,Issue Type,Status,Project key,Project name,Project type,Project lead,Project description,Project url,Priority,Resolution,Assignee,Reporter,Creator,Created,Updated,Last Viewed,Resolved,Affects Version/s,Affects Version/s,Affects Version/s,Affects Version/s,Fix Version/s,Fix Version/s,Fix Version/s,Fix Version/s,Fix Version/s,Fix Version/s,Component/s,Component/s,Component/s,Due Date,Votes,Labels,Labels,Description,Environment,Watchers,Watchers,Watchers,Watchers,Watchers,Watchers,Watchers,Watchers,Watchers,Watchers,Watchers,Watchers,Watchers,Watchers,Watchers,Watchers,Watchers,Watchers,Watchers,Log Work,Log Work,Log Work,Log Work,Log Work,Log Work,Original Estimate,Remaining Estimate,Time Spent,Work Ratio,Σ Original Estimate,Σ Remaining Estimate,Σ Time Spent,Security Level,Outward issue link (Blocker),Outward issue link (Blocker),Outward issue link (Child-Issue),Outward issue link (Container),Outward issue link (Container),Outward issue link (Container),Outward issue link (Container),Outward issue link (Container),Outward issue link (Container),Outward issue link (Container),Outward issue link (Container),Outward issue link (Container),Outward issue link (Dependent),Outward issue link (Duplicate),Outward issue link (Duplicate),Outward issue link (Duplicate),Outward issue link (Incorporates),Outward issue link (Reference),Outward issue link (Reference),Outward issue link (Reference),Outward issue link (Reference),Outward issue link (Reference),Outward issue link (Reference),Outward issue link (Reference),Outward issue link (Reference),Outward issue link (Reference),Outward issue link (Reference),Outward issue link (Reference),Outward issue link (Reference),Outward issue link (Reference),Outward issue link (Reference),Outward issue link (Reference),Outward issue link (Reference),Outward issue link (Reference),Outward issue link (Reference),Outward issue link (Reference),Outward issue link (Reference),Outward issue link (Reference),Outward issue link (Reference),Outward issue link (Reference),Outward issue link (Reference),Outward issue link (Reference),Outward issue link (Reference),Outward issue link (Reference),Outward issue link (Reference),Outward issue link (Reference),Outward issue link (Reference),Outward issue link (Reference),Outward issue link (Reference),Outward issue link (Reference),Outward issue link (Reference),Outward issue link (Reference),Outward issue link (Reference),Outward issue link (Reference),Outward issue link (Reference),Outward issue link (Reference),Outward issue link (Reference),Outward issue link (Reference),Outward issue link (Reference),Outward issue link (Reference),Outward issue link (Reference),Outward issue link (Reference),Outward issue link (Reference),Outward issue link (Reference),Outward issue link (Reference),Outward issue link (Reference),Outward issue link (Reference),Outward issue link (Reference),Outward issue link (Reference),Outward issue link (Reference),Outward issue link (Reference),Outward issue link (Reference),Outward issue link (Reference),Outward issue link (Reference),Outward issue link (Reference),Outward issue link (Reference),Outward issue link (Reference),Outward issue link (Reference),Outward issue link (Reference),Outward issue link (Reference),Outward issue link (Reference),Outward issue link (Reference),Outward issue link (Reference),Outward issue link (Reference),Outward issue link (Reference),Outward issue link (Reference),Outward issue link (Reference),Outward issue link (Reference),Outward issue link (Reference),Outward issue link (Reference),Outward issue link (Regression),Outward issue link (Required),Outward issue link (Supercedes),Outward issue link (dependent),Outward issue link (dependent),Outward issue link (dependent),Outward issue link (dependent),Outward issue link (dependent),Outward issue link (dependent),Outward issue link (dependent),Attachment,Attachment,Attachment,Attachment,Attachment,Attachment,Attachment,Attachment,Attachment,Attachment,Attachment,Attachment,Attachment,Attachment,Attachment,Attachment,Attachment,Attachment,Attachment,Attachment,Attachment,Attachment,Custom field (Affects version (Component)),Custom field (Attachment count),Custom field (Blog - New Blog Administrators),Custom field (Blog - New Blog PMC),Custom field (Blog - Write access),Custom field (Blog Administrator?),Custom field (Blogs - Admin for blog),Custom field (Blogs - Email Address),Custom field (Blogs - Existing Blog Access Level),Custom field (Blogs - Existing Blog Name),Custom field (Blogs - New Blog Write Access),Custom field (Blogs - Username),Custom field (Bug Category),Custom field (Bugzilla - Email Notification Address),Custom field (Bugzilla - List of usernames),Custom field (Bugzilla - PMC Name),Custom field (Bugzilla - Project Name),Custom field (Bugzilla Id),Custom field (Bugzilla Id),Custom field (Change Category),Custom field (Complexity),Custom field (Date of First Response),Custom field (Discovered By),Custom field (Docs Text),Custom field (Enable Automatic Patch Review),Custom field (Epic Link),Custom field (Estimated Complexity),Custom field (Evidence Of Open Source Adoption),Custom field (Evidence Of Registration),Custom field (Evidence Of Use On World Wide Web),Custom field (Existing GitBox Approval),Custom field (External issue ID),Custom field (External issue URL),Custom field (Fix version (Component)),Custom field (Git Notification Mailing List),Custom field (Git Repository Import Path),Custom field (Git Repository Name),Custom field (Git Repository Type),Custom field (GitHub Options),Custom field (Github Integration),Custom field (Github Integrations - Other),Custom field (Global Rank),Custom field (Hadoop Flags),Custom field (Hadoop Flags),Custom field (INFRA - Subversion Repository Path),Custom field (Initial Confluence Contributors),Custom field (Last public comment date),Custom field (Level of effort),Custom field (Machine Readable Info),Custom field (New-TLP-TLPName),Custom field (Priority),Custom field (Project),Custom field (Protected Branch),Custom field (Rank),Custom field (Rank (Obsolete)),Custom field (Release Note),Custom field (Review Date),Custom field (Reviewer),Custom field (Severity),Custom field (Severity),Custom field (Skill Level),Custom field (Source Control Link),Custom field (Space Description),Custom field (Space Key),Custom field (Space Name),Custom field (Tags),Custom field (Tags),Custom field (Target Version/s),Custom field (Target Version/s),Custom field (Target Version/s),Custom field (Target Version/s),Custom field (Target Version/s),Custom field (Target Version/s),Custom field (Test and Documentation Plan),Custom field (Testcase included),Custom field (Tester),Custom field (Workaround),Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment
Add more unit tests to test appending to files in HDFS,HADOOP-3790,12400570,Test,Closed,HADOOP,Hadoop Common,software,omalley,Hadoop Common is the common library for Apache Hadoop.,http://hadoop.apache.org/,Blocker,Fixed,szetszwo,dhruba,dhruba,18/Jul/08 17:09,02/May/13 02:29,12/Jan/21 11:55,13/Oct/08 20:53,,,,,0.19.0,,,,,,test,,,,0,,,"A new feature ""appends to HDFS files"" have been implemented in HADOOP-1700. There are a set of unit tests in TestFileAppend.java and TestFileAppend2.java. But we would like to have more unit tests.",,cdouglas,dhruba,Fan04290,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,HADOOP-1700,HADOOP-2658,,,,,,"09/Oct/08 01:18;szetszwo;3790_20081008.patch;https://issues.apache.org/jira/secure/attachment/12391793/3790_20081008.patch","10/Oct/08 23:34;szetszwo;3790_20081010.patch;https://issues.apache.org/jira/secure/attachment/12391916/3790_20081010.patch",,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,2008-09-26 04:36:34.495,,,false,,,,,,,,,,,,,,,,,19059,Reviewed,,,,Wed Oct 15 13:56:29 UTC 2008,,,,,,,"0|i0iaa7:",104760,,,,,,,,,,,,,,,,,,,,,,,"26/Sep/08 04:36;nidaley;Copying from HADOOP-3790: One interesting unit test would be introduce ""appends"" to existing unit test TestDatanodeDeath.","09/Oct/08 01:18;szetszwo;3790_20081008.patch: Includes TC 1, 2, 3, 5, 11, 12 defined in https://issues.apache.org/jira/secure/attachment/12391788/20081008testplan.txt

Note that TC3 is currently disabled since HADOOP-4379","09/Oct/08 01:52;szetszwo;{noformat}
     [exec] +1 overall.  

     [exec]     +1 @author.  The patch does not contain any @author tags.

     [exec]     +1 tests included.  The patch appears to include 3 new or modified tests.

     [exec]     +1 javadoc.  The javadoc tool did not generate any warning messages.

     [exec]     +1 javac.  The applied patch does not increase the total number of javac compiler warnings.

     [exec]     +1 findbugs.  The patch does not introduce any new Findbugs warnings.

     [exec]     +1 Eclipse classpath. The patch retains Eclipse classpath integrity.
{noformat}

I tested the new tests locally.","10/Oct/08 00:50;cdouglas;The patch looks good. A few suggestions:
* Instead of local blocks, each of these should probably be separate tests. All can use the same static MiniDFSCluster using TestSetup, as in TestDatamerge, TestReduceFetch, etc.
* In TC11, does it make sense to check the return value of fs.rename?
* Since it's essentially dead code in trunk, it might make more sense to make TC3 part of HADOOP-4379 instead of enabling it once it can be expected to pass","10/Oct/08 23:34;szetszwo;3790_20081010.patch

> Instead of local blocks, each of these should probably be separate tests. All can use the same static MiniDFSCluster using TestSetup, as in TestDatamerge, TestReduceFetch, etc.
Using TestSetup now.

> In TC11, does it make sense to check the return value of fs.rename?
Yes, we should check the return value.  It turns out that TC11 was not implemented correctly.  Good catch!

> Since it's essentially dead code in trunk, it might make more sense to make TC3 part of HADOOP-4379 instead of enabling it once it can be expected to pass
Removed here and, instead, posted in HADOOP-4379.

Thanks, Chris.","11/Oct/08 01:05;cdouglas;+1 Looks good","11/Oct/08 17:17;hadoopqa;+1 overall.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12391916/3790_20081010.patch
  against trunk revision 703609.

    +1 @author.  The patch does not contain any @author tags.

    +1 tests included.  The patch appears to include 6 new or modified tests.

    +1 javadoc.  The javadoc tool did not generate any warning messages.

    +1 javac.  The applied patch does not increase the total number of javac compiler warnings.

    +1 findbugs.  The patch does not introduce any new Findbugs warnings.

    +1 Eclipse classpath. The patch retains Eclipse classpath integrity.

    +1 core tests.  The patch passed core unit tests.

    +1 contrib tests.  The patch passed contrib unit tests.

Test results: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch/3446/testReport/
Findbugs warnings: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch/3446/artifact/trunk/build/test/findbugs/newPatchFindbugsWarnings.html
Checkstyle results: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch/3446/artifact/trunk/build/test/checkstyle-errors.html
Console output: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch/3446/console

This message is automatically generated.","13/Oct/08 20:53;szetszwo;I just committed this.","15/Oct/08 13:56;hudson;Integrated in Hadoop-trunk #634 (See [http://hudson.zones.apache.org/hudson/job/Hadoop-trunk/634/])
    ",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Move cluster_setup.xml from MapReduce to Common,HADOOP-6738,12463385,Test,Closed,HADOOP,Hadoop Common,software,omalley,Hadoop Common is the common library for Apache Hadoop.,http://hadoop.apache.org/,Blocker,Fixed,tomwhite,tomwhite,tomwhite,29/Apr/10 22:54,24/Aug/10 20:43,12/Jan/21 11:55,04/Jun/10 16:36,,,,,0.21.0,,,,,,,,,,0,,,Common half of MAPREDUCE-1404.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"04/Jun/10 05:09;tomwhite;HADOOP-6738.patch;https://issues.apache.org/jira/secure/attachment/12446326/HADOOP-6738.patch","31/May/10 19:30;tomwhite;HADOOP-6738.patch;https://issues.apache.org/jira/secure/attachment/12445959/HADOOP-6738.patch",,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,2010-05-31 20:01:21.391,,,false,,,,,,,,,,,,,,,,,127379,,,,,Sat Jun 05 11:26:03 UTC 2010,,,,,,,"0|i0hzgf:",103006,,,,,,,,,,,,,,,,,,,,,,,"31/May/10 19:30;tomwhite;Other half of patch described in https://issues.apache.org/jira/browse/MAPREDUCE-1404?focusedCommentId=12873763&page=com.atlassian.jira.plugin.system.issuetabpanels%3Acomment-tabpanel#action_12873763.","31/May/10 20:01;hadoopqa;-1 overall.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12445959/HADOOP-6738.patch
  against trunk revision 949658.

    +1 @author.  The patch does not contain any @author tags.

    -1 tests included.  The patch doesn't appear to include any new or modified tests.
                        Please justify why no new tests are needed for this patch.
                        Also please list what manual steps were performed to verify this patch.

    +1 javadoc.  The javadoc tool did not generate any warning messages.

    +1 javac.  The applied patch does not increase the total number of javac compiler warnings.

    +1 findbugs.  The patch does not introduce any new Findbugs warnings.

    +1 release audit.  The applied patch does not increase the total number of release audit warnings.

    +1 core tests.  The patch passed core unit tests.

    +1 contrib tests.  The patch passed contrib unit tests.

Test results: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch-h4.grid.sp2.yahoo.net/554/testReport/
Findbugs warnings: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch-h4.grid.sp2.yahoo.net/554/artifact/trunk/build/test/findbugs/newPatchFindbugsWarnings.html
Checkstyle results: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch-h4.grid.sp2.yahoo.net/554/artifact/trunk/build/test/checkstyle-errors.html
Console output: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch-h4.grid.sp2.yahoo.net/554/console

This message is automatically generated.","04/Jun/10 16:36;tomwhite;I've just committed this.","04/Jun/10 16:52;hudson;Integrated in Hadoop-Common-trunk-Commit #279 (See [http://hudson.zones.apache.org/hudson/job/Hadoop-Common-trunk-Commit/279/])
    HADOOP-6738.  Move cluster_setup.xml, hod_scheduler, commands_manual from MapReduce to Common.
","05/Jun/10 11:26;hudson;Integrated in Hadoop-Common-trunk #357 (See [http://hudson.zones.apache.org/hudson/job/Hadoop-Common-trunk/357/])
    HADOOP-6738.  Move cluster_setup.xml, hod_scheduler, commands_manual from MapReduce to Common.
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Junit tests for FileContextURI,HADOOP-6261,12435867,Test,Closed,HADOOP,Hadoop Common,software,omalley,Hadoop Common is the common library for Apache Hadoop.,http://hadoop.apache.org/,Blocker,Fixed,raviphulari,raviphulari,raviphulari,16/Sep/09 19:23,24/Aug/10 20:39,12/Jan/21 11:55,22/Sep/09 20:32,0.21.0,,,,0.21.0,,,,,,test,,,,0,,,FileContextURI unit tests. ,,cos,garymurry,jghoman,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"20/Sep/09 19:10;raviphulari;HADOOP-6261.patch;https://issues.apache.org/jira/secure/attachment/12420144/HADOOP-6261.patch","19/Sep/09 01:01;raviphulari;HADOOP-6261.patch;https://issues.apache.org/jira/secure/attachment/12420119/HADOOP-6261.patch","18/Sep/09 23:42;raviphulari;HADOOP-6261.patch;https://issues.apache.org/jira/secure/attachment/12420108/HADOOP-6261.patch",,,,,,,,,,,,,,,,,,,,,3.0,,,,,,,,,,,,,,,,,,,,2009-09-18 00:15:32.729,,,false,,,,,,,,,,,,,,,,,127192,Reviewed,,,,Wed Sep 23 11:12:05 UTC 2009,,,,,,,"0|i0i1b3:",103306,,,,,,,,,,,,,,,,,,,,,,,"17/Sep/09 21:23;raviphulari;Attaching patch for review.","18/Sep/09 00:15;cos;A couple of issues:
- indentation: it supposes to be 2 spaces, not 4
- what is the point of making the parent class {{abstract}}. If you want to emphasize the fact that some of the methods are going to be overridden you can {{@Override} annotation where it's needed
- I'd suggest to change the name of {{FileContextURIBaseTest}} to {{FileContextURIBase}} because the first reaction is to suggest to rename the class into {{Test...}} so it'd be picked up by a hardness :-)
- do you want to make this a {{@BeforeClass}} method? Otherwise it kinda stands there along
{noformat}
   {
       for (int i = 0; i < data.length; i++) {
           data[i] = (byte) (i % 10);
       }
   }
{noformat}
- I think {{createFile}} has been written line 137 times already - I think you don't need an extra one 
- in {{qualifiedPath(String pathString, FileContext fc}} you, perhaps, should avoid using a full type name as a part of the var. name. You might want to use hungarian notation, e.g. prefix a String variable with 's', etc. Also, what if {{fc}} would be equals to {{null}}?
- generally, you might want to make a method's parameters {{final}} to suggest that there's no side-effects involved. And it's more secure code, BTW
- it isn't necessary to prefix your test methods with word 'test' since you have the annotation in place. Although, there's no single rule about this 
- {{tearDown}} takes care about cleaning of {{fs2}}. Do you need to do the same for {{fs1}}?
- there's a number of places in the code where you have things like
{noformat}
       String fileName = ""testFile"";
       Path testPath = qualifiedPath(fileName, fc2);
{noformat}
and which is an only one usage of {{fileName}} variable. It's better be declared {{final}} in this case or simply use the literal constant in the call directly.
- you might want to add some sort of messages to ease assertion identifications. Simply havinf {{assertTrue(op1, op2)}} doesn't mean much when a fault is happening and one needs to read the source code to understand the cause of it (e.g. spend time on an unnecessary analysis)
- public methods are suppose to have some Javadoc for them. Besides, it is great to have some sort of documentation or comments about that a test does. This way it is easier to control if specs were changed and/or maintain the test in a long run.
- in the {{testListStatus}} you are likely to get an assertion in the following line
{noformat}
       Assert
           .assertEquals(qualifiedPath(""test/hadoop/c"", fc1), paths[2].getPath());
{noformat}
because the string literal is different from what has been defined by {{testDirs}}
- also I'd suggest to change this last method to something like
{noformat}
   public void testListStatus() throws Exception {
     final String hPrefix = ""test/hadoop"";
     final String [] dirs = { 
         hPrefix + ""/a"", 
         hPrefix + ""/b"", 
         hPrefix + ""/c"" };
     ArrayList<Path> testDirs = new ArrayList<Path>();
     
     for (String d : dirs) {
       testDirs.add(qualifiedPath(d, fc2));
     }
       Assert.assertFalse(fc1.exists(testDirs.get(0)));

       for (Path path : testDirs) {
           Assert.assertTrue(fc1.mkdirs(path, FsPermission.getDefault()));
       }

       FileStatus[] paths = fc1.listStatus(qualifiedPath(""test"", fc1));
       Assert.assertEquals(1, paths.length);
       Assert.assertEquals(qualifiedPath(hPrefix, fc1), paths[0].getPath());

       paths = fc1.listStatus(qualifiedPath(hPrefix, fc1));
       Assert.assertEquals(3, paths.length);
       for (int i=0; i<paths.length; i++) {
         Assert
         .assertEquals(i + "" path element is wrong"", 
             qualifiedPath(dirs[i], fc1), paths[i].getPath());         
       }

       paths = fc1.listStatus(qualifiedPath(dirs[0], fc1));
       Assert.assertEquals(0, paths.length);
   }
{noformat}
this way you have less code duplication

","18/Sep/09 00:41;jghoman;bq. in qualifiedPath(String pathString, FileContext fc you, perhaps, should avoid using a full type name as a part of the var. name. You might want to use hungarian notation, e.g. prefix a String variable with 's', etc.
Let's avoid Hungarian notation, shall we? Just dropping the type from the variable name should be enough.","18/Sep/09 18:29;raviphulari;Cos,thanks for valuable comments and reviewing patch.

bq. indentation: it supposes to be 2 spaces, not 4
Corrected in next patch. 

{quote}
what is the point of making the parent class abstract. If you want to emphasize the fact that some of the methods are going to be overridden you can {{@Override} annotation where it's needed

I'd suggest to change the name of FileContextURIBaseTest to FileContextURIBase because the first reaction is to suggest to rename the class into Test... so it'd be picked up by a hardness 
do you want to make this a @BeforeClass method? Otherwise it kinda stands there along
   {
       for (int i = 0; i < data.length; i++) {
           data[i] = (byte) (i % 10);
       }
   }
I think createFile has been written line 137 times already - I think you don't need an extra one
{quote}
As per our discussion you suggested to disregard above comments .
{quote}
in qualifiedPath(String pathString, FileContext fc you, perhaps, should avoid using a full type name as a part of the var. name. You might want to use hungarian notation, e.g. prefix a String variable with 's', etc. Also, what if fc would be equals to null?
{quote}

I haven't seen hungarian notation used in most of Hadoop code and there is strong opposition to use hungarian notation.

bq.it isn't necessary to prefix your test methods with word 'test' since you have the annotation in place. Although, there's no single rule about this
Changed .

bq. tearDown takes care about cleaning of fs2. Do you need to do the same for fs1?
I guess you meant fc2 and fc1. These 2 are file context pointing to same Dir/Files so cleaning fc2 in tearDown is enough, no need to clean fc1.

{quote} 
there's a number of places in the code where you have things like
       String fileName = ""testFile"";
       Path testPath = qualifiedPath(fileName, fc2);
and which is an only one usage of fileName variable. It's better be declared final in this case or simply use the literal constant in the call directly.
{quote}
This was intentional for clarity. 

I agree with your way of writing testListStatus, I will update that in patch.
","18/Sep/09 18:41;raviphulari;Cos I agree with changing  name of FileContextURIBaseTest to FileContestURIBase.  
In previous comment mistakenly it was included in disregarding section. 
 
","18/Sep/09 23:21;hadoopqa;+1 overall.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12420101/HADOOP-6261.patch
  against trunk revision 816794.

    +1 @author.  The patch does not contain any @author tags.

    +1 tests included.  The patch appears to include 19 new or modified tests.

    +1 javadoc.  The javadoc tool did not generate any warning messages.

    +1 javac.  The applied patch does not increase the total number of javac compiler warnings.

    +1 findbugs.  The patch does not introduce any new Findbugs warnings.

    +1 release audit.  The applied patch does not increase the total number of release audit warnings.

    +1 core tests.  The patch passed core unit tests.

    +1 contrib tests.  The patch passed contrib unit tests.

Test results: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch-h1.grid.sp2.yahoo.net/12/testReport/
Findbugs warnings: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch-h1.grid.sp2.yahoo.net/12/artifact/trunk/build/test/findbugs/newPatchFindbugsWarnings.html
Checkstyle results: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch-h1.grid.sp2.yahoo.net/12/artifact/trunk/build/test/checkstyle-errors.html
Console output: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch-h1.grid.sp2.yahoo.net/12/console

This message is automatically generated.","18/Sep/09 23:28;jghoman;Patch review:
  * {code}System.getProperty(""test.build.data"") + ""/testContextURI"";{code} needs a default option, see HADOOP-5916
  * Remove the TODO comment 
  * Local and S3 implementations, you're catching but not handling an IOException.  The tests shouldn't proceed if one is thrown; don't catch it.
  * FileContextURIBase.java:121 Says an IOException is expected but catches an IllegalArgumentException.","18/Sep/09 23:42;raviphulari;Jakob, Thanks for reviewing patch. I have updated patch as per your suggestion.
 ","18/Sep/09 23:50;jghoman;+1","19/Sep/09 00:38;raviphulari;    [exec] 
     [exec] 
     [exec] There appear to be 4 release audit warnings before the patch and 4 release audit warnings after applying the patch.
     [exec] 
     [exec] 
     [exec] 
     [exec] 
     [exec] +1 overall.  
     [exec] 
     [exec]     +1 @author.  The patch does not contain any @author tags.
     [exec] 
     [exec]     +1 tests included.  The patch appears to include 20 new or modified tests.
     [exec] 
     [exec]     +1 javadoc.  The javadoc tool did not generate any warning messages.
     [exec] 
     [exec]     +1 javac.  The applied patch does not increase the total number of javac compiler warnings.
     [exec] 
     [exec]     +1 findbugs.  The patch does not introduce any new Findbugs warnings.
     [exec] 
     [exec]     +1 release audit.  The applied patch does not increase the total number of release audit warnings.
     [exec] 
     [exec] 
     [exec] 
     [exec] 
     [exec] ======================================================================
     [exec] ======================================================================
     [exec]     Finished build.
     [exec] ======================================================================
     [exec] ======================================================================
     [exec] 
     [exec] 

BUILD SUCCESSFUL
Total time: 20 minutes 15 seconds
","19/Sep/09 00:41;sureshms;Previous patch missed some files. Attaching new patch.","19/Sep/09 01:52;hadoopqa;-1 overall.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12420119/HADOOP-6261.patch
  against trunk revision 816847.

    +1 @author.  The patch does not contain any @author tags.

    +1 tests included.  The patch appears to include 20 new or modified tests.

    +1 javadoc.  The javadoc tool did not generate any warning messages.

    +1 javac.  The applied patch does not increase the total number of javac compiler warnings.

    +1 findbugs.  The patch does not introduce any new Findbugs warnings.

    +1 release audit.  The applied patch does not increase the total number of release audit warnings.

    -1 core tests.  The patch failed core unit tests.

    +1 contrib tests.  The patch passed contrib unit tests.

Test results: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch-h1.grid.sp2.yahoo.net/16/testReport/
Findbugs warnings: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch-h1.grid.sp2.yahoo.net/16/artifact/trunk/build/test/findbugs/newPatchFindbugsWarnings.html
Checkstyle results: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch-h1.grid.sp2.yahoo.net/16/artifact/trunk/build/test/checkstyle-errors.html
Console output: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch-h1.grid.sp2.yahoo.net/16/console

This message is automatically generated.","20/Sep/09 19:35;hadoopqa;-1 overall.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12420144/HADOOP-6261.patch
  against trunk revision 816847.

    +1 @author.  The patch does not contain any @author tags.

    +1 tests included.  The patch appears to include 20 new or modified tests.

    +1 javadoc.  The javadoc tool did not generate any warning messages.

    +1 javac.  The applied patch does not increase the total number of javac compiler warnings.

    +1 findbugs.  The patch does not introduce any new Findbugs warnings.

    +1 release audit.  The applied patch does not increase the total number of release audit warnings.

    -1 core tests.  The patch failed core unit tests.

    +1 contrib tests.  The patch passed contrib unit tests.

Test results: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch-h4.grid.sp2.yahoo.net/56/testReport/
Findbugs warnings: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch-h4.grid.sp2.yahoo.net/56/artifact/trunk/build/test/findbugs/newPatchFindbugsWarnings.html
Checkstyle results: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch-h4.grid.sp2.yahoo.net/56/artifact/trunk/build/test/checkstyle-errors.html
Console output: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch-h4.grid.sp2.yahoo.net/56/console

This message is automatically generated.","20/Sep/09 19:54;raviphulari;Above failure is due to  testListStatusFilterWithAnArrayOrPaths test in fs. 
http://hudson.zones.apache.org/hudson/job/Hadoop-Patch-h4.grid.sp2.yahoo.net/56/testReport/org.apache.hadoop.fs/TestLocalFSFileContextMainOperations/testListStatusFilterWithAnArrayOrPaths 

Above failure is not related to patch. ","21/Sep/09 17:28;garymurry;This is mine.  The test was expecting a certain order to the returned list.  I should have a fix shortly.  I am creating a jira for the patch.","21/Sep/09 21:58;hadoopqa;-1 overall.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12420144/HADOOP-6261.patch
  against trunk revision 817416.

    +1 @author.  The patch does not contain any @author tags.

    +1 tests included.  The patch appears to include 20 new or modified tests.

    +1 javadoc.  The javadoc tool did not generate any warning messages.

    +1 javac.  The applied patch does not increase the total number of javac compiler warnings.

    +1 findbugs.  The patch does not introduce any new Findbugs warnings.

    +1 release audit.  The applied patch does not increase the total number of release audit warnings.

    -1 core tests.  The patch failed core unit tests.

    +1 contrib tests.  The patch passed contrib unit tests.

Test results: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch-h4.grid.sp2.yahoo.net/60/testReport/
Findbugs warnings: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch-h4.grid.sp2.yahoo.net/60/artifact/trunk/build/test/findbugs/newPatchFindbugsWarnings.html
Checkstyle results: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch-h4.grid.sp2.yahoo.net/60/artifact/trunk/build/test/checkstyle-errors.html
Console output: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch-h4.grid.sp2.yahoo.net/60/console

This message is automatically generated.","22/Sep/09 00:09;jnp;+1. The code looks ok.","22/Sep/09 18:56;hadoopqa;+1 overall.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12420144/HADOOP-6261.patch
  against trunk revision 817496.

    +1 @author.  The patch does not contain any @author tags.

    +1 tests included.  The patch appears to include 20 new or modified tests.

    +1 javadoc.  The javadoc tool did not generate any warning messages.

    +1 javac.  The applied patch does not increase the total number of javac compiler warnings.

    +1 findbugs.  The patch does not introduce any new Findbugs warnings.

    +1 release audit.  The applied patch does not increase the total number of release audit warnings.

    +1 core tests.  The patch passed core unit tests.

    +1 contrib tests.  The patch passed contrib unit tests.

Test results: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch-h4.grid.sp2.yahoo.net/62/testReport/
Findbugs warnings: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch-h4.grid.sp2.yahoo.net/62/artifact/trunk/build/test/findbugs/newPatchFindbugsWarnings.html
Checkstyle results: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch-h4.grid.sp2.yahoo.net/62/artifact/trunk/build/test/checkstyle-errors.html
Console output: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch-h4.grid.sp2.yahoo.net/62/console

This message is automatically generated.","22/Sep/09 19:03;hadoopqa;+1 overall.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12420144/HADOOP-6261.patch
  against trunk revision 817496.

    +1 @author.  The patch does not contain any @author tags.

    +1 tests included.  The patch appears to include 20 new or modified tests.

    +1 javadoc.  The javadoc tool did not generate any warning messages.

    +1 javac.  The applied patch does not increase the total number of javac compiler warnings.

    +1 findbugs.  The patch does not introduce any new Findbugs warnings.

    +1 release audit.  The applied patch does not increase the total number of release audit warnings.

    +1 core tests.  The patch passed core unit tests.

    +1 contrib tests.  The patch passed contrib unit tests.

Test results: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch-h1.grid.sp2.yahoo.net/17/testReport/
Findbugs warnings: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch-h1.grid.sp2.yahoo.net/17/artifact/trunk/build/test/findbugs/newPatchFindbugsWarnings.html
Checkstyle results: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch-h1.grid.sp2.yahoo.net/17/artifact/trunk/build/test/checkstyle-errors.html
Console output: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch-h1.grid.sp2.yahoo.net/17/console

This message is automatically generated.","22/Sep/09 20:32;sureshms;Committed this change to both trunk and release 21. Thank you Ravi.
","22/Sep/09 20:40;hudson;Integrated in Hadoop-Common-trunk-Commit #49 (See [http://hudson.zones.apache.org/hudson/job/Hadoop-Common-trunk-Commit/49/])
    . Add URI based tests for FileContext. Contributed by Ravi Pulari.
","23/Sep/09 11:12;hudson;Integrated in Hadoop-Common-trunk #106 (See [http://hudson.zones.apache.org/hudson/job/Hadoop-Common-trunk/106/])
    . Add URI based tests for FileContext. Contributed by Ravi Pulari.
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Add test for non-writable serializer,HADOOP-2997,12390745,Test,Closed,HADOOP,Hadoop Common,software,omalley,Hadoop Common is the common library for Apache Hadoop.,http://hadoop.apache.org/,Blocker,Fixed,tomwhite,tomwhite,tomwhite,11/Mar/08 11:45,08/Jul/09 16:52,12/Jan/21 11:55,28/Mar/08 09:40,,,,,0.17.0,,,,,,,,,,0,,,It would be useful to have a unit test that tests MapReduce works using a non-writable serializer.,,Fan04290,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"13/Mar/08 10:23;tomwhite;hadoop-2997-v2.patch;https://issues.apache.org/jira/secure/attachment/12377764/hadoop-2997-v2.patch","13/Mar/08 12:50;tomwhite;hadoop-2997-v3.patch;https://issues.apache.org/jira/secure/attachment/12377777/hadoop-2997-v3.patch","11/Mar/08 11:47;tomwhite;hadoop-2997.patch;https://issues.apache.org/jira/secure/attachment/12377604/hadoop-2997.patch",,,,,,,,,,,,,,,,,,,,,3.0,,,,,,,,,,,,,,,,,,,,2008-03-12 22:19:23.251,,,false,,,,,,,,,,,,,,,,,125742,,,,,Sat Mar 29 12:07:07 UTC 2008,,,,,,,"0|i0ie2v:",105375,,,,,,,,,,,,,,,,,,,,,,,"12/Mar/08 22:19;hadoopqa;-1 overall.  Here are the results of testing the latest attachment 
http://issues.apache.org/jira/secure/attachment/12377604/hadoop-2997.patch
against trunk revision 619744.

    @author +1.  The patch does not contain any @author tags.

    tests included +1.  The patch appears to include 3 new or modified tests.

    javadoc +1.  The javadoc tool did not generate any warning messages.

    javac +1.  The applied patch does not generate any new javac compiler warnings.

    release audit -1.  The applied patch generated 193 release audit warnings (more than the trunk's current 192 warnings).

    findbugs +1.  The patch does not introduce any new Findbugs warnings.

    core tests -1.  The patch failed core unit tests.

    contrib tests +1.  The patch passed contrib unit tests.

Test results: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch/1945/testReport/
Findbugs warnings: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch/1945/artifact/trunk/build/test/findbugs/newPatchFindbugsWarnings.html
Checkstyle results: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch/1945/artifact/trunk/build/test/checkstyle-errors.html
Release audit warnings: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch/1945/artifact/trunk/current/releaseAuditDiffWarnings.txt
Console output: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch/1945/console

This message is automatically generated.","13/Mar/08 09:47;ddas;Tom, could you please address the hudson warning and resubmit the patch. Thanks!","13/Mar/08 10:23;tomwhite;I've fixed the release audit problem, the failing unit test reported by hudson was unrelated to this patch. *However*, this test now hangs consistently - it looks like it's related to the changes in HADOOP-2399 since the test passes when I run against revision 636622.","13/Mar/08 11:35;tomwhite;Tracked down the problem - the change in HADOOP-2399 creates instances of keys and values to be reused, however this is not possible for Java serialization since the types don't necessarily have no-arg constructors:

java.lang.RuntimeException: java.lang.NoSuchMethodException: java.lang.Long.<init>()
        at org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:80)
        at org.apache.hadoop.mapred.ReduceTask$ValuesIterator.<init>(ReduceTask.java:213)
        at org.apache.hadoop.mapred.ReduceTask$ReduceValuesIterator.<init>(ReduceTask.java:306)
        at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:388)
        at org.apache.hadoop.mapred.TaskTracker$Child.main(TaskTracker.java:2073)
Caused by: java.lang.NoSuchMethodException: java.lang.Long.<init>()
        at java.lang.Class.getConstructor0(Class.java:2678)
        at java.lang.Class.getDeclaredConstructor(Class.java:1953)
        at org.apache.hadoop.util.ReflectionUtils.newInstance(ReflectionUtils.java:74)
        ... 4 more

The fix is to get the deserializer to create the key and value types, if needed. I'm testing a patch.","14/Mar/08 11:28;hadoopqa;-1 overall.  Here are the results of testing the latest attachment 
http://issues.apache.org/jira/secure/attachment/12377777/hadoop-2997-v3.patch
against trunk revision 619744.

    @author +1.  The patch does not contain any @author tags.

    tests included +1.  The patch appears to include 3 new or modified tests.

    javadoc +1.  The javadoc tool did not generate any warning messages.

    javac +1.  The applied patch does not generate any new javac compiler warnings.

    release audit +1.  The applied patch does not generate any new release audit warnings.

    findbugs +1.  The patch does not introduce any new Findbugs warnings.

    core tests -1.  The patch failed core unit tests.

    contrib tests +1.  The patch passed contrib unit tests.

Test results: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch/1960/testReport/
Findbugs warnings: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch/1960/artifact/trunk/build/test/findbugs/newPatchFindbugsWarnings.html
Checkstyle results: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch/1960/artifact/trunk/build/test/checkstyle-errors.html
Console output: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch/1960/console

This message is automatically generated.","28/Mar/08 07:13;omalley;+1","28/Mar/08 09:40;ddas;I just committed this. Thanks, Tom!","28/Mar/08 12:17;hudson;Integrated in Hadoop-trunk #444 (See [http://hudson.zones.apache.org/hudson/job/Hadoop-trunk/444/])","29/Mar/08 12:07;hudson;Integrated in Hadoop-trunk #445 (See [http://hudson.zones.apache.org/hudson/job/Hadoop-trunk/445/])",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
TestLeaseRecovery.testBlockSynchronization failed on trunk,HADOOP-4403,12406324,Test,Closed,HADOOP,Hadoop Common,software,omalley,Hadoop Common is the common library for Apache Hadoop.,http://hadoop.apache.org/,Blocker,Fixed,szetszwo,yhemanth,yhemanth,13/Oct/08 18:16,08/Jul/09 16:43,12/Jan/21 11:55,14/Oct/08 18:50,,,,,0.18.2,,,,,,test,,,,0,,,TestLeaseRecovery.testBlockSynchronization failed on a hadoop patch build. Please refer to http://hudson.zones.apache.org/hudson/job/Hadoop-Patch/3450/testReport/org.apache.hadoop.hdfs/TestLeaseRecovery/testBlockSynchronization/ for details. I don't know if it is a random issue.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"13/Oct/08 21:20;szetszwo;4403_20081013.patch;https://issues.apache.org/jira/secure/attachment/12392035/4403_20081013.patch","14/Oct/08 02:28;szetszwo;4403_20081013b.patch;https://issues.apache.org/jira/secure/attachment/12392058/4403_20081013b.patch","14/Oct/08 18:47;szetszwo;4403_20081013b_0.18.patch;https://issues.apache.org/jira/secure/attachment/12392120/4403_20081013b_0.18.patch",,,,,,,,,,,,,,,,,,,,,3.0,,,,,,,,,,,,,,,,,,,,2008-10-13 21:13:12.598,,,false,,,,,,,,,,,,,,,,,126522,Reviewed,,,,Wed Oct 15 13:56:30 UTC 2008,,,,,,,"0|i0i7o7:",104337,,,,,,,,,,,,,,,,,,,,,,,"13/Oct/08 21:13;szetszwo;This is a test problem: after created a file, we should wait for replication before proceeding in this test.","13/Oct/08 21:20;szetszwo;4403_20081013.patch: waitReplication","13/Oct/08 21:44;szetszwo;>  I don't know if it is a random issue.
The failure is random.

BTW, the failure is nothing to do with lease recovery.","13/Oct/08 22:43;hairong;+1. The patch looks good.","14/Oct/08 00:20;hadoopqa;-1 overall.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12392035/4403_20081013.patch
  against trunk revision 704261.

    +1 @author.  The patch does not contain any @author tags.

    +1 tests included.  The patch appears to include 3 new or modified tests.

    +1 javadoc.  The javadoc tool did not generate any warning messages.

    +1 javac.  The applied patch does not increase the total number of javac compiler warnings.

    +1 findbugs.  The patch does not introduce any new Findbugs warnings.

    +1 Eclipse classpath. The patch retains Eclipse classpath integrity.

    -1 core tests.  The patch failed core unit tests.

    +1 contrib tests.  The patch passed contrib unit tests.

Test results: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch/3452/testReport/
Findbugs warnings: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch/3452/artifact/trunk/build/test/findbugs/newPatchFindbugsWarnings.html
Checkstyle results: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch/3452/artifact/trunk/build/test/checkstyle-errors.html
Console output: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch/3452/console

This message is automatically generated.","14/Oct/08 02:28;szetszwo;4403_20081013b.patch: make TestFileCreation more robust.","14/Oct/08 07:49;hadoopqa;-1 overall.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12392058/4403_20081013b.patch
  against trunk revision 704310.

    +1 @author.  The patch does not contain any @author tags.

    +1 tests included.  The patch appears to include 6 new or modified tests.

    +1 javadoc.  The javadoc tool did not generate any warning messages.

    +1 javac.  The applied patch does not increase the total number of javac compiler warnings.

    +1 findbugs.  The patch does not introduce any new Findbugs warnings.

    +1 Eclipse classpath. The patch retains Eclipse classpath integrity.

    -1 core tests.  The patch failed core unit tests.

    +1 contrib tests.  The patch passed contrib unit tests.

Test results: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch/3455/testReport/
Findbugs warnings: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch/3455/artifact/trunk/build/test/findbugs/newPatchFindbugsWarnings.html
Checkstyle results: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch/3455/artifact/trunk/build/test/checkstyle-errors.html
Console output: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch/3455/console

This message is automatically generated.","14/Oct/08 18:47;szetszwo;4403_20081013b_0.18.patch: for 0.18","14/Oct/08 18:50;szetszwo;I just committed this.","15/Oct/08 13:56;hudson;Integrated in Hadoop-trunk #634 (See [http://hudson.zones.apache.org/hudson/job/Hadoop-trunk/634/])
    . Make TestLeaseRecovery and TestFileCreation more robust. (szetszwo)
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Block CRC Unit Tests: upgrade test,HADOOP-1629,12374040,Test,Closed,HADOOP,Hadoop Common,software,omalley,Hadoop Common is the common library for Apache Hadoop.,http://hadoop.apache.org/,Blocker,Fixed,rangadi,nidaley,nidaley,18/Jul/07 03:42,08/Jul/09 16:42,12/Jan/21 11:55,15/Aug/07 14:57,0.14.0,,,,0.14.0,,,,,,,,,,0,,,"HADOOP-1286 introduced a distributed upgrade framework.  1 or more unit tests should be developed that start with a zipped up Hadoop 0.12 file system (that is included in Hadoop's src/test directory under version controlled) and attempts to upgrade it to the current version of Hadoop (ie the version that the tests are running against).  The zipped up file system should include some ""interesting"" files, such as:

- zero length files
- file with replication set higher than number of datanodes
- file with no .crc file
- file with corrupt .crc file
- file with multiple blocks (will need to set dfs.block.size to a small value)
- file with multiple checksum blocks
- empty directory
- all of the above again but with a different io.bytes.per.checksum setting

The class that generates the zipped up file system should also be included in this patch.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"13/Aug/07 20:01;rangadi;HADOOP-1629-trunk.patch;https://issues.apache.org/jira/secure/attachment/12363716/HADOOP-1629-trunk.patch","10/Aug/07 17:40;rangadi;HADOOP-1629.patch;https://issues.apache.org/jira/secure/attachment/12363602/HADOOP-1629.patch","09/Aug/07 22:48;rangadi;HADOOP-1629.patch;https://issues.apache.org/jira/secure/attachment/12363538/HADOOP-1629.patch","08/Aug/07 22:15;rangadi;HADOOP-1629.patch;https://issues.apache.org/jira/secure/attachment/12363450/HADOOP-1629.patch","08/Aug/07 22:16;rangadi;hadoop-12-dfs-dir.tgz;https://issues.apache.org/jira/secure/attachment/12363451/hadoop-12-dfs-dir.tgz",,,,,,,,,,,,,,,,,,,5.0,,,,,,,,,,,,,,,,,,,,2007-07-24 19:08:26.986,,,false,,,,,,,,,,,,,,,,,125340,,,,,Wed Aug 15 14:57:54 UTC 2007,,,,,,,"0|i0hxp3:",102721,,,,,,,,,,,,,,,,,,,,,,,"24/Jul/07 19:08;rangadi;Any suggestions on how large the tar-gzip file should be? I can write simple text to blocks so that they compress very well. Since this is meant to be committed, what do you think is reasonable size?
","24/Jul/07 19:17;cutting;> Any suggestions on how large the tar-gzip file should be?

1MB?  We should be able to use small block and buffer sizes to get all of the desired sample files into a meg, no?","24/Jul/07 19:25;rangadi;1MB sounds good. Will plan to keep it even smaller (< 500K) if possible.. so that this will be in the same order as some of the larger source files we have.
","24/Jul/07 19:25;nidaley;I would suspect this could be far smaller than 500Kb once  
compressed.  Also, I think you want to use the java.io.Zip* stuff to  
zip and unzip.




","25/Jul/07 22:29;rangadi;Any suggestions on getting tar.gz functionality in java? Should we pack the directory tree with our own simple format?","26/Jul/07 21:08;cutting;> Any suggestions on getting tar.gz functionality in java?

HADOOP-1622 adds tools to both pack and unpack jar files.  (We currently have only a tool to unpack them in Hadoop, in util.RunJar.)  Will those work?  Jar files can have compression.","08/Aug/07 22:15;rangadi;
Thanks to Nigel for helping through this.

Attached patch for new unit test ""TestDFSUpgradeFromImage"". This is an end-to-end test for upgrade from Hadoop-0.12 to current version. The initial image contain the various categories and error that Nigel mentioned in the Jira desription. 

For now we are using tar-gzipped file. Hadoop anyway requires cygwin. Once HADOOP-1622 goes in we can change the format. 

The patch does not actually contain the {{.tgz}} file. Will attach it. hadoop-12-dfs-dir.txt contains a description of the data and the file checksums that are verified during the unit test.
","08/Aug/07 22:16;rangadi;
attaching hadoop-12-dfs-dir.tgz

Note commiters: Please place this file next to hadoop-12-dfs-dir.txt
","09/Aug/07 22:48;rangadi;Previous patch was missing a file. Now fixed.","09/Aug/07 23:43;nidaley;Looks good, just a few code review comments:

the test needs more comments, especially a reference to the ancillary files that it depends on

private void setupDFSImage() 
should be 
public void setup() 
which Junit will call automatically before the test method.

while ( (line = reader.readLine()) != null ) {
perhaps should be
while ( (line = reader.readLine().trim()) != null ) {

some spacing is wrong

value variable should be better named
","10/Aug/07 17:40;rangadi;Thanks for the feedback Nigel.

Attached the improved patch that includes all of the suggested changes.","13/Aug/07 18:31;nidaley;This patch is ready.","13/Aug/07 18:48;hadoopqa;-1, build or testing failed

2 attempts failed to build and test the latest attachment http://issues.apache.org/jira/secure/attachment/12363602/HADOOP-1629.patch against trunk revision r565434.

Test results:   http://lucene.zones.apache.org:8080/hudson/job/Hadoop-Patch/545/testReport/
Console output: http://lucene.zones.apache.org:8080/hudson/job/Hadoop-Patch/545/console

Please note that this message is automatically generated and may represent a problem with the automation system and not the patch.","13/Aug/07 19:27;rangadi;This conflicts with HADOOP-1621 on the trunk. Will submit different patches for 14 and trunk.
","13/Aug/07 20:01;rangadi;Attached patch for the trunk. Please use HADOOP-1629.patch for branch 14. The difference between the patch is minor. (TestDFSUpgradeFromTrunk.java:136).
","13/Aug/07 20:03;rangadi;TestDFSUpgradeFromImage will fail in the build since it will not have the tar file. ","13/Aug/07 20:43;hadoopqa;-1, build or testing failed

2 attempts failed to build and test the latest attachment http://issues.apache.org/jira/secure/attachment/12363716/HADOOP-1629-trunk.patch against trunk revision r565434.

Test results:   http://lucene.zones.apache.org:8080/hudson/job/Hadoop-Patch/547/testReport/
Console output: http://lucene.zones.apache.org:8080/hudson/job/Hadoop-Patch/547/console

Please note that this message is automatically generated and may represent a problem with the automation system and not the patch.","13/Aug/07 20:46;rangadi;The above failure is expected. ""patch available"" is valid. 

","14/Aug/07 01:13;nidaley;I just committed this.  Thanks Raghu!","15/Aug/07 14:21;enis;I am reopening this issue, since TestDFSUpgradeFromImage fails for hadoop-patch and hudson-nightly builds on hudson. 
The error thrown is :
{noformat}
java.io.IOException: tar: z: unknown function modifier
	at org.apache.hadoop.fs.Command.run(Command.java:33)
	at org.apache.hadoop.fs.Command.execCommand(Command.java:89)
	at org.apache.hadoop.dfs.TestDFSUpgradeFromImage.setUp(TestDFSUpgradeFromImage.java:75)

Standard Output

2007-08-15 13:22:38,601 INFO  dfs.TestDFSUpgradeFromImage (TestDFSUpgradeFromImage.java:setUp(72)) - Unpacking the tar file /export/home/hudson/hudson/jobs/Hadoop-Patch/workspace/trunk/build/test/cache/hadoop-12-dfs-dir.tgz
{noformat}

It seems that gzip is not installed on the lucene.zones.apache.org . Can someone with the privileges check this out.  ","15/Aug/07 14:57;nidaley;Enis, I opened a new Jira, HADOOP-1717, to track the failing of this test on Solaris.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Block CRC Unit Tests: protocol tests,HADOOP-1628,12374039,Test,Closed,HADOOP,Hadoop Common,software,omalley,Hadoop Common is the common library for Apache Hadoop.,http://hadoop.apache.org/,Blocker,Fixed,rangadi,nidaley,nidaley,18/Jul/07 03:31,08/Jul/09 16:42,12/Jan/21 11:55,25/Jul/07 22:00,0.14.0,,,,0.14.0,,,,,,,,,,0,,,"HADOOP-1134 introduced a new protocol between DFS clients and DataNodes.  This protocol needs some unit tests that at least cover these cases:

- bad op codes
- bad field lengths
- bad offsets
- bad versions
- bad block ids",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"25/Jul/07 17:54;rangadi;HADOOP-1628.patch;https://issues.apache.org/jira/secure/attachment/12362542/HADOOP-1628.patch","23/Jul/07 21:07;rangadi;HADOOP-1628.patch;https://issues.apache.org/jira/secure/attachment/12362371/HADOOP-1628.patch",,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,2007-07-23 19:35:35.215,,,false,,,,,,,,,,,,,,,,,125339,,,,,Wed Jul 25 22:00:08 UTC 2007,,,,,,,"0|i0iipr:",106126,,,,,,,,,,,,,,,,,,,,,,,"23/Jul/07 19:35;rangadi;While writing these tests, I noticed some inconsistencies in the current protocol implementation (for e.g. response status for OP_WRITE_BLOCK is one byte, and it is two bytes for OP_READ_BLOCK). 

For this patch, I am planning to note these inconsistencies in in comment and write the test accordingly and fix both in a seperate Jira. Fixing the tests is pretty simple. ","23/Jul/07 21:07;rangadi;Attaching unit test for data transfer protocol. This test sends malformed requests to the Datanode and verifies that Datanode responds as expected (sometimes EOF and sometime ERROR status etc).
","25/Jul/07 17:22;dhruba;+1. Code looks good.","25/Jul/07 17:54;rangadi;
Thanks Dhruba.

The latest patch changes the status reply for OP_WRITE_BLOCK to be a short instead of byte to be consistent with OP_READ_BLOCK.","25/Jul/07 19:42;hadoopqa;+1

http://issues.apache.org/jira/secure/attachment/12362542/HADOOP-1628.patch applied and successfully tested against trunk revision r559068.

Test results:   http://lucene.zones.apache.org:8080/hudson/job/Hadoop-Patch/463/testReport/
Console output: http://lucene.zones.apache.org:8080/hudson/job/Hadoop-Patch/463/console","25/Jul/07 22:00;omalley;I committed this. Thanks, Raghu!",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
TestCapacityScheduler is broken,HADOOP-4426,12406561,Test,Closed,HADOOP,Hadoop Common,software,omalley,Hadoop Common is the common library for Apache Hadoop.,http://hadoop.apache.org/,Blocker,Fixed,yhemanth,yhemanth,yhemanth,16/Oct/08 04:46,08/Jul/09 16:40,12/Jan/21 11:55,16/Oct/08 05:59,0.19.0,,,,0.19.0,,,,,,,,,,0,,,"The commits for HADOOP-4053 and HADOOP-4373 caused each other's test cases to break. The patches were being worked on in parallel, and hence the break wasn't caught earlier.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"16/Oct/08 05:01;yhemanth;HADOOP-4426.patch;https://issues.apache.org/jira/secure/attachment/12392224/HADOOP-4426.patch",,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,2008-10-16 05:19:02.551,,,false,,,,,,,,,,,,,,,,,126533,,,,,Thu Oct 16 15:55:49 UTC 2008,,,,,,,"0|i0i7kf:",104320,,,,,,,,,,,,,,,,,,,,,,,"16/Oct/08 05:01;yhemanth;{{testJobRunStateChange}} was setting the guaranteed capacity percentage as 1%. Before HADOOP-4373, this would have returned a task nevertheless. Fixed the test case to set it to 100%.

{{testCapacityBasedAllocation}} was broken by changes in HADOOP-4053. As {{jobUpdated}} is not called now from the capacity scheduler, but instead only from the real JobTracker, the job which was to be picked up was not moved to the running queue. The test case is updated to raise the required event.","16/Oct/08 05:19;amar_kamat;bq. testJobRunStateChange was setting the guaranteed capacity percentage as 1%.
+1. Changed it to 100% and it worked fine.

bq. testCapacityBasedAllocation was broken by changes in HADOOP-4053.
Other testcases in {{TestCapacityScheduler}} were also failing and I fixed them by using {{submitJobAndInit()}}. {{submitJobAndInit()}} makes sure that the job gets submitted and also the listeners are informed.

+1 for the short fix. ","16/Oct/08 05:28;yhemanth;Results of ant test-patch:

     [exec] +1 overall.

     [exec]     +1 @author.  The patch does not contain any @author tags.

     [exec]     +1 tests included.  The patch appears to include 3 new or modified tests.

     [exec]     +1 javadoc.  The javadoc tool did not generate any warning messages.

     [exec]     +1 javac.  The applied patch does not increase the total number of javac compiler warnings.

     [exec]     +1 findbugs.  The patch does not introduce any new Findbugs warnings.

     [exec]     +1 Eclipse classpath. The patch retains Eclipse classpath integrity.

Since this is only affecting the contrib tests, I ran ant test-contrib. All tests passed.","16/Oct/08 05:59;ddas;I just committed this. Thanks, Hemanth!","16/Oct/08 07:37;hadoopqa;-1 overall.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12392224/HADOOP-4426.patch
  against trunk revision 705124.

    +1 @author.  The patch does not contain any @author tags.

    +1 tests included.  The patch appears to include 3 new or modified tests.

    +1 javadoc.  The javadoc tool did not generate any warning messages.

    +1 javac.  The applied patch does not increase the total number of javac compiler warnings.

    +1 findbugs.  The patch does not introduce any new Findbugs warnings.

    +1 Eclipse classpath. The patch retains Eclipse classpath integrity.

    -1 core tests.  The patch failed core unit tests.

    +1 contrib tests.  The patch passed contrib unit tests.

Test results: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch/3472/testReport/
Findbugs warnings: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch/3472/artifact/trunk/build/test/findbugs/newPatchFindbugsWarnings.html
Checkstyle results: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch/3472/artifact/trunk/build/test/checkstyle-errors.html
Console output: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch/3472/console

This message is automatically generated.","16/Oct/08 15:55;hudson;Integrated in Hadoop-trunk #635 (See [http://hudson.zones.apache.org/hudson/job/Hadoop-trunk/635/])
    . TestCapacityScheduler broke due to the two commits HADOOP-4053 and HADOOP-4373. This patch fixes that. Contributed by Hemanth Yamijala.
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
TestUlimit is failing after Hadoop-4620,HADOOP-4857,12410569,Test,Closed,HADOOP,Hadoop Common,software,omalley,Hadoop Common is the common library for Apache Hadoop.,http://hadoop.apache.org/,Blocker,Fixed,ravidotg,sharadag,sharadag,12/Dec/08 10:17,23/Apr/09 19:17,12/Jan/21 11:55,12/Dec/08 12:59,,,,,0.20.0,,,,,,test,,,,0,,,"TestUlimit launches 3 map tasks and generates output for only 1 as input to other 2 map tasks are empty. With Hadoop-4620, even the map tasks with empty input are generating the output.
The fix could be just setting the no of mapper to 1",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"12/Dec/08 10:20;sharadag;4857.patch;https://issues.apache.org/jira/secure/attachment/12395929/4857.patch",,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,2008-12-12 12:21:52.26,,,false,,,,,,,,,,,,,,,,,126777,Reviewed,,,,Fri Dec 12 12:21:52 UTC 2008,,,,,,,"0|i0i5zj:",104064,,,,,,,,,,,,,,,,,,,,,,,"12/Dec/08 12:16;sharadag;+1","12/Dec/08 12:21;ddas;+1
I just committed this to 0.18, 0.19 branches and trunk. Thanks Sharad & Ravi!",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Separate testClientTriggeredLeaseRecovery() out from TestFileCreation,HADOOP-4464,12406851,Test,Closed,HADOOP,Hadoop Common,software,omalley,Hadoop Common is the common library for Apache Hadoop.,http://hadoop.apache.org/,Blocker,Fixed,szetszwo,szetszwo,szetszwo,20/Oct/08 18:17,20/Nov/08 23:38,12/Jan/21 11:55,20/Oct/08 19:07,,,,,0.19.0,,,,,,test,,,,0,,,TestFileCreation.testClientTriggeredLeaseRecovery() failed in some recent Hudson build.  We should separate testClientTriggeredLeaseRecovery() out from TestFileCreation for easily debugging.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"20/Oct/08 18:19;szetszwo;4464_20081020.patch;https://issues.apache.org/jira/secure/attachment/12392514/4464_20081020.patch",,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,2008-10-20 18:38:48.399,,,false,,,,,,,,,,,,,,,,,126564,Reviewed,,,,Thu Oct 23 21:56:34 UTC 2008,,,,,,,"0|i0i7d3:",104287,,,,,,,,,,,,,,,,,,,,,,,"20/Oct/08 18:19;szetszwo;4464_20081020.patch: moved testClientTriggeredLeaseRecovery() to a new file and changed log levels.","20/Oct/08 18:22;szetszwo;BTW, I have run 500 times in my local machine on trunk for TestFileCreation.testClientTriggeredLeaseRecovery() but I cannot see any failures.  I suspect the failure was due to some machine problems on Hudson.","20/Oct/08 18:28;szetszwo;Both TestFileCreation and TestFileCreationClient don't have any problem in my local machines.  I am running ""ant test-patch"" now.  I plan to commit it without submitting once it has passed ""ant test-patch"", so that the new test could be run more in Hudson.","20/Oct/08 18:32;szetszwo;{noformat}
     [exec] +1 overall.  

     [exec]     +1 @author.  The patch does not contain any @author tags.

     [exec]     +1 tests included.  The patch appears to include 6 new or modified tests.

     [exec]     +1 javadoc.  The javadoc tool did not generate any warning messages.

     [exec]     +1 javac.  The applied patch does not increase the total number of javac compiler warnings.

     [exec]     +1 findbugs.  The patch does not introduce any new Findbugs warnings.

     [exec]     +1 Eclipse classpath. The patch retains Eclipse classpath integrity.
{noformat}","20/Oct/08 18:38;cdouglas;+1","20/Oct/08 19:07;cdouglas;I just committed this. Thanks, Nicholas","23/Oct/08 21:56;hudson;Integrated in Hadoop-trunk #640 (See [http://hudson.zones.apache.org/hudson/job/Hadoop-trunk/640/])
    ",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
test-patch.sh goes into an infinite loop on non-maven builds,HADOOP-11904,12826738,Test,Resolved,HADOOP,Hadoop Common,software,omalley,Hadoop Common is the common library for Apache Hadoop.,http://hadoop.apache.org/,Critical,Fixed,aw,aw,aw,02/May/15 17:59,30/Aug/16 01:28,12/Jan/21 11:55,05/May/15 18:08,,,,,2.8.0,3.0.0-alpha1,,,,,test,,,,0,,,"If post HADOOP-11746 test patch is given a non-maven-based build, it goes into an infinite loop looking for modules pom.xml.  There should be an escape clause after switching branches to see if it is maven based. If it is not maven based, then test-patch should either abort or re-exec using that version's test-patch script.",,aw,busbey,hudson,omalley,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"03/May/15 20:06;aw;HADOOP-11904.patch;https://issues.apache.org/jira/secure/attachment/12730046/HADOOP-11904.patch",,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,2015-05-05 17:56:31.06,,,false,,,,,,,,,,,,,,,,,9223372036854775807,,,,,Wed May 06 16:56:32 UTC 2015,,,,,,,"0|i2e7pz:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,"05/May/15 17:56;omalley;+1 looks good, Allen","05/May/15 18:01;hadoopqa;(!) A patch to test-patch or smart-apply-patch has been detected. 
Re-executing against the patched versions to perform further tests. 
The console is at https://builds.apache.org/job/PreCommit-HADOOP-Build/6486/console in case of problems.","05/May/15 18:02;hadoopqa;\\
\\
| (/) *{color:green}+1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | reexec |   0m  0s | dev-support patch detected. |
| {color:blue}0{color} | pre-patch |   0m  0s | Pre-patch trunk compilation is healthy. |
| {color:blue}0{color} | @author |   0m  0s | Skipping @author checks as test-patch has been patched. |
| {color:green}+1{color} | release audit |   0m 15s | The applied patch does not increase the total number of release audit warnings. |
| {color:blue}0{color} | shellcheck |   0m 15s | Shellcheck was not available. |
| {color:green}+1{color} | whitespace |   0m  0s | The patch has no lines that end in whitespace. |
| | |   0m 23s | |
\\
\\
|| Subsystem || Report/Notes ||
| Patch URL | http://issues.apache.org/jira/secure/attachment/12730046/HADOOP-11904.patch |
| Optional Tests | shellcheck |
| git revision | trunk / fcd4cb7 |
| Java | 1.7.0_55 |
| uname | Linux asf901.gq1.ygridcore.net 3.13.0-36-lowlatency #63-Ubuntu SMP PREEMPT Wed Sep 3 21:56:12 UTC 2014 x86_64 x86_64 x86_64 GNU/Linux |
| Console output | https://builds.apache.org/job/PreCommit-HADOOP-Build/6486/console |


This message was automatically generated.","05/May/15 18:08;aw;thanks!
committed","05/May/15 18:19;hudson;FAILURE: Integrated in Hadoop-trunk-Commit #7737 (See [https://builds.apache.org/job/Hadoop-trunk-Commit/7737/])
HADOOP-11904. test-patch.sh goes into an infinite loop on non-maven builds (aw) (aw: rev 3ff91e9e9302d94b0d18cccebd02d3815c06ce90)
* hadoop-common-project/hadoop-common/CHANGES.txt
* dev-support/test-patch.sh
","06/May/15 12:50;hudson;FAILURE: Integrated in Hadoop-Yarn-trunk-Java8 #186 (See [https://builds.apache.org/job/Hadoop-Yarn-trunk-Java8/186/])
HADOOP-11904. test-patch.sh goes into an infinite loop on non-maven builds (aw) (aw: rev 3ff91e9e9302d94b0d18cccebd02d3815c06ce90)
* dev-support/test-patch.sh
* hadoop-common-project/hadoop-common/CHANGES.txt
","06/May/15 13:09;hudson;SUCCESS: Integrated in Hadoop-Yarn-trunk #919 (See [https://builds.apache.org/job/Hadoop-Yarn-trunk/919/])
HADOOP-11904. test-patch.sh goes into an infinite loop on non-maven builds (aw) (aw: rev 3ff91e9e9302d94b0d18cccebd02d3815c06ce90)
* dev-support/test-patch.sh
* hadoop-common-project/hadoop-common/CHANGES.txt
","06/May/15 15:32;hudson;FAILURE: Integrated in Hadoop-Hdfs-trunk #2117 (See [https://builds.apache.org/job/Hadoop-Hdfs-trunk/2117/])
HADOOP-11904. test-patch.sh goes into an infinite loop on non-maven builds (aw) (aw: rev 3ff91e9e9302d94b0d18cccebd02d3815c06ce90)
* hadoop-common-project/hadoop-common/CHANGES.txt
* dev-support/test-patch.sh
","06/May/15 15:36;hudson;FAILURE: Integrated in Hadoop-Hdfs-trunk-Java8 #176 (See [https://builds.apache.org/job/Hadoop-Hdfs-trunk-Java8/176/])
HADOOP-11904. test-patch.sh goes into an infinite loop on non-maven builds (aw) (aw: rev 3ff91e9e9302d94b0d18cccebd02d3815c06ce90)
* dev-support/test-patch.sh
* hadoop-common-project/hadoop-common/CHANGES.txt
","06/May/15 15:51;busbey;Ugh. This totally broke my reuse efforts over on NIFI-577. I was relying on the plugin system to move into the correct sub-directory to get to poms. I'll file a ticket to add plugin points instead of overriding post checkout?","06/May/15 16:48;hudson;FAILURE: Integrated in Hadoop-Mapreduce-trunk #2135 (See [https://builds.apache.org/job/Hadoop-Mapreduce-trunk/2135/])
HADOOP-11904. test-patch.sh goes into an infinite loop on non-maven builds (aw) (aw: rev 3ff91e9e9302d94b0d18cccebd02d3815c06ce90)
* hadoop-common-project/hadoop-common/CHANGES.txt
* dev-support/test-patch.sh
","06/May/15 16:56;hudson;SUCCESS: Integrated in Hadoop-Mapreduce-trunk-Java8 #186 (See [https://builds.apache.org/job/Hadoop-Mapreduce-trunk-Java8/186/])
HADOOP-11904. test-patch.sh goes into an infinite loop on non-maven builds (aw) (aw: rev 3ff91e9e9302d94b0d18cccebd02d3815c06ce90)
* hadoop-common-project/hadoop-common/CHANGES.txt
* dev-support/test-patch.sh
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Update the hadoop version in TestDynamometerInfra,HADOOP-17442,13347160,Test,Open,HADOOP,Hadoop Common,software,omalley,Hadoop Common is the common library for Apache Hadoop.,http://hadoop.apache.org/,Major,,tasanuma,tasanuma,tasanuma,21/Dec/20 15:25,21/Dec/20 15:25,12/Jan/21 11:55,,,,,,,,,,,,,,,,0,,,,,tasanuma,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,9223372036854775807,,,,,2020-12-21 15:25:18.0,,,,,,,"0|z0lpjc:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Move personality file from Yetus to Hadoop repository ,HADOOP-17205,13322598,Test,Resolved,HADOOP,Hadoop Common,software,omalley,Hadoop Common is the common library for Apache Hadoop.,http://hadoop.apache.org/,Major,Fixed,csun,csun,csun,13/Aug/20 19:24,18/Aug/20 22:36,12/Jan/21 11:55,18/Aug/20 03:14,,,,,2.10.1,2.9.3,3.1.5,3.2.2,3.3.1,3.4.0,test,yetus,,,0,,,"Currently for CI build and testing we maintain personality scripts (i.e., [here|https://github.com/apache/yetus/blob/master/precommit/src/main/shell/personality/hadoop.sh]) in both Apache Yetus and Apache Hadoop. This poses problem when one needs to change both places, for example HADOOP-17125. 

This proposes to move the personality file into the Hadoop repo itself, so that we can manage them in a single place. The downside for this is we may need to duplicate the scripts in every branch. ",,aajisaka,csun,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,2020-08-18 03:14:42.69,,,false,,,,,,,,,,,,,,,,,9223372036854775807,Reviewed,,,,Tue Aug 18 22:36:47 UTC 2020,,,,,,,"0|z0hr3c:",9223372036854775807,,,,,,,,,,,,,2.10.1,2.9.3,3.1.5,3.2.2,3.3.1,3.4.0,,,,,"13/Aug/20 19:24;csun;cc [~aajisaka]","18/Aug/20 03:14;aajisaka;Merged the PR into all the active branches. Thank you [~csun] for your contribution!","18/Aug/20 03:43;aajisaka;Also updated the configs of the precommit jobs (e.g. PreCommit-HADOOP-Build) to use the script.","18/Aug/20 22:36;csun;Thanks [~aajisaka] for the review and commits to other branches!",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Contract test for FS shell commands,HADOOP-13751,13014737,Test,Open,HADOOP,Hadoop Common,software,omalley,Hadoop Common is the common library for Apache Hadoop.,http://hadoop.apache.org/,Major,,,jzhuge,jzhuge,24/Oct/16 14:20,09/Apr/20 18:52,12/Jan/21 11:55,,3.0.0-alpha2,,,,,,,,,,fs,,,,0,,,Create a base contract test for FS shell commands so that various filesystems can subclass and implement.,,brahmareddy,jzhuge,stevel@apache.org,sunilg,weichiu,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,2016-10-24 15:34:04.969,,,false,,,,,,,,,,,,,,,,,9223372036854775807,,,,,Thu Apr 09 18:52:11 UTC 2020,,,,,,,"0|i35awf:",9223372036854775807,,,,,,,,,,,,,3.4.0,,,,,,,,,,"24/Oct/16 15:34;stevel@apache.org;+the hard part: fix the broken implementations. Best to start on the core filesystems, then add an object store at a time","23/Nov/18 11:56;sunilg;Bulk update: moved all 3.2.0 non-blocker issues, please move back if it is a blocker.","09/Apr/20 18:52;brahmareddy;Bulk update: moved all 3.3.0 non-blocker issues, please move back if it is a blocker.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
TestSFTPFileSystem#testFileExists failure: Invalid encoding for signature,HADOOP-14206,13057777,Test,Resolved,HADOOP,Hadoop Common,software,omalley,Hadoop Common is the common library for Apache Hadoop.,http://hadoop.apache.org/,Major,Fixed,Jim_Brennan,jzhuge,jzhuge,21/Mar/17 03:37,08/Mar/20 18:46,12/Jan/21 11:55,08/Mar/20 08:12,2.9.0,,,,2.10.1,2.9.3,3.1.4,3.2.2,3.3.0,,fs,test,,,0,,,"https://builds.apache.org/job/PreCommit-HADOOP-Build/11862/artifact/patchprocess/patch-unit-hadoop-common-project_hadoop-common-jdk1.7.0_121.txt:
{noformat}
Tests run: 9, Failures: 0, Errors: 1, Skipped: 0, Time elapsed: 10.454 sec <<< FAILURE! - in org.apache.hadoop.fs.sftp.TestSFTPFileSystem
testFileExists(org.apache.hadoop.fs.sftp.TestSFTPFileSystem)  Time elapsed: 0.19 sec  <<< ERROR!
java.io.IOException: com.jcraft.jsch.JSchException: Session.connect: java.security.SignatureException: Invalid encoding for signature
	at com.jcraft.jsch.Session.connect(Session.java:565)
	at com.jcraft.jsch.Session.connect(Session.java:183)
	at org.apache.hadoop.fs.sftp.SFTPConnectionPool.connect(SFTPConnectionPool.java:168)
	at org.apache.hadoop.fs.sftp.SFTPFileSystem.connect(SFTPFileSystem.java:149)
	at org.apache.hadoop.fs.sftp.SFTPFileSystem.getFileStatus(SFTPFileSystem.java:663)
	at org.apache.hadoop.fs.FileSystem.exists(FileSystem.java:1626)
	at org.apache.hadoop.fs.sftp.TestSFTPFileSystem.testFileExists(TestSFTPFileSystem.java:190)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:55)
	at org.junit.rules.RunRules.evaluate(RunRules.java:20)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:264)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:153)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:124)
	at org.apache.maven.surefire.booter.ForkedBooter.invokeProviderInSameClassLoader(ForkedBooter.java:200)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:153)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:103)

	at org.apache.hadoop.fs.sftp.SFTPConnectionPool.connect(SFTPConnectionPool.java:180)
	at org.apache.hadoop.fs.sftp.SFTPFileSystem.connect(SFTPFileSystem.java:149)
	at org.apache.hadoop.fs.sftp.SFTPFileSystem.getFileStatus(SFTPFileSystem.java:663)
	at org.apache.hadoop.fs.FileSystem.exists(FileSystem.java:1626)
	at org.apache.hadoop.fs.sftp.TestSFTPFileSystem.testFileExists(TestSFTPFileSystem.java:190)
{noformat}",,hudson,Jim_Brennan,jzhuge,stevel@apache.org,sunilg,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"05/Mar/20 21:41;Jim_Brennan;HADOOP-14206-branch-2.10.001.patch;https://issues.apache.org/jira/secure/attachment/12995786/HADOOP-14206-branch-2.10.001.patch","05/Mar/20 21:45;Jim_Brennan;HADOOP-14206.001.patch;https://issues.apache.org/jira/secure/attachment/12995787/HADOOP-14206.001.patch",,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,2018-11-23 11:55:53.835,,,false,,,,,,,,,,,,,,,,,9223372036854775807,,,,,Sun Mar 08 18:44:36 UTC 2020,,,,,,,"0|i3ck4n:",9223372036854775807,,,,,,,,,,,,,3.3.0,,,,,,,,,,"21/Mar/17 03:39;jzhuge;5 failures in {{Apache Hadoop qbt Report: trunk+JDK8 on Linux/x86}} from Feb 6 to Mar 9.","23/Nov/18 11:55;sunilg;Bulk update: moved all 3.2.0 non-blocker issues, please move back if it is a blocker.","05/Mar/20 21:25;Jim_Brennan;We are still seeing this occasionally on our internal branch-2.10 builds.  I am able to reproduce it easily on branch-2.10 by running this test in a loop.
I haven't been able to get it to occur on trunk though, although I am not sure why.   I believe the problem is as reported here: https://sourceforge.net/p/jsch/bugs/111/
I have found that changing the jsch version from 1.54 to 1.55 does seem to fix the problem.

Even though I haven't been able to repro on trunk, I will put up the patch for trunk.  Any concerns about updating this?
","05/Mar/20 21:42;Jim_Brennan;Submitting patch for branch-2.10","05/Mar/20 22:45;hadoopqa;| (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 54s{color} | {color:blue} Docker mode activated. {color} |
|| || || || {color:brown} Prechecks {color} ||
| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |
| {color:red}-1{color} | {color:red} test4tests {color} | {color:red}  0m  1s{color} | {color:red} The patch doesn't appear to include any new or modified tests. Please justify why no new tests are needed for this patch. Also please list what manual steps were performed to verify this patch. {color} |
|| || || || {color:brown} trunk Compile Tests {color} ||
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 21m  2s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green}  0m 15s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  0m 20s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 36m  1s{color} | {color:green} branch has no errors when building and testing our client artifacts. {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 19s{color} | {color:green} trunk passed {color} |
|| || || || {color:brown} Patch Compile Tests {color} ||
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  0m 12s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green}  0m 11s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javac {color} | {color:green}  0m 11s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  0m 13s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} |
| {color:green}+1{color} | {color:green} xml {color} | {color:green}  0m  2s{color} | {color:green} The patch has no ill-formed XML file. {color} |
| {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 14m 26s{color} | {color:green} patch has no errors when building and testing our client artifacts. {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 14s{color} | {color:green} the patch passed {color} |
|| || || || {color:brown} Other Tests {color} ||
| {color:green}+1{color} | {color:green} unit {color} | {color:green}  0m 12s{color} | {color:green} hadoop-project in the patch passed. {color} |
| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 31s{color} | {color:green} The patch does not generate ASF License warnings. {color} |
| {color:black}{color} | {color:black} {color} | {color:black} 54m 16s{color} | {color:black} {color} |
\\
\\
|| Subsystem || Report/Notes ||
| Docker | Client=19.03.7 Server=19.03.7 Image:yetus/hadoop:c44943d1fc3 |
| JIRA Issue | HADOOP-14206 |
| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12995787/HADOOP-14206.001.patch |
| Optional Tests |  dupname  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  shadedclient  xml  |
| uname | Linux 57bbde5241a8 4.15.0-74-generic #84-Ubuntu SMP Thu Dec 19 08:06:28 UTC 2019 x86_64 x86_64 x86_64 GNU/Linux |
| Build tool | maven |
| Personality | /testptch/patchprocess/precommit/personality/provided.sh |
| git revision | trunk / 004e955 |
| maven | version: Apache Maven 3.3.9 |
| Default Java | 1.8.0_242 |
|  Test Results | https://builds.apache.org/job/PreCommit-HADOOP-Build/16786/testReport/ |
| Max. process+thread count | 309 (vs. ulimit of 5500) |
| modules | C: hadoop-project U: hadoop-project |
| Console output | https://builds.apache.org/job/PreCommit-HADOOP-Build/16786/console |
| Powered by | Apache Yetus 0.8.0   http://yetus.apache.org |


This message was automatically generated.

","05/Mar/20 22:48;Jim_Brennan;No tests are included because this is just a pom file change.
","05/Mar/20 23:27;jzhuge;[~Jim_Brennan] Thanks for finding the fix and submitting a patch!

+1 LGTM","06/Mar/20 15:04;Jim_Brennan;Thanks for the review [~jzhuge]!  Any committers listening who would be willing to commit this, assuming there are no concerns about the change?
","06/Mar/20 17:09;jzhuge;Give a few days for others to chime in, then I will commit.","06/Mar/20 19:28;Jim_Brennan;Thanks [~jzhuge]!","08/Mar/20 07:51;hudson;SUCCESS: Integrated in Jenkins build Hadoop-trunk-Commit #18033 (See [https://builds.apache.org/job/Hadoop-trunk-Commit/18033/])
HADOOP-14206. TestSFTPFileSystem#testFileExists failure: Invalid (jzhuge: rev 999096d82e6cc24023a77a69509af6820913f942)
* (edit) hadoop-project/pom.xml
","08/Mar/20 18:44;jzhuge;Pushed to trunk, branch-3.2, branch-3.1, branch-2.10, and branch-2.9. Thanks [~Jim_Brennan] for the contribution!",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
TestValueQueue#testgetAtMostPolicyALL fails intermittently,HADOOP-12715,12931548,Test,Closed,HADOOP,Hadoop Common,software,omalley,Hadoop Common is the common library for Apache Hadoop.,http://hadoop.apache.org/,Major,Fixed,xiaochen,xiaochen,xiaochen,15/Jan/16 19:16,25/Oct/19 20:25,12/Jan/21 11:55,27/Jan/16 16:23,,,,,2.7.3,2.8.0,3.0.0-alpha1,,,,,,,,0,,,"The test fails intermittently with the following error.
Error Message
{noformat}
expected:<19> but was:<10>
{noformat}
Stacktrace
{noformat}
java.lang.AssertionError: expected:<19> but was:<10>
	at org.junit.Assert.fail(Assert.java:88)
	at org.junit.Assert.failNotEquals(Assert.java:743)
	at org.junit.Assert.assertEquals(Assert.java:118)
	at org.junit.Assert.assertEquals(Assert.java:555)
	at org.junit.Assert.assertEquals(Assert.java:542)
	at org.apache.hadoop.crypto.key.TestValueQueue.testgetAtMostPolicyALL(TestValueQueue.java:149)
{noformat}",,andrew.wang,hudson,junping_du,liuml07,vinodkv,walter.k.su,xiaochen,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"15/Jan/16 22:56;xiaochen;HADOOP-12715.01.patch;https://issues.apache.org/jira/secure/attachment/12782632/HADOOP-12715.01.patch","16/Jan/16 07:45;xiaochen;HADOOP-12715.02.patch;https://issues.apache.org/jira/secure/attachment/12782711/HADOOP-12715.02.patch","23/Jan/16 05:54;xiaochen;HADOOP-12715.03.patch;https://issues.apache.org/jira/secure/attachment/12783988/HADOOP-12715.03.patch",,,,,,,,,,,,,,,,,,,,,3.0,,,,,,,,,,,,,,,,,,,,2016-01-15 20:12:35.207,,,false,,,,,,,,,,,,,,,,,9223372036854775807,Reviewed,,,,Thu Aug 25 22:48:09 UTC 2016,,,,,,,"0|i2rjd3:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,"15/Jan/16 19:19;xiaochen;Reason for the failure is because {{ValueQueue}} has an async filling thread. There's a race between the async filling after {{getAtMost(10)}}, and the sync filling of {{getAtMost(19)}}.

Patch 1 enhanced the test to first check the async {{getAtMost(10)}}, then check the sync {{getAtMost(19)}}. Also added timeout to all tests in this class, and enhanced the asserts to have a message.","15/Jan/16 20:12;hadoopqa;| (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue} 0m 0s {color} | {color:blue} Docker mode activated. {color} |
| {color:green}+1{color} | {color:green} @author {color} | {color:green} 0m 0s {color} | {color:green} The patch does not contain any @author tags. {color} |
| {color:green}+1{color} | {color:green} test4tests {color} | {color:green} 0m 0s {color} | {color:green} The patch appears to include 1 new or modified test files. {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 9m 30s {color} | {color:green} trunk passed {color} |
| {color:red}-1{color} | {color:red} compile {color} | {color:red} 6m 2s {color} | {color:red} root in trunk failed with JDK v1.8.0_66. {color} |
| {color:red}-1{color} | {color:red} compile {color} | {color:red} 0m 47s {color} | {color:red} root in trunk failed with JDK v1.7.0_91. {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green} 0m 19s {color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green} 1m 8s {color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green} 0m 13s {color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green} 2m 12s {color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 1m 12s {color} | {color:green} trunk passed with JDK v1.8.0_66 {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 1m 12s {color} | {color:green} trunk passed with JDK v1.7.0_91 {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 2m 23s {color} | {color:green} the patch passed {color} |
| {color:red}-1{color} | {color:red} compile {color} | {color:red} 4m 7s {color} | {color:red} root in the patch failed with JDK v1.8.0_66. {color} |
| {color:red}-1{color} | {color:red} javac {color} | {color:red} 4m 7s {color} | {color:red} root in the patch failed with JDK v1.8.0_66. {color} |
| {color:red}-1{color} | {color:red} compile {color} | {color:red} 0m 57s {color} | {color:red} root in the patch failed with JDK v1.7.0_91. {color} |
| {color:red}-1{color} | {color:red} javac {color} | {color:red} 0m 57s {color} | {color:red} root in the patch failed with JDK v1.7.0_91. {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green} 0m 22s {color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green} 1m 19s {color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green} 0m 18s {color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} whitespace {color} | {color:green} 0m 0s {color} | {color:green} Patch has no whitespace issues. {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green} 3m 9s {color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 1m 47s {color} | {color:green} the patch passed with JDK v1.8.0_66 {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 1m 33s {color} | {color:green} the patch passed with JDK v1.7.0_91 {color} |
| {color:red}-1{color} | {color:red} unit {color} | {color:red} 0m 38s {color} | {color:red} hadoop-common in the patch failed with JDK v1.8.0_66. {color} |
| {color:red}-1{color} | {color:red} unit {color} | {color:red} 0m 32s {color} | {color:red} hadoop-common in the patch failed with JDK v1.7.0_91. {color} |
| {color:green}+1{color} | {color:green} asflicense {color} | {color:green} 0m 20s {color} | {color:green} Patch does not generate ASF License warnings. {color} |
| {color:black}{color} | {color:black} {color} | {color:black} 41m 56s {color} | {color:black} {color} |
\\
\\
|| Subsystem || Report/Notes ||
| Docker |  Image:yetus/hadoop:0ca8df7 |
| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12782589/HADOOP-12715.01.patch |
| JIRA Issue | HADOOP-12715 |
| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  findbugs  checkstyle  |
| uname | Linux 1cbe98861e52 3.13.0-36-lowlatency #63-Ubuntu SMP PREEMPT Wed Sep 3 21:56:12 UTC 2014 x86_64 x86_64 x86_64 GNU/Linux |
| Build tool | maven |
| Personality | /testptch/hadoop/patchprocess/precommit/personality/provided.sh |
| git revision | trunk / c07f7fa |
| Default Java | 1.7.0_91 |
| Multi-JDK versions |  /usr/lib/jvm/java-8-oracle:1.8.0_66 /usr/lib/jvm/java-7-openjdk-amd64:1.7.0_91 |
| compile | https://builds.apache.org/job/PreCommit-HADOOP-Build/8419/artifact/patchprocess/branch-compile-root-jdk1.8.0_66.txt |
| compile | https://builds.apache.org/job/PreCommit-HADOOP-Build/8419/artifact/patchprocess/branch-compile-root-jdk1.7.0_91.txt |
| findbugs | v3.0.0 |
| compile | https://builds.apache.org/job/PreCommit-HADOOP-Build/8419/artifact/patchprocess/patch-compile-root-jdk1.8.0_66.txt |
| javac | https://builds.apache.org/job/PreCommit-HADOOP-Build/8419/artifact/patchprocess/patch-compile-root-jdk1.8.0_66.txt |
| compile | https://builds.apache.org/job/PreCommit-HADOOP-Build/8419/artifact/patchprocess/patch-compile-root-jdk1.7.0_91.txt |
| javac | https://builds.apache.org/job/PreCommit-HADOOP-Build/8419/artifact/patchprocess/patch-compile-root-jdk1.7.0_91.txt |
| unit | https://builds.apache.org/job/PreCommit-HADOOP-Build/8419/artifact/patchprocess/patch-unit-hadoop-common-project_hadoop-common-jdk1.8.0_66.txt |
| unit | https://builds.apache.org/job/PreCommit-HADOOP-Build/8419/artifact/patchprocess/patch-unit-hadoop-common-project_hadoop-common-jdk1.7.0_91.txt |
| JDK v1.7.0_91  Test Results | https://builds.apache.org/job/PreCommit-HADOOP-Build/8419/testReport/ |
| modules | C: hadoop-common-project/hadoop-common U: hadoop-common-project/hadoop-common |
| Max memory used | 76MB |
| Powered by | Apache Yetus 0.2.0-SNAPSHOT   http://yetus.apache.org |
| Console output | https://builds.apache.org/job/PreCommit-HADOOP-Build/8419/console |


This message was automatically generated.

","15/Jan/16 21:34;xiaochen;Last failure seems to be YETUS-286. Reattaching...","15/Jan/16 22:17;hadoopqa;| (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue} 0m 0s {color} | {color:blue} Docker mode activated. {color} |
| {color:green}+1{color} | {color:green} @author {color} | {color:green} 0m 0s {color} | {color:green} The patch does not contain any @author tags. {color} |
| {color:green}+1{color} | {color:green} test4tests {color} | {color:green} 0m 0s {color} | {color:green} The patch appears to include 1 new or modified test files. {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 8m 24s {color} | {color:green} trunk passed {color} |
| {color:red}-1{color} | {color:red} compile {color} | {color:red} 2m 12s {color} | {color:red} root in trunk failed with JDK v1.8.0_66. {color} |
| {color:red}-1{color} | {color:red} compile {color} | {color:red} 0m 47s {color} | {color:red} root in trunk failed with JDK v1.7.0_91. {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green} 0m 17s {color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green} 1m 8s {color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green} 0m 14s {color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green} 2m 1s {color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 0m 58s {color} | {color:green} trunk passed with JDK v1.8.0_66 {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 1m 8s {color} | {color:green} trunk passed with JDK v1.7.0_91 {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 1m 40s {color} | {color:green} the patch passed {color} |
| {color:red}-1{color} | {color:red} compile {color} | {color:red} 2m 2s {color} | {color:red} root in the patch failed with JDK v1.8.0_66. {color} |
| {color:red}-1{color} | {color:red} javac {color} | {color:red} 2m 2s {color} | {color:red} root in the patch failed with JDK v1.8.0_66. {color} |
| {color:red}-1{color} | {color:red} compile {color} | {color:red} 2m 6s {color} | {color:red} root in the patch failed with JDK v1.7.0_91. {color} |
| {color:red}-1{color} | {color:red} javac {color} | {color:red} 2m 6s {color} | {color:red} root in the patch failed with JDK v1.7.0_91. {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green} 0m 17s {color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green} 1m 4s {color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green} 0m 13s {color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} whitespace {color} | {color:green} 0m 0s {color} | {color:green} Patch has no whitespace issues. {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green} 2m 7s {color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 0m 54s {color} | {color:green} the patch passed with JDK v1.8.0_66 {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 1m 5s {color} | {color:green} the patch passed with JDK v1.7.0_91 {color} |
| {color:red}-1{color} | {color:red} unit {color} | {color:red} 0m 29s {color} | {color:red} hadoop-common in the patch failed with JDK v1.8.0_66. {color} |
| {color:green}+1{color} | {color:green} unit {color} | {color:green} 8m 14s {color} | {color:green} hadoop-common in the patch passed with JDK v1.7.0_91. {color} |
| {color:green}+1{color} | {color:green} asflicense {color} | {color:green} 0m 21s {color} | {color:green} Patch does not generate ASF License warnings. {color} |
| {color:black}{color} | {color:black} {color} | {color:black} 39m 6s {color} | {color:black} {color} |
\\
\\
|| Subsystem || Report/Notes ||
| Docker |  Image:yetus/hadoop:0ca8df7 |
| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12782614/HADOOP-12715.01.patch |
| JIRA Issue | HADOOP-12715 |
| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  findbugs  checkstyle  |
| uname | Linux f4cb814d09f8 3.13.0-36-lowlatency #63-Ubuntu SMP PREEMPT Wed Sep 3 21:56:12 UTC 2014 x86_64 x86_64 x86_64 GNU/Linux |
| Build tool | maven |
| Personality | /testptch/hadoop/patchprocess/precommit/personality/provided.sh |
| git revision | trunk / b2c155f |
| Default Java | 1.7.0_91 |
| Multi-JDK versions |  /usr/lib/jvm/java-8-oracle:1.8.0_66 /usr/lib/jvm/java-7-openjdk-amd64:1.7.0_91 |
| compile | https://builds.apache.org/job/PreCommit-HADOOP-Build/8422/artifact/patchprocess/branch-compile-root-jdk1.8.0_66.txt |
| compile | https://builds.apache.org/job/PreCommit-HADOOP-Build/8422/artifact/patchprocess/branch-compile-root-jdk1.7.0_91.txt |
| findbugs | v3.0.0 |
| compile | https://builds.apache.org/job/PreCommit-HADOOP-Build/8422/artifact/patchprocess/patch-compile-root-jdk1.8.0_66.txt |
| javac | https://builds.apache.org/job/PreCommit-HADOOP-Build/8422/artifact/patchprocess/patch-compile-root-jdk1.8.0_66.txt |
| compile | https://builds.apache.org/job/PreCommit-HADOOP-Build/8422/artifact/patchprocess/patch-compile-root-jdk1.7.0_91.txt |
| javac | https://builds.apache.org/job/PreCommit-HADOOP-Build/8422/artifact/patchprocess/patch-compile-root-jdk1.7.0_91.txt |
| unit | https://builds.apache.org/job/PreCommit-HADOOP-Build/8422/artifact/patchprocess/patch-unit-hadoop-common-project_hadoop-common-jdk1.8.0_66.txt |
| JDK v1.7.0_91  Test Results | https://builds.apache.org/job/PreCommit-HADOOP-Build/8422/testReport/ |
| modules | C: hadoop-common-project/hadoop-common U: hadoop-common-project/hadoop-common |
| Max memory used | 76MB |
| Powered by | Apache Yetus 0.2.0-SNAPSHOT   http://yetus.apache.org |
| Console output | https://builds.apache.org/job/PreCommit-HADOOP-Build/8422/console |


This message was automatically generated.

","16/Jan/16 00:08;hadoopqa;| (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue} 0m 0s {color} | {color:blue} Docker mode activated. {color} |
| {color:green}+1{color} | {color:green} @author {color} | {color:green} 0m 0s {color} | {color:green} The patch does not contain any @author tags. {color} |
| {color:green}+1{color} | {color:green} test4tests {color} | {color:green} 0m 0s {color} | {color:green} The patch appears to include 1 new or modified test files. {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 7m 54s {color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 8m 44s {color} | {color:green} trunk passed with JDK v1.8.0_66 {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 7m 38s {color} | {color:green} trunk passed with JDK v1.7.0_91 {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green} 0m 15s {color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green} 1m 3s {color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green} 0m 13s {color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green} 1m 47s {color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 0m 59s {color} | {color:green} trunk passed with JDK v1.8.0_66 {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 1m 5s {color} | {color:green} trunk passed with JDK v1.7.0_91 {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 1m 29s {color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 8m 2s {color} | {color:green} the patch passed with JDK v1.8.0_66 {color} |
| {color:green}+1{color} | {color:green} javac {color} | {color:green} 8m 2s {color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 7m 16s {color} | {color:green} the patch passed with JDK v1.7.0_91 {color} |
| {color:green}+1{color} | {color:green} javac {color} | {color:green} 7m 16s {color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green} 0m 18s {color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green} 1m 12s {color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green} 0m 12s {color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} whitespace {color} | {color:green} 0m 0s {color} | {color:green} Patch has no whitespace issues. {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green} 2m 0s {color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 1m 0s {color} | {color:green} the patch passed with JDK v1.8.0_66 {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 1m 8s {color} | {color:green} the patch passed with JDK v1.7.0_91 {color} |
| {color:green}+1{color} | {color:green} unit {color} | {color:green} 8m 26s {color} | {color:green} hadoop-common in the patch passed with JDK v1.8.0_66. {color} |
| {color:red}-1{color} | {color:red} unit {color} | {color:red} 7m 45s {color} | {color:red} hadoop-common in the patch failed with JDK v1.7.0_91. {color} |
| {color:green}+1{color} | {color:green} asflicense {color} | {color:green} 0m 21s {color} | {color:green} Patch does not generate ASF License warnings. {color} |
| {color:black}{color} | {color:black} {color} | {color:black} 70m 0s {color} | {color:black} {color} |
\\
\\
|| Reason || Tests ||
| JDK v1.7.0_91 Failed junit tests | hadoop.ipc.TestIPC |
|   | hadoop.metrics2.impl.TestGangliaMetrics |
\\
\\
|| Subsystem || Report/Notes ||
| Docker |  Image:yetus/hadoop:0ca8df7 |
| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12782632/HADOOP-12715.01.patch |
| JIRA Issue | HADOOP-12715 |
| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  findbugs  checkstyle  |
| uname | Linux 2115091413f7 3.13.0-36-lowlatency #63-Ubuntu SMP PREEMPT Wed Sep 3 21:56:12 UTC 2014 x86_64 x86_64 x86_64 GNU/Linux |
| Build tool | maven |
| Personality | /testptch/hadoop/patchprocess/precommit/personality/provided.sh |
| git revision | trunk / 2a30386 |
| Default Java | 1.7.0_91 |
| Multi-JDK versions |  /usr/lib/jvm/java-8-oracle:1.8.0_66 /usr/lib/jvm/java-7-openjdk-amd64:1.7.0_91 |
| findbugs | v3.0.0 |
| unit | https://builds.apache.org/job/PreCommit-HADOOP-Build/8424/artifact/patchprocess/patch-unit-hadoop-common-project_hadoop-common-jdk1.7.0_91.txt |
| unit test logs |  https://builds.apache.org/job/PreCommit-HADOOP-Build/8424/artifact/patchprocess/patch-unit-hadoop-common-project_hadoop-common-jdk1.7.0_91.txt |
| JDK v1.7.0_91  Test Results | https://builds.apache.org/job/PreCommit-HADOOP-Build/8424/testReport/ |
| modules | C: hadoop-common-project/hadoop-common U: hadoop-common-project/hadoop-common |
| Max memory used | 76MB |
| Powered by | Apache Yetus 0.2.0-SNAPSHOT   http://yetus.apache.org |
| Console output | https://builds.apache.org/job/PreCommit-HADOOP-Build/8424/console |


This message was automatically generated.

","16/Jan/16 00:40;xiaochen;Test failure is unrelated. (HADOOP-12605 for the TestIPC failure, would be lovely if someone can help commit. HADOOP-12588 is TestGangliaMetrics )","16/Jan/16 02:19;liuml07;Thanks for working on this. I think your analysis is correct.

If there is any execution exception, we swallow the exception here. Should we retry (returning false) or simply end waiting (returning true)?
{code}
+        } catch (ExecutionException e) {
+          LOG.error(""Exception when getSize."", e);
+          return false;
+        }
+      }
{code}","16/Jan/16 07:45;xiaochen;Thank you for looking into this [~liuml07]. Good point, the {{ExecutionException}} can only possibly come from [LoadingCache#get|http://docs.guava-libraries.googlecode.com/git/javadoc/com/google/common/cache/LoadingCache.html#get(K)], in which case I guess there's no point in retrying.

Patch 2 is attached, the only line changed is to return true.","16/Jan/16 08:57;hadoopqa;| (/) *{color:green}+1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue} 0m 0s {color} | {color:blue} Docker mode activated. {color} |
| {color:green}+1{color} | {color:green} @author {color} | {color:green} 0m 0s {color} | {color:green} The patch does not contain any @author tags. {color} |
| {color:green}+1{color} | {color:green} test4tests {color} | {color:green} 0m 0s {color} | {color:green} The patch appears to include 1 new or modified test files. {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 8m 33s {color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 6m 35s {color} | {color:green} trunk passed with JDK v1.8.0_66 {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 7m 18s {color} | {color:green} trunk passed with JDK v1.7.0_91 {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green} 0m 16s {color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green} 1m 6s {color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green} 0m 14s {color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green} 1m 52s {color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 0m 56s {color} | {color:green} trunk passed with JDK v1.8.0_66 {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 1m 7s {color} | {color:green} trunk passed with JDK v1.7.0_91 {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 1m 38s {color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 6m 32s {color} | {color:green} the patch passed with JDK v1.8.0_66 {color} |
| {color:green}+1{color} | {color:green} javac {color} | {color:green} 6m 32s {color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 7m 21s {color} | {color:green} the patch passed with JDK v1.7.0_91 {color} |
| {color:green}+1{color} | {color:green} javac {color} | {color:green} 7m 21s {color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green} 0m 16s {color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green} 1m 5s {color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green} 0m 14s {color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} whitespace {color} | {color:green} 0m 0s {color} | {color:green} Patch has no whitespace issues. {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green} 2m 5s {color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 0m 56s {color} | {color:green} the patch passed with JDK v1.8.0_66 {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 1m 4s {color} | {color:green} the patch passed with JDK v1.7.0_91 {color} |
| {color:green}+1{color} | {color:green} unit {color} | {color:green} 8m 1s {color} | {color:green} hadoop-common in the patch passed with JDK v1.8.0_66. {color} |
| {color:green}+1{color} | {color:green} unit {color} | {color:green} 8m 0s {color} | {color:green} hadoop-common in the patch passed with JDK v1.7.0_91. {color} |
| {color:green}+1{color} | {color:green} asflicense {color} | {color:green} 0m 23s {color} | {color:green} Patch does not generate ASF License warnings. {color} |
| {color:black}{color} | {color:black} {color} | {color:black} 66m 49s {color} | {color:black} {color} |
\\
\\
|| Subsystem || Report/Notes ||
| Docker |  Image:yetus/hadoop:0ca8df7 |
| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12782711/HADOOP-12715.02.patch |
| JIRA Issue | HADOOP-12715 |
| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  findbugs  checkstyle  |
| uname | Linux 28d77aac6c49 3.13.0-36-lowlatency #63-Ubuntu SMP PREEMPT Wed Sep 3 21:56:12 UTC 2014 x86_64 x86_64 x86_64 GNU/Linux |
| Build tool | maven |
| Personality | /testptch/hadoop/patchprocess/precommit/personality/provided.sh |
| git revision | trunk / 2a30386 |
| Default Java | 1.7.0_91 |
| Multi-JDK versions |  /usr/lib/jvm/java-8-oracle:1.8.0_66 /usr/lib/jvm/java-7-openjdk-amd64:1.7.0_91 |
| findbugs | v3.0.0 |
| JDK v1.7.0_91  Test Results | https://builds.apache.org/job/PreCommit-HADOOP-Build/8428/testReport/ |
| modules | C: hadoop-common-project/hadoop-common U: hadoop-common-project/hadoop-common |
| Max memory used | 76MB |
| Powered by | Apache Yetus 0.2.0-SNAPSHOT   http://yetus.apache.org |
| Console output | https://builds.apache.org/job/PreCommit-HADOOP-Build/8428/console |


This message was automatically generated.

","22/Jan/16 13:51;walter.k.su;I got the same AssertionError if I delay the sync filling of {{getAtMost(19)}} manually. You're correct, thanks [~xiaochen].

{code}
148     // Drain completely
149     Assert.assertEquals(""Failed to drain completely."", 10,
150         vq.getAtMost(""k1"", 10).size());
151     // Synchronous call
152     Assert.assertEquals(""Failed in sync call."", 10, filler.getTop().num);
153     // Ask for more... return all
154     GenericTestUtils.waitFor(new Supplier<Boolean>() {
    ...
169     }, 100, 3000);
170     Assert.assertEquals(""Failed in async call."", 10, filler.getTop().num);
171     // Drain completely after filled by the async thread
172     Assert.assertEquals(""Failed to drain completely after async."", 10,
173         vq.getAtMost(""k1"", 10).size());
{code}
Your comment at line 171 is good. The original comment at line 148 is misleading. When test procedure goes to line 149, the queue in {{LoadingCache}} is already empty.
So what line 148~150 does is ""trigger sync task to fill returned list, and another async task to fill the queue in the cache"".
+1 once addressed.
","23/Jan/16 05:56;xiaochen;Thank you [~walter.k.su] for verifying, and good catch on the comment!
Patch 3 addresses your comment. I also modified some other comments, to make the test clearer. No real code change from patch 2.","23/Jan/16 07:50;hadoopqa;| (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue} 0m 0s {color} | {color:blue} Docker mode activated. {color} |
| {color:green}+1{color} | {color:green} @author {color} | {color:green} 0m 0s {color} | {color:green} The patch does not contain any @author tags. {color} |
| {color:green}+1{color} | {color:green} test4tests {color} | {color:green} 0m 0s {color} | {color:green} The patch appears to include 1 new or modified test files. {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 8m 0s {color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 6m 42s {color} | {color:green} trunk passed with JDK v1.8.0_66 {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 7m 37s {color} | {color:green} trunk passed with JDK v1.7.0_91 {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green} 0m 17s {color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green} 1m 10s {color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green} 0m 14s {color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green} 2m 3s {color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 1m 1s {color} | {color:green} trunk passed with JDK v1.8.0_66 {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 1m 10s {color} | {color:green} trunk passed with JDK v1.7.0_91 {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 1m 38s {color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 8m 38s {color} | {color:green} the patch passed with JDK v1.8.0_66 {color} |
| {color:green}+1{color} | {color:green} javac {color} | {color:green} 8m 38s {color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 8m 6s {color} | {color:green} the patch passed with JDK v1.7.0_91 {color} |
| {color:green}+1{color} | {color:green} javac {color} | {color:green} 8m 6s {color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green} 0m 17s {color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green} 1m 8s {color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green} 0m 14s {color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} whitespace {color} | {color:green} 0m 0s {color} | {color:green} Patch has no whitespace issues. {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green} 2m 19s {color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 1m 2s {color} | {color:green} the patch passed with JDK v1.8.0_66 {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 1m 14s {color} | {color:green} the patch passed with JDK v1.7.0_91 {color} |
| {color:red}-1{color} | {color:red} unit {color} | {color:red} 8m 23s {color} | {color:red} hadoop-common in the patch failed with JDK v1.8.0_66. {color} |
| {color:green}+1{color} | {color:green} unit {color} | {color:green} 8m 40s {color} | {color:green} hadoop-common in the patch passed with JDK v1.7.0_91. {color} |
| {color:green}+1{color} | {color:green} asflicense {color} | {color:green} 0m 25s {color} | {color:green} Patch does not generate ASF License warnings. {color} |
| {color:black}{color} | {color:black} {color} | {color:black} 71m 33s {color} | {color:black} {color} |
\\
\\
|| Reason || Tests ||
| JDK v1.8.0_66 Failed junit tests | hadoop.test.TestTimedOutTestsListener |
\\
\\
|| Subsystem || Report/Notes ||
| Docker |  Image:yetus/hadoop:0ca8df7 |
| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12783988/HADOOP-12715.03.patch |
| JIRA Issue | HADOOP-12715 |
| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  findbugs  checkstyle  |
| uname | Linux 02b38784e2f7 3.13.0-36-lowlatency #63-Ubuntu SMP PREEMPT Wed Sep 3 21:56:12 UTC 2014 x86_64 x86_64 x86_64 GNU/Linux |
| Build tool | maven |
| Personality | /testptch/hadoop/patchprocess/precommit/personality/provided.sh |
| git revision | trunk / 99829eb |
| Default Java | 1.7.0_91 |
| Multi-JDK versions |  /usr/lib/jvm/java-8-oracle:1.8.0_66 /usr/lib/jvm/java-7-openjdk-amd64:1.7.0_91 |
| findbugs | v3.0.0 |
| unit | https://builds.apache.org/job/PreCommit-HADOOP-Build/8453/artifact/patchprocess/patch-unit-hadoop-common-project_hadoop-common-jdk1.8.0_66.txt |
| unit test logs |  https://builds.apache.org/job/PreCommit-HADOOP-Build/8453/artifact/patchprocess/patch-unit-hadoop-common-project_hadoop-common-jdk1.8.0_66.txt |
| JDK v1.7.0_91  Test Results | https://builds.apache.org/job/PreCommit-HADOOP-Build/8453/testReport/ |
| modules | C: hadoop-common-project/hadoop-common U: hadoop-common-project/hadoop-common |
| Max memory used | 76MB |
| Powered by | Apache Yetus 0.2.0-SNAPSHOT   http://yetus.apache.org |
| Console output | https://builds.apache.org/job/PreCommit-HADOOP-Build/8453/console |


This message was automatically generated.

","23/Jan/16 18:56;xiaochen;Failed test is unrelated. (Created HADOOP-12736 for that)","25/Jan/16 12:06;walter.k.su;Committed this to trunk, branch-2, branch-2.8, branch-2.7, and branch-2.6. Thanks [~xiaochen] for the contribution!","25/Jan/16 12:16;hudson;FAILURE: Integrated in Hadoop-trunk-Commit #9179 (See [https://builds.apache.org/job/Hadoop-trunk-Commit/9179/])
HADOOP-12715. TestValueQueue#testgetAtMostPolicyALL fails (waltersu4549: rev 6eacdea0e475b4fff91cedce5005a7c11749cf64)
* hadoop-common-project/hadoop-common/CHANGES.txt
* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/crypto/key/TestValueQueue.java
","25/Jan/16 17:29;xiaochen;Thanks Mingliang for the review, and Walter for the review and commit!","26/Jan/16 14:32;junping_du;Hi, the commit patch on branch-2.6 cause build failure because getSize() is not defined in {{ValueQueue}} as HDFS-7209 is missing. I reopen this JIRA for an addendum patch to get in.","27/Jan/16 15:13;junping_du;It sounds like HDFS-7209 is part of HDFS-6891 which is not target for 2.6 branch. Given this is not critical/blocker for branch-2.6, I will revert the commit for branch-2.6 if no one objects.","27/Jan/16 16:24;junping_du;I just revert it from branch-2.6.","27/Jan/16 16:47;xiaochen;Thanks very much [~junping_du] for taking care of this! I think not having this in branch-2.6 should be Okay. I can also provide a branch-2.6 patch if needed.","27/Jan/16 16:55;junping_du;Thanks [~xiaochen]. As a maintenance release, branch-2.6 is mostly for rapid release of critical/blocker bug fixes. Let's keep this so far.","27/Jan/16 17:08;xiaochen;Makes sense. Thanks again Junping.","25/Aug/16 22:48;vinodkv;Closing the JIRA as part of 2.7.3 release.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Add tests for PB RPC in case version mismatch of client and server,HADOOP-10729,12722682,Test,Resolved,HADOOP,Hadoop Common,software,omalley,Hadoop Common is the common library for Apache Hadoop.,http://hadoop.apache.org/,Major,Fixed,junping_du,junping_du,junping_du,20/Jun/14 01:56,25/Oct/19 20:25,12/Jan/21 11:55,08/Dec/15 21:45,2.4.0,,,,2.8.0,3.0.0-alpha1,,,,,ipc,,,,0,,,"We have ProtocolInfo specified in protocol interface with version info, but we don't have unit test to verify if/how it works. We should have tests to track this annotation work as expectation.",,Fan04290,gujilangzi,hudson,junping_du,sseth,vinodkv,wheat9,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"08/Dec/15 15:38;junping_du;HADOOP-10729-v2.patch;https://issues.apache.org/jira/secure/attachment/12776344/HADOOP-10729-v2.patch","20/Jun/14 02:10;junping_du;HADOOP-10729.patch;https://issues.apache.org/jira/secure/attachment/12651596/HADOOP-10729.patch",,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,2014-06-20 03:35:58.149,,,false,,,,,,,,,,,,,,,,,400873,Reviewed,,,,Wed Dec 09 04:55:57 UTC 2015,,,,,,,"0|i1x05z:",400958,,,,,,,,,,,,,2.8.0,,,,,,,,,,"20/Jun/14 02:10;junping_du;Upload a patch.","20/Jun/14 03:35;hadoopqa;{color:green}+1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12651596/HADOOP-10729.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 3 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  There were no new javadoc warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:green}+1 core tests{color}.  The patch passed unit tests in hadoop-common-project/hadoop-common.

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HADOOP-Build/4121//testReport/
Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/4121//console

This message is automatically generated.","06/Oct/14 03:43;hadoopqa;{color:green}+1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12651596/HADOOP-10729.patch
  against trunk revision 16333b4.

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 3 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  There were no new javadoc warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 2.0.3) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:green}+1 core tests{color}.  The patch passed unit tests in hadoop-common-project/hadoop-common.

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HADOOP-Build/4864//testReport/
Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/4864//console

This message is automatically generated.","06/Oct/14 04:39;hadoopqa;{color:green}+1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12651596/HADOOP-10729.patch
  against trunk revision 16333b4.

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 3 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  There were no new javadoc warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 2.0.3) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:green}+1 core tests{color}.  The patch passed unit tests in hadoop-common-project/hadoop-common.

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HADOOP-Build/4865//testReport/
Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/4865//console

This message is automatically generated.","03/May/15 04:06;hadoopqa;\\
\\
| (/) *{color:green}+1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | pre-patch |   5m  8s | Pre-patch trunk compilation is healthy. |
| {color:green}+1{color} | @author |   0m  0s | The patch does not contain any @author tags. |
| {color:green}+1{color} | tests included |   0m  0s | The patch appears to include 3 new or modified test files. |
| {color:green}+1{color} | javac |   7m 29s | There were no new javac warning messages. |
| {color:green}+1{color} | release audit |   0m 19s | The applied patch does not increase the total number of release audit warnings. |
| {color:green}+1{color} | checkstyle |   1m  4s | There were no new checkstyle issues. |
| {color:green}+1{color} | whitespace |   0m  0s | The patch has no lines that end in whitespace. |
| {color:green}+1{color} | install |   1m 31s | mvn install still works. |
| {color:green}+1{color} | eclipse:eclipse |   0m 31s | The patch built with eclipse:eclipse. |
| {color:green}+1{color} | findbugs |   1m 38s | The patch does not introduce any new Findbugs (version 2.0.3) warnings. |
| {color:green}+1{color} | common tests |  23m 32s | Tests passed in hadoop-common. |
| | |  41m 17s | |
\\
\\
|| Subsystem || Report/Notes ||
| Patch URL | http://issues.apache.org/jira/secure/attachment/12651596/HADOOP-10729.patch |
| Optional Tests | javac unit findbugs checkstyle |
| git revision | trunk / e8d0ee5 |
| hadoop-common test log | https://builds.apache.org/job/PreCommit-HADOOP-Build/6447/artifact/patchprocess/testrun_hadoop-common.txt |
| Test Results | https://builds.apache.org/job/PreCommit-HADOOP-Build/6447/testReport/ |
| Java | 1.7.0_55 |
| uname | Linux asf901.gq1.ygridcore.net 3.13.0-36-lowlatency #63-Ubuntu SMP PREEMPT Wed Sep 3 21:56:12 UTC 2014 x86_64 x86_64 x86_64 GNU/Linux |
| Console output | https://builds.apache.org/job/PreCommit-HADOOP-Build/6447/console |


This message was automatically generated.","30/Jun/15 04:44;vinodkv;Moving bugs out of previously closed releases into the next minor release 2.8.0.","30/Jun/15 06:15;hadoopqa;\\
\\
| (/) *{color:green}+1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | pre-patch |   6m 58s | Pre-patch trunk compilation is healthy. |
| {color:green}+1{color} | @author |   0m  0s | The patch does not contain any @author tags. |
| {color:green}+1{color} | tests included |   0m  0s | The patch appears to include 3 new or modified test files. |
| {color:green}+1{color} | javac |   7m 27s | There were no new javac warning messages. |
| {color:green}+1{color} | release audit |   0m 21s | The applied patch does not increase the total number of release audit warnings. |
| {color:green}+1{color} | checkstyle |   1m  3s | There were no new checkstyle issues. |
| {color:green}+1{color} | whitespace |   0m  0s | The patch has no lines that end in whitespace. |
| {color:green}+1{color} | install |   1m 31s | mvn install still works. |
| {color:green}+1{color} | eclipse:eclipse |   0m 32s | The patch built with eclipse:eclipse. |
| {color:green}+1{color} | findbugs |   1m 49s | The patch does not introduce any new Findbugs (version 3.0.0) warnings. |
| {color:green}+1{color} | common tests |  21m 57s | Tests passed in hadoop-common. |
| | |  41m 42s | |
\\
\\
|| Subsystem || Report/Notes ||
| Patch URL | http://issues.apache.org/jira/secure/attachment/12651596/HADOOP-10729.patch |
| Optional Tests | javac unit findbugs checkstyle |
| git revision | trunk / d3797f9 |
| hadoop-common test log | https://builds.apache.org/job/PreCommit-HADOOP-Build/7096/artifact/patchprocess/testrun_hadoop-common.txt |
| Test Results | https://builds.apache.org/job/PreCommit-HADOOP-Build/7096/testReport/ |
| Java | 1.7.0_55 |
| uname | Linux asf906.gq1.ygridcore.net 3.13.0-36-lowlatency #63-Ubuntu SMP PREEMPT Wed Sep 3 21:56:12 UTC 2014 x86_64 x86_64 x86_64 GNU/Linux |
| Console output | https://builds.apache.org/job/PreCommit-HADOOP-Build/7096/console |


This message was automatically generated.","23/Nov/15 01:01;wheat9;Hi [~junping_du] can you please rebase the patch? Thanks.","08/Dec/15 14:35;junping_du;Ok. Will do. Thanks Haohui.","08/Dec/15 15:38;junping_du;Update patch to sync to latest trunk.","08/Dec/15 17:36;hadoopqa;| (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue} 0m 0s {color} | {color:blue} Docker mode activated. {color} |
| {color:green}+1{color} | {color:green} @author {color} | {color:green} 0m 0s {color} | {color:green} The patch does not contain any @author tags. {color} |
| {color:green}+1{color} | {color:green} test4tests {color} | {color:green} 0m 0s {color} | {color:green} The patch appears to include 3 new or modified test files. {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 10m 6s {color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 13m 24s {color} | {color:green} trunk passed with JDK v1.8.0_66 {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 11m 40s {color} | {color:green} trunk passed with JDK v1.7.0_91 {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green} 0m 21s {color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green} 1m 22s {color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green} 0m 16s {color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green} 2m 21s {color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 1m 22s {color} | {color:green} trunk passed with JDK v1.8.0_66 {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 1m 24s {color} | {color:green} trunk passed with JDK v1.7.0_91 {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 1m 55s {color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 13m 12s {color} | {color:green} the patch passed with JDK v1.8.0_66 {color} |
| {color:green}+1{color} | {color:green} cc {color} | {color:green} 13m 12s {color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javac {color} | {color:green} 13m 12s {color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 11m 38s {color} | {color:green} the patch passed with JDK v1.7.0_91 {color} |
| {color:green}+1{color} | {color:green} cc {color} | {color:green} 11m 38s {color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javac {color} | {color:green} 11m 38s {color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green} 0m 20s {color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green} 1m 23s {color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green} 0m 17s {color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} whitespace {color} | {color:green} 0m 0s {color} | {color:green} Patch has no whitespace issues. {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green} 2m 38s {color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 1m 17s {color} | {color:green} the patch passed with JDK v1.8.0_66 {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 1m 23s {color} | {color:green} the patch passed with JDK v1.7.0_91 {color} |
| {color:red}-1{color} | {color:red} unit {color} | {color:red} 9m 29s {color} | {color:red} hadoop-common in the patch failed with JDK v1.8.0_66. {color} |
| {color:green}+1{color} | {color:green} unit {color} | {color:green} 9m 23s {color} | {color:green} hadoop-common in the patch passed with JDK v1.7.0_91. {color} |
| {color:red}-1{color} | {color:red} asflicense {color} | {color:red} 0m 24s {color} | {color:red} Patch generated 3 ASF License warnings. {color} |
| {color:black}{color} | {color:black} {color} | {color:black} 97m 1s {color} | {color:black} {color} |
\\
\\
|| Reason || Tests ||
| JDK v1.8.0_66 Failed junit tests | hadoop.fs.shell.find.TestFind |
\\
\\
|| Subsystem || Report/Notes ||
| Docker |  Image:yetus/hadoop:0ca8df7 |
| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12776344/HADOOP-10729-v2.patch |
| JIRA Issue | HADOOP-10729 |
| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  findbugs  checkstyle  cc  |
| uname | Linux 52b75d97a0bf 3.13.0-36-lowlatency #63-Ubuntu SMP PREEMPT Wed Sep 3 21:56:12 UTC 2014 x86_64 x86_64 x86_64 GNU/Linux |
| Build tool | maven |
| Personality | /testptch/hadoop/patchprocess/precommit/personality/provided.sh |
| git revision | trunk / d7b3f8d |
| findbugs | v3.0.0 |
| unit | https://builds.apache.org/job/PreCommit-HADOOP-Build/8206/artifact/patchprocess/patch-unit-hadoop-common-project_hadoop-common-jdk1.8.0_66.txt |
| unit test logs |  https://builds.apache.org/job/PreCommit-HADOOP-Build/8206/artifact/patchprocess/patch-unit-hadoop-common-project_hadoop-common-jdk1.8.0_66.txt |
| JDK v1.7.0_91  Test Results | https://builds.apache.org/job/PreCommit-HADOOP-Build/8206/testReport/ |
| asflicense | https://builds.apache.org/job/PreCommit-HADOOP-Build/8206/artifact/patchprocess/patch-asflicense-problems.txt |
| modules | C: hadoop-common-project/hadoop-common U: hadoop-common-project/hadoop-common |
| Max memory used | 75MB |
| Powered by | Apache Yetus    http://yetus.apache.org |
| Console output | https://builds.apache.org/job/PreCommit-HADOOP-Build/8206/console |


This message was automatically generated.

","08/Dec/15 21:41;wheat9;+1. Committing.","08/Dec/15 21:45;wheat9;I've committed the patch to trunk, branch-2 and branch-2.8. Thanks [~junping_du] for the contribution.","08/Dec/15 21:50;hudson;FAILURE: Integrated in Hadoop-trunk-Commit #8942 (See [https://builds.apache.org/job/Hadoop-trunk-Commit/8942/])
HADOOP-10729. Add tests for PB RPC in case version mismatch of client (wheat9: rev c4084d9bc3b5c20405d9da6623b330d5720b64a1)
* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/ipc/TestProtoBufRPCCompatibility.java
* hadoop-common-project/hadoop-common/src/test/proto/test.proto
* hadoop-common-project/hadoop-common/CHANGES.txt
* hadoop-common-project/hadoop-common/src/test/proto/test_rpc_service.proto
","09/Dec/15 04:55;hudson;FAILURE: Integrated in Hadoop-Hdfs-trunk-Java8 #677 (See [https://builds.apache.org/job/Hadoop-Hdfs-trunk-Java8/677/])
HADOOP-10729. Add tests for PB RPC in case version mismatch of client (wheat9: rev c4084d9bc3b5c20405d9da6623b330d5720b64a1)
* hadoop-common-project/hadoop-common/src/test/proto/test_rpc_service.proto
* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/ipc/TestProtoBufRPCCompatibility.java
* hadoop-common-project/hadoop-common/CHANGES.txt
* hadoop-common-project/hadoop-common/src/test/proto/test.proto
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
TestKMS should close providers,HADOOP-15313,13144893,Test,Resolved,HADOOP,Hadoop Common,software,omalley,Hadoop Common is the common library for Apache Hadoop.,http://hadoop.apache.org/,Major,Fixed,xiaochen,xiaochen,xiaochen,13/Mar/18 23:47,02/Oct/19 17:15,12/Jan/21 11:55,26/Mar/18 23:00,,,,,3.0.3,3.1.1,3.2.0,,,,kms,test,,,0,,,"During the review of HADOOP-14445, [~jojochuang] found that we key providers are not closed in tests. Details in [this comment|https://issues.apache.org/jira/browse/HADOOP-14445?focusedCommentId=16397824&page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-16397824].

We should investigate and handle that in all related tests.",,hudson,weichiu,xiaochen,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"23/Mar/18 06:10;xiaochen;HADOOP-15313.01.patch;https://issues.apache.org/jira/secure/attachment/12915824/HADOOP-15313.01.patch","23/Mar/18 16:28;xiaochen;HADOOP-15313.02.patch;https://issues.apache.org/jira/secure/attachment/12915934/HADOOP-15313.02.patch","23/Mar/18 22:02;xiaochen;HADOOP-15313.03.patch;https://issues.apache.org/jira/secure/attachment/12915995/HADOOP-15313.03.patch",,,,,,,,,,,,,,,,,,,,,3.0,,,,,,,,,,,,,,,,,,,,2018-03-23 08:46:14.812,,,false,,,,,,,,,,,,,,,,,9223372036854775807,Reviewed,,,,Tue Apr 10 22:44:35 UTC 2018,,,,,,,"0|i3r9gn:",9223372036854775807,,,,,,,,,,,,,3.2.0,,,,,,,,,,"23/Mar/18 06:10;xiaochen;Patch 1 to close the providers.","23/Mar/18 08:46;genericqa;| (/) *{color:green}+1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 28s{color} | {color:blue} Docker mode activated. {color} |
|| || || || {color:brown} Prechecks {color} ||
| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |
| {color:green}+1{color} | {color:green} test4tests {color} | {color:green}  0m  0s{color} | {color:green} The patch appears to include 1 new or modified test files. {color} |
|| || || || {color:brown} trunk Compile Tests {color} ||
| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  0m 13s{color} | {color:blue} Maven dependency ordering for branch {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 23m 18s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 26m 22s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 42s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  1m 25s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 11m  6s{color} | {color:green} branch has no errors when building and testing our client artifacts. {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  1m 47s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  1m 10s{color} | {color:green} trunk passed {color} |
|| || || || {color:brown} Patch Compile Tests {color} ||
| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  0m  7s{color} | {color:blue} Maven dependency ordering for patch {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  0m 57s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 25m 34s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javac {color} | {color:green} 25m 34s{color} | {color:green} the patch passed {color} |
| {color:orange}-0{color} | {color:orange} checkstyle {color} | {color:orange}  0m 50s{color} | {color:orange} hadoop-common-project: The patch generated 1 new + 101 unchanged - 1 fixed = 102 total (was 102) {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  1m 26s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} |
| {color:green}+1{color} | {color:green} shadedclient {color} | {color:green}  8m 54s{color} | {color:green} patch has no errors when building and testing our client artifacts. {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  2m 15s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  1m  4s{color} | {color:green} the patch passed {color} |
|| || || || {color:brown} Other Tests {color} ||
| {color:green}+1{color} | {color:green} unit {color} | {color:green}  8m 40s{color} | {color:green} hadoop-common in the patch passed. {color} |
| {color:green}+1{color} | {color:green} unit {color} | {color:green}  4m  7s{color} | {color:green} hadoop-kms in the patch passed. {color} |
| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 31s{color} | {color:green} The patch does not generate ASF License warnings. {color} |
| {color:black}{color} | {color:black} {color} | {color:black}120m 13s{color} | {color:black} {color} |
\\
\\
|| Subsystem || Report/Notes ||
| Docker | Client=17.05.0-ce Server=17.05.0-ce Image:yetus/hadoop:8620d2b |
| JIRA Issue | HADOOP-15313 |
| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12915824/HADOOP-15313.01.patch |
| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  shadedclient  findbugs  checkstyle  |
| uname | Linux 2c52bb36325b 4.4.0-64-generic #85-Ubuntu SMP Mon Feb 20 11:50:30 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux |
| Build tool | maven |
| Personality | /testptch/patchprocess/precommit/personality/provided.sh |
| git revision | trunk / 22c5ddb |
| maven | version: Apache Maven 3.3.9 |
| Default Java | 1.8.0_151 |
| findbugs | v3.1.0-RC1 |
| checkstyle | https://builds.apache.org/job/PreCommit-HADOOP-Build/14375/artifact/out/diff-checkstyle-hadoop-common-project.txt |
|  Test Results | https://builds.apache.org/job/PreCommit-HADOOP-Build/14375/testReport/ |
| Max. process+thread count | 1436 (vs. ulimit of 10000) |
| modules | C: hadoop-common-project/hadoop-common hadoop-common-project/hadoop-kms U: hadoop-common-project |
| Console output | https://builds.apache.org/job/PreCommit-HADOOP-Build/14375/console |
| Powered by | Apache Yetus 0.8.0-SNAPSHOT   http://yetus.apache.org |


This message was automatically generated.

","23/Mar/18 19:15;genericqa;| (/) *{color:green}+1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 26s{color} | {color:blue} Docker mode activated. {color} |
|| || || || {color:brown} Prechecks {color} ||
| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |
| {color:green}+1{color} | {color:green} test4tests {color} | {color:green}  0m  0s{color} | {color:green} The patch appears to include 1 new or modified test files. {color} |
|| || || || {color:brown} trunk Compile Tests {color} ||
| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  0m  8s{color} | {color:blue} Maven dependency ordering for branch {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 23m 33s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 27m 34s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 48s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  1m 29s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 11m 23s{color} | {color:green} branch has no errors when building and testing our client artifacts. {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  1m 52s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  1m 14s{color} | {color:green} trunk passed {color} |
|| || || || {color:brown} Patch Compile Tests {color} ||
| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  0m  8s{color} | {color:blue} Maven dependency ordering for patch {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  1m  0s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 26m 12s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javac {color} | {color:green} 26m 12s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 44s{color} | {color:green} hadoop-common-project: The patch generated 0 new + 101 unchanged - 1 fixed = 101 total (was 102) {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  1m 24s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} |
| {color:green}+1{color} | {color:green} shadedclient {color} | {color:green}  8m 40s{color} | {color:green} patch has no errors when building and testing our client artifacts. {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  2m  3s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  1m 10s{color} | {color:green} the patch passed {color} |
|| || || || {color:brown} Other Tests {color} ||
| {color:green}+1{color} | {color:green} unit {color} | {color:green}  8m 22s{color} | {color:green} hadoop-common in the patch passed. {color} |
| {color:green}+1{color} | {color:green} unit {color} | {color:green}  3m 46s{color} | {color:green} hadoop-kms in the patch passed. {color} |
| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 29s{color} | {color:green} The patch does not generate ASF License warnings. {color} |
| {color:black}{color} | {color:black} {color} | {color:black}121m 48s{color} | {color:black} {color} |
\\
\\
|| Subsystem || Report/Notes ||
| Docker | Client=17.05.0-ce Server=17.05.0-ce Image:yetus/hadoop:8620d2b |
| JIRA Issue | HADOOP-15313 |
| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12915934/HADOOP-15313.02.patch |
| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  shadedclient  findbugs  checkstyle  |
| uname | Linux c9f358b8a06e 4.4.0-116-generic #140-Ubuntu SMP Mon Feb 12 21:23:04 UTC 2018 x86_64 x86_64 x86_64 GNU/Linux |
| Build tool | maven |
| Personality | /testptch/patchprocess/precommit/personality/provided.sh |
| git revision | trunk / 6e31a09 |
| maven | version: Apache Maven 3.3.9 |
| Default Java | 1.8.0_151 |
| findbugs | v3.1.0-RC1 |
|  Test Results | https://builds.apache.org/job/PreCommit-HADOOP-Build/14380/testReport/ |
| Max. process+thread count | 1369 (vs. ulimit of 10000) |
| modules | C: hadoop-common-project/hadoop-common hadoop-common-project/hadoop-kms U: hadoop-common-project |
| Console output | https://builds.apache.org/job/PreCommit-HADOOP-Build/14380/console |
| Powered by | Apache Yetus 0.8.0-SNAPSHOT   http://yetus.apache.org |


This message was automatically generated.

","23/Mar/18 20:42;weichiu;Thanks for the patch. Nice approach to capture them all. 

I think you'll also need to add a provider into providersCreated in createKMSClientProvider().

A few places where the provider is expliictly closed, like at line 475
{code:title=TestKMS#testStartStop}
testKp.close();
{code}
and at line 502, line 520, line 2197","23/Mar/18 22:04;xiaochen;Thanks for the review [~weichiu], good catch. Handled createKMSCP, and removed the explicit close on 502 / 520.

We still need the explicit close at 475 / 2197 to verify the close method itself doesn't leak threads, so left these 2 as-is. (Added a comment to 475 to make this clearer)","23/Mar/18 22:15;weichiu;+1 pending Jenkins. Thank you.","24/Mar/18 01:32;genericqa;| (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 27s{color} | {color:blue} Docker mode activated. {color} |
|| || || || {color:brown} Prechecks {color} ||
| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |
| {color:green}+1{color} | {color:green} test4tests {color} | {color:green}  0m  0s{color} | {color:green} The patch appears to include 1 new or modified test files. {color} |
|| || || || {color:brown} trunk Compile Tests {color} ||
| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  0m  8s{color} | {color:blue} Maven dependency ordering for branch {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 27m  6s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 27m 14s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 50s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  1m 34s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 11m 26s{color} | {color:green} branch has no errors when building and testing our client artifacts. {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  1m 53s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  1m  9s{color} | {color:green} trunk passed {color} |
|| || || || {color:brown} Patch Compile Tests {color} ||
| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  0m  9s{color} | {color:blue} Maven dependency ordering for patch {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  1m  2s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 26m 48s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javac {color} | {color:green} 26m 48s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 46s{color} | {color:green} hadoop-common-project: The patch generated 0 new + 101 unchanged - 1 fixed = 101 total (was 102) {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  1m 24s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} |
| {color:green}+1{color} | {color:green} shadedclient {color} | {color:green}  8m 24s{color} | {color:green} patch has no errors when building and testing our client artifacts. {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  2m 15s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  1m 22s{color} | {color:green} the patch passed {color} |
|| || || || {color:brown} Other Tests {color} ||
| {color:red}-1{color} | {color:red} unit {color} | {color:red}  7m 37s{color} | {color:red} hadoop-common in the patch failed. {color} |
| {color:green}+1{color} | {color:green} unit {color} | {color:green}  3m 43s{color} | {color:green} hadoop-kms in the patch passed. {color} |
| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 37s{color} | {color:green} The patch does not generate ASF License warnings. {color} |
| {color:black}{color} | {color:black} {color} | {color:black}125m 22s{color} | {color:black} {color} |
\\
\\
|| Reason || Tests ||
| Failed junit tests | hadoop.util.TestDiskChecker |
|   | hadoop.util.TestReadWriteDiskValidator |
\\
\\
|| Subsystem || Report/Notes ||
| Docker | Client=17.05.0-ce Server=17.05.0-ce Image:yetus/hadoop:8620d2b |
| JIRA Issue | HADOOP-15313 |
| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12915995/HADOOP-15313.03.patch |
| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  shadedclient  findbugs  checkstyle  |
| uname | Linux 6061ea9a27ea 4.4.0-89-generic #112-Ubuntu SMP Mon Jul 31 19:38:41 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux |
| Build tool | maven |
| Personality | /testptch/patchprocess/precommit/personality/provided.sh |
| git revision | trunk / 647058e |
| maven | version: Apache Maven 3.3.9 |
| Default Java | 1.8.0_151 |
| findbugs | v3.1.0-RC1 |
| unit | https://builds.apache.org/job/PreCommit-HADOOP-Build/14383/artifact/out/patch-unit-hadoop-common-project_hadoop-common.txt |
|  Test Results | https://builds.apache.org/job/PreCommit-HADOOP-Build/14383/testReport/ |
| Max. process+thread count | 1677 (vs. ulimit of 10000) |
| modules | C: hadoop-common-project/hadoop-common hadoop-common-project/hadoop-kms U: hadoop-common-project |
| Console output | https://builds.apache.org/job/PreCommit-HADOOP-Build/14383/console |
| Powered by | Apache Yetus 0.8.0-SNAPSHOT   http://yetus.apache.org |


This message was automatically generated.

","26/Mar/18 23:00;xiaochen;Committed to trunk. Thanks for the review Wei-Chiu!","26/Mar/18 23:32;hudson;SUCCESS: Integrated in Jenkins build Hadoop-trunk-Commit #13884 (See [https://builds.apache.org/job/Hadoop-trunk-Commit/13884/])
HADOOP-15313. TestKMS should close providers. (xiao: rev c22d62b338cb16d93c4576a9c634041e3610a116)
* (edit) hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/io/MultipleIOException.java
* (edit) hadoop-common-project/hadoop-kms/src/test/java/org/apache/hadoop/crypto/key/kms/server/TestKMS.java
","10/Apr/18 22:44;xiaochen;Cherry-picked to branch-3.1/branch-3.0",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
GridmixTestUtils uses the wrong staging directory in windows,HADOOP-15578,13169669,Test,Patch Available,HADOOP,Hadoop Common,software,omalley,Hadoop Common is the common library for Apache Hadoop.,http://hadoop.apache.org/,Major,,elgoiri,elgoiri,elgoiri,03/Jul/18 01:44,14/Sep/19 00:04,12/Jan/21 11:55,,,,,,,,,,,,,,,,0,,,{{GridmixTestUtils#createHomeAndStagingDirectory}} gets the staging area from the configuration key {{mapreduce.jobtracker.staging.root.dir}}. This variable depends on {{hadoop.tmp.dir}} which in Windows is set to a local Windows folder. When the test tries to create the path in HDFS it gets an error because the path is not compliant.,,ayushtkn,elgoiri,giovanni.fumarola,huanbang1993,surmountian,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"03/Jul/18 01:46;elgoiri;HADOOP-15578.000.patch;https://issues.apache.org/jira/secure/attachment/12930048/HADOOP-15578.000.patch",,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,2018-07-03 03:39:24.932,,,false,,,,,,,,,,,,,,,,,9223372036854775807,,,,,Sat Sep 14 00:04:03 UTC 2019,,,,,,,"0|i3vh1z:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,"03/Jul/18 01:49;elgoiri;The error would be:
{code}
Exception in thread ""StressJobFactory"" java.lang.IllegalArgumentException: Pathname /D:/hadoop-2.9/hadoop-tools/hadoop-gridmix/target/tmp/mapred/staging from D:/hadoop-2.9/hadoop-tools/hadoop-gridmix/target/tmp/mapred/staging is not a valid DFS filename.
	at org.apache.hadoop.hdfs.DistributedFileSystem.getPathName(DistributedFileSystem.java:221)
	at org.apache.hadoop.hdfs.DistributedFileSystem$27.doCall(DistributedFileSystem.java:1248)
	at org.apache.hadoop.hdfs.DistributedFileSystem$27.doCall(DistributedFileSystem.java:1245)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.mkdirsInternal(DistributedFileSystem.java:1262)
	at org.apache.hadoop.hdfs.DistributedFileSystem.mkdirs(DistributedFileSystem.java:1237)
	at org.apache.hadoop.fs.FileSystem.mkdirs(FileSystem.java:2216)
	at org.apache.hadoop.mapred.gridmix.GridmixTestUtils.createHomeAndStagingDirectory(GridmixTestUtils.java:115)
	at org.apache.hadoop.mapred.gridmix.DebugJobProducer$MockJob.getUser(DebugJobProducer.java:217)
	at org.apache.hadoop.mapred.gridmix.JobFactory$FilterJobStory.getUser(JobFactory.java:147)
	at org.apache.hadoop.mapred.gridmix.StressJobFactory$StressReaderThread.run(StressJobFactory.java:210)
{code}

[~surmountian], do you see any other way to fix this issue?/
","03/Jul/18 03:39;genericqa;| (/) *{color:green}+1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 18s{color} | {color:blue} Docker mode activated. {color} |
|| || || || {color:brown} Prechecks {color} ||
| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |
| {color:green}+1{color} | {color:green} test4tests {color} | {color:green}  0m  0s{color} | {color:green} The patch appears to include 1 new or modified test files. {color} |
|| || || || {color:brown} trunk Compile Tests {color} ||
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 32m 11s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green}  0m 27s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 14s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  0m 31s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 12m 32s{color} | {color:green} branch has no errors when building and testing our client artifacts. {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  0m 39s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 21s{color} | {color:green} trunk passed {color} |
|| || || || {color:brown} Patch Compile Tests {color} ||
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  0m 28s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green}  0m 23s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javac {color} | {color:green}  0m 23s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 11s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  0m 30s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} |
| {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 13m 24s{color} | {color:green} patch has no errors when building and testing our client artifacts. {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  0m 40s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 15s{color} | {color:green} the patch passed {color} |
|| || || || {color:brown} Other Tests {color} ||
| {color:green}+1{color} | {color:green} unit {color} | {color:green} 15m 40s{color} | {color:green} hadoop-gridmix in the patch passed. {color} |
| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 30s{color} | {color:green} The patch does not generate ASF License warnings. {color} |
| {color:black}{color} | {color:black} {color} | {color:black} 79m 42s{color} | {color:black} {color} |
\\
\\
|| Subsystem || Report/Notes ||
| Docker | Client=17.05.0-ce Server=17.05.0-ce Image:yetus/hadoop:abb62dd |
| JIRA Issue | HADOOP-15578 |
| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12930048/HADOOP-15578.000.patch |
| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  shadedclient  findbugs  checkstyle  |
| uname | Linux 612b4b0815fd 3.13.0-139-generic #188-Ubuntu SMP Tue Jan 9 14:43:09 UTC 2018 x86_64 x86_64 x86_64 GNU/Linux |
| Build tool | maven |
| Personality | /testptch/patchprocess/precommit/personality/provided.sh |
| git revision | trunk / 7296b64 |
| maven | version: Apache Maven 3.3.9 |
| Default Java | 1.8.0_171 |
| findbugs | v3.1.0-RC1 |
|  Test Results | https://builds.apache.org/job/PreCommit-HADOOP-Build/14849/testReport/ |
| Max. process+thread count | 983 (vs. ulimit of 10000) |
| modules | C: hadoop-tools/hadoop-gridmix U: hadoop-tools/hadoop-gridmix |
| Console output | https://builds.apache.org/job/PreCommit-HADOOP-Build/14849/console |
| Powered by | Apache Yetus 0.8.0-SNAPSHOT   http://yetus.apache.org |


This message was automatically generated.

","03/Jul/18 16:17;elgoiri;The main issue is that this is indirectly using a local path (hadoop.tmp.dir) as an HDFS path for staging.
We may want to change the path for the staging area instead of just tweaking the Windows path.
Another option is to sanitize the Windows path to make it usable for HDFS.","13/Sep/19 22:11;ayushtkn;Thanx [~elgoiri] for the report, I  guess this problem still persists. 
bq. Another option is to sanitize the Windows path to make it usable for HDFS.
IMO, if we can do this, should be better, we can use the configured value, rather than ignoring it.","14/Sep/19 00:04;hadoopqa;| (/) *{color:green}+1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue} 37m 37s{color} | {color:blue} Docker mode activated. {color} |
|| || || || {color:brown} Prechecks {color} ||
| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |
| {color:green}+1{color} | {color:green} test4tests {color} | {color:green}  0m  0s{color} | {color:green} The patch appears to include 1 new or modified test files. {color} |
|| || || || {color:brown} trunk Compile Tests {color} ||
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 18m 44s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green}  0m 22s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 19s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  0m 26s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 12m 10s{color} | {color:green} branch has no errors when building and testing our client artifacts. {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  0m 31s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 20s{color} | {color:green} trunk passed {color} |
|| || || || {color:brown} Patch Compile Tests {color} ||
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  0m 22s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green}  0m 17s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javac {color} | {color:green}  0m 17s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 13s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  0m 20s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} |
| {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 12m 42s{color} | {color:green} patch has no errors when building and testing our client artifacts. {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  0m 38s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 16s{color} | {color:green} the patch passed {color} |
|| || || || {color:brown} Other Tests {color} ||
| {color:green}+1{color} | {color:green} unit {color} | {color:green} 14m 42s{color} | {color:green} hadoop-gridmix in the patch passed. {color} |
| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 30s{color} | {color:green} The patch does not generate ASF License warnings. {color} |
| {color:black}{color} | {color:black} {color} | {color:black}100m 53s{color} | {color:black} {color} |
\\
\\
|| Subsystem || Report/Notes ||
| Docker | Client=19.03.1 Server=19.03.1 Image:yetus/hadoop:39e82acc485 |
| JIRA Issue | HADOOP-15578 |
| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12930048/HADOOP-15578.000.patch |
| Optional Tests |  dupname  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  shadedclient  findbugs  checkstyle  |
| uname | Linux 7bb166d9d0d4 4.15.0-54-generic #58-Ubuntu SMP Mon Jun 24 10:55:24 UTC 2019 x86_64 x86_64 x86_64 GNU/Linux |
| Build tool | maven |
| Personality | /testptch/patchprocess/precommit/personality/provided.sh |
| git revision | trunk / 6a9f7ca |
| maven | version: Apache Maven 3.3.9 |
| Default Java | 1.8.0_222 |
| findbugs | v3.1.0-RC1 |
|  Test Results | https://builds.apache.org/job/PreCommit-HADOOP-Build/16528/testReport/ |
| Max. process+thread count | 981 (vs. ulimit of 5500) |
| modules | C: hadoop-tools/hadoop-gridmix U: hadoop-tools/hadoop-gridmix |
| Console output | https://builds.apache.org/job/PreCommit-HADOOP-Build/16528/console |
| Powered by | Apache Yetus 0.8.0   http://yetus.apache.org |


This message was automatically generated.

",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Remove the usage of org.mockito.internal.util.reflection.Whitebox,HADOOP-14188,13056544,Test,Resolved,HADOOP,Hadoop Common,software,omalley,Hadoop Common is the common library for Apache Hadoop.,http://hadoop.apache.org/,Major,Fixed,ehiggs,aajisaka,aajisaka,16/Mar/17 04:27,22/Feb/19 01:20,12/Jan/21 11:55,27/Apr/18 10:25,,,,,3.2.0,,,,,,test,,,,0,,,"org.mockito.internal.util.reflection.Whitebox was removed in Mockito 2.1, so we need to remove the usage to upgrade Mockito. Getter/setter method can be used instead of this hack.",,aajisaka,ehiggs,haibochen,hudson,junping_du,ozawa,stevel@apache.org,vincent he,,,,,,,,,,,,,,,,,,,,,,,,,,HADOOP-14178,,,,,,,,,,,,,,,,,HDFS-14307,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"23/Mar/17 08:27;aajisaka;HADOOP-14188.01.patch;https://issues.apache.org/jira/secure/attachment/12860097/HADOOP-14188.01.patch","24/Mar/17 05:00;aajisaka;HADOOP-14188.02.patch;https://issues.apache.org/jira/secure/attachment/12860284/HADOOP-14188.02.patch","24/Mar/17 10:28;aajisaka;HADOOP-14188.03.patch;https://issues.apache.org/jira/secure/attachment/12860325/HADOOP-14188.03.patch","27/Mar/17 07:25;aajisaka;HADOOP-14188.04.patch;https://issues.apache.org/jira/secure/attachment/12860606/HADOOP-14188.04.patch","04/Apr/17 05:41;aajisaka;HADOOP-14188.05.patch;https://issues.apache.org/jira/secure/attachment/12861828/HADOOP-14188.05.patch","03/Jul/17 04:31;aajisaka;HADOOP-14188.06.patch;https://issues.apache.org/jira/secure/attachment/12875444/HADOOP-14188.06.patch","25/Jul/17 10:48;aajisaka;HADOOP-14188.07.patch;https://issues.apache.org/jira/secure/attachment/12878773/HADOOP-14188.07.patch","16/Aug/17 05:48;aajisaka;HADOOP-14188.08.patch;https://issues.apache.org/jira/secure/attachment/12882085/HADOOP-14188.08.patch","11/Oct/17 09:25;aajisaka;HADOOP-14188.09.patch;https://issues.apache.org/jira/secure/attachment/12891446/HADOOP-14188.09.patch","11/Oct/17 10:21;aajisaka;HADOOP-14188.10.patch;https://issues.apache.org/jira/secure/attachment/12891453/HADOOP-14188.10.patch","25/Apr/18 13:33;ehiggs;HADOOP-14188.11.patch;https://issues.apache.org/jira/secure/attachment/12920619/HADOOP-14188.11.patch","26/Apr/18 07:24;ehiggs;HADOOP-14188.12.patch;https://issues.apache.org/jira/secure/attachment/12920741/HADOOP-14188.12.patch",,,,,,,,,,,,12.0,,,,,,,,,,,,,,,,,,,,2017-03-23 12:00:54.625,,,false,,,,,,,,,,,,,,,,,9223372036854775807,Reviewed,,,,Fri Apr 27 10:44:12 UTC 2018,,,,,,,"0|i3ccif:",9223372036854775807,,,,,,,,,,,,,3.2.0,,,,,,,,,,"16/Mar/17 07:20;aajisaka;Whitebox was removed by https://github.com/mockito/mockito/issues/489","23/Mar/17 12:00;hadoopqa;| (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 16s{color} | {color:blue} Docker mode activated. {color} |
| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |
| {color:green}+1{color} | {color:green} test4tests {color} | {color:green}  0m  0s{color} | {color:green} The patch appears to include 45 new or modified test files. {color} |
| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  0m 14s{color} | {color:blue} Maven dependency ordering for branch {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 12m 38s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 21m 52s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  2m 27s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  4m 19s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green}  1m 58s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  6m 48s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  3m 18s{color} | {color:green} trunk passed {color} |
| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  0m 16s{color} | {color:blue} Maven dependency ordering for patch {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  2m 59s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 16m 22s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javac {color} | {color:green} 16m 22s{color} | {color:green} the patch passed {color} |
| {color:orange}-0{color} | {color:orange} checkstyle {color} | {color:orange}  2m 30s{color} | {color:orange} root: The patch generated 12 new + 2404 unchanged - 17 fixed = 2416 total (was 2421) {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  4m 40s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green}  2m 16s{color} | {color:green} the patch passed {color} |
| {color:red}-1{color} | {color:red} whitespace {color} | {color:red}  0m  0s{color} | {color:red} The patch has 4 line(s) that end in whitespace. Use git apply --whitespace=fix <<patch_file>>. Refer https://git-scm.com/docs/git-apply {color} |
| {color:red}-1{color} | {color:red} findbugs {color} | {color:red}  1m 40s{color} | {color:red} hadoop-common-project/hadoop-common generated 1 new + 0 unchanged - 0 fixed = 1 total (was 0) {color} |
| {color:red}-1{color} | {color:red} findbugs {color} | {color:red}  1m 46s{color} | {color:red} hadoop-hdfs-project/hadoop-hdfs-client generated 1 new + 0 unchanged - 0 fixed = 1 total (was 0) {color} |
| {color:red}-1{color} | {color:red} findbugs {color} | {color:red}  2m  6s{color} | {color:red} hadoop-hdfs-project/hadoop-hdfs generated 2 new + 0 unchanged - 0 fixed = 2 total (was 0) {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  3m 40s{color} | {color:green} the patch passed {color} |
| {color:red}-1{color} | {color:red} unit {color} | {color:red}  8m 10s{color} | {color:red} hadoop-common in the patch failed. {color} |
| {color:green}+1{color} | {color:green} unit {color} | {color:green}  0m 34s{color} | {color:green} hadoop-nfs in the patch passed. {color} |
| {color:green}+1{color} | {color:green} unit {color} | {color:green}  3m  4s{color} | {color:green} hadoop-kms in the patch passed. {color} |
| {color:green}+1{color} | {color:green} unit {color} | {color:green}  1m  9s{color} | {color:green} hadoop-hdfs-client in the patch passed. {color} |
| {color:red}-1{color} | {color:red} unit {color} | {color:red} 65m  0s{color} | {color:red} hadoop-hdfs in the patch failed. {color} |
| {color:green}+1{color} | {color:green} unit {color} | {color:green}  3m  0s{color} | {color:green} hadoop-mapreduce-client-core in the patch passed. {color} |
| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 42s{color} | {color:green} The patch does not generate ASF License warnings. {color} |
| {color:black}{color} | {color:black} {color} | {color:black}202m  9s{color} | {color:black} {color} |
\\
\\
|| Reason || Tests ||
| FindBugs | module:hadoop-common-project/hadoop-common |
|  |  Write to static field org.apache.hadoop.fs.RawLocalFileSystem.useDeprecatedFileStatus from instance method org.apache.hadoop.fs.RawLocalFileSystem.setUseDeprecatedFileStatus(boolean)  At RawLocalFileSystem.java:from instance method org.apache.hadoop.fs.RawLocalFileSystem.setUseDeprecatedFileStatus(boolean)  At RawLocalFileSystem.java:[line 74] |
| FindBugs | module:hadoop-hdfs-project/hadoop-hdfs-client |
|  |  Inconsistent synchronization of org.apache.hadoop.hdfs.web.WebHdfsFileSystem.canRefreshDelegationToken; locked 80% of time  Unsynchronized access at WebHdfsFileSystem.java:80% of time  Unsynchronized access at WebHdfsFileSystem.java:[line 144] |
| FindBugs | module:hadoop-hdfs-project/hadoop-hdfs |
|  |  Inconsistent synchronization of org.apache.hadoop.hdfs.server.blockmanagement.BlockManagerSafeMode.blockSafe; locked 90% of time  Unsynchronized access at BlockManagerSafeMode.java:90% of time  Unsynchronized access at BlockManagerSafeMode.java:[line 666] |
|  |  Inconsistent synchronization of org.apache.hadoop.hdfs.server.namenode.FSNamesystem.manualSafeMode; locked 75% of time  Unsynchronized access at FSNamesystem.java:75% of time  Unsynchronized access at FSNamesystem.java:[line 588] |
| Failed junit tests | hadoop.security.TestKDiag |
|   | hadoop.net.TestDNS |
|   | hadoop.hdfs.server.datanode.TestDataNodeMXBean |
|   | hadoop.hdfs.server.namenode.snapshot.TestFileWithSnapshotFeature |
\\
\\
|| Subsystem || Report/Notes ||
| Docker |  Image:yetus/hadoop:a9ad5d6 |
| JIRA Issue | HADOOP-14188 |
| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12860097/HADOOP-14188.01.patch |
| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  findbugs  checkstyle  |
| uname | Linux 6e665ccc8540 3.13.0-106-generic #153-Ubuntu SMP Tue Dec 6 15:44:32 UTC 2016 x86_64 x86_64 x86_64 GNU/Linux |
| Build tool | maven |
| Personality | /testptch/hadoop/patchprocess/precommit/personality/provided.sh |
| git revision | trunk / 59d6925 |
| Default Java | 1.8.0_121 |
| findbugs | v3.0.0 |
| checkstyle | https://builds.apache.org/job/PreCommit-HADOOP-Build/11894/artifact/patchprocess/diff-checkstyle-root.txt |
| whitespace | https://builds.apache.org/job/PreCommit-HADOOP-Build/11894/artifact/patchprocess/whitespace-eol.txt |
| findbugs | https://builds.apache.org/job/PreCommit-HADOOP-Build/11894/artifact/patchprocess/new-findbugs-hadoop-common-project_hadoop-common.html |
| findbugs | https://builds.apache.org/job/PreCommit-HADOOP-Build/11894/artifact/patchprocess/new-findbugs-hadoop-hdfs-project_hadoop-hdfs-client.html |
| findbugs | https://builds.apache.org/job/PreCommit-HADOOP-Build/11894/artifact/patchprocess/new-findbugs-hadoop-hdfs-project_hadoop-hdfs.html |
| unit | https://builds.apache.org/job/PreCommit-HADOOP-Build/11894/artifact/patchprocess/patch-unit-hadoop-common-project_hadoop-common.txt |
| unit | https://builds.apache.org/job/PreCommit-HADOOP-Build/11894/artifact/patchprocess/patch-unit-hadoop-hdfs-project_hadoop-hdfs.txt |
|  Test Results | https://builds.apache.org/job/PreCommit-HADOOP-Build/11894/testReport/ |
| modules | C: hadoop-common-project/hadoop-common hadoop-common-project/hadoop-nfs hadoop-common-project/hadoop-kms hadoop-hdfs-project/hadoop-hdfs-client hadoop-hdfs-project/hadoop-hdfs hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core U: . |
| Console output | https://builds.apache.org/job/PreCommit-HADOOP-Build/11894/console |
| Powered by | Apache Yetus 0.5.0-SNAPSHOT   http://yetus.apache.org |


This message was automatically generated.

","24/Mar/17 05:00;aajisaka;02 patch
* Removed trailing whitespaces
* Fixed findbugs warnings
* Fixed TestFileWithSnapshotFeature
* Fixed checkstyle warnings","24/Mar/17 05:51;ozawa;{quote}
Getter/setter method can be used instead of this hack.
{quote}

Personally, I don't prefer to add setter/getter to actual code, (I mean not test code),  to upgrade a test tool since this solution breaks encapsulation. Instead of that, how about porting Whitebox class over to Hadoop common as a utility tool? The choice is worth thinking, since your patch just proved that the Whitebox class is useful and widely used. Fortunately, mockito is distributed under MIT license.","24/Mar/17 06:48;aajisaka;Thanks [~ozawa] for the comment. Using Whitebox is a bad practice and that's why it was removed.
* We need to take care of the name of the field. If the name is changed, the test code can be compiled but runtime error happens.
* Using Whitebox means the production code is not testable. We need to refactor the code instead of the hack.

However, I agreed with porting Whitebox class as a temporal solution because this solution breaks encapsulation. Adding getter/setter methods should be done judiciously.

Now I'd like to port the class and then upgrade Mockito to 2.x, and then we gradually and carefully refactor the code to remove the usage of Whitebox.","24/Mar/17 07:53;ozawa;If Whitebox is a bad practice, how about refactoring with DI framework? We have already used Guice.","24/Mar/17 08:08;aajisaka;bq. If Whitebox is a bad practice, how about refactoring with DI framework? We have already used Guice.
+1","24/Mar/17 08:37;hadoopqa;| (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 15s{color} | {color:blue} Docker mode activated. {color} |
| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |
| {color:green}+1{color} | {color:green} test4tests {color} | {color:green}  0m  0s{color} | {color:green} The patch appears to include 45 new or modified test files. {color} |
| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  0m 14s{color} | {color:blue} Maven dependency ordering for branch {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 14m 49s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 17m 36s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  2m 35s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  4m 56s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green}  2m  6s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  8m  2s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  3m 38s{color} | {color:green} trunk passed {color} |
| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  0m 17s{color} | {color:blue} Maven dependency ordering for patch {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  3m 43s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 16m 18s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javac {color} | {color:green} 16m 18s{color} | {color:green} the patch passed {color} |
| {color:orange}-0{color} | {color:orange} checkstyle {color} | {color:orange}  2m 28s{color} | {color:orange} root: The patch generated 7 new + 2383 unchanged - 40 fixed = 2390 total (was 2423) {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  4m 40s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green}  2m 17s{color} | {color:green} the patch passed {color} |
| {color:red}-1{color} | {color:red} whitespace {color} | {color:red}  0m  0s{color} | {color:red} The patch has 1 line(s) that end in whitespace. Use git apply --whitespace=fix <<patch_file>>. Refer https://git-scm.com/docs/git-apply {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  7m 58s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  3m 40s{color} | {color:green} the patch passed {color} |
| {color:red}-1{color} | {color:red} unit {color} | {color:red}  8m 17s{color} | {color:red} hadoop-common in the patch failed. {color} |
| {color:green}+1{color} | {color:green} unit {color} | {color:green}  0m 32s{color} | {color:green} hadoop-nfs in the patch passed. {color} |
| {color:green}+1{color} | {color:green} unit {color} | {color:green}  3m  3s{color} | {color:green} hadoop-kms in the patch passed. {color} |
| {color:green}+1{color} | {color:green} unit {color} | {color:green}  1m 11s{color} | {color:green} hadoop-hdfs-client in the patch passed. {color} |
| {color:red}-1{color} | {color:red} unit {color} | {color:red} 71m  1s{color} | {color:red} hadoop-hdfs in the patch failed. {color} |
| {color:green}+1{color} | {color:green} unit {color} | {color:green}  3m  7s{color} | {color:green} hadoop-mapreduce-client-core in the patch passed. {color} |
| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 38s{color} | {color:green} The patch does not generate ASF License warnings. {color} |
| {color:black}{color} | {color:black} {color} | {color:black}209m 18s{color} | {color:black} {color} |
\\
\\
|| Reason || Tests ||
| Failed junit tests | hadoop.security.TestKDiag |
|   | hadoop.hdfs.server.namenode.snapshot.TestSnapshotFileLength |
|   | hadoop.hdfs.server.datanode.TestDataNodeVolumeFailureReporting |
\\
\\
|| Subsystem || Report/Notes ||
| Docker |  Image:yetus/hadoop:a9ad5d6 |
| JIRA Issue | HADOOP-14188 |
| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12860284/HADOOP-14188.02.patch |
| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  findbugs  checkstyle  |
| uname | Linux 498824f757ca 3.13.0-106-generic #153-Ubuntu SMP Tue Dec 6 15:44:32 UTC 2016 x86_64 x86_64 x86_64 GNU/Linux |
| Build tool | maven |
| Personality | /testptch/hadoop/patchprocess/precommit/personality/provided.sh |
| git revision | trunk / 1280155 |
| Default Java | 1.8.0_121 |
| findbugs | v3.0.0 |
| checkstyle | https://builds.apache.org/job/PreCommit-HADOOP-Build/11906/artifact/patchprocess/diff-checkstyle-root.txt |
| whitespace | https://builds.apache.org/job/PreCommit-HADOOP-Build/11906/artifact/patchprocess/whitespace-eol.txt |
| unit | https://builds.apache.org/job/PreCommit-HADOOP-Build/11906/artifact/patchprocess/patch-unit-hadoop-common-project_hadoop-common.txt |
| unit | https://builds.apache.org/job/PreCommit-HADOOP-Build/11906/artifact/patchprocess/patch-unit-hadoop-hdfs-project_hadoop-hdfs.txt |
|  Test Results | https://builds.apache.org/job/PreCommit-HADOOP-Build/11906/testReport/ |
| modules | C: hadoop-common-project/hadoop-common hadoop-common-project/hadoop-nfs hadoop-common-project/hadoop-kms hadoop-hdfs-project/hadoop-hdfs-client hadoop-hdfs-project/hadoop-hdfs hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core U: . |
| Console output | https://builds.apache.org/job/PreCommit-HADOOP-Build/11906/console |
| Powered by | Apache Yetus 0.5.0-SNAPSHOT   http://yetus.apache.org |


This message was automatically generated.

","24/Mar/17 10:28;aajisaka;03 patch:
* Ported Whitebox to org.apache.hadoop.test.Whitebox.
* Replace the usage.","24/Mar/17 12:08;hadoopqa;| (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 23s{color} | {color:blue} Docker mode activated. {color} |
| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |
| {color:green}+1{color} | {color:green} test4tests {color} | {color:green}  0m  0s{color} | {color:green} The patch appears to include 46 new or modified test files. {color} |
| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  1m 55s{color} | {color:blue} Maven dependency ordering for branch {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 12m 43s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 13m 47s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  1m 58s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  4m 23s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green}  2m 10s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  6m 22s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  3m 18s{color} | {color:green} trunk passed {color} |
| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  0m 13s{color} | {color:blue} Maven dependency ordering for patch {color} |
| {color:red}-1{color} | {color:red} mvninstall {color} | {color:red}  0m 30s{color} | {color:red} hadoop-common in the patch failed. {color} |
| {color:red}-1{color} | {color:red} mvninstall {color} | {color:red}  0m 12s{color} | {color:red} hadoop-nfs in the patch failed. {color} |
| {color:red}-1{color} | {color:red} mvninstall {color} | {color:red}  0m 12s{color} | {color:red} hadoop-kms in the patch failed. {color} |
| {color:red}-1{color} | {color:red} mvninstall {color} | {color:red}  0m 27s{color} | {color:red} hadoop-hdfs-client in the patch failed. {color} |
| {color:red}-1{color} | {color:red} mvninstall {color} | {color:red}  0m 38s{color} | {color:red} hadoop-hdfs in the patch failed. {color} |
| {color:red}-1{color} | {color:red} mvninstall {color} | {color:red}  0m 22s{color} | {color:red} hadoop-mapreduce-client-core in the patch failed. {color} |
| {color:red}-1{color} | {color:red} compile {color} | {color:red}  0m 54s{color} | {color:red} root in the patch failed. {color} |
| {color:red}-1{color} | {color:red} javac {color} | {color:red}  0m 54s{color} | {color:red} root in the patch failed. {color} |
| {color:orange}-0{color} | {color:orange} checkstyle {color} | {color:orange}  1m 43s{color} | {color:orange} root: The patch generated 2 new + 978 unchanged - 2 fixed = 980 total (was 980) {color} |
| {color:red}-1{color} | {color:red} mvnsite {color} | {color:red}  0m 35s{color} | {color:red} hadoop-common in the patch failed. {color} |
| {color:red}-1{color} | {color:red} mvnsite {color} | {color:red}  0m 13s{color} | {color:red} hadoop-nfs in the patch failed. {color} |
| {color:red}-1{color} | {color:red} mvnsite {color} | {color:red}  0m 14s{color} | {color:red} hadoop-kms in the patch failed. {color} |
| {color:red}-1{color} | {color:red} mvnsite {color} | {color:red}  0m 30s{color} | {color:red} hadoop-hdfs-client in the patch failed. {color} |
| {color:red}-1{color} | {color:red} mvnsite {color} | {color:red}  0m 42s{color} | {color:red} hadoop-hdfs in the patch failed. {color} |
| {color:red}-1{color} | {color:red} mvnsite {color} | {color:red}  0m 21s{color} | {color:red} hadoop-mapreduce-client-core in the patch failed. {color} |
| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green}  1m  4s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} |
| {color:green}+1{color} | {color:green} xml {color} | {color:green}  0m  1s{color} | {color:green} The patch has no ill-formed XML file. {color} |
| {color:red}-1{color} | {color:red} findbugs {color} | {color:red}  0m 26s{color} | {color:red} hadoop-common in the patch failed. {color} |
| {color:red}-1{color} | {color:red} findbugs {color} | {color:red}  0m 15s{color} | {color:red} hadoop-nfs in the patch failed. {color} |
| {color:red}-1{color} | {color:red} findbugs {color} | {color:red}  0m 17s{color} | {color:red} hadoop-kms in the patch failed. {color} |
| {color:red}-1{color} | {color:red} findbugs {color} | {color:red}  0m 17s{color} | {color:red} hadoop-hdfs-client in the patch failed. {color} |
| {color:red}-1{color} | {color:red} findbugs {color} | {color:red}  0m 27s{color} | {color:red} hadoop-hdfs in the patch failed. {color} |
| {color:red}-1{color} | {color:red} findbugs {color} | {color:red}  0m 19s{color} | {color:red} hadoop-mapreduce-client-core in the patch failed. {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  2m 56s{color} | {color:green} the patch passed {color} |
| {color:red}-1{color} | {color:red} unit {color} | {color:red}  0m 42s{color} | {color:red} hadoop-common in the patch failed. {color} |
| {color:red}-1{color} | {color:red} unit {color} | {color:red}  0m 20s{color} | {color:red} hadoop-nfs in the patch failed. {color} |
| {color:red}-1{color} | {color:red} unit {color} | {color:red}  0m 21s{color} | {color:red} hadoop-kms in the patch failed. {color} |
| {color:red}-1{color} | {color:red} unit {color} | {color:red}  0m 34s{color} | {color:red} hadoop-hdfs-client in the patch failed. {color} |
| {color:red}-1{color} | {color:red} unit {color} | {color:red}  0m 46s{color} | {color:red} hadoop-hdfs in the patch failed. {color} |
| {color:red}-1{color} | {color:red} unit {color} | {color:red}  0m 28s{color} | {color:red} hadoop-mapreduce-client-core in the patch failed. {color} |
| {color:red}-1{color} | {color:red} asflicense {color} | {color:red}  0m 27s{color} | {color:red} The patch generated 1 ASF License warnings. {color} |
| {color:black}{color} | {color:black} {color} | {color:black} 89m  8s{color} | {color:black} {color} |
\\
\\
|| Subsystem || Report/Notes ||
| Docker |  Image:yetus/hadoop:a9ad5d6 |
| JIRA Issue | HADOOP-14188 |
| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12860325/HADOOP-14188.03.patch |
| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  findbugs  checkstyle  xml  |
| uname | Linux 1aeac3ef5aed 4.4.0-43-generic #63-Ubuntu SMP Wed Oct 12 13:48:03 UTC 2016 x86_64 x86_64 x86_64 GNU/Linux |
| Build tool | maven |
| Personality | /testptch/hadoop/patchprocess/precommit/personality/provided.sh |
| git revision | trunk / ab759e9 |
| Default Java | 1.8.0_121 |
| findbugs | v3.0.0 |
| mvninstall | https://builds.apache.org/job/PreCommit-HADOOP-Build/11909/artifact/patchprocess/patch-mvninstall-hadoop-common-project_hadoop-common.txt |
| mvninstall | https://builds.apache.org/job/PreCommit-HADOOP-Build/11909/artifact/patchprocess/patch-mvninstall-hadoop-common-project_hadoop-nfs.txt |
| mvninstall | https://builds.apache.org/job/PreCommit-HADOOP-Build/11909/artifact/patchprocess/patch-mvninstall-hadoop-common-project_hadoop-kms.txt |
| mvninstall | https://builds.apache.org/job/PreCommit-HADOOP-Build/11909/artifact/patchprocess/patch-mvninstall-hadoop-hdfs-project_hadoop-hdfs-client.txt |
| mvninstall | https://builds.apache.org/job/PreCommit-HADOOP-Build/11909/artifact/patchprocess/patch-mvninstall-hadoop-hdfs-project_hadoop-hdfs.txt |
| mvninstall | https://builds.apache.org/job/PreCommit-HADOOP-Build/11909/artifact/patchprocess/patch-mvninstall-hadoop-mapreduce-project_hadoop-mapreduce-client_hadoop-mapreduce-client-core.txt |
| compile | https://builds.apache.org/job/PreCommit-HADOOP-Build/11909/artifact/patchprocess/patch-compile-root.txt |
| javac | https://builds.apache.org/job/PreCommit-HADOOP-Build/11909/artifact/patchprocess/patch-compile-root.txt |
| checkstyle | https://builds.apache.org/job/PreCommit-HADOOP-Build/11909/artifact/patchprocess/diff-checkstyle-root.txt |
| mvnsite | https://builds.apache.org/job/PreCommit-HADOOP-Build/11909/artifact/patchprocess/patch-mvnsite-hadoop-common-project_hadoop-common.txt |
| mvnsite | https://builds.apache.org/job/PreCommit-HADOOP-Build/11909/artifact/patchprocess/patch-mvnsite-hadoop-common-project_hadoop-nfs.txt |
| mvnsite | https://builds.apache.org/job/PreCommit-HADOOP-Build/11909/artifact/patchprocess/patch-mvnsite-hadoop-common-project_hadoop-kms.txt |
| mvnsite | https://builds.apache.org/job/PreCommit-HADOOP-Build/11909/artifact/patchprocess/patch-mvnsite-hadoop-hdfs-project_hadoop-hdfs-client.txt |
| mvnsite | https://builds.apache.org/job/PreCommit-HADOOP-Build/11909/artifact/patchprocess/patch-mvnsite-hadoop-hdfs-project_hadoop-hdfs.txt |
| mvnsite | https://builds.apache.org/job/PreCommit-HADOOP-Build/11909/artifact/patchprocess/patch-mvnsite-hadoop-mapreduce-project_hadoop-mapreduce-client_hadoop-mapreduce-client-core.txt |
| findbugs | https://builds.apache.org/job/PreCommit-HADOOP-Build/11909/artifact/patchprocess/patch-findbugs-hadoop-common-project_hadoop-common.txt |
| findbugs | https://builds.apache.org/job/PreCommit-HADOOP-Build/11909/artifact/patchprocess/patch-findbugs-hadoop-common-project_hadoop-nfs.txt |
| findbugs | https://builds.apache.org/job/PreCommit-HADOOP-Build/11909/artifact/patchprocess/patch-findbugs-hadoop-common-project_hadoop-kms.txt |
| findbugs | https://builds.apache.org/job/PreCommit-HADOOP-Build/11909/artifact/patchprocess/patch-findbugs-hadoop-hdfs-project_hadoop-hdfs-client.txt |
| findbugs | https://builds.apache.org/job/PreCommit-HADOOP-Build/11909/artifact/patchprocess/patch-findbugs-hadoop-hdfs-project_hadoop-hdfs.txt |
| findbugs | https://builds.apache.org/job/PreCommit-HADOOP-Build/11909/artifact/patchprocess/patch-findbugs-hadoop-mapreduce-project_hadoop-mapreduce-client_hadoop-mapreduce-client-core.txt |
| unit | https://builds.apache.org/job/PreCommit-HADOOP-Build/11909/artifact/patchprocess/patch-unit-hadoop-common-project_hadoop-common.txt |
| unit | https://builds.apache.org/job/PreCommit-HADOOP-Build/11909/artifact/patchprocess/patch-unit-hadoop-common-project_hadoop-nfs.txt |
| unit | https://builds.apache.org/job/PreCommit-HADOOP-Build/11909/artifact/patchprocess/patch-unit-hadoop-common-project_hadoop-kms.txt |
| unit | https://builds.apache.org/job/PreCommit-HADOOP-Build/11909/artifact/patchprocess/patch-unit-hadoop-hdfs-project_hadoop-hdfs-client.txt |
| unit | https://builds.apache.org/job/PreCommit-HADOOP-Build/11909/artifact/patchprocess/patch-unit-hadoop-hdfs-project_hadoop-hdfs.txt |
| unit | https://builds.apache.org/job/PreCommit-HADOOP-Build/11909/artifact/patchprocess/patch-unit-hadoop-mapreduce-project_hadoop-mapreduce-client_hadoop-mapreduce-client-core.txt |
|  Test Results | https://builds.apache.org/job/PreCommit-HADOOP-Build/11909/testReport/ |
| asflicense | https://builds.apache.org/job/PreCommit-HADOOP-Build/11909/artifact/patchprocess/patch-asflicense-problems.txt |
| modules | C: hadoop-common-project/hadoop-common hadoop-common-project/hadoop-nfs hadoop-common-project/hadoop-kms hadoop-hdfs-project/hadoop-hdfs-client hadoop-hdfs-project/hadoop-hdfs hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core U: . |
| Console output | https://builds.apache.org/job/PreCommit-HADOOP-Build/11909/console |
| Powered by | Apache Yetus 0.5.0-SNAPSHOT   http://yetus.apache.org |


This message was automatically generated.

","27/Mar/17 07:25;aajisaka;Fix compile error.","27/Mar/17 10:58;hadoopqa;| (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 19s{color} | {color:blue} Docker mode activated. {color} |
| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |
| {color:green}+1{color} | {color:green} test4tests {color} | {color:green}  0m  0s{color} | {color:green} The patch appears to include 46 new or modified test files. {color} |
| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  1m 46s{color} | {color:blue} Maven dependency ordering for branch {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 13m 45s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 19m 22s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  2m 11s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  4m 49s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green}  2m  3s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  6m 50s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  3m 21s{color} | {color:green} trunk passed {color} |
| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  0m 16s{color} | {color:blue} Maven dependency ordering for patch {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  2m 57s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 14m 24s{color} | {color:green} the patch passed {color} |
| {color:red}-1{color} | {color:red} javac {color} | {color:red} 14m 24s{color} | {color:red} root generated 153 new + 777 unchanged - 0 fixed = 930 total (was 777) {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  2m 11s{color} | {color:green} root: The patch generated 0 new + 978 unchanged - 1 fixed = 978 total (was 979) {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  4m 40s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green}  2m 16s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} |
| {color:green}+1{color} | {color:green} xml {color} | {color:green}  0m  2s{color} | {color:green} The patch has no ill-formed XML file. {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  8m 43s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  3m 47s{color} | {color:green} the patch passed {color} |
| {color:red}-1{color} | {color:red} unit {color} | {color:red}  8m 31s{color} | {color:red} hadoop-common in the patch failed. {color} |
| {color:green}+1{color} | {color:green} unit {color} | {color:green}  0m 35s{color} | {color:green} hadoop-nfs in the patch passed. {color} |
| {color:green}+1{color} | {color:green} unit {color} | {color:green}  3m  6s{color} | {color:green} hadoop-kms in the patch passed. {color} |
| {color:green}+1{color} | {color:green} unit {color} | {color:green}  1m 12s{color} | {color:green} hadoop-hdfs-client in the patch passed. {color} |
| {color:red}-1{color} | {color:red} unit {color} | {color:red} 73m 27s{color} | {color:red} hadoop-hdfs in the patch failed. {color} |
| {color:green}+1{color} | {color:green} unit {color} | {color:green}  2m 59s{color} | {color:green} hadoop-mapreduce-client-core in the patch passed. {color} |
| {color:red}-1{color} | {color:red} asflicense {color} | {color:red}  0m 41s{color} | {color:red} The patch generated 1 ASF License warnings. {color} |
| {color:black}{color} | {color:black} {color} | {color:black}210m  0s{color} | {color:black} {color} |
\\
\\
|| Reason || Tests ||
| Failed junit tests | hadoop.security.TestKDiag |
|   | hadoop.hdfs.server.blockmanagement.TestRBWBlockInvalidation |
|   | hadoop.hdfs.server.datanode.TestDataNodeVolumeFailure |
|   | hadoop.hdfs.server.datanode.TestDataNodeVolumeFailureReporting |
\\
\\
|| Subsystem || Report/Notes ||
| Docker |  Image:yetus/hadoop:a9ad5d6 |
| JIRA Issue | HADOOP-14188 |
| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12860606/HADOOP-14188.04.patch |
| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  findbugs  checkstyle  xml  |
| uname | Linux bbdb204154a2 3.13.0-106-generic #153-Ubuntu SMP Tue Dec 6 15:44:32 UTC 2016 x86_64 x86_64 x86_64 GNU/Linux |
| Build tool | maven |
| Personality | /testptch/hadoop/patchprocess/precommit/personality/provided.sh |
| git revision | trunk / 945b006 |
| Default Java | 1.8.0_121 |
| findbugs | v3.0.0 |
| javac | https://builds.apache.org/job/PreCommit-HADOOP-Build/11936/artifact/patchprocess/diff-compile-javac-root.txt |
| unit | https://builds.apache.org/job/PreCommit-HADOOP-Build/11936/artifact/patchprocess/patch-unit-hadoop-common-project_hadoop-common.txt |
| unit | https://builds.apache.org/job/PreCommit-HADOOP-Build/11936/artifact/patchprocess/patch-unit-hadoop-hdfs-project_hadoop-hdfs.txt |
|  Test Results | https://builds.apache.org/job/PreCommit-HADOOP-Build/11936/testReport/ |
| asflicense | https://builds.apache.org/job/PreCommit-HADOOP-Build/11936/artifact/patchprocess/patch-asflicense-problems.txt |
| modules | C: hadoop-common-project/hadoop-common hadoop-common-project/hadoop-nfs hadoop-common-project/hadoop-kms hadoop-hdfs-project/hadoop-hdfs-client hadoop-hdfs-project/hadoop-hdfs hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core U: . |
| Console output | https://builds.apache.org/job/PreCommit-HADOOP-Build/11936/console |
| Powered by | Apache Yetus 0.5.0-SNAPSHOT   http://yetus.apache.org |


This message was automatically generated.

","04/Apr/17 05:41;aajisaka;05 patch:
* fixed license error
* modified LICENSE.txt","04/Apr/17 08:27;hadoopqa;| (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 18s{color} | {color:blue} Docker mode activated. {color} |
| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |
| {color:green}+1{color} | {color:green} test4tests {color} | {color:green}  0m  0s{color} | {color:green} The patch appears to include 46 new or modified test files. {color} |
| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  0m 18s{color} | {color:blue} Maven dependency ordering for branch {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 14m 34s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 17m 18s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  2m 20s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green} 10m 50s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green}  1m 17s{color} | {color:green} trunk passed {color} |
| {color:blue}0{color} | {color:blue} findbugs {color} | {color:blue}  0m  0s{color} | {color:blue} Skipped patched modules with no Java source: . {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  7m 35s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  5m  3s{color} | {color:green} trunk passed {color} |
| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  0m 17s{color} | {color:blue} Maven dependency ordering for patch {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 16m 12s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 13m 49s{color} | {color:green} the patch passed {color} |
| {color:red}-1{color} | {color:red} javac {color} | {color:red} 13m 49s{color} | {color:red} root generated 153 new + 787 unchanged - 0 fixed = 940 total (was 787) {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  2m 14s{color} | {color:green} root: The patch generated 0 new + 978 unchanged - 1 fixed = 978 total (was 979) {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  9m 23s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green}  1m  8s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} |
| {color:green}+1{color} | {color:green} xml {color} | {color:green}  0m  1s{color} | {color:green} The patch has no ill-formed XML file. {color} |
| {color:blue}0{color} | {color:blue} findbugs {color} | {color:blue}  0m  0s{color} | {color:blue} Skipped patched modules with no Java source: . {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  7m 45s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  4m 47s{color} | {color:green} the patch passed {color} |
| {color:red}-1{color} | {color:red} unit {color} | {color:red} 18m 26s{color} | {color:red} root in the patch failed. {color} |
| {color:red}-1{color} | {color:red} asflicense {color} | {color:red}  0m 38s{color} | {color:red} The patch generated 2 ASF License warnings. {color} |
| {color:black}{color} | {color:black} {color} | {color:black}158m 32s{color} | {color:black} {color} |
\\
\\
|| Reason || Tests ||
| Failed junit tests | hadoop.security.TestRaceWhenRelogin |
|   | hadoop.security.TestKDiag |
\\
\\
|| Subsystem || Report/Notes ||
| Docker |  Image:yetus/hadoop:a9ad5d6 |
| JIRA Issue | HADOOP-14188 |
| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12861828/HADOOP-14188.05.patch |
| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  findbugs  checkstyle  xml  |
| uname | Linux 124557373a76 3.13.0-106-generic #153-Ubuntu SMP Tue Dec 6 15:44:32 UTC 2016 x86_64 x86_64 x86_64 GNU/Linux |
| Build tool | maven |
| Personality | /testptch/hadoop/patchprocess/precommit/personality/provided.sh |
| git revision | trunk / 6eba792 |
| Default Java | 1.8.0_121 |
| findbugs | v3.0.0 |
| javac | https://builds.apache.org/job/PreCommit-HADOOP-Build/12020/artifact/patchprocess/diff-compile-javac-root.txt |
| unit | https://builds.apache.org/job/PreCommit-HADOOP-Build/12020/artifact/patchprocess/patch-unit-root.txt |
|  Test Results | https://builds.apache.org/job/PreCommit-HADOOP-Build/12020/testReport/ |
| asflicense | https://builds.apache.org/job/PreCommit-HADOOP-Build/12020/artifact/patchprocess/patch-asflicense-problems.txt |
| modules | C: hadoop-common-project/hadoop-common hadoop-common-project/hadoop-nfs hadoop-common-project/hadoop-kms hadoop-hdfs-project/hadoop-hdfs-client hadoop-hdfs-project/hadoop-hdfs hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core . U: . |
| Console output | https://builds.apache.org/job/PreCommit-HADOOP-Build/12020/console |
| Powered by | Apache Yetus 0.5.0-SNAPSHOT   http://yetus.apache.org |


This message was automatically generated.

","05/Apr/17 04:50;aajisaka;Can someone review the latest patch? I'm thinking the patch is ready for review.","30/Jun/17 01:42;hadoopqa;| (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m  0s{color} | {color:blue} Docker mode activated. {color} |
| {color:red}-1{color} | {color:red} patch {color} | {color:red}  0m  5s{color} | {color:red} HADOOP-14188 does not apply to trunk. Rebase required? Wrong Branch? See https://wiki.apache.org/hadoop/HowToContribute for help. {color} |
\\
\\
|| Subsystem || Report/Notes ||
| JIRA Issue | HADOOP-14188 |
| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12861828/HADOOP-14188.05.patch |
| Console output | https://builds.apache.org/job/PreCommit-HADOOP-Build/12679/console |
| Powered by | Apache Yetus 0.5.0-SNAPSHOT   http://yetus.apache.org |


This message was automatically generated.

","03/Jul/17 04:31;aajisaka;06: rebased.","03/Jul/17 07:02;hadoopqa;| (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 17s{color} | {color:blue} Docker mode activated. {color} |
| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |
| {color:green}+1{color} | {color:green} test4tests {color} | {color:green}  0m  0s{color} | {color:green} The patch appears to include 48 new or modified test files. {color} |
| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  1m 26s{color} | {color:blue} Maven dependency ordering for branch {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 15m 35s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 15m 17s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  2m  5s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  9m 51s{color} | {color:green} trunk passed {color} |
| {color:blue}0{color} | {color:blue} findbugs {color} | {color:blue}  0m  0s{color} | {color:blue} Skipped patched modules with no Java source: . {color} |
| {color:red}-1{color} | {color:red} findbugs {color} | {color:red}  1m 30s{color} | {color:red} hadoop-hdfs-project/hadoop-hdfs-client in trunk has 2 extant Findbugs warnings. {color} |
| {color:red}-1{color} | {color:red} findbugs {color} | {color:red}  1m 48s{color} | {color:red} hadoop-hdfs-project/hadoop-hdfs in trunk has 10 extant Findbugs warnings. {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  5m 40s{color} | {color:green} trunk passed {color} |
| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  0m 21s{color} | {color:blue} Maven dependency ordering for patch {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 17m 54s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 10m 20s{color} | {color:green} the patch passed {color} |
| {color:red}-1{color} | {color:red} javac {color} | {color:red} 10m 20s{color} | {color:red} root generated 164 new + 825 unchanged - 0 fixed = 989 total (was 825) {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  2m  9s{color} | {color:green} root: The patch generated 0 new + 972 unchanged - 1 fixed = 972 total (was 973) {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  9m 32s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} |
| {color:green}+1{color} | {color:green} xml {color} | {color:green}  0m  2s{color} | {color:green} The patch has no ill-formed XML file. {color} |
| {color:blue}0{color} | {color:blue} findbugs {color} | {color:blue}  0m  0s{color} | {color:blue} Skipped patched modules with no Java source: . {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  7m 14s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  4m 30s{color} | {color:green} the patch passed {color} |
| {color:red}-1{color} | {color:red} unit {color} | {color:red} 13m  5s{color} | {color:red} root in the patch failed. {color} |
| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 38s{color} | {color:green} The patch does not generate ASF License warnings. {color} |
| {color:black}{color} | {color:black} {color} | {color:black}143m 59s{color} | {color:black} {color} |
\\
\\
|| Reason || Tests ||
| Failed junit tests | hadoop.fs.viewfs.TestViewFileSystemWithAuthorityLocalFileSystem |
\\
\\
|| Subsystem || Report/Notes ||
| Docker |  Image:yetus/hadoop:14b5c93 |
| JIRA Issue | HADOOP-14188 |
| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12875444/HADOOP-14188.06.patch |
| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  findbugs  checkstyle  xml  |
| uname | Linux 10c3bcdd24e8 3.13.0-116-generic #163-Ubuntu SMP Fri Mar 31 14:13:22 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux |
| Build tool | maven |
| Personality | /testptch/hadoop/patchprocess/precommit/personality/provided.sh |
| git revision | trunk / bf1f599 |
| Default Java | 1.8.0_131 |
| findbugs | v3.1.0-RC1 |
| findbugs | https://builds.apache.org/job/PreCommit-HADOOP-Build/12699/artifact/patchprocess/branch-findbugs-hadoop-hdfs-project_hadoop-hdfs-client-warnings.html |
| findbugs | https://builds.apache.org/job/PreCommit-HADOOP-Build/12699/artifact/patchprocess/branch-findbugs-hadoop-hdfs-project_hadoop-hdfs-warnings.html |
| javac | https://builds.apache.org/job/PreCommit-HADOOP-Build/12699/artifact/patchprocess/diff-compile-javac-root.txt |
| unit | https://builds.apache.org/job/PreCommit-HADOOP-Build/12699/artifact/patchprocess/patch-unit-root.txt |
|  Test Results | https://builds.apache.org/job/PreCommit-HADOOP-Build/12699/testReport/ |
| modules | C: hadoop-common-project/hadoop-common hadoop-common-project/hadoop-nfs hadoop-common-project/hadoop-kms hadoop-hdfs-project/hadoop-hdfs-client hadoop-hdfs-project/hadoop-hdfs hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core . U: . |
| Console output | https://builds.apache.org/job/PreCommit-HADOOP-Build/12699/console |
| Powered by | Apache Yetus 0.5.0-SNAPSHOT   http://yetus.apache.org |


This message was automatically generated.

","25/Jul/17 10:48;aajisaka;07: rebased","25/Jul/17 21:17;hadoopqa;| (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 15s{color} | {color:blue} Docker mode activated. {color} |
|| || || || {color:brown} Prechecks {color} ||
| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |
| {color:green}+1{color} | {color:green} test4tests {color} | {color:green}  0m  0s{color} | {color:green} The patch appears to include 48 new or modified test files. {color} |
|| || || || {color:brown} trunk Compile Tests {color} ||
| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  1m 23s{color} | {color:blue} Maven dependency ordering for branch {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 14m 35s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 14m 36s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  2m  9s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green} 11m 20s{color} | {color:green} trunk passed {color} |
| {color:blue}0{color} | {color:blue} findbugs {color} | {color:blue}  0m  0s{color} | {color:blue} Skipped patched modules with no Java source: . {color} |
| {color:red}-1{color} | {color:red} findbugs {color} | {color:red}  1m 30s{color} | {color:red} hadoop-hdfs-project/hadoop-hdfs-client in trunk has 2 extant Findbugs warnings. {color} |
| {color:red}-1{color} | {color:red} findbugs {color} | {color:red}  1m 45s{color} | {color:red} hadoop-hdfs-project/hadoop-hdfs in trunk has 10 extant Findbugs warnings. {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  4m 30s{color} | {color:green} trunk passed {color} |
|| || || || {color:brown} Patch Compile Tests {color} ||
| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  0m 16s{color} | {color:blue} Maven dependency ordering for patch {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 17m 50s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 11m 16s{color} | {color:green} the patch passed {color} |
| {color:red}-1{color} | {color:red} javac {color} | {color:red} 11m 16s{color} | {color:red} root generated 162 new + 1313 unchanged - 0 fixed = 1475 total (was 1313) {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  2m  8s{color} | {color:green} root: The patch generated 0 new + 971 unchanged - 1 fixed = 971 total (was 972) {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green} 10m 20s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} |
| {color:blue}0{color} | {color:blue} findbugs {color} | {color:blue}  0m  0s{color} | {color:blue} Skipped patched modules with no Java source: . {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  7m 18s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  4m 32s{color} | {color:green} the patch passed {color} |
|| || || || {color:brown} Other Tests {color} ||
| {color:red}-1{color} | {color:red} unit {color} | {color:red} 13m 32s{color} | {color:red} root in the patch failed. {color} |
| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 38s{color} | {color:green} The patch does not generate ASF License warnings. {color} |
| {color:black}{color} | {color:black} {color} | {color:black}144m 33s{color} | {color:black} {color} |
\\
\\
|| Reason || Tests ||
| Failed junit tests | hadoop.security.TestKDiag |
\\
\\
|| Subsystem || Report/Notes ||
| Docker |  Image:yetus/hadoop:14b5c93 |
| JIRA Issue | HADOOP-14188 |
| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12878773/HADOOP-14188.07.patch |
| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  findbugs  checkstyle  |
| uname | Linux 7413c4302d1a 3.13.0-117-generic #164-Ubuntu SMP Fri Apr 7 11:05:26 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux |
| Build tool | maven |
| Personality | /testptch/hadoop/patchprocess/precommit/personality/provided.sh |
| git revision | trunk / ac9489f |
| Default Java | 1.8.0_131 |
| findbugs | v3.1.0-RC1 |
| findbugs | https://builds.apache.org/job/PreCommit-HADOOP-Build/12851/artifact/patchprocess/branch-findbugs-hadoop-hdfs-project_hadoop-hdfs-client-warnings.html |
| findbugs | https://builds.apache.org/job/PreCommit-HADOOP-Build/12851/artifact/patchprocess/branch-findbugs-hadoop-hdfs-project_hadoop-hdfs-warnings.html |
| javac | https://builds.apache.org/job/PreCommit-HADOOP-Build/12851/artifact/patchprocess/diff-compile-javac-root.txt |
| unit | https://builds.apache.org/job/PreCommit-HADOOP-Build/12851/artifact/patchprocess/patch-unit-root.txt |
|  Test Results | https://builds.apache.org/job/PreCommit-HADOOP-Build/12851/testReport/ |
| modules | C: hadoop-common-project/hadoop-common hadoop-common-project/hadoop-nfs hadoop-common-project/hadoop-kms hadoop-hdfs-project/hadoop-hdfs-client hadoop-hdfs-project/hadoop-hdfs hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core . U: . |
| Console output | https://builds.apache.org/job/PreCommit-HADOOP-Build/12851/console |
| Powered by | Apache Yetus 0.6.0-SNAPSHOT   http://yetus.apache.org |


This message was automatically generated.

","16/Aug/17 05:48;aajisaka;08: rebased","16/Aug/17 08:15;hadoopqa;| (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 18s{color} | {color:blue} Docker mode activated. {color} |
|| || || || {color:brown} Prechecks {color} ||
| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |
| {color:green}+1{color} | {color:green} test4tests {color} | {color:green}  0m  0s{color} | {color:green} The patch appears to include 48 new or modified test files. {color} |
|| || || || {color:brown} trunk Compile Tests {color} ||
| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  0m 17s{color} | {color:blue} Maven dependency ordering for branch {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 15m 23s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 15m 35s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  2m 11s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green} 10m 39s{color} | {color:green} trunk passed {color} |
| {color:blue}0{color} | {color:blue} findbugs {color} | {color:blue}  0m  0s{color} | {color:blue} Skipped patched modules with no Java source: . {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  6m 12s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  4m 42s{color} | {color:green} trunk passed {color} |
|| || || || {color:brown} Patch Compile Tests {color} ||
| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  0m 17s{color} | {color:blue} Maven dependency ordering for patch {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 17m  4s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 10m 42s{color} | {color:green} the patch passed {color} |
| {color:red}-1{color} | {color:red} javac {color} | {color:red} 10m 42s{color} | {color:red} root generated 162 new + 1317 unchanged - 0 fixed = 1479 total (was 1317) {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  2m 14s{color} | {color:green} root: The patch generated 0 new + 970 unchanged - 1 fixed = 970 total (was 971) {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green} 10m 37s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} |
| {color:green}+1{color} | {color:green} xml {color} | {color:green}  0m  2s{color} | {color:green} The patch has no ill-formed XML file. {color} |
| {color:blue}0{color} | {color:blue} findbugs {color} | {color:blue}  0m  0s{color} | {color:blue} Skipped patched modules with no Java source: . {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  7m 18s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  4m 44s{color} | {color:green} the patch passed {color} |
|| || || || {color:brown} Other Tests {color} ||
| {color:red}-1{color} | {color:red} unit {color} | {color:red} 13m 47s{color} | {color:red} root in the patch failed. {color} |
| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 33s{color} | {color:green} The patch does not generate ASF License warnings. {color} |
| {color:black}{color} | {color:black} {color} | {color:black}144m 28s{color} | {color:black} {color} |
\\
\\
|| Reason || Tests ||
| Failed junit tests | hadoop.fs.shell.TestCopyFromLocal |
|   | hadoop.ipc.TestRPC |
|   | hadoop.security.TestKDiag |
|   | hadoop.net.TestDNS |
\\
\\
|| Subsystem || Report/Notes ||
| Docker |  Image:yetus/hadoop:14b5c93 |
| JIRA Issue | HADOOP-14188 |
| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12882085/HADOOP-14188.08.patch |
| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  xml  findbugs  checkstyle  |
| uname | Linux d74750864d83 3.13.0-117-generic #164-Ubuntu SMP Fri Apr 7 11:05:26 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux |
| Build tool | maven |
| Personality | /testptch/hadoop/patchprocess/precommit/personality/provided.sh |
| git revision | trunk / 588c190 |
| Default Java | 1.8.0_144 |
| findbugs | v3.1.0-RC1 |
| javac | https://builds.apache.org/job/PreCommit-HADOOP-Build/13043/artifact/patchprocess/diff-compile-javac-root.txt |
| unit | https://builds.apache.org/job/PreCommit-HADOOP-Build/13043/artifact/patchprocess/patch-unit-root.txt |
|  Test Results | https://builds.apache.org/job/PreCommit-HADOOP-Build/13043/testReport/ |
| modules | C: hadoop-common-project/hadoop-common hadoop-common-project/hadoop-nfs hadoop-common-project/hadoop-kms hadoop-hdfs-project/hadoop-hdfs-client hadoop-hdfs-project/hadoop-hdfs hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core . U: . |
| Console output | https://builds.apache.org/job/PreCommit-HADOOP-Build/13043/console |
| Powered by | Apache Yetus 0.6.0-SNAPSHOT   http://yetus.apache.org |


This message was automatically generated.

","11/Oct/17 09:25;aajisaka;09: rebased","11/Oct/17 10:22;aajisaka;10: Removed the usage of org.mockito.internal.util.reflection.Whitebox from TestReencryption.java and TestReencryptionHandler.java.","11/Oct/17 12:25;hadoopqa;| (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 14s{color} | {color:blue} Docker mode activated. {color} |
|| || || || {color:brown} Prechecks {color} ||
| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  1s{color} | {color:green} The patch does not contain any @author tags. {color} |
| {color:green}+1{color} | {color:green} test4tests {color} | {color:green}  0m  0s{color} | {color:green} The patch appears to include 48 new or modified test files. {color} |
|| || || || {color:brown} trunk Compile Tests {color} ||
| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  0m 20s{color} | {color:blue} Maven dependency ordering for branch {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 15m 24s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 17m 15s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  2m 20s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green} 10m 47s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 24m 42s{color} | {color:green} branch has no errors when building and testing our client artifacts. {color} |
| {color:blue}0{color} | {color:blue} findbugs {color} | {color:blue}  0m  0s{color} | {color:blue} Skipped patched modules with no Java source: . {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  7m 26s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  5m 38s{color} | {color:green} trunk passed {color} |
|| || || || {color:brown} Patch Compile Tests {color} ||
| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  0m 20s{color} | {color:blue} Maven dependency ordering for patch {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 19m  8s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 12m 56s{color} | {color:green} the patch passed {color} |
| {color:red}-1{color} | {color:red} javac {color} | {color:red} 12m 56s{color} | {color:red} root generated 166 new + 1271 unchanged - 0 fixed = 1437 total (was 1271) {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  2m 19s{color} | {color:green} root: The patch generated 0 new + 969 unchanged - 1 fixed = 969 total (was 970) {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  9m  9s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} |
| {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 11m 25s{color} | {color:green} patch has no errors when building and testing our client artifacts. {color} |
| {color:blue}0{color} | {color:blue} findbugs {color} | {color:blue}  0m  0s{color} | {color:blue} Skipped patched modules with no Java source: . {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  7m 32s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  4m 52s{color} | {color:green} the patch passed {color} |
|| || || || {color:brown} Other Tests {color} ||
| {color:red}-1{color} | {color:red} unit {color} | {color:red} 14m 22s{color} | {color:red} root in the patch failed. {color} |
| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 35s{color} | {color:green} The patch does not generate ASF License warnings. {color} |
| {color:black}{color} | {color:black} {color} | {color:black}174m 15s{color} | {color:black} {color} |
\\
\\
|| Reason || Tests ||
| Failed junit tests | hadoop.security.TestRaceWhenRelogin |
|   | hadoop.security.TestKDiag |
|   | hadoop.net.TestDNS |
\\
\\
|| Subsystem || Report/Notes ||
| Docker |  Image:yetus/hadoop:3d04c00 |
| JIRA Issue | HADOOP-14188 |
| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12891446/HADOOP-14188.09.patch |
| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  shadedclient  findbugs  checkstyle  |
| uname | Linux d927b81aa5a1 3.13.0-117-generic #164-Ubuntu SMP Fri Apr 7 11:05:26 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux |
| Build tool | maven |
| Personality | /testptch/hadoop/patchprocess/precommit/personality/provided.sh |
| git revision | trunk / dc63a6a |
| Default Java | 1.8.0_144 |
| findbugs | v3.1.0-RC1 |
| javac | https://builds.apache.org/job/PreCommit-HADOOP-Build/13482/artifact/patchprocess/diff-compile-javac-root.txt |
| unit | https://builds.apache.org/job/PreCommit-HADOOP-Build/13482/artifact/patchprocess/patch-unit-root.txt |
|  Test Results | https://builds.apache.org/job/PreCommit-HADOOP-Build/13482/testReport/ |
| modules | C: hadoop-common-project/hadoop-common hadoop-common-project/hadoop-nfs hadoop-common-project/hadoop-kms hadoop-hdfs-project/hadoop-hdfs-client hadoop-hdfs-project/hadoop-hdfs hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core . U: . |
| Console output | https://builds.apache.org/job/PreCommit-HADOOP-Build/13482/console |
| Powered by | Apache Yetus 0.6.0-SNAPSHOT   http://yetus.apache.org |


This message was automatically generated.

","11/Oct/17 15:53;hadoopqa;| (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 12s{color} | {color:blue} Docker mode activated. {color} |
|| || || || {color:brown} Prechecks {color} ||
| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |
| {color:green}+1{color} | {color:green} test4tests {color} | {color:green}  0m  0s{color} | {color:green} The patch appears to include 50 new or modified test files. {color} |
|| || || || {color:brown} trunk Compile Tests {color} ||
| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  1m 27s{color} | {color:blue} Maven dependency ordering for branch {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 13m 35s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 15m 43s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  2m 15s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  9m 48s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 23m 19s{color} | {color:green} branch has no errors when building and testing our client artifacts. {color} |
| {color:blue}0{color} | {color:blue} findbugs {color} | {color:blue}  0m  0s{color} | {color:blue} Skipped patched modules with no Java source: . {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  6m 56s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  5m 19s{color} | {color:green} trunk passed {color} |
|| || || || {color:brown} Patch Compile Tests {color} ||
| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  0m 16s{color} | {color:blue} Maven dependency ordering for patch {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 17m 30s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 11m  4s{color} | {color:green} the patch passed {color} |
| {color:red}-1{color} | {color:red} javac {color} | {color:red} 11m  4s{color} | {color:red} root generated 180 new + 1271 unchanged - 0 fixed = 1451 total (was 1271) {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  2m 15s{color} | {color:green} root: The patch generated 0 new + 970 unchanged - 1 fixed = 970 total (was 971) {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  9m  7s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} |
| {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 11m 19s{color} | {color:green} patch has no errors when building and testing our client artifacts. {color} |
| {color:blue}0{color} | {color:blue} findbugs {color} | {color:blue}  0m  0s{color} | {color:blue} Skipped patched modules with no Java source: . {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  7m 47s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  5m 16s{color} | {color:green} the patch passed {color} |
|| || || || {color:brown} Other Tests {color} ||
| {color:red}-1{color} | {color:red} unit {color} | {color:red}167m 49s{color} | {color:red} root in the patch failed. {color} |
| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  1m 50s{color} | {color:green} The patch does not generate ASF License warnings. {color} |
| {color:black}{color} | {color:black} {color} | {color:black}321m 45s{color} | {color:black} {color} |
\\
\\
|| Reason || Tests ||
| Failed junit tests | hadoop.hdfs.server.datanode.TestDataNodeVolumeFailure |
|   | hadoop.hdfs.TestDFSStripedOutputStreamWithFailure070 |
|   | hadoop.hdfs.TestDFSStripedOutputStreamWithFailure010 |
|   | hadoop.hdfs.server.datanode.TestDataNodeVolumeFailureReporting |
|   | hadoop.hdfs.TestDFSStripedOutputStreamWithFailure060 |
|   | hadoop.hdfs.security.TestDelegationTokenForProxyUser |
|   | hadoop.hdfs.TestDFSStripedOutputStreamWithFailure100 |
|   | hadoop.yarn.server.nodemanager.scheduler.TestDistributedScheduler |
|   | hadoop.yarn.server.nodemanager.containermanager.scheduler.TestContainerSchedulerQueuing |
| Timed out junit tests | org.apache.hadoop.hdfs.TestLargeBlock |
|   | org.apache.hadoop.hdfs.TestParallelShortCircuitRead |
|   | org.apache.hadoop.hdfs.TestDFSStripedOutputStreamWithFailure |
|   | org.apache.hadoop.hdfs.TestHdfsAdmin |
|   | org.apache.hadoop.hdfs.tools.TestDFSAdminWithHA |
|   | org.apache.hadoop.hdfs.TestDFSStartupVersions |
|   | org.apache.hadoop.hdfs.tools.offlineEditsViewer.TestOfflineEditsViewer |
|   | org.apache.hadoop.hdfs.tools.offlineImageViewer.TestOfflineImageViewer |
|   | org.apache.hadoop.hdfs.TestDatanodeRegistration |
|   | org.apache.hadoop.hdfs.TestParallelRead |
|   | org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingCorruptData |
|   | org.apache.hadoop.hdfs.TestReadStripedFileWithDNFailure |
|   | org.apache.hadoop.hdfs.TestDFSStripedOutputStreamWithRandomECPolicy |
|   | org.apache.hadoop.hdfs.TestBlocksScheduledCounter |
|   | org.apache.hadoop.hdfs.TestErasureCodingPoliciesWithRandomECPolicy |
|   | org.apache.hadoop.hdfs.TestMultiThreadedHflush |
|   | org.apache.hadoop.hdfs.TestDFSStripedInputStreamWithRandomECPolicy |
|   | org.apache.hadoop.hdfs.TestReservedRawPaths |
|   | org.apache.hadoop.hdfs.TestClientProtocolForPipelineRecovery |
|   | org.apache.hadoop.hdfs.TestSetrepIncreasing |
|   | org.apache.hadoop.hdfs.tools.offlineImageViewer.TestOfflineImageViewerWithStripedBlocks |
|   | org.apache.hadoop.hdfs.TestDFSStripedOutputStreamWithFailure170 |
|   | org.apache.hadoop.hdfs.TestDFSStripedOutputStreamWithFailure160 |
|   | org.apache.hadoop.hdfs.TestAclsEndToEnd |
|   | org.apache.hadoop.hdfs.TestDFSStripedOutputStreamWithFailure150 |
|   | org.apache.hadoop.hdfs.TestReplication |
|   | org.apache.hadoop.hdfs.TestDataTransferKeepalive |
|   | org.apache.hadoop.hdfs.TestSafeModeWithStripedFile |
|   | org.apache.hadoop.hdfs.TestDatanodeDeath |
|   | org.apache.hadoop.hdfs.TestDFSStripedOutputStreamWithFailure120 |
|   | org.apache.hadoop.hdfs.TestFileLengthOnClusterRestart |
|   | org.apache.hadoop.hdfs.TestReconstructStripedFile |
|   | org.apache.hadoop.hdfs.TestFileAppend |
|   | org.apache.hadoop.hdfs.TestUnsetAndChangeDirectoryEcPolicy |
|   | org.apache.hadoop.hdfs.TestWriteReadStripedFile |
|   | org.apache.hadoop.hdfs.TestSafeMode |
|   | org.apache.hadoop.hdfs.util.TestStripedBlockUtil |
|   | org.apache.hadoop.hdfs.TestDFSClientRetries |
|   | org.apache.hadoop.hdfs.TestDFSStorageStateRecovery |
|   | org.apache.hadoop.hdfs.TestDFSFinalize |
|   | org.apache.hadoop.hdfs.TestFileAppend3 |
|   | org.apache.hadoop.hdfs.TestRead |
|   | org.apache.hadoop.hdfs.TestRollingUpgradeDowngrade |
|   | org.apache.hadoop.hdfs.TestHDFSFileSystemContract |
|   | org.apache.hadoop.hdfs.TestFileAppend2 |
|   | org.apache.hadoop.hdfs.TestDFSUpgradeFromImage |
|   | org.apache.hadoop.hdfs.TestDFSPermission |
|   | org.apache.hadoop.hdfs.TestDFSInotifyEventInputStream |
|   | org.apache.hadoop.hdfs.TestDatanodeStartupFixesLegacyStorageIDs |
|   | org.apache.hadoop.hdfs.TestSecureEncryptionZoneWithKMS |
|   | org.apache.hadoop.hdfs.TestReadWhileWriting |
|   | org.apache.hadoop.hdfs.TestFileAppendRestart |
|   | org.apache.hadoop.hdfs.TestErasureCodingPolicies |
|   | org.apache.hadoop.hdfs.TestDFSStripedOutputStream |
|   | org.apache.hadoop.hdfs.TestWriteConfigurationToDFS |
|   | org.apache.hadoop.hdfs.TestCrcCorruption |
|   | org.apache.hadoop.hdfs.TestApplyingStoragePolicy |
|   | org.apache.hadoop.hdfs.TestEncryptionZonesWithKMS |
|   | org.apache.hadoop.hdfs.protocol.datatransfer.sasl.TestSaslDataTransfer |
|   | org.apache.hadoop.hdfs.TestBlockStoragePolicy |
|   | org.apache.hadoop.hdfs.tools.offlineImageViewer.TestOfflineImageViewerForAcl |
|   | org.apache.hadoop.hdfs.tools.TestWebHDFSStoragePolicyCommands |
|   | org.apache.hadoop.hdfs.TestSeekBug |
|   | org.apache.hadoop.tracing.TestTracing |
|   | org.apache.hadoop.hdfs.tools.TestViewFSStoragePolicyCommands |
|   | org.apache.hadoop.hdfs.TestHDFSServerPorts |
|   | org.apache.hadoop.hdfs.TestDatanodeReport |
|   | org.apache.hadoop.hdfs.tools.TestStoragePolicyCommands |
|   | org.apache.hadoop.hdfs.tools.TestDFSHAAdminMiniCluster |
|   | org.apache.hadoop.hdfs.TestReadStripedFileWithMissingBlocks |
|   | org.apache.hadoop.hdfs.TestRollingUpgradeRollback |
|   | org.apache.hadoop.hdfs.TestDataStream |
|   | org.apache.hadoop.hdfs.TestMissingBlocksAlert |
|   | org.apache.hadoop.hdfs.TestDFSStripedOutputStreamWithFailure090 |
|   | org.apache.hadoop.hdfs.TestDFSStripedOutputStreamWithFailure080 |
|   | org.apache.hadoop.hdfs.shortcircuit.TestShortCircuitCache |
|   | org.apache.hadoop.hdfs.crypto.TestHdfsCryptoStreams |
|   | org.apache.hadoop.hdfs.TestFileConcurrentReader |
|   | org.apache.hadoop.hdfs.TestExtendedAcls |
|   | org.apache.hadoop.hdfs.TestDFSStripedOutputStreamWithFailure040 |
|   | org.apache.hadoop.hdfs.shortcircuit.TestShortCircuitLocalRead |
|   | org.apache.hadoop.hdfs.TestExternalBlockReader |
|   | org.apache.hadoop.hdfs.TestDFSClientSocketSize |
|   | org.apache.hadoop.hdfs.TestDFSStripedOutputStreamWithFailure210 |
|   | org.apache.hadoop.hdfs.TestDFSStripedOutputStreamWithFailure030 |
|   | org.apache.hadoop.hdfs.TestSnapshotCommands |
|   | org.apache.hadoop.hdfs.TestDFSStripedOutputStreamWithFailure200 |
|   | org.apache.hadoop.hdfs.TestTrashWithSecureEncryptionZones |
|   | org.apache.hadoop.hdfs.tools.offlineImageViewer.TestOfflineImageViewerForContentSummary |
|   | org.apache.hadoop.hdfs.TestDFSRollback |
|   | org.apache.hadoop.hdfs.TestMiniDFSCluster |
|   | org.apache.hadoop.hdfs.TestDFSStripedOutputStreamWithFailure000 |
|   | org.apache.hadoop.hdfs.TestDistributedFileSystem |
|   | org.apache.hadoop.hdfs.tools.TestDFSZKFailoverController |
|   | org.apache.hadoop.hdfs.TestReadStripedFileWithDecodingDeletedData |
|   | org.apache.hadoop.hdfs.TestHFlush |
|   | org.apache.hadoop.hdfs.TestDFSClientExcludedNodes |
|   | org.apache.hadoop.hdfs.TestEncryptedTransfer |
|   | org.apache.hadoop.hdfs.TestTrashWithEncryptionZones |
|   | org.apache.hadoop.hdfs.TestReplaceDatanodeFailureReplication |
|   | org.apache.hadoop.hdfs.TestPersistBlocks |
|   | org.apache.hadoop.hdfs.tools.TestDebugAdmin |
|   | org.apache.hadoop.hdfs.TestGetBlocks |
|   | org.apache.hadoop.hdfs.TestDFSStripedOutputStreamWithFailureWithRandomECPolicy |
|   | org.apache.hadoop.hdfs.TestDFSRename |
|   | org.apache.hadoop.hdfs.tools.TestDFSAdmin |
|   | org.apache.hadoop.tracing.TestTraceAdmin |
|   | org.apache.hadoop.hdfs.TestParallelUnixDomainRead |
|   | org.apache.hadoop.hdfs.TestErasureCodingPolicyWithSnapshotWithRandomECPolicy |
\\
\\
|| Subsystem || Report/Notes ||
| Docker |  Image:yetus/hadoop:3d04c00 |
| JIRA Issue | HADOOP-14188 |
| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12891453/HADOOP-14188.10.patch |
| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  shadedclient  findbugs  checkstyle  |
| uname | Linux ffbeebdcfd1e 3.13.0-129-generic #178-Ubuntu SMP Fri Aug 11 12:48:20 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux |
| Build tool | maven |
| Personality | /testptch/hadoop/patchprocess/precommit/personality/provided.sh |
| git revision | trunk / dc63a6a |
| Default Java | 1.8.0_144 |
| findbugs | v3.1.0-RC1 |
| javac | https://builds.apache.org/job/PreCommit-HADOOP-Build/13483/artifact/patchprocess/diff-compile-javac-root.txt |
| unit | https://builds.apache.org/job/PreCommit-HADOOP-Build/13483/artifact/patchprocess/patch-unit-root.txt |
|  Test Results | https://builds.apache.org/job/PreCommit-HADOOP-Build/13483/testReport/ |
| modules | C: hadoop-common-project/hadoop-common hadoop-common-project/hadoop-nfs hadoop-common-project/hadoop-kms hadoop-hdfs-project/hadoop-hdfs-client hadoop-hdfs-project/hadoop-hdfs hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core . U: . |
| Console output | https://builds.apache.org/job/PreCommit-HADOOP-Build/13483/console |
| Powered by | Apache Yetus 0.6.0-SNAPSHOT   http://yetus.apache.org |


This message was automatically generated.

","25/Apr/18 13:33;ehiggs;Attaching 11 patch which rebases 10 onto current trunk HEAD (626690612cd0957316628376744a8be62f891665)","25/Apr/18 19:48;genericqa;| (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 23s{color} | {color:blue} Docker mode activated. {color} |
|| || || || {color:brown} Prechecks {color} ||
| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |
| {color:green}+1{color} | {color:green} test4tests {color} | {color:green}  0m  0s{color} | {color:green} The patch appears to include 50 new or modified test files. {color} |
|| || || || {color:brown} trunk Compile Tests {color} ||
| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  0m 19s{color} | {color:blue} Maven dependency ordering for branch {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 24m 43s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 29m  9s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  3m 21s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  5m  3s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 18m 51s{color} | {color:green} branch has no errors when building and testing our client artifacts. {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  7m 48s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  3m 50s{color} | {color:green} trunk passed {color} |
|| || || || {color:brown} Patch Compile Tests {color} ||
| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  0m 30s{color} | {color:blue} Maven dependency ordering for patch {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  4m  6s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 28m 24s{color} | {color:green} the patch passed {color} |
| {color:red}-1{color} | {color:red} javac {color} | {color:red} 28m 24s{color} | {color:red} root generated 180 new + 1276 unchanged - 0 fixed = 1456 total (was 1276) {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  3m 21s{color} | {color:green} root: The patch generated 0 new + 956 unchanged - 1 fixed = 956 total (was 957) {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  4m 46s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} |
| {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 10m 41s{color} | {color:green} patch has no errors when building and testing our client artifacts. {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  8m 37s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  3m 41s{color} | {color:green} the patch passed {color} |
|| || || || {color:brown} Other Tests {color} ||
| {color:green}+1{color} | {color:green} unit {color} | {color:green}  9m 37s{color} | {color:green} hadoop-common in the patch passed. {color} |
| {color:green}+1{color} | {color:green} unit {color} | {color:green}  0m 39s{color} | {color:green} hadoop-nfs in the patch passed. {color} |
| {color:green}+1{color} | {color:green} unit {color} | {color:green}  3m 43s{color} | {color:green} hadoop-kms in the patch passed. {color} |
| {color:green}+1{color} | {color:green} unit {color} | {color:green}  1m 41s{color} | {color:green} hadoop-hdfs-client in the patch passed. {color} |
| {color:red}-1{color} | {color:red} unit {color} | {color:red} 99m 50s{color} | {color:red} hadoop-hdfs in the patch failed. {color} |
| {color:green}+1{color} | {color:green} unit {color} | {color:green}  3m 59s{color} | {color:green} hadoop-mapreduce-client-core in the patch passed. {color} |
| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 38s{color} | {color:green} The patch does not generate ASF License warnings. {color} |
| {color:black}{color} | {color:black} {color} | {color:black}272m 21s{color} | {color:black} {color} |
\\
\\
|| Reason || Tests ||
| Failed junit tests | hadoop.hdfs.TestRollingUpgrade |
\\
\\
|| Subsystem || Report/Notes ||
| Docker | Client=17.05.0-ce Server=17.05.0-ce Image:yetus/hadoop:b78c94f |
| JIRA Issue | HADOOP-14188 |
| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12920619/HADOOP-14188.11.patch |
| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  shadedclient  findbugs  checkstyle  |
| uname | Linux d9bd4ed32843 3.13.0-137-generic #186-Ubuntu SMP Mon Dec 4 19:09:19 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux |
| Build tool | maven |
| Personality | /testptch/patchprocess/precommit/personality/provided.sh |
| git revision | trunk / 6266906 |
| maven | version: Apache Maven 3.3.9 |
| Default Java | 1.8.0_162 |
| findbugs | v3.1.0-RC1 |
| javac | https://builds.apache.org/job/PreCommit-HADOOP-Build/14521/artifact/out/diff-compile-javac-root.txt |
| unit | https://builds.apache.org/job/PreCommit-HADOOP-Build/14521/artifact/out/patch-unit-hadoop-hdfs-project_hadoop-hdfs.txt |
|  Test Results | https://builds.apache.org/job/PreCommit-HADOOP-Build/14521/testReport/ |
| Max. process+thread count | 2652 (vs. ulimit of 10000) |
| modules | C: hadoop-common-project/hadoop-common hadoop-common-project/hadoop-nfs hadoop-common-project/hadoop-kms hadoop-hdfs-project/hadoop-hdfs-client hadoop-hdfs-project/hadoop-hdfs hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core U: . |
| Console output | https://builds.apache.org/job/PreCommit-HADOOP-Build/14521/console |
| Powered by | Apache Yetus 0.8.0-SNAPSHOT   http://yetus.apache.org |


This message was automatically generated.

","26/Apr/18 02:27;aajisaka;Thank you for rebasing, [~ehiggs]. Would you replace the usages in the following classes as well? I'm +1 if that is addressed.
{noformat}
$ find . -name ""*.java"" | xargs grep ""import org.mockito.internal.util.reflection.Whitebox;""
./hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager/src/test/java/org/apache/hadoop/yarn/server/nodemanager/containermanager/launcher/TestContainersLauncher.java:import org.mockito.internal.util.reflection.Whitebox;
./hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/hdfs/server/federation/FederationTestUtils.java:import org.mockito.internal.util.reflection.Whitebox;
./hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/hdfs/server/federation/router/TestRouterRPCClientRetries.java:import org.mockito.internal.util.reflection.Whitebox;
./hadoop-ozone/integration-test/src/test/java/org/apache/hadoop/ozone/ksm/TestKSMMetrcis.java:import org.mockito.internal.util.reflection.Whitebox;
{noformat}","26/Apr/18 07:25;ehiggs;Removing references to mockito whitebox in the files [~ajisakaa] mentioned. Good catch!","26/Apr/18 12:39;genericqa;| (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 22s{color} | {color:blue} Docker mode activated. {color} |
|| || || || {color:brown} Prechecks {color} ||
| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |
| {color:green}+1{color} | {color:green} test4tests {color} | {color:green}  0m  0s{color} | {color:green} The patch appears to include 54 new or modified test files. {color} |
|| || || || {color:brown} trunk Compile Tests {color} ||
| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  0m 17s{color} | {color:blue} Maven dependency ordering for branch {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 24m 40s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 27m 47s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  3m 20s{color} | {color:green} trunk passed {color} |
| {color:red}-1{color} | {color:red} mvnsite {color} | {color:red}  0m 35s{color} | {color:red} integration-test in trunk failed. {color} |
| {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 20m 46s{color} | {color:green} branch has no errors when building and testing our client artifacts. {color} |
| {color:blue}0{color} | {color:blue} findbugs {color} | {color:blue}  0m  0s{color} | {color:blue} Skipped patched modules with no Java source: hadoop-ozone/integration-test {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  9m  3s{color} | {color:green} trunk passed {color} |
| {color:red}-1{color} | {color:red} javadoc {color} | {color:red}  0m 20s{color} | {color:red} integration-test in trunk failed. {color} |
|| || || || {color:brown} Patch Compile Tests {color} ||
| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  0m 18s{color} | {color:blue} Maven dependency ordering for patch {color} |
| {color:red}-1{color} | {color:red} mvninstall {color} | {color:red}  0m 10s{color} | {color:red} integration-test in the patch failed. {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 27m  6s{color} | {color:green} the patch passed {color} |
| {color:red}-1{color} | {color:red} javac {color} | {color:red} 27m  6s{color} | {color:red} root generated 193 new + 1276 unchanged - 0 fixed = 1469 total (was 1276) {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  3m 21s{color} | {color:green} root: The patch generated 0 new + 956 unchanged - 1 fixed = 956 total (was 957) {color} |
| {color:red}-1{color} | {color:red} mvnsite {color} | {color:red}  0m 21s{color} | {color:red} integration-test in the patch failed. {color} |
| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} |
| {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 10m 18s{color} | {color:green} patch has no errors when building and testing our client artifacts. {color} |
| {color:blue}0{color} | {color:blue} findbugs {color} | {color:blue}  0m  0s{color} | {color:blue} Skipped patched modules with no Java source: hadoop-ozone/integration-test {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  9m 58s{color} | {color:green} the patch passed {color} |
| {color:red}-1{color} | {color:red} javadoc {color} | {color:red}  0m 20s{color} | {color:red} integration-test in the patch failed. {color} |
|| || || || {color:brown} Other Tests {color} ||
| {color:green}+1{color} | {color:green} unit {color} | {color:green}  8m 46s{color} | {color:green} hadoop-common in the patch passed. {color} |
| {color:green}+1{color} | {color:green} unit {color} | {color:green}  0m 39s{color} | {color:green} hadoop-nfs in the patch passed. {color} |
| {color:green}+1{color} | {color:green} unit {color} | {color:green}  3m 33s{color} | {color:green} hadoop-kms in the patch passed. {color} |
| {color:green}+1{color} | {color:green} unit {color} | {color:green}  1m 35s{color} | {color:green} hadoop-hdfs-client in the patch passed. {color} |
| {color:red}-1{color} | {color:red} unit {color} | {color:red} 97m 36s{color} | {color:red} hadoop-hdfs in the patch failed. {color} |
| {color:green}+1{color} | {color:green} unit {color} | {color:green} 14m  6s{color} | {color:green} hadoop-hdfs-rbf in the patch passed. {color} |
| {color:red}-1{color} | {color:red} unit {color} | {color:red} 18m 50s{color} | {color:red} hadoop-yarn-server-nodemanager in the patch failed. {color} |
| {color:green}+1{color} | {color:green} unit {color} | {color:green}  3m 52s{color} | {color:green} hadoop-mapreduce-client-core in the patch passed. {color} |
| {color:red}-1{color} | {color:red} unit {color} | {color:red}  0m 22s{color} | {color:red} integration-test in the patch failed. {color} |
| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 37s{color} | {color:green} The patch does not generate ASF License warnings. {color} |
| {color:black}{color} | {color:black} {color} | {color:black}308m 24s{color} | {color:black} {color} |
\\
\\
|| Reason || Tests ||
| Failed junit tests | hadoop.hdfs.TestDFSStripedOutputStreamWithFailureWithRandomECPolicy |
|   | hadoop.hdfs.server.namenode.TestNameNodeMetadataConsistency |
|   | hadoop.hdfs.TestDFSClientRetries |
|   | hadoop.hdfs.TestReconstructStripedFile |
|   | hadoop.yarn.server.nodemanager.containermanager.scheduler.TestContainerSchedulerQueuing |
\\
\\
|| Subsystem || Report/Notes ||
| Docker | Client=17.05.0-ce Server=17.05.0-ce Image:yetus/hadoop:b78c94f |
| JIRA Issue | HADOOP-14188 |
| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12920741/HADOOP-14188.12.patch |
| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  shadedclient  findbugs  checkstyle  |
| uname | Linux 61dc99e1bdc5 3.13.0-137-generic #186-Ubuntu SMP Mon Dec 4 19:09:19 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux |
| Build tool | maven |
| Personality | /testptch/patchprocess/precommit/personality/provided.sh |
| git revision | trunk / af986b4 |
| maven | version: Apache Maven 3.3.9 |
| Default Java | 1.8.0_162 |
| mvnsite | https://builds.apache.org/job/PreCommit-HADOOP-Build/14527/artifact/out/branch-mvnsite-hadoop-ozone_integration-test.txt |
| findbugs | v3.1.0-RC1 |
| javadoc | https://builds.apache.org/job/PreCommit-HADOOP-Build/14527/artifact/out/branch-javadoc-hadoop-ozone_integration-test.txt |
| mvninstall | https://builds.apache.org/job/PreCommit-HADOOP-Build/14527/artifact/out/patch-mvninstall-hadoop-ozone_integration-test.txt |
| javac | https://builds.apache.org/job/PreCommit-HADOOP-Build/14527/artifact/out/diff-compile-javac-root.txt |
| mvnsite | https://builds.apache.org/job/PreCommit-HADOOP-Build/14527/artifact/out/patch-mvnsite-hadoop-ozone_integration-test.txt |
| javadoc | https://builds.apache.org/job/PreCommit-HADOOP-Build/14527/artifact/out/patch-javadoc-hadoop-ozone_integration-test.txt |
| unit | https://builds.apache.org/job/PreCommit-HADOOP-Build/14527/artifact/out/patch-unit-hadoop-hdfs-project_hadoop-hdfs.txt |
| unit | https://builds.apache.org/job/PreCommit-HADOOP-Build/14527/artifact/out/patch-unit-hadoop-yarn-project_hadoop-yarn_hadoop-yarn-server_hadoop-yarn-server-nodemanager.txt |
| unit | https://builds.apache.org/job/PreCommit-HADOOP-Build/14527/artifact/out/patch-unit-hadoop-ozone_integration-test.txt |
|  Test Results | https://builds.apache.org/job/PreCommit-HADOOP-Build/14527/testReport/ |
| Max. process+thread count | 2650 (vs. ulimit of 10000) |
| modules | C: hadoop-common-project/hadoop-common hadoop-common-project/hadoop-nfs hadoop-common-project/hadoop-kms hadoop-hdfs-project/hadoop-hdfs-client hadoop-hdfs-project/hadoop-hdfs hadoop-hdfs-project/hadoop-hdfs-rbf hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core hadoop-ozone/integration-test U: . |
| Console output | https://builds.apache.org/job/PreCommit-HADOOP-Build/14527/console |
| Powered by | Apache Yetus 0.8.0-SNAPSHOT   http://yetus.apache.org |


This message was automatically generated.

","27/Apr/18 10:24;aajisaka;+1, the test failures are not related to the patch. Committing this.","27/Apr/18 10:25;aajisaka;Committed this to trunk. Thanks [~ehiggs]!","27/Apr/18 10:44;hudson;SUCCESS: Integrated in Jenkins build Hadoop-trunk-Commit #14078 (See [https://builds.apache.org/job/Hadoop-trunk-Commit/14078/])
HADOOP-14188. Remove the usage of (aajisaka: rev 84ecfe3cebe32ae048eae4b1bf02f6cdfd1fafe9)
* (edit) hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/blockmanagement/TestPendingInvalidateBlock.java
* (edit) hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/DFSTestUtil.java
* (edit) hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/web/TestWebHdfsTokens.java
* (edit) hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/ha/TestHASafeMode.java
* (edit) hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestDFSOutputStream.java
* (edit) hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/crypto/TestCryptoStreamsWithOpensslAesCtrCryptoCodec.java
* (edit) hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestCommitBlockSynchronization.java
* (edit) hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/blockmanagement/TestBlockInfoStriped.java
* (edit) hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/TestLocalFileSystem.java
* (edit) hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/ha/TestBootstrapStandbyWithQJM.java
* (add) hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/test/Whitebox.java
* (edit) hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestSaveNamespace.java
* (edit) hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/metrics2/impl/TestStatsDMetrics.java
* (edit) hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/ipc/TestIPC.java
* (edit) hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/web/TestWebHDFS.java
* (edit) hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestReencryptionHandler.java
* (edit) hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestFSNamesystem.java
* (edit) hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/blockmanagement/TestBlockManagerSafeMode.java
* (edit) hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/blockmanagement/TestDatanodeManager.java
* (edit) hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestAddStripedBlockInFBR.java
* (edit) hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestDeleteRace.java
* (edit) hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/snapshot/TestFileWithSnapshotFeature.java
* (edit) hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/web/TestWebHDFSForHA.java
* (edit) hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/blockmanagement/TestComputeInvalidateWork.java
* (edit) hadoop-common-project/hadoop-kms/src/test/java/org/apache/hadoop/crypto/key/kms/server/TestKMS.java
* (edit) hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/blockmanagement/TestSequentialBlockGroupId.java
* (edit) hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/blockmanagement/TestReconstructStripedBlocksWithRackAwareness.java
* (edit) hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/ha/TestDFSUpgradeWithHA.java
* (edit) hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/http/TestHttpServer.java
* (edit) hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/snapshot/TestRenameWithSnapshots.java
* (edit) hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestReencryption.java
* (edit) hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestEncryptionZonesWithKMS.java
* (edit) hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/balancer/TestKeyManager.java
* (edit) hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/blockmanagement/TestHostFileManager.java
* (edit) hadoop-common-project/hadoop-nfs/src/test/java/org/apache/hadoop/portmap/TestPortmap.java
* (edit) hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager/src/test/java/org/apache/hadoop/yarn/server/nodemanager/containermanager/launcher/TestContainersLauncher.java
* (edit) hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/datanode/TestBlockPoolManager.java
* (edit) hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockManagerTestUtil.java
* (edit) hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/metrics2/impl/TestGraphiteMetrics.java
* (edit) hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/test/java/org/apache/hadoop/mapreduce/task/reduce/TestMergeManager.java
* (edit) hadoop-ozone/integration-test/src/test/java/org/apache/hadoop/ozone/ksm/TestKSMMetrcis.java
* (edit) hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/ipc/TestRPC.java
* (edit) hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/hdfs/server/federation/router/TestRouterRPCClientRetries.java
* (edit) hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/ha/TestDelegationTokensWithHA.java
* (edit) hadoop-hdfs-project/hadoop-hdfs-rbf/src/test/java/org/apache/hadoop/hdfs/server/federation/FederationTestUtils.java
* (edit) hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/TestTruncateQuotaUpdate.java
* (edit) hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestDistributedFileSystem.java
* (edit) hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/security/TestDelegationTokenForProxyUser.java
* (edit) hadoop-common-project/hadoop-kms/src/test/java/org/apache/hadoop/crypto/key/kms/server/TestKMSAudit.java
* (edit) hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestLeaseRecoveryStriped.java
* (edit) hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/blockmanagement/TestUnderReplicatedBlocks.java
* (edit) hadoop-hdfs-project/hadoop-hdfs-client/src/test/java/org/apache/hadoop/hdfs/web/TestByteRangeInputStream.java
* (edit) hadoop-hdfs-project/hadoop-hdfs-client/src/test/java/org/apache/hadoop/hdfs/web/TestTokenAspect.java
* (edit) hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/server/namenode/NameNodeAdapter.java
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Upgrade JUnit 3 test cases to JUnit 4,HADOOP-14729,13092126,Test,Resolved,HADOOP,Hadoop Common,software,omalley,Hadoop Common is the common library for Apache Hadoop.,http://hadoop.apache.org/,Major,Fixed,ajayydv,aajisaka,aajisaka,03/Aug/17 08:49,14/Jan/19 19:57,12/Jan/21 11:55,25/Aug/17 16:57,,,,,3.0.0-beta1,,,,,,,,,,0,newbie,,There are still test classes that extend from junit.framework.TestCase in hadoop-common. Upgrade them to JUnit4.,,aajisaka,ajayydv,arp,boky01,hudson,stevel@apache.org,,,,,,,,,,,,,,,,,,,,,,,,,,,,HADOOP-14693,,,,,,,,,,,,,,,,,MAPREDUCE-6050,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,MAPREDUCE-6667,,,,,,,,"10/Aug/17 04:47;ajayydv;HADOOP-14729.001.patch;https://issues.apache.org/jira/secure/attachment/12881135/HADOOP-14729.001.patch","10/Aug/17 19:01;ajayydv;HADOOP-14729.002.patch;https://issues.apache.org/jira/secure/attachment/12881301/HADOOP-14729.002.patch","12/Aug/17 04:58;ajayydv;HADOOP-14729.003.patch;https://issues.apache.org/jira/secure/attachment/12881597/HADOOP-14729.003.patch","12/Aug/17 05:56;ajayydv;HADOOP-14729.004.patch;https://issues.apache.org/jira/secure/attachment/12881600/HADOOP-14729.004.patch","12/Aug/17 06:04;ajayydv;HADOOP-14729.005.patch;https://issues.apache.org/jira/secure/attachment/12881601/HADOOP-14729.005.patch","13/Aug/17 01:00;ajayydv;HADOOP-14729.006.patch;https://issues.apache.org/jira/secure/attachment/12881637/HADOOP-14729.006.patch","16/Aug/17 23:37;ajayydv;HADOOP-14729.007.patch;https://issues.apache.org/jira/secure/attachment/12882229/HADOOP-14729.007.patch","21/Aug/17 17:53;ajayydv;HADOOP-14729.008.patch;https://issues.apache.org/jira/secure/attachment/12882924/HADOOP-14729.008.patch","21/Aug/17 20:37;ajayydv;HADOOP-14729.009.patch;https://issues.apache.org/jira/secure/attachment/12882971/HADOOP-14729.009.patch","22/Aug/17 18:34;ajayydv;HADOOP-14729.010.patch;https://issues.apache.org/jira/secure/attachment/12883161/HADOOP-14729.010.patch","23/Aug/17 19:05;ajayydv;HADOOP-14729.011.patch;https://issues.apache.org/jira/secure/attachment/12883387/HADOOP-14729.011.patch","23/Aug/17 19:43;ajayydv;HADOOP-14729.012.patch;https://issues.apache.org/jira/secure/attachment/12883393/HADOOP-14729.012.patch",,,,,,,,,,,,12.0,,,,,,,,,,,,,,,,,,,,2017-08-10 05:36:53.194,,,false,,,,,,,,,,,,,,,,,9223372036854775807,Reviewed,,,,Tue Sep 26 00:24:01 UTC 2017,,,,,,,"0|i3id4f:",9223372036854775807,,,,,,,,,,,,,3.0.0-beta1,,,,,,,,,,"03/Aug/17 08:53;aajisaka;There are 35 occurrences in hadoop-common-project.
{noformat}
$ find hadoop-common-project/ -name ""*.java"" | xargs grep ""junit.framework"" | wc -l
      35
{noformat}","03/Aug/17 08:55;aajisaka;There are only 1 occurrence in hadoop-hdfs-project and only 4 occurrences in hadoop-yarn-project, so we can fix them in this issue as well.","10/Aug/17 05:36;boky01;[~ajayydv],

It will not compile because {{TestMapFileOutputFormat}} (and some other classes) miss(es) the import of After annotation.
In addition, in your 2nd patch please use two spaces for indentation instead of tab.","10/Aug/17 09:48;hadoopqa;| (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 14s{color} | {color:blue} Docker mode activated. {color} |
|| || || || {color:brown} Prechecks {color} ||
| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |
| {color:green}+1{color} | {color:green} test4tests {color} | {color:green}  0m  0s{color} | {color:green} The patch appears to include 106 new or modified test files. {color} |
|| || || || {color:brown} trunk Compile Tests {color} ||
| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  1m 22s{color} | {color:blue} Maven dependency ordering for branch {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 13m 45s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 13m 58s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  2m 19s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green} 12m 34s{color} | {color:green} trunk passed {color} |
| {color:red}-1{color} | {color:red} findbugs {color} | {color:red}  1m 51s{color} | {color:red} hadoop-hdfs-project/hadoop-hdfs in trunk has 9 extant Findbugs warnings. {color} |
| {color:red}-1{color} | {color:red} findbugs {color} | {color:red}  0m 53s{color} | {color:red} hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager in trunk has 1 extant Findbugs warnings. {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  9m 34s{color} | {color:green} trunk passed {color} |
|| || || || {color:brown} Patch Compile Tests {color} ||
| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  0m 19s{color} | {color:blue} Maven dependency ordering for patch {color} |
| {color:red}-1{color} | {color:red} mvninstall {color} | {color:red}  0m 54s{color} | {color:red} hadoop-hdfs in the patch failed. {color} |
| {color:red}-1{color} | {color:red} mvninstall {color} | {color:red}  0m 29s{color} | {color:red} hadoop-yarn-server-nodemanager in the patch failed. {color} |
| {color:red}-1{color} | {color:red} mvninstall {color} | {color:red}  0m 20s{color} | {color:red} hadoop-yarn-server-applicationhistoryservice in the patch failed. {color} |
| {color:red}-1{color} | {color:red} mvninstall {color} | {color:red}  0m 39s{color} | {color:red} hadoop-yarn-server-resourcemanager in the patch failed. {color} |
| {color:red}-1{color} | {color:red} mvninstall {color} | {color:red}  0m 21s{color} | {color:red} hadoop-yarn-server-router in the patch failed. {color} |
| {color:red}-1{color} | {color:red} mvninstall {color} | {color:red}  0m 28s{color} | {color:red} hadoop-mapreduce-client-core in the patch failed. {color} |
| {color:red}-1{color} | {color:red} mvninstall {color} | {color:red}  0m 25s{color} | {color:red} hadoop-mapreduce-client-common in the patch failed. {color} |
| {color:red}-1{color} | {color:red} mvninstall {color} | {color:red}  0m 18s{color} | {color:red} hadoop-mapreduce-client-nativetask in the patch failed. {color} |
| {color:red}-1{color} | {color:red} mvninstall {color} | {color:red}  0m 20s{color} | {color:red} hadoop-mapreduce-examples in the patch failed. {color} |
| {color:red}-1{color} | {color:red} compile {color} | {color:red}  2m 35s{color} | {color:red} root in the patch failed. {color} |
| {color:red}-1{color} | {color:red} javac {color} | {color:red}  2m 35s{color} | {color:red} root in the patch failed. {color} |
| {color:orange}-0{color} | {color:orange} checkstyle {color} | {color:orange}  2m 23s{color} | {color:orange} root: The patch generated 519 new + 1663 unchanged - 38 fixed = 2182 total (was 1701) {color} |
| {color:red}-1{color} | {color:red} mvnsite {color} | {color:red}  0m 55s{color} | {color:red} hadoop-hdfs in the patch failed. {color} |
| {color:red}-1{color} | {color:red} mvnsite {color} | {color:red}  0m 34s{color} | {color:red} hadoop-yarn-server-nodemanager in the patch failed. {color} |
| {color:red}-1{color} | {color:red} mvnsite {color} | {color:red}  0m 25s{color} | {color:red} hadoop-yarn-server-applicationhistoryservice in the patch failed. {color} |
| {color:red}-1{color} | {color:red} mvnsite {color} | {color:red}  0m 40s{color} | {color:red} hadoop-yarn-server-resourcemanager in the patch failed. {color} |
| {color:red}-1{color} | {color:red} mvnsite {color} | {color:red}  0m 22s{color} | {color:red} hadoop-yarn-server-router in the patch failed. {color} |
| {color:red}-1{color} | {color:red} mvnsite {color} | {color:red}  0m 31s{color} | {color:red} hadoop-mapreduce-client-core in the patch failed. {color} |
| {color:red}-1{color} | {color:red} mvnsite {color} | {color:red}  0m 23s{color} | {color:red} hadoop-mapreduce-client-common in the patch failed. {color} |
| {color:red}-1{color} | {color:red} mvnsite {color} | {color:red}  0m 25s{color} | {color:red} hadoop-mapreduce-client-nativetask in the patch failed. {color} |
| {color:red}-1{color} | {color:red} mvnsite {color} | {color:red}  0m 20s{color} | {color:red} hadoop-mapreduce-examples in the patch failed. {color} |
| {color:red}-1{color} | {color:red} whitespace {color} | {color:red}  0m  0s{color} | {color:red} The patch 517 line(s) with tabs. {color} |
| {color:red}-1{color} | {color:red} findbugs {color} | {color:red}  0m 32s{color} | {color:red} hadoop-hdfs in the patch failed. {color} |
| {color:red}-1{color} | {color:red} findbugs {color} | {color:red}  0m 23s{color} | {color:red} hadoop-yarn-server-nodemanager in the patch failed. {color} |
| {color:red}-1{color} | {color:red} findbugs {color} | {color:red}  0m 20s{color} | {color:red} hadoop-yarn-server-applicationhistoryservice in the patch failed. {color} |
| {color:red}-1{color} | {color:red} findbugs {color} | {color:red}  0m 29s{color} | {color:red} hadoop-yarn-server-resourcemanager in the patch failed. {color} |
| {color:red}-1{color} | {color:red} findbugs {color} | {color:red}  0m 21s{color} | {color:red} hadoop-yarn-server-router in the patch failed. {color} |
| {color:red}-1{color} | {color:red} findbugs {color} | {color:red}  0m 22s{color} | {color:red} hadoop-mapreduce-client-core in the patch failed. {color} |
| {color:red}-1{color} | {color:red} findbugs {color} | {color:red}  0m 19s{color} | {color:red} hadoop-mapreduce-client-common in the patch failed. {color} |
| {color:red}-1{color} | {color:red} findbugs {color} | {color:red}  0m 19s{color} | {color:red} hadoop-mapreduce-client-nativetask in the patch failed. {color} |
| {color:red}-1{color} | {color:red} findbugs {color} | {color:red}  0m 19s{color} | {color:red} hadoop-mapreduce-examples in the patch failed. {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  7m 46s{color} | {color:green} the patch passed {color} |
|| || || || {color:brown} Other Tests {color} ||
| {color:green}+1{color} | {color:green} unit {color} | {color:green}  2m 51s{color} | {color:green} hadoop-auth in the patch passed. {color} |
| {color:red}-1{color} | {color:red} unit {color} | {color:red} 18m 19s{color} | {color:red} hadoop-common in the patch failed. {color} |
| {color:red}-1{color} | {color:red} unit {color} | {color:red}  0m 30s{color} | {color:red} hadoop-kms in the patch failed. {color} |
| {color:red}-1{color} | {color:red} unit {color} | {color:red}  0m 49s{color} | {color:red} hadoop-hdfs in the patch failed. {color} |
| {color:red}-1{color} | {color:red} unit {color} | {color:red}  0m 45s{color} | {color:red} hadoop-yarn-server-nodemanager in the patch failed. {color} |
| {color:red}-1{color} | {color:red} unit {color} | {color:red}  0m 29s{color} | {color:red} hadoop-yarn-server-web-proxy in the patch failed. {color} |
| {color:red}-1{color} | {color:red} unit {color} | {color:red}  0m 24s{color} | {color:red} hadoop-yarn-server-applicationhistoryservice in the patch failed. {color} |
| {color:red}-1{color} | {color:red} unit {color} | {color:red}  0m 36s{color} | {color:red} hadoop-yarn-server-resourcemanager in the patch failed. {color} |
| {color:red}-1{color} | {color:red} unit {color} | {color:red}  0m 21s{color} | {color:red} hadoop-yarn-server-router in the patch failed. {color} |
| {color:red}-1{color} | {color:red} unit {color} | {color:red}  0m 59s{color} | {color:red} hadoop-yarn-applications-distributedshell in the patch failed. {color} |
| {color:red}-1{color} | {color:red} unit {color} | {color:red}  0m 29s{color} | {color:red} hadoop-mapreduce-client-core in the patch failed. {color} |
| {color:red}-1{color} | {color:red} unit {color} | {color:red}  0m 24s{color} | {color:red} hadoop-mapreduce-client-common in the patch failed. {color} |
| {color:red}-1{color} | {color:red} unit {color} | {color:red} 99m 53s{color} | {color:red} hadoop-mapreduce-client-jobclient in the patch failed. {color} |
| {color:red}-1{color} | {color:red} unit {color} | {color:red}  0m 51s{color} | {color:red} hadoop-mapreduce-client-nativetask in the patch failed. {color} |
| {color:red}-1{color} | {color:red} unit {color} | {color:red}  0m 29s{color} | {color:red} hadoop-mapreduce-examples in the patch failed. {color} |
| {color:green}+1{color} | {color:green} unit {color} | {color:green}  5m 46s{color} | {color:green} hadoop-streaming in the patch passed. {color} |
| {color:red}-1{color} | {color:red} unit {color} | {color:red} 13m 37s{color} | {color:red} hadoop-distcp in the patch failed. {color} |
| {color:red}-1{color} | {color:red} unit {color} | {color:red}  0m 29s{color} | {color:red} hadoop-datajoin in the patch failed. {color} |
| {color:green}+1{color} | {color:green} unit {color} | {color:green}  0m 27s{color} | {color:green} hadoop-openstack in the patch passed. {color} |
| {color:green}+1{color} | {color:green} unit {color} | {color:green}  0m 34s{color} | {color:green} hadoop-aws in the patch passed. {color} |
| {color:green}+1{color} | {color:green} unit {color} | {color:green}  2m 14s{color} | {color:green} hadoop-azure in the patch passed. {color} |
| {color:green}+1{color} | {color:green} unit {color} | {color:green}  3m 42s{color} | {color:green} hadoop-azure-datalake in the patch passed. {color} |
| {color:red}-1{color} | {color:red} asflicense {color} | {color:red}  0m 31s{color} | {color:red} The patch generated 2 ASF License warnings. {color} |
| {color:black}{color} | {color:black} {color} | {color:black}297m 51s{color} | {color:black} {color} |
\\
\\
|| Reason || Tests ||
| Failed junit tests | hadoop.fs.TestGetFileBlockLocations |
|   | hadoop.fs.TestTrash |
|   | hadoop.ipc.TestRetryCache |
|   | hadoop.security.TestKDiag |
|   | hadoop.conf.TestConfiguration |
|   | hadoop.crypto.key.kms.server.TestKMS |
|   | hadoop.yarn.server.webproxy.TestAppReportFetcher |
|   | hadoop.yarn.applications.distributedshell.TestDistributedShell |
|   | hadoop.mapreduce.TestMRJobClient |
|   | hadoop.tools.mapred.TestUniformSizeInputFormat |
|   | hadoop.contrib.utils.join.TestDataJoin |
| Timed out junit tests | org.apache.hadoop.ipc.TestFairCallQueue |
\\
\\
|| Subsystem || Report/Notes ||
| Docker |  Image:yetus/hadoop:14b5c93 |
| JIRA Issue | HADOOP-14729 |
| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12881135/HADOOP-14729.001.patch |
| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  findbugs  checkstyle  |
| uname | Linux f5425421361f 3.13.0-117-generic #164-Ubuntu SMP Fri Apr 7 11:05:26 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux |
| Build tool | maven |
| Personality | /testptch/hadoop/patchprocess/precommit/personality/provided.sh |
| git revision | trunk / ac7d060 |
| Default Java | 1.8.0_131 |
| findbugs | v3.1.0-RC1 |
| findbugs | https://builds.apache.org/job/PreCommit-HADOOP-Build/12997/artifact/patchprocess/branch-findbugs-hadoop-hdfs-project_hadoop-hdfs-warnings.html |
| findbugs | https://builds.apache.org/job/PreCommit-HADOOP-Build/12997/artifact/patchprocess/branch-findbugs-hadoop-yarn-project_hadoop-yarn_hadoop-yarn-server_hadoop-yarn-server-nodemanager-warnings.html |
| mvninstall | https://builds.apache.org/job/PreCommit-HADOOP-Build/12997/artifact/patchprocess/patch-mvninstall-hadoop-hdfs-project_hadoop-hdfs.txt |
| mvninstall | https://builds.apache.org/job/PreCommit-HADOOP-Build/12997/artifact/patchprocess/patch-mvninstall-hadoop-yarn-project_hadoop-yarn_hadoop-yarn-server_hadoop-yarn-server-nodemanager.txt |
| mvninstall | https://builds.apache.org/job/PreCommit-HADOOP-Build/12997/artifact/patchprocess/patch-mvninstall-hadoop-yarn-project_hadoop-yarn_hadoop-yarn-server_hadoop-yarn-server-applicationhistoryservice.txt |
| mvninstall | https://builds.apache.org/job/PreCommit-HADOOP-Build/12997/artifact/patchprocess/patch-mvninstall-hadoop-yarn-project_hadoop-yarn_hadoop-yarn-server_hadoop-yarn-server-resourcemanager.txt |
| mvninstall | https://builds.apache.org/job/PreCommit-HADOOP-Build/12997/artifact/patchprocess/patch-mvninstall-hadoop-yarn-project_hadoop-yarn_hadoop-yarn-server_hadoop-yarn-server-router.txt |
| mvninstall | https://builds.apache.org/job/PreCommit-HADOOP-Build/12997/artifact/patchprocess/patch-mvninstall-hadoop-mapreduce-project_hadoop-mapreduce-client_hadoop-mapreduce-client-core.txt |
| mvninstall | https://builds.apache.org/job/PreCommit-HADOOP-Build/12997/artifact/patchprocess/patch-mvninstall-hadoop-mapreduce-project_hadoop-mapreduce-client_hadoop-mapreduce-client-common.txt |
| mvninstall | https://builds.apache.org/job/PreCommit-HADOOP-Build/12997/artifact/patchprocess/patch-mvninstall-hadoop-mapreduce-project_hadoop-mapreduce-client_hadoop-mapreduce-client-nativetask.txt |
| mvninstall | https://builds.apache.org/job/PreCommit-HADOOP-Build/12997/artifact/patchprocess/patch-mvninstall-hadoop-mapreduce-project_hadoop-mapreduce-examples.txt |
| compile | https://builds.apache.org/job/PreCommit-HADOOP-Build/12997/artifact/patchprocess/patch-compile-root.txt |
| javac | https://builds.apache.org/job/PreCommit-HADOOP-Build/12997/artifact/patchprocess/patch-compile-root.txt |
| checkstyle | https://builds.apache.org/job/PreCommit-HADOOP-Build/12997/artifact/patchprocess/diff-checkstyle-root.txt |
| mvnsite | https://builds.apache.org/job/PreCommit-HADOOP-Build/12997/artifact/patchprocess/patch-mvnsite-hadoop-hdfs-project_hadoop-hdfs.txt |
| mvnsite | https://builds.apache.org/job/PreCommit-HADOOP-Build/12997/artifact/patchprocess/patch-mvnsite-hadoop-yarn-project_hadoop-yarn_hadoop-yarn-server_hadoop-yarn-server-nodemanager.txt |
| mvnsite | https://builds.apache.org/job/PreCommit-HADOOP-Build/12997/artifact/patchprocess/patch-mvnsite-hadoop-yarn-project_hadoop-yarn_hadoop-yarn-server_hadoop-yarn-server-applicationhistoryservice.txt |
| mvnsite | https://builds.apache.org/job/PreCommit-HADOOP-Build/12997/artifact/patchprocess/patch-mvnsite-hadoop-yarn-project_hadoop-yarn_hadoop-yarn-server_hadoop-yarn-server-resourcemanager.txt |
| mvnsite | https://builds.apache.org/job/PreCommit-HADOOP-Build/12997/artifact/patchprocess/patch-mvnsite-hadoop-yarn-project_hadoop-yarn_hadoop-yarn-server_hadoop-yarn-server-router.txt |
| mvnsite | https://builds.apache.org/job/PreCommit-HADOOP-Build/12997/artifact/patchprocess/patch-mvnsite-hadoop-mapreduce-project_hadoop-mapreduce-client_hadoop-mapreduce-client-core.txt |
| mvnsite | https://builds.apache.org/job/PreCommit-HADOOP-Build/12997/artifact/patchprocess/patch-mvnsite-hadoop-mapreduce-project_hadoop-mapreduce-client_hadoop-mapreduce-client-common.txt |
| mvnsite | https://builds.apache.org/job/PreCommit-HADOOP-Build/12997/artifact/patchprocess/patch-mvnsite-hadoop-mapreduce-project_hadoop-mapreduce-client_hadoop-mapreduce-client-nativetask.txt |
| mvnsite | https://builds.apache.org/job/PreCommit-HADOOP-Build/12997/artifact/patchprocess/patch-mvnsite-hadoop-mapreduce-project_hadoop-mapreduce-examples.txt |
| whitespace | https://builds.apache.org/job/PreCommit-HADOOP-Build/12997/artifact/patchprocess/whitespace-tabs.txt |
| findbugs | https://builds.apache.org/job/PreCommit-HADOOP-Build/12997/artifact/patchprocess/patch-findbugs-hadoop-hdfs-project_hadoop-hdfs.txt |
| findbugs | https://builds.apache.org/job/PreCommit-HADOOP-Build/12997/artifact/patchprocess/patch-findbugs-hadoop-yarn-project_hadoop-yarn_hadoop-yarn-server_hadoop-yarn-server-nodemanager.txt |
| findbugs | https://builds.apache.org/job/PreCommit-HADOOP-Build/12997/artifact/patchprocess/patch-findbugs-hadoop-yarn-project_hadoop-yarn_hadoop-yarn-server_hadoop-yarn-server-applicationhistoryservice.txt |
| findbugs | https://builds.apache.org/job/PreCommit-HADOOP-Build/12997/artifact/patchprocess/patch-findbugs-hadoop-yarn-project_hadoop-yarn_hadoop-yarn-server_hadoop-yarn-server-resourcemanager.txt |
| findbugs | https://builds.apache.org/job/PreCommit-HADOOP-Build/12997/artifact/patchprocess/patch-findbugs-hadoop-yarn-project_hadoop-yarn_hadoop-yarn-server_hadoop-yarn-server-router.txt |
| findbugs | https://builds.apache.org/job/PreCommit-HADOOP-Build/12997/artifact/patchprocess/patch-findbugs-hadoop-mapreduce-project_hadoop-mapreduce-client_hadoop-mapreduce-client-core.txt |
| findbugs | https://builds.apache.org/job/PreCommit-HADOOP-Build/12997/artifact/patchprocess/patch-findbugs-hadoop-mapreduce-project_hadoop-mapreduce-client_hadoop-mapreduce-client-common.txt |
| findbugs | https://builds.apache.org/job/PreCommit-HADOOP-Build/12997/artifact/patchprocess/patch-findbugs-hadoop-mapreduce-project_hadoop-mapreduce-client_hadoop-mapreduce-client-nativetask.txt |
| findbugs | https://builds.apache.org/job/PreCommit-HADOOP-Build/12997/artifact/patchprocess/patch-findbugs-hadoop-mapreduce-project_hadoop-mapreduce-examples.txt |
| unit | https://builds.apache.org/job/PreCommit-HADOOP-Build/12997/artifact/patchprocess/patch-unit-hadoop-common-project_hadoop-common.txt |
| unit | https://builds.apache.org/job/PreCommit-HADOOP-Build/12997/artifact/patchprocess/patch-unit-hadoop-common-project_hadoop-kms.txt |
| unit | https://builds.apache.org/job/PreCommit-HADOOP-Build/12997/artifact/patchprocess/patch-unit-hadoop-hdfs-project_hadoop-hdfs.txt |
| unit | https://builds.apache.org/job/PreCommit-HADOOP-Build/12997/artifact/patchprocess/patch-unit-hadoop-yarn-project_hadoop-yarn_hadoop-yarn-server_hadoop-yarn-server-nodemanager.txt |
| unit | https://builds.apache.org/job/PreCommit-HADOOP-Build/12997/artifact/patchprocess/patch-unit-hadoop-yarn-project_hadoop-yarn_hadoop-yarn-server_hadoop-yarn-server-web-proxy.txt |
| unit | https://builds.apache.org/job/PreCommit-HADOOP-Build/12997/artifact/patchprocess/patch-unit-hadoop-yarn-project_hadoop-yarn_hadoop-yarn-server_hadoop-yarn-server-applicationhistoryservice.txt |
| unit | https://builds.apache.org/job/PreCommit-HADOOP-Build/12997/artifact/patchprocess/patch-unit-hadoop-yarn-project_hadoop-yarn_hadoop-yarn-server_hadoop-yarn-server-resourcemanager.txt |
| unit | https://builds.apache.org/job/PreCommit-HADOOP-Build/12997/artifact/patchprocess/patch-unit-hadoop-yarn-project_hadoop-yarn_hadoop-yarn-server_hadoop-yarn-server-router.txt |
| unit | https://builds.apache.org/job/PreCommit-HADOOP-Build/12997/artifact/patchprocess/patch-unit-hadoop-yarn-project_hadoop-yarn_hadoop-yarn-applications_hadoop-yarn-applications-distributedshell.txt |
| unit | https://builds.apache.org/job/PreCommit-HADOOP-Build/12997/artifact/patchprocess/patch-unit-hadoop-mapreduce-project_hadoop-mapreduce-client_hadoop-mapreduce-client-core.txt |
| unit | https://builds.apache.org/job/PreCommit-HADOOP-Build/12997/artifact/patchprocess/patch-unit-hadoop-mapreduce-project_hadoop-mapreduce-client_hadoop-mapreduce-client-common.txt |
| unit | https://builds.apache.org/job/PreCommit-HADOOP-Build/12997/artifact/patchprocess/patch-unit-hadoop-mapreduce-project_hadoop-mapreduce-client_hadoop-mapreduce-client-jobclient.txt |
| unit | https://builds.apache.org/job/PreCommit-HADOOP-Build/12997/artifact/patchprocess/patch-unit-hadoop-mapreduce-project_hadoop-mapreduce-client_hadoop-mapreduce-client-nativetask.txt |
| unit | https://builds.apache.org/job/PreCommit-HADOOP-Build/12997/artifact/patchprocess/patch-unit-hadoop-mapreduce-project_hadoop-mapreduce-examples.txt |
| unit | https://builds.apache.org/job/PreCommit-HADOOP-Build/12997/artifact/patchprocess/patch-unit-hadoop-tools_hadoop-distcp.txt |
| unit | https://builds.apache.org/job/PreCommit-HADOOP-Build/12997/artifact/patchprocess/patch-unit-hadoop-tools_hadoop-datajoin.txt |
|  Test Results | https://builds.apache.org/job/PreCommit-HADOOP-Build/12997/testReport/ |
| asflicense | https://builds.apache.org/job/PreCommit-HADOOP-Build/12997/artifact/patchprocess/patch-asflicense-problems.txt |
| modules | C: hadoop-common-project/hadoop-auth hadoop-common-project/hadoop-common hadoop-common-project/hadoop-kms hadoop-hdfs-project/hadoop-hdfs hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-web-proxy hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-applicationhistoryservice hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-applications-distributedshell hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-common hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-nativetask hadoop-mapreduce-project/hadoop-mapreduce-examples hadoop-tools/hadoop-streaming hadoop-tools/hadoop-distcp hadoop-tools/hadoop-datajoin hadoop-tools/hadoop-openstack hadoop-tools/hadoop-aws hadoop-tools/hadoop-azure hadoop-tools/hadoop-azure-datalake U: . |
| Console output | https://builds.apache.org/job/PreCommit-HADOOP-Build/12997/console |
| Powered by | Apache Yetus 0.6.0-SNAPSHOT   http://yetus.apache.org |


This message was automatically generated.

","10/Aug/17 18:58;ajayydv;[~boky01] Thanks for input. In second patch replaced tab with 2 spaces.","11/Aug/17 02:16;hadoopqa;| (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 14s{color} | {color:blue} Docker mode activated. {color} |
|| || || || {color:brown} Prechecks {color} ||
| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |
| {color:green}+1{color} | {color:green} test4tests {color} | {color:green}  0m  0s{color} | {color:green} The patch appears to include 99 new or modified test files. {color} |
|| || || || {color:brown} trunk Compile Tests {color} ||
| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  0m 16s{color} | {color:blue} Maven dependency ordering for branch {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 14m 45s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 14m 53s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  2m 29s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green} 10m 43s{color} | {color:green} trunk passed {color} |
| {color:blue}0{color} | {color:blue} findbugs {color} | {color:blue}  0m  0s{color} | {color:blue} Skipped patched modules with no Java source: hadoop-hdfs-project/hadoop-hdfs-native-client {color} |
| {color:red}-1{color} | {color:red} findbugs {color} | {color:red}  1m 56s{color} | {color:red} hadoop-hdfs-project/hadoop-hdfs in trunk has 9 extant Findbugs warnings. {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  8m  4s{color} | {color:green} trunk passed {color} |
|| || || || {color:brown} Patch Compile Tests {color} ||
| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  0m 20s{color} | {color:blue} Maven dependency ordering for patch {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  7m 59s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 12m  0s{color} | {color:green} the patch passed {color} |
| {color:red}-1{color} | {color:red} javac {color} | {color:red} 12m  0s{color} | {color:red} root generated 16 new + 1372 unchanged - 2 fixed = 1388 total (was 1374) {color} |
| {color:orange}-0{color} | {color:orange} checkstyle {color} | {color:orange}  2m 33s{color} | {color:orange} root: The patch generated 145 new + 2235 unchanged - 136 fixed = 2380 total (was 2371) {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green} 11m 28s{color} | {color:green} the patch passed {color} |
| {color:red}-1{color} | {color:red} whitespace {color} | {color:red}  0m  0s{color} | {color:red} The patch 34 line(s) with tabs. {color} |
| {color:blue}0{color} | {color:blue} findbugs {color} | {color:blue}  0m  0s{color} | {color:blue} Skipped patched modules with no Java source: hadoop-hdfs-project/hadoop-hdfs-native-client {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green} 18m 11s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  9m  5s{color} | {color:green} the patch passed {color} |
|| || || || {color:brown} Other Tests {color} ||
| {color:green}+1{color} | {color:green} unit {color} | {color:green}  2m 53s{color} | {color:green} hadoop-auth in the patch passed. {color} |
| {color:red}-1{color} | {color:red} unit {color} | {color:red}  9m  4s{color} | {color:red} hadoop-common in the patch failed. {color} |
| {color:red}-1{color} | {color:red} unit {color} | {color:red} 76m 12s{color} | {color:red} hadoop-hdfs in the patch failed. {color} |
| {color:green}+1{color} | {color:green} unit {color} | {color:green}  0m 59s{color} | {color:green} hadoop-hdfs-native-client in the patch passed. {color} |
| {color:green}+1{color} | {color:green} unit {color} | {color:green}  0m 42s{color} | {color:green} hadoop-yarn-server-web-proxy in the patch passed. {color} |
| {color:red}-1{color} | {color:red} unit {color} | {color:red} 46m 30s{color} | {color:red} hadoop-yarn-server-resourcemanager in the patch failed. {color} |
| {color:green}+1{color} | {color:green} unit {color} | {color:green}  2m 38s{color} | {color:green} hadoop-mapreduce-client-core in the patch passed. {color} |
| {color:green}+1{color} | {color:green} unit {color} | {color:green}  0m 58s{color} | {color:green} hadoop-mapreduce-client-common in the patch passed. {color} |
| {color:green}+1{color} | {color:green} unit {color} | {color:green}  8m 52s{color} | {color:green} hadoop-mapreduce-client-app in the patch passed. {color} |
| {color:green}+1{color} | {color:green} unit {color} | {color:green}  3m 52s{color} | {color:green} hadoop-mapreduce-client-hs in the patch passed. {color} |
| {color:green}+1{color} | {color:green} unit {color} | {color:green}104m 27s{color} | {color:green} hadoop-mapreduce-client-jobclient in the patch passed. {color} |
| {color:green}+1{color} | {color:green} unit {color} | {color:green}  9m 31s{color} | {color:green} hadoop-mapreduce-client-nativetask in the patch passed. {color} |
| {color:green}+1{color} | {color:green} unit {color} | {color:green}  0m 55s{color} | {color:green} hadoop-mapreduce-examples in the patch passed. {color} |
| {color:green}+1{color} | {color:green} unit {color} | {color:green}  5m 39s{color} | {color:green} hadoop-streaming in the patch passed. {color} |
| {color:red}-1{color} | {color:red} unit {color} | {color:red}  0m 38s{color} | {color:red} hadoop-datajoin in the patch failed. {color} |
| {color:green}+1{color} | {color:green} unit {color} | {color:green}  0m 39s{color} | {color:green} hadoop-extras in the patch passed. {color} |
| {color:green}+1{color} | {color:green} unit {color} | {color:green}  0m 49s{color} | {color:green} hadoop-aws in the patch passed. {color} |
| {color:green}+1{color} | {color:green} unit {color} | {color:green}  2m 24s{color} | {color:green} hadoop-azure in the patch passed. {color} |
| {color:green}+1{color} | {color:green} unit {color} | {color:green}  3m 52s{color} | {color:green} hadoop-azure-datalake in the patch passed. {color} |
| {color:red}-1{color} | {color:red} asflicense {color} | {color:red}  0m 48s{color} | {color:red} The patch generated 2 ASF License warnings. {color} |
| {color:black}{color} | {color:black} {color} | {color:black}435m 52s{color} | {color:black} {color} |
\\
\\
|| Reason || Tests ||
| Failed junit tests | hadoop.fs.TestGetFileBlockLocations |
|   | hadoop.fs.TestTrash |
|   | hadoop.ipc.TestRetryCache |
|   | hadoop.security.TestKDiag |
|   | hadoop.security.token.TestToken |
|   | hadoop.conf.TestConfiguration |
|   | hadoop.conf.TestCommonConfigurationFields |
|   | hadoop.hdfs.TestEncryptionZonesWithKMS |
|   | hadoop.hdfs.TestMaintenanceState |
|   | hadoop.yarn.server.resourcemanager.security.TestDelegationTokenRenewer |
|   | hadoop.contrib.utils.join.TestDataJoin |
| Timed out junit tests | org.apache.hadoop.yarn.server.resourcemanager.TestSubmitApplicationWithRMHA |
\\
\\
|| Subsystem || Report/Notes ||
| Docker |  Image:yetus/hadoop:14b5c93 |
| JIRA Issue | HADOOP-14729 |
| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12881299/HADOOP-14729.002.patch |
| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  findbugs  checkstyle  |
| uname | Linux 454332e92985 3.13.0-117-generic #164-Ubuntu SMP Fri Apr 7 11:05:26 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux |
| Build tool | maven |
| Personality | /testptch/hadoop/patchprocess/precommit/personality/provided.sh |
| git revision | trunk / 312e57b |
| Default Java | 1.8.0_131 |
| findbugs | v3.1.0-RC1 |
| findbugs | https://builds.apache.org/job/PreCommit-HADOOP-Build/13001/artifact/patchprocess/branch-findbugs-hadoop-hdfs-project_hadoop-hdfs-warnings.html |
| javac | https://builds.apache.org/job/PreCommit-HADOOP-Build/13001/artifact/patchprocess/diff-compile-javac-root.txt |
| checkstyle | https://builds.apache.org/job/PreCommit-HADOOP-Build/13001/artifact/patchprocess/diff-checkstyle-root.txt |
| whitespace | https://builds.apache.org/job/PreCommit-HADOOP-Build/13001/artifact/patchprocess/whitespace-tabs.txt |
| unit | https://builds.apache.org/job/PreCommit-HADOOP-Build/13001/artifact/patchprocess/patch-unit-hadoop-common-project_hadoop-common.txt |
| unit | https://builds.apache.org/job/PreCommit-HADOOP-Build/13001/artifact/patchprocess/patch-unit-hadoop-hdfs-project_hadoop-hdfs.txt |
| unit | https://builds.apache.org/job/PreCommit-HADOOP-Build/13001/artifact/patchprocess/patch-unit-hadoop-yarn-project_hadoop-yarn_hadoop-yarn-server_hadoop-yarn-server-resourcemanager.txt |
| unit | https://builds.apache.org/job/PreCommit-HADOOP-Build/13001/artifact/patchprocess/patch-unit-hadoop-tools_hadoop-datajoin.txt |
|  Test Results | https://builds.apache.org/job/PreCommit-HADOOP-Build/13001/testReport/ |
| asflicense | https://builds.apache.org/job/PreCommit-HADOOP-Build/13001/artifact/patchprocess/patch-asflicense-problems.txt |
| modules | C: hadoop-common-project/hadoop-auth hadoop-common-project/hadoop-common hadoop-hdfs-project/hadoop-hdfs hadoop-hdfs-project/hadoop-hdfs-native-client hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-web-proxy hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-common hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-hs hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-nativetask hadoop-mapreduce-project/hadoop-mapreduce-examples hadoop-tools/hadoop-streaming hadoop-tools/hadoop-datajoin hadoop-tools/hadoop-extras hadoop-tools/hadoop-aws hadoop-tools/hadoop-azure hadoop-tools/hadoop-azure-datalake U: . |
| Console output | https://builds.apache.org/job/PreCommit-HADOOP-Build/13001/console |
| Powered by | Apache Yetus 0.6.0-SNAPSHOT   http://yetus.apache.org |


This message was automatically generated.

","11/Aug/17 03:10;hadoopqa;| (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 20s{color} | {color:blue} Docker mode activated. {color} |
|| || || || {color:brown} Prechecks {color} ||
| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |
| {color:green}+1{color} | {color:green} test4tests {color} | {color:green}  0m  0s{color} | {color:green} The patch appears to include 99 new or modified test files. {color} |
|| || || || {color:brown} trunk Compile Tests {color} ||
| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  1m 46s{color} | {color:blue} Maven dependency ordering for branch {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 14m 50s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 15m 47s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  2m 31s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green} 11m  3s{color} | {color:green} trunk passed {color} |
| {color:blue}0{color} | {color:blue} findbugs {color} | {color:blue}  0m  0s{color} | {color:blue} Skipped patched modules with no Java source: hadoop-hdfs-project/hadoop-hdfs-native-client {color} |
| {color:red}-1{color} | {color:red} findbugs {color} | {color:red}  1m 51s{color} | {color:red} hadoop-hdfs-project/hadoop-hdfs in trunk has 9 extant Findbugs warnings. {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  8m 26s{color} | {color:green} trunk passed {color} |
|| || || || {color:brown} Patch Compile Tests {color} ||
| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  0m 17s{color} | {color:blue} Maven dependency ordering for patch {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  8m 24s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 12m 49s{color} | {color:green} the patch passed {color} |
| {color:red}-1{color} | {color:red} javac {color} | {color:red} 12m 49s{color} | {color:red} root generated 16 new + 1372 unchanged - 2 fixed = 1388 total (was 1374) {color} |
| {color:orange}-0{color} | {color:orange} checkstyle {color} | {color:orange}  2m 31s{color} | {color:orange} root: The patch generated 125 new + 2235 unchanged - 136 fixed = 2360 total (was 2371) {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green} 12m 22s{color} | {color:green} the patch passed {color} |
| {color:red}-1{color} | {color:red} whitespace {color} | {color:red}  0m  0s{color} | {color:red} The patch 15 line(s) with tabs. {color} |
| {color:blue}0{color} | {color:blue} findbugs {color} | {color:blue}  0m  0s{color} | {color:blue} Skipped patched modules with no Java source: hadoop-hdfs-project/hadoop-hdfs-native-client {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green} 17m 32s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  9m 13s{color} | {color:green} the patch passed {color} |
|| || || || {color:brown} Other Tests {color} ||
| {color:green}+1{color} | {color:green} unit {color} | {color:green}  3m 12s{color} | {color:green} hadoop-auth in the patch passed. {color} |
| {color:red}-1{color} | {color:red} unit {color} | {color:red}  8m 36s{color} | {color:red} hadoop-common in the patch failed. {color} |
| {color:red}-1{color} | {color:red} unit {color} | {color:red}101m 23s{color} | {color:red} hadoop-hdfs in the patch failed. {color} |
| {color:green}+1{color} | {color:green} unit {color} | {color:green}  0m 58s{color} | {color:green} hadoop-hdfs-native-client in the patch passed. {color} |
| {color:green}+1{color} | {color:green} unit {color} | {color:green}  0m 39s{color} | {color:green} hadoop-yarn-server-web-proxy in the patch passed. {color} |
| {color:red}-1{color} | {color:red} unit {color} | {color:red} 48m 19s{color} | {color:red} hadoop-yarn-server-resourcemanager in the patch failed. {color} |
| {color:green}+1{color} | {color:green} unit {color} | {color:green}  3m  2s{color} | {color:green} hadoop-mapreduce-client-core in the patch passed. {color} |
| {color:green}+1{color} | {color:green} unit {color} | {color:green}  1m  8s{color} | {color:green} hadoop-mapreduce-client-common in the patch passed. {color} |
| {color:green}+1{color} | {color:green} unit {color} | {color:green}  9m 15s{color} | {color:green} hadoop-mapreduce-client-app in the patch passed. {color} |
| {color:green}+1{color} | {color:green} unit {color} | {color:green}  3m 28s{color} | {color:green} hadoop-mapreduce-client-hs in the patch passed. {color} |
| {color:green}+1{color} | {color:green} unit {color} | {color:green}109m  0s{color} | {color:green} hadoop-mapreduce-client-jobclient in the patch passed. {color} |
| {color:green}+1{color} | {color:green} unit {color} | {color:green} 11m 47s{color} | {color:green} hadoop-mapreduce-client-nativetask in the patch passed. {color} |
| {color:green}+1{color} | {color:green} unit {color} | {color:green}  1m 19s{color} | {color:green} hadoop-mapreduce-examples in the patch passed. {color} |
| {color:green}+1{color} | {color:green} unit {color} | {color:green}  7m 38s{color} | {color:green} hadoop-streaming in the patch passed. {color} |
| {color:red}-1{color} | {color:red} unit {color} | {color:red}  0m 54s{color} | {color:red} hadoop-datajoin in the patch failed. {color} |
| {color:green}+1{color} | {color:green} unit {color} | {color:green}  0m 44s{color} | {color:green} hadoop-extras in the patch passed. {color} |
| {color:green}+1{color} | {color:green} unit {color} | {color:green}  0m 58s{color} | {color:green} hadoop-aws in the patch passed. {color} |
| {color:green}+1{color} | {color:green} unit {color} | {color:green}  2m 50s{color} | {color:green} hadoop-azure in the patch passed. {color} |
| {color:green}+1{color} | {color:green} unit {color} | {color:green}  4m 10s{color} | {color:green} hadoop-azure-datalake in the patch passed. {color} |
| {color:red}-1{color} | {color:red} asflicense {color} | {color:red}  1m 55s{color} | {color:red} The patch generated 2 ASF License warnings. {color} |
| {color:black}{color} | {color:black} {color} | {color:black}479m 34s{color} | {color:black} {color} |
\\
\\
|| Reason || Tests ||
| Failed junit tests | hadoop.fs.TestGetFileBlockLocations |
|   | hadoop.conf.TestCommonConfigurationFields |
|   | hadoop.security.token.TestToken |
|   | hadoop.ipc.TestRetryCache |
|   | hadoop.fs.TestTrash |
|   | hadoop.conf.TestConfiguration |
|   | hadoop.hdfs.TestDFSStripedInputStreamWithRandomECPolicy |
|   | hadoop.hdfs.server.namenode.TestNameNodeMXBean |
|   | hadoop.hdfs.server.datanode.TestDataNodeVolumeFailure |
|   | hadoop.hdfs.TestDFSStripedOutputStreamWithFailure080 |
|   | hadoop.hdfs.server.datanode.TestDataNodeVolumeFailureReporting |
|   | hadoop.yarn.server.resourcemanager.scheduler.fair.TestFSAppStarvation |
|   | hadoop.contrib.utils.join.TestDataJoin |
| Timed out junit tests | org.apache.hadoop.yarn.server.resourcemanager.TestSubmitApplicationWithRMHA |
|   | org.apache.hadoop.yarn.server.resourcemanager.TestKillApplicationWithRMHA |
\\
\\
|| Subsystem || Report/Notes ||
| Docker |  Image:yetus/hadoop:14b5c93 |
| JIRA Issue | HADOOP-14729 |
| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12881301/HADOOP-14729.002.patch |
| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  findbugs  checkstyle  |
| uname | Linux ab95f18d27ae 3.13.0-119-generic #166-Ubuntu SMP Wed May 3 12:18:55 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux |
| Build tool | maven |
| Personality | /testptch/hadoop/patchprocess/precommit/personality/provided.sh |
| git revision | trunk / 312e57b |
| Default Java | 1.8.0_131 |
| findbugs | v3.1.0-RC1 |
| findbugs | https://builds.apache.org/job/PreCommit-HADOOP-Build/13002/artifact/patchprocess/branch-findbugs-hadoop-hdfs-project_hadoop-hdfs-warnings.html |
| javac | https://builds.apache.org/job/PreCommit-HADOOP-Build/13002/artifact/patchprocess/diff-compile-javac-root.txt |
| checkstyle | https://builds.apache.org/job/PreCommit-HADOOP-Build/13002/artifact/patchprocess/diff-checkstyle-root.txt |
| whitespace | https://builds.apache.org/job/PreCommit-HADOOP-Build/13002/artifact/patchprocess/whitespace-tabs.txt |
| unit | https://builds.apache.org/job/PreCommit-HADOOP-Build/13002/artifact/patchprocess/patch-unit-hadoop-common-project_hadoop-common.txt |
| unit | https://builds.apache.org/job/PreCommit-HADOOP-Build/13002/artifact/patchprocess/patch-unit-hadoop-hdfs-project_hadoop-hdfs.txt |
| unit | https://builds.apache.org/job/PreCommit-HADOOP-Build/13002/artifact/patchprocess/patch-unit-hadoop-yarn-project_hadoop-yarn_hadoop-yarn-server_hadoop-yarn-server-resourcemanager.txt |
| unit | https://builds.apache.org/job/PreCommit-HADOOP-Build/13002/artifact/patchprocess/patch-unit-hadoop-tools_hadoop-datajoin.txt |
|  Test Results | https://builds.apache.org/job/PreCommit-HADOOP-Build/13002/testReport/ |
| asflicense | https://builds.apache.org/job/PreCommit-HADOOP-Build/13002/artifact/patchprocess/patch-asflicense-problems.txt |
| modules | C: hadoop-common-project/hadoop-auth hadoop-common-project/hadoop-common hadoop-hdfs-project/hadoop-hdfs hadoop-hdfs-project/hadoop-hdfs-native-client hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-web-proxy hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-common hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-hs hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-nativetask hadoop-mapreduce-project/hadoop-mapreduce-examples hadoop-tools/hadoop-streaming hadoop-tools/hadoop-datajoin hadoop-tools/hadoop-extras hadoop-tools/hadoop-aws hadoop-tools/hadoop-azure hadoop-tools/hadoop-azure-datalake U: . |
| Console output | https://builds.apache.org/job/PreCommit-HADOOP-Build/13002/console |
| Powered by | Apache Yetus 0.6.0-SNAPSHOT   http://yetus.apache.org |


This message was automatically generated.

","11/Aug/17 09:28;stevel@apache.org;{{TestCommonConfigurationFields}} unrelated","12/Aug/17 05:00;hadoopqa;| (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m  0s{color} | {color:blue} Docker mode activated. {color} |
| {color:red}-1{color} | {color:red} patch {color} | {color:red}  0m  5s{color} | {color:red} HADOOP-14729 does not apply to trunk. Rebase required? Wrong Branch? See https://wiki.apache.org/hadoop/HowToContribute for help. {color} |
\\
\\
|| Subsystem || Report/Notes ||
| JIRA Issue | HADOOP-14729 |
| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12881597/HADOOP-14729.003.patch |
| Console output | https://builds.apache.org/job/PreCommit-HADOOP-Build/13014/console |
| Powered by | Apache Yetus 0.6.0-SNAPSHOT   http://yetus.apache.org |


This message was automatically generated.

","12/Aug/17 05:40;hadoopqa;| (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m  0s{color} | {color:blue} Docker mode activated. {color} |
| {color:red}-1{color} | {color:red} patch {color} | {color:red}  0m  5s{color} | {color:red} HADOOP-14729 does not apply to trunk. Rebase required? Wrong Branch? See https://wiki.apache.org/hadoop/HowToContribute for help. {color} |
\\
\\
|| Subsystem || Report/Notes ||
| JIRA Issue | HADOOP-14729 |
| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12881598/HADOOP-14729.004.patch |
| Console output | https://builds.apache.org/job/PreCommit-HADOOP-Build/13016/console |
| Powered by | Apache Yetus 0.6.0-SNAPSHOT   http://yetus.apache.org |


This message was automatically generated.

","12/Aug/17 11:34;hadoopqa;| (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 21s{color} | {color:blue} Docker mode activated. {color} |
|| || || || {color:brown} Prechecks {color} ||
| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |
| {color:green}+1{color} | {color:green} test4tests {color} | {color:green}  0m  0s{color} | {color:green} The patch appears to include 77 new or modified test files. {color} |
|| || || || {color:brown} trunk Compile Tests {color} ||
| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  1m 23s{color} | {color:blue} Maven dependency ordering for branch {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 14m  1s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 14m 19s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  2m 14s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  9m 24s{color} | {color:green} trunk passed {color} |
| {color:red}-1{color} | {color:red} findbugs {color} | {color:red}  1m 49s{color} | {color:red} hadoop-hdfs-project/hadoop-hdfs in trunk has 9 extant Findbugs warnings. {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  7m 19s{color} | {color:green} trunk passed {color} |
|| || || || {color:brown} Patch Compile Tests {color} ||
| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  0m 16s{color} | {color:blue} Maven dependency ordering for patch {color} |
| {color:red}-1{color} | {color:red} mvninstall {color} | {color:red}  0m 36s{color} | {color:red} hadoop-common in the patch failed. {color} |
| {color:red}-1{color} | {color:red} compile {color} | {color:red}  0m 57s{color} | {color:red} root in the patch failed. {color} |
| {color:red}-1{color} | {color:red} javac {color} | {color:red}  0m 57s{color} | {color:red} root in the patch failed. {color} |
| {color:orange}-0{color} | {color:orange} checkstyle {color} | {color:orange}  2m 13s{color} | {color:orange} root: The patch generated 58 new + 1159 unchanged - 109 fixed = 1217 total (was 1268) {color} |
| {color:red}-1{color} | {color:red} mvnsite {color} | {color:red}  0m 40s{color} | {color:red} hadoop-common in the patch failed. {color} |
| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} |
| {color:red}-1{color} | {color:red} findbugs {color} | {color:red}  0m 32s{color} | {color:red} hadoop-common in the patch failed. {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  5m 59s{color} | {color:green} the patch passed {color} |
|| || || || {color:brown} Other Tests {color} ||
| {color:green}+1{color} | {color:green} unit {color} | {color:green}  2m 41s{color} | {color:green} hadoop-auth in the patch passed. {color} |
| {color:red}-1{color} | {color:red} unit {color} | {color:red}  0m 44s{color} | {color:red} hadoop-common in the patch failed. {color} |
| {color:red}-1{color} | {color:red} unit {color} | {color:red} 64m 33s{color} | {color:red} hadoop-hdfs in the patch failed. {color} |
| {color:green}+1{color} | {color:green} unit {color} | {color:green}  0m 31s{color} | {color:green} hadoop-yarn-server-web-proxy in the patch passed. {color} |
| {color:green}+1{color} | {color:green} unit {color} | {color:green}  2m 28s{color} | {color:green} hadoop-mapreduce-client-core in the patch passed. {color} |
| {color:green}+1{color} | {color:green} unit {color} | {color:green}  0m 51s{color} | {color:green} hadoop-mapreduce-client-common in the patch passed. {color} |
| {color:green}+1{color} | {color:green} unit {color} | {color:green}  9m 18s{color} | {color:green} hadoop-mapreduce-client-app in the patch passed. {color} |
| {color:green}+1{color} | {color:green} unit {color} | {color:green}  3m 22s{color} | {color:green} hadoop-mapreduce-client-hs in the patch passed. {color} |
| {color:green}+1{color} | {color:green} unit {color} | {color:green} 98m 22s{color} | {color:green} hadoop-mapreduce-client-jobclient in the patch passed. {color} |
| {color:green}+1{color} | {color:green} unit {color} | {color:green} 11m  9s{color} | {color:green} hadoop-mapreduce-client-nativetask in the patch passed. {color} |
| {color:green}+1{color} | {color:green} unit {color} | {color:green}  0m 59s{color} | {color:green} hadoop-mapreduce-examples in the patch passed. {color} |
| {color:green}+1{color} | {color:green} unit {color} | {color:green}  6m 48s{color} | {color:green} hadoop-streaming in the patch passed. {color} |
| {color:green}+1{color} | {color:green} unit {color} | {color:green}  0m 45s{color} | {color:green} hadoop-datajoin in the patch passed. {color} |
| {color:green}+1{color} | {color:green} unit {color} | {color:green}  0m 39s{color} | {color:green} hadoop-extras in the patch passed. {color} |
| {color:green}+1{color} | {color:green} unit {color} | {color:green}  0m 46s{color} | {color:green} hadoop-aws in the patch passed. {color} |
| {color:green}+1{color} | {color:green} unit {color} | {color:green}  2m 47s{color} | {color:green} hadoop-azure in the patch passed. {color} |
| {color:green}+1{color} | {color:green} unit {color} | {color:green}  3m 57s{color} | {color:green} hadoop-azure-datalake in the patch passed. {color} |
| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 43s{color} | {color:green} The patch does not generate ASF License warnings. {color} |
| {color:black}{color} | {color:black} {color} | {color:black}333m 27s{color} | {color:black} {color} |
\\
\\
|| Reason || Tests ||
| Failed junit tests | hadoop.hdfs.TestDFSStripedInputStreamWithRandomECPolicy |
|   | hadoop.hdfs.TestDFSStripedOutputStreamWithFailureWithRandomECPolicy |
\\
\\
|| Subsystem || Report/Notes ||
| Docker |  Image:yetus/hadoop:14b5c93 |
| JIRA Issue | HADOOP-14729 |
| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12881600/HADOOP-14729.004.patch |
| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  findbugs  checkstyle  |
| uname | Linux f141906eddb0 3.13.0-119-generic #166-Ubuntu SMP Wed May 3 12:18:55 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux |
| Build tool | maven |
| Personality | /testptch/hadoop/patchprocess/precommit/personality/provided.sh |
| git revision | trunk / 8b242f0 |
| Default Java | 1.8.0_144 |
| findbugs | v3.1.0-RC1 |
| findbugs | https://builds.apache.org/job/PreCommit-HADOOP-Build/13017/artifact/patchprocess/branch-findbugs-hadoop-hdfs-project_hadoop-hdfs-warnings.html |
| mvninstall | https://builds.apache.org/job/PreCommit-HADOOP-Build/13017/artifact/patchprocess/patch-mvninstall-hadoop-common-project_hadoop-common.txt |
| compile | https://builds.apache.org/job/PreCommit-HADOOP-Build/13017/artifact/patchprocess/patch-compile-root.txt |
| javac | https://builds.apache.org/job/PreCommit-HADOOP-Build/13017/artifact/patchprocess/patch-compile-root.txt |
| checkstyle | https://builds.apache.org/job/PreCommit-HADOOP-Build/13017/artifact/patchprocess/diff-checkstyle-root.txt |
| mvnsite | https://builds.apache.org/job/PreCommit-HADOOP-Build/13017/artifact/patchprocess/patch-mvnsite-hadoop-common-project_hadoop-common.txt |
| findbugs | https://builds.apache.org/job/PreCommit-HADOOP-Build/13017/artifact/patchprocess/patch-findbugs-hadoop-common-project_hadoop-common.txt |
| unit | https://builds.apache.org/job/PreCommit-HADOOP-Build/13017/artifact/patchprocess/patch-unit-hadoop-common-project_hadoop-common.txt |
| unit | https://builds.apache.org/job/PreCommit-HADOOP-Build/13017/artifact/patchprocess/patch-unit-hadoop-hdfs-project_hadoop-hdfs.txt |
|  Test Results | https://builds.apache.org/job/PreCommit-HADOOP-Build/13017/testReport/ |
| modules | C: hadoop-common-project/hadoop-auth hadoop-common-project/hadoop-common hadoop-hdfs-project/hadoop-hdfs hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-web-proxy hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-common hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-hs hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-nativetask hadoop-mapreduce-project/hadoop-mapreduce-examples hadoop-tools/hadoop-streaming hadoop-tools/hadoop-datajoin hadoop-tools/hadoop-extras hadoop-tools/hadoop-aws hadoop-tools/hadoop-azure hadoop-tools/hadoop-azure-datalake U: . |
| Console output | https://builds.apache.org/job/PreCommit-HADOOP-Build/13017/console |
| Powered by | Apache Yetus 0.6.0-SNAPSHOT   http://yetus.apache.org |


This message was automatically generated.

","12/Aug/17 13:20;hadoopqa;| (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 17s{color} | {color:blue} Docker mode activated. {color} |
|| || || || {color:brown} Prechecks {color} ||
| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |
| {color:green}+1{color} | {color:green} test4tests {color} | {color:green}  0m  0s{color} | {color:green} The patch appears to include 77 new or modified test files. {color} |
|| || || || {color:brown} trunk Compile Tests {color} ||
| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  1m 31s{color} | {color:blue} Maven dependency ordering for branch {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 17m  9s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 17m 54s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  2m 35s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green} 11m 19s{color} | {color:green} trunk passed {color} |
| {color:red}-1{color} | {color:red} findbugs {color} | {color:red}  2m 10s{color} | {color:red} hadoop-hdfs-project/hadoop-hdfs in trunk has 9 extant Findbugs warnings. {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  8m 30s{color} | {color:green} trunk passed {color} |
|| || || || {color:brown} Patch Compile Tests {color} ||
| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  0m 19s{color} | {color:blue} Maven dependency ordering for patch {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  8m 22s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 13m 37s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javac {color} | {color:green} 13m 37s{color} | {color:green} root generated 0 new + 1343 unchanged - 2 fixed = 1343 total (was 1345) {color} |
| {color:orange}-0{color} | {color:orange} checkstyle {color} | {color:orange}  2m 39s{color} | {color:orange} root: The patch generated 57 new + 1159 unchanged - 109 fixed = 1216 total (was 1268) {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green} 12m 12s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green} 18m 57s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  9m 27s{color} | {color:green} the patch passed {color} |
|| || || || {color:brown} Other Tests {color} ||
| {color:green}+1{color} | {color:green} unit {color} | {color:green}  3m  4s{color} | {color:green} hadoop-auth in the patch passed. {color} |
| {color:green}+1{color} | {color:green} unit {color} | {color:green}  9m 32s{color} | {color:green} hadoop-common in the patch passed. {color} |
| {color:red}-1{color} | {color:red} unit {color} | {color:red} 80m 25s{color} | {color:red} hadoop-hdfs in the patch failed. {color} |
| {color:green}+1{color} | {color:green} unit {color} | {color:green}  0m 48s{color} | {color:green} hadoop-yarn-server-web-proxy in the patch passed. {color} |
| {color:green}+1{color} | {color:green} unit {color} | {color:green}  3m  0s{color} | {color:green} hadoop-mapreduce-client-core in the patch passed. {color} |
| {color:green}+1{color} | {color:green} unit {color} | {color:green}  1m  7s{color} | {color:green} hadoop-mapreduce-client-common in the patch passed. {color} |
| {color:green}+1{color} | {color:green} unit {color} | {color:green} 10m  3s{color} | {color:green} hadoop-mapreduce-client-app in the patch passed. {color} |
| {color:green}+1{color} | {color:green} unit {color} | {color:green}  3m 59s{color} | {color:green} hadoop-mapreduce-client-hs in the patch passed. {color} |
| {color:green}+1{color} | {color:green} unit {color} | {color:green}113m 18s{color} | {color:green} hadoop-mapreduce-client-jobclient in the patch passed. {color} |
| {color:green}+1{color} | {color:green} unit {color} | {color:green} 10m 48s{color} | {color:green} hadoop-mapreduce-client-nativetask in the patch passed. {color} |
| {color:green}+1{color} | {color:green} unit {color} | {color:green}  0m 59s{color} | {color:green} hadoop-mapreduce-examples in the patch passed. {color} |
| {color:green}+1{color} | {color:green} unit {color} | {color:green}  6m 37s{color} | {color:green} hadoop-streaming in the patch passed. {color} |
| {color:green}+1{color} | {color:green} unit {color} | {color:green}  0m 50s{color} | {color:green} hadoop-datajoin in the patch passed. {color} |
| {color:green}+1{color} | {color:green} unit {color} | {color:green}  0m 42s{color} | {color:green} hadoop-extras in the patch passed. {color} |
| {color:green}+1{color} | {color:green} unit {color} | {color:green}  0m 51s{color} | {color:green} hadoop-aws in the patch passed. {color} |
| {color:green}+1{color} | {color:green} unit {color} | {color:green}  2m 45s{color} | {color:green} hadoop-azure in the patch passed. {color} |
| {color:green}+1{color} | {color:green} unit {color} | {color:green}  4m  3s{color} | {color:green} hadoop-azure-datalake in the patch passed. {color} |
| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 50s{color} | {color:green} The patch does not generate ASF License warnings. {color} |
| {color:black}{color} | {color:black} {color} | {color:black}419m 57s{color} | {color:black} {color} |
\\
\\
|| Reason || Tests ||
| Failed junit tests | hadoop.hdfs.TestDFSStripedOutputStreamWithFailure070 |
|   | hadoop.hdfs.server.balancer.TestBalancer |
|   | hadoop.hdfs.TestEncryptionZones |
|   | hadoop.hdfs.server.datanode.TestDataNodeVolumeFailureReporting |
|   | hadoop.hdfs.TestDFSStripedOutputStreamWithFailure160 |
|   | hadoop.hdfs.server.datanode.TestDataNodeVolumeFailureToleration |
|   | hadoop.hdfs.TestDFSStripedInputStreamWithRandomECPolicy |
\\
\\
|| Subsystem || Report/Notes ||
| Docker |  Image:yetus/hadoop:14b5c93 |
| JIRA Issue | HADOOP-14729 |
| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12881601/HADOOP-14729.005.patch |
| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  findbugs  checkstyle  |
| uname | Linux fde56a1f8177 3.13.0-116-generic #163-Ubuntu SMP Fri Mar 31 14:13:22 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux |
| Build tool | maven |
| Personality | /testptch/hadoop/patchprocess/precommit/personality/provided.sh |
| git revision | trunk / 8b242f0 |
| Default Java | 1.8.0_144 |
| findbugs | v3.1.0-RC1 |
| findbugs | https://builds.apache.org/job/PreCommit-HADOOP-Build/13018/artifact/patchprocess/branch-findbugs-hadoop-hdfs-project_hadoop-hdfs-warnings.html |
| checkstyle | https://builds.apache.org/job/PreCommit-HADOOP-Build/13018/artifact/patchprocess/diff-checkstyle-root.txt |
| unit | https://builds.apache.org/job/PreCommit-HADOOP-Build/13018/artifact/patchprocess/patch-unit-hadoop-hdfs-project_hadoop-hdfs.txt |
|  Test Results | https://builds.apache.org/job/PreCommit-HADOOP-Build/13018/testReport/ |
| modules | C: hadoop-common-project/hadoop-auth hadoop-common-project/hadoop-common hadoop-hdfs-project/hadoop-hdfs hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-web-proxy hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-common hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-hs hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-nativetask hadoop-mapreduce-project/hadoop-mapreduce-examples hadoop-tools/hadoop-streaming hadoop-tools/hadoop-datajoin hadoop-tools/hadoop-extras hadoop-tools/hadoop-aws hadoop-tools/hadoop-azure hadoop-tools/hadoop-azure-datalake U: . |
| Console output | https://builds.apache.org/job/PreCommit-HADOOP-Build/13018/console |
| Powered by | Apache Yetus 0.6.0-SNAPSHOT   http://yetus.apache.org |


This message was automatically generated.

","13/Aug/17 07:11;hadoopqa;| (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 15s{color} | {color:blue} Docker mode activated. {color} |
|| || || || {color:brown} Prechecks {color} ||
| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |
| {color:green}+1{color} | {color:green} test4tests {color} | {color:green}  0m  0s{color} | {color:green} The patch appears to include 77 new or modified test files. {color} |
|| || || || {color:brown} trunk Compile Tests {color} ||
| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  0m 44s{color} | {color:blue} Maven dependency ordering for branch {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 13m 52s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 14m  0s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  2m 15s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  9m 26s{color} | {color:green} trunk passed {color} |
| {color:red}-1{color} | {color:red} findbugs {color} | {color:red}  1m 49s{color} | {color:red} hadoop-hdfs-project/hadoop-hdfs in trunk has 9 extant Findbugs warnings. {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  7m 23s{color} | {color:green} trunk passed {color} |
|| || || || {color:brown} Patch Compile Tests {color} ||
| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  0m 17s{color} | {color:blue} Maven dependency ordering for patch {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  6m 41s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 10m 38s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javac {color} | {color:green} 10m 38s{color} | {color:green} root generated 0 new + 1343 unchanged - 2 fixed = 1343 total (was 1345) {color} |
| {color:orange}-0{color} | {color:orange} checkstyle {color} | {color:orange}  2m 15s{color} | {color:orange} root: The patch generated 42 new + 1155 unchanged - 113 fixed = 1197 total (was 1268) {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green} 10m 17s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green} 15m 25s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  8m 17s{color} | {color:green} the patch passed {color} |
|| || || || {color:brown} Other Tests {color} ||
| {color:green}+1{color} | {color:green} unit {color} | {color:green}  2m 51s{color} | {color:green} hadoop-auth in the patch passed. {color} |
| {color:red}-1{color} | {color:red} unit {color} | {color:red}  8m  8s{color} | {color:red} hadoop-common in the patch failed. {color} |
| {color:red}-1{color} | {color:red} unit {color} | {color:red} 65m 12s{color} | {color:red} hadoop-hdfs in the patch failed. {color} |
| {color:green}+1{color} | {color:green} unit {color} | {color:green}  0m 38s{color} | {color:green} hadoop-yarn-server-web-proxy in the patch passed. {color} |
| {color:green}+1{color} | {color:green} unit {color} | {color:green}  2m 34s{color} | {color:green} hadoop-mapreduce-client-core in the patch passed. {color} |
| {color:green}+1{color} | {color:green} unit {color} | {color:green}  0m 56s{color} | {color:green} hadoop-mapreduce-client-common in the patch passed. {color} |
| {color:green}+1{color} | {color:green} unit {color} | {color:green}  8m 51s{color} | {color:green} hadoop-mapreduce-client-app in the patch passed. {color} |
| {color:green}+1{color} | {color:green} unit {color} | {color:green}  3m 19s{color} | {color:green} hadoop-mapreduce-client-hs in the patch passed. {color} |
| {color:green}+1{color} | {color:green} unit {color} | {color:green}102m 13s{color} | {color:green} hadoop-mapreduce-client-jobclient in the patch passed. {color} |
| {color:green}+1{color} | {color:green} unit {color} | {color:green}  9m 54s{color} | {color:green} hadoop-mapreduce-client-nativetask in the patch passed. {color} |
| {color:green}+1{color} | {color:green} unit {color} | {color:green}  0m 51s{color} | {color:green} hadoop-mapreduce-examples in the patch passed. {color} |
| {color:green}+1{color} | {color:green} unit {color} | {color:green}  5m 55s{color} | {color:green} hadoop-streaming in the patch passed. {color} |
| {color:green}+1{color} | {color:green} unit {color} | {color:green}  0m 47s{color} | {color:green} hadoop-datajoin in the patch passed. {color} |
| {color:green}+1{color} | {color:green} unit {color} | {color:green}  0m 39s{color} | {color:green} hadoop-extras in the patch passed. {color} |
| {color:green}+1{color} | {color:green} unit {color} | {color:green}  0m 47s{color} | {color:green} hadoop-aws in the patch passed. {color} |
| {color:green}+1{color} | {color:green} unit {color} | {color:green}  2m 25s{color} | {color:green} hadoop-azure in the patch passed. {color} |
| {color:green}+1{color} | {color:green} unit {color} | {color:green}  3m 50s{color} | {color:green} hadoop-azure-datalake in the patch passed. {color} |
| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 46s{color} | {color:green} The patch does not generate ASF License warnings. {color} |
| {color:black}{color} | {color:black} {color} | {color:black}360m 44s{color} | {color:black} {color} |
\\
\\
|| Reason || Tests ||
| Failed junit tests | hadoop.security.TestKDiag |
|   | hadoop.net.TestDNS |
|   | hadoop.hdfs.TestDFSStripedOutputStreamWithFailureWithRandomECPolicy |
|   | hadoop.hdfs.server.datanode.TestDataNodeVolumeFailure |
|   | hadoop.hdfs.server.blockmanagement.TestBlockTokenWithDFSStriped |
|   | hadoop.hdfs.TestDFSStripedOutputStreamWithFailure070 |
\\
\\
|| Subsystem || Report/Notes ||
| Docker |  Image:yetus/hadoop:14b5c93 |
| JIRA Issue | HADOOP-14729 |
| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12881637/HADOOP-14729.006.patch |
| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  findbugs  checkstyle  |
| uname | Linux 3ff5c8f2deb4 3.13.0-117-generic #164-Ubuntu SMP Fri Apr 7 11:05:26 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux |
| Build tool | maven |
| Personality | /testptch/hadoop/patchprocess/precommit/personality/provided.sh |
| git revision | trunk / 8b242f0 |
| Default Java | 1.8.0_144 |
| findbugs | v3.1.0-RC1 |
| findbugs | https://builds.apache.org/job/PreCommit-HADOOP-Build/13023/artifact/patchprocess/branch-findbugs-hadoop-hdfs-project_hadoop-hdfs-warnings.html |
| checkstyle | https://builds.apache.org/job/PreCommit-HADOOP-Build/13023/artifact/patchprocess/diff-checkstyle-root.txt |
| unit | https://builds.apache.org/job/PreCommit-HADOOP-Build/13023/artifact/patchprocess/patch-unit-hadoop-common-project_hadoop-common.txt |
| unit | https://builds.apache.org/job/PreCommit-HADOOP-Build/13023/artifact/patchprocess/patch-unit-hadoop-hdfs-project_hadoop-hdfs.txt |
|  Test Results | https://builds.apache.org/job/PreCommit-HADOOP-Build/13023/testReport/ |
| modules | C: hadoop-common-project/hadoop-auth hadoop-common-project/hadoop-common hadoop-hdfs-project/hadoop-hdfs hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-web-proxy hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-common hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-hs hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-nativetask hadoop-mapreduce-project/hadoop-mapreduce-examples hadoop-tools/hadoop-streaming hadoop-tools/hadoop-datajoin hadoop-tools/hadoop-extras hadoop-tools/hadoop-aws hadoop-tools/hadoop-azure hadoop-tools/hadoop-azure-datalake U: . |
| Console output | https://builds.apache.org/job/PreCommit-HADOOP-Build/13023/console |
| Powered by | Apache Yetus 0.6.0-SNAPSHOT   http://yetus.apache.org |


This message was automatically generated.

","14/Aug/17 15:02;ajayydv;[~stevel@apache.org],[~boky01],[~ajisakaa] Request you to review the patch. test failures are unrelated.","16/Aug/17 21:58;arp;Thanks for taking on this monumental task [~ajayydv]. I haven't reviewed the entire patch but here's a few early comments:
# There are two deleted test cases in TestConfiguration - testDumpSensitiveProperty and testDumpSensitiveConfiguration
# TestDistCh#testDistCh - missing @Test annotation.
# TestDU#testDU - missing @Test annotation.
# TestFairCallQueue#testDrainTo and #testDrainToWithLimit - missing @Test annotations.","16/Aug/17 23:39;ajayydv;Hi [~arpiagariu], Thanks for review. Uploaded new patch with suggested changes.","17/Aug/17 07:11;hadoopqa;| (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 32s{color} | {color:blue} Docker mode activated. {color} |
|| || || || {color:brown} Prechecks {color} ||
| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |
| {color:green}+1{color} | {color:green} test4tests {color} | {color:green}  0m  0s{color} | {color:green} The patch appears to include 76 new or modified test files. {color} |
|| || || || {color:brown} trunk Compile Tests {color} ||
| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  1m 54s{color} | {color:blue} Maven dependency ordering for branch {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 19m 32s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 17m  4s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  2m 41s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  9m  8s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green} 11m 52s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  7m  4s{color} | {color:green} trunk passed {color} |
|| || || || {color:brown} Patch Compile Tests {color} ||
| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  0m 17s{color} | {color:blue} Maven dependency ordering for patch {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  6m 24s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 11m  8s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javac {color} | {color:green} 11m  8s{color} | {color:green} root generated 0 new + 1315 unchanged - 2 fixed = 1315 total (was 1317) {color} |
| {color:orange}-0{color} | {color:orange} checkstyle {color} | {color:orange}  2m 18s{color} | {color:orange} root: The patch generated 42 new + 1136 unchanged - 110 fixed = 1178 total (was 1246) {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  9m 51s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green} 14m 41s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  7m 59s{color} | {color:green} the patch passed {color} |
|| || || || {color:brown} Other Tests {color} ||
| {color:red}-1{color} | {color:red} unit {color} | {color:red}  8m 53s{color} | {color:red} hadoop-common in the patch failed. {color} |
| {color:red}-1{color} | {color:red} unit {color} | {color:red}118m 42s{color} | {color:red} hadoop-hdfs in the patch failed. {color} |
| {color:green}+1{color} | {color:green} unit {color} | {color:green}  1m 22s{color} | {color:green} hadoop-yarn-server-web-proxy in the patch passed. {color} |
| {color:green}+1{color} | {color:green} unit {color} | {color:green}  4m 13s{color} | {color:green} hadoop-mapreduce-client-core in the patch passed. {color} |
| {color:green}+1{color} | {color:green} unit {color} | {color:green}  1m 42s{color} | {color:green} hadoop-mapreduce-client-common in the patch passed. {color} |
| {color:green}+1{color} | {color:green} unit {color} | {color:green} 10m  0s{color} | {color:green} hadoop-mapreduce-client-app in the patch passed. {color} |
| {color:green}+1{color} | {color:green} unit {color} | {color:green}  3m 29s{color} | {color:green} hadoop-mapreduce-client-hs in the patch passed. {color} |
| {color:green}+1{color} | {color:green} unit {color} | {color:green}113m 32s{color} | {color:green} hadoop-mapreduce-client-jobclient in the patch passed. {color} |
| {color:green}+1{color} | {color:green} unit {color} | {color:green} 15m  3s{color} | {color:green} hadoop-mapreduce-client-nativetask in the patch passed. {color} |
| {color:green}+1{color} | {color:green} unit {color} | {color:green}  1m 20s{color} | {color:green} hadoop-mapreduce-examples in the patch passed. {color} |
| {color:green}+1{color} | {color:green} unit {color} | {color:green}  8m 12s{color} | {color:green} hadoop-streaming in the patch passed. {color} |
| {color:green}+1{color} | {color:green} unit {color} | {color:green}  0m 59s{color} | {color:green} hadoop-datajoin in the patch passed. {color} |
| {color:green}+1{color} | {color:green} unit {color} | {color:green}  1m 32s{color} | {color:green} hadoop-extras in the patch passed. {color} |
| {color:green}+1{color} | {color:green} unit {color} | {color:green}  1m  2s{color} | {color:green} hadoop-aws in the patch passed. {color} |
| {color:green}+1{color} | {color:green} unit {color} | {color:green}  3m  7s{color} | {color:green} hadoop-azure in the patch passed. {color} |
| {color:green}+1{color} | {color:green} unit {color} | {color:green}  4m 18s{color} | {color:green} hadoop-azure-datalake in the patch passed. {color} |
| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  1m  9s{color} | {color:green} The patch does not generate ASF License warnings. {color} |
| {color:black}{color} | {color:black} {color} | {color:black}446m 49s{color} | {color:black} {color} |
\\
\\
|| Reason || Tests ||
| Failed junit tests | hadoop.security.TestRaceWhenRelogin |
|   | hadoop.ipc.TestRPC |
|   | hadoop.hdfs.TestDFSStripedOutputStreamWithFailure160 |
|   | hadoop.hdfs.server.datanode.TestDataNodeVolumeFailure |
|   | hadoop.hdfs.TestRollingUpgrade |
|   | hadoop.hdfs.TestReconstructStripedFile |
|   | hadoop.hdfs.server.datanode.TestDataNodeVolumeFailureReporting |
|   | hadoop.hdfs.server.datanode.fsdataset.impl.TestLazyPersistReplicaRecovery |
|   | hadoop.metrics2.sink.TestRollingFileSystemSinkWithHdfs |
| Timed out junit tests | org.apache.hadoop.hdfs.TestLeaseRecovery2 |
\\
\\
|| Subsystem || Report/Notes ||
| Docker |  Image:yetus/hadoop:14b5c93 |
| JIRA Issue | HADOOP-14729 |
| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12882229/HADOOP-14729.007.patch |
| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  findbugs  checkstyle  |
| uname | Linux 2241aca7cc9e 3.13.0-119-generic #166-Ubuntu SMP Wed May 3 12:18:55 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux |
| Build tool | maven |
| Personality | /testptch/hadoop/patchprocess/precommit/personality/provided.sh |
| git revision | trunk / ab051bd |
| Default Java | 1.8.0_144 |
| findbugs | v3.1.0-RC1 |
| checkstyle | https://builds.apache.org/job/PreCommit-HADOOP-Build/13053/artifact/patchprocess/diff-checkstyle-root.txt |
| unit | https://builds.apache.org/job/PreCommit-HADOOP-Build/13053/artifact/patchprocess/patch-unit-hadoop-common-project_hadoop-common.txt |
| unit | https://builds.apache.org/job/PreCommit-HADOOP-Build/13053/artifact/patchprocess/patch-unit-hadoop-hdfs-project_hadoop-hdfs.txt |
|  Test Results | https://builds.apache.org/job/PreCommit-HADOOP-Build/13053/testReport/ |
| modules | C: hadoop-common-project/hadoop-common hadoop-hdfs-project/hadoop-hdfs hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-web-proxy hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-common hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-hs hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-nativetask hadoop-mapreduce-project/hadoop-mapreduce-examples hadoop-tools/hadoop-streaming hadoop-tools/hadoop-datajoin hadoop-tools/hadoop-extras hadoop-tools/hadoop-aws hadoop-tools/hadoop-azure hadoop-tools/hadoop-azure-datalake U: . |
| Console output | https://builds.apache.org/job/PreCommit-HADOOP-Build/13053/console |
| Powered by | Apache Yetus 0.6.0-SNAPSHOT   http://yetus.apache.org |


This message was automatically generated.

","21/Aug/17 05:26;aajisaka;Thanks [~ajayydv] for providing the patches! My comments:

* TestConfiguration#testSetPattern and #testGetClassByNameOrNull - missing @Test annotations.
* TestDU#testDUGetUsedWillNotReturnNegative - missing @Test annotation.
* TestGetFileBlockLocations#setup and #teardown - javadoc can be removed.
* TestTrash#testPluggableTrash and #performanceTestDeleteSameFile - missing @Test annotation.
* TestTrash#teardown - javadoc can be removed.
* Would you undo the change in the following class since the classes are already migrated to JUnit 4 style? :
** ViewFileSystemBaseTest
** TestActiveStandbyElectorRealZK
** TestArrayWritable
** TestWritable
** TestCodec
** TestTFileJClassComparatorByteArrays
** TestTFileLzoCodecsByteArrays
** TestTFileLzoCodecsStreams
** TestTFileNoneCodecsByteArrays
** TestTFileNoneCodecsJClassComparatorByteArrays
** TestTFileNoneCodecsStreams
** TestIPC
** TestDelegationToken
** TestTaskAttempt
** TestMapFileOutputFormat (Nice catch! Missing @After is a bug, should be addressed in a separate jira.)
** TestJobInfo
** TestInputPath
** TestMiniMRClasspath
** TestAdlFileContextMainOperationsLive

* org.apache.hadoop.mapred.TestFileOutputCommitter#testRecoveryV1 - missing @Test annotation.
* org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter#testCommitterWithDuplicatedCommitV1 and testMapFileOutputCommitterV2 - missing @Test annotations.
* TestIndexCache#testCreateRace - missing @Test annotation.
* TestJobEndNotifier#testLocalJobRunnerUriSubstitution, testLocalJobRunnerRetryCount, and testNotificationTimeout - missing @Test annotations.
* TestMRCJCFileOutputCommitter#testFailAbort - missing @Test annotation.
* Please do not modify the ASF license header in TestLongLong.","21/Aug/17 19:46;ajayydv;[~ajisakaa], thanks for detailed review. I missed some changes you suggested in patch 008. Will upload new one with suggested changes.","21/Aug/17 20:40;ajayydv;[~ajisakaa],[~arpitagarwal] Attached new patch (HADOOP-14729.009.patch) with all suggested changes. Please review when possible.","22/Aug/17 01:36;hadoopqa;| (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 18s{color} | {color:blue} Docker mode activated. {color} |
|| || || || {color:brown} Prechecks {color} ||
| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |
| {color:green}+1{color} | {color:green} test4tests {color} | {color:green}  0m  1s{color} | {color:green} The patch appears to include 76 new or modified test files. {color} |
|| || || || {color:brown} trunk Compile Tests {color} ||
| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  1m 30s{color} | {color:blue} Maven dependency ordering for branch {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 20m 24s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 21m 37s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  2m 46s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green} 11m 35s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green} 16m 57s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 10m 24s{color} | {color:green} trunk passed {color} |
|| || || || {color:brown} Patch Compile Tests {color} ||
| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  0m 22s{color} | {color:blue} Maven dependency ordering for patch {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 11m 28s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 18m 19s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javac {color} | {color:green} 18m 19s{color} | {color:green} root generated 0 new + 1295 unchanged - 2 fixed = 1295 total (was 1297) {color} |
| {color:orange}-0{color} | {color:orange} checkstyle {color} | {color:orange}  3m 24s{color} | {color:orange} root: The patch generated 42 new + 1136 unchanged - 110 fixed = 1178 total (was 1246) {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green} 16m  4s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green} 20m 17s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  9m 30s{color} | {color:green} the patch passed {color} |
|| || || || {color:brown} Other Tests {color} ||
| {color:red}-1{color} | {color:red} unit {color} | {color:red} 10m 12s{color} | {color:red} hadoop-common in the patch failed. {color} |
| {color:red}-1{color} | {color:red} unit {color} | {color:red} 68m 52s{color} | {color:red} hadoop-hdfs in the patch failed. {color} |
| {color:green}+1{color} | {color:green} unit {color} | {color:green}  1m 51s{color} | {color:green} hadoop-yarn-server-web-proxy in the patch passed. {color} |
| {color:green}+1{color} | {color:green} unit {color} | {color:green}  4m 21s{color} | {color:green} hadoop-mapreduce-client-core in the patch passed. {color} |
| {color:green}+1{color} | {color:green} unit {color} | {color:green}  1m 34s{color} | {color:green} hadoop-mapreduce-client-common in the patch passed. {color} |
| {color:green}+1{color} | {color:green} unit {color} | {color:green} 12m 42s{color} | {color:green} hadoop-mapreduce-client-app in the patch passed. {color} |
| {color:green}+1{color} | {color:green} unit {color} | {color:green}  5m 38s{color} | {color:green} hadoop-mapreduce-client-hs in the patch passed. {color} |
| {color:green}+1{color} | {color:green} unit {color} | {color:green}120m 50s{color} | {color:green} hadoop-mapreduce-client-jobclient in the patch passed. {color} |
| {color:green}+1{color} | {color:green} unit {color} | {color:green} 12m  4s{color} | {color:green} hadoop-mapreduce-client-nativetask in the patch passed. {color} |
| {color:green}+1{color} | {color:green} unit {color} | {color:green}  1m 49s{color} | {color:green} hadoop-mapreduce-examples in the patch passed. {color} |
| {color:green}+1{color} | {color:green} unit {color} | {color:green}  8m 40s{color} | {color:green} hadoop-streaming in the patch passed. {color} |
| {color:green}+1{color} | {color:green} unit {color} | {color:green}  1m  4s{color} | {color:green} hadoop-datajoin in the patch passed. {color} |
| {color:green}+1{color} | {color:green} unit {color} | {color:green}  1m 34s{color} | {color:green} hadoop-extras in the patch passed. {color} |
| {color:green}+1{color} | {color:green} unit {color} | {color:green}  1m 11s{color} | {color:green} hadoop-aws in the patch passed. {color} |
| {color:green}+1{color} | {color:green} unit {color} | {color:green}  3m 52s{color} | {color:green} hadoop-azure in the patch passed. {color} |
| {color:green}+1{color} | {color:green} unit {color} | {color:green}  4m 42s{color} | {color:green} hadoop-azure-datalake in the patch passed. {color} |
| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  1m  8s{color} | {color:green} The patch does not generate ASF License warnings. {color} |
| {color:black}{color} | {color:black} {color} | {color:black}455m 25s{color} | {color:black} {color} |
\\
\\
|| Reason || Tests ||
| Failed junit tests | hadoop.io.TestWritable |
|   | hadoop.hdfs.server.datanode.TestDataNodeMultipleRegistrations |
|   | hadoop.hdfs.server.datanode.TestDataNodeVolumeFailure |
|   | hadoop.hdfs.server.datanode.TestDirectoryScanner |
|   | hadoop.hdfs.server.namenode.ha.TestHAAppend |
|   | hadoop.hdfs.server.blockmanagement.TestNameNodePrunesMissingStorages |
|   | hadoop.hdfs.server.datanode.TestDataNodeVolumeFailureReporting |
|   | hadoop.hdfs.server.namenode.metrics.TestNameNodeMetrics |
|   | hadoop.hdfs.TestDFSStripedOutputStreamWithFailure140 |
| Timed out junit tests | org.apache.hadoop.hdfs.TestDFSStripedOutputStreamWithFailure190 |
|   | org.apache.hadoop.hdfs.server.blockmanagement.TestBlockStatsMXBean |
|   | org.apache.hadoop.hdfs.server.balancer.TestBalancer |
|   | org.apache.hadoop.hdfs.TestDataTransferProtocol |
\\
\\
|| Subsystem || Report/Notes ||
| Docker |  Image:yetus/hadoop:14b5c93 |
| JIRA Issue | HADOOP-14729 |
| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12882924/HADOOP-14729.008.patch |
| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  findbugs  checkstyle  |
| uname | Linux 996b0a84f04a 3.13.0-116-generic #163-Ubuntu SMP Fri Mar 31 14:13:22 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux |
| Build tool | maven |
| Personality | /testptch/hadoop/patchprocess/precommit/personality/provided.sh |
| git revision | trunk / 267e19a |
| Default Java | 1.8.0_144 |
| findbugs | v3.1.0-RC1 |
| checkstyle | https://builds.apache.org/job/PreCommit-HADOOP-Build/13083/artifact/patchprocess/diff-checkstyle-root.txt |
| unit | https://builds.apache.org/job/PreCommit-HADOOP-Build/13083/artifact/patchprocess/patch-unit-hadoop-common-project_hadoop-common.txt |
| unit | https://builds.apache.org/job/PreCommit-HADOOP-Build/13083/artifact/patchprocess/patch-unit-hadoop-hdfs-project_hadoop-hdfs.txt |
|  Test Results | https://builds.apache.org/job/PreCommit-HADOOP-Build/13083/testReport/ |
| modules | C: hadoop-common-project/hadoop-common hadoop-hdfs-project/hadoop-hdfs hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-web-proxy hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-common hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-app hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-hs hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-nativetask hadoop-mapreduce-project/hadoop-mapreduce-examples hadoop-tools/hadoop-streaming hadoop-tools/hadoop-datajoin hadoop-tools/hadoop-extras hadoop-tools/hadoop-aws hadoop-tools/hadoop-azure hadoop-tools/hadoop-azure-datalake U: . |
| Console output | https://builds.apache.org/job/PreCommit-HADOOP-Build/13083/console |
| Powered by | Apache Yetus 0.6.0-SNAPSHOT   http://yetus.apache.org |


This message was automatically generated.

","22/Aug/17 01:56;hadoopqa;| (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 18s{color} | {color:blue} Docker mode activated. {color} |
|| || || || {color:brown} Prechecks {color} ||
| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |
| {color:green}+1{color} | {color:green} test4tests {color} | {color:green}  0m  0s{color} | {color:green} The patch appears to include 58 new or modified test files. {color} |
|| || || || {color:brown} trunk Compile Tests {color} ||
| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  0m 17s{color} | {color:blue} Maven dependency ordering for branch {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 15m 39s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 16m 12s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  2m 11s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  6m 43s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  8m 17s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  5m 12s{color} | {color:green} trunk passed {color} |
|| || || || {color:brown} Patch Compile Tests {color} ||
| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  0m 17s{color} | {color:blue} Maven dependency ordering for patch {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  4m 56s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 13m  2s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javac {color} | {color:green} 13m  2s{color} | {color:green} root generated 0 new + 1295 unchanged - 2 fixed = 1295 total (was 1297) {color} |
| {color:orange}-0{color} | {color:orange} checkstyle {color} | {color:orange}  2m 17s{color} | {color:orange} root: The patch generated 41 new + 779 unchanged - 90 fixed = 820 total (was 869) {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  7m 15s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green} 11m 20s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  5m 46s{color} | {color:green} the patch passed {color} |
|| || || || {color:brown} Other Tests {color} ||
| {color:red}-1{color} | {color:red} unit {color} | {color:red}  8m 31s{color} | {color:red} hadoop-common in the patch failed. {color} |
| {color:green}+1{color} | {color:green} unit {color} | {color:green}  0m 37s{color} | {color:green} hadoop-yarn-server-web-proxy in the patch passed. {color} |
| {color:green}+1{color} | {color:green} unit {color} | {color:green}  2m 56s{color} | {color:green} hadoop-mapreduce-client-core in the patch passed. {color} |
| {color:green}+1{color} | {color:green} unit {color} | {color:green}  0m 56s{color} | {color:green} hadoop-mapreduce-client-common in the patch passed. {color} |
| {color:green}+1{color} | {color:green} unit {color} | {color:green}109m 10s{color} | {color:green} hadoop-mapreduce-client-jobclient in the patch passed. {color} |
| {color:green}+1{color} | {color:green} unit {color} | {color:green} 12m 12s{color} | {color:green} hadoop-mapreduce-client-nativetask in the patch passed. {color} |
| {color:green}+1{color} | {color:green} unit {color} | {color:green}  1m 21s{color} | {color:green} hadoop-mapreduce-examples in the patch passed. {color} |
| {color:green}+1{color} | {color:green} unit {color} | {color:green}  6m 46s{color} | {color:green} hadoop-streaming in the patch passed. {color} |
| {color:green}+1{color} | {color:green} unit {color} | {color:green}  0m 44s{color} | {color:green} hadoop-datajoin in the patch passed. {color} |
| {color:green}+1{color} | {color:green} unit {color} | {color:green}  1m 10s{color} | {color:green} hadoop-extras in the patch passed. {color} |
| {color:green}+1{color} | {color:green} unit {color} | {color:green}  0m 50s{color} | {color:green} hadoop-aws in the patch passed. {color} |
| {color:green}+1{color} | {color:green} unit {color} | {color:green}  2m 40s{color} | {color:green} hadoop-azure in the patch passed. {color} |
| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 47s{color} | {color:green} The patch does not generate ASF License warnings. {color} |
| {color:black}{color} | {color:black} {color} | {color:black}272m 51s{color} | {color:black} {color} |
\\
\\
|| Reason || Tests ||
| Failed junit tests | hadoop.fs.TestTrash |
\\
\\
|| Subsystem || Report/Notes ||
| Docker |  Image:yetus/hadoop:14b5c93 |
| JIRA Issue | HADOOP-14729 |
| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12882971/HADOOP-14729.009.patch |
| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  findbugs  checkstyle  |
| uname | Linux 2b1ff604c5cd 3.13.0-119-generic #166-Ubuntu SMP Wed May 3 12:18:55 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux |
| Build tool | maven |
| Personality | /testptch/hadoop/patchprocess/precommit/personality/provided.sh |
| git revision | trunk / b6bfb2f |
| Default Java | 1.8.0_144 |
| findbugs | v3.1.0-RC1 |
| checkstyle | https://builds.apache.org/job/PreCommit-HADOOP-Build/13086/artifact/patchprocess/diff-checkstyle-root.txt |
| unit | https://builds.apache.org/job/PreCommit-HADOOP-Build/13086/artifact/patchprocess/patch-unit-hadoop-common-project_hadoop-common.txt |
|  Test Results | https://builds.apache.org/job/PreCommit-HADOOP-Build/13086/testReport/ |
| modules | C: hadoop-common-project/hadoop-common hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-web-proxy hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-common hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-nativetask hadoop-mapreduce-project/hadoop-mapreduce-examples hadoop-tools/hadoop-streaming hadoop-tools/hadoop-datajoin hadoop-tools/hadoop-extras hadoop-tools/hadoop-aws hadoop-tools/hadoop-azure U: . |
| Console output | https://builds.apache.org/job/PreCommit-HADOOP-Build/13086/console |
| Powered by | Apache Yetus 0.6.0-SNAPSHOT   http://yetus.apache.org |


This message was automatically generated.

","22/Aug/17 08:38;aajisaka;Thank you for updating the patch, [~ajayydv]! My comments:

* Would you remove @Test from TestTrash#performanceTestDeleteSameFile since this should not be run as a unit test? Sorry for back and forth.
* Would you undo the change in TestActiveStandbyElectorRealZK and TestWritableName since the classes are already migrated to JUnit 4 style?
* org.apache.hadoop.mapreduce.lib.output.TestFileOutputCommitter#testMapFileOutputCommitterV2 - missing @Test annotation.","22/Aug/17 18:35;ajayydv;[~ajisakaa] thanks for review. Updated patch with suggested changes.","22/Aug/17 23:01;hadoopqa;| (/) *{color:green}+1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 21s{color} | {color:blue} Docker mode activated. {color} |
|| || || || {color:brown} Prechecks {color} ||
| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |
| {color:green}+1{color} | {color:green} test4tests {color} | {color:green}  0m  0s{color} | {color:green} The patch appears to include 56 new or modified test files. {color} |
|| || || || {color:brown} trunk Compile Tests {color} ||
| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  1m 36s{color} | {color:blue} Maven dependency ordering for branch {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 15m  6s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 14m 53s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  2m 10s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  6m 42s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  8m 27s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  5m  0s{color} | {color:green} trunk passed {color} |
|| || || || {color:brown} Patch Compile Tests {color} ||
| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  0m 16s{color} | {color:blue} Maven dependency ordering for patch {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  4m 33s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 11m 14s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javac {color} | {color:green} 11m 14s{color} | {color:green} root generated 0 new + 1289 unchanged - 2 fixed = 1289 total (was 1291) {color} |
| {color:orange}-0{color} | {color:orange} checkstyle {color} | {color:orange}  2m 15s{color} | {color:orange} root: The patch generated 41 new + 771 unchanged - 89 fixed = 812 total (was 860) {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  7m 13s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green} 11m 23s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  9m 24s{color} | {color:green} the patch passed {color} |
|| || || || {color:brown} Other Tests {color} ||
| {color:green}+1{color} | {color:green} unit {color} | {color:green}  8m  7s{color} | {color:green} hadoop-common in the patch passed. {color} |
| {color:green}+1{color} | {color:green} unit {color} | {color:green}  0m 42s{color} | {color:green} hadoop-yarn-server-web-proxy in the patch passed. {color} |
| {color:green}+1{color} | {color:green} unit {color} | {color:green}  2m 50s{color} | {color:green} hadoop-mapreduce-client-core in the patch passed. {color} |
| {color:green}+1{color} | {color:green} unit {color} | {color:green}  0m 56s{color} | {color:green} hadoop-mapreduce-client-common in the patch passed. {color} |
| {color:green}+1{color} | {color:green} unit {color} | {color:green} 98m 20s{color} | {color:green} hadoop-mapreduce-client-jobclient in the patch passed. {color} |
| {color:green}+1{color} | {color:green} unit {color} | {color:green}  9m 53s{color} | {color:green} hadoop-mapreduce-client-nativetask in the patch passed. {color} |
| {color:green}+1{color} | {color:green} unit {color} | {color:green}  0m 51s{color} | {color:green} hadoop-mapreduce-examples in the patch passed. {color} |
| {color:green}+1{color} | {color:green} unit {color} | {color:green}  5m 53s{color} | {color:green} hadoop-streaming in the patch passed. {color} |
| {color:green}+1{color} | {color:green} unit {color} | {color:green}  0m 43s{color} | {color:green} hadoop-datajoin in the patch passed. {color} |
| {color:green}+1{color} | {color:green} unit {color} | {color:green}  1m  5s{color} | {color:green} hadoop-extras in the patch passed. {color} |
| {color:green}+1{color} | {color:green} unit {color} | {color:green}  0m 42s{color} | {color:green} hadoop-aws in the patch passed. {color} |
| {color:green}+1{color} | {color:green} unit {color} | {color:green}  2m 28s{color} | {color:green} hadoop-azure in the patch passed. {color} |
| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 45s{color} | {color:green} The patch does not generate ASF License warnings. {color} |
| {color:black}{color} | {color:black} {color} | {color:black}260m 39s{color} | {color:black} {color} |
\\
\\
|| Subsystem || Report/Notes ||
| Docker |  Image:yetus/hadoop:14b5c93 |
| JIRA Issue | HADOOP-14729 |
| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12883161/HADOOP-14729.010.patch |
| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  findbugs  checkstyle  |
| uname | Linux 871b4adf1045 3.13.0-119-generic #166-Ubuntu SMP Wed May 3 12:18:55 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux |
| Build tool | maven |
| Personality | /testptch/hadoop/patchprocess/precommit/personality/provided.sh |
| git revision | trunk / 657dd59 |
| Default Java | 1.8.0_144 |
| findbugs | v3.1.0-RC1 |
| checkstyle | https://builds.apache.org/job/PreCommit-HADOOP-Build/13095/artifact/patchprocess/diff-checkstyle-root.txt |
|  Test Results | https://builds.apache.org/job/PreCommit-HADOOP-Build/13095/testReport/ |
| modules | C: hadoop-common-project/hadoop-common hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-web-proxy hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-common hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-nativetask hadoop-mapreduce-project/hadoop-mapreduce-examples hadoop-tools/hadoop-streaming hadoop-tools/hadoop-datajoin hadoop-tools/hadoop-extras hadoop-tools/hadoop-aws hadoop-tools/hadoop-azure U: . |
| Console output | https://builds.apache.org/job/PreCommit-HADOOP-Build/13095/console |
| Powered by | Apache Yetus 0.6.0-SNAPSHOT   http://yetus.apache.org |


This message was automatically generated.

","23/Aug/17 07:26;aajisaka;LGTM, +1. I'll commit this tomorrow if there are no objection.","23/Aug/17 16:36;stevel@apache.org;Has anyone tested the azure stuff? 

If not, I'm go ask for those changes to be kept out on the general ""no changes to WASB without a full test run"" policy.

In HADOOP-14553 we've been moving everything to a test/integration test setup; I'd really like to do the changes in there. It brings the test run down to <15 minutes, which means the ""test before you submit a patch"" policy is viable","23/Aug/17 19:11;hadoopqa;| (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m  0s{color} | {color:blue} Docker mode activated. {color} |
| {color:red}-1{color} | {color:red} patch {color} | {color:red}  0m  6s{color} | {color:red} HADOOP-14729 does not apply to trunk. Rebase required? Wrong Branch? See https://wiki.apache.org/hadoop/HowToContribute for help. {color} |
\\
\\
|| Subsystem || Report/Notes ||
| JIRA Issue | HADOOP-14729 |
| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12883387/HADOOP-14729.011.patch |
| Console output | https://builds.apache.org/job/PreCommit-HADOOP-Build/13100/console |
| Powered by | Apache Yetus 0.6.0-SNAPSHOT   http://yetus.apache.org |


This message was automatically generated.

","23/Aug/17 19:12;ajayydv;[~stevel@apache.org], Revereted back changes for azure and s3 test class. Jira to track upgrade for TestS3NInMemoryFileSystem. [HADOOP-14803]","24/Aug/17 00:02;hadoopqa;| (/) *{color:green}+1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 18s{color} | {color:blue} Docker mode activated. {color} |
|| || || || {color:brown} Prechecks {color} ||
| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |
| {color:green}+1{color} | {color:green} test4tests {color} | {color:green}  0m  0s{color} | {color:green} The patch appears to include 53 new or modified test files. {color} |
|| || || || {color:brown} trunk Compile Tests {color} ||
| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  1m 42s{color} | {color:blue} Maven dependency ordering for branch {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 16m 49s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 17m 18s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  2m 19s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  6m  8s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  7m 37s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  4m 35s{color} | {color:green} trunk passed {color} |
|| || || || {color:brown} Patch Compile Tests {color} ||
| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  0m 18s{color} | {color:blue} Maven dependency ordering for patch {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  4m  9s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 13m 42s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javac {color} | {color:green} 13m 42s{color} | {color:green} root generated 0 new + 1289 unchanged - 2 fixed = 1289 total (was 1291) {color} |
| {color:orange}-0{color} | {color:orange} checkstyle {color} | {color:orange}  2m 14s{color} | {color:orange} root: The patch generated 43 new + 703 unchanged - 97 fixed = 746 total (was 800) {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  6m  6s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  9m  4s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  4m 54s{color} | {color:green} the patch passed {color} |
|| || || || {color:brown} Other Tests {color} ||
| {color:green}+1{color} | {color:green} unit {color} | {color:green}  8m 51s{color} | {color:green} hadoop-common in the patch passed. {color} |
| {color:green}+1{color} | {color:green} unit {color} | {color:green}  0m 37s{color} | {color:green} hadoop-yarn-server-web-proxy in the patch passed. {color} |
| {color:green}+1{color} | {color:green} unit {color} | {color:green}  2m 54s{color} | {color:green} hadoop-mapreduce-client-core in the patch passed. {color} |
| {color:green}+1{color} | {color:green} unit {color} | {color:green}  0m 57s{color} | {color:green} hadoop-mapreduce-client-common in the patch passed. {color} |
| {color:green}+1{color} | {color:green} unit {color} | {color:green} 98m 18s{color} | {color:green} hadoop-mapreduce-client-jobclient in the patch passed. {color} |
| {color:green}+1{color} | {color:green} unit {color} | {color:green}  9m 32s{color} | {color:green} hadoop-mapreduce-client-nativetask in the patch passed. {color} |
| {color:green}+1{color} | {color:green} unit {color} | {color:green}  0m 51s{color} | {color:green} hadoop-mapreduce-examples in the patch passed. {color} |
| {color:green}+1{color} | {color:green} unit {color} | {color:green}  5m 42s{color} | {color:green} hadoop-streaming in the patch passed. {color} |
| {color:green}+1{color} | {color:green} unit {color} | {color:green}  0m 44s{color} | {color:green} hadoop-datajoin in the patch passed. {color} |
| {color:green}+1{color} | {color:green} unit {color} | {color:green}  1m  4s{color} | {color:green} hadoop-extras in the patch passed. {color} |
| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 49s{color} | {color:green} The patch does not generate ASF License warnings. {color} |
| {color:black}{color} | {color:black} {color} | {color:black}251m 38s{color} | {color:black} {color} |
\\
\\
|| Subsystem || Report/Notes ||
| Docker |  Image:yetus/hadoop:14b5c93 |
| JIRA Issue | HADOOP-14729 |
| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12883393/HADOOP-14729.012.patch |
| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  findbugs  checkstyle  |
| uname | Linux cc5bc467a3f8 3.13.0-119-generic #166-Ubuntu SMP Wed May 3 12:18:55 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux |
| Build tool | maven |
| Personality | /testptch/hadoop/patchprocess/precommit/personality/provided.sh |
| git revision | trunk / 7e6463d |
| Default Java | 1.8.0_144 |
| findbugs | v3.1.0-RC1 |
| checkstyle | https://builds.apache.org/job/PreCommit-HADOOP-Build/13101/artifact/patchprocess/diff-checkstyle-root.txt |
|  Test Results | https://builds.apache.org/job/PreCommit-HADOOP-Build/13101/testReport/ |
| modules | C: hadoop-common-project/hadoop-common hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-web-proxy hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-common hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-nativetask hadoop-mapreduce-project/hadoop-mapreduce-examples hadoop-tools/hadoop-streaming hadoop-tools/hadoop-datajoin hadoop-tools/hadoop-extras U: . |
| Console output | https://builds.apache.org/job/PreCommit-HADOOP-Build/13101/console |
| Powered by | Apache Yetus 0.6.0-SNAPSHOT   http://yetus.apache.org |


This message was automatically generated.

","24/Aug/17 10:50;stevel@apache.org;Thanks. FWIW I wasn't worried about S3n, as I don't worry about S3n...we're thinking there about ""how to remove it completely""","24/Aug/17 20:24;arp;+1 for the v12 patch.

I will hold off committing until tomorrow in case Akira or Steve have further comments.
","24/Aug/17 20:55;stevel@apache.org;LGTM","24/Aug/17 22:08;ajayydv;[~arpitagarwal],[~stevel@apache.org] thanks for review.","25/Aug/17 16:57;arp;I've committed this. Thanks for taking on this tedious task [~ajayydv].

Thanks Akira, Steve for the code reviews.","25/Aug/17 17:23;hudson;SUCCESS: Integrated in Jenkins build Hadoop-trunk-Commit #12241 (See [https://builds.apache.org/job/Hadoop-trunk-Commit/12241/])
HADOOP-14729. Upgrade JUnit 3 test cases to JUnit 4. Contributed by Ajay (arp: rev 8b7cbe3840f1a4f4dc038ac3018a4f0dbe3bc82d)
* (edit) hadoop-tools/hadoop-extras/src/test/java/org/apache/hadoop/tools/TestDistCh.java
* (edit) hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/util/TestFileBasedIPList.java
* (edit) hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/conf/TestDeprecatedKeys.java
* (edit) hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/test/java/org/apache/hadoop/mapreduce/lib/output/TestFileOutputCommitter.java
* (edit) hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-nativetask/src/test/java/org/apache/hadoop/mapred/nativetask/buffer/TestOutputBuffer.java
* (edit) hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/TestDU.java
* (edit) hadoop-tools/hadoop-streaming/src/test/java/org/apache/hadoop/typedbytes/TestTypedBytesWritable.java
* (edit) hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-nativetask/src/test/java/org/apache/hadoop/mapred/nativetask/utils/TestSizedWritable.java
* (edit) hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/net/TestScriptBasedMappingWithDependency.java
* (edit) hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/log/TestLog4Json.java
* (edit) hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/test/java/org/apache/hadoop/mapreduce/lib/input/TestDelegatingInputFormat.java
* (edit) hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/security/token/TestToken.java
* (edit) hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/util/TestFindClass.java
* (edit) hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/TestGetFileBlockLocations.java
* (edit) hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/TestFilterFs.java
* (edit) hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/util/TestGenericsUtil.java
* (edit) hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-common/src/test/java/org/apache/hadoop/mapred/TestMRWithDistributedCache.java
* (edit) hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/conf/TestConfigurationSubclass.java
* (edit) hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/net/TestScriptBasedMapping.java
* (edit) hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/security/TestAuthenticationFilter.java
* (edit) hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-nativetask/src/test/java/org/apache/hadoop/mapred/nativetask/buffer/TestInputBuffer.java
* (edit) hadoop-mapreduce-project/hadoop-mapreduce-examples/src/test/java/org/apache/hadoop/examples/pi/math/TestModular.java
* (edit) hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/util/TestNativeLibraryChecker.java
* (edit) hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/test/java/org/apache/hadoop/mapred/TestFileOutputCommitter.java
* (edit) hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-web-proxy/src/test/java/org/apache/hadoop/yarn/server/webproxy/amfilter/TestAmFilterInitializer.java
* (edit) hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/test/java/org/apache/hadoop/mapreduce/lib/jobcontrol/TestMapReduceJobControl.java
* (edit) hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-nativetask/src/test/java/org/apache/hadoop/mapred/nativetask/TestTaskContext.java
* (edit) hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/conf/TestGetInstances.java
* (edit) hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/test/java/org/apache/hadoop/mapred/TestJobEndNotifier.java
* (edit) hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/TestTrash.java
* (edit) hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/permission/TestFsPermission.java
* (edit) hadoop-mapreduce-project/hadoop-mapreduce-examples/src/test/java/org/apache/hadoop/examples/pi/math/TestSummation.java
* (edit) hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/util/TestAsyncDiskService.java
* (edit) hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/TestTruncatedInputBug.java
* (edit) hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/test/java/org/apache/hadoop/mapreduce/lib/output/TestFileOutputFormat.java
* (edit) hadoop-mapreduce-project/hadoop-mapreduce-examples/src/test/java/org/apache/hadoop/examples/pi/math/TestLongLong.java
* (edit) hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/test/java/org/apache/hadoop/mapred/jobcontrol/TestJobControl.java
* (edit) hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/security/TestWhitelistBasedResolver.java
* (edit) hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/test/java/org/apache/hadoop/mapreduce/TestJobMonitorAndPrint.java
* (edit) hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/test/java/org/apache/hadoop/mapreduce/lib/output/TestMRCJCFileOutputCommitter.java
* (edit) hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-nativetask/src/test/java/org/apache/hadoop/mapred/nativetask/serde/TestKVSerializer.java
* (edit) hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/conf/TestConfiguration.java
* (edit) hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/security/TestAuthenticationWithProxyUserFilter.java
* (edit) hadoop-tools/hadoop-datajoin/src/test/java/org/apache/hadoop/contrib/utils/join/TestDataJoin.java
* (edit) hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-nativetask/src/test/java/org/apache/hadoop/mapred/nativetask/utils/TestReadWriteBuffer.java
* (edit) hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/TestAvroFSInput.java
* (edit) hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/test/java/org/apache/hadoop/mapred/TestIndexCache.java
* (edit) hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/TestGlobExpander.java
* (edit) hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-jobclient/src/test/java/org/apache/hadoop/mapreduce/TestMapCollection.java
* (edit) hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/ipc/TestFairCallQueue.java
* (edit) hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/util/TestIndexedSort.java
* (edit) hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/util/TestCacheableIPList.java
* (edit) hadoop-mapreduce-project/hadoop-mapreduce-examples/src/test/java/org/apache/hadoop/examples/TestBaileyBorweinPlouffe.java
","26/Sep/17 00:24;ajayydv;[~ajisakaa] ,[~stevel@apache.org] thanks for reviewing tedious patch. [~arpitagarwal], thanks for review and commit.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
org.apache.hadoop.ipc.TestIPC fail,HADOOP-15929,13198156,Test,Open,HADOOP,Hadoop Common,software,omalley,Hadoop Common is the common library for Apache Hadoop.,http://hadoop.apache.org/,Major,,,elaineang,elaineang,13/Nov/18 21:14,13/Nov/18 21:16,12/Jan/21 11:55,,2.8.5,,,,,,,,,,common,,,,0,,,"The unit test for module **hadoop-common-project/hadoop-common (version 2.8.5 checkout from Github) failed.

Reproduce:
 # Clone [Hadoop Github reop|https://github.com/apache/hadoop] and checkout tag release-2.8.5-RC0
 # Compile & test
{noformat}
mvn clean compile 
cd hadoop-common-project/hadoop-common/
mvn test{noformat}

 

Below is the failed test log when running as non-root user.

 
{noformat}
Failed tests:
 TestSymlinkLocalFSFileSystem>TestSymlinkLocalFS.testSetTimesSymlinkToDir:233->SymlinkBaseTest.testSetTimesSymlinkToDir:1395 expected:<3000> but was:<1542140218000>
 TestIPC.testUserBinding:1495->checkUserBinding:1516
Wanted but not invoked:
socket.bind(OptiPlex/127.0.1.1:0);
-> at org.apache.hadoop.ipc.TestIPC.checkUserBinding(TestIPC.java:1516)

However, there were other interactions with this mock:
-> at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:645)
-> at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:646)
-> at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:515)
-> at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:529)
-> at org.apache.hadoop.ipc.Client$Connection.closeConnection(Client.java:872)

 TestIPC.testProxyUserBinding:1500->checkUserBinding:1516
Wanted but not invoked:
socket.bind(OptiPlex/127.0.1.1:0);
-> at org.apache.hadoop.ipc.TestIPC.checkUserBinding(TestIPC.java:1516)

However, there were other interactions with this mock:
-> at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:645)
-> at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:646)
-> at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:515)
-> at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:529)
-> at org.apache.hadoop.ipc.Client$Connection.closeConnection(Client.java:872){noformat}
 

 Attached is a more verbosed test output.  [^org.apache.hadoop.ipc.TestIPC-output.txt]

^Suggestions regarding how to resolve this would be helpful.^",,elaineang,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"13/Nov/18 21:07;elaineang;org.apache.hadoop.ipc.TestIPC-output.txt;https://issues.apache.org/jira/secure/attachment/12948024/org.apache.hadoop.ipc.TestIPC-output.txt",,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,9223372036854775807,,,,,2018-11-13 21:14:48.0,,,,,,,"0|s00gag:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Some rack awareness question,HADOOP-15724,13183345,Test,Open,HADOOP,Hadoop Common,software,omalley,Hadoop Common is the common library for Apache Hadoop.,http://hadoop.apache.org/,Major,,,xuejipeng,xuejipeng,06/Sep/18 09:22,06/Sep/18 09:22,12/Jan/21 11:55,,,,,,,,,,,,,,,,0,,,"When I use the rack awareness, I stop all the machines in a rack, and then write the data and report the following error，I don't think this is a reasonable design
!image-2018-09-06-17-12-02-610.png!

I think the following design is more reasonable:
 can write, but only one replica, or can write, several copies on the same rack

I have some questions
 1. What's the difference when writing data, between rack awareness and no rack
 2. Join a rack awareness when a running cluster joins, will the old data be distributed to both racks?
Forgive me, I am not very familiar with java programming, can't understand the source code.",hadoop-2.5.2,xuejipeng,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"06/Sep/18 09:12;xuejipeng;image-2018-09-06-17-12-02-610.png;https://issues.apache.org/jira/secure/attachment/12938619/image-2018-09-06-17-12-02-610.png",,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,9223372036854775807,,,,,2018-09-06 09:22:46.0,,,,,,,"0|i3xslr:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Audit all of the findbugs excludes,HADOOP-11882,12824306,Test,Resolved,HADOOP,Hadoop Common,software,omalley,Hadoop Common is the common library for Apache Hadoop.,http://hadoop.apache.org/,Major,Won't Fix,,aw,aw,27/Apr/15 15:13,01/Sep/18 20:30,12/Jan/21 11:55,01/Sep/18 20:30,,,,,,,,,,,build,test,,,0,,,It would be worth while to verify that all of the exclusions listed still make sense/are real/etc.,,aw,cdouglas,gliptak,kiranmr,sekikn,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,2015-05-29 23:13:05.346,,,false,,,,,,,,,,,,,,,,,9223372036854775807,,,,,Fri May 29 23:13:05 UTC 2015,,,,,,,"0|i2dt7r:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,"29/May/15 23:13;gliptak;[~aw] Would you be also interested in patches to clean up Findbugs warnings?",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
testDanglingLink fails on OS X,HADOOP-13176,12970884,Test,Resolved,HADOOP,Hadoop Common,software,omalley,Hadoop Common is the common library for Apache Hadoop.,http://hadoop.apache.org/,Major,Won't Fix,,aw,aw,18/May/16 18:48,01/Sep/18 20:19,12/Jan/21 11:55,01/Sep/18 20:19,3.0.0-alpha1,,,,,,,,,,test,,,,0,,,"This test assumes that the list of groups is given in a certain order.  This is not the case on at least OS X 10.9, at least when the given user is an admin user.",,aajisaka,aw,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,9223372036854775807,,,,,Wed May 18 18:48:26 UTC 2016,,,,,,,"0|i2y60n:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,"18/May/16 18:48;aw;
Related test failures:

{code}
testDanglingLink(org.apache.hadoop.fs.TestSymlinkLocalFSFileContext)  Time elapsed: 0.226 sec  <<< FAILURE!
org.junit.ComparisonFailure: expected:<[admin]> but was:<[staff]>
	at org.junit.Assert.assertEquals(Assert.java:115)
	at org.junit.Assert.assertEquals(Assert.java:144)
	at org.apache.hadoop.fs.TestSymlinkLocalFS.testDanglingLink(TestSymlinkLocalFS.java:158)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)

Tests run: 63, Failures: 1, Errors: 0, Skipped: 7, Time elapsed: 10.236 sec <<< FAILURE! - in org.apache.hadoop.fs.TestSymlinkLocalFSFileSystem
testDanglingLink(org.apache.hadoop.fs.TestSymlinkLocalFSFileSystem)  Time elapsed: 0.097 sec  <<< FAILURE!
org.junit.ComparisonFailure: expected:<[admin]> but was:<[staff]>
	at org.junit.Assert.assertEquals(Assert.java:115)
	at org.junit.Assert.assertEquals(Assert.java:144)
	at org.apache.hadoop.fs.TestSymlinkLocalFS.testDanglingLink(TestSymlinkLocalFS.java:158)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)
{code}",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
TestCodec's sequenceFileCodecTest doesn't use correct directory,HADOOP-14664,13087476,Test,Resolved,HADOOP,Hadoop Common,software,omalley,Hadoop Common is the common library for Apache Hadoop.,http://hadoop.apache.org/,Major,Won't Fix,,aw,aw,17/Jul/17 04:59,01/Sep/18 20:11,12/Jan/21 11:55,01/Sep/18 20:11,3.0.0-beta1,,,,,,,,,,build,test,,,0,,,"While playing with OpenClover (HADOOP-14663), it doesn't appear that sequenceFileCodecTest in TestCodec.java is properly setting the working directory for the test files, resulting in test data running around in places it shouldn't.",,aajisaka,aw,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,9223372036854775807,,,,,2017-07-17 04:59:22.0,,,,,,,"0|i3hkvz:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Get a daily QBT run for Windows,HADOOP-14724,13091960,Test,Resolved,HADOOP,Hadoop Common,software,omalley,Hadoop Common is the common library for Apache Hadoop.,http://hadoop.apache.org/,Major,Fixed,aw,aw,aw,02/Aug/17 18:05,01/Sep/18 20:04,12/Jan/21 11:55,01/Sep/18 20:04,3.0.0-beta1,,,,,,,,,,test,,,,0,,,We used to have Windows as part of our testing infrastructure.  Let's get it back up and running now that the ASF has more boxes (and who knows what the status of the hadoop-win-1 box is),,aw,stevel@apache.org,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,HADOOP-12463,HADOOP-14667,INFRA-14627,HADOOP-14696,INFRA-14755,YETUS-534,INFRA-15010,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,2017-08-03 09:15:44.53,,,false,,,,,,,,,,,,,,,,,9223372036854775807,,,,,Sat Sep 01 20:04:03 UTC 2018,,,,,,,"0|i3ic3r:",9223372036854775807,,,,,,,,,,,,,3.2.0,,,,,,,,,,"02/Aug/17 18:07;aw;Here's the link to Jenkins:

https://builds.apache.org/view/H-L/view/Hadoop/job/hadoop-trunk-win
","03/Aug/17 09:15;stevel@apache.org;One problem I've hit in the past is MiniYarnCluster refusing to play as it couldn't lock down the permissions of some directories in the VMs. Is this going to bite us again? If so, we may need to add an option to disable those checks","15/Sep/17 21:30;aw;For posterity... added https://builds.apache.org/job/PreCommit-hadoop-win which allows patch testing on Windows.  ","17/Sep/17 19:00;aw;Looks like HADOOP-14869 just tipped us over the command line limit on Windows. :(

 https://builds.apache.org/job/hadoop-trunk-win/200/artifact/out/patch-mvninstall-root.txt

I'll try using setting a different mvn repo, but I don't have a lot of hope.  We desperately need MOJO-2044 in our build.","17/Sep/17 20:08;aw;OK, using F:\short\%JOBNAME% for the workspace got us over the hump.  But we're going to have to deal with this sooner rather than later.","01/Sep/18 20:04;aw;Was fixed for quite a while, now appears to be broken again. Oh well.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Add new test class to org.apache.hadoop.ipc.Client,HADOOP-8112,12544102,Test,Resolved,HADOOP,Hadoop Common,software,omalley,Hadoop Common is the common library for Apache Hadoop.,http://hadoop.apache.org/,Major,Won't Fix,,marblejenka,marblejenka,25/Feb/12 06:17,19/Jan/18 14:17,12/Jan/21 11:55,19/Jan/18 14:17,0.23.0,,,,,,,,,,ipc,,,,0,,,"Test class of org.apache.hadoop.ipc.Client dose not exists.

",,atm,boky01,sho.shimauchi,sureshms,tlipcon,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,2012-02-25 06:37:37.009,,,false,,,,,,,,,,,,,,,,,229340,,,,,Fri Jan 19 14:17:03 UTC 2018,,,,,,,"0|i07v3z:",43807,,,,,,,,,,,,,,,,,,,,,,,"25/Feb/12 06:37;sureshms;ipc.Client is tested through many a test cases, that test WritableRpcEngine, ProtobufRpcEngine etc. So I'm not sure what the intention of this Jira is?","19/Jan/18 14:17;boky01;{\{org.apache.hadoop.ipc.Client}} is tested through other classes.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
open(PathHandle) contract test should be exhaustive for default options,HADOOP-15117,13125026,Test,Resolved,HADOOP,Hadoop Common,software,omalley,Hadoop Common is the common library for Apache Hadoop.,http://hadoop.apache.org/,Major,Fixed,cdouglas,cdouglas,cdouglas,14/Dec/17 19:20,31/Dec/17 02:21,12/Jan/21 11:55,31/Dec/17 01:59,,,,,3.1.0,,,,,,,,,,0,,,"The current {{AbstractContractOpenTest}} covers many, but not all of the permutations of the default {{HandleOpt}}. It could also be refactored to be clearer as documentation",,cdouglas,elgoiri,hudson,nanda,stevel@apache.org,virajith,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,HADOOP-15106,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"27/Dec/17 02:04;cdouglas;HADOOP-15117.000.patch;https://issues.apache.org/jira/secure/attachment/12903749/HADOOP-15117.000.patch","28/Dec/17 23:10;cdouglas;HADOOP-15117.001.patch;https://issues.apache.org/jira/secure/attachment/12903953/HADOOP-15117.001.patch","29/Dec/17 18:07;cdouglas;HADOOP-15117.002.patch;https://issues.apache.org/jira/secure/attachment/12904033/HADOOP-15117.002.patch","30/Dec/17 01:43;cdouglas;HADOOP-15117.003.patch;https://issues.apache.org/jira/secure/attachment/12904049/HADOOP-15117.003.patch",,,,,,,,,,,,,,,,,,,,4.0,,,,,,,,,,,,,,,,,,,,2017-12-27 05:16:00.935,,,false,,,,,,,,,,,,,,,,,9223372036854775807,Reviewed,,,,Sun Dec 31 02:21:35 UTC 2017,,,,,,,"0|i3nx13:",9223372036854775807,,,,,,,,,,,,,3.1.0,,,,,,,,,,"27/Dec/17 02:05;cdouglas;Added a new contract test to validate the {{PathHandle}} defaults

/cc [~elgoiri], [~stevel@apache.org]","27/Dec/17 05:16;genericqa;| (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m  9s{color} | {color:blue} Docker mode activated. {color} |
|| || || || {color:brown} Prechecks {color} ||
| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |
| {color:green}+1{color} | {color:green} test4tests {color} | {color:green}  0m  0s{color} | {color:green} The patch appears to include 3 new or modified test files. {color} |
|| || || || {color:brown} trunk Compile Tests {color} ||
| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  0m 41s{color} | {color:blue} Maven dependency ordering for branch {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 16m 16s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 12m 51s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  2m  3s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  2m 56s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 15m 35s{color} | {color:green} branch has no errors when building and testing our client artifacts. {color} |
| {color:red}-1{color} | {color:red} findbugs {color} | {color:red}  1m 57s{color} | {color:red} hadoop-hdfs-project/hadoop-hdfs in trunk has 1 extant Findbugs warnings. {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  2m 21s{color} | {color:green} trunk passed {color} |
|| || || || {color:brown} Patch Compile Tests {color} ||
| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  0m 15s{color} | {color:blue} Maven dependency ordering for patch {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  2m 16s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 11m 38s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javac {color} | {color:green} 11m 38s{color} | {color:green} the patch passed {color} |
| {color:orange}-0{color} | {color:orange} checkstyle {color} | {color:orange}  2m  3s{color} | {color:orange} root: The patch generated 21 new + 7 unchanged - 0 fixed = 28 total (was 7) {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  2m 52s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} |
| {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 10m  2s{color} | {color:green} patch has no errors when building and testing our client artifacts. {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  5m 24s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  2m 21s{color} | {color:green} the patch passed {color} |
|| || || || {color:brown} Other Tests {color} ||
| {color:red}-1{color} | {color:red} unit {color} | {color:red}  8m 14s{color} | {color:red} hadoop-common in the patch failed. {color} |
| {color:green}+1{color} | {color:green} unit {color} | {color:green}  1m 30s{color} | {color:green} hadoop-hdfs-client in the patch passed. {color} |
| {color:red}-1{color} | {color:red} unit {color} | {color:red} 82m 37s{color} | {color:red} hadoop-hdfs in the patch failed. {color} |
| {color:red}-1{color} | {color:red} asflicense {color} | {color:red}  0m 34s{color} | {color:red} The patch generated 1 ASF License warnings. {color} |
| {color:black}{color} | {color:black} {color} | {color:black}185m  7s{color} | {color:black} {color} |
\\
\\
|| Reason || Tests ||
| Failed junit tests | hadoop.fs.viewfs.TestViewFileSystemLocalFileSystem |
|   | hadoop.fs.viewfs.TestViewFileSystemWithAuthorityLocalFileSystem |
\\
\\
|| Subsystem || Report/Notes ||
| Docker | Client=17.05.0-ce Server=17.05.0-ce Image:yetus/hadoop:5b98639 |
| JIRA Issue | HADOOP-15117 |
| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12903749/HADOOP-15117.000.patch |
| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  shadedclient  findbugs  checkstyle  |
| uname | Linux a540065c2163 3.13.0-135-generic #184-Ubuntu SMP Wed Oct 18 11:55:51 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux |
| Build tool | maven |
| Personality | /testptch/patchprocess/precommit/personality/provided.sh |
| git revision | trunk / 52babbb |
| maven | version: Apache Maven 3.3.9 |
| Default Java | 1.8.0_151 |
| findbugs | v3.1.0-RC1 |
| findbugs | https://builds.apache.org/job/PreCommit-HADOOP-Build/13890/artifact/out/branch-findbugs-hadoop-hdfs-project_hadoop-hdfs-warnings.html |
| checkstyle | https://builds.apache.org/job/PreCommit-HADOOP-Build/13890/artifact/out/diff-checkstyle-root.txt |
| unit | https://builds.apache.org/job/PreCommit-HADOOP-Build/13890/artifact/out/patch-unit-hadoop-common-project_hadoop-common.txt |
| unit | https://builds.apache.org/job/PreCommit-HADOOP-Build/13890/artifact/out/patch-unit-hadoop-hdfs-project_hadoop-hdfs.txt |
|  Test Results | https://builds.apache.org/job/PreCommit-HADOOP-Build/13890/testReport/ |
| asflicense | https://builds.apache.org/job/PreCommit-HADOOP-Build/13890/artifact/out/patch-asflicense-problems.txt |
| Max. process+thread count | 3939 (vs. ulimit of 5000) |
| modules | C: hadoop-common-project/hadoop-common hadoop-hdfs-project/hadoop-hdfs-client hadoop-hdfs-project/hadoop-hdfs U: . |
| Console output | https://builds.apache.org/job/PreCommit-HADOOP-Build/13890/console |
| Powered by | Apache Yetus 0.7.0-SNAPSHOT   http://yetus.apache.org |


This message was automatically generated.

","28/Dec/17 09:29;elgoiri;{{AbstractContractPathHandleTest}} gives a very good overview of the expected behavior and much cleaner than what we had in {{AbstractContractOpenTest}}.

A couple comments:
* Should we make sure we trigger the exception? For example, should {{testMoved}} have a {{fail()}} after the {{verifyRead()}} that expects exceptions?
* We do the serialization of the {{PathHandle}} a bunch of times in the tests, I'm not sure we should add it to the handle itself but wrapping it in a function may make sense.
* Similarly to what you do in {{testChangedAndMoved()}}, you could split (with extra lines), the part that does the changes/moves from the ones that do the checks.
* Does it make sense to {{fail()}} in the unreachable statement case for {{getHandleOrSkip()}}; I don't see how else that could happen but I guess is more complete that way.

Nice to see that adding these exhaustive unit tests showed the need to add the stat null check to {{HdfsPathHandle}}.","28/Dec/17 23:12;cdouglas;Thanks for taking a look, [~elgoiri].

bq. Should we make sure we trigger the exception? For example, should testMoved have a fail() after the verifyRead() that expects exceptions?
Instead of the try/fail, catch/ignore pattern this checks the option to determine if the exception should have been thrown (and vice versa). The {{verifyRead}} ensures the referent is correct with the expected content.

bq. We do the serialization of the PathHandle a bunch of times in the tests, I'm not sure we should add it to the handle itself but wrapping it in a function may make sense.
Good point. Changed whether the handle is first serialized to be another parameter for the tests. Either {{Paramaterized}} has a bug, or I'm using the naming incorrectly, because including this parameter in the name causes odd test failures. As-is, it's enough for someone to figure out what's going wrong.

bq. Similarly to what you do in testChangedAndMoved(), you could split (with extra lines), the part that does the changes/moves from the ones that do the checks.
Done

bq. Does it make sense to fail() in the unreachable statement case for getHandleOrSkip()
Unfortunately the return statement is still required. It really is unreachable if {{skip}} does what it's supposed to do.","29/Dec/17 02:43;genericqa;| (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 11s{color} | {color:blue} Docker mode activated. {color} |
|| || || || {color:brown} Prechecks {color} ||
| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |
| {color:green}+1{color} | {color:green} test4tests {color} | {color:green}  0m  0s{color} | {color:green} The patch appears to include 3 new or modified test files. {color} |
|| || || || {color:brown} trunk Compile Tests {color} ||
| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  0m 16s{color} | {color:blue} Maven dependency ordering for branch {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 17m 28s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 14m  7s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  2m 13s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  3m  9s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 16m  9s{color} | {color:green} branch has no errors when building and testing our client artifacts. {color} |
| {color:red}-1{color} | {color:red} findbugs {color} | {color:red}  2m 10s{color} | {color:red} hadoop-hdfs-project/hadoop-hdfs in trunk has 1 extant Findbugs warnings. {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  2m 24s{color} | {color:green} trunk passed {color} |
|| || || || {color:brown} Patch Compile Tests {color} ||
| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  0m 43s{color} | {color:blue} Maven dependency ordering for patch {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  2m 40s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 12m 14s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javac {color} | {color:green} 12m 14s{color} | {color:green} the patch passed {color} |
| {color:orange}-0{color} | {color:orange} checkstyle {color} | {color:orange}  2m  4s{color} | {color:orange} root: The patch generated 16 new + 7 unchanged - 0 fixed = 23 total (was 7) {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  2m 51s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} |
| {color:green}+1{color} | {color:green} shadedclient {color} | {color:green}  9m 53s{color} | {color:green} patch has no errors when building and testing our client artifacts. {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  5m 25s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  2m 19s{color} | {color:green} the patch passed {color} |
|| || || || {color:brown} Other Tests {color} ||
| {color:red}-1{color} | {color:red} unit {color} | {color:red}  8m 16s{color} | {color:red} hadoop-common in the patch failed. {color} |
| {color:green}+1{color} | {color:green} unit {color} | {color:green}  1m 31s{color} | {color:green} hadoop-hdfs-client in the patch passed. {color} |
| {color:red}-1{color} | {color:red} unit {color} | {color:red} 95m 55s{color} | {color:red} hadoop-hdfs in the patch failed. {color} |
| {color:red}-1{color} | {color:red} asflicense {color} | {color:red}  0m 35s{color} | {color:red} The patch generated 1 ASF License warnings. {color} |
| {color:black}{color} | {color:black} {color} | {color:black}202m 56s{color} | {color:black} {color} |
\\
\\
|| Reason || Tests ||
| Failed junit tests | hadoop.fs.viewfs.TestViewFileSystemLocalFileSystem |
|   | hadoop.fs.viewfs.TestViewFileSystemWithAuthorityLocalFileSystem |
\\
\\
|| Subsystem || Report/Notes ||
| Docker | Client=17.05.0-ce Server=17.05.0-ce Image:yetus/hadoop:5b98639 |
| JIRA Issue | HADOOP-15117 |
| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12903953/HADOOP-15117.001.patch |
| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  shadedclient  findbugs  checkstyle  |
| uname | Linux 6ec2f77e2bec 3.13.0-135-generic #184-Ubuntu SMP Wed Oct 18 11:55:51 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux |
| Build tool | maven |
| Personality | /testptch/patchprocess/precommit/personality/provided.sh |
| git revision | trunk / 5bf7e59 |
| maven | version: Apache Maven 3.3.9 |
| Default Java | 1.8.0_151 |
| findbugs | v3.1.0-RC1 |
| findbugs | https://builds.apache.org/job/PreCommit-HADOOP-Build/13897/artifact/out/branch-findbugs-hadoop-hdfs-project_hadoop-hdfs-warnings.html |
| checkstyle | https://builds.apache.org/job/PreCommit-HADOOP-Build/13897/artifact/out/diff-checkstyle-root.txt |
| unit | https://builds.apache.org/job/PreCommit-HADOOP-Build/13897/artifact/out/patch-unit-hadoop-common-project_hadoop-common.txt |
| unit | https://builds.apache.org/job/PreCommit-HADOOP-Build/13897/artifact/out/patch-unit-hadoop-hdfs-project_hadoop-hdfs.txt |
|  Test Results | https://builds.apache.org/job/PreCommit-HADOOP-Build/13897/testReport/ |
| asflicense | https://builds.apache.org/job/PreCommit-HADOOP-Build/13897/artifact/out/patch-asflicense-problems.txt |
| Max. process+thread count | 4238 (vs. ulimit of 5000) |
| modules | C: hadoop-common-project/hadoop-common hadoop-hdfs-project/hadoop-hdfs-client hadoop-hdfs-project/hadoop-hdfs U: . |
| Console output | https://builds.apache.org/job/PreCommit-HADOOP-Build/13897/console |
| Powered by | Apache Yetus 0.7.0-SNAPSHOT   http://yetus.apache.org |


This message was automatically generated.

","29/Dec/17 18:07;cdouglas;Fixed checkstyle, missing license. The unit test failures are also on trunk, unfortunately.","29/Dec/17 19:14;cdouglas;The failing tests are being tracked in HADOOP-15128.","29/Dec/17 21:07;elgoiri;In general [^HADOOP-15117.002.patch] looks good.
* In {{AbstractContractPathHandleTest}}, do we need the {{if}} checks in the catch after 180? We should've made sure those were true before. Are we covering anything there?
* Can we describe the {{serialize}} in {{TestHDFSContractPathHandle}}? Maybe move it from {{Boolean}} to {{boolean}} too.","29/Dec/17 21:25;genericqa;| (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 11s{color} | {color:blue} Docker mode activated. {color} |
|| || || || {color:brown} Prechecks {color} ||
| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |
| {color:green}+1{color} | {color:green} test4tests {color} | {color:green}  0m  0s{color} | {color:green} The patch appears to include 3 new or modified test files. {color} |
|| || || || {color:brown} trunk Compile Tests {color} ||
| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  1m 21s{color} | {color:blue} Maven dependency ordering for branch {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 17m 45s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 13m 56s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  2m 19s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  3m 23s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 16m 19s{color} | {color:green} branch has no errors when building and testing our client artifacts. {color} |
| {color:red}-1{color} | {color:red} findbugs {color} | {color:red}  2m  4s{color} | {color:red} hadoop-hdfs-project/hadoop-hdfs in trunk has 1 extant Findbugs warnings. {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  2m 23s{color} | {color:green} trunk passed {color} |
|| || || || {color:brown} Patch Compile Tests {color} ||
| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  0m 16s{color} | {color:blue} Maven dependency ordering for patch {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  2m 35s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 13m 27s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javac {color} | {color:green} 13m 27s{color} | {color:green} the patch passed {color} |
| {color:orange}-0{color} | {color:orange} checkstyle {color} | {color:orange}  2m  4s{color} | {color:orange} root: The patch generated 1 new + 7 unchanged - 0 fixed = 8 total (was 7) {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  2m 56s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} |
| {color:green}+1{color} | {color:green} shadedclient {color} | {color:green}  9m 57s{color} | {color:green} patch has no errors when building and testing our client artifacts. {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  5m 23s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  2m 18s{color} | {color:green} the patch passed {color} |
|| || || || {color:brown} Other Tests {color} ||
| {color:red}-1{color} | {color:red} unit {color} | {color:red}  7m 46s{color} | {color:red} hadoop-common in the patch failed. {color} |
| {color:green}+1{color} | {color:green} unit {color} | {color:green}  1m 30s{color} | {color:green} hadoop-hdfs-client in the patch passed. {color} |
| {color:red}-1{color} | {color:red} unit {color} | {color:red} 85m 51s{color} | {color:red} hadoop-hdfs in the patch failed. {color} |
| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 39s{color} | {color:green} The patch does not generate ASF License warnings. {color} |
| {color:black}{color} | {color:black} {color} | {color:black}194m 23s{color} | {color:black} {color} |
\\
\\
|| Reason || Tests ||
| Failed junit tests | hadoop.fs.viewfs.TestViewFileSystemWithAuthorityLocalFileSystem |
|   | hadoop.fs.viewfs.TestViewFileSystemLocalFileSystem |
|   | hadoop.hdfs.TestErasureCodingMultipleRacks |
|   | hadoop.hdfs.server.datanode.TestDataNodeVolumeFailureReporting |
|   | hadoop.hdfs.server.namenode.TestReencryptionWithKMS |
\\
\\
|| Subsystem || Report/Notes ||
| Docker | Client=17.05.0-ce Server=17.05.0-ce Image:yetus/hadoop:5b98639 |
| JIRA Issue | HADOOP-15117 |
| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12904033/HADOOP-15117.002.patch |
| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  shadedclient  findbugs  checkstyle  |
| uname | Linux 93e4fb4838f4 3.13.0-129-generic #178-Ubuntu SMP Fri Aug 11 12:48:20 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux |
| Build tool | maven |
| Personality | /testptch/patchprocess/precommit/personality/provided.sh |
| git revision | trunk / a55884c |
| maven | version: Apache Maven 3.3.9 |
| Default Java | 1.8.0_151 |
| findbugs | v3.1.0-RC1 |
| findbugs | https://builds.apache.org/job/PreCommit-HADOOP-Build/13901/artifact/out/branch-findbugs-hadoop-hdfs-project_hadoop-hdfs-warnings.html |
| checkstyle | https://builds.apache.org/job/PreCommit-HADOOP-Build/13901/artifact/out/diff-checkstyle-root.txt |
| unit | https://builds.apache.org/job/PreCommit-HADOOP-Build/13901/artifact/out/patch-unit-hadoop-common-project_hadoop-common.txt |
| unit | https://builds.apache.org/job/PreCommit-HADOOP-Build/13901/artifact/out/patch-unit-hadoop-hdfs-project_hadoop-hdfs.txt |
|  Test Results | https://builds.apache.org/job/PreCommit-HADOOP-Build/13901/testReport/ |
| Max. process+thread count | 3791 (vs. ulimit of 5000) |
| modules | C: hadoop-common-project/hadoop-common hadoop-hdfs-project/hadoop-hdfs-client hadoop-hdfs-project/hadoop-hdfs U: . |
| Console output | https://builds.apache.org/job/PreCommit-HADOOP-Build/13901/console |
| Powered by | Apache Yetus 0.7.0-SNAPSHOT   http://yetus.apache.org |


This message was automatically generated.

","30/Dec/17 01:37;cdouglas;bq. In AbstractContractPathHandleTest, do we need the if checks in the catch after 180? We should've made sure those were true before. Are we covering anything there?
Yes, that's where the test verifies that if an exception was thrown, it must be because the rename or the modification was disallowed (because it's the expression in the {{try}} that throws). If one is allowed, then it must have been the other that caused the exception. In the case where both are disallowed, we don't need an assertion because we've already checked both conditions.

bq. Can we describe the serialize in TestHDFSContractPathHandle? Maybe move it from Boolean to boolean too.
Sure, I'll add a comment. IIRC the change to {{Boolean}} was in service of an invocation problem from {{Parameterized}}, but it might have been trying to work around the {{name}} issue. I'll make sure it's necessary.","30/Dec/17 05:08;genericqa;| (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  9m 38s{color} | {color:blue} Docker mode activated. {color} |
|| || || || {color:brown} Prechecks {color} ||
| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |
| {color:green}+1{color} | {color:green} test4tests {color} | {color:green}  0m  0s{color} | {color:green} The patch appears to include 3 new or modified test files. {color} |
|| || || || {color:brown} trunk Compile Tests {color} ||
| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  1m 17s{color} | {color:blue} Maven dependency ordering for branch {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 16m 21s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 12m 47s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  2m  1s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  2m 55s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 15m 22s{color} | {color:green} branch has no errors when building and testing our client artifacts. {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  4m 57s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  2m 20s{color} | {color:green} trunk passed {color} |
|| || || || {color:brown} Patch Compile Tests {color} ||
| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  0m 16s{color} | {color:blue} Maven dependency ordering for patch {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  2m 19s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 11m 44s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javac {color} | {color:green} 11m 44s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  2m  3s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  2m 51s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} |
| {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 10m  1s{color} | {color:green} patch has no errors when building and testing our client artifacts. {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  5m 24s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  2m 20s{color} | {color:green} the patch passed {color} |
|| || || || {color:brown} Other Tests {color} ||
| {color:red}-1{color} | {color:red} unit {color} | {color:red}  8m 15s{color} | {color:red} hadoop-common in the patch failed. {color} |
| {color:green}+1{color} | {color:green} unit {color} | {color:green}  1m 28s{color} | {color:green} hadoop-hdfs-client in the patch passed. {color} |
| {color:red}-1{color} | {color:red} unit {color} | {color:red} 85m 48s{color} | {color:red} hadoop-hdfs in the patch failed. {color} |
| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 35s{color} | {color:green} The patch does not generate ASF License warnings. {color} |
| {color:black}{color} | {color:black} {color} | {color:black}198m 15s{color} | {color:black} {color} |
\\
\\
|| Reason || Tests ||
| Failed junit tests | hadoop.fs.viewfs.TestViewFileSystemLocalFileSystem |
|   | hadoop.fs.viewfs.TestViewFileSystemWithAuthorityLocalFileSystem |
\\
\\
|| Subsystem || Report/Notes ||
| Docker | Client=17.05.0-ce Server=17.05.0-ce Image:yetus/hadoop:5b98639 |
| JIRA Issue | HADOOP-15117 |
| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12904049/HADOOP-15117.003.patch |
| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  shadedclient  findbugs  checkstyle  |
| uname | Linux 1d21809c0941 3.13.0-135-generic #184-Ubuntu SMP Wed Oct 18 11:55:51 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux |
| Build tool | maven |
| Personality | /testptch/patchprocess/precommit/personality/provided.sh |
| git revision | trunk / 4bb765e |
| maven | version: Apache Maven 3.3.9 |
| Default Java | 1.8.0_151 |
| findbugs | v3.1.0-RC1 |
| unit | https://builds.apache.org/job/PreCommit-HADOOP-Build/13902/artifact/out/patch-unit-hadoop-common-project_hadoop-common.txt |
| unit | https://builds.apache.org/job/PreCommit-HADOOP-Build/13902/artifact/out/patch-unit-hadoop-hdfs-project_hadoop-hdfs.txt |
|  Test Results | https://builds.apache.org/job/PreCommit-HADOOP-Build/13902/testReport/ |
| Max. process+thread count | 3799 (vs. ulimit of 5000) |
| modules | C: hadoop-common-project/hadoop-common hadoop-hdfs-project/hadoop-hdfs-client hadoop-hdfs-project/hadoop-hdfs U: . |
| Console output | https://builds.apache.org/job/PreCommit-HADOOP-Build/13902/console |
| Powered by | Apache Yetus 0.7.0-SNAPSHOT   http://yetus.apache.org |


This message was automatically generated.

","30/Dec/17 20:39;elgoiri;As [~chris.douglas] mentions, the failed unit tests are already tracked in a another JIRA. +1","31/Dec/17 01:59;cdouglas;Thanks for the reviews, [~elgoiri]. I committed this.","31/Dec/17 02:21;hudson;SUCCESS: Integrated in Jenkins build Hadoop-trunk-Commit #13430 (See [https://builds.apache.org/job/Hadoop-trunk-Commit/13430/])
HADOOP-15117. open(PathHandle) contract test should be exhaustive for (cdouglas: rev 7fe6f83c8f0f67b1456c37d94b0de807e81a904a)
* (edit) hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/contract/AbstractContractOpenTest.java
* (edit) hadoop-hdfs-project/hadoop-hdfs-client/src/main/java/org/apache/hadoop/hdfs/protocol/HdfsPathHandle.java
* (add) hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/contract/AbstractContractPathHandleTest.java
* (add) hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/contract/hdfs/TestHDFSContractPathHandle.java
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Upgrade JUnit 3 TestCase to JUnit 4 in TestS3NInMemoryFileSystem,HADOOP-14803,13097113,Test,Resolved,HADOOP,Hadoop Common,software,omalley,Hadoop Common is the common library for Apache Hadoop.,http://hadoop.apache.org/,Major,Not A Problem,,ajayydv,ajayydv,23/Aug/17 19:07,14/Oct/17 08:28,12/Jan/21 11:55,14/Oct/17 08:28,,,,,,,,,,,fs/s3,,,,0,,, Upgrade JUnit 3 TestCase to JUnit 4 in TestS3NInMemoryFileSystem,,aajisaka,ajayydv,arp,stevel@apache.org,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,HADOOP-14729,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,2017-10-14 08:28:04.493,,,false,,,,,,,,,,,,,,,,,9223372036854775807,,,,,Sat Oct 14 08:28:04 UTC 2017,,,,,,,"0|i3j7fr:",9223372036854775807,,,,,,,,,,,junit3,,,,,,,,,,,,"14/Oct/17 08:28;aajisaka;The test was removed by HADOOP-14738. Closing.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
DFS i/o benchmark.,HADOOP-193,12333108,Test,Closed,HADOOP,Hadoop Common,software,omalley,Hadoop Common is the common library for Apache Hadoop.,http://hadoop.apache.org/,Major,Fixed,shv,shv,shv,04/May/06 08:57,10/Aug/17 18:20,12/Jan/21 11:55,04/May/06 11:39,,,,,0.2.0,,,,,,fs,,,,0,,,"DFS i/o benchmark is a map-reduce based test that measures performance of the cluster for reads and writes.
This is an evolved version of HADOOP-72, and HADOOP-95 test.

This test writes into or reads from a specified number of files.
File size is specified as a parameter to the test.
Each file is processed in a separate map task.
The unique reducer then collects stats.
Finally, the following information is displayed

# read or write test
# date and time the test finished
# number of files processed
# total number of bytes processed
# throughput in mb/sec (total number of bytes / sum of processing times)
# average i/o rate in mb/sec per file
# standard i/o rate deviation

I  included the test into the AllTestDriver.",,angushe,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"04/May/06 08:57;shv;IOBenchmark.patch;https://issues.apache.org/jira/secure/attachment/12326226/IOBenchmark.patch",,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,2006-05-04 11:39:48.0,,,false,,,,,,,,,,,,,,,,,124683,,,,,Thu May 04 11:39:48 UTC 2006,,,,,,,"0|i0ipuv:",107283,,,,,,,,,,,,,,,,,,,,,,,"04/May/06 11:39;cutting;I just committed this.  Thanks, Konstantin.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
TestShellBasedIdMapping.testStaticMapUpdate doesn't work on OS X,HADOOP-13178,12970929,Test,Resolved,HADOOP,Hadoop Common,software,omalley,Hadoop Common is the common library for Apache Hadoop.,http://hadoop.apache.org/,Major,Fixed,lewuathe,aw,aw,18/May/16 21:08,24/Jul/17 03:12,12/Jan/21 11:55,21/May/16 17:01,3.0.0-alpha1,,,,2.8.2,2.9.0,3.0.0-alpha1,,,,test,,,,0,,,TestShellBasedIdMapping.testStaticMapUpdate throws an error on OS X.,,aajisaka,aw,hudson,lewuathe,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"19/May/16 11:54;lewuathe;HADOOP-13178.01.patch;https://issues.apache.org/jira/secure/attachment/12804922/HADOOP-13178.01.patch","20/May/16 13:12;lewuathe;HADOOP-13178.02.patch;https://issues.apache.org/jira/secure/attachment/12805211/HADOOP-13178.02.patch",,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,2016-05-19 11:56:47.662,,,false,,,,,,,,,,,,,,,,,9223372036854775807,,,,,Mon Jul 24 03:12:25 UTC 2017,,,,,,,"0|i2y6an:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,"18/May/16 21:08;aw;{code}
testStaticMapUpdate(org.apache.hadoop.security.TestShellBasedIdMapping)  Time elapsed: 2.12 sec  <<< FAILURE!
java.lang.AssertionError: expected:<9999> but was:<-1>
	at org.junit.Assert.fail(Assert.java:88)
	at org.junit.Assert.failNotEquals(Assert.java:743)
	at org.junit.Assert.assertEquals(Assert.java:118)
	at org.junit.Assert.assertEquals(Assert.java:144)
	at org.apache.hadoop.security.TestShellBasedIdMapping.testStaticMapUpdate(TestShellBasedIdMapping.java:198)
{code}","19/May/16 11:56;lewuathe;I updated to 
* Fix mapping patter to match negative values
* Test all available ids on system.","19/May/16 17:24;hadoopqa;| (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue} 0m 11s {color} | {color:blue} Docker mode activated. {color} |
| {color:green}+1{color} | {color:green} @author {color} | {color:green} 0m 0s {color} | {color:green} The patch does not contain any @author tags. {color} |
| {color:green}+1{color} | {color:green} test4tests {color} | {color:green} 0m 0s {color} | {color:green} The patch appears to include 1 new or modified test files. {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 6m 18s {color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 6m 38s {color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green} 0m 24s {color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green} 0m 57s {color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green} 0m 12s {color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green} 1m 19s {color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 0m 55s {color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 0m 38s {color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 6m 24s {color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javac {color} | {color:green} 6m 24s {color} | {color:green} the patch passed {color} |
| {color:red}-1{color} | {color:red} checkstyle {color} | {color:red} 0m 22s {color} | {color:red} hadoop-common-project/hadoop-common: The patch generated 3 new + 46 unchanged - 5 fixed = 49 total (was 51) {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green} 0m 54s {color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green} 0m 12s {color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} whitespace {color} | {color:green} 0m 0s {color} | {color:green} The patch has no whitespace issues. {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green} 1m 29s {color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 0m 54s {color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} unit {color} | {color:green} 7m 9s {color} | {color:green} hadoop-common in the patch passed. {color} |
| {color:green}+1{color} | {color:green} asflicense {color} | {color:green} 0m 20s {color} | {color:green} The patch does not generate ASF License warnings. {color} |
| {color:black}{color} | {color:black} {color} | {color:black} 35m 54s {color} | {color:black} {color} |
\\
\\
|| Subsystem || Report/Notes ||
| Docker |  Image:yetus/hadoop:2c91fd8 |
| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12804922/HADOOP-13178.01.patch |
| JIRA Issue | HADOOP-13178 |
| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  findbugs  checkstyle  |
| uname | Linux 6b552f5803ed 3.13.0-36-lowlatency #63-Ubuntu SMP PREEMPT Wed Sep 3 21:56:12 UTC 2014 x86_64 x86_64 x86_64 GNU/Linux |
| Build tool | maven |
| Personality | /testptch/hadoop/patchprocess/precommit/personality/provided.sh |
| git revision | trunk / 141873c |
| Default Java | 1.8.0_91 |
| findbugs | v3.0.0 |
| checkstyle | https://builds.apache.org/job/PreCommit-HADOOP-Build/9516/artifact/patchprocess/diff-checkstyle-hadoop-common-project_hadoop-common.txt |
|  Test Results | https://builds.apache.org/job/PreCommit-HADOOP-Build/9516/testReport/ |
| modules | C: hadoop-common-project/hadoop-common U: hadoop-common-project/hadoop-common |
| Console output | https://builds.apache.org/job/PreCommit-HADOOP-Build/9516/console |
| Powered by | Apache Yetus 0.3.0-SNAPSHOT   http://yetus.apache.org |


This message was automatically generated.

","20/May/16 13:56;hadoopqa;| (/) *{color:green}+1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue} 0m 15s {color} | {color:blue} Docker mode activated. {color} |
| {color:green}+1{color} | {color:green} @author {color} | {color:green} 0m 0s {color} | {color:green} The patch does not contain any @author tags. {color} |
| {color:green}+1{color} | {color:green} test4tests {color} | {color:green} 0m 0s {color} | {color:green} The patch appears to include 1 new or modified test files. {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 6m 27s {color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 6m 33s {color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green} 0m 25s {color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green} 0m 55s {color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green} 0m 13s {color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green} 1m 21s {color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 0m 55s {color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 0m 41s {color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 6m 29s {color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javac {color} | {color:green} 6m 29s {color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green} 0m 23s {color} | {color:green} hadoop-common-project/hadoop-common: The patch generated 0 new + 46 unchanged - 5 fixed = 46 total (was 51) {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green} 0m 53s {color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green} 0m 12s {color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} whitespace {color} | {color:green} 0m 0s {color} | {color:green} The patch has no whitespace issues. {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green} 1m 28s {color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 0m 54s {color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} unit {color} | {color:green} 8m 19s {color} | {color:green} hadoop-common in the patch passed. {color} |
| {color:green}+1{color} | {color:green} asflicense {color} | {color:green} 0m 19s {color} | {color:green} The patch does not generate ASF License warnings. {color} |
| {color:black}{color} | {color:black} {color} | {color:black} 37m 23s {color} | {color:black} {color} |
\\
\\
|| Subsystem || Report/Notes ||
| Docker |  Image:yetus/hadoop:2c91fd8 |
| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12805211/HADOOP-13178.02.patch |
| JIRA Issue | HADOOP-13178 |
| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  findbugs  checkstyle  |
| uname | Linux 8ca663a59d66 3.13.0-36-lowlatency #63-Ubuntu SMP PREEMPT Wed Sep 3 21:56:12 UTC 2014 x86_64 x86_64 x86_64 GNU/Linux |
| Build tool | maven |
| Personality | /testptch/hadoop/patchprocess/precommit/personality/provided.sh |
| git revision | trunk / 757050f |
| Default Java | 1.8.0_91 |
| findbugs | v3.0.0 |
|  Test Results | https://builds.apache.org/job/PreCommit-HADOOP-Build/9536/testReport/ |
| modules | C: hadoop-common-project/hadoop-common U: hadoop-common-project/hadoop-common |
| Console output | https://builds.apache.org/job/PreCommit-HADOOP-Build/9536/console |
| Powered by | Apache Yetus 0.3.0-SNAPSHOT   http://yetus.apache.org |


This message was automatically generated.

","21/May/16 15:27;hadoopqa;| (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:green}+1{color} | {color:green} @author {color} | {color:green} 0m 00s {color} | {color:green} The patch does not contain any @author tags. {color} |
| {color:green}+1{color} | {color:green} test4tests {color} | {color:green} 0m 00s {color} | {color:green} The patch appears to include 1 new or modified test files. {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 7m 50s {color} | {color:green} trunk passed {color} |
| {color:red}-1{color} | {color:red} compile {color} | {color:red} 3m 45s {color} | {color:red} root in trunk failed. {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 0m 49s {color} | {color:green} the patch passed {color} |
| {color:red}-1{color} | {color:red} compile {color} | {color:red} 3m 35s {color} | {color:red} root in the patch failed. {color} |
| {color:red}-1{color} | {color:red} javac {color} | {color:red} 3m 35s {color} | {color:red} root in the patch failed. {color} |
| {color:red}-1{color} | {color:red} unit {color} | {color:red} 10m 14s {color} | {color:red} hadoop-common in the patch failed. {color} |
| {color:black}{color} | {color:black} {color} | {color:black} 26m 38s {color} | {color:black} {color} |
\\
\\
|| Reason || Tests ||
| Failed junit tests | hadoop.fs.TestSymlinkLocalFSFileContext |
|   | hadoop.fs.TestSymlinkLocalFSFileSystem |
|   | hadoop.net.unix.TestDomainSocket |
|   | hadoop.security.ssl.TestReloadingX509TrustManager |
\\
\\
|| Subsystem || Report/Notes ||
| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12805211/HADOOP-13178.02.patch |
| JIRA Issue | HADOOP-13178 |
| Optional Tests |  compile  javac  mvninstall  unit  |
| uname | Darwin Gavins-Mac-mini.local 13.2.0 Darwin Kernel Version 13.2.0: Thu Apr 17 23:03:13 PDT 2014; root:xnu-2422.100.13~1/RELEASE_X86_64 x86_64 |
| Build tool | maven |
| Personality | /Users/jenkins/jenkins-home/workspace/Precommit-HADOOP-OSX/patchprocess/apache-yetus-21ed107/precommit/personality/hadoop.sh |
| git revision | trunk / 500e946 |
| Default Java | 1.8.0_74 |
| compile | https://builds.apache.org/job/Precommit-HADOOP-OSX/16/artifact/patchprocess/branch-compile-root.txt |
| compile | https://builds.apache.org/job/Precommit-HADOOP-OSX/16/artifact/patchprocess/patch-compile-root.txt |
| javac | https://builds.apache.org/job/Precommit-HADOOP-OSX/16/artifact/patchprocess/patch-compile-root.txt |
| unit | https://builds.apache.org/job/Precommit-HADOOP-OSX/16/artifact/patchprocess/patch-unit-hadoop-common-project_hadoop-common.txt |
| unit test logs |  https://builds.apache.org/job/Precommit-HADOOP-OSX/16/artifact/patchprocess/patch-unit-hadoop-common-project_hadoop-common.txt |
|  Test Results | https://builds.apache.org/job/Precommit-HADOOP-OSX/16/testReport/ |
| modules | C: hadoop-common-project/hadoop-common U: hadoop-common-project/hadoop-common |
| Console output | https://builds.apache.org/job/Precommit-HADOOP-OSX/16/console |
| Powered by | Apache Yetus 0.3.0-SNAPSHOT   http://yetus.apache.org |


This message was automatically generated.

","21/May/16 15:40;aw;* hadoop.fs.TestSymlinkLocalFSFile* (HADOOP-13176) and TestDomainSocket (HADOOP-12487 for general portability issues, but probably needs one for OS X) are known broken on OS X
* compile with native in YARN is known broken (YARN-5121)

That said, I've never seen  hadoop.security.ssl.TestReloadingX509TrustManager  break, but I can't imagine it is related.  Let's run this through again and see if it breaks again.","21/May/16 16:08;hadoopqa;| (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:green}+1{color} | {color:green} @author {color} | {color:green} 0m 00s {color} | {color:green} The patch does not contain any @author tags. {color} |
| {color:green}+1{color} | {color:green} test4tests {color} | {color:green} 0m 00s {color} | {color:green} The patch appears to include 1 new or modified test files. {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 7m 59s {color} | {color:green} trunk passed {color} |
| {color:red}-1{color} | {color:red} compile {color} | {color:red} 3m 53s {color} | {color:red} root in trunk failed. {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 0m 51s {color} | {color:green} the patch passed {color} |
| {color:red}-1{color} | {color:red} compile {color} | {color:red} 3m 33s {color} | {color:red} root in the patch failed. {color} |
| {color:red}-1{color} | {color:red} javac {color} | {color:red} 3m 33s {color} | {color:red} root in the patch failed. {color} |
| {color:red}-1{color} | {color:red} unit {color} | {color:red} 10m 18s {color} | {color:red} hadoop-common in the patch failed. {color} |
| {color:black}{color} | {color:black} {color} | {color:black} 26m 59s {color} | {color:black} {color} |
\\
\\
|| Reason || Tests ||
| Failed junit tests | hadoop.fs.TestSymlinkLocalFSFileContext |
|   | hadoop.fs.TestSymlinkLocalFSFileSystem |
|   | hadoop.ipc.TestRPCWaitForProxy |
|   | hadoop.net.unix.TestDomainSocket |
\\
\\
|| Subsystem || Report/Notes ||
| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12805211/HADOOP-13178.02.patch |
| JIRA Issue | HADOOP-13178 |
| Optional Tests |  compile  javac  mvninstall  unit  |
| uname | Darwin Gavins-Mac-mini.local 13.2.0 Darwin Kernel Version 13.2.0: Thu Apr 17 23:03:13 PDT 2014; root:xnu-2422.100.13~1/RELEASE_X86_64 x86_64 |
| Build tool | maven |
| Personality | /Users/jenkins/jenkins-home/workspace/Precommit-HADOOP-OSX/patchprocess/apache-yetus-21ed107/precommit/personality/hadoop.sh |
| git revision | trunk / 39ec151 |
| Default Java | 1.8.0_74 |
| compile | https://builds.apache.org/job/Precommit-HADOOP-OSX/17/artifact/patchprocess/branch-compile-root.txt |
| compile | https://builds.apache.org/job/Precommit-HADOOP-OSX/17/artifact/patchprocess/patch-compile-root.txt |
| javac | https://builds.apache.org/job/Precommit-HADOOP-OSX/17/artifact/patchprocess/patch-compile-root.txt |
| unit | https://builds.apache.org/job/Precommit-HADOOP-OSX/17/artifact/patchprocess/patch-unit-hadoop-common-project_hadoop-common.txt |
| unit test logs |  https://builds.apache.org/job/Precommit-HADOOP-OSX/17/artifact/patchprocess/patch-unit-hadoop-common-project_hadoop-common.txt |
|  Test Results | https://builds.apache.org/job/Precommit-HADOOP-OSX/17/testReport/ |
| modules | C: hadoop-common-project/hadoop-common U: hadoop-common-project/hadoop-common |
| Console output | https://builds.apache.org/job/Precommit-HADOOP-OSX/17/console |
| Powered by | Apache Yetus 0.3.0-SNAPSHOT   http://yetus.apache.org |


This message was automatically generated.

","21/May/16 17:01;aw;+1 committing to trunk.

Thanks!","21/May/16 17:16;hudson;SUCCESS: Integrated in Hadoop-trunk-Commit #9837 (See [https://builds.apache.org/job/Hadoop-trunk-Commit/9837/])
HADOOP-13178. TestShellBasedIdMapping.testStaticMapUpdate doesn't work (aw: rev d8c1fd1944160ad5b5d093731ae987d701802321)
* hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/security/ShellBasedIdMapping.java
* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/security/TestShellBasedIdMapping.java
","24/Jul/17 03:12;aajisaka;Cherry-picked this to branch-2 and branch-2.8.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Coverage fix for org.apache.hadoop.fs.s3,HADOOP-9360,12635315,Test,Resolved,HADOOP,Hadoop Common,software,omalley,Hadoop Common is the common library for Apache Hadoop.,http://hadoop.apache.org/,Major,Won't Fix,aleksgor,aleksgor,aleksgor,05/Mar/13 10:36,15/Jun/17 14:16,12/Jan/21 11:55,15/Jun/17 14:16,0.23.7,2.1.0-beta,3.0.0-alpha1,,3.0.0-alpha4,,,,,,fs/s3,,,,0,BB2015-05-TBR,,"Coverage fix for org.apache.hadoop.fs.s3
patch HADOOP-9360-trunk.patch for trunk and branch-2 
HADOOP-9360-branch-0.23.patch for branch-0.23",,aklochkov,aleksgor,iveselovsky,stevel@apache.org,sureshms,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"04/Apr/13 13:52;aleksgor;HADOOP-9360-branch-0.23-a.patch;https://issues.apache.org/jira/secure/attachment/12576980/HADOOP-9360-branch-0.23-a.patch","05/Mar/13 10:38;aleksgor;HADOOP-9360-branch-0.23.patch;https://issues.apache.org/jira/secure/attachment/12572064/HADOOP-9360-branch-0.23.patch","04/Apr/13 13:52;aleksgor;HADOOP-9360-trunk-a.patch;https://issues.apache.org/jira/secure/attachment/12576981/HADOOP-9360-trunk-a.patch","05/Mar/13 10:38;aleksgor;HADOOP-9360-trunk.patch;https://issues.apache.org/jira/secure/attachment/12572065/HADOOP-9360-trunk.patch",,,,,,,,,,,,,,,,,,,,4.0,,,,,,,,,,,,,,,,,,,,2013-03-05 11:15:44.727,,,false,,,,,,,,,,,,,,,,,315808,,,,,Thu Jun 15 14:16:21 UTC 2017,,,,,,,"0|i1ihuf:",316151,,,,,,,,,,,,,,,,,,,,,,,"05/Mar/13 11:15;hadoopqa;{color:green}+1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12572065/HADOOP-9360-trunk.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 3 new or modified test files.

    {color:green}+1 tests included appear to have a timeout.{color}

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  The javadoc tool did not generate any warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:green}+1 core tests{color}.  The patch passed unit tests in hadoop-common-project/hadoop-common.

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HADOOP-Build/2261//testReport/
Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/2261//console

This message is automatically generated.","06/Mar/13 14:26;stevel@apache.org;I'm always pleased to see new tests

# there's some abuse of introspection in the migration tests, I'd recommend package-scoped accessors marked {{@VisibleForTesting}} to get at the internals instead. If it's JetS3t internals you are playing with, then introspection exceptions should be caught and downgraded to {{AssumptionViolatedException}}, so the failure is converted to a skip.

# a couple of the tests look for specific text in exceptions. I don't like that -either make the string constant in the source class, or change S3 &s3n to raise specific exceptions for these failures (e.g unauthorised). 
# {{S3ServerStub.writeFile()}} should always close, even on an exception. That must not be in the finally, as you wan't problems in a normal close() to surface. Instead {{IOException}} should be caught, {{FileUtils.close()}} used to close the stream quietly.
# must use {{Exception.toString()}} over {{Exception.getMessage()}} except for the specific checks of exception messages
# would be nice to have text messages on all assertion failures.
# trivial: needs a quick proofread of comments and method names. In particular {{getDummiTextFile}} should be {{getDummyTextFile}}
","04/Apr/13 13:53;aleksgor;Thanks Steve for your remarks.
I've updated patches.
HADOOP-9360-trunk-a.patch for trunk and branch-2
HADOOP-9360-branch-0.23-a.patch for branch-0.23 ","04/Apr/13 14:42;hadoopqa;{color:green}+1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12576981/HADOOP-9360-trunk-a.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 3 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  The javadoc tool did not generate any warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:green}+1 core tests{color}.  The patch passed unit tests in hadoop-common-project/hadoop-common.

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HADOOP-Build/2413//testReport/
Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/2413//console

This message is automatically generated.","02/May/15 04:25;hadoopqa;\\
\\
| (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:red}-1{color} | patch |   0m  0s | The patch command could not apply the patch during dryrun. |
\\
\\
|| Subsystem || Report/Notes ||
| Patch URL | http://issues.apache.org/jira/secure/attachment/12576981/HADOOP-9360-trunk-a.patch |
| Optional Tests | javadoc javac unit findbugs checkstyle |
| git revision | trunk / f1a152c |
| Console output | https://builds.apache.org/job/PreCommit-HADOOP-Build/6269/console |


This message was automatically generated.","02/May/15 04:30;hadoopqa;\\
\\
| (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:red}-1{color} | patch |   0m  0s | The patch command could not apply the patch during dryrun. |
\\
\\
|| Subsystem || Report/Notes ||
| Patch URL | http://issues.apache.org/jira/secure/attachment/12576981/HADOOP-9360-trunk-a.patch |
| Optional Tests | javadoc javac unit findbugs checkstyle |
| git revision | trunk / f1a152c |
| Console output | https://builds.apache.org/job/PreCommit-HADOOP-Build/6292/console |


This message was automatically generated.","12/May/16 20:59;hadoopqa;| (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue} 0m 0s {color} | {color:blue} Docker mode activated. {color} |
| {color:red}-1{color} | {color:red} patch {color} | {color:red} 0m 4s {color} | {color:red} HADOOP-9360 does not apply to trunk. Rebase required? Wrong Branch? See https://wiki.apache.org/hadoop/HowToContribute for help. {color} |
\\
\\
|| Subsystem || Report/Notes ||
| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12576981/HADOOP-9360-trunk-a.patch |
| JIRA Issue | HADOOP-9360 |
| Console output | https://builds.apache.org/job/PreCommit-HADOOP-Build/9384/console |
| Powered by | Apache Yetus 0.3.0-SNAPSHOT   http://yetus.apache.org |


This message was automatically generated.

","15/Jun/17 14:16;stevel@apache.org;Afraid I'm going to close this as a wontfix; we've cut the s3: // client out internally.

Aleksey —sorry this didn't get in. I know from personal experience how frustrating it is to have your patches ignored.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Adding additional unit test for Trash (I),HADOOP-13686,13009923,Test,Resolved,HADOOP,Hadoop Common,software,omalley,Hadoop Common is the common library for Apache Hadoop.,http://hadoop.apache.org/,Major,Fixed,cheersyang,xyao,xyao,05/Oct/16 17:16,04/Apr/17 21:53,12/Jan/21 11:55,14/Oct/16 06:07,,,,,2.8.0,3.0.0-alpha2,,,,,,,,,0,,,"This ticket is opened to track adding the forllowing unit test in hadoop-common. 
#test users can delete their own trash directory
#test users can delete an empty directory and the directory is moved to trash
#test fs.trash.interval with invalid values such as 0 or negative",,aajisaka,cheersyang,Fan04290,hudson,xyao,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,HADOOP-14277,,,,,,,,,,"14/Oct/16 08:25;cheersyang;HADOOP-13686-branch-2.8.01.patch;https://issues.apache.org/jira/secure/attachment/12833323/HADOOP-13686-branch-2.8.01.patch","08/Oct/16 14:47;cheersyang;HADOOP-13686.01.patch;https://issues.apache.org/jira/secure/attachment/12832268/HADOOP-13686.01.patch","11/Oct/16 09:00;cheersyang;HADOOP-13686.02.patch;https://issues.apache.org/jira/secure/attachment/12832627/HADOOP-13686.02.patch","11/Oct/16 15:59;cheersyang;HADOOP-13686.03.patch;https://issues.apache.org/jira/secure/attachment/12832685/HADOOP-13686.03.patch","12/Oct/16 07:53;cheersyang;HADOOP-13686.04.patch;https://issues.apache.org/jira/secure/attachment/12832843/HADOOP-13686.04.patch","12/Oct/16 09:23;cheersyang;HADOOP-13686.05.patch;https://issues.apache.org/jira/secure/attachment/12832856/HADOOP-13686.05.patch","12/Oct/16 13:41;cheersyang;HADOOP-13686.06.patch;https://issues.apache.org/jira/secure/attachment/12832885/HADOOP-13686.06.patch","14/Oct/16 02:30;cheersyang;HADOOP-13686.07.patch;https://issues.apache.org/jira/secure/attachment/12833276/HADOOP-13686.07.patch",,,,,,,,,,,,,,,,8.0,,,,,,,,,,,,,,,,,,,,2016-10-08 14:47:12.343,,,false,,,,,,,,,,,,,,,,,9223372036854775807,Reviewed,,,,Fri Oct 14 15:47:32 UTC 2016,,,,,,,"0|i34hbz:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,"08/Oct/16 14:47;cheersyang;Added following tests

# {{testCheckpointInterval}} this test sets multiple values (legal and illegal) to *fs.trash.checkpoint.interval* and verify the values are set in emptier as expected.
# {{testTrashPermission}} this test verifies when files moved to trash, file permission is reserved. And user is able to remove their own trash directory.
# {{testMoveEmptyDirToTrash}} this test user is able to move an empty directory to trash.
# {{testTrashRestarts}} this tests simulates a restart of the parent process (NN), verifies *fs.trash.interval* is honoured during restart.

Some more things

bq. 3. test fs.trash.interval with invalid values such as 0 or negative

This is already covered so it's not in this patch. {{TestTrash#trashShell}} tested setting value to 0. {{TestStateTransitionFailure}} tested setting a negative value. Namenode will not be started with error ""Cannot start trash emptier with negative interval. Set fs.trash.interval to a positive value"". 

And this patch fixed an issue that setting a negative value to fs.trash.checkpoint.interval is not handled in {{TrashPolicyDefault}}.
","08/Oct/16 15:31;hadoopqa;| (/) *{color:green}+1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 19s{color} | {color:blue} Docker mode activated. {color} |
| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |
| {color:green}+1{color} | {color:green} test4tests {color} | {color:green}  0m  0s{color} | {color:green} The patch appears to include 1 new or modified test files. {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  6m 36s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green}  7m 18s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 27s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  1m  8s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green}  0m 14s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  1m 32s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 45s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  0m 42s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green}  8m 23s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javac {color} | {color:green}  8m 23s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 25s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  1m  6s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green}  0m 13s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  1m 44s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 45s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} unit {color} | {color:green}  9m 14s{color} | {color:green} hadoop-common in the patch passed. {color} |
| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 22s{color} | {color:green} The patch does not generate ASF License warnings. {color} |
| {color:black}{color} | {color:black} {color} | {color:black} 42m 38s{color} | {color:black} {color} |
\\
\\
|| Subsystem || Report/Notes ||
| Docker |  Image:yetus/hadoop:9560f25 |
| JIRA Issue | HADOOP-13686 |
| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12832268/HADOOP-13686.01.patch |
| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  findbugs  checkstyle  |
| uname | Linux 2251e5b0c0b2 3.13.0-36-lowlatency #63-Ubuntu SMP PREEMPT Wed Sep 3 21:56:12 UTC 2014 x86_64 x86_64 x86_64 GNU/Linux |
| Build tool | maven |
| Personality | /testptch/hadoop/patchprocess/precommit/personality/provided.sh |
| git revision | trunk / 4d10621 |
| Default Java | 1.8.0_101 |
| findbugs | v3.0.0 |
|  Test Results | https://builds.apache.org/job/PreCommit-HADOOP-Build/10712/testReport/ |
| modules | C: hadoop-common-project/hadoop-common U: hadoop-common-project/hadoop-common |
| Console output | https://builds.apache.org/job/PreCommit-HADOOP-Build/10712/console |
| Powered by | Apache Yetus 0.4.0-SNAPSHOT   http://yetus.apache.org |


This message was automatically generated.

","09/Oct/16 00:58;cheersyang;Hello [~xyao]

The patch is ready for review now, can you please help to kindly review? Thanks a lot.","10/Oct/16 21:24;xyao;Thanks [~Weiwei Yang] for working on this. The patch looks good to me overall. Here are some early feedbacks.

1. testMoveEmptyDirToTrash

Can we add a helper method by passing a FileSystem obj as parameter
so that this test can be used to test Trash with not only raw file system but also 
other HCFS?

Can we further verify that the only directory under trash is the empty directory?

verifyDefaultPolicyIntervalValues
{{FileSystem fs = null;}} can be removed.

2. testTrashPermission
Can we add a helper method by passing a FileSystem obj as parameter
so that this test can be used to test Trash with not only raw file system but also 
other HCFS?

3. NIT: Can we use try with resource to simplify the logic?
{code}
try {
} finally {
698	      if(fs != null) {
699	        fs.close();
700	      }
701	    }
{code}

4. Let's move AuditableTrashPolicy/AuditableCheckpoints in a separate file for reusing with HDFS-10922.

5. NIT: AuditableCheckpoints: can be a static class. But I would suggest we 
declare the members var/methods to be non-static. This can avoid issues when 
running multiple AuditableTrashPolicy instances.

","11/Oct/16 09:12;cheersyang;Hello [~xyao]

Thanks for your comments, it's helpful. I have addressed #1, #2 and #3 in v2 patch. But I am a little hesitated to do #4 and #5. I don't think HDFS-10922 will use AuditableTrashPolicy/AuditableCheckpoints, they are helper classes to verify trash intervals in {{testTrashRestarts}}, I can't see how to reuse it in HDFS trash tests. Regarding to #5, I used static AuditableCheckpoints and static vars, because I need to share checkpoint states between multiple instances of trash policies while simulating restart, I used atom integer to avoid thread safety problem.

Once this one is committed, I will add test case in HDFS-10922 to call {{TestTrash#testMoveEmptyDirToTrash}} and {{TestTrash#testTrashPermission}}, so that to reuse these tests in HDFS. I already tried locally and it worked fine.

Please let me know how v2 looks, appreciate your help.","11/Oct/16 09:46;hadoopqa;| (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 20s{color} | {color:blue} Docker mode activated. {color} |
| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |
| {color:green}+1{color} | {color:green} test4tests {color} | {color:green}  0m  0s{color} | {color:green} The patch appears to include 1 new or modified test files. {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  6m 44s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green}  6m 55s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 29s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  0m 58s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green}  0m 13s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  1m 20s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 44s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  0m 36s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green}  6m 52s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javac {color} | {color:green}  6m 52s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 24s{color} | {color:green} hadoop-common-project/hadoop-common: The patch generated 0 new + 75 unchanged - 1 fixed = 75 total (was 76) {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  0m 54s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green}  0m 13s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  1m 29s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 42s{color} | {color:green} the patch passed {color} |
| {color:red}-1{color} | {color:red} unit {color} | {color:red}  7m 51s{color} | {color:red} hadoop-common in the patch failed. {color} |
| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 21s{color} | {color:green} The patch does not generate ASF License warnings. {color} |
| {color:black}{color} | {color:black} {color} | {color:black} 38m 31s{color} | {color:black} {color} |
\\
\\
|| Reason || Tests ||
| Failed junit tests | hadoop.fs.TestTrash |
\\
\\
|| Subsystem || Report/Notes ||
| Docker |  Image:yetus/hadoop:9560f25 |
| JIRA Issue | HADOOP-13686 |
| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12832627/HADOOP-13686.02.patch |
| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  findbugs  checkstyle  |
| uname | Linux 25f6325b0db7 3.13.0-36-lowlatency #63-Ubuntu SMP PREEMPT Wed Sep 3 21:56:12 UTC 2014 x86_64 x86_64 x86_64 GNU/Linux |
| Build tool | maven |
| Personality | /testptch/hadoop/patchprocess/precommit/personality/provided.sh |
| git revision | trunk / 96b1266 |
| Default Java | 1.8.0_101 |
| findbugs | v3.0.0 |
| unit | https://builds.apache.org/job/PreCommit-HADOOP-Build/10730/artifact/patchprocess/patch-unit-hadoop-common-project_hadoop-common.txt |
|  Test Results | https://builds.apache.org/job/PreCommit-HADOOP-Build/10730/testReport/ |
| modules | C: hadoop-common-project/hadoop-common U: hadoop-common-project/hadoop-common |
| Console output | https://builds.apache.org/job/PreCommit-HADOOP-Build/10730/console |
| Powered by | Apache Yetus 0.4.0-SNAPSHOT   http://yetus.apache.org |


This message was automatically generated.

","11/Oct/16 18:22;hadoopqa;| (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 18s{color} | {color:blue} Docker mode activated. {color} |
| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |
| {color:green}+1{color} | {color:green} test4tests {color} | {color:green}  0m  0s{color} | {color:green} The patch appears to include 2 new or modified test files. {color} |
| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  1m 33s{color} | {color:blue} Maven dependency ordering for branch {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  6m 43s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green}  6m 48s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  1m 26s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  1m 49s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green}  0m 26s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  3m  4s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  1m 27s{color} | {color:green} trunk passed {color} |
| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  0m 17s{color} | {color:blue} Maven dependency ordering for patch {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  1m 28s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green}  8m 31s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javac {color} | {color:green}  8m 31s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  1m 33s{color} | {color:green} root: The patch generated 0 new + 78 unchanged - 1 fixed = 78 total (was 79) {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  1m 59s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green}  0m 32s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  3m 41s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  1m 32s{color} | {color:green} the patch passed {color} |
| {color:red}-1{color} | {color:red} unit {color} | {color:red}  8m  3s{color} | {color:red} hadoop-common in the patch failed. {color} |
| {color:green}+1{color} | {color:green} unit {color} | {color:green} 59m 22s{color} | {color:green} hadoop-hdfs in the patch passed. {color} |
| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 29s{color} | {color:green} The patch does not generate ASF License warnings. {color} |
| {color:black}{color} | {color:black} {color} | {color:black}134m 22s{color} | {color:black} {color} |
\\
\\
|| Reason || Tests ||
| Failed junit tests | hadoop.fs.TestTrash |
\\
\\
|| Subsystem || Report/Notes ||
| Docker |  Image:yetus/hadoop:9560f25 |
| JIRA Issue | HADOOP-13686 |
| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12832685/HADOOP-13686.03.patch |
| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  findbugs  checkstyle  |
| uname | Linux 7dbfce05169c 3.13.0-36-lowlatency #63-Ubuntu SMP PREEMPT Wed Sep 3 21:56:12 UTC 2014 x86_64 x86_64 x86_64 GNU/Linux |
| Build tool | maven |
| Personality | /testptch/hadoop/patchprocess/precommit/personality/provided.sh |
| git revision | trunk / ecb51b8 |
| Default Java | 1.8.0_101 |
| findbugs | v3.0.0 |
| unit | https://builds.apache.org/job/PreCommit-HADOOP-Build/10732/artifact/patchprocess/patch-unit-hadoop-common-project_hadoop-common.txt |
|  Test Results | https://builds.apache.org/job/PreCommit-HADOOP-Build/10732/testReport/ |
| modules | C: hadoop-common-project/hadoop-common hadoop-hdfs-project/hadoop-hdfs U: . |
| Console output | https://builds.apache.org/job/PreCommit-HADOOP-Build/10732/console |
| Powered by | Apache Yetus 0.4.0-SNAPSHOT   http://yetus.apache.org |


This message was automatically generated.

","11/Oct/16 18:31;xyao;Thanks [~cheersyang] for the update. patch v3 looks good to me. Two remaining issues:
1. We need leave the change of TestHDFSTrash.java in HDFS-10922.
2. Address the Jenkins failures in testTrashPermission.

bq. 
I don't think HDFS-10922 will use AuditableTrashPolicy/AuditableCheckpoints, they are helper classes to verify trash intervals in testTrashRestarts, I can't see how to reuse it in HDFS trash tests. 

You are right. I proposed to reuse AuditableTrashPolicy/AuditableCheckpoints because the patch v06 in HDFS-10922 has duplicated code at the time when I review this one. Now that you've updated HDFS-10922. We don't need to address #4 now.  

bq. Regarding to #5, I used static AuditableCheckpoints and static vars, because I need to share checkpoint states between multiple instances of trash policies while simulating restart, I used atom integer to avoid thread safety problem.

Make sense to me.","12/Oct/16 08:25;hadoopqa;| (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 16s{color} | {color:blue} Docker mode activated. {color} |
| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |
| {color:green}+1{color} | {color:green} test4tests {color} | {color:green}  0m  0s{color} | {color:green} The patch appears to include 1 new or modified test files. {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  7m  6s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green}  7m 47s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 28s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  1m  9s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green}  0m 15s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  1m 40s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 50s{color} | {color:green} trunk passed {color} |
| {color:red}-1{color} | {color:red} mvninstall {color} | {color:red}  0m 43s{color} | {color:red} hadoop-common in the patch failed. {color} |
| {color:red}-1{color} | {color:red} compile {color} | {color:red}  1m  2s{color} | {color:red} root in the patch failed. {color} |
| {color:red}-1{color} | {color:red} javac {color} | {color:red}  1m  2s{color} | {color:red} root in the patch failed. {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 26s{color} | {color:green} hadoop-common-project/hadoop-common: The patch generated 0 new + 76 unchanged - 1 fixed = 76 total (was 77) {color} |
| {color:red}-1{color} | {color:red} mvnsite {color} | {color:red}  0m 42s{color} | {color:red} hadoop-common in the patch failed. {color} |
| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green}  0m 11s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} |
| {color:red}-1{color} | {color:red} findbugs {color} | {color:red}  0m 25s{color} | {color:red} hadoop-common in the patch failed. {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 42s{color} | {color:green} the patch passed {color} |
| {color:red}-1{color} | {color:red} unit {color} | {color:red}  0m 44s{color} | {color:red} hadoop-common in the patch failed. {color} |
| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 19s{color} | {color:green} The patch does not generate ASF License warnings. {color} |
| {color:black}{color} | {color:black} {color} | {color:black} 26m  8s{color} | {color:black} {color} |
\\
\\
|| Subsystem || Report/Notes ||
| Docker |  Image:yetus/hadoop:9560f25 |
| JIRA Issue | HADOOP-13686 |
| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12832843/HADOOP-13686.04.patch |
| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  findbugs  checkstyle  |
| uname | Linux 06945d86cbbd 3.13.0-36-lowlatency #63-Ubuntu SMP PREEMPT Wed Sep 3 21:56:12 UTC 2014 x86_64 x86_64 x86_64 GNU/Linux |
| Build tool | maven |
| Personality | /testptch/hadoop/patchprocess/precommit/personality/provided.sh |
| git revision | trunk / 6476934 |
| Default Java | 1.8.0_101 |
| findbugs | v3.0.0 |
| mvninstall | https://builds.apache.org/job/PreCommit-HADOOP-Build/10740/artifact/patchprocess/patch-mvninstall-hadoop-common-project_hadoop-common.txt |
| compile | https://builds.apache.org/job/PreCommit-HADOOP-Build/10740/artifact/patchprocess/patch-compile-root.txt |
| javac | https://builds.apache.org/job/PreCommit-HADOOP-Build/10740/artifact/patchprocess/patch-compile-root.txt |
| mvnsite | https://builds.apache.org/job/PreCommit-HADOOP-Build/10740/artifact/patchprocess/patch-mvnsite-hadoop-common-project_hadoop-common.txt |
| findbugs | https://builds.apache.org/job/PreCommit-HADOOP-Build/10740/artifact/patchprocess/patch-findbugs-hadoop-common-project_hadoop-common.txt |
| unit | https://builds.apache.org/job/PreCommit-HADOOP-Build/10740/artifact/patchprocess/patch-unit-hadoop-common-project_hadoop-common.txt |
|  Test Results | https://builds.apache.org/job/PreCommit-HADOOP-Build/10740/testReport/ |
| modules | C: hadoop-common-project/hadoop-common U: hadoop-common-project/hadoop-common |
| Console output | https://builds.apache.org/job/PreCommit-HADOOP-Build/10740/console |
| Powered by | Apache Yetus 0.4.0-SNAPSHOT   http://yetus.apache.org |


This message was automatically generated.

","12/Oct/16 10:10;hadoopqa;| (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 17s{color} | {color:blue} Docker mode activated. {color} |
| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |
| {color:green}+1{color} | {color:green} test4tests {color} | {color:green}  0m  0s{color} | {color:green} The patch appears to include 1 new or modified test files. {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  7m 47s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green}  8m  1s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 26s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  1m  3s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green}  0m 13s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  1m 26s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 44s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  0m 45s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green}  7m 56s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javac {color} | {color:green}  7m 56s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 24s{color} | {color:green} hadoop-common-project/hadoop-common: The patch generated 0 new + 76 unchanged - 1 fixed = 76 total (was 77) {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  1m  4s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green}  0m 13s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  1m 34s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 46s{color} | {color:green} the patch passed {color} |
| {color:red}-1{color} | {color:red} unit {color} | {color:red}  8m  3s{color} | {color:red} hadoop-common in the patch failed. {color} |
| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 21s{color} | {color:green} The patch does not generate ASF License warnings. {color} |
| {color:black}{color} | {color:black} {color} | {color:black} 42m 28s{color} | {color:black} {color} |
\\
\\
|| Reason || Tests ||
| Failed junit tests | hadoop.fs.TestTrash |
\\
\\
|| Subsystem || Report/Notes ||
| Docker |  Image:yetus/hadoop:9560f25 |
| JIRA Issue | HADOOP-13686 |
| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12832856/HADOOP-13686.05.patch |
| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  findbugs  checkstyle  |
| uname | Linux 21ef0e91e1c3 3.13.0-36-lowlatency #63-Ubuntu SMP PREEMPT Wed Sep 3 21:56:12 UTC 2014 x86_64 x86_64 x86_64 GNU/Linux |
| Build tool | maven |
| Personality | /testptch/hadoop/patchprocess/precommit/personality/provided.sh |
| git revision | trunk / 6476934 |
| Default Java | 1.8.0_101 |
| findbugs | v3.0.0 |
| unit | https://builds.apache.org/job/PreCommit-HADOOP-Build/10741/artifact/patchprocess/patch-unit-hadoop-common-project_hadoop-common.txt |
|  Test Results | https://builds.apache.org/job/PreCommit-HADOOP-Build/10741/testReport/ |
| modules | C: hadoop-common-project/hadoop-common U: hadoop-common-project/hadoop-common |
| Console output | https://builds.apache.org/job/PreCommit-HADOOP-Build/10741/console |
| Powered by | Apache Yetus 0.4.0-SNAPSHOT   http://yetus.apache.org |


This message was automatically generated.

","12/Oct/16 14:37;hadoopqa;| (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 16s{color} | {color:blue} Docker mode activated. {color} |
| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |
| {color:green}+1{color} | {color:green} test4tests {color} | {color:green}  0m  0s{color} | {color:green} The patch appears to include 1 new or modified test files. {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  7m  8s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green}  7m 11s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 24s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  1m  2s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green}  0m 13s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  1m 25s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 44s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  0m 39s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green}  7m 22s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javac {color} | {color:green}  7m 22s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 24s{color} | {color:green} hadoop-common-project/hadoop-common: The patch generated 0 new + 76 unchanged - 1 fixed = 76 total (was 77) {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  0m 55s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green}  0m 13s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  1m 30s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 42s{color} | {color:green} the patch passed {color} |
| {color:red}-1{color} | {color:red} unit {color} | {color:red} 17m  1s{color} | {color:red} hadoop-common in the patch failed. {color} |
| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 20s{color} | {color:green} The patch does not generate ASF License warnings. {color} |
| {color:black}{color} | {color:black} {color} | {color:black} 48m 54s{color} | {color:black} {color} |
\\
\\
|| Reason || Tests ||
| Timed out junit tests | org.apache.hadoop.http.TestHttpServerLifecycle |
\\
\\
|| Subsystem || Report/Notes ||
| Docker |  Image:yetus/hadoop:9560f25 |
| JIRA Issue | HADOOP-13686 |
| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12832885/HADOOP-13686.06.patch |
| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  findbugs  checkstyle  |
| uname | Linux f1648a2ae91f 3.13.0-36-lowlatency #63-Ubuntu SMP PREEMPT Wed Sep 3 21:56:12 UTC 2014 x86_64 x86_64 x86_64 GNU/Linux |
| Build tool | maven |
| Personality | /testptch/hadoop/patchprocess/precommit/personality/provided.sh |
| git revision | trunk / 6476934 |
| Default Java | 1.8.0_101 |
| findbugs | v3.0.0 |
| unit | https://builds.apache.org/job/PreCommit-HADOOP-Build/10743/artifact/patchprocess/patch-unit-hadoop-common-project_hadoop-common.txt |
|  Test Results | https://builds.apache.org/job/PreCommit-HADOOP-Build/10743/testReport/ |
| modules | C: hadoop-common-project/hadoop-common U: hadoop-common-project/hadoop-common |
| Console output | https://builds.apache.org/job/PreCommit-HADOOP-Build/10743/console |
| Powered by | Apache Yetus 0.4.0-SNAPSHOT   http://yetus.apache.org |


This message was automatically generated.

","12/Oct/16 14:53;cheersyang;Hello [~xyao]

# I have fixed UT failure in v8 patch, it was because the test gets an old FileSystem instance from cache. So I added {{FileSystem.closeAll()}} to fix this problem. It will ensure each test gets a new instance, it should be stable now.
# The code change in TestHDFSTrash was added by mistake, I have removed, sorry about that :).
# The failure TestHttpServerLifecycle in latest jenkins run was not related to this patch, it is a known issue and tracked by HADOOP-13471.

Please help to review this patch and let know if you have further comments.

Thank you","13/Oct/16 19:19;xyao;[~cheersyang], can you rebase the patch v06 with the latest trunk changes from HADOOP-13700? Otherwise, looks good to me. ","14/Oct/16 02:30;cheersyang;V7 patch removed the throws IOException in AuditableTrashPolicy#initialize function according to the change of HADOOP-13700. No functional change. ","14/Oct/16 03:18;hadoopqa;| (/) *{color:green}+1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 15s{color} | {color:blue} Docker mode activated. {color} |
| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |
| {color:green}+1{color} | {color:green} test4tests {color} | {color:green}  0m  0s{color} | {color:green} The patch appears to include 1 new or modified test files. {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  6m 41s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green}  6m 48s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 24s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  0m 56s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green}  0m 12s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  1m 23s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 45s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  0m 37s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green}  7m 23s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javac {color} | {color:green}  7m 23s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 25s{color} | {color:green} hadoop-common-project/hadoop-common: The patch generated 0 new + 76 unchanged - 1 fixed = 76 total (was 77) {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  0m 57s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green}  0m 13s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  1m 32s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 44s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} unit {color} | {color:green}  8m 39s{color} | {color:green} hadoop-common in the patch passed. {color} |
| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 21s{color} | {color:green} The patch does not generate ASF License warnings. {color} |
| {color:black}{color} | {color:black} {color} | {color:black} 39m 44s{color} | {color:black} {color} |
\\
\\
|| Subsystem || Report/Notes ||
| Docker |  Image:yetus/hadoop:9560f25 |
| JIRA Issue | HADOOP-13686 |
| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12833276/HADOOP-13686.07.patch |
| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  findbugs  checkstyle  |
| uname | Linux f621f4f2914b 3.13.0-36-lowlatency #63-Ubuntu SMP PREEMPT Wed Sep 3 21:56:12 UTC 2014 x86_64 x86_64 x86_64 GNU/Linux |
| Build tool | maven |
| Personality | /testptch/hadoop/patchprocess/precommit/personality/provided.sh |
| git revision | trunk / 0a85d07 |
| Default Java | 1.8.0_101 |
| findbugs | v3.0.0 |
|  Test Results | https://builds.apache.org/job/PreCommit-HADOOP-Build/10783/testReport/ |
| modules | C: hadoop-common-project/hadoop-common U: hadoop-common-project/hadoop-common |
| Console output | https://builds.apache.org/job/PreCommit-HADOOP-Build/10783/console |
| Powered by | Apache Yetus 0.4.0-SNAPSHOT   http://yetus.apache.org |


This message was automatically generated.

","14/Oct/16 05:42;xyao;Thanks [~cheersyang] for the update. +1 for v7 patch and I will commit it shortly.","14/Oct/16 06:07;xyao;Thanks [~cheersyang] for the contribution. I've commit the patch to trunk, branch-2 and brach-2.8.","14/Oct/16 06:19;hudson;SUCCESS: Integrated in Jenkins build Hadoop-trunk-Commit #10610 (See [https://builds.apache.org/job/Hadoop-trunk-Commit/10610/])
HADOOP-13686. Adding additional unit test for Trash (I). Contributed by (xyao: rev dbe663d5241feea0c88a3a9391ad48a029001d94)
* (edit) hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/TestTrash.java
* (edit) hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/TrashPolicyDefault.java
","14/Oct/16 06:25;cheersyang;Thanks a lot [~xyao] :).","14/Oct/16 07:02;xyao;[~cheersyang], can you attach a branch-2.8 patch without using GenericTestUtils.getTempPath()? Thanks!","14/Oct/16 09:29;cheersyang;Sure, attached a patch for branch-2.8. Replaced GenericTestUtils.getTempPath() with TEST_DIR.","14/Oct/16 15:47;xyao;Thanks [~cheersyang] for the branch-2.8 patch. I've tested it and commit it to branch-2.8. ",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
[Azure Data Lake] Support for contract test and unit test cases,HADOOP-12875,12946515,Test,Resolved,HADOOP,Hadoop Common,software,omalley,Hadoop Common is the common library for Apache Hadoop.,http://hadoop.apache.org/,Major,Fixed,vishwajeet.dusane,vishwajeet.dusane,vishwajeet.dusane,03/Mar/16 11:09,20/Mar/17 20:12,12/Jan/21 11:55,16/Jun/16 16:49,,,,,3.0.0-alpha1,,,,,,fs/adl,test,tools,,0,,,This JIRA describes contract test and unit test cases support for azure data lake file system.,,Cathy.Palmer@microsoft.com,cdouglas,cnauroth,fabbri,hudson,jzhuge,shrikant,stevel@apache.org,twu,vishwajeet.dusane,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,HADOOP-12666,,,,,HADOOP-13257,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,HADOOP-13929,,,,,,,,,,"03/Mar/16 11:44;vishwajeet.dusane;Hadoop-12875-001.patch;https://issues.apache.org/jira/secure/attachment/12791157/Hadoop-12875-001.patch","12/Apr/16 13:09;vishwajeet.dusane;Hadoop-12875-002.patch;https://issues.apache.org/jira/secure/attachment/12798260/Hadoop-12875-002.patch","13/Apr/16 04:21;vishwajeet.dusane;Hadoop-12875-003.patch;https://issues.apache.org/jira/secure/attachment/12798437/Hadoop-12875-003.patch","10/May/16 13:21;vishwajeet.dusane;Hadoop-12875-004.patch;https://issues.apache.org/jira/secure/attachment/12803230/Hadoop-12875-004.patch","13/Jun/16 10:30;vishwajeet.dusane;Hadoop-12875-005.patch;https://issues.apache.org/jira/secure/attachment/12809807/Hadoop-12875-005.patch",,,,,,,,,,,,,,,,,,,5.0,,,,,,,,,,,,,,,,,,,,2016-03-07 13:36:18.138,,,false,,,,,,,,,,,,,,,,,9223372036854775807,Reviewed,,,,Mon Mar 20 20:12:51 UTC 2017,,,,,,,"0|i2u3d3:",9223372036854775807,,,,,,,,,,,,,3.0.0-alpha1,,,,,,,,,,"07/Mar/16 13:36;hadoopqa;| (/) *{color:green}+1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue} 0m 9s {color} | {color:blue} Docker mode activated. {color} |
| {color:green}+1{color} | {color:green} @author {color} | {color:green} 0m 0s {color} | {color:green} The patch does not contain any @author tags. {color} |
| {color:green}+1{color} | {color:green} test4tests {color} | {color:green} 0m 0s {color} | {color:green} The patch appears to include 22 new or modified test files. {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 6m 38s {color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 1m 10s {color} | {color:green} trunk passed with JDK v1.8.0_74 {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 1m 19s {color} | {color:green} trunk passed with JDK v1.7.0_95 {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green} 0m 25s {color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green} 1m 48s {color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green} 0m 26s {color} | {color:green} trunk passed {color} |
| {color:blue}0{color} | {color:blue} findbugs {color} | {color:blue} 0m 0s {color} | {color:blue} Skipped branch modules with no Java source: hadoop-tools {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green} 0m 0s {color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 0m 49s {color} | {color:green} trunk passed with JDK v1.8.0_74 {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 0m 58s {color} | {color:green} trunk passed with JDK v1.7.0_95 {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 1m 14s {color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 1m 1s {color} | {color:green} the patch passed with JDK v1.8.0_74 {color} |
| {color:green}+1{color} | {color:green} javac {color} | {color:green} 1m 1s {color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 1m 14s {color} | {color:green} the patch passed with JDK v1.7.0_95 {color} |
| {color:green}+1{color} | {color:green} javac {color} | {color:green} 1m 14s {color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green} 0m 23s {color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green} 1m 43s {color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green} 0m 18s {color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} whitespace {color} | {color:green} 0m 0s {color} | {color:green} Patch has no whitespace issues. {color} |
| {color:green}+1{color} | {color:green} xml {color} | {color:green} 0m 0s {color} | {color:green} The patch has no ill-formed XML file. {color} |
| {color:blue}0{color} | {color:blue} findbugs {color} | {color:blue} 0m 0s {color} | {color:blue} Skipped patch modules with no Java source: hadoop-tools {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green} 0m 0s {color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 0m 42s {color} | {color:green} the patch passed with JDK v1.8.0_74 {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 0m 55s {color} | {color:green} the patch passed with JDK v1.7.0_95 {color} |
| {color:green}+1{color} | {color:green} unit {color} | {color:green} 31m 38s {color} | {color:green} hadoop-tools in the patch passed with JDK v1.8.0_74. {color} |
| {color:green}+1{color} | {color:green} unit {color} | {color:green} 32m 31s {color} | {color:green} hadoop-tools in the patch passed with JDK v1.7.0_95. {color} |
| {color:green}+1{color} | {color:green} asflicense {color} | {color:green} 0m 19s {color} | {color:green} Patch does not generate ASF License warnings. {color} |
| {color:black}{color} | {color:black} {color} | {color:black} 86m 29s {color} | {color:black} {color} |
\\
\\
|| Subsystem || Report/Notes ||
| Docker |  Image:yetus/hadoop:0ca8df7 |
| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12791157/Hadoop-12875-001.patch |
| JIRA Issue | HADOOP-12875 |
| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  findbugs  checkstyle  xml  |
| uname | Linux d725d3e9582e 3.13.0-36-lowlatency #63-Ubuntu SMP PREEMPT Wed Sep 3 21:56:12 UTC 2014 x86_64 x86_64 x86_64 GNU/Linux |
| Build tool | maven |
| Personality | /testptch/hadoop/patchprocess/precommit/personality/provided.sh |
| git revision | trunk / fd1c09b |
| Default Java | 1.7.0_95 |
| Multi-JDK versions |  /usr/lib/jvm/java-8-oracle:1.8.0_74 /usr/lib/jvm/java-7-openjdk-amd64:1.7.0_95 |
| JDK v1.7.0_95  Test Results | https://builds.apache.org/job/PreCommit-HADOOP-Build/8805/testReport/ |
| modules | C: hadoop-tools U: hadoop-tools |
| Console output | https://builds.apache.org/job/PreCommit-HADOOP-Build/8805/console |
| Powered by | Apache Yetus 0.3.0-SNAPSHOT   http://yetus.apache.org |


This message was automatically generated.

","28/Mar/16 15:23;twu;Hi [~vishwajeet.dusane],

Thanks a lot for filing a separate JIRA, isolating out the ADL unit tests and providing a FS contract test! This is very helpful. 

I did a quick scan of the patch and have the following comments regarding the newly added FS contract tests:

Instead of having the following change in various contract test implementations:
{code:java}
+  @Override
+  protected boolean isSupported(String feature) throws IOException {
+    return true;
+  }
{code}
It's better to define a {{adls.xml}} file where you specify the file system behavior. You can refer to {{wasb.xml}} as an example. This page [here|https://hadoop.apache.org/docs/r2.7.2/hadoop-project-dist/hadoop-common/filesystem/testing.html] also describes the details of FS contract tests and best practices of adding new ones.

Instead of adding {{@Ignore}} to test cases unsupported by ADL, I believe you can use {{ContractTestUtils#unsupported(""..."")}} or {{ContractTestUtils#unsupported(""skip"")}} instead.
","04/Apr/16 15:49;vishwajeet.dusane;Thanks [~twu] - Good point. I will make the changes to incorporate the same.","07/Apr/16 23:56;cnauroth;[~vishwajeet.dusane], thank you for providing a patch to make use of the contract tests.  I have a few comments in addition to the helpful feedback from Tony.

How can I (and other Apache community members) obtain account credentials that we can put into contract-test-options.xml, so that we can run the tests?  I have an Azure subscription.  I checked manage.windowsazure.com, but I couldn't find an option for provisioning Azure Data Lake access.  It's going to be vital for ongoing maintenance that community members have a way to get credentials so that they can test patches against the live service before committing.

For configuration of the credentials, I recommend using a technique we've used in hadoop-aws and hadoop-azure to split the credentials into a separate XML file, which then gets XIncluded from the main XML file.  We can then place the name of the file with the credentials into .gitignore.  This helps prevent accidentally committing someone's private credentials to the Apache repo, which would then compromise the account.  Check out hadoop-aws and hadoop-azure for more details on how to do this.

{code}
    System.setProperty(""hadoop.home.dir"", System.getProperty(""user.dir""));
{code}

Why is this necessary?

I'm unclear on the intent of the various ""benchmark"" tests.  They use a mock back-end, so they aren't really providing an accurate benchmark of the true service interaction.  There are no assertions, so they aren't verifying functionality beyond making sure things don't throw exceptions.  They print timing information to the console, so is the expectation that these tests could be used for manual measurement before and after applying later patches?

Your time measurements are using {{System#currentTimeMillis}}, which may be subject to inaccuracy if the system clock changes or NTP makes a negative adjustment in the middle of a test run.  Instead, I recommend using {{org.apache.hadoop.util.Time#monotonicNow}}, which is a wrapper over {{System#nanoTime}}, which is guaranteed to be monotonic increasing.

{code}
  @Override
  protected AbstractFSContract createContract(Configuration configuration) {
    try {
      return new AdlStorageContract(configuration);
    } catch (URISyntaxException e) {
      return null;
    } catch (IOException e) {
      return null;
    }
  }
{code}

If any of these exceptions happens, then returning null is likely to cause a confusing {{NullPointerException}} later.  I'd prefer that we fail fast by throwing an unchecked exception, such as {{IllegalStateException}}, with a descriptive error message, and the original exception nested as root cause.

It's unusual to see contract test subclasses adding other test cases specific to the file system, like {{readCombinationTest}}.  The abstract contract test classes are meant to fully define the test cases, and then the subclasses usually just tweak the contract and skip tests that they aren't able to satisfy yet.  For clarity, I suggest refactoring those additional tests into separate suites.
","08/Apr/16 19:21;cnauroth;I just found the Azure Data Lake getting started link from the documentation in the HADOOP-12666 patch.  When I get a chance, I'll try following that to see if I can get these tests running end-to-end.

https://azure.microsoft.com/en-in/documentation/articles/data-lake-store-get-started-portal/","12/Apr/16 13:09;vishwajeet.dusane;- Added more Live as well as stub test code to verify adl driver functionality.
- Separated Contract Live test code from the additional test cases added.
- Replaced  mockserver-netty with mockwebserver since its reliable and faster while executing stubbed network tests.
- ","12/Apr/16 13:16;vishwajeet.dusane;[~cnauroth] - Thanks for the review. 
1. For .gitignore - Should this file be added after the initial checkin ? 
2. Below code is not necessary, i have removed that code.
{code}
    System.setProperty(""hadoop.home.dir"", System.getProperty(""user.dir"")); 
{code}
3. Benchmark test were to get latency of Adl driver alone to finds an overhead adl driver logic is adding. I have removed those test because that should be a different benchmark suite altogether and need not be part of this patchset.
4. using {{org.apache.hadoop.util.Time#monotonicNow}} now instead of the {{System#currentTimeMillis}}
5. Throwing {{IllegalStateException}} instead of {{NullPointerException}}, this would be useful for developer to debug quickly on what had gone wrong. Thanks again for this comment.
6. Created separate class for non contract test cases.
 
","12/Apr/16 16:05;hadoopqa;| (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue} 0m 16s {color} | {color:blue} Docker mode activated. {color} |
| {color:green}+1{color} | {color:green} @author {color} | {color:green} 0m 0s {color} | {color:green} The patch does not contain any @author tags. {color} |
| {color:green}+1{color} | {color:green} test4tests {color} | {color:green} 0m 0s {color} | {color:green} The patch appears to include 28 new or modified test files. {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 9m 3s {color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 1m 54s {color} | {color:green} trunk passed with JDK v1.8.0_77 {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 1m 43s {color} | {color:green} trunk passed with JDK v1.7.0_95 {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green} 0m 33s {color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green} 2m 23s {color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green} 0m 28s {color} | {color:green} trunk passed {color} |
| {color:blue}0{color} | {color:blue} findbugs {color} | {color:blue} 0m 0s {color} | {color:blue} Skipped branch modules with no Java source: hadoop-tools {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green} 0m 0s {color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 1m 38s {color} | {color:green} trunk passed with JDK v1.8.0_77 {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 1m 24s {color} | {color:green} trunk passed with JDK v1.7.0_95 {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 1m 49s {color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 2m 0s {color} | {color:green} the patch passed with JDK v1.8.0_77 {color} |
| {color:green}+1{color} | {color:green} javac {color} | {color:green} 2m 0s {color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 1m 38s {color} | {color:green} the patch passed with JDK v1.7.0_95 {color} |
| {color:green}+1{color} | {color:green} javac {color} | {color:green} 1m 38s {color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green} 0m 27s {color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green} 2m 8s {color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green} 0m 23s {color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} whitespace {color} | {color:green} 0m 0s {color} | {color:green} Patch has no whitespace issues. {color} |
| {color:green}+1{color} | {color:green} xml {color} | {color:green} 0m 1s {color} | {color:green} The patch has no ill-formed XML file. {color} |
| {color:blue}0{color} | {color:blue} findbugs {color} | {color:blue} 0m 0s {color} | {color:blue} Skipped patch modules with no Java source: hadoop-tools {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green} 0m 0s {color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 1m 21s {color} | {color:green} the patch passed with JDK v1.8.0_77 {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 1m 19s {color} | {color:green} the patch passed with JDK v1.7.0_95 {color} |
| {color:green}+1{color} | {color:green} unit {color} | {color:green} 43m 53s {color} | {color:green} hadoop-tools in the patch passed with JDK v1.8.0_77. {color} |
| {color:green}+1{color} | {color:green} unit {color} | {color:green} 38m 9s {color} | {color:green} hadoop-tools in the patch passed with JDK v1.7.0_95. {color} |
| {color:red}-1{color} | {color:red} asflicense {color} | {color:red} 0m 22s {color} | {color:red} Patch generated 7 ASF License warnings. {color} |
| {color:black}{color} | {color:black} {color} | {color:black} 113m 59s {color} | {color:black} {color} |
\\
\\
|| Subsystem || Report/Notes ||
| Docker |  Image:yetus/hadoop:fbe3e86 |
| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12798260/Hadoop-12875-002.patch |
| JIRA Issue | HADOOP-12875 |
| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  findbugs  checkstyle  xml  |
| uname | Linux ca40c0177660 3.13.0-36-lowlatency #63-Ubuntu SMP PREEMPT Wed Sep 3 21:56:12 UTC 2014 x86_64 x86_64 x86_64 GNU/Linux |
| Build tool | maven |
| Personality | /testptch/hadoop/patchprocess/precommit/personality/provided.sh |
| git revision | trunk / 437e9d6 |
| Default Java | 1.7.0_95 |
| Multi-JDK versions |  /usr/lib/jvm/java-8-oracle:1.8.0_77 /usr/lib/jvm/java-7-openjdk-amd64:1.7.0_95 |
| JDK v1.7.0_95  Test Results | https://builds.apache.org/job/PreCommit-HADOOP-Build/9064/testReport/ |
| asflicense | https://builds.apache.org/job/PreCommit-HADOOP-Build/9064/artifact/patchprocess/patch-asflicense-problems.txt |
| modules | C: hadoop-tools U: hadoop-tools |
| Console output | https://builds.apache.org/job/PreCommit-HADOOP-Build/9064/console |
| Powered by | Apache Yetus 0.2.0   http://yetus.apache.org |


This message was automatically generated.

","12/Apr/16 16:12;vishwajeet.dusane;I will update the patch earliest with ASF license for the missing 7 newly added files.","13/Apr/16 04:21;vishwajeet.dusane;Updated ASF license for the 7 newly added files.","13/Apr/16 06:14;hadoopqa;| (/) *{color:green}+1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue} 0m 18s {color} | {color:blue} Docker mode activated. {color} |
| {color:green}+1{color} | {color:green} @author {color} | {color:green} 0m 0s {color} | {color:green} The patch does not contain any @author tags. {color} |
| {color:green}+1{color} | {color:green} test4tests {color} | {color:green} 0m 0s {color} | {color:green} The patch appears to include 28 new or modified test files. {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 9m 7s {color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 1m 56s {color} | {color:green} trunk passed with JDK v1.8.0_77 {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 1m 36s {color} | {color:green} trunk passed with JDK v1.7.0_95 {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green} 0m 29s {color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green} 2m 8s {color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green} 0m 24s {color} | {color:green} trunk passed {color} |
| {color:blue}0{color} | {color:blue} findbugs {color} | {color:blue} 0m 0s {color} | {color:blue} Skipped branch modules with no Java source: hadoop-tools {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green} 0m 0s {color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 1m 23s {color} | {color:green} trunk passed with JDK v1.8.0_77 {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 1m 15s {color} | {color:green} trunk passed with JDK v1.7.0_95 {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 1m 36s {color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 1m 40s {color} | {color:green} the patch passed with JDK v1.8.0_77 {color} |
| {color:green}+1{color} | {color:green} javac {color} | {color:green} 1m 40s {color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 1m 25s {color} | {color:green} the patch passed with JDK v1.7.0_95 {color} |
| {color:green}+1{color} | {color:green} javac {color} | {color:green} 1m 25s {color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green} 0m 24s {color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green} 1m 49s {color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green} 0m 19s {color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} whitespace {color} | {color:green} 0m 0s {color} | {color:green} Patch has no whitespace issues. {color} |
| {color:green}+1{color} | {color:green} xml {color} | {color:green} 0m 1s {color} | {color:green} The patch has no ill-formed XML file. {color} |
| {color:blue}0{color} | {color:blue} findbugs {color} | {color:blue} 0m 0s {color} | {color:blue} Skipped patch modules with no Java source: hadoop-tools {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green} 0m 0s {color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 1m 3s {color} | {color:green} the patch passed with JDK v1.8.0_77 {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 1m 3s {color} | {color:green} the patch passed with JDK v1.7.0_95 {color} |
| {color:green}+1{color} | {color:green} unit {color} | {color:green} 37m 51s {color} | {color:green} hadoop-tools in the patch passed with JDK v1.8.0_77. {color} |
| {color:green}+1{color} | {color:green} unit {color} | {color:green} 38m 25s {color} | {color:green} hadoop-tools in the patch passed with JDK v1.7.0_95. {color} |
| {color:green}+1{color} | {color:green} asflicense {color} | {color:green} 0m 23s {color} | {color:green} Patch does not generate ASF License warnings. {color} |
| {color:black}{color} | {color:black} {color} | {color:black} 105m 29s {color} | {color:black} {color} |
\\
\\
|| Subsystem || Report/Notes ||
| Docker |  Image:yetus/hadoop:fbe3e86 |
| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12798437/Hadoop-12875-003.patch |
| JIRA Issue | HADOOP-12875 |
| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  findbugs  checkstyle  xml  |
| uname | Linux 7d685cbd02af 3.13.0-36-lowlatency #63-Ubuntu SMP PREEMPT Wed Sep 3 21:56:12 UTC 2014 x86_64 x86_64 x86_64 GNU/Linux |
| Build tool | maven |
| Personality | /testptch/hadoop/patchprocess/precommit/personality/provided.sh |
| git revision | trunk / 35f0770 |
| Default Java | 1.7.0_95 |
| Multi-JDK versions |  /usr/lib/jvm/java-8-oracle:1.8.0_77 /usr/lib/jvm/java-7-openjdk-amd64:1.7.0_95 |
| JDK v1.7.0_95  Test Results | https://builds.apache.org/job/PreCommit-HADOOP-Build/9077/testReport/ |
| modules | C: hadoop-tools U: hadoop-tools |
| Console output | https://builds.apache.org/job/PreCommit-HADOOP-Build/9077/console |
| Powered by | Apache Yetus 0.2.0   http://yetus.apache.org |


This message was automatically generated.

","10/May/16 13:21;vishwajeet.dusane;1.	Removed large data set generation test that cause add latency in the test execution
2.	Live test - Added support for FileContext test cases from Hadoop which cover more basic functionality.
3.	Removed unused code TestDataForCreate. 
4.	Replaced appropriate name of the test data generation functions
5.	Renamed TestConcurrentRead to TestSplitSizeCalculation
","10/May/16 14:59;hadoopqa;| (/) *{color:green}+1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue} 0m 12s {color} | {color:blue} Docker mode activated. {color} |
| {color:green}+1{color} | {color:green} @author {color} | {color:green} 0m 0s {color} | {color:green} The patch does not contain any @author tags. {color} |
| {color:green}+1{color} | {color:green} test4tests {color} | {color:green} 0m 0s {color} | {color:green} The patch appears to include 29 new or modified test files. {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 6m 43s {color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 1m 4s {color} | {color:green} trunk passed with JDK v1.8.0_91 {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 1m 16s {color} | {color:green} trunk passed with JDK v1.7.0_95 {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green} 0m 28s {color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green} 1m 45s {color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green} 0m 28s {color} | {color:green} trunk passed {color} |
| {color:blue}0{color} | {color:blue} findbugs {color} | {color:blue} 0m 0s {color} | {color:blue} Skipped patched modules with no Java source: hadoop-tools {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green} 0m 0s {color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 0m 48s {color} | {color:green} trunk passed with JDK v1.8.0_91 {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 0m 59s {color} | {color:green} trunk passed with JDK v1.7.0_95 {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 1m 17s {color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 1m 0s {color} | {color:green} the patch passed with JDK v1.8.0_91 {color} |
| {color:green}+1{color} | {color:green} javac {color} | {color:green} 1m 0s {color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 1m 14s {color} | {color:green} the patch passed with JDK v1.7.0_95 {color} |
| {color:green}+1{color} | {color:green} javac {color} | {color:green} 1m 14s {color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green} 0m 25s {color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green} 1m 44s {color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green} 0m 20s {color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} whitespace {color} | {color:green} 0m 0s {color} | {color:green} The patch has no whitespace issues. {color} |
| {color:green}+1{color} | {color:green} xml {color} | {color:green} 0m 1s {color} | {color:green} The patch has no ill-formed XML file. {color} |
| {color:blue}0{color} | {color:blue} findbugs {color} | {color:blue} 0m 0s {color} | {color:blue} Skipped patched modules with no Java source: hadoop-tools {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green} 0m 0s {color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 0m 46s {color} | {color:green} the patch passed with JDK v1.8.0_91 {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 0m 56s {color} | {color:green} the patch passed with JDK v1.7.0_95 {color} |
| {color:green}+1{color} | {color:green} unit {color} | {color:green} 33m 0s {color} | {color:green} hadoop-tools in the patch passed with JDK v1.8.0_91. {color} |
| {color:green}+1{color} | {color:green} unit {color} | {color:green} 33m 29s {color} | {color:green} hadoop-tools in the patch passed with JDK v1.7.0_95. {color} |
| {color:green}+1{color} | {color:green} asflicense {color} | {color:green} 0m 19s {color} | {color:green} The patch does not generate ASF License warnings. {color} |
| {color:black}{color} | {color:black} {color} | {color:black} 89m 10s {color} | {color:black} {color} |
\\
\\
|| Subsystem || Report/Notes ||
| Docker |  Image:yetus/hadoop:cf2ee45 |
| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12803230/Hadoop-12875-004.patch |
| JIRA Issue | HADOOP-12875 |
| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  findbugs  checkstyle  xml  |
| uname | Linux 886b3b933e98 3.13.0-36-lowlatency #63-Ubuntu SMP PREEMPT Wed Sep 3 21:56:12 UTC 2014 x86_64 x86_64 x86_64 GNU/Linux |
| Build tool | maven |
| Personality | /testptch/hadoop/patchprocess/precommit/personality/provided.sh |
| git revision | trunk / 87f5e35 |
| Default Java | 1.7.0_95 |
| Multi-JDK versions |  /usr/lib/jvm/java-8-oracle:1.8.0_91 /usr/lib/jvm/java-7-openjdk-amd64:1.7.0_95 |
| JDK v1.7.0_95  Test Results | https://builds.apache.org/job/PreCommit-HADOOP-Build/9353/testReport/ |
| modules | C: hadoop-tools U: hadoop-tools |
| Console output | https://builds.apache.org/job/PreCommit-HADOOP-Build/9353/console |
| Powered by | Apache Yetus 0.3.0-SNAPSHOT   http://yetus.apache.org |


This message was automatically generated.

","06/Jun/16 22:50;cnauroth;I am canceling this patch until its pre-requisites are committed.","06/Jun/16 22:54;cnauroth;+1 for patch 004, pending a pre-commit run after commit of HADOOP-12666.  I did a successful full test run integrated against the Azure Data Lake back-end.  I plan to commit this to trunk and branch-2 later this week.","09/Jun/16 23:58;hadoopqa;| (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 25s{color} | {color:blue} Docker mode activated. {color} |
| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |
| {color:green}+1{color} | {color:green} test4tests {color} | {color:green}  0m  0s{color} | {color:green} The patch appears to include 29 new or modified test files. {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  6m 43s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green}  0m 15s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 11s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  0m 18s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green}  0m 13s{color} | {color:green} trunk passed {color} |
| {color:red}-1{color} | {color:red} findbugs {color} | {color:red}  0m 23s{color} | {color:red} hadoop-tools/hadoop-azure-datalake in trunk has 1 extant Findbugs warnings. {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 12s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  0m 18s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green}  0m 17s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javac {color} | {color:green}  0m 17s{color} | {color:green} the patch passed {color} |
| {color:red}-1{color} | {color:red} checkstyle {color} | {color:red}  0m 10s{color} | {color:red} hadoop-tools/hadoop-azure-datalake: The patch generated 82 new + 0 unchanged - 0 fixed = 82 total (was 0) {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  0m 16s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green}  0m 11s{color} | {color:green} the patch passed {color} |
| {color:red}-1{color} | {color:red} whitespace {color} | {color:red}  0m  0s{color} | {color:red} The patch has 20 line(s) that end in whitespace. Use git apply --whitespace=fix. {color} |
| {color:green}+1{color} | {color:green} xml {color} | {color:green}  0m  3s{color} | {color:green} The patch has no ill-formed XML file. {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  0m 29s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m  9s{color} | {color:green} the patch passed {color} |
| {color:red}-1{color} | {color:red} unit {color} | {color:red}  2m 16s{color} | {color:red} hadoop-azure-datalake in the patch failed. {color} |
| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 15s{color} | {color:green} The patch does not generate ASF License warnings. {color} |
| {color:black}{color} | {color:black} {color} | {color:black} 13m 44s{color} | {color:black} {color} |
\\
\\
|| Reason || Tests ||
| Failed junit tests | hadoop.fs.adl.live.TestAdlFileSystemContractLive |
\\
\\
|| Subsystem || Report/Notes ||
| Docker |  Image:yetus/hadoop:2c91fd8 |
| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12803230/Hadoop-12875-004.patch |
| JIRA Issue | HADOOP-12875 |
| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  findbugs  checkstyle  xml  |
| uname | Linux ff48f6f32063 3.13.0-36-lowlatency #63-Ubuntu SMP PREEMPT Wed Sep 3 21:56:12 UTC 2014 x86_64 x86_64 x86_64 GNU/Linux |
| Build tool | maven |
| Personality | /testptch/hadoop/patchprocess/precommit/personality/provided.sh |
| git revision | trunk / 9581fb7 |
| Default Java | 1.8.0_91 |
| findbugs | v3.0.0 |
| findbugs | https://builds.apache.org/job/PreCommit-HADOOP-Build/9715/artifact/patchprocess/branch-findbugs-hadoop-tools_hadoop-azure-datalake-warnings.html |
| checkstyle | https://builds.apache.org/job/PreCommit-HADOOP-Build/9715/artifact/patchprocess/diff-checkstyle-hadoop-tools_hadoop-azure-datalake.txt |
| whitespace | https://builds.apache.org/job/PreCommit-HADOOP-Build/9715/artifact/patchprocess/whitespace-eol.txt |
| unit | https://builds.apache.org/job/PreCommit-HADOOP-Build/9715/artifact/patchprocess/patch-unit-hadoop-tools_hadoop-azure-datalake.txt |
|  Test Results | https://builds.apache.org/job/PreCommit-HADOOP-Build/9715/testReport/ |
| modules | C: hadoop-tools/hadoop-azure-datalake U: hadoop-tools/hadoop-azure-datalake |
| Console output | https://builds.apache.org/job/PreCommit-HADOOP-Build/9715/console |
| Powered by | Apache Yetus 0.4.0-SNAPSHOT   http://yetus.apache.org |


This message was automatically generated.

","10/Jun/16 10:17;stevel@apache.org; -1

Various tests are being skipped with a ""BUG"" commentary. those are signs of where the FS doesn't behave as expected. It's generally acceptable to skip tests where the feature is unimplemented especially in the quirks of object stores —but not where things are fundamentally at odds with [the filesystem specification|https://hadoop.apache.org/docs/stable2/hadoop-project-dist/hadoop-common/filesystem/filesystem.html] As an example, the test {{testRmNonEmptyRootDirNonRecursive()}} is skipped. That test is verifying a core feature of the FS behaviour. Same for {{AbstractContractMkdirTest.testNoMkdirOverFile()}}, where we say ""you cannot create a directory where there is a file"".
 
* TestListStatus uses {{System.out}}. Replace with logging
* Contract tests must not be using {{fs.default.fs}} as source; makes it impossible to have >1 FS in a test module. Look at how hadoop-aws defines a separate FS URI for each FS in options like {{test.fs.s3n.name}} and {{test.fs.s3a.name}}
* I don't understand why every setup has been overridden with a check for the test being enabled. The {{AdlStorageContract}} class should subclass {{isEnabled()}} for this
* Add a test for a seek of a long negative number, expect it throw an EOFException. Your seek() bounds checking only checks for -1, which is only a small subset of the possible negative seek ranges. This test should actually go into {{AbstractContractSeekTest}}, as we should see what other filesystems get up to.
* Rather than skip some of {{AbstractContractMkdirTest}}, these MUST be fixed.
* In {{TestConfigurationSetting}}}, all the {{close()}} calls must be designed to complete even in the presence of assertion failures. Use try-with-resources.
","10/Jun/16 18:49;cnauroth;[~stevel@apache.org], building on discussion in HADOOP-12666, our plan was to commit that and this together with known follow-on work to be tracked in separate JIRAs.  This would have broken the multi-month logjam on HADOOP-12666 and allowed further progress to proceed more iteratively and easily.  The contract tests, while still needing the additional work you pointed out, are still going to be helpful for catching regressions during subsequent work.  Can I please ask you to compromise, lift your -1, and defer these additional items to be tracked in separate JIRAs?  If not, then would you at least consider deferring a subset of those items?

I had kicked off a pre-commit run right after committing HADOOP-12666.  [~vishwajeet.dusane], the pre-commit warnings definitely need to be addressed, including the Findbugs warning.  Mysteriously, that Findbugs warning was not flagged during pre-commit of HADOOP-12666.","10/Jun/16 19:03;stevel@apache.org;OK, i'll lift it. Given the functional code is in there, the tests do at least track regressions.

=0.

I just do think all those skipped contract tests need to get working, for the benefit of everyone. I know doing it hurts: I've just managed to break listStatus() quite dramatically in a test run next to this browser and spent 2+ hours in the nuances of listFiles, but they are the closest thing we have in the hadoop codebase for trying to define what these implementations do. they are needed: and if they fail, that's a warning sign, not something to skip

I'd propose a followup JIRA then ""improve contract tests"", taking in my concerns","10/Jun/16 19:17;cnauroth;Steve, thank you for the flexibility.  I have filed HADOOP-13257 and copy-pasted your comments.

[~vishwajeet.dusane], the remaining thing we need to do on this patch is to address the warnings from pre-commit:

# Please fix the Findbugs warning.
# Please fix the Checkstyle warnings.  Sometimes Checkstyle warnings are overly pedantic and we proceed without addressing all of them.  Feel free to ask me if you think you're looking at a warning that might fall into that category, and I'd be happy to advise on whether or not I think it's necessary.
# Pre-commit is reporting tests as failing, because it won't have ADL credentials.  You probably need to adjust the test configuration setup and the pom.xml file so that tests won't get triggered if the credentials file is missing.  I recommend taking a look at the pom.xml in hadoop-aws for an example of how to do that.

bq. I just do think all those skipped contract tests need to get working, for the benefit of everyone.

Absolutely.  They are invaluable for catching issues before more costly long-running system tests.","13/Jun/16 10:30;vishwajeet.dusane;1. Fixed Findbugs warnings 
2. Fixed all checkstyle warnings. For unexplained reason these warning never showed up during local build as well.
3. Adjusted testConfiguration to run without failure when configuration is missing.","13/Jun/16 10:36;vishwajeet.dusane;[~cnauroth] and [~stevel@apache.org], thanks a lot for being flexible. [~stevel@apache.org] - Existing failing cases requires some change in our Adls backend server. Since the change to reflect in production environment is not immediate as of today and requires to go through internal test cycles, we agreed to mark those test as bug and once the fix is available in production environment, we would uncomment the overridden stub to execute the test.","13/Jun/16 10:55;hadoopqa;| (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 29s{color} | {color:blue} Docker mode activated. {color} |
| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |
| {color:green}+1{color} | {color:green} test4tests {color} | {color:green}  0m  0s{color} | {color:green} The patch appears to include 30 new or modified test files. {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  8m 13s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green}  0m 15s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 12s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  0m 19s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green}  0m 15s{color} | {color:green} trunk passed {color} |
| {color:red}-1{color} | {color:red} findbugs {color} | {color:red}  0m 28s{color} | {color:red} hadoop-tools/hadoop-azure-datalake in trunk has 1 extant Findbugs warnings. {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 13s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  0m 17s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green}  0m 16s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javac {color} | {color:green}  0m 16s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 11s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  0m 28s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green}  0m 13s{color} | {color:green} the patch passed {color} |
| {color:red}-1{color} | {color:red} whitespace {color} | {color:red}  0m  0s{color} | {color:red} The patch has 20 line(s) that end in whitespace. Use git apply --whitespace=fix. {color} |
| {color:green}+1{color} | {color:green} xml {color} | {color:green}  0m  3s{color} | {color:green} The patch has no ill-formed XML file. {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  0m 38s{color} | {color:green} hadoop-tools/hadoop-azure-datalake generated 0 new + 0 unchanged - 1 fixed = 0 total (was 1) {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 10s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} unit {color} | {color:green}  2m 23s{color} | {color:green} hadoop-azure-datalake in the patch passed. {color} |
| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 16s{color} | {color:green} The patch does not generate ASF License warnings. {color} |
| {color:black}{color} | {color:black} {color} | {color:black} 16m  4s{color} | {color:black} {color} |
\\
\\
|| Subsystem || Report/Notes ||
| Docker |  Image:yetus/hadoop:2c91fd8 |
| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12809807/Hadoop-12875-005.patch |
| JIRA Issue | HADOOP-12875 |
| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  findbugs  checkstyle  xml  |
| uname | Linux 1ca230bf08ea 3.13.0-36-lowlatency #63-Ubuntu SMP PREEMPT Wed Sep 3 21:56:12 UTC 2014 x86_64 x86_64 x86_64 GNU/Linux |
| Build tool | maven |
| Personality | /testptch/hadoop/patchprocess/precommit/personality/provided.sh |
| git revision | trunk / 28b66ae |
| Default Java | 1.8.0_91 |
| findbugs | v3.0.0 |
| findbugs | https://builds.apache.org/job/PreCommit-HADOOP-Build/9758/artifact/patchprocess/branch-findbugs-hadoop-tools_hadoop-azure-datalake-warnings.html |
| whitespace | https://builds.apache.org/job/PreCommit-HADOOP-Build/9758/artifact/patchprocess/whitespace-eol.txt |
|  Test Results | https://builds.apache.org/job/PreCommit-HADOOP-Build/9758/testReport/ |
| modules | C: hadoop-tools/hadoop-azure-datalake U: hadoop-tools/hadoop-azure-datalake |
| Console output | https://builds.apache.org/job/PreCommit-HADOOP-Build/9758/console |
| Powered by | Apache Yetus 0.4.0-SNAPSHOT   http://yetus.apache.org |


This message was automatically generated.

","13/Jun/16 13:19;vishwajeet.dusane;[~cnauroth] - White-space issue is originated from file {./hadoop-build-tools/src/main/resources/META-INF/LICENSE.txt} and not introduced in this patch. 
For Findbug issue reported - I have removed Math.round usage as well but still the warning has been pointed on the line which does not contain Math.Round usage. The issue does look like to be ignored, Could you please have a look once ? ","16/Jun/16 16:49;cnauroth;[~vishwajeet.dusane], thank you for pointing out the Findbugs misreporting.  I confirmed manually that this patch clears the Findbugs warning.

+1, and committed to trunk.","16/Jun/16 16:54;hudson;SUCCESS: Integrated in Hadoop-trunk-Commit #9969 (See [https://builds.apache.org/job/Hadoop-trunk-Commit/9969/])
HADOOP-12875. [Azure Data Lake] Support for contract test and unit test (cnauroth: rev c9e71382a58b6ffcb3fccb79d3c146877f1c8313)
* hadoop-tools/hadoop-azure-datalake/src/test/resources/adls.xml
* hadoop-tools/hadoop-azure-datalake/src/test/java/org/apache/hadoop/fs/adl/live/TestAdlContractOpenLive.java
* hadoop-tools/hadoop-azure-datalake/src/test/java/org/apache/hadoop/fs/common/AdlMockWebServer.java
* hadoop-tools/hadoop-azure-datalake/src/test/java/org/apache/hadoop/hdfs/web/TestSplitSizeCalculation.java
* hadoop-tools/hadoop-azure-datalake/src/test/java/org/apache/hadoop/fs/adl/live/AdlStorageConfiguration.java
* hadoop-tools/hadoop-azure-datalake/src/test/java/org/apache/hadoop/fs/adl/live/TestAdlContractDeleteLive.java
* hadoop-tools/hadoop-azure-datalake/src/test/java/org/apache/hadoop/fs/adl/live/TestAdlContractConcatLive.java
* hadoop-tools/hadoop-azure-datalake/src/test/java/org/apache/hadoop/hdfs/web/TestAdlRead.java
* hadoop-tools/hadoop-azure-datalake/src/test/java/org/apache/hadoop/fs/adl/live/TestAdlContractAppendLive.java
* hadoop-tools/hadoop-azure-datalake/src/test/java/org/apache/hadoop/fs/adl/live/TestAdlWebHdfsFileContextCreateMkdirLive.java
* hadoop-tools/hadoop-azure-datalake/src/test/java/org/apache/hadoop/fs/adl/live/TestAdlFileSystemContractLive.java
* hadoop-tools/hadoop-azure-datalake/src/test/java/org/apache/hadoop/fs/adl/live/TestAdlContractRenameLive.java
* hadoop-tools/hadoop-azure-datalake/src/test/java/org/apache/hadoop/hdfs/web/TestConcurrentDataReadOperations.java
* hadoop-tools/hadoop-azure-datalake/src/test/java/org/apache/hadoop/fs/adl/live/TestAdlContractMkdirLive.java
* hadoop-tools/hadoop-azure-datalake/src/test/java/org/apache/hadoop/fs/adl/TestListStatus.java
* hadoop-tools/hadoop-azure-datalake/src/test/java/org/apache/hadoop/fs/adl/live/AdlStorageContract.java
* hadoop-tools/hadoop-azure-datalake/src/test/java/org/apache/hadoop/fs/adl/live/TestAdlReadLive.java
* hadoop-tools/hadoop-azure-datalake/src/test/java/org/apache/hadoop/fs/adl/TestGetFileStatus.java
* hadoop-tools/hadoop-azure-datalake/src/test/java/org/apache/hadoop/fs/adl/live/TestAdlContractRootDirLive.java
* hadoop-tools/hadoop-azure-datalake/src/test/resources/contract-test-options.xml
* hadoop-tools/hadoop-azure-datalake/src/test/java/org/apache/hadoop/fs/adl/live/TestAdlWebHdfsFileContextMainOperationsLive.java
* hadoop-tools/hadoop-azure-datalake/src/test/java/org/apache/hadoop/fs/adl/live/TestAdlContractCreateLive.java
* hadoop-tools/hadoop-azure-datalake/src/test/java/org/apache/hadoop/hdfs/web/TestConfigurationSetting.java
* hadoop-tools/hadoop-azure-datalake/src/test/java/org/apache/hadoop/fs/adl/TestableAdlFileSystem.java
* hadoop-tools/hadoop-azure-datalake/src/main/java/org/apache/hadoop/hdfs/web/PrivateAzureDataLakeFileSystem.java
* hadoop-tools/hadoop-azure-datalake/src/test/java/org/apache/hadoop/fs/adl/live/TestAdlDifferentSizeWritesLive.java
* hadoop-tools/hadoop-azure-datalake/src/test/java/org/apache/hadoop/fs/adl/oauth2/TestCachedRefreshTokenBasedAccessTokenProvider.java
* hadoop-tools/hadoop-azure-datalake/src/test/java/org/apache/hadoop/fs/common/ExpectedResponse.java
* hadoop-tools/hadoop-azure-datalake/src/test/java/org/apache/hadoop/fs/adl/TestADLResponseData.java
* hadoop-tools/hadoop-azure-datalake/src/test/java/org/apache/hadoop/fs/common/TestDataForRead.java
* hadoop-tools/hadoop-azure-datalake/src/test/java/org/apache/hadoop/fs/adl/live/TestAdlContractSeekLive.java
","20/Mar/17 18:39;jzhuge;[~chris.douglas], [~vishwajeet.dusane] Should we backport this to branch-2.8.0 as well? Would love pass live ADLS unit tests in all supported branches.","20/Mar/17 18:57;vishwajeet.dusane;I think HADOOP-13257 ported to branch 2.8 should already cover the changes from this patch.","20/Mar/17 20:12;jzhuge;Thanks [~vishwajeet.dusane].",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
TestRawLocalFileSystemContract is needed,HADOOP-7363,12509487,Test,Resolved,HADOOP,Hadoop Common,software,omalley,Hadoop Common is the common library for Apache Hadoop.,http://hadoop.apache.org/,Major,Fixed,boky01,mattf,mattf,07/Jun/11 17:31,21/Nov/16 23:24,12/Jan/21 11:55,13/Sep/16 17:51,3.0.0-alpha2,,,,3.0.0-alpha1,,,,,,fs,,,,0,,,"FileSystemContractBaseTest is supposed to be run with each concrete FileSystem implementation to insure adherence to the ""contract"" for FileSystem behavior.  However, currently only HDFS and S3 do so.  RawLocalFileSystem, at least, needs to be added. ",,aengineer,andrew.wang,boky01,eli,hudson,mattf,stevel@apache.org,sureshms,tomwhite,,,,,,,,,,,,,,,,,,,,,,,,,HADOOP-7352,HDFS-303,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"20/Jul/16 14:05;boky01;HADOOP-7363.01.patch;https://issues.apache.org/jira/secure/attachment/12819094/HADOOP-7363.01.patch","21/Jul/16 09:24;boky01;HADOOP-7363.02.patch;https://issues.apache.org/jira/secure/attachment/12819295/HADOOP-7363.02.patch","21/Jul/16 12:02;boky01;HADOOP-7363.03.patch;https://issues.apache.org/jira/secure/attachment/12819308/HADOOP-7363.03.patch","18/Aug/16 16:58;boky01;HADOOP-7363.04.patch;https://issues.apache.org/jira/secure/attachment/12824403/HADOOP-7363.04.patch","19/Aug/16 09:00;boky01;HADOOP-7363.05.patch;https://issues.apache.org/jira/secure/attachment/12824522/HADOOP-7363.05.patch","26/Aug/16 15:47;boky01;HADOOP-7363.06.patch;https://issues.apache.org/jira/secure/attachment/12825674/HADOOP-7363.06.patch",,,,,,,,,,,,,,,,,,6.0,,,,,,,,,,,,,,,,,,,,2016-05-04 19:56:02.174,,,false,,,,,,,,,,,,,,,,,71029,Reviewed,,,,Tue Oct 18 22:14:20 UTC 2016,,,,,,,"0|i0hwqf:",102565,,,,,,,,,,,,,3.0.0-alpha2,,,,,,,,,,"17/Jun/11 21:17;mattf;There is overlap between the intent of this ticket and the existing TestFSMainOperationsLocalFileSystem and FSMainOperationsBaseTest.","04/May/16 19:56;boky01;Currently 35 test case fails from 43 with RawLocalFileSystem.","10/May/16 13:59;boky01;Where do you think the test should be placed? org.apache.hadoop.fs package sounds good?","12/May/16 13:54;boky01;Adding [^HADOOP-7363.01.patch].
It will fail until HADOOP-13073 is merged.","12/May/16 14:36;boky01;[^HADOOP-7363.01.patch] was tested on Windows, CentOS and Mac.
Notes:
# I consider Windows and Mac as non-case sensitive filesystem. So related tests will skipped.
# I set rename support to false to skip the related tests. See HADOOP-13082 for details.
# I overwrote {{path}} method. A lot of tests are based on writing root directory which is not permitted on local filesystems. Instead the tests will work into target directory.
# {{testLSRootDir}} and {{testListStatusRootDir}} will also work into target instead of root directory. It tries to create a directory on root which is not allowed to test user. With this solution we are still able to test the listing and status checking functions of the filesystem. I did not see any reason to force the code to work on root. In case of a raw local fs there is no difference between / and other directories (other than permissions). 
# Please help whether I chose correct package for my new test.

In spite of that it fails until HADOOP-13073 resolved/merged a review is welcome.","20/Jul/16 14:05;boky01;Reattach patch 01 to kick [~hadoopqa].","20/Jul/16 18:00;hadoopqa;| (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m  0s{color} | {color:blue} Docker mode activated. {color} |
| {color:red}-1{color} | {color:red} patch {color} | {color:red}  0m  4s{color} | {color:red} HADOOP-7363 does not apply to trunk. Rebase required? Wrong Branch? See https://wiki.apache.org/hadoop/HowToContribute for help. {color} |
\\
\\
|| Subsystem || Report/Notes ||
| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12819094/HADOOP-7363.01.patch |
| JIRA Issue | HADOOP-7363 |
| Console output | https://builds.apache.org/job/PreCommit-HADOOP-Build/10031/console |
| Powered by | Apache Yetus 0.4.0-SNAPSHOT   http://yetus.apache.org |


This message was automatically generated.

","20/Jul/16 21:21;hadoopqa;| (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m  0s{color} | {color:blue} Docker mode activated. {color} |
| {color:red}-1{color} | {color:red} patch {color} | {color:red}  0m  4s{color} | {color:red} HADOOP-7363 does not apply to trunk. Rebase required? Wrong Branch? See https://wiki.apache.org/hadoop/HowToContribute for help. {color} |
\\
\\
|| Subsystem || Report/Notes ||
| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12819094/HADOOP-7363.01.patch |
| JIRA Issue | HADOOP-7363 |
| Console output | https://builds.apache.org/job/PreCommit-HADOOP-Build/10036/console |
| Powered by | Apache Yetus 0.4.0-SNAPSHOT   http://yetus.apache.org |


This message was automatically generated.

","21/Jul/16 09:24;boky01;My path does not apply since HADOOP-12709.
I am attaching [^HADOOP-7363.02.patch] for rebase.","21/Jul/16 10:15;hadoopqa;| (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 26s{color} | {color:blue} Docker mode activated. {color} |
| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |
| {color:green}+1{color} | {color:green} test4tests {color} | {color:green}  0m  0s{color} | {color:green} The patch appears to include 2 new or modified test files. {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  6m 59s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green}  7m  3s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 24s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  0m 55s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green}  0m 13s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  1m 20s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 46s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  0m 38s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green}  6m 56s{color} | {color:green} the patch passed {color} |
| {color:red}-1{color} | {color:red} javac {color} | {color:red}  6m 56s{color} | {color:red} root generated 1 new + 708 unchanged - 1 fixed = 709 total (was 709) {color} |
| {color:orange}-0{color} | {color:orange} checkstyle {color} | {color:orange}  0m 23s{color} | {color:orange} hadoop-common-project/hadoop-common: The patch generated 3 new + 35 unchanged - 0 fixed = 38 total (was 35) {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  0m 53s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green}  0m 13s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  1m 27s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 45s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} unit {color} | {color:green}  7m 13s{color} | {color:green} hadoop-common in the patch passed. {color} |
| {color:red}-1{color} | {color:red} asflicense {color} | {color:red}  0m 21s{color} | {color:red} The patch generated 1 ASF License warnings. {color} |
| {color:black}{color} | {color:black} {color} | {color:black} 38m 19s{color} | {color:black} {color} |
\\
\\
|| Subsystem || Report/Notes ||
| Docker |  Image:yetus/hadoop:9560f25 |
| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12819295/HADOOP-7363.02.patch |
| JIRA Issue | HADOOP-7363 |
| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  findbugs  checkstyle  |
| uname | Linux b65402f33702 3.13.0-36-lowlatency #63-Ubuntu SMP PREEMPT Wed Sep 3 21:56:12 UTC 2014 x86_64 x86_64 x86_64 GNU/Linux |
| Build tool | maven |
| Personality | /testptch/hadoop/patchprocess/precommit/personality/provided.sh |
| git revision | trunk / 557a245 |
| Default Java | 1.8.0_91 |
| findbugs | v3.0.0 |
| javac | https://builds.apache.org/job/PreCommit-HADOOP-Build/10053/artifact/patchprocess/diff-compile-javac-root.txt |
| checkstyle | https://builds.apache.org/job/PreCommit-HADOOP-Build/10053/artifact/patchprocess/diff-checkstyle-hadoop-common-project_hadoop-common.txt |
|  Test Results | https://builds.apache.org/job/PreCommit-HADOOP-Build/10053/testReport/ |
| asflicense | https://builds.apache.org/job/PreCommit-HADOOP-Build/10053/artifact/patchprocess/patch-asflicense-problems.txt |
| modules | C: hadoop-common-project/hadoop-common U: hadoop-common-project/hadoop-common |
| Console output | https://builds.apache.org/job/PreCommit-HADOOP-Build/10053/console |
| Powered by | Apache Yetus 0.4.0-SNAPSHOT   http://yetus.apache.org |


This message was automatically generated.

","21/Jul/16 12:02;boky01;Uploading patch 03 to eliminate Hadoop QA warnings.","21/Jul/16 14:08;hadoopqa;| (/) *{color:green}+1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 25s{color} | {color:blue} Docker mode activated. {color} |
| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |
| {color:green}+1{color} | {color:green} test4tests {color} | {color:green}  0m  0s{color} | {color:green} The patch appears to include 2 new or modified test files. {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  7m  3s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green}  6m 54s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 23s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  0m 57s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green}  0m 13s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  1m 21s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 44s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  0m 38s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green}  7m  1s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javac {color} | {color:green}  7m  1s{color} | {color:green} root generated 0 new + 708 unchanged - 1 fixed = 708 total (was 709) {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 24s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  0m 55s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green}  0m 12s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  1m 34s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 49s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} unit {color} | {color:green}  7m 38s{color} | {color:green} hadoop-common in the patch passed. {color} |
| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 23s{color} | {color:green} The patch does not generate ASF License warnings. {color} |
| {color:black}{color} | {color:black} {color} | {color:black} 38m 57s{color} | {color:black} {color} |
\\
\\
|| Subsystem || Report/Notes ||
| Docker |  Image:yetus/hadoop:9560f25 |
| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12819308/HADOOP-7363.03.patch |
| JIRA Issue | HADOOP-7363 |
| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  findbugs  checkstyle  |
| uname | Linux 73aba80d7dd7 3.13.0-36-lowlatency #63-Ubuntu SMP PREEMPT Wed Sep 3 21:56:12 UTC 2014 x86_64 x86_64 x86_64 GNU/Linux |
| Build tool | maven |
| Personality | /testptch/hadoop/patchprocess/precommit/personality/provided.sh |
| git revision | trunk / 557a245 |
| Default Java | 1.8.0_91 |
| findbugs | v3.0.0 |
|  Test Results | https://builds.apache.org/job/PreCommit-HADOOP-Build/10054/testReport/ |
| modules | C: hadoop-common-project/hadoop-common U: hadoop-common-project/hadoop-common |
| Console output | https://builds.apache.org/job/PreCommit-HADOOP-Build/10054/console |
| Powered by | Apache Yetus 0.4.0-SNAPSHOT   http://yetus.apache.org |


This message was automatically generated.

","21/Jul/16 14:26;boky01;Can somebody review my patch? I got my +1 from Hadoop QA.","21/Jul/16 14:44;hadoopqa;| (/) *{color:green}+1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 27s{color} | {color:blue} Docker mode activated. {color} |
| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |
| {color:green}+1{color} | {color:green} test4tests {color} | {color:green}  0m  0s{color} | {color:green} The patch appears to include 2 new or modified test files. {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  6m 35s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green}  6m 46s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 23s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  0m 54s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green}  0m 12s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  1m 18s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 46s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  0m 41s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green}  6m 57s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javac {color} | {color:green}  6m 57s{color} | {color:green} root generated 0 new + 708 unchanged - 1 fixed = 708 total (was 709) {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 23s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  0m 52s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green}  0m 13s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  1m 35s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 46s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} unit {color} | {color:green}  7m 20s{color} | {color:green} hadoop-common in the patch passed. {color} |
| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 20s{color} | {color:green} The patch does not generate ASF License warnings. {color} |
| {color:black}{color} | {color:black} {color} | {color:black} 37m 55s{color} | {color:black} {color} |
\\
\\
|| Subsystem || Report/Notes ||
| Docker |  Image:yetus/hadoop:9560f25 |
| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12819308/HADOOP-7363.03.patch |
| JIRA Issue | HADOOP-7363 |
| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  findbugs  checkstyle  |
| uname | Linux ccdde068dda8 3.13.0-36-lowlatency #63-Ubuntu SMP PREEMPT Wed Sep 3 21:56:12 UTC 2014 x86_64 x86_64 x86_64 GNU/Linux |
| Build tool | maven |
| Personality | /testptch/hadoop/patchprocess/precommit/personality/provided.sh |
| git revision | trunk / 557a245 |
| Default Java | 1.8.0_91 |
| findbugs | v3.0.0 |
|  Test Results | https://builds.apache.org/job/PreCommit-HADOOP-Build/10056/testReport/ |
| modules | C: hadoop-common-project/hadoop-common U: hadoop-common-project/hadoop-common |
| Console output | https://builds.apache.org/job/PreCommit-HADOOP-Build/10056/console |
| Powered by | Apache Yetus 0.4.0-SNAPSHOT   http://yetus.apache.org |


This message was automatically generated.

","17/Aug/16 21:47;aengineer;[~boky01] Thanks for adding this test case. One small comment. 
{{FileSystemContractBaseTest.java#Line 181}}: After the {{catch (UnsupportedOperationException e)}}, we seem to continue. Did you want to abort the test at that point ?  

typo : scema =>schema ","18/Aug/16 17:11;aengineer;[~boky01] Thanks for updating the patch. But I see that we still catch the UnsupportedOperationException and then continue the test. That seems little strange to me. We do log a WARN though. I am sure I am missing something here, could you please take a moment and explain to me why the test is doing this ? 

","18/Aug/16 17:46;hadoopqa;| (/) *{color:green}+1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 15s{color} | {color:blue} Docker mode activated. {color} |
| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |
| {color:green}+1{color} | {color:green} test4tests {color} | {color:green}  0m  0s{color} | {color:green} The patch appears to include 2 new or modified test files. {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  6m 42s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green}  6m 45s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 23s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  0m 54s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green}  0m 12s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  1m 20s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 45s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  0m 37s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green}  6m 42s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javac {color} | {color:green}  6m 42s{color} | {color:green} root generated 0 new + 709 unchanged - 1 fixed = 709 total (was 710) {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 23s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  0m 52s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green}  0m 13s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  1m 25s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 45s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} unit {color} | {color:green}  8m  3s{color} | {color:green} hadoop-common in the patch passed. {color} |
| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 21s{color} | {color:green} The patch does not generate ASF License warnings. {color} |
| {color:black}{color} | {color:black} {color} | {color:black} 38m  2s{color} | {color:black} {color} |
\\
\\
|| Subsystem || Report/Notes ||
| Docker |  Image:yetus/hadoop:9560f25 |
| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12824403/HADOOP-7363.04.patch |
| JIRA Issue | HADOOP-7363 |
| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  findbugs  checkstyle  |
| uname | Linux 27db1e9ad139 3.13.0-36-lowlatency #63-Ubuntu SMP PREEMPT Wed Sep 3 21:56:12 UTC 2014 x86_64 x86_64 x86_64 GNU/Linux |
| Build tool | maven |
| Personality | /testptch/hadoop/patchprocess/precommit/personality/provided.sh |
| git revision | trunk / 0da69c3 |
| Default Java | 1.8.0_101 |
| findbugs | v3.0.0 |
|  Test Results | https://builds.apache.org/job/PreCommit-HADOOP-Build/10298/testReport/ |
| modules | C: hadoop-common-project/hadoop-common U: hadoop-common-project/hadoop-common |
| Console output | https://builds.apache.org/job/PreCommit-HADOOP-Build/10298/console |
| Powered by | Apache Yetus 0.4.0-SNAPSHOT   http://yetus.apache.org |


This message was automatically generated.

","19/Aug/16 08:59;boky01;Hi [~anu],

I was going to explain but I realized my new patch needs some change.

So the related test checks whether the FileSystem is S3 or not by schema name. If it is S3 we skip the test because S3 does not implement permissions.
In case of {{RawLocalFileSystem}} the {{getScheme}} call throws {{UnsupportedOperationException}} which does not mean an error happened. Actually it is not a problem at all. In that block we just need to check the S3. We don't have to stop the test in case of UnsupportedOperationException.

So far the test cases did not run with {{RawLocalFileSystem}}. That is why they did not get exception so far.

I am uploading patch 05.

Does it make sense?","19/Aug/16 09:46;hadoopqa;| (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 16s{color} | {color:blue} Docker mode activated. {color} |
| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |
| {color:green}+1{color} | {color:green} test4tests {color} | {color:green}  0m  0s{color} | {color:green} The patch appears to include 2 new or modified test files. {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  6m 38s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green}  6m 45s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 23s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  0m 54s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green}  0m 13s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  1m 19s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 46s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  0m 37s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green}  6m 42s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javac {color} | {color:green}  6m 42s{color} | {color:green} root generated 0 new + 709 unchanged - 1 fixed = 709 total (was 710) {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 23s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  0m 51s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green}  0m 13s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  1m 27s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 46s{color} | {color:green} the patch passed {color} |
| {color:red}-1{color} | {color:red} unit {color} | {color:red}  7m 42s{color} | {color:red} hadoop-common in the patch failed. {color} |
| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 21s{color} | {color:green} The patch does not generate ASF License warnings. {color} |
| {color:black}{color} | {color:black} {color} | {color:black} 37m 39s{color} | {color:black} {color} |
\\
\\
|| Reason || Tests ||
| Failed junit tests | hadoop.net.TestClusterTopology |
\\
\\
|| Subsystem || Report/Notes ||
| Docker |  Image:yetus/hadoop:9560f25 |
| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12824522/HADOOP-7363.05.patch |
| JIRA Issue | HADOOP-7363 |
| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  findbugs  checkstyle  |
| uname | Linux 7475aea66078 3.13.0-36-lowlatency #63-Ubuntu SMP PREEMPT Wed Sep 3 21:56:12 UTC 2014 x86_64 x86_64 x86_64 GNU/Linux |
| Build tool | maven |
| Personality | /testptch/hadoop/patchprocess/precommit/personality/provided.sh |
| git revision | trunk / 8179f9a |
| Default Java | 1.8.0_101 |
| findbugs | v3.0.0 |
| unit | https://builds.apache.org/job/PreCommit-HADOOP-Build/10307/artifact/patchprocess/patch-unit-hadoop-common-project_hadoop-common.txt |
|  Test Results | https://builds.apache.org/job/PreCommit-HADOOP-Build/10307/testReport/ |
| modules | C: hadoop-common-project/hadoop-common U: hadoop-common-project/hadoop-common |
| Console output | https://builds.apache.org/job/PreCommit-HADOOP-Build/10307/console |
| Powered by | Apache Yetus 0.4.0-SNAPSHOT   http://yetus.apache.org |


This message was automatically generated.

","19/Aug/16 13:56;boky01;Test fail is unrelated.","19/Aug/16 16:07;aengineer;[~boky01] Thanks for taking time out to explain this to me. Now that I understand why you are doing this, may I suggest that we re-write that try catch as a function, something like isS3a(fs) and then the code would look like

if (!isS3a(fs)) {
// assume it is a raw file system
}

I feel that might add more clarity to code rather than just continuing in the face of an exception, which would make the next developer reading code wonder if that is a bug.
","22/Aug/16 15:01;boky01;Hi [~anu],

Good point. In addition I would use Assume framework so the test would be skipped instead of passed in case of S3.
The problem is that this test is based on JUnit3 but I am not sure if changing to JUnit4 is out of scope on this ticket or not. If so I can create another clean up ticket to take care with this and other issues (IDE, checkstyle warnings, {{testFilesystemIsCaseSensitive}} could also use Assume, and so on).
What do you think?","22/Aug/16 16:31;aengineer;[~boky01] Thank you for your comments. I do agree that a deeper cleanup in another JIRA is useful. However  I do feel that we should *not* check-in the current change as is .. where we catch an exception, log a warn and continue running the test. That pattern is really hard for someone to understand. While I do see that there are a bunch of things that you mentioned that needs cleanup, committing this fragment of code would be confusing to other maintainers.

so if you don't mind, let us fix this one issue in this JIRA and get this committed or fix all the things you are mentioning in this change list itself, either one works.","26/Aug/16 15:47;boky01;[~anu],

I extracted the logic to {{isS3}} method and I added some explanation in javadoc.
I was struggling with javadoc generation due to some memory issue. I will investigate it later.
I will create a cleanup JIRA on the class as of ""The Boy Scout Rule"".
Please check the new patch.","26/Aug/16 16:27;hadoopqa;| (/) *{color:green}+1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 19s{color} | {color:blue} Docker mode activated. {color} |
| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |
| {color:green}+1{color} | {color:green} test4tests {color} | {color:green}  0m  0s{color} | {color:green} The patch appears to include 2 new or modified test files. {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  6m 39s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green}  6m 47s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 23s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  0m 53s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green}  0m 13s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  1m 19s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 45s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  0m 36s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green}  6m 46s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javac {color} | {color:green}  6m 46s{color} | {color:green} root generated 0 new + 709 unchanged - 1 fixed = 709 total (was 710) {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 23s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  0m 51s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green}  0m 12s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  1m 26s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 45s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} unit {color} | {color:green}  8m  8s{color} | {color:green} hadoop-common in the patch passed. {color} |
| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 21s{color} | {color:green} The patch does not generate ASF License warnings. {color} |
| {color:black}{color} | {color:black} {color} | {color:black} 38m 15s{color} | {color:black} {color} |
\\
\\
|| Subsystem || Report/Notes ||
| Docker |  Image:yetus/hadoop:9560f25 |
| JIRA Issue | HADOOP-7363 |
| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12824522/HADOOP-7363.05.patch |
| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  findbugs  checkstyle  |
| uname | Linux 9b9caaa0f634 3.13.0-36-lowlatency #63-Ubuntu SMP PREEMPT Wed Sep 3 21:56:12 UTC 2014 x86_64 x86_64 x86_64 GNU/Linux |
| Build tool | maven |
| Personality | /testptch/hadoop/patchprocess/precommit/personality/provided.sh |
| git revision | trunk / 13fb1b5 |
| Default Java | 1.8.0_101 |
| findbugs | v3.0.0 |
|  Test Results | https://builds.apache.org/job/PreCommit-HADOOP-Build/10382/testReport/ |
| modules | C: hadoop-common-project/hadoop-common U: hadoop-common-project/hadoop-common |
| Console output | https://builds.apache.org/job/PreCommit-HADOOP-Build/10382/console |
| Powered by | Apache Yetus 0.4.0-SNAPSHOT   http://yetus.apache.org |


This message was automatically generated.

","26/Aug/16 17:14;aengineer;Thanks for the new patch. It looks really good. One small issue, my apologies for not noticing this in the earlier code reviews.
We seem to use a path ==> ""/test/newDir"" shouldn't this be relative to the test directory rather than absolute path ? Otherwise the patch is good to go.","29/Aug/16 12:27;boky01;Hi [~anu],

That is why I overwrote {{path()}} method in {{TestRawLocalFileSystemContract}}. The tests will work into target directory. The {{GenericTestUtils.getTempPath(pathString)}} will return with taget directory + pathString.","29/Aug/16 15:45;aengineer;+1, Sorry I missed that. I will commit this shortly.","29/Aug/16 16:28;aengineer;[~boky01] Thanks for taking care of this. I have committed this to Trunk , I am not resolving this since there are some conflicts when applying to branch-2. Could you please post a patch for branch-2 too. I will use this same jira to commit to branch-2 too.

","29/Aug/16 16:40;hudson;SUCCESS: Integrated in Jenkins build Hadoop-trunk-Commit #10365 (See [https://builds.apache.org/job/Hadoop-trunk-Commit/10365/])
HADOOP-7363. TestRawLocalFileSystemContract is needed. Contributed by (aengineer: rev e1ad598cef61cbd3a6f505f40221c8140a36b7e4)
* (edit) hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/FileSystemContractBaseTest.java
* (add) hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/TestRawLocalFileSystemContract.java
","29/Aug/16 19:05;boky01;Thanks a lot [~anu],

Should this patch be available on branch-2? It only adds some JUnit tests.
In addition, this ticket was blocked by one of my other tickets: HADOOP-13073. HADOOP-13073 was not merged into branch-2 so {{testMkdirsWithUmask}} will not pass.","13/Sep/16 17:51;aengineer;Since we decided that this is not going into branch-2, resolving this issue. [~boky01] Thank you for the contribution.","14/Sep/16 14:51;boky01;Thanks a lot for all of your help [~anu].","18/Oct/16 22:14;andrew.wang;Looks like this was not committed to branch-2 and only to trunk, so updating fix/target versions.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Create MiniKMS for testing,HADOOP-11070,12739581,Test,Closed,HADOOP,Hadoop Common,software,omalley,Hadoop Common is the common library for Apache Hadoop.,http://hadoop.apache.org/,Major,Fixed,tucu00,tucu00,tucu00,05/Sep/14 20:15,16/Nov/16 20:34,12/Jan/21 11:55,06/Sep/14 05:02,2.6.0,,,,2.6.0,,,,,,security,test,,,0,,,This will facilitate testing HDFS and MR with HDFS encryption fully reproducing a real deployment setup.,,andrew.wang,apurtell,hudson,tucu00,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,HDFS-7006,,,,,,,,,,,,,,,,,HADOOP-13597,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"05/Sep/14 20:16;tucu00;HADOOP-11070.patch;https://issues.apache.org/jira/secure/attachment/12666875/HADOOP-11070.patch",,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,2014-09-05 20:27:12.128,,,false,,,,,,,,,,,,,,,,,9223372036854775807,Reviewed,,,,Sat Sep 06 14:06:27 UTC 2014,,,,,,,"0|i1zqpz:",9223372036854775807,,,,,,,,,,,,,2.6.0,,,,,,,,,,"05/Sep/14 20:27;andrew.wang;+1","05/Sep/14 20:47;hadoopqa;{color:green}+1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12666875/HADOOP-11070.patch
  against trunk revision 0571b45.

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 2 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  There were no new javadoc warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 2.0.3) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:green}+1 core tests{color}.  The patch passed unit tests in hadoop-common-project/hadoop-kms.

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HADOOP-Build/4661//testReport/
Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/4661//console

This message is automatically generated.","06/Sep/14 05:02;tucu00;committed to trunk and branch-2.","06/Sep/14 11:28;hudson;SUCCESS: Integrated in Hadoop-Yarn-trunk #672 (See [https://builds.apache.org/job/Hadoop-Yarn-trunk/672/])
HADOOP-11070. Create MiniKMS for testing. (tucu) (tucu: rev 71c8d735f5038e3b516947f12180d7568b6979dc)
* hadoop-common-project/hadoop-kms/src/test/java/org/apache/hadoop/crypto/key/kms/server/MiniKMS.java
* hadoop-common-project/hadoop-common/CHANGES.txt
* hadoop-common-project/hadoop-kms/pom.xml
* hadoop-common-project/hadoop-kms/src/test/java/org/apache/hadoop/crypto/key/kms/server/TestKMS.java
","06/Sep/14 13:44;hudson;FAILURE: Integrated in Hadoop-Mapreduce-trunk #1888 (See [https://builds.apache.org/job/Hadoop-Mapreduce-trunk/1888/])
HADOOP-11070. Create MiniKMS for testing. (tucu) (tucu: rev 71c8d735f5038e3b516947f12180d7568b6979dc)
* hadoop-common-project/hadoop-common/CHANGES.txt
* hadoop-common-project/hadoop-kms/src/test/java/org/apache/hadoop/crypto/key/kms/server/MiniKMS.java
* hadoop-common-project/hadoop-kms/src/test/java/org/apache/hadoop/crypto/key/kms/server/TestKMS.java
* hadoop-common-project/hadoop-kms/pom.xml
","06/Sep/14 14:06;hudson;SUCCESS: Integrated in Hadoop-Hdfs-trunk #1863 (See [https://builds.apache.org/job/Hadoop-Hdfs-trunk/1863/])
HADOOP-11070. Create MiniKMS for testing. (tucu) (tucu: rev 71c8d735f5038e3b516947f12180d7568b6979dc)
* hadoop-common-project/hadoop-kms/pom.xml
* hadoop-common-project/hadoop-common/CHANGES.txt
* hadoop-common-project/hadoop-kms/src/test/java/org/apache/hadoop/crypto/key/kms/server/MiniKMS.java
* hadoop-common-project/hadoop-kms/src/test/java/org/apache/hadoop/crypto/key/kms/server/TestKMS.java
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Unittest TestKeyShell, TestCredShell and TestKMS assume UNIX path separator for JECKS key store path",HADOOP-11088,12741113,Test,Closed,HADOOP,Hadoop Common,software,omalley,Hadoop Common is the common library for Apache Hadoop.,http://hadoop.apache.org/,Major,Fixed,xyao,xyao,xyao,12/Sep/14 17:37,03/Nov/16 23:10,12/Jan/21 11:55,12/Sep/14 21:53,2.4.1,,,,2.6.0,,,,,,security,,,,0,,,"TestKeyShell and TestCredShell assume UNIX path separator for JECKS key store path. This will fail the tests on Windows which uses a different path separator. The fix should be something like:

{code}
-    jceksProvider = ""jceks://file"" + tmpDir + ""/keystore.jceks"";
+    final Path jksPath = new Path(tmpDir.toString(), ""keystore.jceks"");
+    jceksProvider = ""jceks://file"" + jksPath.toUri();
{code}


",,cnauroth,hudson,xyao,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"12/Sep/14 18:41;xyao;HADOOP-11088.0.patch;https://issues.apache.org/jira/secure/attachment/12668423/HADOOP-11088.0.patch","12/Sep/14 21:31;xyao;HADOOP-11088.1.patch;https://issues.apache.org/jira/secure/attachment/12668466/HADOOP-11088.1.patch",,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,2014-09-12 20:43:05.503,,,false,,,,,,,,,,,,,,,,,9223372036854775807,Reviewed,,,,Thu Nov 03 23:10:32 UTC 2016,,,,,,,"0|i1zzfj:",9223372036854775807,,,,,,,,,,,,,2.6.0,,,,,,,,,,"12/Sep/14 20:43;hadoopqa;{color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12668423/HADOOP-11088.0.patch
  against trunk revision 3122daa.

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 4 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  There were no new javadoc warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 2.0.3) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:red}-1 core tests{color}.  The patch failed these unit tests in hadoop-common-project/hadoop-common hadoop-common-project/hadoop-kms:

                  org.apache.hadoop.ipc.TestFairCallQueue
                  org.apache.hadoop.crypto.key.TestValueQueue
                  org.apache.hadoop.ipc.TestDecayRpcScheduler
                  org.apache.hadoop.ipc.TestIPC
                  org.apache.hadoop.crypto.random.TestOsSecureRandom
                  org.apache.hadoop.crypto.key.kms.server.TestKMS

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HADOOP-Build/4704//testReport/
Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/4704//console

This message is automatically generated.","12/Sep/14 21:02;cnauroth;Hi, [~xyao].  In {{KMSConfiguration}}, I think we'll want to preserve the validation checks that the configuration directory is an absolute path.  The existing implementation that checks for '/' as the first character is incorrect though.  Instead, we can check {{Path#isUriPathAbsolute}}.  That method is already implemented to handle this correctly cross-platform.

Otherwise, the patch looks good.","12/Sep/14 21:31;xyao;Thanks [~cnauroth] for reviewing the fix. I've updated the patch.","12/Sep/14 21:49;cnauroth;+1 for the patch.  I verified that it works on Mac and Windows.  I'll commit this.","12/Sep/14 21:53;cnauroth;I committed this to trunk and branch-2.  Xiaoyu, thank you for providing this patch.","12/Sep/14 23:15;hadoopqa;{color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12668466/HADOOP-11088.1.patch
  against trunk revision 54e5794.

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 4 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  There were no new javadoc warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 2.0.3) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:red}-1 core tests{color}.  The patch failed these unit tests in hadoop-common-project/hadoop-common hadoop-common-project/hadoop-kms:

                  org.apache.hadoop.ipc.TestFairCallQueue
                  org.apache.hadoop.crypto.key.TestValueQueue
                  org.apache.hadoop.crypto.random.TestOsSecureRandom

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HADOOP-Build/4707//testReport/
Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/4707//console

This message is automatically generated.","13/Sep/14 11:29;hudson;SUCCESS: Integrated in Hadoop-Yarn-trunk #679 (See [https://builds.apache.org/job/Hadoop-Yarn-trunk/679/])
HADOOP-11088. Unittest TestKeyShell, TestCredShell and TestKMS assume UNIX path separator for JECKS key store path. Contributed by Xiaoyu Yao. (cnauroth: rev 957414d4cb57cb8172070cc53530b7da78b8c9ca)
* hadoop-common-project/hadoop-kms/src/test/java/org/apache/hadoop/crypto/key/kms/server/TestKMS.java
* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/crypto/key/TestKeyShell.java
* hadoop-common-project/hadoop-kms/src/test/java/org/apache/hadoop/crypto/key/kms/server/MiniKMS.java
* hadoop-common-project/hadoop-common/CHANGES.txt
* hadoop-common-project/hadoop-kms/src/main/java/org/apache/hadoop/crypto/key/kms/server/KMSConfiguration.java
* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/security/alias/TestCredShell.java
","13/Sep/14 13:47;hudson;FAILURE: Integrated in Hadoop-Mapreduce-trunk #1895 (See [https://builds.apache.org/job/Hadoop-Mapreduce-trunk/1895/])
HADOOP-11088. Unittest TestKeyShell, TestCredShell and TestKMS assume UNIX path separator for JECKS key store path. Contributed by Xiaoyu Yao. (cnauroth: rev 957414d4cb57cb8172070cc53530b7da78b8c9ca)
* hadoop-common-project/hadoop-kms/src/test/java/org/apache/hadoop/crypto/key/kms/server/MiniKMS.java
* hadoop-common-project/hadoop-common/CHANGES.txt
* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/crypto/key/TestKeyShell.java
* hadoop-common-project/hadoop-kms/src/main/java/org/apache/hadoop/crypto/key/kms/server/KMSConfiguration.java
* hadoop-common-project/hadoop-kms/src/test/java/org/apache/hadoop/crypto/key/kms/server/TestKMS.java
* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/security/alias/TestCredShell.java
","13/Sep/14 14:05;hudson;SUCCESS: Integrated in Hadoop-Hdfs-trunk #1870 (See [https://builds.apache.org/job/Hadoop-Hdfs-trunk/1870/])
HADOOP-11088. Unittest TestKeyShell, TestCredShell and TestKMS assume UNIX path separator for JECKS key store path. Contributed by Xiaoyu Yao. (cnauroth: rev 957414d4cb57cb8172070cc53530b7da78b8c9ca)
* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/crypto/key/TestKeyShell.java
* hadoop-common-project/hadoop-kms/src/test/java/org/apache/hadoop/crypto/key/kms/server/TestKMS.java
* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/security/alias/TestCredShell.java
* hadoop-common-project/hadoop-kms/src/test/java/org/apache/hadoop/crypto/key/kms/server/MiniKMS.java
* hadoop-common-project/hadoop-kms/src/main/java/org/apache/hadoop/crypto/key/kms/server/KMSConfiguration.java
* hadoop-common-project/hadoop-common/CHANGES.txt
","03/Nov/16 23:10;hudson;SUCCESS: Integrated in Jenkins build Hadoop-trunk-Commit #10768 (See [https://builds.apache.org/job/Hadoop-trunk-Commit/10768/])
HADOOP-11088. Quash unnecessary safemode WARN message during NameNode (wang: rev 5cad93d5c753112931ce97dba966d1ce6b53724b)
* (edit) hadoop-hdfs-project/hadoop-hdfs/src/main/java/org/apache/hadoop/hdfs/server/blockmanagement/BlockManagerSafeMode.java
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
HADOOP-13614 pre-commit testing JIRA,HADOOP-13758,13015194,Test,Resolved,HADOOP,Hadoop Common,software,omalley,Hadoop Common is the common library for Apache Hadoop.,http://hadoop.apache.org/,Major,Duplicate,stevel@apache.org,cnauroth,cnauroth,25/Oct/16 18:56,26/Oct/16 15:41,12/Jan/21 11:55,26/Oct/16 15:41,,,,,,,,,,,fs/s3,,,,0,,,We've hit a situation where pre-commit testing on HADOOP-13614 is blocked due to some confusion in the interactions between patch file attachments and GitHub pull requests.  This is a fresh JIRA issue intended to help facilitate pre-commit testing for HADOOP-13614.,,cnauroth,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,HADOOP-13614,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"25/Oct/16 18:57;cnauroth;HADOOP-13758-branch-2.001.patch;https://issues.apache.org/jira/secure/attachment/12835173/HADOOP-13758-branch-2.001.patch","25/Oct/16 21:49;cnauroth;HADOOP-13758-branch-2.002.patch;https://issues.apache.org/jira/secure/attachment/12835208/HADOOP-13758-branch-2.002.patch",,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,2016-10-25 20:33:36.511,,,false,,,,,,,,,,,,,,,,,9223372036854775807,,,,,Wed Oct 26 15:41:07 UTC 2016,,,,,,,"0|i35dpz:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,"25/Oct/16 18:56;cnauroth;Please keep any dicussion about the HADOOP-13614 code change in the HADOOP-13614 JIRA issue.  This issue ultimately will be closed as a duplicate of that one.","25/Oct/16 20:33;hadoopqa;| (/) *{color:green}+1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 21s{color} | {color:blue} Docker mode activated. {color} |
| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |
| {color:green}+1{color} | {color:green} test4tests {color} | {color:green}  0m  0s{color} | {color:green} The patch appears to include 25 new or modified test files. {color} |
| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  0m 14s{color} | {color:blue} Maven dependency ordering for branch {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  6m 30s{color} | {color:green} branch-2 passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green}  5m 33s{color} | {color:green} branch-2 passed with JDK v1.8.0_101 {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green}  6m 32s{color} | {color:green} branch-2 passed with JDK v1.7.0_111 {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  1m 24s{color} | {color:green} branch-2 passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  1m 23s{color} | {color:green} branch-2 passed {color} |
| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green}  0m 31s{color} | {color:green} branch-2 passed {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  2m 17s{color} | {color:green} branch-2 passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  1m  3s{color} | {color:green} branch-2 passed with JDK v1.8.0_101 {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  1m 16s{color} | {color:green} branch-2 passed with JDK v1.7.0_111 {color} |
| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  0m 16s{color} | {color:blue} Maven dependency ordering for patch {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  1m  4s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green}  6m 28s{color} | {color:green} the patch passed with JDK v1.8.0_101 {color} |
| {color:green}+1{color} | {color:green} javac {color} | {color:green}  6m 28s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green}  6m 55s{color} | {color:green} the patch passed with JDK v1.7.0_111 {color} |
| {color:green}+1{color} | {color:green} javac {color} | {color:green}  6m 55s{color} | {color:green} the patch passed {color} |
| {color:orange}-0{color} | {color:orange} checkstyle {color} | {color:orange}  1m 39s{color} | {color:orange} root: The patch generated 10 new + 50 unchanged - 1 fixed = 60 total (was 51) {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  1m 31s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green}  0m 38s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} |
| {color:green}+1{color} | {color:green} xml {color} | {color:green}  0m  1s{color} | {color:green} The patch has no ill-formed XML file. {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  2m 52s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  1m  9s{color} | {color:green} the patch passed with JDK v1.8.0_101 {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  1m 23s{color} | {color:green} the patch passed with JDK v1.7.0_111 {color} |
| {color:green}+1{color} | {color:green} unit {color} | {color:green}  8m 54s{color} | {color:green} hadoop-common in the patch passed with JDK v1.7.0_111. {color} |
| {color:green}+1{color} | {color:green} unit {color} | {color:green}  0m 30s{color} | {color:green} hadoop-aws in the patch passed with JDK v1.7.0_111. {color} |
| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 28s{color} | {color:green} The patch does not generate ASF License warnings. {color} |
| {color:black}{color} | {color:black} {color} | {color:black} 94m 54s{color} | {color:black} {color} |
\\
\\
|| Reason || Tests ||
| JDK v1.8.0_101 Failed junit tests | hadoop.security.ssl.TestSSLFactory |
\\
\\
|| Subsystem || Report/Notes ||
| Docker |  Image:yetus/hadoop:b59b8b7 |
| JIRA Issue | HADOOP-13758 |
| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12835173/HADOOP-13758-branch-2.001.patch |
| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  findbugs  checkstyle  xml  |
| uname | Linux 353b5a62d818 3.13.0-36-lowlatency #63-Ubuntu SMP PREEMPT Wed Sep 3 21:56:12 UTC 2014 x86_64 x86_64 x86_64 GNU/Linux |
| Build tool | maven |
| Personality | /testptch/hadoop/patchprocess/precommit/personality/provided.sh |
| git revision | branch-2 / 7bc170b |
| Default Java | 1.7.0_111 |
| Multi-JDK versions |  /usr/lib/jvm/java-8-oracle:1.8.0_101 /usr/lib/jvm/java-7-openjdk-amd64:1.7.0_111 |
| findbugs | v3.0.0 |
| checkstyle | https://builds.apache.org/job/PreCommit-HADOOP-Build/10894/artifact/patchprocess/diff-checkstyle-root.txt |
| JDK v1.7.0_111  Test Results | https://builds.apache.org/job/PreCommit-HADOOP-Build/10894/testReport/ |
| modules | C: hadoop-common-project/hadoop-common hadoop-tools/hadoop-aws U: . |
| Console output | https://builds.apache.org/job/PreCommit-HADOOP-Build/10894/console |
| Powered by | Apache Yetus 0.4.0-SNAPSHOT   http://yetus.apache.org |


This message was automatically generated.

","25/Oct/16 21:49;cnauroth;Patch revision 002 just cleans up some unused imports.  (These were genuine unused imports, not imports that we need to retain for use in JavaDoc references.)","25/Oct/16 23:33;hadoopqa;| (/) *{color:green}+1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 19s{color} | {color:blue} Docker mode activated. {color} |
| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |
| {color:green}+1{color} | {color:green} test4tests {color} | {color:green}  0m  0s{color} | {color:green} The patch appears to include 25 new or modified test files. {color} |
| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  1m  8s{color} | {color:blue} Maven dependency ordering for branch {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  6m 42s{color} | {color:green} branch-2 passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green}  5m 33s{color} | {color:green} branch-2 passed with JDK v1.8.0_101 {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green}  6m 33s{color} | {color:green} branch-2 passed with JDK v1.7.0_111 {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  1m 25s{color} | {color:green} branch-2 passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  1m 23s{color} | {color:green} branch-2 passed {color} |
| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green}  0m 31s{color} | {color:green} branch-2 passed {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  2m 21s{color} | {color:green} branch-2 passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  1m  2s{color} | {color:green} branch-2 passed with JDK v1.8.0_101 {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  1m 17s{color} | {color:green} branch-2 passed with JDK v1.7.0_111 {color} |
| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  0m 17s{color} | {color:blue} Maven dependency ordering for patch {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  1m  3s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green}  5m 31s{color} | {color:green} the patch passed with JDK v1.8.0_101 {color} |
| {color:green}+1{color} | {color:green} javac {color} | {color:green}  5m 31s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green}  6m 35s{color} | {color:green} the patch passed with JDK v1.7.0_111 {color} |
| {color:green}+1{color} | {color:green} javac {color} | {color:green}  6m 35s{color} | {color:green} the patch passed {color} |
| {color:orange}-0{color} | {color:orange} checkstyle {color} | {color:orange}  1m 29s{color} | {color:orange} root: The patch generated 2 new + 50 unchanged - 1 fixed = 52 total (was 51) {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  1m 29s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green}  0m 38s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} |
| {color:green}+1{color} | {color:green} xml {color} | {color:green}  0m  0s{color} | {color:green} The patch has no ill-formed XML file. {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  2m 50s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  1m  9s{color} | {color:green} the patch passed with JDK v1.8.0_101 {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  1m 21s{color} | {color:green} the patch passed with JDK v1.7.0_111 {color} |
| {color:green}+1{color} | {color:green} unit {color} | {color:green}  8m 21s{color} | {color:green} hadoop-common in the patch passed with JDK v1.7.0_111. {color} |
| {color:green}+1{color} | {color:green} unit {color} | {color:green}  0m 30s{color} | {color:green} hadoop-aws in the patch passed with JDK v1.7.0_111. {color} |
| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 29s{color} | {color:green} The patch does not generate ASF License warnings. {color} |
| {color:black}{color} | {color:black} {color} | {color:black} 94m 13s{color} | {color:black} {color} |
\\
\\
|| Subsystem || Report/Notes ||
| Docker |  Image:yetus/hadoop:b59b8b7 |
| JIRA Issue | HADOOP-13758 |
| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12835208/HADOOP-13758-branch-2.002.patch |
| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  findbugs  checkstyle  xml  |
| uname | Linux 9fb9ef19e6c8 3.13.0-36-lowlatency #63-Ubuntu SMP PREEMPT Wed Sep 3 21:56:12 UTC 2014 x86_64 x86_64 x86_64 GNU/Linux |
| Build tool | maven |
| Personality | /testptch/hadoop/patchprocess/precommit/personality/provided.sh |
| git revision | branch-2 / aedd5c4 |
| Default Java | 1.7.0_111 |
| Multi-JDK versions |  /usr/lib/jvm/java-8-oracle:1.8.0_101 /usr/lib/jvm/java-7-openjdk-amd64:1.7.0_111 |
| findbugs | v3.0.0 |
| checkstyle | https://builds.apache.org/job/PreCommit-HADOOP-Build/10895/artifact/patchprocess/diff-checkstyle-root.txt |
| JDK v1.7.0_111  Test Results | https://builds.apache.org/job/PreCommit-HADOOP-Build/10895/testReport/ |
| modules | C: hadoop-common-project/hadoop-common hadoop-tools/hadoop-aws U: . |
| Console output | https://builds.apache.org/job/PreCommit-HADOOP-Build/10895/console |
| Powered by | Apache Yetus 0.4.0-SNAPSHOT   http://yetus.apache.org |


This message was automatically generated.

","26/Oct/16 15:41;cnauroth;I have +1'd the patch on HADOOP-13614 and committed it.  I'm resolving this as a duplicate.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
TestZKFailoverControllerStress#testExpireBackAndForth occasionally fails,HADOOP-10668,12718912,Test,Closed,HADOOP,Hadoop Common,software,omalley,Hadoop Common is the common library for Apache Hadoop.,http://hadoop.apache.org/,Major,Fixed,mingma,yuzhihong@gmail.com,yuzhihong@gmail.com,06/Jun/14 18:59,30/Aug/16 01:32,12/Jan/21 11:55,19/Jan/15 19:36,,,,,2.6.3,2.7.0,3.0.0-alpha1,,,,test,,,,1,test,,"From https://builds.apache.org/job/PreCommit-HADOOP-Build/4018//testReport/org.apache.hadoop.ha/TestZKFailoverControllerStress/testExpireBackAndForth/ :
{code}
org.apache.zookeeper.KeeperException$NoNodeException: KeeperErrorCode = NoNode
	at org.apache.zookeeper.server.DataTree.getData(DataTree.java:648)
	at org.apache.zookeeper.server.ZKDatabase.getData(ZKDatabase.java:371)
	at org.apache.hadoop.ha.MiniZKFCCluster.expireActiveLockHolder(MiniZKFCCluster.java:199)
	at org.apache.hadoop.ha.MiniZKFCCluster.expireAndVerifyFailover(MiniZKFCCluster.java:234)
	at org.apache.hadoop.ha.TestZKFailoverControllerStress.testExpireBackAndForth(TestZKFailoverControllerStress.java:84)
{code}",,aajisaka,arp,cnauroth,decster,hudson,mingma,praste,raviprak,sevada,sjlee0,spandan,stevel@apache.org,yuzhihong@gmail.com,yzhangal,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,HADOOP-9555,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"20/Jan/15 20:06;mingma;HADOOP-10668-2.patch;https://issues.apache.org/jira/secure/attachment/12693376/HADOOP-10668-2.patch","13/Jan/15 00:02;mingma;HADOOP-10668.patch;https://issues.apache.org/jira/secure/attachment/12691790/HADOOP-10668.patch",,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,2014-06-09 21:47:18.579,,,false,,,,,,,,,,,,,,,,,397111,Reviewed,,,,Thu Nov 05 18:46:12 UTC 2015,,,,,,,"0|i1wd9r:",397234,,,,,,,,,,,,,2.7.0,,,,,,,,,,"09/Jun/14 21:47;cnauroth;I'm planning on upgrading us to the recently released ZooKeeper 3.4.6 as part of HADOOP-9555.  It would be interesting to see if we still have this problem after the upgrade.","10/Jun/14 18:56;cnauroth;I've committed HADOOP-9555.  I've run {{TestZKFailoverControllerStress}} multiple times with no failures.  Maybe the ZooKeeper upgrade fixed this by side effect.  Ted, do you have a consistent repro, or were you only seeing it on Jenkins?  If so, then maybe we need to wait and see how the test behaves on Jenkins over the next several days.","10/Jun/14 19:22;yuzhihong@gmail.com;I saw the test failure on Jenkins.

Will keep an eye on Jenkins in the future.","10/Jun/14 22:45;cnauroth;It looks like upgrading ZooKeeper didn't fix this.  Here is a Jenkins build after HADOOP-9555 was committed, showing a failure in {{TestZKFailoverController#testAutoFailoverOnLostZKSession}}.

https://builds.apache.org/job/PreCommit-HADOOP-Build/4039/

Let's keep HADOOP-10668 open.","16/Jun/14 09:40;decster;The test failed again in HDFS-5574
https://builds.apache.org/job/PreCommit-HDFS-Build/7127//testReport/org.apache.hadoop.ha/TestZKFailoverControllerStress/testExpireBackAndForth/
","18/Jun/14 17:04;stevel@apache.org;...happening a lot on jenkins builds. There's a risk here we'll start ignoring real failures","12/Aug/14 13:59;yuzhihong@gmail.com;It failed again in https://builds.apache.org/job/Hadoop-Common-trunk/1204/consoleFull
{code}
Tests run: 3, Failures: 0, Errors: 1, Skipped: 0, Time elapsed: 92.317 sec <<< FAILURE! - in org.apache.hadoop.ha.TestZKFailoverControllerStress
testExpireBackAndForth(org.apache.hadoop.ha.TestZKFailoverControllerStress)  Time elapsed: 30.195 sec  <<< ERROR!
org.apache.zookeeper.KeeperException$NoNodeException: KeeperErrorCode = NoNode
	at org.apache.zookeeper.server.DataTree.getData(DataTree.java:648)
	at org.apache.zookeeper.server.ZKDatabase.getData(ZKDatabase.java:371)
	at org.apache.hadoop.ha.MiniZKFCCluster.expireActiveLockHolder(MiniZKFCCluster.java:199)
	at org.apache.hadoop.ha.MiniZKFCCluster.expireAndVerifyFailover(MiniZKFCCluster.java:234)
	at org.apache.hadoop.ha.TestZKFailoverControllerStress.testExpireBackAndForth(TestZKFailoverControllerStress.java:79)
{code}","19/Aug/14 16:02;yuzhihong@gmail.com;Failed again in https://builds.apache.org/job/Hadoop-Common-trunk/1211/consoleFull","31/Oct/14 13:48;praste;I am running into same issue when I try to build Hadoop branch-2.6 on Ubuntu","15/Dec/14 10:54;stevel@apache.org;uprating as blocking hadoop common trunk builds","13/Jan/15 00:02;mingma;It appears the check whether a node is in the right state could be the issue. {{ZKFailoverController}} has its own {{serviceState}}. HA service such as DummyHAService has its own state. What happened here is {{MiniZKFCCluster}}'s {{waitForHAState}} uses DummyHAService state to decide the state has transitioned properly. But when fencing is involved, the to-be-elected active will directly call the old active's {{transitionToStandby}} method. Thus {{DummyHAService}}'s state could be set to standby before {{ZKFailoverController}}'s state is updated.

The patch didn't change the fact {{ZKFailoverController}}'s state is only updated when it receives notification from ZK callback. So with the fix, it might still get the following error in the log. But that is ok, {{ZKFailoverController}}'s state eventually will be changed to standby.
 
{noformat}
2015-01-12 15:08:16,497 ERROR ha.ZKFailoverController (ZKFailoverController.java:verifyChangedServiceState(828)) - Local service DummyHAService #1 has changed the serviceState to standby. Expected was active. Quitting election marking fencing necessary.
{noformat}","13/Jan/15 00:42;hadoopqa;{color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12691790/HADOOP-10668.patch
  against trunk revision f3507fa.

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 1 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  There were no new javadoc warning messages.

    {color:red}-1 eclipse:eclipse{color}.  The patch failed to build with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 2.0.3) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:green}+1 core tests{color}.  The patch passed unit tests in .

Test results: https://builds.apache.org/job/PreCommit-HADOOP-Build/5392//testReport/
Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/5392//console

This message is automatically generated.","15/Jan/15 17:25;mingma;Anyone has time to review this? It has been verified by running the test repeatedly. Thanks.","19/Jan/15 19:36;cnauroth;Great investigation, Ming.  I ran this several times on multiple VMs, and it passed every time.

+1 for the patch.  I committed it to trunk and branch-2.  Thank you, Ming.","19/Jan/15 19:43;hudson;FAILURE: Integrated in Hadoop-trunk-Commit #6888 (See [https://builds.apache.org/job/Hadoop-trunk-Commit/6888/])
HADOOP-10668. TestZKFailoverControllerStress#testExpireBackAndForth occasionally fails. Contributed by Ming Ma. (cnauroth: rev 7fc1f2f5cf4312d72aeffb1a9cef497d00c60adb)
* hadoop-common-project/hadoop-common/CHANGES.txt
* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/ha/MiniZKFCCluster.java
* hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/ha/ZKFailoverController.java
","20/Jan/15 10:41;hudson;FAILURE: Integrated in Hadoop-Yarn-trunk-Java8 #79 (See [https://builds.apache.org/job/Hadoop-Yarn-trunk-Java8/79/])
HADOOP-10668. TestZKFailoverControllerStress#testExpireBackAndForth occasionally fails. Contributed by Ming Ma. (cnauroth: rev 7fc1f2f5cf4312d72aeffb1a9cef497d00c60adb)
* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/ha/MiniZKFCCluster.java
* hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/ha/ZKFailoverController.java
* hadoop-common-project/hadoop-common/CHANGES.txt
","20/Jan/15 11:52;hudson;FAILURE: Integrated in Hadoop-Yarn-trunk #813 (See [https://builds.apache.org/job/Hadoop-Yarn-trunk/813/])
HADOOP-10668. TestZKFailoverControllerStress#testExpireBackAndForth occasionally fails. Contributed by Ming Ma. (cnauroth: rev 7fc1f2f5cf4312d72aeffb1a9cef497d00c60adb)
* hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/ha/ZKFailoverController.java
* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/ha/MiniZKFCCluster.java
* hadoop-common-project/hadoop-common/CHANGES.txt
","20/Jan/15 14:39;hudson;FAILURE: Integrated in Hadoop-Hdfs-trunk-Java8 #76 (See [https://builds.apache.org/job/Hadoop-Hdfs-trunk-Java8/76/])
HADOOP-10668. TestZKFailoverControllerStress#testExpireBackAndForth occasionally fails. Contributed by Ming Ma. (cnauroth: rev 7fc1f2f5cf4312d72aeffb1a9cef497d00c60adb)
* hadoop-common-project/hadoop-common/CHANGES.txt
* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/ha/MiniZKFCCluster.java
* hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/ha/ZKFailoverController.java
","20/Jan/15 14:42;hudson;SUCCESS: Integrated in Hadoop-Hdfs-trunk #2011 (See [https://builds.apache.org/job/Hadoop-Hdfs-trunk/2011/])
HADOOP-10668. TestZKFailoverControllerStress#testExpireBackAndForth occasionally fails. Contributed by Ming Ma. (cnauroth: rev 7fc1f2f5cf4312d72aeffb1a9cef497d00c60adb)
* hadoop-common-project/hadoop-common/CHANGES.txt
* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/ha/MiniZKFCCluster.java
* hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/ha/ZKFailoverController.java
","20/Jan/15 15:10;hudson;FAILURE: Integrated in Hadoop-Mapreduce-trunk-Java8 #80 (See [https://builds.apache.org/job/Hadoop-Mapreduce-trunk-Java8/80/])
HADOOP-10668. TestZKFailoverControllerStress#testExpireBackAndForth occasionally fails. Contributed by Ming Ma. (cnauroth: rev 7fc1f2f5cf4312d72aeffb1a9cef497d00c60adb)
* hadoop-common-project/hadoop-common/CHANGES.txt
* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/ha/MiniZKFCCluster.java
* hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/ha/ZKFailoverController.java
","20/Jan/15 15:28;hudson;FAILURE: Integrated in Hadoop-Mapreduce-trunk #2030 (See [https://builds.apache.org/job/Hadoop-Mapreduce-trunk/2030/])
HADOOP-10668. TestZKFailoverControllerStress#testExpireBackAndForth occasionally fails. Contributed by Ming Ma. (cnauroth: rev 7fc1f2f5cf4312d72aeffb1a9cef497d00c60adb)
* hadoop-common-project/hadoop-common/CHANGES.txt
* hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/ha/ZKFailoverController.java
* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/ha/MiniZKFCCluster.java
","20/Jan/15 20:06;mingma;Thanks, Chris. Sorry, I didn't update {{TestZKFailoverController}} test cases that rely on the old behavior of {{MiniZKFCCluster#waitForHAState}}. It is strange how it passed the jenkins build above. Here is the addendum patch.","21/Jan/15 19:58;cnauroth;Ming, thank you for the addendum patch.  I committed it to trunk and branch-2.

Looking back at the Jenkins output, it appears that there was some error while trying to identify the subset of test modules to execute, so in reality it didn't run any tests.  I don't know if this is happening often, so we'll have to watch out for it.  The tell-tale sign is the text ""patch passed unit tests in"", followed by a blank list instead of the sub-modules.","21/Jan/15 20:03;hudson;FAILURE: Integrated in Hadoop-trunk-Commit #6905 (See [https://builds.apache.org/job/Hadoop-trunk-Commit/6905/])
HADOOP-10668. Addendum patch to fix TestZKFailoverController. Contributed by Ming Ma. (cnauroth: rev 925c9fed3311ea1fd8f5ed1cb6b1c0abc5c90425)
* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/ha/TestZKFailoverController.java
* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/ha/MiniZKFCCluster.java
","22/Jan/15 10:42;hudson;FAILURE: Integrated in Hadoop-Yarn-trunk-Java8 #81 (See [https://builds.apache.org/job/Hadoop-Yarn-trunk-Java8/81/])
HADOOP-10668. Addendum patch to fix TestZKFailoverController. Contributed by Ming Ma. (cnauroth: rev 925c9fed3311ea1fd8f5ed1cb6b1c0abc5c90425)
* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/ha/MiniZKFCCluster.java
* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/ha/TestZKFailoverController.java
","22/Jan/15 10:45;hudson;FAILURE: Integrated in Hadoop-Yarn-trunk #815 (See [https://builds.apache.org/job/Hadoop-Yarn-trunk/815/])
HADOOP-10668. Addendum patch to fix TestZKFailoverController. Contributed by Ming Ma. (cnauroth: rev 925c9fed3311ea1fd8f5ed1cb6b1c0abc5c90425)
* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/ha/TestZKFailoverController.java
* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/ha/MiniZKFCCluster.java
","22/Jan/15 14:10;hudson;FAILURE: Integrated in Hadoop-Hdfs-trunk #2013 (See [https://builds.apache.org/job/Hadoop-Hdfs-trunk/2013/])
HADOOP-10668. Addendum patch to fix TestZKFailoverController. Contributed by Ming Ma. (cnauroth: rev 925c9fed3311ea1fd8f5ed1cb6b1c0abc5c90425)
* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/ha/MiniZKFCCluster.java
* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/ha/TestZKFailoverController.java
","22/Jan/15 14:21;hudson;FAILURE: Integrated in Hadoop-Hdfs-trunk-Java8 #78 (See [https://builds.apache.org/job/Hadoop-Hdfs-trunk-Java8/78/])
HADOOP-10668. Addendum patch to fix TestZKFailoverController. Contributed by Ming Ma. (cnauroth: rev 925c9fed3311ea1fd8f5ed1cb6b1c0abc5c90425)
* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/ha/TestZKFailoverController.java
* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/ha/MiniZKFCCluster.java
","22/Jan/15 15:10;hudson;FAILURE: Integrated in Hadoop-Mapreduce-trunk-Java8 #82 (See [https://builds.apache.org/job/Hadoop-Mapreduce-trunk-Java8/82/])
HADOOP-10668. Addendum patch to fix TestZKFailoverController. Contributed by Ming Ma. (cnauroth: rev 925c9fed3311ea1fd8f5ed1cb6b1c0abc5c90425)
* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/ha/TestZKFailoverController.java
* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/ha/MiniZKFCCluster.java
","22/Jan/15 15:23;hudson;FAILURE: Integrated in Hadoop-Mapreduce-trunk #2032 (See [https://builds.apache.org/job/Hadoop-Mapreduce-trunk/2032/])
HADOOP-10668. Addendum patch to fix TestZKFailoverController. Contributed by Ming Ma. (cnauroth: rev 925c9fed3311ea1fd8f5ed1cb6b1c0abc5c90425)
* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/ha/MiniZKFCCluster.java
* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/ha/TestZKFailoverController.java
","05/Nov/15 18:46;sjlee0;Cherry-picked the fix to branch-2.6.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
rewrite test-patch.sh,HADOOP-11746,12785402,Test,Resolved,HADOOP,Hadoop Common,software,omalley,Hadoop Common is the common library for Apache Hadoop.,http://hadoop.apache.org/,Major,Fixed,aw,aw,aw,25/Mar/15 03:29,30/Aug/16 01:30,12/Jan/21 11:55,21/Apr/15 20:45,3.0.0-alpha1,,,,2.8.0,3.0.0-alpha1,,,,,build,test,,,2,,,This code is bad and you should feel bad.,,aajisaka,andrew.wang,aw,busbey,cmccabe,cnauroth,cutting,gkesavan,hudson,kasha,kihwal,leftnoteasy,Naganarasimha,ndimiduk,nielsbasjes,omalley,raviprak,xiaochen,zhz,,,,,,,,,,,,,,,,,,HADOOP-6186,HADOOP-8714,HADOOP-11845,HADOOP-11745,HADOOP-7435,HADOOP-8875,HADOOP-7670,HADOOP-9572,HADOOP-11220,,,,,,HADOOP-11781,HADOOP-11861,HADOOP-11881,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,HADOOP-11778,,,,,,,,,"25/Mar/15 05:48;aw;HADOOP-11746-00.patch;https://issues.apache.org/jira/secure/attachment/12707145/HADOOP-11746-00.patch","26/Mar/15 04:32;aw;HADOOP-11746-01.patch;https://issues.apache.org/jira/secure/attachment/12707424/HADOOP-11746-01.patch","27/Mar/15 05:49;aw;HADOOP-11746-02.patch;https://issues.apache.org/jira/secure/attachment/12707696/HADOOP-11746-02.patch","29/Mar/15 05:08;aw;HADOOP-11746-03.patch;https://issues.apache.org/jira/secure/attachment/12708024/HADOOP-11746-03.patch","31/Mar/15 05:48;aw;HADOOP-11746-04.patch;https://issues.apache.org/jira/secure/attachment/12708341/HADOOP-11746-04.patch","01/Apr/15 19:15;aw;HADOOP-11746-05.patch;https://issues.apache.org/jira/secure/attachment/12708777/HADOOP-11746-05.patch","05/Apr/15 02:55;aw;HADOOP-11746-06.patch;https://issues.apache.org/jira/secure/attachment/12709449/HADOOP-11746-06.patch","05/Apr/15 17:37;aw;HADOOP-11746-07.patch;https://issues.apache.org/jira/secure/attachment/12709479/HADOOP-11746-07.patch","06/Apr/15 22:09;aw;HADOOP-11746-09.patch;https://issues.apache.org/jira/secure/attachment/12723460/HADOOP-11746-09.patch","07/Apr/15 22:55;aw;HADOOP-11746-10.patch;https://issues.apache.org/jira/secure/attachment/12723763/HADOOP-11746-10.patch","08/Apr/15 04:08;aw;HADOOP-11746-11.patch;https://issues.apache.org/jira/secure/attachment/12723822/HADOOP-11746-11.patch","09/Apr/15 04:15;aw;HADOOP-11746-12.patch;https://issues.apache.org/jira/secure/attachment/12724125/HADOOP-11746-12.patch","09/Apr/15 17:49;aw;HADOOP-11746-13.patch;https://issues.apache.org/jira/secure/attachment/12724277/HADOOP-11746-13.patch","10/Apr/15 04:35;aw;HADOOP-11746-14.patch;https://issues.apache.org/jira/secure/attachment/12724454/HADOOP-11746-14.patch","10/Apr/15 19:02;aw;HADOOP-11746-15.patch;https://issues.apache.org/jira/secure/attachment/12724628/HADOOP-11746-15.patch","16/Apr/15 08:41;aw;HADOOP-11746-16.patch;https://issues.apache.org/jira/secure/attachment/12725807/HADOOP-11746-16.patch","17/Apr/15 08:23;aw;HADOOP-11746-17.patch;https://issues.apache.org/jira/secure/attachment/12726104/HADOOP-11746-17.patch","17/Apr/15 20:30;aw;HADOOP-11746-18.patch;https://issues.apache.org/jira/secure/attachment/12726255/HADOOP-11746-18.patch","19/Apr/15 19:14;aw;HADOOP-11746-19.patch;https://issues.apache.org/jira/secure/attachment/12726461/HADOOP-11746-19.patch","20/Apr/15 18:09;aw;HADOOP-11746-20.patch;https://issues.apache.org/jira/secure/attachment/12726614/HADOOP-11746-20.patch","21/Apr/15 20:13;aw;HADOOP-11746-21.branch-2.patch;https://issues.apache.org/jira/secure/attachment/12726985/HADOOP-11746-21.branch-2.patch","21/Apr/15 19:31;aw;HADOOP-11746-21.patch;https://issues.apache.org/jira/secure/attachment/12726970/HADOOP-11746-21.patch",,22.0,,,,,,,,,,,,,,,,,,,,2015-03-25 03:48:29.255,,,false,,,,,,,,,,,,,,,,,9223372036854775807,Incompatible change,Reviewed,,,Fri Apr 24 20:15:58 UTC 2015,,,,,,,"0|i27bfb:",9223372036854775807,"<!-- markdown -->
* test-patch.sh now has new output that is different than the previous versions
* test-patch.sh is now pluggable via the test-patch.d directory, with checkstyle and shellcheck tests included
* JIRA comments now use much more markup to improve readability
* test-patch.sh now supports either a file name, a URL, or a JIRA issue as input in developer mode
* If part of the patch testing code is changed, test-patch.sh will now attempt to re-executing itself using the new version.
* Some logic to try and reduce the amount of unnecessary tests.  For example, patches that only modify markdown should not run the Java compilation tests.
* Plugins for checkstyle, shellcheck, and whitespace now execute as necessary.
* New test code for mvn site
* A breakdown of the times needed to execute certain blocks as well as a total runtime is now reported to assist in fixing long running tests and optimize the entire process.
* Several new options
  * --resetrepo will put test-patch.sh in destructive mode, similar to a normal Jenkins run
  * --testlist allows one to provide a comma delimited list of test subsystems to forcibly execute
  * --modulelist to provide a comma delimited list of module tests to execute in addition to the ones that are automatically detected
  * --offline mode to attempt to stop connecting to the Internet for certain operations
* test-patch.sh now defaults to the POSIX equivalents on Solaris and Illumos-based operating systems
* shelldocs.py may be used to generate test-patch.sh API information
* FindBugs output is now listed on the JIRA comment
* lots of general code cleanup, including attempts to remove any local state files to reduce potential race conditions
* Some logic to determine if a patch is for a given major branch using several strategies as well as a particular git ref (using git+ref as part of the name).
* Some logic to determine if a patch references a particular JIRA issue.
* Unit tests are only flagged as necessary with native or Java code, since Hadoop has no framework in place yet for other types of unit tests.
* test-patch now exits with a failure status if problems arise trying to do git checkouts.  Previously the exit code was success.",,,,,,,,,,,,,,,,,,,,,,"25/Mar/15 03:48;gkesavan;[~aw] are you planning to re-write the test-patch.sh in python? 
I'm interested in helping in any means, writing the python code or testing it out. please let me know. 
","25/Mar/15 05:00;aw;I'm going to go for bash for now, simply because there would be a ton of shell outs if we did it in python to the point that half the code would be bash anyway.  I *might* write some helper code in python to replace the wget though.  That would be significantly better to fetch from JIRA via REST.

As it is, just running shellcheck on the existing code has found quite a few subtle bugs. :(","25/Mar/15 05:48;aw;-00:
* initial pass that just fixes the vast majority of shellcheck errors","25/Mar/15 22:40;busbey;Just heads up, I'd like to coalesce the test-patch process for both Hadoop and HBase. My planned start wasn't until April.

I'll try applying similar changes to the HBase fork as you develop here. Are the subtle bugs enough that I should do a pass of that now?","25/Mar/15 22:46;aw;Nah.  Probably not worth it. 

FWIW, the biggest problems are mixing up string and arithmetic comparison operators.","26/Mar/15 04:32;aw;-01:
* start preparing for set -euo pipefail mode (hopeful thinking)
* complain if JAVA_HOME isn't found since some of the maven tests fail if it isn't defined
*  JIRA output now uses more markup, because tables are cool
* rework the generic console output header bits to auto-center
* rework the error report based upon the new JIRA output, including splitting it out into its own outputter 
* add a few helper routines to auto center text, etc.
* only find the changed modules once instead of twice
* run it through a shell code formatter, but I really hate how it handles backslashed lines
* lots of ""oh we have a variable for this binary, but let's ignore it and call whatever is in the path anyway"" fixes
* fix a few inconsistencies in how we checked and reported errors
* updated quite a few things to modern bash semantics
* local and lowercase'd all of the local vars
* removed forrest bits

I haven't done a full run yet, never mind against Jenkins, but this one might actually work. ;) Still a lot to do, including making it pluggable and moving some of these bits into that plug-in dir.","26/Mar/15 04:57;aw;I see a few off by one errors. Woops.","27/Mar/15 05:49;aw;-02: 
* still very little new functionality, except that --dirty-workspace is now working for me.
* console output cleanup
* fix the /tmp default for the patch scratch space to be /tmp/(projname)-test-patch/pid to allow for simultaneous test patch runs
* add in a timer to show how long various steps take (as requested by [~raviprak] )
* Fix more ""we should have a var rather than hard code this binary"" issues
* just skip the findbugs test if findbugs isn't installed
* send the mvn install run to a log file rather than dumping it to the screen
* fix some of the backslash indentation problems generated by the autoformatter


Current console output now looks like:

{noformat}
w$ dev-support/test-patch.sh --dirty-workspace /tmp/H1
Running in developer mode
/tmp/Hadoop-test-patch/54448 has been created


=======================================================================
=======================================================================
                        Testing patch for H1.
=======================================================================
=======================================================================
....
-1 overall

| Vote |           Subsystem | Comment
|  +1  |            @author  |  00m 00s  | The patch does not contain any 
                                         | @author tags.
|  -1  |     tests included  |  00m 00s  | The patch doesn't appear to include 
                                         | any new or modified tests. Please
                                         | justify why no new tests are needed
                                         | for this patch. Also please list what
                                         | manual steps were performed to verify
                                         | this patch.
|  +1  |              javac  |  04m 30s  | There were no new javac warning 
                                         | messages.
|  +1  |            javadoc  |  06m 15s  | There were no new javadoc warning 
                                         | messages.
|  +1  |    eclipse:eclipse  |  00m 24s  | The patch built with eclipse:eclipse.
|  -1  |      release audit  |  00m 05s  | The applied patch generated 1 release 
                                         | audit warnings.


=======================================================================
=======================================================================
                           Finished build.
=======================================================================
=======================================================================
{noformat}

Note the always centered text and the column wrap on the output. :D","29/Mar/15 05:08;aw;-03:
* Beginnings of plug-in support, including some very alpha checkstyle and shellcheck plug-ins
* --debug support
* Branch detection for --dirty-workspace and the ability to work on branches that aren't trunk  (note: must conform to HowToContribute wiki!)
* Some more output cleanup/enhancements
* re-arrange/label the usage/help message output
* re-order the basic tests a bit
* include some status/timings for things that are normally hidden
* imported some routines from hadoop-funcions.sh, so the start of some shelldoc.py support

Any hints on how I can start testing under jenkins?  How do I duplicate what we currently have?
","29/Mar/15 05:14;aw;Current shell-output.  (Note that HADOOP-11746 is the name of the git branch where I ran the test-patch script)

{noformat}
-1 overall

| Vote |           Subsystem |  Runtime  | Comment
|   0  |          pre-patch  |  09m 30s  |  Pre-patch HADOOP-11746 compilation 
|      |                     |           | is healthy.
|  +1  |            @author  |  00m 00s  |  The patch does not contain any 
|      |                     |           | @author tags.
|  -1  |     tests included  |  00m 00s  |  The patch doesn't appear to include 
|      |                     |           | any new or modified tests. Please
|      |                     |           | justify why no new tests are needed
|      |                     |           | for this patch. Also please list what
|      |                     |           | manual steps were performed to verify
|      |                     |           | this patch.
|  +1  |              javac  |  04m 22s  |  There were no new javac warning 
|      |                     |           | messages.
|  +1  |            javadoc  |  06m 16s  |  There were no new javadoc warning 
|      |                     |           | messages.
|  -1  |      release audit  |  00m 09s  |  The applied patch generated 3 
|      |                     |           | release audit warnings.
|  +1  |         checkstyle  |  03m 04s  |  There were no new checkstyle issues. 
|  +1  |         shellcheck  |  00m 02s  |  There were no new shellcheck issues. 
|  +1  |            install  |  02m 31s  |  mvn install still works. 
|  +1  |    eclipse:eclipse  |  00m 24s  |  The patch built with 
|      |                     |           | eclipse:eclipse.


|| Subsystem || Report ||
| Release Audit | /tmp/hadoop-test-patch/14934/patchReleaseAuditProblems.txt |
{noformat}

The current jira format has some minor issues. :( Fixing the two missing new lines and the missing backslash results in:

(x) *{color:red}-1 overall{color}*
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | pre-patch | 09m 30s | Pre-patch HADOOP-11746 compilation is healthy. |
| {color:green}+1{color} | @author | 00m 00s | The patch does not contain any @author tags. |
| {color:red}-1{color} | tests included | 00m 00s | The patch doesn't appear to include any new or modified tests.  Please justify why no new tests are needed for this patch. Also please list what manual steps were performed to verify this patch. |
| {color:green}+1{color} | javac | 04m 22s | There were no new javac warning messages. |
| {color:green}+1{color} | javadoc | 06m 16s | There were no new javadoc warning messages. |
| {color:red}-1{color} | release audit | 00m 09s | The applied patch generated 3 release audit warnings. |
| {color:green}+1{color} | checkstyle | 03m 04s | There were no new checkstyle issues. |
| {color:green}+1{color} | shellcheck | 00m 02s | There were no new shellcheck issues. |
| {color:green}+1{color} | install | 02m 31s | mvn install still works. |
| {color:green}+1{color} | eclipse:eclipse | 00m 24s | The patch built with eclipse:eclipse. |
\\
|| Subsystem || Report ||
| Release Audit | /artifact/patchprocess/patchReleaseAuditProblems.txt |
| Console output | /artifact/patchprocess/console |


This message was automatically generated.","31/Mar/15 03:23;aw;Setting HADOOP-11778 as required for checkstyle support, based upon my current experiments.","31/Mar/15 05:48;aw;-04:
* *MUCH* better branch and issue detection on patches
* checkstyle sort of works now!
* add missing license files
* some general code cleanup
* JIRA comments are now formatted correctly
* console comments had some display issues fixed
* Removed a lot of ""if jenkins this, if not jenkins this"", simplifying the code paths
* in addition to files, test-patch.sh now supports issues and http(s) URLs which will automatically download patches off of JIRA 
* give some hints about execution times while running too
* fixed some issues around running tests

To-do:
* Add some ssssaaaaafffffffeeeeetttttttyyyyy checks.
* Test on Jenkins
* Do more broken patch tests
* cleanup the function names, comment the code more, etc.
* Any other requests?","31/Mar/15 05:53;aw;I'm marking this as incompatible because the output changed.","31/Mar/15 06:23;hadoopqa;{color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12708341/HADOOP-11746-04.patch
  against trunk revision 85dc3c1.

    {color:red}-1 @author{color}.  The patch appears to contain 12 @author tags which the Hadoop community has agreed to not allow in code contributions.

    {color:green}+1 tests included{color}.  The patch appears to include 3 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  There were no new javadoc warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 2.0.3) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:green}+1 core tests{color}.  The patch passed unit tests in .

Test results: https://builds.apache.org/job/PreCommit-HADOOP-Build/6030//testReport/
Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/6030//console

This message is automatically generated.","31/Mar/15 14:20;aw;bq. -1 @author. The patch appears to contain 12 @author tags which the Hadoop community has agreed to not allow in code contributions.

lol","31/Mar/15 17:14;aw;Found two bugs this morning with the current patch, both of them minor:
* http mode doesn't work because I forgot how regexp match worked in bash on that line. ;)
* in jenkins mode, we shouldn't try to cp the support dir lib if it doesn't exist.

BTW, there's a good chance I've already fixed the race that [~kasha] is hitting in YARN-3412.  findmodules (which is the one that determines which pom.xml files to use for tests) was one of the first parts of the old code that I saw that scared me a bit.  It features a hard-coded path that isn't tied to the current patch run directory at all and is global to the box.  While it does use the pid for the name, given the right conditions (like, oh, something that spawns lots of child processes...), one could see a race there.

FWIW, the current code races pretty hard at the directory level in developer mode.  In Jenkins mode, this should be less of a concern unless Jenkins isn't able to clean up it's workspace directory.","31/Mar/15 17:34;aw;Oh, also, smart-apply.sh has the same /tmp race issues (using the exact same file name as test-patch.sh).  Hooray!","01/Apr/15 19:15;aw;-05:
* more major code cleanup: renamed quite a few functions, removed more cruft, etc
* shelldoc capability docs
* added a different table for test failures
* slightly changed the overall +/-1 output
* fixed some issues with relative paths
* reworked some branch detection stuff
* reworked the failed test output list to remove the org.apache part

Need someone to review this now....","01/Apr/15 19:32;busbey;would you mind throwing this on reviewboard? ","01/Apr/15 19:39;aw;I pretty much don't trust ASF's reviewboard, given it has millions of spam accounts on it.  I don't think it's secure at all.","01/Apr/15 20:10;busbey;I don't follow. Presuming it is insecure, what could we lose by having the patch there? Is there another review tool that's more accessible than locally applying an putting comments here in Jira?","01/Apr/15 21:02;hadoopqa;{color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12708777/HADOOP-11746-05.patch
  against trunk revision ed72daa.

    {color:red}-1 @author{color}.  The patch appears to contain 13 @author tags which the Hadoop community has agreed to not allow in code contributions.

    {color:green}+1 tests included{color}.  The patch appears to include 3 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  There were no new javadoc warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 2.0.3) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:green}+1 core tests{color}.  The patch passed unit tests in .

Test results: https://builds.apache.org/job/PreCommit-HADOOP-Build/6043//testReport/
Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/6043//console

This message is automatically generated.","01/Apr/15 22:35;aw;I actively try to avoid services that are so obviously compromised and not maintained since who knows what other problems may exist... iframe injections, etc.   Plus, Hadoop uses JIRA as the platform for this.  I understand that other projects use different tools, but we don't.","01/Apr/15 23:05;cmccabe;[~busbey], have you tried out https://chrome.google.com/webstore/detail/git-patch-viewer/hkoggakcdopbgnaeeidcmopfekipkleg ?  I find it really helpful for viewing diffs on JIRA.

[edit: looking at this again, this may not be too helpful since this is mostly a rewrite, so having both the left and right sides is not that important.]","05/Apr/15 02:55;aw;-06:
* lots of fixes and cleanup, including some minor perf fixes and removing a few needless temp files
* On Solaris, use POSIX not SVID binaries
* If a patch hits test-patch or smart-apply-path, short-circuit some pre-patch logic, then use the new versions as part of testing the patch
","05/Apr/15 03:33;hadoopqa;{color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12709449/HADOOP-11746-06.patch
  against trunk revision 4b3948e.

    {color:red}-1 @author{color}.  The patch appears to contain 13 @author tags which the Hadoop community has agreed to not allow in code contributions.

    {color:green}+1 tests included{color}.  The patch appears to include 3 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  There were no new javadoc warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 2.0.3) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:green}+1 core tests{color}.  The patch passed unit tests in .

Test results: https://builds.apache.org/job/PreCommit-HADOOP-Build/6064//testReport/
Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/6064//console

This message is automatically generated.","05/Apr/15 03:56;aw;Argh, just realized -06 doesn't have the uniq'ing of CHANGED_MODULES, so you'll see duplicate tests.  ","05/Apr/15 17:37;aw;-07:
* fixes the duplicate test bit that was missing in -06","05/Apr/15 17:40;aw;One thing I'm still confused by is why the original test-patch exit'd with 0 during some failure situations.  Is this a bug in the original or was there a reason?  I kept that behavior but it still seems wrong...","05/Apr/15 18:13;hadoopqa;{color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12709479/HADOOP-11746-07.patch
  against trunk revision 96d7211.

    {color:red}-1 @author{color}.  The patch appears to contain 13 @author tags which the Hadoop community has agreed to not allow in code contributions.

    {color:green}+1 tests included{color}.  The patch appears to include 3 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  There were no new javadoc warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 2.0.3) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:green}+1 core tests{color}.  The patch passed unit tests in .

Test results: https://builds.apache.org/job/PreCommit-HADOOP-Build/6065//testReport/
Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/6065//console

This message is automatically generated.","06/Apr/15 21:46;aw;-08:
* borrow some code from the folks at HBase to help make the checkstyle check more useful
* add an EOL whitespace check bz i'm tired of checking for it myself. :D
* fix some extraneous output when no tests have failed
","06/Apr/15 22:09;aw;-09:
* -08 was the wrong file. woops.","06/Apr/15 22:24;hadoopqa;{color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12723454/HADOOP-11746-08.patch
  against trunk revision 3fb5abf.

    {color:red}-1 @author{color}.  The patch appears to contain 13 @author tags which the Hadoop community has agreed to not allow in code contributions.

    {color:green}+1 tests included{color}.  The patch appears to include 4 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  There were no new javadoc warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 2.0.3) warnings.

        {color:red}-1 release audit{color}.  The applied patch generated 1 release audit warnings.

    {color:green}+1 core tests{color}.  The patch passed unit tests in .

Test results: https://builds.apache.org/job/PreCommit-HADOOP-Build/6068//testReport/
Release audit warnings: https://builds.apache.org/job/PreCommit-HADOOP-Build/6068//artifact/patchprocess/patchReleaseAuditProblems.txt
Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/6068//console

This message is automatically generated.","07/Apr/15 01:31;hadoopqa;{color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12723460/HADOOP-11746-09.patch
  against trunk revision 3fb5abf.

    {color:red}-1 @author{color}.  The patch appears to contain 13 @author tags which the Hadoop community has agreed to not allow in code contributions.

    {color:green}+1 tests included{color}.  The patch appears to include 4 new or modified test files.

      {color:red}-1 javac{color}.  The applied patch generated 1148 javac compiler warnings (more than the trunk's current 208 warnings).

    {color:red}-1 javadoc{color}.  The javadoc tool appears to have generated 43 warning messages.
        See https://builds.apache.org/job/PreCommit-HADOOP-Build/6069//artifact/patchprocess/diffJavadocWarnings.txt for details.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 2.0.3) warnings.

        {color:red}-1 release audit{color}.  The applied patch generated 1 release audit warnings.

    {color:red}-1 core tests{color}.  The patch failed these unit tests in hadoop-hdfs-project/hadoop-hdfs:

                  org.apache.hadoop.hdfs.TestDFSOutputStream

                                      The following test timeouts occurred in hadoop-hdfs-project/hadoop-hdfs:

org.apache.hadoop.hdfs.server.balancer.TestBalancerWithMultipleNameNodes

Test results: https://builds.apache.org/job/PreCommit-HADOOP-Build/6069//testReport/
Release audit warnings: https://builds.apache.org/job/PreCommit-HADOOP-Build/6069//artifact/patchprocess/patchReleaseAuditProblems.txt
Javac warnings: https://builds.apache.org/job/PreCommit-HADOOP-Build/6069//artifact/patchprocess/diffJavacWarnings.txt
Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/6069//console

This message is automatically generated.","07/Apr/15 06:01;aw;The rat error is real, the rest are obviously bogus.  Will fix and post an update tomorrow.","07/Apr/15 22:55;aw;-10:
* fix the rat error
* add better heuristics to determine the minimal amount of long running tests to execute: significantly faster run times for certain classes of patches
* add a site compilation test; doc patches actually get tested
* fix a few bugs in the checkstyle plugin
* fix a few bugs in the whitespace plugin

","07/Apr/15 23:33;hadoopqa;{color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12723763/HADOOP-11746-10.patch
  against trunk revision bd77a7c.

    {color:red}-1 @author{color}.  The patch appears to contain 13 @author tags which the Hadoop community has agreed to not allow in code contributions.

    {color:green}+1 tests included{color}.  The patch appears to include 4 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  There were no new javadoc warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 2.0.3) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:green}+1 core tests{color}.  The patch passed unit tests in .

Test results: https://builds.apache.org/job/PreCommit-HADOOP-Build/6071//testReport/
Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/6071//console

This message is automatically generated.","08/Apr/15 04:08;aw;-11:
* clean up the test selector API so that plugins could easily use it. so now checkstyle and (sometimes) shellcheck only kick in when necessary
* added mvn install check to javac or javadoc test check. suspect it really only needs javadoc, but let's be conservative for now
* fixed the regexes on the test selector
* added cmakelists.txt as a trigger for the native code checks

","08/Apr/15 04:12;aw;Testing this patch takes less than a minute, BTW.  Huge improvement over the 20+ mins it takes to run tests that don't make a bit of difference. It pulls in the shellcheck tests and completely skips the java-related tests.  Testing other patches seems to indicate the heuristics do more false positives (more tests than needed) but I haven't seen a situation with false negatives (missing tests that should really be run) yet. They are likely there, but we'll see. The system does report what tests it ran so we should be able to watch for that.","08/Apr/15 04:43;hadoopqa;{color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12723822/HADOOP-11746-11.patch
  against trunk revision 4be648b.

    {color:red}-1 @author{color}.  The patch appears to contain 13 @author tags which the Hadoop community has agreed to not allow in code contributions.

    {color:green}+1 tests included{color}.  The patch appears to include 4 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  There were no new javadoc warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 2.0.3) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:green}+1 core tests{color}.  The patch passed unit tests in .

Test results: https://builds.apache.org/job/PreCommit-HADOOP-Build/6073//testReport/
Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/6073//console

This message is automatically generated.","08/Apr/15 16:46;aw;[~gkesavan], how do we test this on a jenkins instance?","08/Apr/15 17:35;cnauroth;As per discussion on common-dev, we'd like to be able to exit early from test-patch runs against an attachment if the file name doesn't match *.patch.  This would cut down on spam from Jenkins trying to run test-patch on other kinds of attachments, like screenshots and design docs.

Another potential improvement on top of that would be to skip runs if the patch file name contains a branch name, because we only do pre-commit for trunk currently.

Just as a reminder, naming conventions for patch files are documented here:

https://wiki.apache.org/hadoop/HowToContribute#Naming_your_patch
","08/Apr/15 17:43;aw;bq.  Another potential improvement on top of that would be to skip runs if the patch file name contains a branch name, because we only do pre-commit for trunk currently.

This code actually can do pre-commit runs for non-trunk based upon the patch name...","08/Apr/15 19:55;omalley;This looks like a nice improvement.

It would be great if we could name patch files like git####.patch and have it apply to the git hash ####. That would let you upload patches for branches without worrying about conflicting changes.","09/Apr/15 04:15;aw;-12:
* add --resetrepo to simulate jenkins git repo nuker in developer mode
* don't send a jira message and abort early if the URL doesn't end in .patch
* Allow git(8 chars) or git(41 chars) as branch names for patch testing
* make it explicit in the report output if we were in branch or git ref mode
* fix some issues with checkstyle
* when using --resetrepo mode, shellcheck would erroneously flag .orig and .rej files from previous patches since those aren't cleared by git due to .gitignore
* fix a few shellcheck warnings I had missed. (shellcheck is still mostly ignoring dev-support. should probably fix that.)
* findbugs now gives a summary report on the console/jira output rather than forcing folks to look at the full findbugs output (altho that is still listed too!)
* set the TIMER default at startup to be current time rather 0 to prevent incredibly bogus, decades long runtimes in case of early aborts
* re-order the flags in the options parser
* fix an issue with the test heuristics so that external plugins aren't prematurely ignored

Testing itself, it says:

\\
\\
| (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | reexec | 00m 00s | dev-support patch detected. |
| {color:blue}0{color} | pre-patch | 00m 00s | Pre-patch trunk compilation is healthy. |
| {color:red}-1{color} | @author | 00m 00s | The patch appears to contain 13 @author tags which the Hadoop  community has agreed to not allow in code contributions. |
| {color:green}+1{color} | whitespace | 00m 00s | The patch has no   lines that end in whitespace. |
| {color:green}+1{color} | release audit | 00m 09s | The applied patch does not increase the total number of release audit warnings. |
| {color:green}+1{color} | shellcheck | 00m 02s | There were no new shellcheck issues. |
\\
\\
|| Subsystem || Report/Notes ||
| Optional Tests | shellcheck |
| git revision | f4b3fc5 / trunk |
| Console output | /artifact/patchprocess/console |


This message was automatically generated.","09/Apr/15 04:19;aw;If I rename the patch file to be HADOOP-11746-12.git5449adc.patch, it provides this output in the JIRA message.  Note how it gives the 5449adc reference instead of trunk above.

\\
\\
| (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | reexec | 00m 00s | dev-support patch detected. |
| {color:blue}0{color} | pre-patch | 00m 00s | Pre-patch 5449adc compilation is healthy. |
| {color:red}-1{color} | @author | 00m 00s | The patch appears to contain 13 @author tags which the Hadoop  community has agreed to not allow in code contributions. |
| {color:green}+1{color} | whitespace | 00m 00s | The patch has no   lines that end in whitespace. |
| {color:green}+1{color} | release audit | 00m 09s | The applied patch does not increase the total number of release audit warnings. |
| {color:green}+1{color} | shellcheck | 00m 02s | There were no new shellcheck issues. |
\\
\\
|| Subsystem || Report/Notes ||
| Optional Tests | shellcheck |
| git revision | 5449adc / 5449adc |
| Console output | /artifact/patchprocess/console |","09/Apr/15 04:49;aw;For comparison, I ran MAPREDUCE-6301 through it which has some known issues just so everyone can see what a Java failure looks like.  It downloaded the current patch (MR-6301-002) and gave this output:

\\
\\
| (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | pre-patch | 08m 44s | Pre-patch trunk compilation is healthy. |
| {color:green}+1{color} | @author | 00m 00s | The patch does not contain any @author tags. |
| {color:red}-1{color} | tests included | 00m 00s | The patch doesn't appear to include any new or modified tests.  Please justify why no new tests are needed for this patch. Also please list what manual steps were performed to verify this patch. |
| {color:red}-1{color} | whitespace | 00m 00s | The patch has 1  lines that end in whitespace. |
| {color:green}+1{color} | javac | 04m 09s | There were no new javac warning messages. |
| {color:green}+1{color} | javadoc | 05m 41s | There were no new javadoc warning messages. |
| {color:green}+1{color} | release audit | 00m 11s | The applied patch does not increase the total number of release audit warnings. |
| {color:green}+1{color} | checkstyle | 03m 22s | There were no new checkstyle issues. |
| {color:green}+1{color} | install | 01m 00s | mvn install still works. |
| {color:green}+1{color} | eclipse:eclipse | 00m 22s | The patch built with eclipse:eclipse. |
| {color:red}-1{color} | findbugs | 00m 51s | The patch appears to introduce 2 new Findbugs (version 3.0.1) warnings. |
| {color:red}-1{color} | core tests | 01m 20s | Tests failed in hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common. |
\\
\\
|| Reason || Tests ||
| FindBugs | FindBugs |
|   |  Unread public/protected field:At Log4jWarningErrorMetricsAppender.java:[line 44] |
| FindBugs | FindBugs |
|   |  Unread public/protected field:At Log4jWarningErrorMetricsAppender.java:[line 45] |
| Failed unit tests | Failed unit tests |
|   | hadoop.yarn.util.TestLog4jWarningErrorMetricsAppender |
\\
\\
|| Subsystem || Report/Notes ||
| Patch URL | http://issues.apache.org/jira/secure/attachment/12723637/MAPREDUCE-6301-002.patch |
| Optional Tests | javadoc javac unit checkstyle |
| git revision | f4b3fc5 / trunk |
| whitespace | /artifact/patchprocess/whitespace.txt |
| Findbugs warnings | /artifact/patchprocess/newPatchFindbugsWarningshadoop-yarn-common.html |
| hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common test log | /artifact/patchprocess/testrun_hadoop-yarn-common.txt |
| Test Results | /testReport/ |
| Console output | /artifact/patchprocess/console |


This message was automatically generated.","09/Apr/15 04:53;hadoopqa;{color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12724125/HADOOP-11746-12.patch
  against trunk revision dc0282d.

    {color:red}-1 @author{color}.  The patch appears to contain 13 @author tags which the Hadoop community has agreed to not allow in code contributions.

    {color:green}+1 tests included{color}.  The patch appears to include 4 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  There were no new javadoc warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 2.0.3) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:green}+1 core tests{color}.  The patch passed unit tests in .

Test results: https://builds.apache.org/job/PreCommit-HADOOP-Build/6084//testReport/
Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/6084//console

This message is automatically generated.","09/Apr/15 04:58;aw;
 Console summary for previous Java example:

{noformat}


-1 overall

| Vote |           Subsystem |  Runtime  | Comment
|   0  |          pre-patch  |  08m 44s  | Pre-patch trunk compilation is 
|      |                     |           | healthy.
|  +1  |            @author  |  00m 00s  | The patch does not contain any 
|      |                     |           | @author tags.
|  -1  |     tests included  |  00m 00s  | The patch doesn't appear to include 
|      |                     |           | any new or modified tests. Please
|      |                     |           | justify why no new tests are needed
|      |                     |           | for this patch. Also please list what
|      |                     |           | manual steps were performed to verify
|      |                     |           | this patch.
|  -1  |         whitespace  |  00m 00s  | The patch has 1 lines that end in 
|      |                     |           | whitespace.
|  +1  |              javac  |  04m 09s  | There were no new javac warning 
|      |                     |           | messages.
|  +1  |            javadoc  |  05m 41s  | There were no new javadoc warning 
|      |                     |           | messages.
|  +1  |      release audit  |  00m 11s  | The applied patch does not increase 
|      |                     |           | the total number of release audit
|      |                     |           | warnings.
|  +1  |         checkstyle  |  03m 22s  | There were no new checkstyle issues. 
|  +1  |            install  |  01m 00s  | mvn install still works. 
|  +1  |    eclipse:eclipse  |  00m 22s  | The patch built with 
|      |                     |           | eclipse:eclipse.
|  -1  |           findbugs  |  00m 51s  | The patch appears to introduce 2 new 
|      |                     |           | Findbugs (version 3.0.1) warnings.
|  -1  |         core tests  |  01m 20s  | Tests failed in 
|      |                     |           | hadoop-yarn-project/hadoop-yarn/hadoop
|      |                     |           | -yarn-common.


             Reason | Tests
          FindBugs  |  FindBugs 
                    |  Unread public/protected field:At Log4jWarningErrorMetricsAppender.java:[line 44] 
          FindBugs  |  FindBugs 
                    |  Unread public/protected field:At Log4jWarningErrorMetricsAppender.java:[line 45] 
 Failed unit tests  |  Failed unit tests 
                    |  hadoop.yarn.util.TestLog4jWarningErrorMetricsAppender 


|| Subsystem || Report/Notes ||
| Patch URL | http://issues.apache.org/jira/secure/attachment/12723637/MAPREDUCE-6301-002.patch |
| Optional Tests | javadoc javac unit checkstyle |
| git revision | f4b3fc5 / trunk |
| whitespace | /tmp/hadoop-test-patch/75950/whitespace.txt |
| Findbugs warnings | /tmp/hadoop-test-patch/75950/newPatchFindbugsWarningshadoop-yarn-common.html |
| hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common test log | /tmp/hadoop-test-patch/75950/testrun_hadoop-yarn-common.txt |
| Test Results | /testReport/ |
{noformat}","09/Apr/15 17:49;aw;-13:
* fix an issue where a git ref may be in the future vs. the copy on disk.  We no longer do a pull --rebase, but a fetch + checkout --force in jenkins mode.
* shellcheck support beefed up, including now failing on new errors, not if the total count was higher. Also smarter about picking up on patches that patch shell code that are not in the normal places
* cosmetic fixes for the test table
* renamed populate_unit_table to populate_test_table to better reflect what it is
* findbugs moved into its own optional test instead of being tied to javac so that pom.xml, native code, etc, won't trigger a run. (This does mean that testing findbugs itself will get missed now... but that's a very rare occurrence...)

\\
\\
| (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | reexec | 00m 00s | dev-support patch detected. |
| {color:blue}0{color} | pre-patch | 00m 00s | Pre-patch trunk compilation is healthy. |
| {color:red}-1{color} | @author | 00m 00s | The patch appears to contain 13 @author tags which the Hadoop  community has agreed to not allow in code contributions. |
| {color:green}+1{color} | whitespace | 00m 00s | The patch has no   lines that end in whitespace. |
| {color:green}+1{color} | release audit | 00m 08s | The applied patch does not increase the total number of release audit warnings. |
| {color:red}-1{color} | shellcheck | 00m 03s | The applied patch generated  6 new shellcheck issues (total was 165, now 27). |
","09/Apr/15 18:23;hadoopqa;{color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12724277/HADOOP-11746-13.patch
  against trunk revision 1885141.

    {color:red}-1 @author{color}.  The patch appears to contain 13 @author tags which the Hadoop community has agreed to not allow in code contributions.

    {color:green}+1 tests included{color}.  The patch appears to include 4 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  There were no new javadoc warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 2.0.3) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:green}+1 core tests{color}.  The patch passed unit tests in .

Test results: https://builds.apache.org/job/PreCommit-HADOOP-Build/6087//testReport/
Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/6087//console

This message is automatically generated.","10/Apr/15 00:25;hadoopqa;(!) A patch to test-patch or smart-apply-patch has been detected. 
Re-executing against the patched versions to perform further tests.","10/Apr/15 00:26;hadoopqa;\\
\\
| (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | reexec | 00m 00s | dev-support patch detected. |
| {color:blue}0{color} | pre-patch | 00m 00s | Pre-patch trunk compilation is healthy. |
| {color:red}-1{color} | @author | 00m 00s | The patch appears to contain 13 @author tags which the Hadoop  community has agreed to not allow in code contributions. |
| {color:green}+1{color} | whitespace | 00m 00s | The patch has no   lines that end in whitespace. |
| {color:green}+1{color} | release audit | 00m 09s | The applied patch does not increase the total number of release audit warnings. |
| {color:red}-1{color} | shellcheck | 00m 03s | The applied patch generated  7 new shellcheck issues (total was 165, now 28). |
| | | 00m 14s | |
\\
\\
|| Subsystem || Report/Notes ||
| Optional Tests | shellcheck |
| git revision | f4b3fc5 / trunk |
| shellcheck | https://builds.apache.org/job/PreCommit-HADOOP-Build/fake//artifact/patchprocessdiffpatchshellcheck.txt |
| Console output | https://builds.apache.org/job/PreCommit-HADOOP-Build/fake//artifact/patchprocessconsole |


This message was automatically generated.","10/Apr/15 04:35;aw;-14:
* add --offline mode to prevent connections to the internet. extremely useful on planes and trains.
* changed the unit test output so that one can see runtimes *per module*.  extremely useful to figure out which set of tests need some love
* changed how timers work so that there is now an timer for the entire run
* after a lot of testing with bigger patches, increased the minute marks to be 3 digits since some tests run for hours. :(
* lots of other, more minor output tweaking, esp after doing a better jenkins simulation
* don't print out the reexec command line because of security issues","10/Apr/15 04:36;hadoopqa;(!) A patch to test-patch or smart-apply-patch has been detected. 
Re-executing against the patched versions to perform further tests.","10/Apr/15 04:37;hadoopqa;\\
\\
| (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | reexec |   0m 00s | dev-support patch detected. |
| {color:blue}0{color} | pre-patch |   0m 00s | Pre-patch trunk compilation is healthy. |
| {color:red}-1{color} | @author |   0m 00s | The patch appears to contain 13 @author tags which the Hadoop  community has agreed to not allow in code contributions. |
| {color:green}+1{color} | whitespace |   0m 00s | The patch has no lines that end in whitespace. |
| {color:green}+1{color} | release audit |   0m 09s | The applied patch does not increase the total number of release audit warnings. |
| {color:red}-1{color} | shellcheck |   0m 03s | The applied patch generated  7 new shellcheck issues (total was 165, now 28). |
| | |   0m 14s | |
\\
\\
|| Subsystem || Report/Notes ||
| Optional Tests | shellcheck |
| git revision | trunk / f4b3fc5 |
| shellcheck | https://builds.apache.org/job/PreCommit-HADOOP-Build/fake/artifact/patchprocess/diffpatchshellcheck.txt |
| Console output | https://builds.apache.org/job/PreCommit-HADOOP-Build/fake//console |


This message was automatically generated.","10/Apr/15 05:14;hadoopqa;{color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12724454/HADOOP-11746-14.patch
  against trunk revision af9d4fe.

    {color:red}-1 @author{color}.  The patch appears to contain 13 @author tags which the Hadoop community has agreed to not allow in code contributions.

    {color:green}+1 tests included{color}.  The patch appears to include 4 new or modified test files.

      {color:red}-1 javac{color}.  The applied patch generated 1201 javac compiler warnings (more than the trunk's current 1163 warnings).

    {color:green}+1 javadoc{color}.  There were no new javadoc warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 2.0.3) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:green}+1 core tests{color}.  The patch passed unit tests in .

Test results: https://builds.apache.org/job/PreCommit-HADOOP-Build/6092//testReport/
Javac warnings: https://builds.apache.org/job/PreCommit-HADOOP-Build/6092//artifact/patchprocess/diffJavacWarnings.txt
Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/6092//console

This message is automatically generated.","10/Apr/15 19:02;aw;-15:
* go back to git pull rebase
","10/Apr/15 19:58;hadoopqa;{color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12724628/HADOOP-11746-15.patch
  against trunk revision 7660da9.

    {color:red}-1 @author{color}.  The patch appears to contain 13 @author tags which the Hadoop community has agreed to not allow in code contributions.

    {color:green}+1 tests included{color}.  The patch appears to include 4 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  There were no new javadoc warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 2.0.3) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:green}+1 core tests{color}.  The patch passed unit tests in .

Test results: https://builds.apache.org/job/PreCommit-HADOOP-Build/6093//testReport/
Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/6093//console

This message is automatically generated.","15/Apr/15 19:21;cnauroth;Thank you for the patch, Allen.  The new functionality looks great!  Here are a few comments.

checkstyle.sh
# {{checkstyle_postapply}}: Please correct the indentation on this line.
{code}
 cp -p ""${BASEDIR}/target/checkstyle-result.xml"" ""${PATCH_DIR}/checkstyle-result-patch.xml""
{code}
# Do you think it's worthwhile to move the Python code into its own .py file?

shellcheck.sh
# {{shellcheck_private_findbash}}: This looks for files in bin and sbin.  Do we also need libexec, which is currently used in hadoop-kms and hadoop-hdfs-httpfs?
# There are shellcheck warnings on lines 49 and 70.  I see shellcheck.sh caught them in the last run, so that's cool.  :-)

whitespace.sh
# From some quick testing of the grep, it's catching trailing spaces, but not trailing tabs.

test-patch.sh
# {{precheck_without_patch}} and {{check_site}}: The mvn site command that is echoed is slightly different from what is actually run.  The arguments are in a different order.  I wonder if it would be helpful to have a {{echo_and_exec}} helper function to call everywhere that we do this kind of thing.
# {{determine_needed_tests}}: I believe this would not identify tests for a patch that contained only changes in test resources (not Java test code).  Examples of this include testConf.xml and editsStored and editsStored.xml.
# {{check_unittests}}: The echo of the mvn command on line 1736 does not include the redirection of output to test_logfile as the actual executed command does.
# {{output_to_console}}: Today I learned that your secret talent is ASCII elephant art.  :-)
# There are shellcheck warnings on lines 1158, 1573, 1732, 1751, and 1995.
# The old test-patch.sh output always included a hyperlink to the patch file that it ran.  Can we please add that?  I always found that helpful for knowing exactly which patch it was reporting on, in case multiple revisions got uploaded quickly.

Are you planning to clean up smart-apply-patch.sh in scope of this jira, or will that happen elsewhere?
","16/Apr/15 08:41;aw;-16:
* Fixed, etc through all of the [~cnauroth]'s review comments.  Much thanks!

Some notes:

{{checkstyle.sh}}

bq. 2. Do you think it's worthwhile to move the Python code into its own .py file?

I've been debating this myself.  Two advantages of doing it this way:
* the whole plug-in is self contained.
* the dev-support patch detection is a lot easier

{{shellcheck.sh}}

bq. 1. {{shellcheck_private_findbash}}: This looks for files in bin and sbin. Do we also need libexec, which is currently used in hadoop-kms and hadoop-hdfs-httpfs?

Great catch.  I also added shellprofile.d while I was there!

{{whitespace.sh}}

Ugh. Good point. That should be [[:blank:]] not [[:space:]].  Easy fix.  This also means this works in non-C locales a bit better.

{{testpatch.sh}}

bq. 2. {{determine_needed_tests}}: I believe this would not identify tests for a patch that contained only changes in test resources (not Java test code). Examples of this include testConf.xml and editsStored and editsStored.xml.

Relevant code:
{code}
    elif [[ ${i} =~ \.c$
...
      || ${i} =~ src/test
...
       ]]; then
       hadoop_debug ""tests/native: ${i}""
       add_test javac
       add_test unit
{code}

It should.  If *any* file has src/test in its path, it will trigger the javac and unit tests.  It's really not ""tests/native"", so maybe that should get renamed to something else I guess.  (This is counter to tests/java which also triggers javadoc tests)

bq. 4. {{output_to_console}}: Today I learned that your secret talent is ASCII elephant art. 

I don't know what you are talking about.  Maybe your patch download was bad? ;)

bq. 5. There are shellcheck warnings on lines 1158, 1573, 1732, 1751, and 1995.

Fixed or disabled all of these except two, which are a) false positives and b) extremely hard to escape because they are actually awk commands in a multiline pipe.

bq. 6. The old test-patch.sh output always included a hyperlink to the patch file that it ran. Can we please add that? I always found that helpful for knowing exactly which patch it was reporting on, in case multiple revisions got uploaded quickly.

It actually does this when the patch provided is from either a JIRA or a URL.  This is consistent with the old code.

FWIW, I've uploaded the same patch into HADOOP-11820 and ran it in jenkins mode.  You'll see the shellcheck #'s and the patch URL there as well. Check out that execution time. :D :D","16/Apr/15 08:47;aw;Oh, forgot:

bq. Are you planning to clean up smart-apply-patch.sh in scope of this jira, or will that happen elsewhere?

I was planning on ignoring smart-apply-patch for the time being.  [~raymie]'s patch in HADOOP-11781 fixed the dangerous problems.  Plus the HBase people are putting the pressure on for me to start work on HBASE-13231, especially since [~stack] is going around telling people publicly the new shell code will be a feature in 2.0... ;)","16/Apr/15 09:23;hadoopqa;{color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12725807/HADOOP-11746-16.patch
  against trunk revision 1b89a3e.

    {color:red}-1 @author{color}.  The patch appears to contain 13 @author tags which the Hadoop community has agreed to not allow in code contributions.

    {color:green}+1 tests included{color}.  The patch appears to include 4 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  There were no new javadoc warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 2.0.3) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:green}+1 core tests{color}.  The patch passed unit tests in .

Test results: https://builds.apache.org/job/PreCommit-HADOOP-Build/6111//testReport/
Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/6111//console

This message is automatically generated.","16/Apr/15 18:33;cnauroth;+1 for patch v16.  All of my feedback has been addressed either by code changes or explaining parts of the logic that I misunderstood.

Since this impacts everyone's day-to-day work, can we please hold off committing until Friday, 4/17, just in case there are other opinions?  I'll send notice now to the dev lists.

I have just one more procedural question.  I see this is flagged as an incompatible change.  While that's technically true, I don't think compatibility concerns apply to our internal dev tooling.  If it's flagged as incompatible, then it may cause confusion for Hadoop end users who think they need to do something in their deployments to react to this incompatibility.  What do you think?
","16/Apr/15 20:23;aw;A few things:

a) It'd be great if HADOOP-11778 was committed as well.  This updates the maven checkstyle plugin so that it doesn't NPE on our code base in certain conditions, at least on trunk.  It doesn't *break* the plugin, but it does mean the results may not be 100% accurate.

b) We need to be aware that shellcheck isn't installed on the jenkins boxes yet.  This means the shellcheck tests won't execute until that's rectified. (That plugin shouldn't error, however, since the code does try to see if it is installed first.)

c) We'll likely need to commit to branch-2 anyway if we want the patch branch detection code to work.  I don't know how jenkins actually uses test-patch.sh, but this code does *not* switch the branch back to trunk after it runs on another branch.  This might very well be a bug, now that I think about it more.","16/Apr/15 20:31;aw;(Although, really, that's a problem with the branch detection period unless we backport it to every single branch.  So we probably just need to commit this to a reasonable number of branches (branch-1, branch-2, branch-2.7, trunk, ... ? ) and just be aware that someone can upload a patch that may throw things off.)","17/Apr/15 08:23;aw;After sleeping on it, I think it's better to be safe than sorry in case of problems. A few extra lines for extra paranoia...

-17:
* During re-exec mode, make sure jenkins reports the console in the ""switching"" message in case something goes wrong.
* In reset repo mode, always force checkout to trunk after cleaning the repo area.  This might not actually matter in the grand scheme of things, but if something goes haywire in the middle this should provide some level of safety to get us back to a clean slate.
* Don't switch to any branches that match: branch-0, branch-1, branch-2.[0-7]. It should be noted that currently the code to find a branch won't properly detect minor or micro version branches anyway, so the branch-2 minor version lockout is just in case someone fixes that bug later. ;)

It should be safe to commit this to branch-2 and have the system come back to trunk for 'real' patches.

","17/Apr/15 09:03;hadoopqa;{color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12726104/HADOOP-11746-17.patch
  against trunk revision 76e7264.

    {color:red}-1 @author{color}.  The patch appears to contain 13 @author tags which the Hadoop community has agreed to not allow in code contributions.

    {color:green}+1 tests included{color}.  The patch appears to include 4 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  There were no new javadoc warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 2.0.3) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:green}+1 core tests{color}.  The patch passed unit tests in .

Test results: https://builds.apache.org/job/PreCommit-HADOOP-Build/6115//testReport/
Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/6115//console

This message is automatically generated.","17/Apr/15 14:41;busbey;The jenkins job should be restoring a clean workspace at job start, so we shouldn't need to worry about changing branches back after.","17/Apr/15 15:07;busbey;+1 after non-nit issues below. Adding audience / stability comments is a really nice touch.

{code}
+## @description  Some crazy people like Eclipse.  Make sure Maven's eclipse generation
+## @description  works so they don't freak out.
{code}

Please leave out the ableist pejorative.

{code}
+function check_unittests
+{
+  verify_needed_test unit
+
+  if [[ $? == 0 ]]; then
+    echo ""Existing unit tests do not test patched files. Skipping.""
+    return 0
+  fi

+  big_console_header ""Running unit tests""
{code}

Nit: could we make this (and maybe the module choosing) optional so that if I know tests end up covering my changes indirectly I can set a flag to run through things? (Although maybe I missed how I could do this myself)

This will mostly be useful when I try to merge this set of changes with things over in HBase, since we run through all the unit tests on pre-patch.

{code}
+    if [[ -d ""${mypwd}/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs"" ]]; then
+      echo ""Changing permission on ${mypwd}/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs to avoid broken builds""
+      chmod +x -R ""${mypwd}/hadoop-hdfs-project/hadoop-hdfs/target/test/data/dfs""
+    fi
{code}

Nit: so long as we're cleaning things up, could we replace this with a general solution? The root cause of the issue that introduced this change originally was that we need to ensure any directories that exist under a maven module target directory are executable. We know tests can break that one, but there's no reason some other module might break a different one later.","17/Apr/15 16:41;cnauroth;+1 from me also after resolution of Sean's comments.  (Thanks, Sean!)","17/Apr/15 20:30;aw;-18:
* add --modulelist and --testlist options to forcibly add modules and test subsystems to a run. there is no way to delete, but that's probably a good thing really.
* removed the branch restrictions since this apparently won't impact jenkins
* the check for new tests actually uses the /test/ file path against the list of changed files in the check for new tests in unit test mode.  This prevents some false positives and should improve the count in certain/rare situations.  Prior to this, it just looked for (something)/test(something) in the actual patch... which meant test-patch itself would be cleared.  (Ironically, test-patch.sh is now capable of testing itself, so ... yeah.  test-ception.)
* in developer mode when \-\-resetrepo is used, the user output reminds that the code the user chose to run in a destructive mode. (\-\-resetrepo is the default in jenkins mode, obviously)
* Added code to chmod +x all directories in echo_and_redirect. This should cover every maven run.
* Cleaned up the eclipse description.
* Checkstyle now uses the ${PROJECT_NAME} var instead of the hard coded hadoop value, making the code more portable.
* Reworded some debug output for test subsystems when they are triggered
* verify_needed_test was missing documentation

bq. Adding audience / stability comments is a really nice touch.

Thanks. If you run shelldoc.py (after HADOOP-11845 is applied... ugh) against the code, you'll get a markdown document of the function calls. We're currently using this same functionality in trunk to document hadoop-functions.sh as the 'official' shell API for shell profiles.

","17/Apr/15 21:16;hadoopqa;{color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12726255/HADOOP-11746-18.patch
  against trunk revision d573f09.

    {color:red}-1 @author{color}.  The patch appears to contain 13 @author tags which the Hadoop community has agreed to not allow in code contributions.

    {color:green}+1 tests included{color}.  The patch appears to include 4 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  There were no new javadoc warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 2.0.3) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:green}+1 core tests{color}.  The patch passed unit tests in .

Test results: https://builds.apache.org/job/PreCommit-HADOOP-Build/6118//testReport/
Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/6118//console

This message is automatically generated.","19/Apr/15 19:14;aw;-19:
* Merged in the fixes from HADOOP-11845, otherwise rat checks fail because mvn site generates a file that violates rat.  this also enables shelldocs to actually build documentation for test-patch's API too.
* shellcheck test reports version of shellcheck
* shellcheck find command was very broken
* upgraded my local copy of shellcheck, which now includes some new checks. fixed errors from those new checks (mainly local blah=subshell issues)
* somewhere along the way, the value of the initial cwd got screwed up.
* re-arranged the findbugs code a bit to give more realistic times
* if for some reason openssl or base64 throws an error, just send them to /dev/null
* fixed a minor message bug in the site check","19/Apr/15 19:53;hadoopqa;{color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12726461/HADOOP-11746-19.patch
  against trunk revision 5459b24.

    {color:red}-1 @author{color}.  The patch appears to contain 13 @author tags which the Hadoop community has agreed to not allow in code contributions.

    {color:green}+1 tests included{color}.  The patch appears to include 4 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  There were no new javadoc warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 2.0.3) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:green}+1 core tests{color}.  The patch passed unit tests in .

Test results: https://builds.apache.org/job/PreCommit-HADOOP-Build/6123//testReport/
Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/6123//console

This message is automatically generated.","20/Apr/15 03:26;busbey;This is a nit / stylistic issue, but I noticed that if compilation, javadoc, site, or checkstyle are broken before applying the patch, the jira comment is -1. I found that surprising, as compared to say ""-0"" since in those cases the QA bot can't judge the suitability of the patch.

The rewrite is a great improvement. Any idea what else you want to cover before pushing?","20/Apr/15 07:31;aw;bq.  I found that surprising, as compared to say ""-0"" since in those cases the QA bot can't judge the suitability of the patch.

This is actually how the old test-patch.sh works as well.  I tend to agree with the -1 because if the base universe is broken, it really can't judge how well the patch is going to work either.  The +1's are going to be false flags. 

bq. The rewrite is a great improvement. Any idea what else you want to cover before pushing?

Thanks! Not really planning on more changes.  Playing around with HADOOP-11843 (which upgraded shellcheck) and realizing I hadn't exercised the site tests yet popped up the problems fixed in -19.  At this point, I think all the subsystems have been thoroughly worked (at least by me) so any outstanding issues will likely be edge case bugs and/or issues with the Jenkins build environment.

[There are one or two more optimizations I could make in site tests, but since those run so quickly anyway, they aren't a big concern.]","20/Apr/15 09:25;aw;bq. One thing I'm still confused by is why the original test-patch exit'd with 0 during some failure situations. Is this a bug in the original or was there a reason? I kept that behavior but it still seems wrong...

I asked this question way above, but haven't gotten an answer.  This still feels wrong to me and suspect these should really be exiting with 1.","20/Apr/15 15:51;busbey;probably an oversight? exiting with 0 in those conditions would prevent the jenkins job from registering as a failure, but I'm not sure why that would be desirable.","20/Apr/15 18:09;aw;Yeah I think it was probably a mistake.

Here's -20 which changes all of those to return 1, thus failing the jenkins build.  I guess we'll see what happens.  ","20/Apr/15 18:44;hadoopqa;{color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12726614/HADOOP-11746-20.patch
  against trunk revision f967fd2.

    {color:red}-1 @author{color}.  The patch appears to contain 13 @author tags which the Hadoop community has agreed to not allow in code contributions.

    {color:green}+1 tests included{color}.  The patch appears to include 4 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  There were no new javadoc warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 2.0.3) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:green}+1 core tests{color}.  The patch passed unit tests in .

Test results: https://builds.apache.org/job/PreCommit-HADOOP-Build/6129//testReport/
Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/6129//console

This message is automatically generated.","21/Apr/15 19:31;aw;-21:
A one line change in the site test:

{code}
< +  add_jira_table +1 site ""There were no new javadoc warning messages.""
---
> +  add_jira_table +1 site ""Site still builds.""
{code}

...

[~cnauroth], does your +1 still stand?  I'm pretty much ready to commit this. Promise.  lol","21/Apr/15 19:43;cnauroth;I checked the diff since my last review (-17), and everything looks good to me.  I agree with the decision to maintain the existing behavior of -1 when the existing trunk build is already broken, and I agree with changing those failure code paths to exit with a non-zero code.

+1 for patch -21.  Thanks for your work on this, Allen.  The new functionality is great.  Now hurry up and commit before you get more ideas!  :-)  Sean, thank you for helping with the code review.","21/Apr/15 20:13;aw;branch-2 version.","21/Apr/15 20:20;hadoopqa;{color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12726970/HADOOP-11746-21.patch
  against trunk revision 997408e.

    {color:red}-1 @author{color}.  The patch appears to contain 13 @author tags which the Hadoop community has agreed to not allow in code contributions.

    {color:green}+1 tests included{color}.  The patch appears to include 4 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  There were no new javadoc warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 2.0.3) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:green}+1 core tests{color}.  The patch passed unit tests in .

Test results: https://builds.apache.org/job/PreCommit-HADOOP-Build/6141//testReport/
Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/6141//console

This message is automatically generated.","21/Apr/15 20:40;cnauroth;I didn't realize trunk test-patch.sh had diverged so much from branch-2.  Is this basically just copying the new code over to branch-2?  If so, then +1 for the branch-2 patch.  If not, then can you point out specific bits that would need review?  Thanks!","21/Apr/15 20:44;aw;Yeah, I was surprised too!  I did indeed just copy the code over the top of it.  Hopefully it works. Haha.","21/Apr/15 20:45;aw;This has been committed to trunk and branch-2.  

Thanks everyone for the assistance!","21/Apr/15 21:03;hudson;FAILURE: Integrated in Hadoop-trunk-Commit #7627 (See [https://builds.apache.org/job/Hadoop-trunk-Commit/7627/])
HADOOP-11746. rewrite test-patch.sh (aw) (aw: rev 73ddb6b4f825be1d06fd1d2be86a4bea241e7aa0)
* dev-support/test-patch.d/checkstyle.sh
* dev-support/shelldocs.py
* hadoop-common-project/hadoop-common/CHANGES.txt
* dev-support/test-patch.sh
* dev-support/test-patch.d/shellcheck.sh
* dev-support/test-patch.d/whitespace.sh
","21/Apr/15 21:27;aw;FYI, HDFS-8200 @ https://builds.apache.org/job/PreCommit-HDFS-Build/10335/console appears to be the first jenkins run with the new test-patch.sh .","21/Apr/15 21:34;aw;Nope, MAPREDUCE-6324 @ https://builds.apache.org/job/PreCommit-MAPREDUCE-Build/5426/console was first by a few minutes.

Both have entered into mvn test phase.  Interesting to note that git clean removed quite a bit of gunk from the git repo on the HDFS test.  Hmmmmmmmmmm......","22/Apr/15 07:17;aw;I posted this on -dev, but to copy the status update here:

* So far, HADOOP-11861 was filed which is luckily an extremely easy bug to fix.

* There have been a few runs which seems to indicate that *something* is destroying the artifact directory in the middle of runs…. which is very very odd and something I hadn’t seen in any of my testing.  In any case, I clearly need to add some safety code here to report back that something went awry and report back which node, console, etc this happened on. Someone more familiar with the Jenkins setup might be able to shed some light on why that might happen. All of these runs appear to be on H3, so might be related? Impacted issues with this have been:

- HDFS-8200 (https://builds.apache.org/job/PreCommit-HDFS-Build/10335/)
- HDFS-8147 (https://builds.apache.org/job/PreCommit-HDFS-Build/10338/)
- YARN-3301 (https://builds.apache.org/job/PreCommit-YARN-Build/7441/) 

* Some sort of good news! The new mvn site test does appear to be capable of catching issues!  YARN-3410 was committed just prior to the new test code and has markdown-to-html syntax issues.  HADOOP-11627 (for example) shows the results. :D","22/Apr/15 11:35;hudson;FAILURE: Integrated in Hadoop-Hdfs-trunk #2103 (See [https://builds.apache.org/job/Hadoop-Hdfs-trunk/2103/])
HADOOP-11746. rewrite test-patch.sh (aw) (aw: rev 73ddb6b4f825be1d06fd1d2be86a4bea241e7aa0)
* dev-support/test-patch.d/whitespace.sh
* dev-support/test-patch.d/checkstyle.sh
* dev-support/shelldocs.py
* dev-support/test-patch.sh
* dev-support/test-patch.d/shellcheck.sh
* hadoop-common-project/hadoop-common/CHANGES.txt
","22/Apr/15 11:35;hudson;FAILURE: Integrated in Hadoop-Hdfs-trunk-Java8 #162 (See [https://builds.apache.org/job/Hadoop-Hdfs-trunk-Java8/162/])
HADOOP-11746. rewrite test-patch.sh (aw) (aw: rev 73ddb6b4f825be1d06fd1d2be86a4bea241e7aa0)
* dev-support/test-patch.d/shellcheck.sh
* dev-support/test-patch.sh
* hadoop-common-project/hadoop-common/CHANGES.txt
* dev-support/shelldocs.py
* dev-support/test-patch.d/whitespace.sh
* dev-support/test-patch.d/checkstyle.sh
","22/Apr/15 11:38;hudson;FAILURE: Integrated in Hadoop-Yarn-trunk-Java8 #171 (See [https://builds.apache.org/job/Hadoop-Yarn-trunk-Java8/171/])
HADOOP-11746. rewrite test-patch.sh (aw) (aw: rev 73ddb6b4f825be1d06fd1d2be86a4bea241e7aa0)
* hadoop-common-project/hadoop-common/CHANGES.txt
* dev-support/test-patch.sh
* dev-support/test-patch.d/shellcheck.sh
* dev-support/shelldocs.py
* dev-support/test-patch.d/whitespace.sh
* dev-support/test-patch.d/checkstyle.sh
","22/Apr/15 12:00;hudson;SUCCESS: Integrated in Hadoop-Yarn-trunk #905 (See [https://builds.apache.org/job/Hadoop-Yarn-trunk/905/])
HADOOP-11746. rewrite test-patch.sh (aw) (aw: rev 73ddb6b4f825be1d06fd1d2be86a4bea241e7aa0)
* dev-support/test-patch.sh
* dev-support/shelldocs.py
* hadoop-common-project/hadoop-common/CHANGES.txt
* dev-support/test-patch.d/whitespace.sh
* dev-support/test-patch.d/shellcheck.sh
* dev-support/test-patch.d/checkstyle.sh
","22/Apr/15 13:21;hudson;FAILURE: Integrated in Hadoop-Mapreduce-trunk-Java8 #172 (See [https://builds.apache.org/job/Hadoop-Mapreduce-trunk-Java8/172/])
HADOOP-11746. rewrite test-patch.sh (aw) (aw: rev 73ddb6b4f825be1d06fd1d2be86a4bea241e7aa0)
* dev-support/test-patch.d/whitespace.sh
* dev-support/shelldocs.py
* dev-support/test-patch.d/checkstyle.sh
* dev-support/test-patch.sh
* hadoop-common-project/hadoop-common/CHANGES.txt
* dev-support/test-patch.d/shellcheck.sh
","22/Apr/15 13:41;hudson;FAILURE: Integrated in Hadoop-Mapreduce-trunk #2121 (See [https://builds.apache.org/job/Hadoop-Mapreduce-trunk/2121/])
HADOOP-11746. rewrite test-patch.sh (aw) (aw: rev 73ddb6b4f825be1d06fd1d2be86a4bea241e7aa0)
* dev-support/shelldocs.py
* dev-support/test-patch.d/whitespace.sh
* dev-support/test-patch.sh
* hadoop-common-project/hadoop-common/CHANGES.txt
* dev-support/test-patch.d/checkstyle.sh
* dev-support/test-patch.d/shellcheck.sh
","22/Apr/15 16:46;Naganarasimha;Hi [~aw], 
Sorry for the naive query but some how dint understand the output of the check style. For instance in yarn-2740 output comes as 
{quote}
hadoop-yarn-project/hadoop-yarn/hadoop-yarn-api/src/main/java/org/apache/hadoop/yarn/conf/YarnConfiguration.java	601	604
hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common/src/main/java/org/apache/hadoop/yarn/nodelabels/NodeLabelsStore.java	32	33
hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common/src/main/java/org/apache/hadoop/yarn/nodelabels/FileSystemNodeLabelsStore.java	75	77
hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common/src/main/java/org/apache/hadoop/yarn/nodelabels/CommonNodeLabelsManager.java	240	241
hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager/src/main/java/org/apache/hadoop/yarn/server/resourcemanager/AdminService.java	146	151
{quote}
whats the significance of the 2 integers which follows the modified file name ?","22/Apr/15 16:49;busbey;First is number of reported errors in that file pre-patch, second is the number after.

Getting useful pointers from checkstyle is difficult. It's relatively high on the list of improvements for HBase (we do this file-level count right now as well). When that happens we'll push it back over into Hadoop.","22/Apr/15 16:59;Naganarasimha;thanks for the reply [~busbey], 
In that case would it be better to have header some thing like ""Name of the modified Java file | Number of Previous check style issues | Number of Current check style issues""  ? and also if possible print the links of previous and current check style output. (either in the report or in the output file)","22/Apr/15 17:20;busbey;Those sounds like fine things for a follow-on improvement jira. :)","22/Apr/15 17:25;Naganarasimha;i have already raised one followup jira [HADOOP-11866] will add this point to it... :)","22/Apr/15 17:44;aw;I originally had links to the checkstyle reports.  Then realized they were *several megabytes* in size.... basically, too big to stuff into a web browser (at least, by random people clicking on it.. surprise!) plus I was worried about the load on the jenkins' hosts . :(

I tried a few different strategies to make checkstyle more usable, but it frankly isn't built for this type of thing.  I opted to steal the HBase code and punt on it.  On the flip side, it should be possible for someone to generate their *own* checkstyle report, dig up the file that broke, and fix it.","22/Apr/15 17:45;aw;Linking HADOOP-11861, which I've stuffed a few fixes.","22/Apr/15 18:09;leftnoteasy;Thanks [~aw] for this great work, adding checkstyle/whitespace check is helpful, but I think it's better to indicate it's a -0/+0 instead of ""-1"". Different from other checks like findbugs/javac WARNINGs/test-not-include, they're best-to-have minor format suggestions. 

An example is: https://issues.apache.org/jira/browse/YARN-3413?focusedCommentId=14507511&page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-14507511.

Thoughts?","22/Apr/15 19:01;busbey;The QA bot doesn't get a binding vote, so I think clearly stating -1 for things that violate the community guidelines is preferable. Individual committers can always choose to ignore build bot feedback.

The whitespace / checkstyle improvements are being tracked on HADOOP-11866. please keep the discussion of them over there.","22/Apr/15 19:25;aw;bq. Thoughts?

I think ignoring whitespace problems when pointed out is lazy, given how relatively easy they are to fix. At this point, both git and test-patch are now warning about this issue.  If one is unmotivated to fix such a simple problem, what else is getting ignored? 

HowToContribute is actually pretty explicit about checkstyle errors.  Patches that violate it are supposed to be rejected.  We've been lax in the past. It's time to step up our vigilance and this is the first step.  We certainly need to improve the output here, but at least we're getting notified about them.","22/Apr/15 21:56;aw;Just a heads up, I've posted an addendum patch to HADOOP-11861 that fixes some semi-critical bugs based upon the past 24 hours of Jenkins usage.","24/Apr/15 20:15;cnauroth;[~aw], I noticed a small discrepancy in CHANGES.txt between trunk and branch-2.  On trunk, HADOOP-11746 is listed in the Incompatible Changes section.  On branch-2, it's in New Features.  Would you mind committing a change to make them consistent?

I'd suggest New Features.  I mentioned in an earlier comment that I don't think the compatibility guidelines apply to CI automation that doesn't ship with the product.  If you feel strongly about marking it incompatible though, I'm still +1 to moving it to the Incompatible Changes section.  Thanks!"
test-patch.sh javac result is wildly wrong,HADOOP-11881,12824304,Test,Resolved,HADOOP,Hadoop Common,software,omalley,Hadoop Common is the common library for Apache Hadoop.,http://hadoop.apache.org/,Major,Fixed,sekikn,aw,aw,27/Apr/15 15:08,30/Aug/16 01:29,12/Jan/21 11:55,28/Apr/15 17:44,,,,,2.8.0,3.0.0-alpha1,,,,,build,test,,,0,newbie,,"The summary report appears to list the total amount of javac warnings, not the amount of new ones.  See MAPREDUCE-6192 as an example.

",,aw,hudson,sekikn,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"28/Apr/15 17:09;sekikn;HADOOP-11881.001.patch;https://issues.apache.org/jira/secure/attachment/12728839/HADOOP-11881.001.patch",,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,2015-04-28 17:09:15.219,,,false,,,,,,,,,,,,,,,,,9223372036854775807,,,,,Tue May 12 15:15:31 UTC 2015,,,,,,,"0|i2dt7b:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,"28/Apr/15 17:09;sekikn;Attaching a patch. I applied MAPREDUCE-6192.006.patch and confirm that  the number of javac warnings in the summary report was the same as the number of differences appeared in diffJavacWarnings.txt.","28/Apr/15 17:20;hadoopqa;(!) A patch to test-patch or smart-apply-patch has been detected. 
Re-executing against the patched versions to perform further tests. 
The console is at https://builds.apache.org/job/PreCommit-HADOOP-Build/6206/console in case of problems.","28/Apr/15 17:21;hadoopqa;\\
\\
| (/) *{color:green}+1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | reexec |   0m  0s | dev-support patch detected. |
| {color:blue}0{color} | pre-patch |   0m  0s | Pre-patch trunk compilation is healthy. |
| {color:blue}0{color} | @author |   0m  0s | Skipping @author checks as test-patch has been patched. |
| {color:green}+1{color} | whitespace |   0m  0s | The patch has no lines that end in whitespace. |
| {color:green}+1{color} | release audit |   0m 18s | The applied patch does not increase the total number of release audit warnings. |
| {color:blue}0{color} | shellcheck |   0m 18s | Shellcheck was not available. |
| | |   0m 26s | |
\\
\\
|| Subsystem || Report/Notes ||
| Patch URL | http://issues.apache.org/jira/secure/attachment/12728839/HADOOP-11881.001.patch |
| Optional Tests | shellcheck |
| git revision | trunk / 99fe03e |
| Java | 1.7.0_55 |
| uname | Linux asf907.gq1.ygridcore.net 3.13.0-36-lowlatency #63-Ubuntu SMP PREEMPT Wed Sep 3 21:56:12 UTC 2014 x86_64 x86_64 x86_64 GNU/Linux |
| Console output | https://builds.apache.org/job/PreCommit-HADOOP-Build/6206/console |


This message was automatically generated.","28/Apr/15 17:29;aw;I figured it was something dumb I did. :)

+1 will commit here in a bit.

Thanks!","28/Apr/15 17:42;hudson;FAILURE: Integrated in Hadoop-trunk-Commit #7693 (See [https://builds.apache.org/job/Hadoop-trunk-Commit/7693/])
HADOOP-11881. test-patch.sh javac result is wildly wrong (Kengo Seki via aw) (aw: rev eccf709a619b05aaa92b27693a9c302d349acf22)
* hadoop-common-project/hadoop-common/CHANGES.txt
* dev-support/test-patch.sh
","29/Apr/15 12:00;hudson;FAILURE: Integrated in Hadoop-Hdfs-trunk #2110 (See [https://builds.apache.org/job/Hadoop-Hdfs-trunk/2110/])
HADOOP-11881. test-patch.sh javac result is wildly wrong (Kengo Seki via aw) (aw: rev eccf709a619b05aaa92b27693a9c302d349acf22)
* hadoop-common-project/hadoop-common/CHANGES.txt
* dev-support/test-patch.sh
","29/Apr/15 12:08;hudson;FAILURE: Integrated in Hadoop-Hdfs-trunk-Java8 #169 (See [https://builds.apache.org/job/Hadoop-Hdfs-trunk-Java8/169/])
HADOOP-11881. test-patch.sh javac result is wildly wrong (Kengo Seki via aw) (aw: rev eccf709a619b05aaa92b27693a9c302d349acf22)
* dev-support/test-patch.sh
* hadoop-common-project/hadoop-common/CHANGES.txt
","29/Apr/15 12:23;hudson;FAILURE: Integrated in Hadoop-Yarn-trunk-Java8 #178 (See [https://builds.apache.org/job/Hadoop-Yarn-trunk-Java8/178/])
HADOOP-11881. test-patch.sh javac result is wildly wrong (Kengo Seki via aw) (aw: rev eccf709a619b05aaa92b27693a9c302d349acf22)
* dev-support/test-patch.sh
* hadoop-common-project/hadoop-common/CHANGES.txt
","29/Apr/15 12:40;hudson;FAILURE: Integrated in Hadoop-Yarn-trunk #912 (See [https://builds.apache.org/job/Hadoop-Yarn-trunk/912/])
HADOOP-11881. test-patch.sh javac result is wildly wrong (Kengo Seki via aw) (aw: rev eccf709a619b05aaa92b27693a9c302d349acf22)
* dev-support/test-patch.sh
* hadoop-common-project/hadoop-common/CHANGES.txt
","29/Apr/15 15:15;hudson;FAILURE: Integrated in Hadoop-Mapreduce-trunk-Java8 #179 (See [https://builds.apache.org/job/Hadoop-Mapreduce-trunk-Java8/179/])
HADOOP-11881. test-patch.sh javac result is wildly wrong (Kengo Seki via aw) (aw: rev eccf709a619b05aaa92b27693a9c302d349acf22)
* hadoop-common-project/hadoop-common/CHANGES.txt
* dev-support/test-patch.sh
","29/Apr/15 15:34;hudson;FAILURE: Integrated in Hadoop-Mapreduce-trunk #2128 (See [https://builds.apache.org/job/Hadoop-Mapreduce-trunk/2128/])
HADOOP-11881. test-patch.sh javac result is wildly wrong (Kengo Seki via aw) (aw: rev eccf709a619b05aaa92b27693a9c302d349acf22)
* dev-support/test-patch.sh
* hadoop-common-project/hadoop-common/CHANGES.txt
","11/May/15 19:25;hudson;FAILURE: Integrated in Hadoop-trunk-Commit #7797 (See [https://builds.apache.org/job/Hadoop-trunk-Commit/7797/])
re-commit of HADOOP-11881 (aw: rev cbea5d2db4c71a9662e544bf0b37ecf4dca1fadc)
* dev-support/test-patch.sh
","12/May/15 12:03;hudson;SUCCESS: Integrated in Hadoop-Yarn-trunk #925 (See [https://builds.apache.org/job/Hadoop-Yarn-trunk/925/])
re-commit of HADOOP-11881 (aw: rev cbea5d2db4c71a9662e544bf0b37ecf4dca1fadc)
* dev-support/test-patch.sh
","12/May/15 12:16;hudson;FAILURE: Integrated in Hadoop-Yarn-trunk-Java8 #194 (See [https://builds.apache.org/job/Hadoop-Yarn-trunk-Java8/194/])
re-commit of HADOOP-11881 (aw: rev cbea5d2db4c71a9662e544bf0b37ecf4dca1fadc)
* dev-support/test-patch.sh
","12/May/15 14:31;hudson;FAILURE: Integrated in Hadoop-Mapreduce-trunk #2141 (See [https://builds.apache.org/job/Hadoop-Mapreduce-trunk/2141/])
re-commit of HADOOP-11881 (aw: rev cbea5d2db4c71a9662e544bf0b37ecf4dca1fadc)
* dev-support/test-patch.sh
","12/May/15 14:41;hudson;FAILURE: Integrated in Hadoop-Hdfs-trunk #2123 (See [https://builds.apache.org/job/Hadoop-Hdfs-trunk/2123/])
re-commit of HADOOP-11881 (aw: rev cbea5d2db4c71a9662e544bf0b37ecf4dca1fadc)
* dev-support/test-patch.sh
","12/May/15 14:48;hudson;FAILURE: Integrated in Hadoop-Hdfs-trunk-Java8 #183 (See [https://builds.apache.org/job/Hadoop-Hdfs-trunk-Java8/183/])
re-commit of HADOOP-11881 (aw: rev cbea5d2db4c71a9662e544bf0b37ecf4dca1fadc)
* dev-support/test-patch.sh
","12/May/15 15:15;hudson;SUCCESS: Integrated in Hadoop-Mapreduce-trunk-Java8 #193 (See [https://builds.apache.org/job/Hadoop-Mapreduce-trunk-Java8/193/])
re-commit of HADOOP-11881 (aw: rev cbea5d2db4c71a9662e544bf0b37ecf4dca1fadc)
* dev-support/test-patch.sh
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
test-patch.sh should use 'file' command for patch determinism,HADOOP-11906,12826755,Test,Resolved,HADOOP,Hadoop Common,software,omalley,Hadoop Common is the common library for Apache Hadoop.,http://hadoop.apache.org/,Major,Fixed,busbey,aw,aw,02/May/15 21:07,30/Aug/16 01:28,12/Jan/21 11:55,08/May/15 22:14,,,,,2.8.0,3.0.0-alpha1,,,,,,,,,0,,,test-patch.sh currently restricts patches to the extension .patch.  It might be useful to also check if the file command says it is a diff.  This would allow us to determine if files that end in .txt are actually patches.,,aw,busbey,cmccabe,hudson,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"08/May/15 16:42;busbey;HADOOP-11906.1.patch;https://issues.apache.org/jira/secure/attachment/12731503/HADOOP-11906.1.patch","08/May/15 20:55;busbey;HADOOP-11906.2.patch;https://issues.apache.org/jira/secure/attachment/12731593/HADOOP-11906.2.patch",,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,2015-05-06 01:12:52.896,,,false,,,,,,,,,,,,,,,,,9223372036854775807,,,,,Sat May 09 15:30:35 UTC 2015,,,,,,,"0|i2e7tr:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,"04/May/15 01:53;aw;Some notes here.  If a file doesn't end in .patch, then we should assume the person is a new or confused contributor and give them some pointers for help:

* Part of HADOOP-11906 should probably be a -mild scolding- pointer to the naming standard for patches
* The branch detection rules should be disabled","04/May/15 17:11;aw;After doing a bit of playing, two things:

* file tends to output 'diff' on most platforms I've tested on
* git format-patch files show up as ascii text due to the header.

So we might need to use two checks, file and a grep for diff.  It's also worthwhile noting that it's possible to generate a patch that smart-apply-patch can take but will confuse the hell out of test-patch.sh.  For example:

using git diff: 
{code}
diff --git a/start-build-env.sh b/start-build-env.sh
old mode 100644
new mode 100755
{code}

start-build-env.sh is not in the changed files list so shellcheck does not get triggered.  ","04/May/15 17:13;aw;Filed HADOOP-11914 to cover the mode change patch.","06/May/15 01:12;cmccabe;GNU file (aka libmagic) had some security vulnerabilities.  A little googling turns up CVE-2014-2270 and CVE-2012-1571.  I'd be wary of running it on untrusted input.  Perhaps we could use something like the new BSD file implementation?  http://marc.info/?l=openbsd-cvs&m=142989267412968&w=2","06/May/15 01:16;busbey;We're already executing arbitrary changes to the maven pom, which can easily call arbitrary shell commands. I'd say vulnerabilities in the GNU file command are obviated by the security concerns inherent in what we're already doing.","06/May/15 02:07;aw;That.  Once I get test-patch.sh launching itself inside a Docker container, we can have a better a much more nuanced discussion around what security should be in place (esp since we'll able to control what binaries are actually being used).  But right now, it's kind of moot. ","06/May/15 15:04;busbey;Let's hope 'file' on jenkins does better than the on on OS X 10.8

{code}
$ file -version
file-5.04
magic file from /usr/share/file/magic
$ find ../patches/ -type f -exec file {} \; | cut -d: -f2 | sort | uniq -c | sort -n -r
 103  ASCII English text
  82  diff output text
  53  exported SGML document text
  50  ASCII C++ program text
  37  ASCII Java program text
  27  RCS/CVS diff output text
  23  HTML document text
  23  ASCII text
  10  ASCII English text, with very long lines
   7  UTF-8 Unicode English text
   3  ASCII C++ program text, with very long lines
   2  data
   2  PDF document, version 1.4
   2  ASCII Java program text, with very long lines
   1  UTF-8 Unicode English text, with very long lines
   1  Git bundle
   1  ASCII text, with very long lines
   1  ASCII C++ program text, with CRLF, CR, LF line terminators
{code}","06/May/15 15:11;busbey;For comparison, if I use the heuristic ""does the first line look like a patch?"" I get 417 out of 428:

{code}
$ find ../patches/ -type f -exec head -n 1 {} \; | grep -E ""^(From [a-z0-9]* Mon Sep 17 00:00:00 2001)|(diff .*)|(Index: .*)$"" | wc -l
     417
$ find ../patches/ -type f -exec head -n 1 {} \; | grep -v -E ""^(From [a-z0-9]* Mon Sep 17 00:00:00 2001)|(diff .*)|(Index: .*)$"" | wc -l
      11
{code}","08/May/15 16:42;busbey;-01
  * ""why not both?"" - use {{file}} and fall back to first-line parsing.
  * If we think it's a patch but it's named wrong, give a warning on the jira and point them at the HowToContribute guide","08/May/15 17:16;aw;Fantastic. I threw it at all the patches that the current version had issues with and it appears to do the correct thing. One nit: I don't think it's worth the effort to make head replaceable since it doesn't have very many variants that don't understand our syntax.","08/May/15 19:53;hadoopqa;(!) A patch to test-patch or smart-apply-patch has been detected. 
Re-executing against the patched versions to perform further tests. 
The console is at https://builds.apache.org/job/PreCommit-HADOOP-Build/6551/console in case of problems.","08/May/15 19:53;hadoopqa;\\
\\
| (/) *{color:green}+1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | reexec |   0m  0s | dev-support patch detected. |
| {color:blue}0{color} | pre-patch |   0m  0s | Pre-patch trunk compilation is healthy. |
| {color:blue}0{color} | @author |   0m  0s | Skipping @author checks as test-patch has been patched. |
| {color:green}+1{color} | release audit |   0m 15s | The applied patch does not increase the total number of release audit warnings. |
| {color:green}+1{color} | shellcheck |   0m  5s | There were no new shellcheck (v0.3.3) issues. |
| {color:green}+1{color} | whitespace |   0m  1s | The patch has no lines that end in whitespace. |
| | |   0m 24s | |
\\
\\
|| Subsystem || Report/Notes ||
| Patch URL | http://issues.apache.org/jira/secure/attachment/12731503/HADOOP-11906.1.patch |
| Optional Tests | shellcheck |
| git revision | trunk / 8f7c236 |
| Java | 1.7.0_55 |
| uname | Linux asf903.gq1.ygridcore.net 3.13.0-36-lowlatency #63-Ubuntu SMP PREEMPT Wed Sep 3 21:56:12 UTC 2014 x86_64 x86_64 x86_64 GNU/Linux |
| Console output | https://builds.apache.org/job/PreCommit-HADOOP-Build/6551/console |


This message was automatically generated.","08/May/15 20:55;busbey;-02

 * remove configurable 'head' command","08/May/15 21:45;cmccabe;That's a fair point.  We should talk more about how to sandbox this stuff.  Something like Xen and using a clean image each time would be the best... but maybe docker is the best we can get.","08/May/15 22:14;aw;+1 committed to trunk and that other branch.","08/May/15 22:23;hudson;FAILURE: Integrated in Hadoop-trunk-Commit #7779 (See [https://builds.apache.org/job/Hadoop-trunk-Commit/7779/])
HADOOP-11906. test-patch.sh should use file command for patch determinism (Sean Busbey via aw) (aw: rev effcc5cbb717fe31eb8d64e505f57bc2786399ff)
* hadoop-common-project/hadoop-common/CHANGES.txt
* dev-support/test-patch.sh
","09/May/15 11:57;hudson;SUCCESS: Integrated in Hadoop-Yarn-trunk-Java8 #191 (See [https://builds.apache.org/job/Hadoop-Yarn-trunk-Java8/191/])
HADOOP-11906. test-patch.sh should use file command for patch determinism (Sean Busbey via aw) (aw: rev effcc5cbb717fe31eb8d64e505f57bc2786399ff)
* hadoop-common-project/hadoop-common/CHANGES.txt
* dev-support/test-patch.sh
","09/May/15 12:01;hudson;SUCCESS: Integrated in Hadoop-Yarn-trunk #922 (See [https://builds.apache.org/job/Hadoop-Yarn-trunk/922/])
HADOOP-11906. test-patch.sh should use file command for patch determinism (Sean Busbey via aw) (aw: rev effcc5cbb717fe31eb8d64e505f57bc2786399ff)
* hadoop-common-project/hadoop-common/CHANGES.txt
* dev-support/test-patch.sh
","09/May/15 14:21;hudson;FAILURE: Integrated in Hadoop-Hdfs-trunk #2120 (See [https://builds.apache.org/job/Hadoop-Hdfs-trunk/2120/])
HADOOP-11906. test-patch.sh should use file command for patch determinism (Sean Busbey via aw) (aw: rev effcc5cbb717fe31eb8d64e505f57bc2786399ff)
* dev-support/test-patch.sh
* hadoop-common-project/hadoop-common/CHANGES.txt
","09/May/15 14:27;hudson;FAILURE: Integrated in Hadoop-Hdfs-trunk-Java8 #180 (See [https://builds.apache.org/job/Hadoop-Hdfs-trunk-Java8/180/])
HADOOP-11906. test-patch.sh should use file command for patch determinism (Sean Busbey via aw) (aw: rev effcc5cbb717fe31eb8d64e505f57bc2786399ff)
* dev-support/test-patch.sh
* hadoop-common-project/hadoop-common/CHANGES.txt
","09/May/15 15:16;hudson;SUCCESS: Integrated in Hadoop-Mapreduce-trunk-Java8 #190 (See [https://builds.apache.org/job/Hadoop-Mapreduce-trunk-Java8/190/])
HADOOP-11906. test-patch.sh should use file command for patch determinism (Sean Busbey via aw) (aw: rev effcc5cbb717fe31eb8d64e505f57bc2786399ff)
* dev-support/test-patch.sh
* hadoop-common-project/hadoop-common/CHANGES.txt
","09/May/15 15:30;hudson;SUCCESS: Integrated in Hadoop-Mapreduce-trunk #2138 (See [https://builds.apache.org/job/Hadoop-Mapreduce-trunk/2138/])
HADOOP-11906. test-patch.sh should use file command for patch determinism (Sean Busbey via aw) (aw: rev effcc5cbb717fe31eb8d64e505f57bc2786399ff)
* dev-support/test-patch.sh
* hadoop-common-project/hadoop-common/CHANGES.txt
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
test-patch in offline mode should tell maven to be in offline mode,HADOOP-11930,12827718,Test,Resolved,HADOOP,Hadoop Common,software,omalley,Hadoop Common is the common library for Apache Hadoop.,http://hadoop.apache.org/,Major,Fixed,busbey,busbey,busbey,06/May/15 16:44,30/Aug/16 01:28,12/Jan/21 11:55,28/May/15 19:28,,,,,2.8.0,3.0.0-alpha1,,,,,,,,,0,,,"when we use --offline for test-patch, we should also flag maven to be offline so that it doesn't attempt to talk to the internet.",,aw,busbey,hudson,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"06/May/15 16:59;busbey;HADOOP-11930.1.patch;https://issues.apache.org/jira/secure/attachment/12730877/HADOOP-11930.1.patch","28/May/15 19:02;busbey;HADOOP-11930.2.patch;https://issues.apache.org/jira/secure/attachment/12735942/HADOOP-11930.2.patch",,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,2015-05-06 17:01:00.691,,,false,,,,,,,,,,,,,,,,,9223372036854775807,,,,,Fri May 29 15:19:15 UTC 2015,,,,,,,"0|i2edef:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,"06/May/15 17:01;hadoopqa;(!) A patch to test-patch or smart-apply-patch has been detected. 
Re-executing against the patched versions to perform further tests. 
The console is at https://builds.apache.org/job/PreCommit-HADOOP-Build/6506/console in case of problems.","06/May/15 17:01;hadoopqa;\\
\\
| (/) *{color:green}+1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | reexec |   0m  0s | dev-support patch detected. |
| {color:blue}0{color} | pre-patch |   0m  0s | Pre-patch trunk compilation is healthy. |
| {color:blue}0{color} | @author |   0m  0s | Skipping @author checks as test-patch has been patched. |
| {color:green}+1{color} | release audit |   0m 15s | The applied patch does not increase the total number of release audit warnings. |
| {color:blue}0{color} | shellcheck |   0m 15s | Shellcheck was not available. |
| {color:green}+1{color} | whitespace |   0m  0s | The patch has no lines that end in whitespace. |
| | |   0m 27s | |
\\
\\
|| Subsystem || Report/Notes ||
| Patch URL | http://issues.apache.org/jira/secure/attachment/12730877/HADOOP-11930.1.patch |
| Optional Tests | shellcheck |
| git revision | trunk / a583a40 |
| Java | 1.7.0_55 |
| uname | Linux asf906.gq1.ygridcore.net 3.13.0-36-lowlatency #63-Ubuntu SMP PREEMPT Wed Sep 3 21:56:12 UTC 2014 x86_64 x86_64 x86_64 GNU/Linux |
| Console output | https://builds.apache.org/job/PreCommit-HADOOP-Build/6506/console |


This message was automatically generated.","11/May/15 19:38;aw;I need to play with this a bit, but a visual inspection makes me concerned that we're passing a null parameter to maven when --offline is not in use.","11/May/15 20:03;busbey;I suspect that's true, though I can confirm mvn is ignoring it if so.

Here's a bash-ism I wasn't sure about. When I have something like {noformat}""${MVN}"" ""${MAVEN_ARGS[@]}"" clean{noformat} and there's multiple elements in MAVEN_ARGS, do they expand to individual quote-wrapped parameters? Or do they turn into a single space separated list that's quoted?","28/May/15 18:19;aw;After a bit of playing, this is actually safe to do.  Now we just need the patch rebased. :)","28/May/15 18:49;busbey;cancel patch till rebase.","28/May/15 19:02;busbey;-02
  * rebased to current trunk","28/May/15 19:27;hudson;FAILURE: Integrated in Hadoop-trunk-Commit #7919 (See [https://builds.apache.org/job/Hadoop-trunk-Commit/7919/])
HADOOP-11930. test-patch in offline mode should tell maven to be in offline mode (Sean Busbey via aw) (aw: rev 7ebe80ec12a91602b4dcdafb4e3a75def6035ad6)
* hadoop-common-project/hadoop-common/CHANGES.txt
* dev-support/test-patch.sh
","28/May/15 19:28;aw;+1 committed.

thanks!","28/May/15 23:38;hudson;FAILURE: Integrated in Hadoop-Hdfs-trunk-Java8 #200 (See [https://builds.apache.org/job/Hadoop-Hdfs-trunk-Java8/200/])
HADOOP-11930. test-patch in offline mode should tell maven to be in offline mode (Sean Busbey via aw) (aw: rev 7ebe80ec12a91602b4dcdafb4e3a75def6035ad6)
* hadoop-common-project/hadoop-common/CHANGES.txt
* dev-support/test-patch.sh
","29/May/15 11:55;hudson;SUCCESS: Integrated in Hadoop-Yarn-trunk-Java8 #212 (See [https://builds.apache.org/job/Hadoop-Yarn-trunk-Java8/212/])
HADOOP-11930. test-patch in offline mode should tell maven to be in offline mode (Sean Busbey via aw) (aw: rev 7ebe80ec12a91602b4dcdafb4e3a75def6035ad6)
* hadoop-common-project/hadoop-common/CHANGES.txt
* dev-support/test-patch.sh
","29/May/15 11:59;hudson;SUCCESS: Integrated in Hadoop-Yarn-trunk #942 (See [https://builds.apache.org/job/Hadoop-Yarn-trunk/942/])
HADOOP-11930. test-patch in offline mode should tell maven to be in offline mode (Sean Busbey via aw) (aw: rev 7ebe80ec12a91602b4dcdafb4e3a75def6035ad6)
* hadoop-common-project/hadoop-common/CHANGES.txt
* dev-support/test-patch.sh
","29/May/15 13:03;hudson;FAILURE: Integrated in Hadoop-Hdfs-trunk #2140 (See [https://builds.apache.org/job/Hadoop-Hdfs-trunk/2140/])
HADOOP-11930. test-patch in offline mode should tell maven to be in offline mode (Sean Busbey via aw) (aw: rev 7ebe80ec12a91602b4dcdafb4e3a75def6035ad6)
* dev-support/test-patch.sh
* hadoop-common-project/hadoop-common/CHANGES.txt
","29/May/15 15:19;hudson;SUCCESS: Integrated in Hadoop-Mapreduce-trunk-Java8 #210 (See [https://builds.apache.org/job/Hadoop-Mapreduce-trunk-Java8/210/])
HADOOP-11930. test-patch in offline mode should tell maven to be in offline mode (Sean Busbey via aw) (aw: rev 7ebe80ec12a91602b4dcdafb4e3a75def6035ad6)
* hadoop-common-project/hadoop-common/CHANGES.txt
* dev-support/test-patch.sh
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Add user-provided plugins to test-patch,HADOOP-11949,12828606,Test,Resolved,HADOOP,Hadoop Common,software,omalley,Hadoop Common is the common library for Apache Hadoop.,http://hadoop.apache.org/,Major,Fixed,busbey,busbey,busbey,09/May/15 18:20,30/Aug/16 01:28,12/Jan/21 11:55,18/May/15 17:07,,,,,2.8.0,3.0.0-alpha1,,,,,,,,,0,,,"we have a default set of plugins located in dev-support/test-patch.d. On jenkins set up where we're installed as a peer directory to a component under test, it's much easier to add plugins for that component if we can give a command line arg for additional plugins.",,aw,busbey,Fan04290,hudson,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"09/May/15 19:38;busbey;HADOOP-11949.1.patch;https://issues.apache.org/jira/secure/attachment/12731741/HADOOP-11949.1.patch","16/May/15 07:17;busbey;HADOOP-11949.2.patch;https://issues.apache.org/jira/secure/attachment/12733309/HADOOP-11949.2.patch","18/May/15 02:49;busbey;HADOOP-11949.3.patch;https://issues.apache.org/jira/secure/attachment/12733430/HADOOP-11949.3.patch",,,,,,,,,,,,,,,,,,,,,3.0,,,,,,,,,,,,,,,,,,,,2015-05-09 19:40:20.515,,,false,,,,,,,,,,,,,,,,,9223372036854775807,,,,,Tue May 19 15:33:16 UTC 2015,,,,,,,"0|i2eisf:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,"09/May/15 19:40;hadoopqa;(!) A patch to test-patch or smart-apply-patch has been detected. 
Re-executing against the patched versions to perform further tests. 
The console is at https://builds.apache.org/job/PreCommit-HADOOP-Build/6571/console in case of problems.","09/May/15 19:40;hadoopqa;\\
\\
| (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | reexec |   0m  0s | dev-support patch detected. |
| {color:blue}0{color} | pre-patch |   0m  0s | Pre-patch trunk compilation is healthy. |
| {color:blue}0{color} | @author |   0m  0s | Skipping @author checks as test-patch has been patched. |
| {color:green}+1{color} | release audit |   0m 15s | The applied patch does not increase the total number of release audit warnings. |
| {color:green}+1{color} | shellcheck |   0m  6s | There were no new shellcheck (v0.3.3) issues. |
| {color:red}-1{color} | whitespace |   0m  0s | The patch has 1  line(s) that end in whitespace. Use git apply --whitespace=fix. |
| | |   0m 24s | |
\\
\\
|| Subsystem || Report/Notes ||
| Patch URL | http://issues.apache.org/jira/secure/attachment/12731741/HADOOP-11949.1.patch |
| Optional Tests | shellcheck |
| git revision | trunk / df36ad0 |
| whitespace | https://builds.apache.org/job/PreCommit-HADOOP-Build/6571/artifact/patchprocess/whitespace.txt |
| Java | 1.7.0_55 |
| uname | Linux asf906.gq1.ygridcore.net 3.13.0-36-lowlatency #63-Ubuntu SMP PREEMPT Wed Sep 3 21:56:12 UTC 2014 x86_64 x86_64 x86_64 GNU/Linux |
| Console output | https://builds.apache.org/job/PreCommit-HADOOP-Build/6571/console |


This message was automatically generated.","11/May/15 19:38;aw;OK, I see what you are doing in NIFI.  ","11/May/15 19:39;hadoopqa;\\
\\
| (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:red}-1{color} | patch |   0m  3s | The patch command could not apply the patch. |
\\
\\
|| Subsystem || Report/Notes ||
| Patch URL | http://issues.apache.org/jira/secure/attachment/12731741/HADOOP-11949.1.patch |
| Optional Tests | shellcheck |
| git revision | trunk / ea11590 |
| Console output | https://builds.apache.org/job/PreCommit-HADOOP-Build/6591/console |


This message was automatically generated.","11/May/15 21:05;aw;Need a rebase on this one too.","16/May/15 07:17;busbey;-02
  * rebased to current trunk.","16/May/15 07:20;hadoopqa;(!) A patch to test-patch or smart-apply-patch has been detected. 
Re-executing against the patched versions to perform further tests. 
The console is at https://builds.apache.org/job/PreCommit-HADOOP-Build/6711/console in case of problems.","16/May/15 07:20;hadoopqa;\\
\\
| (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | reexec |   0m  0s | dev-support patch detected. |
| {color:blue}0{color} | pre-patch |   0m  0s | Pre-patch trunk compilation is healthy. |
| {color:blue}0{color} | @author |   0m  0s | Skipping @author checks as test-patch has been patched. |
| {color:green}+1{color} | release audit |   0m 14s | The applied patch does not increase the total number of release audit warnings. |
| {color:red}-1{color} | shellcheck |   0m  7s | The applied patch generated  1 new shellcheck (v0.3.3) issues (total was 38, now 39). |
| {color:green}+1{color} | whitespace |   0m  0s | The patch has no lines that end in whitespace. |
| | |   0m 25s | |
\\
\\
|| Subsystem || Report/Notes ||
| Patch URL | http://issues.apache.org/jira/secure/attachment/12733309/HADOOP-11949.2.patch |
| Optional Tests | shellcheck |
| git revision | trunk / b0ad644 |
| shellcheck | https://builds.apache.org/job/PreCommit-HADOOP-Build/6711/artifact/patchprocess/diffpatchshellcheck.txt |
| Java | 1.7.0_55 |
| uname | Linux asf909.gq1.ygridcore.net 3.13.0-36-lowlatency #63-Ubuntu SMP PREEMPT Wed Sep 3 21:56:12 UTC 2014 x86_64 x86_64 x86_64 GNU/Linux |
| Console output | https://builds.apache.org/job/PreCommit-HADOOP-Build/6711/console |


This message was automatically generated.","18/May/15 02:49;busbey;-03

  * fixed shellcheck warning.","18/May/15 02:50;hadoopqa;(!) A patch to test-patch or smart-apply-patch has been detected. 
Re-executing against the patched versions to perform further tests. 
The console is at https://builds.apache.org/job/PreCommit-HADOOP-Build/6723/console in case of problems.","18/May/15 02:51;hadoopqa;\\
\\
| (/) *{color:green}+1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | reexec |   0m  0s | dev-support patch detected. |
| {color:blue}0{color} | pre-patch |   0m  0s | Pre-patch trunk compilation is healthy. |
| {color:blue}0{color} | @author |   0m  0s | Skipping @author checks as test-patch has been patched. |
| {color:green}+1{color} | release audit |   0m 15s | The applied patch does not increase the total number of release audit warnings. |
| {color:green}+1{color} | shellcheck |   0m  7s | There were no new shellcheck (v0.3.3) issues. |
| {color:green}+1{color} | whitespace |   0m  0s | The patch has no lines that end in whitespace. |
| | |   0m 26s | |
\\
\\
|| Subsystem || Report/Notes ||
| Patch URL | http://issues.apache.org/jira/secure/attachment/12733430/HADOOP-11949.3.patch |
| Optional Tests | shellcheck |
| git revision | trunk / cab0dad |
| Java | 1.7.0_55 |
| uname | Linux asf906.gq1.ygridcore.net 3.13.0-36-lowlatency #63-Ubuntu SMP PREEMPT Wed Sep 3 21:56:12 UTC 2014 x86_64 x86_64 x86_64 GNU/Linux |
| Console output | https://builds.apache.org/job/PreCommit-HADOOP-Build/6723/console |


This message was automatically generated.","18/May/15 17:07;aw;+1 committed

thanks!","18/May/15 17:12;hudson;FAILURE: Integrated in Hadoop-trunk-Commit #7854 (See [https://builds.apache.org/job/Hadoop-trunk-Commit/7854/])
HADOOP-11949. Add user-provided plugins to test-patch (Sean Busbey via aw) (aw: rev 060c84ea86257e3dea2f834aac7ae27b1456c434)
* dev-support/test-patch.sh
* hadoop-common-project/hadoop-common/CHANGES.txt
","19/May/15 11:39;hudson;FAILURE: Integrated in Hadoop-Yarn-trunk #932 (See [https://builds.apache.org/job/Hadoop-Yarn-trunk/932/])
HADOOP-11949. Add user-provided plugins to test-patch (Sean Busbey via aw) (aw: rev 060c84ea86257e3dea2f834aac7ae27b1456c434)
* hadoop-common-project/hadoop-common/CHANGES.txt
* dev-support/test-patch.sh
","19/May/15 11:54;hudson;SUCCESS: Integrated in Hadoop-Yarn-trunk-Java8 #201 (See [https://builds.apache.org/job/Hadoop-Yarn-trunk-Java8/201/])
HADOOP-11949. Add user-provided plugins to test-patch (Sean Busbey via aw) (aw: rev 060c84ea86257e3dea2f834aac7ae27b1456c434)
* hadoop-common-project/hadoop-common/CHANGES.txt
* dev-support/test-patch.sh
","19/May/15 14:22;hudson;FAILURE: Integrated in Hadoop-Hdfs-trunk #2130 (See [https://builds.apache.org/job/Hadoop-Hdfs-trunk/2130/])
HADOOP-11949. Add user-provided plugins to test-patch (Sean Busbey via aw) (aw: rev 060c84ea86257e3dea2f834aac7ae27b1456c434)
* hadoop-common-project/hadoop-common/CHANGES.txt
* dev-support/test-patch.sh
","19/May/15 14:29;hudson;FAILURE: Integrated in Hadoop-Hdfs-trunk-Java8 #190 (See [https://builds.apache.org/job/Hadoop-Hdfs-trunk-Java8/190/])
HADOOP-11949. Add user-provided plugins to test-patch (Sean Busbey via aw) (aw: rev 060c84ea86257e3dea2f834aac7ae27b1456c434)
* hadoop-common-project/hadoop-common/CHANGES.txt
* dev-support/test-patch.sh
","19/May/15 15:16;hudson;SUCCESS: Integrated in Hadoop-Mapreduce-trunk-Java8 #200 (See [https://builds.apache.org/job/Hadoop-Mapreduce-trunk-Java8/200/])
HADOOP-11949. Add user-provided plugins to test-patch (Sean Busbey via aw) (aw: rev 060c84ea86257e3dea2f834aac7ae27b1456c434)
* hadoop-common-project/hadoop-common/CHANGES.txt
* dev-support/test-patch.sh
","19/May/15 15:33;hudson;FAILURE: Integrated in Hadoop-Mapreduce-trunk #2148 (See [https://builds.apache.org/job/Hadoop-Mapreduce-trunk/2148/])
HADOOP-11949. Add user-provided plugins to test-patch (Sean Busbey via aw) (aw: rev 060c84ea86257e3dea2f834aac7ae27b1456c434)
* dev-support/test-patch.sh
* hadoop-common-project/hadoop-common/CHANGES.txt
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
cannot use --java-home in test-patch,HADOOP-12000,12831195,Test,Resolved,HADOOP,Hadoop Common,software,omalley,Hadoop Common is the common library for Apache Hadoop.,http://hadoop.apache.org/,Major,Fixed,aw,aw,aw,19/May/15 22:10,30/Aug/16 01:27,12/Jan/21 11:55,19/May/15 22:27,,,,,2.8.0,3.0.0-alpha1,,,,,scripts,,,,0,,,"Trivial bug, but breaks the docker patch:  --java-home=blah doesn't work because the case statement is broken.",,aw,cnauroth,hudson,raviprak,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"19/May/15 22:15;aw;HADOOP-12000.patch;https://issues.apache.org/jira/secure/attachment/12733967/HADOOP-12000.patch",,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,2015-05-19 22:16:53.179,,,false,,,,,,,,,,,,,,,,,9223372036854775807,Reviewed,,,,Wed May 20 16:21:55 UTC 2015,,,,,,,"0|i2eyhb:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,"19/May/15 22:16;raviprak;+1. Please feel free to commit.","19/May/15 22:17;cnauroth;+1 pending Jenkins.  Thanks, Allen.","19/May/15 22:22;hadoopqa;(!) A patch to test-patch or smart-apply-patch has been detected. 
Re-executing against the patched versions to perform further tests. 
The console is at https://builds.apache.org/job/PreCommit-HADOOP-Build/6749/console in case of problems.","19/May/15 22:23;hadoopqa;\\
\\
| (/) *{color:green}+1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | reexec |   0m  0s | dev-support patch detected. |
| {color:blue}0{color} | pre-patch |   0m  0s | Pre-patch trunk compilation is healthy. |
| {color:blue}0{color} | @author |   0m  0s | Skipping @author checks as test-patch has been patched. |
| {color:green}+1{color} | release audit |   0m 14s | The applied patch does not increase the total number of release audit warnings. |
| {color:green}+1{color} | shellcheck |   0m  7s | There were no new shellcheck (v0.3.3) issues. |
| {color:green}+1{color} | whitespace |   0m  0s | The patch has no lines that end in whitespace. |
| | |   0m 25s | |
\\
\\
|| Subsystem || Report/Notes ||
| Patch URL | http://issues.apache.org/jira/secure/attachment/12733967/HADOOP-12000.patch |
| Optional Tests | shellcheck |
| git revision | trunk / 7438966 |
| Java | 1.7.0_55 |
| uname | Linux asf909.gq1.ygridcore.net 3.13.0-36-lowlatency #63-Ubuntu SMP PREEMPT Wed Sep 3 21:56:12 UTC 2014 x86_64 x86_64 x86_64 GNU/Linux |
| Console output | https://builds.apache.org/job/PreCommit-HADOOP-Build/6749/console |


This message was automatically generated.","19/May/15 22:27;aw;Thanks.

Committed... now back to the docker patch... ","19/May/15 22:35;hudson;FAILURE: Integrated in Hadoop-trunk-Commit #7869 (See [https://builds.apache.org/job/Hadoop-trunk-Commit/7869/])
HADOOP-12000. cannot use --java-home in test-patch (aw) (aw: rev 12d6c5ce4f78bc0e9464522715920866abe1f727)
* hadoop-common-project/hadoop-common/CHANGES.txt
* dev-support/test-patch.sh
","20/May/15 11:53;hudson;FAILURE: Integrated in Hadoop-Yarn-trunk-Java8 #202 (See [https://builds.apache.org/job/Hadoop-Yarn-trunk-Java8/202/])
HADOOP-12000. cannot use --java-home in test-patch (aw) (aw: rev 12d6c5ce4f78bc0e9464522715920866abe1f727)
* hadoop-common-project/hadoop-common/CHANGES.txt
* dev-support/test-patch.sh
","20/May/15 11:58;hudson;SUCCESS: Integrated in Hadoop-Yarn-trunk #933 (See [https://builds.apache.org/job/Hadoop-Yarn-trunk/933/])
HADOOP-12000. cannot use --java-home in test-patch (aw) (aw: rev 12d6c5ce4f78bc0e9464522715920866abe1f727)
* dev-support/test-patch.sh
* hadoop-common-project/hadoop-common/CHANGES.txt
","20/May/15 14:31;hudson;FAILURE: Integrated in Hadoop-Hdfs-trunk #2131 (See [https://builds.apache.org/job/Hadoop-Hdfs-trunk/2131/])
HADOOP-12000. cannot use --java-home in test-patch (aw) (aw: rev 12d6c5ce4f78bc0e9464522715920866abe1f727)
* dev-support/test-patch.sh
* hadoop-common-project/hadoop-common/CHANGES.txt
","20/May/15 14:56;hudson;FAILURE: Integrated in Hadoop-Hdfs-trunk-Java8 #191 (See [https://builds.apache.org/job/Hadoop-Hdfs-trunk-Java8/191/])
HADOOP-12000. cannot use --java-home in test-patch (aw) (aw: rev 12d6c5ce4f78bc0e9464522715920866abe1f727)
* dev-support/test-patch.sh
* hadoop-common-project/hadoop-common/CHANGES.txt
","20/May/15 16:05;hudson;SUCCESS: Integrated in Hadoop-Mapreduce-trunk-Java8 #201 (See [https://builds.apache.org/job/Hadoop-Mapreduce-trunk-Java8/201/])
HADOOP-12000. cannot use --java-home in test-patch (aw) (aw: rev 12d6c5ce4f78bc0e9464522715920866abe1f727)
* dev-support/test-patch.sh
* hadoop-common-project/hadoop-common/CHANGES.txt
","20/May/15 16:21;hudson;SUCCESS: Integrated in Hadoop-Mapreduce-trunk #2149 (See [https://builds.apache.org/job/Hadoop-Mapreduce-trunk/2149/])
HADOOP-12000. cannot use --java-home in test-patch (aw) (aw: rev 12d6c5ce4f78bc0e9464522715920866abe1f727)
* dev-support/test-patch.sh
* hadoop-common-project/hadoop-common/CHANGES.txt
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
test-patch should only report on newly introduced findbugs warnings.,HADOOP-12030,12832473,Test,Resolved,HADOOP,Hadoop Common,software,omalley,Hadoop Common is the common library for Apache Hadoop.,http://hadoop.apache.org/,Major,Fixed,busbey,busbey,busbey,25/May/15 08:21,30/Aug/16 01:27,12/Jan/21 11:55,28/May/15 16:54,,,,,2.8.0,3.0.0-alpha1,,,,,,,,,0,test-patch,,findbugs is currently reporting the total number of findbugs warnings for touched modules rather than just newly introduced bugs.,,aw,busbey,hudson,varun_saxena,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,HBASE-13525,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"25/May/15 08:25;busbey;HADOOP-12030.1.patch;https://issues.apache.org/jira/secure/attachment/12735132/HADOOP-12030.1.patch","26/May/15 12:04;busbey;HADOOP-12030.2.patch;https://issues.apache.org/jira/secure/attachment/12735307/HADOOP-12030.2.patch",,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,2015-05-25 08:30:42.823,,,false,,,,,,,,,,,,,,,,,9223372036854775807,,,,,Fri May 29 15:19:20 UTC 2015,,,,,,,"0|i2f5q7:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,"25/May/15 08:25;busbey;-01
  * moves findbugs into a plugin
  * on preapply calculates findbugs report for changed modules
  * on postapply calculates the diff

one thing I'm not sure of is passing in FINDBUGS_HOME as a cli arg. there's no good way to move that into a plugin.","25/May/15 08:30;hadoopqa;(!) A patch to test-patch or smart-apply-patch has been detected. 
Re-executing against the patched versions to perform further tests. 
The console is at https://builds.apache.org/job/PreCommit-HADOOP-Build/6817/console in case of problems.","25/May/15 08:31;hadoopqa;\\
\\
| (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | reexec |   0m  0s | dev-support patch detected. |
| {color:blue}0{color} | pre-patch |   0m  0s | Pre-patch trunk compilation is healthy. |
| {color:blue}0{color} | @author |   0m  0s | Skipping @author checks as test-patch has been patched. |
| {color:green}+1{color} | release audit |   0m 24s | The applied patch does not increase the total number of release audit warnings. |
| {color:red}-1{color} | shellcheck |   0m  8s | The applied patch generated  3 new shellcheck (v0.3.3) issues (total was 38, now 40). |
| {color:green}+1{color} | whitespace |   0m  0s | The patch has no lines that end in whitespace. |
| | |   0m 35s | |
\\
\\
|| Subsystem || Report/Notes ||
| Patch URL | http://issues.apache.org/jira/secure/attachment/12735132/HADOOP-12030.1.patch |
| Optional Tests | shellcheck |
| git revision | trunk / ada233b |
| shellcheck | https://builds.apache.org/job/PreCommit-HADOOP-Build/6817/artifact/patchprocess/diffpatchshellcheck.txt |
| Java | 1.7.0_55 |
| uname | Linux asf903.gq1.ygridcore.net 3.13.0-36-lowlatency #63-Ubuntu SMP PREEMPT Wed Sep 3 21:56:12 UTC 2014 x86_64 x86_64 x86_64 GNU/Linux |
| Console output | https://builds.apache.org/job/PreCommit-HADOOP-Build/6817/console |


This message was automatically generated.","25/May/15 18:40;aw;I'm not sure this is a good idea.  We've definitely seen patches that pass findbugs only to come back in a subsequent test run blow up with errors.  Plus findbugs are one of those things that being constantly reminded to fix is a good thing.

Also:

bq. one thing I'm not sure of is passing in FINDBUGS_HOME as a cli arg. there's no good way to move that into a plugin.

This is why findbugs wasn't made a plugin earlier.  I always meant to go back and add some sort of plugin hook into parse_args but never did.","26/May/15 12:04;busbey;-02
  * moves findbugs back into test-patch proper
  * adds opt-in failure of pre-patch when extant warnings","26/May/15 12:09;busbey;I agree that it's important to stay on top of findbugs problems, but it's also important that we properly indicate things that are problems before the patch and problems with the patch. otherwise folks will think of our warnings as false positives and stop listening to us.

I'm also torn on failing pre-patch over findbugs. Nightlies are really the place to flag issues with the main code base, though I get the advantage of how much more visible precommit QA is. Also, projects that want to be strict about findbugs status could always tie things into their main build so that pre-patch javac would fail with findbugs warnings anyways (and they could even do this just in QA by using the project patch process profile).

Anyhwo, I checked this version against HBase with HBASE-13716 with and without the cli option and it behaved correctly in both cases, either just saying ""everything is fine"" or ""before this patch there are 60-ish findbugs things wrong""","26/May/15 12:10;hadoopqa;(!) A patch to test-patch or smart-apply-patch has been detected. 
Re-executing against the patched versions to perform further tests. 
The console is at https://builds.apache.org/job/PreCommit-HADOOP-Build/6825/console in case of problems.","26/May/15 12:11;hadoopqa;\\
\\
| (/) *{color:green}+1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | reexec |   0m  0s | dev-support patch detected. |
| {color:blue}0{color} | pre-patch |   0m  0s | Pre-patch trunk compilation is healthy. |
| {color:blue}0{color} | @author |   0m  0s | Skipping @author checks as test-patch has been patched. |
| {color:green}+1{color} | release audit |   0m 14s | The applied patch does not increase the total number of release audit warnings. |
| {color:green}+1{color} | shellcheck |   0m  9s | There were no new shellcheck (v0.3.3) issues. |
| {color:green}+1{color} | whitespace |   0m  0s | The patch has no lines that end in whitespace. |
| | |   0m 27s | |
\\
\\
|| Subsystem || Report/Notes ||
| Patch URL | http://issues.apache.org/jira/secure/attachment/12735307/HADOOP-12030.2.patch |
| Optional Tests | shellcheck |
| git revision | trunk / 9a3d617 |
| Java | 1.7.0_55 |
| uname | Linux asf901.gq1.ygridcore.net 3.13.0-36-lowlatency #63-Ubuntu SMP PREEMPT Wed Sep 3 21:56:12 UTC 2014 x86_64 x86_64 x86_64 GNU/Linux |
| Console output | https://builds.apache.org/job/PreCommit-HADOOP-Build/6825/console |


This message was automatically generated.","28/May/15 16:54;aw;+ 1 committed

thanks","28/May/15 17:31;hudson;FAILURE: Integrated in Hadoop-trunk-Commit #7916 (See [https://builds.apache.org/job/Hadoop-trunk-Commit/7916/])
HADOOP-12030. test-patch should only report on newly introduced findbugs warnings. (Sean Busbey via aw) (aw: rev b01d33cf862a34f9988584d3d1f3995118110b90)
* hadoop-common-project/hadoop-common/CHANGES.txt
* dev-support/test-patch.sh
","28/May/15 17:32;busbey;I updated the precommit H/H/Y/M builds to all include {{--findbugs-strict-precheck }}","28/May/15 23:38;hudson;FAILURE: Integrated in Hadoop-Hdfs-trunk-Java8 #200 (See [https://builds.apache.org/job/Hadoop-Hdfs-trunk-Java8/200/])
HADOOP-12030. test-patch should only report on newly introduced findbugs warnings. (Sean Busbey via aw) (aw: rev b01d33cf862a34f9988584d3d1f3995118110b90)
* hadoop-common-project/hadoop-common/CHANGES.txt
* dev-support/test-patch.sh
","29/May/15 11:55;hudson;SUCCESS: Integrated in Hadoop-Yarn-trunk-Java8 #212 (See [https://builds.apache.org/job/Hadoop-Yarn-trunk-Java8/212/])
HADOOP-12030. test-patch should only report on newly introduced findbugs warnings. (Sean Busbey via aw) (aw: rev b01d33cf862a34f9988584d3d1f3995118110b90)
* hadoop-common-project/hadoop-common/CHANGES.txt
* dev-support/test-patch.sh
","29/May/15 11:59;hudson;SUCCESS: Integrated in Hadoop-Yarn-trunk #942 (See [https://builds.apache.org/job/Hadoop-Yarn-trunk/942/])
HADOOP-12030. test-patch should only report on newly introduced findbugs warnings. (Sean Busbey via aw) (aw: rev b01d33cf862a34f9988584d3d1f3995118110b90)
* hadoop-common-project/hadoop-common/CHANGES.txt
* dev-support/test-patch.sh
","29/May/15 13:03;hudson;FAILURE: Integrated in Hadoop-Hdfs-trunk #2140 (See [https://builds.apache.org/job/Hadoop-Hdfs-trunk/2140/])
HADOOP-12030. test-patch should only report on newly introduced findbugs warnings. (Sean Busbey via aw) (aw: rev b01d33cf862a34f9988584d3d1f3995118110b90)
* dev-support/test-patch.sh
* hadoop-common-project/hadoop-common/CHANGES.txt
","29/May/15 15:19;hudson;SUCCESS: Integrated in Hadoop-Mapreduce-trunk-Java8 #210 (See [https://builds.apache.org/job/Hadoop-Mapreduce-trunk-Java8/210/])
HADOOP-12030. test-patch should only report on newly introduced findbugs warnings. (Sean Busbey via aw) (aw: rev b01d33cf862a34f9988584d3d1f3995118110b90)
* hadoop-common-project/hadoop-common/CHANGES.txt
* dev-support/test-patch.sh
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Add automatic search of default Configuration variables to TestConfigurationFieldsBase,HADOOP-12101,12838680,Test,Resolved,HADOOP,Hadoop Common,software,omalley,Hadoop Common is the common library for Apache Hadoop.,http://hadoop.apache.org/,Major,Fixed,rchiang,rchiang,rchiang,18/Jun/15 05:18,30/Aug/16 01:26,12/Jan/21 11:55,05/May/16 03:26,2.7.0,,,,2.8.0,3.0.0-alpha1,,,,,test,,,,0,supportability,,"Add functionality given a Configuration variable FOO, to at least check the xml file value against DEFAULT_FOO.

Without waivers and a mapping for exceptions, this can probably never be a test method that generates actual errors.",,Fan04290,hudson,iwasakims,ozawa,rkanter,weichiu,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,HADOOP-12738,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"18/Jun/15 05:21;rchiang;HADOOP-12101.001.patch;https://issues.apache.org/jira/secure/attachment/12740302/HADOOP-12101.001.patch","22/Jun/15 18:59;rchiang;HADOOP-12101.002.patch;https://issues.apache.org/jira/secure/attachment/12741095/HADOOP-12101.002.patch","28/Sep/15 20:59;rchiang;HADOOP-12101.003.patch;https://issues.apache.org/jira/secure/attachment/12764098/HADOOP-12101.003.patch","15/Oct/15 19:14;rchiang;HADOOP-12101.004.patch;https://issues.apache.org/jira/secure/attachment/12766856/HADOOP-12101.004.patch","22/Oct/15 23:10;rchiang;HADOOP-12101.005.patch;https://issues.apache.org/jira/secure/attachment/12768166/HADOOP-12101.005.patch","23/Oct/15 21:22;rchiang;HADOOP-12101.006.patch;https://issues.apache.org/jira/secure/attachment/12768415/HADOOP-12101.006.patch","07/Jan/16 23:44;rchiang;HADOOP-12101.007.patch;https://issues.apache.org/jira/secure/attachment/12781100/HADOOP-12101.007.patch","29/Feb/16 19:25;rchiang;HADOOP-12101.008.patch;https://issues.apache.org/jira/secure/attachment/12790537/HADOOP-12101.008.patch","04/Mar/16 07:43;rchiang;HADOOP-12101.009.patch;https://issues.apache.org/jira/secure/attachment/12791423/HADOOP-12101.009.patch","25/Apr/16 18:40;rchiang;HADOOP-12101.010.patch;https://issues.apache.org/jira/secure/attachment/12800592/HADOOP-12101.010.patch","25/Apr/16 19:08;rchiang;HADOOP-12101.011.patch;https://issues.apache.org/jira/secure/attachment/12800606/HADOOP-12101.011.patch","27/Apr/16 23:18;rchiang;HADOOP-12101.012.patch;https://issues.apache.org/jira/secure/attachment/12801145/HADOOP-12101.012.patch","02/May/16 17:16;rchiang;HADOOP-12101.013.patch;https://issues.apache.org/jira/secure/attachment/12801779/HADOOP-12101.013.patch","02/May/16 18:51;rchiang;HADOOP-12101.014.patch;https://issues.apache.org/jira/secure/attachment/12801793/HADOOP-12101.014.patch","02/May/16 23:25;rchiang;HADOOP-12101.015.patch;https://issues.apache.org/jira/secure/attachment/12801854/HADOOP-12101.015.patch","03/May/16 15:42;rchiang;HADOOP-12101.016.patch;https://issues.apache.org/jira/secure/attachment/12801968/HADOOP-12101.016.patch",,,,,,,,16.0,,,,,,,,,,,,,,,,,,,,2015-06-18 05:47:28.386,,,false,,,,,,,,,,,,,,,,,9223372036854775807,Reviewed,,,,Thu May 05 06:21:25 UTC 2016,,,,,,,"0|i2g6uf:",9223372036854775807,,,,,,,,,,,,,2.8.0,,,,,,,,,,"18/Jun/15 05:47;ozawa;[~rchiang] Thank you for taking this issue. It looks very useful tool. +1 on the idea. It's very useful to add this as a test. I think it's also useful to add a shell script to dev-support directory to launch the check. Thoughts?","18/Jun/15 05:59;rchiang;Thanks!

I did talk to [~aw] about running it as a separate test category and it seemed like test-patch should figure out when to run it automatically.  I haven't done any work yet to verify that .xml changes or Configuration changes would trigger the various Test*Config* unit tests.

I can certainly add a basic shell script for running the 3 existing tests.  I might need some help with doing anything fancier since I'm not super familiar with any of the build/test scripts.","18/Jun/15 10:54;hadoopqa;\\
\\
| (/) *{color:green}+1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | pre-patch |   7m  5s | Pre-patch trunk compilation is healthy. |
| {color:green}+1{color} | @author |   0m  0s | The patch does not contain any @author tags. |
| {color:green}+1{color} | tests included |   0m  0s | The patch appears to include 1 new or modified test files. |
| {color:green}+1{color} | javac |   7m 49s | There were no new javac warning messages. |
| {color:green}+1{color} | release audit |   0m 19s | The applied patch does not increase the total number of release audit warnings. |
| {color:green}+1{color} | checkstyle |   1m  6s | There were no new checkstyle issues. |
| {color:green}+1{color} | whitespace |   0m  1s | The patch has no lines that end in whitespace. |
| {color:green}+1{color} | install |   1m 36s | mvn install still works. |
| {color:green}+1{color} | eclipse:eclipse |   0m 32s | The patch built with eclipse:eclipse. |
| {color:green}+1{color} | findbugs |   1m 49s | The patch does not introduce any new Findbugs (version 3.0.0) warnings. |
| {color:green}+1{color} | common tests |  22m 10s | Tests passed in hadoop-common. |
| | |  42m 30s | |
\\
\\
|| Subsystem || Report/Notes ||
| Patch URL | http://issues.apache.org/jira/secure/attachment/12740302/HADOOP-12101.001.patch |
| Optional Tests | javac unit findbugs checkstyle |
| git revision | trunk / 295d678 |
| hadoop-common test log | https://builds.apache.org/job/PreCommit-HADOOP-Build/6987/artifact/patchprocess/testrun_hadoop-common.txt |
| Test Results | https://builds.apache.org/job/PreCommit-HADOOP-Build/6987/testReport/ |
| Java | 1.7.0_55 |
| uname | Linux asf904.gq1.ygridcore.net 3.13.0-36-lowlatency #63-Ubuntu SMP PREEMPT Wed Sep 3 21:56:12 UTC 2014 x86_64 x86_64 x86_64 GNU/Linux |
| Console output | https://builds.apache.org/job/PreCommit-HADOOP-Build/6987/console |


This message was automatically generated.","22/Jun/15 18:59;rchiang;- Fix some places where the xml filename was hardcoded
- Add test script called verify-xml.sh","22/Jun/15 19:42;hadoopqa;\\
\\
| (/) *{color:green}+1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | pre-patch |   6m 50s | Pre-patch trunk compilation is healthy. |
| {color:green}+1{color} | @author |   0m  0s | The patch does not contain any @author tags. |
| {color:green}+1{color} | tests included |   0m  0s | The patch appears to include 1 new or modified test files. |
| {color:green}+1{color} | javac |   7m 29s | There were no new javac warning messages. |
| {color:green}+1{color} | release audit |   0m 20s | The applied patch does not increase the total number of release audit warnings. |
| {color:green}+1{color} | checkstyle |   1m  4s | There were no new checkstyle issues. |
| {color:green}+1{color} | shellcheck |   0m  5s | There were no new shellcheck (v0.3.3) issues. |
| {color:green}+1{color} | whitespace |   0m  1s | The patch has no lines that end in whitespace. |
| {color:green}+1{color} | install |   1m 33s | mvn install still works. |
| {color:green}+1{color} | eclipse:eclipse |   0m 31s | The patch built with eclipse:eclipse. |
| {color:green}+1{color} | findbugs |   1m 50s | The patch does not introduce any new Findbugs (version 3.0.0) warnings. |
| {color:green}+1{color} | common tests |  21m 50s | Tests passed in hadoop-common. |
| | |  41m 36s | |
\\
\\
|| Subsystem || Report/Notes ||
| Patch URL | http://issues.apache.org/jira/secure/attachment/12741095/HADOOP-12101.002.patch |
| Optional Tests | shellcheck javac unit findbugs checkstyle |
| git revision | trunk / 445b132 |
| hadoop-common test log | https://builds.apache.org/job/PreCommit-HADOOP-Build/7015/artifact/patchprocess/testrun_hadoop-common.txt |
| Test Results | https://builds.apache.org/job/PreCommit-HADOOP-Build/7015/testReport/ |
| Java | 1.7.0_55 |
| uname | Linux asf906.gq1.ygridcore.net 3.13.0-36-lowlatency #63-Ubuntu SMP PREEMPT Wed Sep 3 21:56:12 UTC 2014 x86_64 x86_64 x86_64 GNU/Linux |
| Console output | https://builds.apache.org/job/PreCommit-HADOOP-Build/7015/console |


This message was automatically generated.","26/Sep/15 00:01;rchiang;Any comments?  I'd love to get this in instead of patching all my other trees for my own debugging.","26/Sep/15 02:15;hadoopqa;\\
\\
| (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | pre-patch |   7m 26s | Pre-patch trunk compilation is healthy. |
| {color:green}+1{color} | @author |   0m  0s | The patch does not contain any @author tags. |
| {color:green}+1{color} | tests included |   0m  0s | The patch appears to include 1 new or modified test files. |
| {color:green}+1{color} | javac |   8m  0s | There were no new javac warning messages. |
| {color:green}+1{color} | release audit |   0m 22s | The applied patch does not increase the total number of release audit warnings. |
| {color:green}+1{color} | checkstyle |   1m  8s | There were no new checkstyle issues. |
| {color:red}-1{color} | shellcheck |   0m  5s | The applied patch generated  14 new shellcheck (v0.3.3) issues (total was 20, now 34). |
| {color:green}+1{color} | whitespace |   0m  1s | The patch has no lines that end in whitespace. |
| {color:green}+1{color} | install |   1m 27s | mvn install still works. |
| {color:green}+1{color} | eclipse:eclipse |   0m 33s | The patch built with eclipse:eclipse. |
| {color:green}+1{color} | findbugs |   1m 54s | The patch does not introduce any new Findbugs (version 3.0.0) warnings. |
| {color:green}+1{color} | common tests |  23m  4s | Tests passed in hadoop-common. |
| | |  44m  4s | |
\\
\\
|| Subsystem || Report/Notes ||
| Patch URL | http://issues.apache.org/jira/secure/attachment/12741095/HADOOP-12101.002.patch |
| Optional Tests | shellcheck javac unit findbugs checkstyle |
| git revision | trunk / 67b0e96 |
| shellcheck | https://builds.apache.org/job/PreCommit-HADOOP-Build/7708/artifact/patchprocess/diffpatchshellcheck.txt |
| hadoop-common test log | https://builds.apache.org/job/PreCommit-HADOOP-Build/7708/artifact/patchprocess/testrun_hadoop-common.txt |
| Test Results | https://builds.apache.org/job/PreCommit-HADOOP-Build/7708/testReport/ |
| Java | 1.7.0_55 |
| uname | Linux asf902.gq1.ygridcore.net 3.13.0-36-lowlatency #63-Ubuntu SMP PREEMPT Wed Sep 3 21:56:12 UTC 2014 x86_64 x86_64 x86_64 GNU/Linux |
| Console output | https://builds.apache.org/job/PreCommit-HADOOP-Build/7708/console |


This message was automatically generated.","28/Sep/15 20:59;rchiang;- Minor shellcheck cleanup","28/Sep/15 22:26;hadoopqa;\\
\\
| (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:red}-1{color} | pre-patch |   7m 26s | Pre-patch trunk has 1 extant Findbugs (version 3.0.0) warnings. |
| {color:green}+1{color} | @author |   0m  0s | The patch does not contain any @author tags. |
| {color:green}+1{color} | tests included |   0m  0s | The patch appears to include 1 new or modified test files. |
| {color:green}+1{color} | javac |   8m  0s | There were no new javac warning messages. |
| {color:green}+1{color} | release audit |   0m 22s | The applied patch does not increase the total number of release audit warnings. |
| {color:green}+1{color} | checkstyle |   1m  8s | There were no new checkstyle issues. |
| {color:green}+1{color} | whitespace |   0m  0s | The patch has no lines that end in whitespace. |
| {color:green}+1{color} | install |   1m 30s | mvn install still works. |
| {color:green}+1{color} | eclipse:eclipse |   0m 33s | The patch built with eclipse:eclipse. |
| {color:green}+1{color} | findbugs |   1m 51s | The patch does not introduce any new Findbugs (version 3.0.0) warnings. |
| {color:red}-1{color} | common tests |   7m 22s | Tests failed in hadoop-common. |
| | |  28m 17s | |
\\
\\
|| Reason || Tests ||
| Failed unit tests | hadoop.ipc.TestRPCWaitForProxy |
\\
\\
|| Subsystem || Report/Notes ||
| Patch URL | http://issues.apache.org/jira/secure/attachment/12764098/HADOOP-12101.003.patch |
| Optional Tests | javac unit findbugs checkstyle |
| git revision | trunk / e5992ef |
| Pre-patch Findbugs warnings | https://builds.apache.org/job/PreCommit-HADOOP-Build/7720/artifact/patchprocess/trunkFindbugsWarningshadoop-common.html |
| hadoop-common test log | https://builds.apache.org/job/PreCommit-HADOOP-Build/7720/artifact/patchprocess/testrun_hadoop-common.txt |
| Test Results | https://builds.apache.org/job/PreCommit-HADOOP-Build/7720/testReport/ |
| Java | 1.7.0_55 |
| uname | Linux asf909.gq1.ygridcore.net 3.13.0-36-lowlatency #63-Ubuntu SMP PREEMPT Wed Sep 3 21:56:12 UTC 2014 x86_64 x86_64 x86_64 GNU/Linux |
| Console output | https://builds.apache.org/job/PreCommit-HADOOP-Build/7720/console |


This message was automatically generated.","29/Sep/15 18:59;rchiang;RE: Pre-patch findbugs

Not in related code

RE: Failed unit test

Unrelated test and test doesn't fail in my tree


","09/Oct/15 21:41;rchiang;[~ajisakaa] [~ozawa], any other comments?","15/Oct/15 19:14;rchiang;Add back missing script.","15/Oct/15 20:42;hadoopqa;\\
\\
| (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | pre-patch |   9m 43s | Pre-patch trunk compilation is healthy. |
| {color:green}+1{color} | @author |   0m  0s | The patch does not contain any @author tags. |
| {color:green}+1{color} | tests included |   0m  0s | The patch appears to include 1 new or modified test files. |
| {color:green}+1{color} | javac |  10m 30s | There were no new javac warning messages. |
| {color:green}+1{color} | release audit |   0m 25s | The applied patch does not increase the total number of release audit warnings. |
| {color:green}+1{color} | checkstyle |   1m 30s | There were no new checkstyle issues. |
| {color:red}-1{color} | shellcheck |   0m  8s | The applied patch generated  118 new shellcheck (v0.3.3) issues (total was 20, now 138). |
| {color:green}+1{color} | whitespace |   0m  1s | The patch has no lines that end in whitespace. |
| {color:green}+1{color} | install |   1m 51s | mvn install still works. |
| {color:green}+1{color} | eclipse:eclipse |   0m 40s | The patch built with eclipse:eclipse. |
| {color:green}+1{color} | findbugs |   2m 21s | The patch does not introduce any new Findbugs (version 3.0.0) warnings. |
| {color:red}-1{color} | common tests |  15m 51s | Tests failed in hadoop-common. |
| | |  43m  4s | |
\\
\\
|| Reason || Tests ||
| Failed unit tests | hadoop.ipc.TestDecayRpcScheduler |
|   | hadoop.ha.TestZKFailoverController |
\\
\\
|| Subsystem || Report/Notes ||
| Patch URL | http://issues.apache.org/jira/secure/attachment/12766856/HADOOP-12101.004.patch |
| Optional Tests | shellcheck javac unit findbugs checkstyle |
| git revision | trunk / 8d2d3eb |
| shellcheck | https://builds.apache.org/job/PreCommit-HADOOP-Build/7826/artifact/patchprocess/diffpatchshellcheck.txt |
| hadoop-common test log | https://builds.apache.org/job/PreCommit-HADOOP-Build/7826/artifact/patchprocess/testrun_hadoop-common.txt |
| Test Results | https://builds.apache.org/job/PreCommit-HADOOP-Build/7826/testReport/ |
| Java | 1.7.0_55 |
| uname | Linux asf907.gq1.ygridcore.net 3.13.0-36-lowlatency #63-Ubuntu SMP PREEMPT Wed Sep 3 21:56:12 UTC 2014 x86_64 x86_64 x86_64 GNU/Linux |
| Console output | https://builds.apache.org/job/PreCommit-HADOOP-Build/7826/console |


This message was automatically generated.","15/Oct/15 21:26;rkanter;Overall looks good.  A few minor comments:
- In the usage output, {{mode}} should be {{<mode>}}
- If you do the {{all}} mode, it prints out the location of the output file after each maven run, so earlier runs get buried (or lost depending on scroll back).  We should print them all out at the end when doing {{all}}.  
- We could save some time and lots of output when running all by having it use the same maven invocation for all of them.  In other words, {{mvn test -Dtest=TestHdfsConfigFields,TestMapreduceConfigFields,TestYarnConfigurationFields}} instead of three separate {{mvn test}} runs.  
- When running the {{yarn}} mode, it doesn't print out the location of the output file, though I don't see why.","22/Oct/15 22:54;rchiang;For the last item, it looks like YARN-3958 moved the test from hadoop-yarn-common to hadoop-yarn-api.","22/Oct/15 23:10;rchiang;- Update script based on feedback","23/Oct/15 00:42;hadoopqa;| (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue} 0m 9s {color} | {color:blue} docker + precommit patch detected. {color} |
| {color:green}+1{color} | {color:green} @author {color} | {color:green} 0m 0s {color} | {color:green} The patch does not contain any @author tags. {color} |
| {color:green}+1{color} | {color:green} test4tests {color} | {color:green} 0m 0s {color} | {color:green} The patch appears to include 1 new or modified test files. {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 3m 11s {color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 4m 34s {color} | {color:green} trunk passed with JDK v1.8.0_60 {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 4m 12s {color} | {color:green} trunk passed with JDK v1.7.0_79 {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green} 0m 16s {color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green} 0m 16s {color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green} 1m 37s {color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 0m 57s {color} | {color:green} trunk passed with JDK v1.8.0_60 {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 1m 5s {color} | {color:green} trunk passed with JDK v1.7.0_79 {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 1m 26s {color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 4m 21s {color} | {color:green} the patch passed with JDK v1.8.0_60 {color} |
| {color:green}+1{color} | {color:green} javac {color} | {color:green} 4m 21s {color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 4m 8s {color} | {color:green} the patch passed with JDK v1.7.0_79 {color} |
| {color:green}+1{color} | {color:green} javac {color} | {color:green} 4m 8s {color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green} 0m 15s {color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green} 0m 14s {color} | {color:green} the patch passed {color} |
| {color:red}-1{color} | {color:red} shellcheck {color} | {color:red} 0m 9s {color} | {color:red} The applied patch generated 1 new shellcheck issues (total was 97, now 98). {color} |
| {color:green}+1{color} | {color:green} whitespace {color} | {color:green} 0m 0s {color} | {color:green} Patch has no whitespace issues. {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green} 1m 54s {color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 0m 58s {color} | {color:green} the patch passed with JDK v1.8.0_60 {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 1m 6s {color} | {color:green} the patch passed with JDK v1.7.0_79 {color} |
| {color:red}-1{color} | {color:red} unit {color} | {color:red} 8m 6s {color} | {color:red} hadoop-common in the patch failed with JDK v1.8.0_60. {color} |
| {color:red}-1{color} | {color:red} unit {color} | {color:red} 8m 7s {color} | {color:red} hadoop-common in the patch failed with JDK v1.7.0_79. {color} |
| {color:green}+1{color} | {color:green} asflicense {color} | {color:green} 0m 24s {color} | {color:green} Patch does not generate ASF License warnings. {color} |
| {color:black}{color} | {color:black} {color} | {color:black} 48m 31s {color} | {color:black} {color} |
\\
\\
|| Reason || Tests ||
| JDK v1.7.0_79 Failed junit tests | hadoop.metrics2.impl.TestGangliaMetrics |
|   | hadoop.fs.shell.TestCopyPreserveFlag |
\\
\\
|| Subsystem || Report/Notes ||
| Docker | Client=1.7.1 Server=1.7.1 Image:test-patch-base-hadoop-date2015-10-22 |
| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12768166/HADOOP-12101.005.patch |
| JIRA Issue | HADOOP-12101 |
| Optional Tests |  asflicense  unit  shellcheck  javac  javadoc  mvninstall  findbugs  checkstyle  compile  |
| uname | Linux 4d2b1d0050e2 3.13.0-36-lowlatency #63-Ubuntu SMP PREEMPT Wed Sep 3 21:56:12 UTC 2014 x86_64 x86_64 x86_64 GNU/Linux |
| Build tool | maven |
| Personality | /home/jenkins/jenkins-slave/workspace/PreCommit-HADOOP-Build/patchprocess/apache-yetus-28a3a3d/dev-support/personality/hadoop.sh |
| git revision | trunk / 124a412 |
| Default Java | 1.7.0_79 |
| Multi-JDK versions |  /usr/lib/jvm/java-8-oracle:1.8.0_60 /usr/lib/jvm/java-7-openjdk-amd64:1.7.0_79 |
| findbugs | v3.0.0 |
| shellcheck | v0.4.1 |
| shellcheck | https://builds.apache.org/job/PreCommit-HADOOP-Build/7916/artifact/patchprocess/diff-patch-shellcheck.txt |
| unit | https://builds.apache.org/job/PreCommit-HADOOP-Build/7916/artifact/patchprocess/patch-unit-hadoop-common-project_hadoop-common-jdk1.8.0_60.txt |
| unit | https://builds.apache.org/job/PreCommit-HADOOP-Build/7916/artifact/patchprocess/patch-unit-hadoop-common-project_hadoop-common-jdk1.7.0_79.txt |
| unit test logs |  https://builds.apache.org/job/PreCommit-HADOOP-Build/7916/artifact/patchprocess/patch-unit-hadoop-common-project_hadoop-common-jdk1.8.0_60.txt https://builds.apache.org/job/PreCommit-HADOOP-Build/7916/artifact/patchprocess/patch-unit-hadoop-common-project_hadoop-common-jdk1.7.0_79.txt |
| JDK v1.7.0_79  Test Results | https://builds.apache.org/job/PreCommit-HADOOP-Build/7916/testReport/ |
| Max memory used | 225MB |
| Powered by | Apache Yetus   http://yetus.apache.org |
| Console output | https://builds.apache.org/job/PreCommit-HADOOP-Build/7916/console |


This message was automatically generated.

","23/Oct/15 21:22;rchiang;Fix shellcheck issue","24/Oct/15 00:33;hadoopqa;| (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue} 0m 12s {color} | {color:blue} docker + precommit patch detected. {color} |
| {color:green}+1{color} | {color:green} @author {color} | {color:green} 0m 0s {color} | {color:green} The patch does not contain any @author tags. {color} |
| {color:green}+1{color} | {color:green} test4tests {color} | {color:green} 0m 0s {color} | {color:green} The patch appears to include 1 new or modified test files. {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 8m 58s {color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 4m 27s {color} | {color:green} trunk passed with JDK v1.8.0_60 {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 4m 15s {color} | {color:green} trunk passed with JDK v1.7.0_79 {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green} 0m 18s {color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green} 0m 17s {color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green} 1m 49s {color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 0m 55s {color} | {color:green} trunk passed with JDK v1.8.0_60 {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 1m 5s {color} | {color:green} trunk passed with JDK v1.7.0_79 {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 1m 35s {color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 4m 23s {color} | {color:green} the patch passed with JDK v1.8.0_60 {color} |
| {color:green}+1{color} | {color:green} javac {color} | {color:green} 4m 23s {color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 4m 11s {color} | {color:green} the patch passed with JDK v1.7.0_79 {color} |
| {color:green}+1{color} | {color:green} javac {color} | {color:green} 4m 11s {color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green} 0m 16s {color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green} 0m 13s {color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} shellcheck {color} | {color:green} 0m 8s {color} | {color:green} There were no new shellcheck issues. {color} |
| {color:green}+1{color} | {color:green} whitespace {color} | {color:green} 0m 0s {color} | {color:green} Patch has no whitespace issues. {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green} 1m 47s {color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 0m 51s {color} | {color:green} the patch passed with JDK v1.8.0_60 {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 1m 3s {color} | {color:green} the patch passed with JDK v1.7.0_79 {color} |
| {color:red}-1{color} | {color:red} unit {color} | {color:red} 8m 9s {color} | {color:red} hadoop-common in the patch failed with JDK v1.8.0_60. {color} |
| {color:red}-1{color} | {color:red} unit {color} | {color:red} 8m 33s {color} | {color:red} hadoop-common in the patch failed with JDK v1.7.0_79. {color} |
| {color:green}+1{color} | {color:green} asflicense {color} | {color:green} 0m 23s {color} | {color:green} Patch does not generate ASF License warnings. {color} |
| {color:black}{color} | {color:black} {color} | {color:black} 54m 49s {color} | {color:black} {color} |
\\
\\
|| Reason || Tests ||
| JDK v1.7.0_79 Failed junit tests | hadoop.metrics2.impl.TestGangliaMetrics |
|   | hadoop.metrics2.impl.TestGangliaMetrics |
|   | hadoop.fs.TestSymlinkLocalFSFileSystem |
|   | hadoop.fs.TestSymlinkLocalFSFileContext |
\\
\\
|| Subsystem || Report/Notes ||
| Docker | Client=1.7.1 Server=1.7.1 Image:test-patch-base-hadoop-date2015-10-23 |
| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12768415/HADOOP-12101.006.patch |
| JIRA Issue | HADOOP-12101 |
| Optional Tests |  asflicense  unit  shellcheck  javac  javadoc  mvninstall  findbugs  checkstyle  compile  |
| uname | Linux e331dbc2d731 3.13.0-36-lowlatency #63-Ubuntu SMP PREEMPT Wed Sep 3 21:56:12 UTC 2014 x86_64 x86_64 x86_64 GNU/Linux |
| Build tool | maven |
| Personality | /home/jenkins/jenkins-slave/workspace/PreCommit-HADOOP-Build/patchprocess/apache-yetus-28a3a3d/dev-support/personality/hadoop.sh |
| git revision | trunk / 15eb84b |
| Default Java | 1.7.0_79 |
| Multi-JDK versions |  /usr/lib/jvm/java-8-oracle:1.8.0_60 /usr/lib/jvm/java-7-openjdk-amd64:1.7.0_79 |
| findbugs | v3.0.0 |
| shellcheck | v0.4.1 |
| unit | https://builds.apache.org/job/PreCommit-HADOOP-Build/7922/artifact/patchprocess/patch-unit-hadoop-common-project_hadoop-common-jdk1.8.0_60.txt |
| unit | https://builds.apache.org/job/PreCommit-HADOOP-Build/7922/artifact/patchprocess/patch-unit-hadoop-common-project_hadoop-common-jdk1.7.0_79.txt |
| unit test logs |  https://builds.apache.org/job/PreCommit-HADOOP-Build/7922/artifact/patchprocess/patch-unit-hadoop-common-project_hadoop-common-jdk1.8.0_60.txt https://builds.apache.org/job/PreCommit-HADOOP-Build/7922/artifact/patchprocess/patch-unit-hadoop-common-project_hadoop-common-jdk1.7.0_79.txt |
| JDK v1.7.0_79  Test Results | https://builds.apache.org/job/PreCommit-HADOOP-Build/7922/testReport/ |
| Max memory used | 229MB |
| Powered by | Apache Yetus   http://yetus.apache.org |
| Console output | https://builds.apache.org/job/PreCommit-HADOOP-Build/7922/console |


This message was automatically generated.

","26/Oct/15 17:34;rchiang;RE: failing unit tests

Unrelated unit tests.  All tests pass in my tree.","07/Jan/16 23:44;rchiang;- Add short values to catch a few more matchups","08/Jan/16 01:44;hadoopqa;| (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue} 0m 0s {color} | {color:blue} Docker mode activated. {color} |
| {color:green}+1{color} | {color:green} @author {color} | {color:green} 0m 0s {color} | {color:green} The patch does not contain any @author tags. {color} |
| {color:green}+1{color} | {color:green} test4tests {color} | {color:green} 0m 0s {color} | {color:green} The patch appears to include 1 new or modified test files. {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 8m 58s {color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 11m 26s {color} | {color:green} trunk passed with JDK v1.8.0_66 {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 9m 28s {color} | {color:green} trunk passed with JDK v1.7.0_91 {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green} 0m 18s {color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green} 1m 6s {color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green} 0m 15s {color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green} 2m 9s {color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 1m 5s {color} | {color:green} trunk passed with JDK v1.8.0_66 {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 1m 18s {color} | {color:green} trunk passed with JDK v1.7.0_91 {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 1m 49s {color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 11m 18s {color} | {color:green} the patch passed with JDK v1.8.0_66 {color} |
| {color:green}+1{color} | {color:green} javac {color} | {color:green} 11m 18s {color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 9m 32s {color} | {color:green} the patch passed with JDK v1.7.0_91 {color} |
| {color:green}+1{color} | {color:green} javac {color} | {color:green} 9m 32s {color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green} 0m 17s {color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green} 1m 9s {color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green} 0m 15s {color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} shellcheck {color} | {color:green} 0m 8s {color} | {color:green} There were no new shellcheck issues. {color} |
| {color:green}+1{color} | {color:green} whitespace {color} | {color:green} 0m 0s {color} | {color:green} Patch has no whitespace issues. {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green} 2m 14s {color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 1m 2s {color} | {color:green} the patch passed with JDK v1.8.0_66 {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 1m 10s {color} | {color:green} the patch passed with JDK v1.7.0_91 {color} |
| {color:red}-1{color} | {color:red} unit {color} | {color:red} 10m 9s {color} | {color:red} hadoop-common in the patch failed with JDK v1.8.0_66. {color} |
| {color:green}+1{color} | {color:green} unit {color} | {color:green} 9m 39s {color} | {color:green} hadoop-common in the patch passed with JDK v1.7.0_91. {color} |
| {color:green}+1{color} | {color:green} asflicense {color} | {color:green} 0m 24s {color} | {color:green} Patch does not generate ASF License warnings. {color} |
| {color:black}{color} | {color:black} {color} | {color:black} 86m 30s {color} | {color:black} {color} |
\\
\\
|| Reason || Tests ||
| JDK v1.8.0_66 Failed junit tests | hadoop.metrics2.impl.TestGangliaMetrics |
|   | hadoop.ha.TestZKFailoverController |
\\
\\
|| Subsystem || Report/Notes ||
| Docker |  Image:yetus/hadoop:0ca8df7 |
| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12781100/HADOOP-12101.007.patch |
| JIRA Issue | HADOOP-12101 |
| Optional Tests |  asflicense  mvnsite  unit  shellcheck  compile  javac  javadoc  mvninstall  findbugs  checkstyle  |
| uname | Linux e2dcd59408ad 3.13.0-36-lowlatency #63-Ubuntu SMP PREEMPT Wed Sep 3 21:56:12 UTC 2014 x86_64 x86_64 x86_64 GNU/Linux |
| Build tool | maven |
| Personality | /testptch/hadoop/patchprocess/precommit/personality/provided.sh |
| git revision | trunk / 89022f8 |
| Default Java | 1.7.0_91 |
| Multi-JDK versions |  /usr/lib/jvm/java-8-oracle:1.8.0_66 /usr/lib/jvm/java-7-openjdk-amd64:1.7.0_91 |
| findbugs | v3.0.0 |
| shellcheck | v0.4.1 |
| unit | https://builds.apache.org/job/PreCommit-HADOOP-Build/8360/artifact/patchprocess/patch-unit-hadoop-common-project_hadoop-common-jdk1.8.0_66.txt |
| unit test logs |  https://builds.apache.org/job/PreCommit-HADOOP-Build/8360/artifact/patchprocess/patch-unit-hadoop-common-project_hadoop-common-jdk1.8.0_66.txt |
| JDK v1.7.0_91  Test Results | https://builds.apache.org/job/PreCommit-HADOOP-Build/8360/testReport/ |
| modules | C: hadoop-common-project/hadoop-common U: hadoop-common-project/hadoop-common |
| Max memory used | 75MB |
| Powered by | Apache Yetus 0.2.0-SNAPSHOT   http://yetus.apache.org |
| Console output | https://builds.apache.org/job/PreCommit-HADOOP-Build/8360/console |


This message was automatically generated.

","08/Jan/16 18:53;rchiang;RE: Failing unit tests with JDK8

Both tests pass in my tree using JDK8.","29/Feb/16 19:25;rchiang;- Move verify-xml.sh into dev-support/bin directory","29/Feb/16 20:41;hadoopqa;| (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue} 0m 12s {color} | {color:blue} Docker mode activated. {color} |
| {color:blue}0{color} | {color:blue} shelldocs {color} | {color:blue} 0m 3s {color} | {color:blue} Shelldocs was not available. {color} |
| {color:green}+1{color} | {color:green} @author {color} | {color:green} 0m 0s {color} | {color:green} The patch does not contain any @author tags. {color} |
| {color:green}+1{color} | {color:green} test4tests {color} | {color:green} 0m 0s {color} | {color:green} The patch appears to include 1 new or modified test files. {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 6m 58s {color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 7m 53s {color} | {color:green} trunk passed with JDK v1.8.0_72 {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 7m 5s {color} | {color:green} trunk passed with JDK v1.7.0_95 {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green} 0m 19s {color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green} 1m 7s {color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green} 0m 13s {color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green} 1m 35s {color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 1m 0s {color} | {color:green} trunk passed with JDK v1.8.0_72 {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 1m 7s {color} | {color:green} trunk passed with JDK v1.7.0_95 {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 0m 42s {color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 7m 48s {color} | {color:green} the patch passed with JDK v1.8.0_72 {color} |
| {color:green}+1{color} | {color:green} javac {color} | {color:green} 7m 48s {color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 7m 19s {color} | {color:green} the patch passed with JDK v1.7.0_95 {color} |
| {color:green}+1{color} | {color:green} javac {color} | {color:green} 7m 19s {color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green} 0m 19s {color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green} 1m 3s {color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green} 0m 13s {color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} shellcheck {color} | {color:green} 0m 8s {color} | {color:green} There were no new shellcheck issues. {color} |
| {color:green}+1{color} | {color:green} whitespace {color} | {color:green} 0m 0s {color} | {color:green} Patch has no whitespace issues. {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green} 1m 47s {color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 0m 59s {color} | {color:green} the patch passed with JDK v1.8.0_72 {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 1m 7s {color} | {color:green} the patch passed with JDK v1.7.0_95 {color} |
| {color:green}+1{color} | {color:green} unit {color} | {color:green} 11m 31s {color} | {color:green} hadoop-common in the patch passed with JDK v1.8.0_72. {color} |
| {color:red}-1{color} | {color:red} unit {color} | {color:red} 11m 7s {color} | {color:red} hadoop-common in the patch failed with JDK v1.7.0_95. {color} |
| {color:green}+1{color} | {color:green} asflicense {color} | {color:green} 0m 24s {color} | {color:green} Patch does not generate ASF License warnings. {color} |
| {color:black}{color} | {color:black} {color} | {color:black} 73m 1s {color} | {color:black} {color} |
\\
\\
|| Reason || Tests ||
| JDK v1.7.0_95 Failed junit tests | hadoop.fs.shell.find.TestIname |
|   | hadoop.fs.shell.find.TestPrint0 |
|   | hadoop.fs.shell.find.TestPrint |
|   | hadoop.fs.shell.find.TestName |
|   | hadoop.ipc.TestProtoBufRpc |
\\
\\
|| Subsystem || Report/Notes ||
| Docker |  Image:yetus/hadoop:0ca8df7 |
| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12790537/HADOOP-12101.008.patch |
| JIRA Issue | HADOOP-12101 |
| Optional Tests |  asflicense  mvnsite  unit  shellcheck  shelldocs  compile  javac  javadoc  mvninstall  findbugs  checkstyle  |
| uname | Linux d8d0a3792a3d 3.13.0-36-lowlatency #63-Ubuntu SMP PREEMPT Wed Sep 3 21:56:12 UTC 2014 x86_64 x86_64 x86_64 GNU/Linux |
| Build tool | maven |
| Personality | /testptch/hadoop/patchprocess/precommit/personality/provided.sh |
| git revision | trunk / 1cb2f93 |
| Default Java | 1.7.0_95 |
| Multi-JDK versions |  /usr/lib/jvm/java-8-oracle:1.8.0_72 /usr/lib/jvm/java-7-openjdk-amd64:1.7.0_95 |
| shellcheck | v0.4.3 |
| findbugs | v3.0.0 |
| unit | https://builds.apache.org/job/PreCommit-HADOOP-Build/8746/artifact/patchprocess/patch-unit-hadoop-common-project_hadoop-common-jdk1.7.0_95.txt |
| unit test logs |  https://builds.apache.org/job/PreCommit-HADOOP-Build/8746/artifact/patchprocess/patch-unit-hadoop-common-project_hadoop-common-jdk1.7.0_95.txt |
| JDK v1.7.0_95  Test Results | https://builds.apache.org/job/PreCommit-HADOOP-Build/8746/testReport/ |
| modules | C: hadoop-common-project/hadoop-common U: hadoop-common-project/hadoop-common |
| Console output | https://builds.apache.org/job/PreCommit-HADOOP-Build/8746/console |
| Powered by | Apache Yetus 0.2.0-SNAPSHOT   http://yetus.apache.org |


This message was automatically generated.

","29/Feb/16 20:57;rchiang;RE: Failing unit tests

All tests pass in my tree and are unrelated.","04/Mar/16 01:29;rkanter;A few more minor things:
# Use curly braces on this if statement in {{extractDefaultVariablesFromConfigurationFields}}.  I've found that not having them, even for such simple things, are very error-prone, especially if someone else needs to update this in the future.
{code:java}
+    if (fields==null)
+      return null;
{code}
# I'm not sure there's an advantage to declaring these ahead of the try block in {{extractDefaultVariablesFromConfigurationFields}}.
{code:java}
+        boolean bValue;
+        float fValue;
+        short shValue;
+        int iValue;
+        long lValue;
+        String sValue;
{code}
# The try block in {{extractDefaultVariablesFromConfigurationFields }} doesn't handle {{double}}.  That doesn't seem to be a problem running the script now, but {{Configuration}} does have a {{getDouble()}} method, so we should add it to be on the safe side.
# Why put the script in {{dev-support/bin/}} instead of just {{dev-support/}}?  There's other scripts in {{dev-support/}} already so I don't think we need to add a new {{bin/}} subdir.","04/Mar/16 07:43;rchiang;- Updates based on Robert's feedback.","04/Mar/16 09:14;hadoopqa;| (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue} 10m 44s {color} | {color:blue} Docker mode activated. {color} |
| {color:blue}0{color} | {color:blue} shelldocs {color} | {color:blue} 0m 4s {color} | {color:blue} Shelldocs was not available. {color} |
| {color:green}+1{color} | {color:green} @author {color} | {color:green} 0m 0s {color} | {color:green} The patch does not contain any @author tags. {color} |
| {color:green}+1{color} | {color:green} test4tests {color} | {color:green} 0m 0s {color} | {color:green} The patch appears to include 1 new or modified test files. {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 6m 43s {color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 5m 42s {color} | {color:green} trunk passed with JDK v1.8.0_74 {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 7m 12s {color} | {color:green} trunk passed with JDK v1.7.0_95 {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green} 0m 20s {color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green} 1m 1s {color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green} 0m 13s {color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green} 1m 34s {color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 0m 52s {color} | {color:green} trunk passed with JDK v1.8.0_74 {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 1m 9s {color} | {color:green} trunk passed with JDK v1.7.0_95 {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 0m 46s {color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 7m 9s {color} | {color:green} the patch passed with JDK v1.8.0_74 {color} |
| {color:green}+1{color} | {color:green} javac {color} | {color:green} 7m 9s {color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 6m 39s {color} | {color:green} the patch passed with JDK v1.7.0_95 {color} |
| {color:green}+1{color} | {color:green} javac {color} | {color:green} 6m 39s {color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green} 0m 21s {color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green} 0m 56s {color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green} 0m 14s {color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} shellcheck {color} | {color:green} 0m 9s {color} | {color:green} There were no new shellcheck issues. {color} |
| {color:green}+1{color} | {color:green} whitespace {color} | {color:green} 0m 0s {color} | {color:green} Patch has no whitespace issues. {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green} 1m 50s {color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 0m 56s {color} | {color:green} the patch passed with JDK v1.8.0_74 {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 1m 2s {color} | {color:green} the patch passed with JDK v1.7.0_95 {color} |
| {color:red}-1{color} | {color:red} unit {color} | {color:red} 7m 47s {color} | {color:red} hadoop-common in the patch failed with JDK v1.8.0_74. {color} |
| {color:green}+1{color} | {color:green} unit {color} | {color:green} 8m 44s {color} | {color:green} hadoop-common in the patch passed with JDK v1.7.0_95. {color} |
| {color:green}+1{color} | {color:green} asflicense {color} | {color:green} 0m 23s {color} | {color:green} Patch does not generate ASF License warnings. {color} |
| {color:black}{color} | {color:black} {color} | {color:black} 73m 35s {color} | {color:black} {color} |
\\
\\
|| Reason || Tests ||
| JDK v1.8.0_74 Failed junit tests | hadoop.ha.TestZKFailoverController |
\\
\\
|| Subsystem || Report/Notes ||
| Docker |  Image:yetus/hadoop:0ca8df7 |
| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12791423/HADOOP-12101.009.patch |
| JIRA Issue | HADOOP-12101 |
| Optional Tests |  asflicense  mvnsite  unit  shellcheck  shelldocs  compile  javac  javadoc  mvninstall  findbugs  checkstyle  |
| uname | Linux 6e20199ee676 3.13.0-36-lowlatency #63-Ubuntu SMP PREEMPT Wed Sep 3 21:56:12 UTC 2014 x86_64 x86_64 x86_64 GNU/Linux |
| Build tool | maven |
| Personality | /testptch/hadoop/patchprocess/precommit/personality/provided.sh |
| git revision | trunk / cbd3132 |
| Default Java | 1.7.0_95 |
| Multi-JDK versions |  /usr/lib/jvm/java-8-oracle:1.8.0_74 /usr/lib/jvm/java-7-openjdk-amd64:1.7.0_95 |
| shellcheck | v0.4.3 |
| findbugs | v3.0.0 |
| unit | https://builds.apache.org/job/PreCommit-HADOOP-Build/8786/artifact/patchprocess/patch-unit-hadoop-common-project_hadoop-common-jdk1.8.0_74.txt |
| unit test logs |  https://builds.apache.org/job/PreCommit-HADOOP-Build/8786/artifact/patchprocess/patch-unit-hadoop-common-project_hadoop-common-jdk1.8.0_74.txt |
| JDK v1.7.0_95  Test Results | https://builds.apache.org/job/PreCommit-HADOOP-Build/8786/testReport/ |
| modules | C: hadoop-common-project/hadoop-common U: hadoop-common-project/hadoop-common |
| Console output | https://builds.apache.org/job/PreCommit-HADOOP-Build/8786/console |
| Powered by | Apache Yetus 0.3.0-SNAPSHOT   http://yetus.apache.org |


This message was automatically generated.

","04/Mar/16 16:33;rchiang;RE: Failed unit test

Test passes in my tree.","25/Apr/16 18:40;rchiang;- Add support for TestCommonConfigurationFields
- Current fails TestYarnConfigurationFields due to YARN-4992
","25/Apr/16 18:59;hadoopqa;| (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue} 0m 0s {color} | {color:blue} Docker mode activated. {color} |
| {color:red}-1{color} | {color:red} docker {color} | {color:red} 11m 2s {color} | {color:red} Docker failed to build yetus/hadoop:fbe3e86. {color} |
\\
\\
|| Subsystem || Report/Notes ||
| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12800592/HADOOP-12101.010.patch |
| JIRA Issue | HADOOP-12101 |
| Console output | https://builds.apache.org/job/PreCommit-HADOOP-Build/9170/console |
| Powered by | Apache Yetus 0.2.0   http://yetus.apache.org |


This message was automatically generated.

","25/Apr/16 19:08;rchiang;- Same patch.  Re-launch Jenkins.","25/Apr/16 19:31;hadoopqa;| (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue} 0m 0s {color} | {color:blue} Docker mode activated. {color} |
| {color:red}-1{color} | {color:red} docker {color} | {color:red} 0m 3s {color} | {color:red} Docker failed to build yetus/hadoop:fbe3e86. {color} |
\\
\\
|| Subsystem || Report/Notes ||
| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12800606/HADOOP-12101.011.patch |
| JIRA Issue | HADOOP-12101 |
| Console output | https://builds.apache.org/job/PreCommit-HADOOP-Build/9173/console |
| Powered by | Apache Yetus 0.2.0   http://yetus.apache.org |


This message was automatically generated.

","27/Apr/16 23:18;rchiang;- Same file.  Force Jenkins relaunch.","28/Apr/16 05:37;iwasakims;verify-xml.sh is intended to be run on top directory of source tree but it is not obvious. Is it possible to do cd in the script before run_*_xml_test? like
{noformat}
# Main body

cd -P -- ""$(dirname -- ${BASH_SOURCE-$0})/..""
dir=""$(pwd -P)""
export commonOutputFile=""$(find ""${dir}"" -name org.apache.hadoop.conf.TestCommonConfigurationFields-output.txt)""
...
{noformat}

Otherwise we should add some instruction to comment and usage.


{noformat}
  *)                                                                                                                                                                                           |
    echo ""$0 <mode>""
    echo ""  where <mode> is one of all, hdfs, mr, yarn""
{noformat}
Usage should be prefixed by ""Usage: "" and {{common}} is missing in modes.
","28/Apr/16 16:51;iwasakims;The patch affects TestHdfsConfigFields, TestYarnConfigurationFields and TestMapreduceConfigFields but QA build does not run them since the patch only changes the codes under hadoop-common. I ran TestHdfsConfigFields, TestYarnConfigurationFields and TestMapreduceConfigFields locally and verified that it works.

I think it is ok to handle values with units and variable expantion in follow-up JIRAs.

{noformat}
  XML Property: dfs.namenode.lifeline.handler.ratio
  XML Value:    0.10
  Config Name:  DFS_NAMENODE_LIFELINE_HANDLER_RATIO_DEFAULT
  Config Value: 0.1

  XML Property: dfs.namenode.retrycache.heap.percent
  XML Value:    0.03f
  Config Name:  DFS_NAMENODE_RETRY_CACHE_HEAP_PERCENT_DEFAULT
  Config Value: 0.03

  XML Property: dfs.namenode.edits.dir
  XML Value:    ${dfs.namenode.name.dir}
  Config Name:  DFS_NAMENODE_EDITS_DIR_DEFAULT
  Config Value: file:///tmp/hadoop/dfs/name

  XML Property: dfs.datanode.balance.bandwidthPerSec
  XML Value:    10m
  Config Name:  DFS_DATANODE_BALANCE_BANDWIDTHPERSEC_DEFAULT
  Config Value: 10485760
{noformat}
","28/Apr/16 17:10;rchiang;Thanks Masatake!  I will update the script with your suggestions.","02/May/16 17:16;rchiang;- Fixes for verify-xml.sh script","02/May/16 18:22;hadoopqa;| (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue} 0m 12s {color} | {color:blue} Docker mode activated. {color} |
| {color:blue}0{color} | {color:blue} shelldocs {color} | {color:blue} 0m 4s {color} | {color:blue} Shelldocs was not available. {color} |
| {color:green}+1{color} | {color:green} @author {color} | {color:green} 0m 0s {color} | {color:green} The patch does not contain any @author tags. {color} |
| {color:green}+1{color} | {color:green} test4tests {color} | {color:green} 0m 0s {color} | {color:green} The patch appears to include 1 new or modified test files. {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 6m 55s {color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 5m 47s {color} | {color:green} trunk passed with JDK v1.8.0_91 {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 6m 38s {color} | {color:green} trunk passed with JDK v1.7.0_95 {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green} 0m 23s {color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green} 1m 3s {color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green} 0m 16s {color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green} 1m 34s {color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 0m 57s {color} | {color:green} trunk passed with JDK v1.8.0_91 {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 1m 6s {color} | {color:green} trunk passed with JDK v1.7.0_95 {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 0m 42s {color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 5m 41s {color} | {color:green} the patch passed with JDK v1.8.0_91 {color} |
| {color:green}+1{color} | {color:green} javac {color} | {color:green} 5m 41s {color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 6m 35s {color} | {color:green} the patch passed with JDK v1.7.0_95 {color} |
| {color:green}+1{color} | {color:green} javac {color} | {color:green} 6m 35s {color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green} 0m 22s {color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green} 0m 57s {color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green} 0m 16s {color} | {color:green} the patch passed {color} |
| {color:red}-1{color} | {color:red} shellcheck {color} | {color:red} 0m 11s {color} | {color:red} The patch generated 3 new + 96 unchanged - 0 fixed = 99 total (was 96) {color} |
| {color:green}+1{color} | {color:green} whitespace {color} | {color:green} 0m 0s {color} | {color:green} The patch has no whitespace issues. {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green} 1m 49s {color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 0m 54s {color} | {color:green} the patch passed with JDK v1.8.0_91 {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 1m 4s {color} | {color:green} the patch passed with JDK v1.7.0_95 {color} |
| {color:red}-1{color} | {color:red} unit {color} | {color:red} 6m 40s {color} | {color:red} hadoop-common in the patch failed with JDK v1.8.0_91. {color} |
| {color:red}-1{color} | {color:red} unit {color} | {color:red} 7m 0s {color} | {color:red} hadoop-common in the patch failed with JDK v1.7.0_95. {color} |
| {color:green}+1{color} | {color:green} asflicense {color} | {color:green} 0m 26s {color} | {color:green} The patch does not generate ASF License warnings. {color} |
| {color:black}{color} | {color:black} {color} | {color:black} 58m 53s {color} | {color:black} {color} |
\\
\\
|| Reason || Tests ||
| JDK v1.8.0_91 Failed junit tests | hadoop.metrics2.impl.TestGangliaMetrics |
| JDK v1.7.0_95 Failed junit tests | hadoop.security.ssl.TestReloadingX509TrustManager |
\\
\\
|| Subsystem || Report/Notes ||
| Docker |  Image:yetus/hadoop:cf2ee45 |
| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12801779/HADOOP-12101.013.patch |
| JIRA Issue | HADOOP-12101 |
| Optional Tests |  asflicense  mvnsite  unit  shellcheck  shelldocs  compile  javac  javadoc  mvninstall  findbugs  checkstyle  |
| uname | Linux fce83610b2c5 3.13.0-36-lowlatency #63-Ubuntu SMP PREEMPT Wed Sep 3 21:56:12 UTC 2014 x86_64 x86_64 x86_64 GNU/Linux |
| Build tool | maven |
| Personality | /testptch/hadoop/patchprocess/precommit/personality/provided.sh |
| git revision | trunk / 2beedea |
| Default Java | 1.7.0_95 |
| Multi-JDK versions |  /usr/lib/jvm/java-8-oracle:1.8.0_91 /usr/lib/jvm/java-7-openjdk-amd64:1.7.0_95 |
| shellcheck | v0.4.3 |
| findbugs | v3.0.0 |
| shellcheck | https://builds.apache.org/job/PreCommit-HADOOP-Build/9251/artifact/patchprocess/diff-patch-shellcheck.txt |
| unit | https://builds.apache.org/job/PreCommit-HADOOP-Build/9251/artifact/patchprocess/patch-unit-hadoop-common-project_hadoop-common-jdk1.8.0_91.txt |
| unit | https://builds.apache.org/job/PreCommit-HADOOP-Build/9251/artifact/patchprocess/patch-unit-hadoop-common-project_hadoop-common-jdk1.7.0_95.txt |
| unit test logs |  https://builds.apache.org/job/PreCommit-HADOOP-Build/9251/artifact/patchprocess/patch-unit-hadoop-common-project_hadoop-common-jdk1.8.0_91.txt https://builds.apache.org/job/PreCommit-HADOOP-Build/9251/artifact/patchprocess/patch-unit-hadoop-common-project_hadoop-common-jdk1.7.0_95.txt |
| JDK v1.7.0_95  Test Results | https://builds.apache.org/job/PreCommit-HADOOP-Build/9251/testReport/ |
| modules | C: hadoop-common-project/hadoop-common U: hadoop-common-project/hadoop-common |
| Console output | https://builds.apache.org/job/PreCommit-HADOOP-Build/9251/console |
| Powered by | Apache Yetus 0.3.0-SNAPSHOT   http://yetus.apache.org |


This message was automatically generated.

","02/May/16 18:51;rchiang;- Fix shellcheck issues and fix missing pasted code.","02/May/16 22:12;iwasakims;Thanks for the update.

{noformat}
108	export yarnOutputFile=""$(find ""{dir}"" -name org.apache.hadoop.yarn.conf.TestYarnConfigurationFields-output.txt)""
{noformat}

{dir} should be ${dir}
","02/May/16 23:25;rchiang;- Fix variable reference","03/May/16 00:17;hadoopqa;| (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue} 0m 11s {color} | {color:blue} Docker mode activated. {color} |
| {color:blue}0{color} | {color:blue} shelldocs {color} | {color:blue} 0m 4s {color} | {color:blue} Shelldocs was not available. {color} |
| {color:green}+1{color} | {color:green} @author {color} | {color:green} 0m 0s {color} | {color:green} The patch does not contain any @author tags. {color} |
| {color:green}+1{color} | {color:green} test4tests {color} | {color:green} 0m 0s {color} | {color:green} The patch appears to include 1 new or modified test files. {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 6m 39s {color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 7m 1s {color} | {color:green} trunk passed with JDK v1.8.0_91 {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 7m 0s {color} | {color:green} trunk passed with JDK v1.7.0_95 {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green} 0m 23s {color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green} 1m 1s {color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green} 0m 16s {color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green} 1m 37s {color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 0m 57s {color} | {color:green} trunk passed with JDK v1.8.0_91 {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 1m 7s {color} | {color:green} trunk passed with JDK v1.7.0_95 {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 0m 43s {color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 6m 14s {color} | {color:green} the patch passed with JDK v1.8.0_91 {color} |
| {color:green}+1{color} | {color:green} javac {color} | {color:green} 6m 14s {color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 7m 12s {color} | {color:green} the patch passed with JDK v1.7.0_95 {color} |
| {color:green}+1{color} | {color:green} javac {color} | {color:green} 7m 12s {color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green} 0m 24s {color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green} 1m 3s {color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green} 0m 16s {color} | {color:green} the patch passed {color} |
| {color:red}-1{color} | {color:red} shellcheck {color} | {color:red} 0m 10s {color} | {color:red} The patch generated 12 new + 96 unchanged - 0 fixed = 108 total (was 96) {color} |
| {color:green}+1{color} | {color:green} whitespace {color} | {color:green} 0m 0s {color} | {color:green} The patch has no whitespace issues. {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green} 1m 53s {color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 0m 57s {color} | {color:green} the patch passed with JDK v1.8.0_91 {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 1m 8s {color} | {color:green} the patch passed with JDK v1.7.0_95 {color} |
| {color:red}-1{color} | {color:red} unit {color} | {color:red} 21m 24s {color} | {color:red} hadoop-common in the patch failed with JDK v1.8.0_91. {color} |
| {color:green}+1{color} | {color:green} unit {color} | {color:green} 9m 15s {color} | {color:green} hadoop-common in the patch passed with JDK v1.7.0_95. {color} |
| {color:green}+1{color} | {color:green} asflicense {color} | {color:green} 0m 25s {color} | {color:green} The patch does not generate ASF License warnings. {color} |
| {color:black}{color} | {color:black} {color} | {color:black} 78m 34s {color} | {color:black} {color} |
\\
\\
|| Reason || Tests ||
| JDK v1.8.0_91 Failed junit tests | hadoop.ipc.TestIPC |
| JDK v1.8.0_91 Timed out junit tests | org.apache.hadoop.http.TestHttpServerLifecycle |
\\
\\
|| Subsystem || Report/Notes ||
| Docker |  Image:yetus/hadoop:cf2ee45 |
| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12801793/HADOOP-12101.014.patch |
| JIRA Issue | HADOOP-12101 |
| Optional Tests |  asflicense  mvnsite  unit  shellcheck  shelldocs  compile  javac  javadoc  mvninstall  findbugs  checkstyle  |
| uname | Linux 486a897fcceb 3.13.0-36-lowlatency #63-Ubuntu SMP PREEMPT Wed Sep 3 21:56:12 UTC 2014 x86_64 x86_64 x86_64 GNU/Linux |
| Build tool | maven |
| Personality | /testptch/hadoop/patchprocess/precommit/personality/provided.sh |
| git revision | trunk / 9e8411d |
| Default Java | 1.7.0_95 |
| Multi-JDK versions |  /usr/lib/jvm/java-8-oracle:1.8.0_91 /usr/lib/jvm/java-7-openjdk-amd64:1.7.0_95 |
| shellcheck | v0.4.3 |
| findbugs | v3.0.0 |
| shellcheck | https://builds.apache.org/job/PreCommit-HADOOP-Build/9252/artifact/patchprocess/diff-patch-shellcheck.txt |
| unit | https://builds.apache.org/job/PreCommit-HADOOP-Build/9252/artifact/patchprocess/patch-unit-hadoop-common-project_hadoop-common-jdk1.8.0_91.txt |
| unit test logs |  https://builds.apache.org/job/PreCommit-HADOOP-Build/9252/artifact/patchprocess/patch-unit-hadoop-common-project_hadoop-common-jdk1.8.0_91.txt |
| JDK v1.7.0_95  Test Results | https://builds.apache.org/job/PreCommit-HADOOP-Build/9252/testReport/ |
| modules | C: hadoop-common-project/hadoop-common U: hadoop-common-project/hadoop-common |
| Console output | https://builds.apache.org/job/PreCommit-HADOOP-Build/9252/console |
| Powered by | Apache Yetus 0.3.0-SNAPSHOT   http://yetus.apache.org |


This message was automatically generated.

","03/May/16 02:18;hadoopqa;| (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue} 0m 13s {color} | {color:blue} Docker mode activated. {color} |
| {color:blue}0{color} | {color:blue} shelldocs {color} | {color:blue} 0m 4s {color} | {color:blue} Shelldocs was not available. {color} |
| {color:green}+1{color} | {color:green} @author {color} | {color:green} 0m 0s {color} | {color:green} The patch does not contain any @author tags. {color} |
| {color:green}+1{color} | {color:green} test4tests {color} | {color:green} 0m 0s {color} | {color:green} The patch appears to include 1 new or modified test files. {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 7m 9s {color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 6m 6s {color} | {color:green} trunk passed with JDK v1.8.0_91 {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 6m 49s {color} | {color:green} trunk passed with JDK v1.7.0_95 {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green} 0m 23s {color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green} 1m 4s {color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green} 0m 18s {color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green} 1m 39s {color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 0m 59s {color} | {color:green} trunk passed with JDK v1.8.0_91 {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 1m 5s {color} | {color:green} trunk passed with JDK v1.7.0_95 {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 0m 43s {color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 6m 4s {color} | {color:green} the patch passed with JDK v1.8.0_91 {color} |
| {color:green}+1{color} | {color:green} javac {color} | {color:green} 6m 4s {color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 6m 52s {color} | {color:green} the patch passed with JDK v1.7.0_95 {color} |
| {color:green}+1{color} | {color:green} javac {color} | {color:green} 6m 52s {color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green} 0m 24s {color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green} 1m 0s {color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green} 0m 17s {color} | {color:green} the patch passed {color} |
| {color:red}-1{color} | {color:red} shellcheck {color} | {color:red} 0m 10s {color} | {color:red} The patch generated 12 new + 96 unchanged - 0 fixed = 108 total (was 96) {color} |
| {color:green}+1{color} | {color:green} whitespace {color} | {color:green} 0m 0s {color} | {color:green} The patch has no whitespace issues. {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green} 1m 53s {color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 0m 57s {color} | {color:green} the patch passed with JDK v1.8.0_91 {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 1m 6s {color} | {color:green} the patch passed with JDK v1.7.0_95 {color} |
| {color:red}-1{color} | {color:red} unit {color} | {color:red} 13m 53s {color} | {color:red} hadoop-common in the patch failed with JDK v1.8.0_91. {color} |
| {color:green}+1{color} | {color:green} unit {color} | {color:green} 8m 58s {color} | {color:green} hadoop-common in the patch passed with JDK v1.7.0_95. {color} |
| {color:green}+1{color} | {color:green} asflicense {color} | {color:green} 0m 27s {color} | {color:green} The patch does not generate ASF License warnings. {color} |
| {color:black}{color} | {color:black} {color} | {color:black} 69m 49s {color} | {color:black} {color} |
\\
\\
|| Subsystem || Report/Notes ||
| Docker |  Image:yetus/hadoop:cf2ee45 |
| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12801854/HADOOP-12101.015.patch |
| JIRA Issue | HADOOP-12101 |
| Optional Tests |  asflicense  mvnsite  unit  shellcheck  shelldocs  compile  javac  javadoc  mvninstall  findbugs  checkstyle  |
| uname | Linux 7182d29494b6 3.13.0-36-lowlatency #63-Ubuntu SMP PREEMPT Wed Sep 3 21:56:12 UTC 2014 x86_64 x86_64 x86_64 GNU/Linux |
| Build tool | maven |
| Personality | /testptch/hadoop/patchprocess/precommit/personality/provided.sh |
| git revision | trunk / 9e8411d |
| Default Java | 1.7.0_95 |
| Multi-JDK versions |  /usr/lib/jvm/java-8-oracle:1.8.0_91 /usr/lib/jvm/java-7-openjdk-amd64:1.7.0_95 |
| shellcheck | v0.4.3 |
| findbugs | v3.0.0 |
| shellcheck | https://builds.apache.org/job/PreCommit-HADOOP-Build/9254/artifact/patchprocess/diff-patch-shellcheck.txt |
| unit | https://builds.apache.org/job/PreCommit-HADOOP-Build/9254/artifact/patchprocess/patch-unit-hadoop-common-project_hadoop-common-jdk1.8.0_91.txt |
| JDK v1.7.0_95  Test Results | https://builds.apache.org/job/PreCommit-HADOOP-Build/9254/testReport/ |
| modules | C: hadoop-common-project/hadoop-common U: hadoop-common-project/hadoop-common |
| Console output | https://builds.apache.org/job/PreCommit-HADOOP-Build/9254/console |
| Powered by | Apache Yetus 0.3.0-SNAPSHOT   http://yetus.apache.org |


This message was automatically generated.

","03/May/16 15:42;rchiang;- More shellcheck cleanup","03/May/16 17:01;hadoopqa;| (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue} 0m 12s {color} | {color:blue} Docker mode activated. {color} |
| {color:blue}0{color} | {color:blue} shelldocs {color} | {color:blue} 0m 6s {color} | {color:blue} Shelldocs was not available. {color} |
| {color:green}+1{color} | {color:green} @author {color} | {color:green} 0m 0s {color} | {color:green} The patch does not contain any @author tags. {color} |
| {color:green}+1{color} | {color:green} test4tests {color} | {color:green} 0m 0s {color} | {color:green} The patch appears to include 1 new or modified test files. {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 6m 50s {color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 6m 4s {color} | {color:green} trunk passed with JDK v1.8.0_92 {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 6m 36s {color} | {color:green} trunk passed with JDK v1.7.0_95 {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green} 0m 23s {color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green} 1m 3s {color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green} 0m 17s {color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green} 1m 37s {color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 0m 57s {color} | {color:green} trunk passed with JDK v1.8.0_92 {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 1m 7s {color} | {color:green} trunk passed with JDK v1.7.0_95 {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 0m 42s {color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 5m 40s {color} | {color:green} the patch passed with JDK v1.8.0_92 {color} |
| {color:green}+1{color} | {color:green} javac {color} | {color:green} 5m 40s {color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 6m 37s {color} | {color:green} the patch passed with JDK v1.7.0_95 {color} |
| {color:green}+1{color} | {color:green} javac {color} | {color:green} 6m 37s {color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green} 0m 23s {color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green} 0m 59s {color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green} 0m 17s {color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} shellcheck {color} | {color:green} 0m 10s {color} | {color:green} There were no new shellcheck issues. {color} |
| {color:green}+1{color} | {color:green} whitespace {color} | {color:green} 0m 0s {color} | {color:green} The patch has no whitespace issues. {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green} 1m 53s {color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 0m 59s {color} | {color:green} the patch passed with JDK v1.8.0_92 {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 1m 7s {color} | {color:green} the patch passed with JDK v1.7.0_95 {color} |
| {color:red}-1{color} | {color:red} unit {color} | {color:red} 17m 7s {color} | {color:red} hadoop-common in the patch failed with JDK v1.8.0_92. {color} |
| {color:green}+1{color} | {color:green} unit {color} | {color:green} 9m 35s {color} | {color:green} hadoop-common in the patch passed with JDK v1.7.0_95. {color} |
| {color:green}+1{color} | {color:green} asflicense {color} | {color:green} 0m 26s {color} | {color:green} The patch does not generate ASF License warnings. {color} |
| {color:black}{color} | {color:black} {color} | {color:black} 72m 23s {color} | {color:black} {color} |
\\
\\
|| Reason || Tests ||
| JDK v1.8.0_92 Timed out junit tests | org.apache.hadoop.http.TestHttpServerLifecycle |
\\
\\
|| Subsystem || Report/Notes ||
| Docker |  Image:yetus/hadoop:cf2ee45 |
| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12801968/HADOOP-12101.016.patch |
| JIRA Issue | HADOOP-12101 |
| Optional Tests |  asflicense  mvnsite  unit  shellcheck  shelldocs  compile  javac  javadoc  mvninstall  findbugs  checkstyle  |
| uname | Linux 5f1451e135df 3.13.0-36-lowlatency #63-Ubuntu SMP PREEMPT Wed Sep 3 21:56:12 UTC 2014 x86_64 x86_64 x86_64 GNU/Linux |
| Build tool | maven |
| Personality | /testptch/hadoop/patchprocess/precommit/personality/provided.sh |
| git revision | trunk / 06413da |
| Default Java | 1.7.0_95 |
| Multi-JDK versions |  /usr/lib/jvm/java-8-oracle:1.8.0_92 /usr/lib/jvm/java-7-openjdk-amd64:1.7.0_95 |
| shellcheck | v0.4.3 |
| findbugs | v3.0.0 |
| unit | https://builds.apache.org/job/PreCommit-HADOOP-Build/9259/artifact/patchprocess/patch-unit-hadoop-common-project_hadoop-common-jdk1.8.0_92.txt |
| unit test logs |  https://builds.apache.org/job/PreCommit-HADOOP-Build/9259/artifact/patchprocess/patch-unit-hadoop-common-project_hadoop-common-jdk1.8.0_92.txt |
| JDK v1.7.0_95  Test Results | https://builds.apache.org/job/PreCommit-HADOOP-Build/9259/testReport/ |
| modules | C: hadoop-common-project/hadoop-common U: hadoop-common-project/hadoop-common |
| Console output | https://builds.apache.org/job/PreCommit-HADOOP-Build/9259/console |
| Powered by | Apache Yetus 0.3.0-SNAPSHOT   http://yetus.apache.org |


This message was automatically generated.

","04/May/16 06:13;iwasakims;+1, committing this.","04/May/16 06:45;hudson;FAILURE: Integrated in Hadoop-trunk-Commit #9711 (See [https://builds.apache.org/job/Hadoop-trunk-Commit/9711/])
HADOOP-12101. Add automatic search of default Configuration variables to (iwasakims: rev 355325bcc7111fa4aac801fd23a26422ffabaf7c)
* dev-support/verify-xml.sh
* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/conf/TestConfigurationFieldsBase.java
","05/May/16 03:26;iwasakims;Committed. Thanks, [~rchiang]!","05/May/16 06:21;rchiang;Thanks for the review and the commit [~iwasakims]!",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Add Tests for S3FileSystem Contract,HADOOP-12696,12928558,Test,Resolved,HADOOP,Hadoop Common,software,omalley,Hadoop Common is the common library for Apache Hadoop.,http://hadoop.apache.org/,Major,Fixed,mattpaduano,mattpaduano,mattpaduano,08/Jan/16 05:07,30/Aug/16 01:20,12/Jan/21 11:55,19/Jan/16 22:03,2.7.0,,,,2.8.0,3.0.0-alpha1,,,,,tools,,,,0,S3,,The regression fixed by HADOOP-12689 had no unit tests to expose the problem.   Add filesystem tests according to http://hadoop.apache.org/docs/current/hadoop-project-dist/hadoop-common/filesystem/testing.html for the s3 scheme.,,cnauroth,Fan04290,hudson,mattpaduano,raviprak,vinodkv,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,HADOOP-12709,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,HADOOP-12815,,,,,,,,,,"08/Jan/16 05:26;mattpaduano;HADOOP-12696.01.patch;https://issues.apache.org/jira/secure/attachment/12781144/HADOOP-12696.01.patch","09/Jan/16 03:14;mattpaduano;HADOOP-12696.02.patch;https://issues.apache.org/jira/secure/attachment/12781367/HADOOP-12696.02.patch","08/Jan/16 05:24;mattpaduano;log.fail2;https://issues.apache.org/jira/secure/attachment/12781142/log.fail2","08/Jan/16 20:48;mattpaduano;log.hdfs;https://issues.apache.org/jira/secure/attachment/12781297/log.hdfs","09/Jan/16 03:13;mattpaduano;log.patch02;https://issues.apache.org/jira/secure/attachment/12781366/log.patch02","08/Jan/16 20:48;mattpaduano;log.s3a;https://issues.apache.org/jira/secure/attachment/12781295/log.s3a","08/Jan/16 20:48;mattpaduano;log.s3n;https://issues.apache.org/jira/secure/attachment/12781296/log.s3n","08/Jan/16 05:25;mattpaduano;log.succ;https://issues.apache.org/jira/secure/attachment/12781143/log.succ",,,,,,,,,,,,,,,,8.0,,,,,,,,,,,,,,,,,,,,2016-01-08 06:44:27.395,,,false,,,,,,,,,,,,,,,,,9223372036854775807,,,,,Wed Feb 17 19:03:32 UTC 2016,,,,,,,"0|i2r0xb:",9223372036854775807,,,,,,,,,,,,,2.8.0,,,,,,,,,,"08/Jan/16 05:24;mattpaduano;test log with regression from HADOOP-12689 being caught","08/Jan/16 05:25;mattpaduano;test log against current trunk - 47 tests run, 10 skipped, 37 passed","08/Jan/16 06:44;hadoopqa;| (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue} 0m 0s {color} | {color:blue} Docker mode activated. {color} |
| {color:green}+1{color} | {color:green} @author {color} | {color:green} 0m 0s {color} | {color:green} The patch does not contain any @author tags. {color} |
| {color:green}+1{color} | {color:green} test4tests {color} | {color:green} 0m 0s {color} | {color:green} The patch appears to include 9 new or modified test files. {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 7m 59s {color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 8m 46s {color} | {color:green} trunk passed with JDK v1.8.0_66 {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 8m 56s {color} | {color:green} trunk passed with JDK v1.7.0_91 {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green} 0m 58s {color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green} 1m 19s {color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green} 0m 26s {color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green} 2m 14s {color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 1m 9s {color} | {color:green} trunk passed with JDK v1.8.0_66 {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 1m 17s {color} | {color:green} trunk passed with JDK v1.7.0_91 {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 1m 50s {color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 7m 56s {color} | {color:green} the patch passed with JDK v1.8.0_66 {color} |
| {color:green}+1{color} | {color:green} javac {color} | {color:green} 7m 56s {color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 8m 46s {color} | {color:green} the patch passed with JDK v1.7.0_91 {color} |
| {color:green}+1{color} | {color:green} javac {color} | {color:green} 8m 46s {color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green} 0m 59s {color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green} 1m 22s {color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green} 0m 26s {color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} whitespace {color} | {color:green} 0m 0s {color} | {color:green} Patch has no whitespace issues. {color} |
| {color:green}+1{color} | {color:green} xml {color} | {color:green} 0m 1s {color} | {color:green} The patch has no ill-formed XML file. {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green} 2m 32s {color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 1m 8s {color} | {color:green} the patch passed with JDK v1.8.0_66 {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 1m 17s {color} | {color:green} the patch passed with JDK v1.7.0_91 {color} |
| {color:green}+1{color} | {color:green} unit {color} | {color:green} 7m 11s {color} | {color:green} hadoop-common in the patch passed with JDK v1.8.0_66. {color} |
| {color:green}+1{color} | {color:green} unit {color} | {color:green} 0m 12s {color} | {color:green} hadoop-aws in the patch passed with JDK v1.8.0_66. {color} |
| {color:red}-1{color} | {color:red} unit {color} | {color:red} 6m 54s {color} | {color:red} hadoop-common in the patch failed with JDK v1.7.0_91. {color} |
| {color:green}+1{color} | {color:green} unit {color} | {color:green} 0m 14s {color} | {color:green} hadoop-aws in the patch passed with JDK v1.7.0_91. {color} |
| {color:green}+1{color} | {color:green} asflicense {color} | {color:green} 0m 24s {color} | {color:green} Patch does not generate ASF License warnings. {color} |
| {color:black}{color} | {color:black} {color} | {color:black} 75m 41s {color} | {color:black} {color} |
\\
\\
|| Reason || Tests ||
| JDK v1.7.0_91 Failed junit tests | hadoop.fs.TestLocalFsFCStatistics |
\\
\\
|| Subsystem || Report/Notes ||
| Docker |  Image:yetus/hadoop:0ca8df7 |
| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12781144/HADOOP-12696.01.patch |
| JIRA Issue | HADOOP-12696 |
| Optional Tests |  asflicense  mvnsite  compile  javac  javadoc  mvninstall  unit  findbugs  checkstyle  xml  |
| uname | Linux 4294f69c6180 3.13.0-36-lowlatency #63-Ubuntu SMP PREEMPT Wed Sep 3 21:56:12 UTC 2014 x86_64 x86_64 x86_64 GNU/Linux |
| Build tool | maven |
| Personality | /testptch/hadoop/patchprocess/precommit/personality/provided.sh |
| git revision | trunk / 89022f8 |
| Default Java | 1.7.0_91 |
| Multi-JDK versions |  /usr/lib/jvm/java-8-oracle:1.8.0_66 /usr/lib/jvm/java-7-openjdk-amd64:1.7.0_91 |
| findbugs | v3.0.0 |
| unit | https://builds.apache.org/job/PreCommit-HADOOP-Build/8363/artifact/patchprocess/patch-unit-hadoop-common-project_hadoop-common-jdk1.7.0_91.txt |
| unit test logs |  https://builds.apache.org/job/PreCommit-HADOOP-Build/8363/artifact/patchprocess/patch-unit-hadoop-common-project_hadoop-common-jdk1.7.0_91.txt |
| JDK v1.7.0_91  Test Results | https://builds.apache.org/job/PreCommit-HADOOP-Build/8363/testReport/ |
| modules | C: hadoop-common-project/hadoop-common hadoop-tools/hadoop-aws U: . |
| Max memory used | 76MB |
| Powered by | Apache Yetus 0.2.0-SNAPSHOT   http://yetus.apache.org |
| Console output | https://builds.apache.org/job/PreCommit-HADOOP-Build/8363/console |


This message was automatically generated.

","08/Jan/16 20:07;raviprak;Hi Matt!
Thanks for the patch. You seem to have copied s3.xml from hdfs.xml. I wonder if s3n.xml is not a better XML to copy. e.g. is-blobstore should probably be true for S3 too, shouldn't it?
","08/Jan/16 20:48;mattpaduano;to copy.

   I dunno.   maybe.  maybe not.   I did see ContractOptions.IS_BLOBSTORE
in a
   few places in the test code when I was reviewing the failures.  But it
didn't seem
   like it would have fixed the test issues to me whichever way it pointed.

   But, it is easy enough to run the tests with various contracts.   I
removed
   all the forced skip @overrides from the test code and re-ran the tests
with
   the original s3.xml (== hdfs.xml) and also with s3a.xml and s3n.xml.
The
   same 10 tests still have issues, but the issues are different ;)

   I attached the output from all three test runs to this email.   summary:

   hdfs     Tests run: 47, Failures: 3, Errors: 7, Skipped: 0
   s3n      Tests run: 47, Failures: 2, Errors: 6, Skipped: 2
   s3a      Tests run: 47, Failures: 3, Errors: 7, Skipped: 2

   the s3n case does seem to account for two of the errors and
   instead they are ""auto skipped"".  testCreatedFileIsImmediatelyVisible
   (which is the atomic file option I think) and
testOverwriteNonEmptyDirectory
   (not sure of the option).   I am not sure I understand the skip code...
   it is sort of like a intermediate state between fail and pass...


matt
","08/Jan/16 20:57;mattpaduano;oops... I did not intend to reply to that address  :/

but since I did, I should also mention that I think those 10
issues can be fixed in one of S3FileSystem, S3InputStream
and/or the contract and AbstractFSContractTestBase.","09/Jan/16 03:13;mattpaduano;log.patch02 is the output of running:

mvn -l /tmp/log test -Ptests-on -Dtest=org.apache.hadoop.fs.contract.TestS3Contract*","09/Jan/16 03:17;mattpaduano;patch02 contains fixes for S3FileSystem, S3InputStream and one additional ContractOption with corresponding code in the SeekTest.

Tests run: 47, Failures: 0, Errors: 0, Skipped: 1
","09/Jan/16 04:46;hadoopqa;| (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue} 0m 0s {color} | {color:blue} Docker mode activated. {color} |
| {color:green}+1{color} | {color:green} @author {color} | {color:green} 0m 0s {color} | {color:green} The patch does not contain any @author tags. {color} |
| {color:green}+1{color} | {color:green} test4tests {color} | {color:green} 0m 0s {color} | {color:green} The patch appears to include 11 new or modified test files. {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 8m 45s {color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 9m 27s {color} | {color:green} trunk passed with JDK v1.8.0_66 {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 10m 3s {color} | {color:green} trunk passed with JDK v1.7.0_91 {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green} 1m 9s {color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green} 1m 35s {color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green} 0m 30s {color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green} 2m 39s {color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 1m 17s {color} | {color:green} trunk passed with JDK v1.8.0_66 {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 1m 26s {color} | {color:green} trunk passed with JDK v1.7.0_91 {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 1m 59s {color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 8m 23s {color} | {color:green} the patch passed with JDK v1.8.0_66 {color} |
| {color:green}+1{color} | {color:green} javac {color} | {color:green} 8m 23s {color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 8m 51s {color} | {color:green} the patch passed with JDK v1.7.0_91 {color} |
| {color:green}+1{color} | {color:green} javac {color} | {color:green} 8m 51s {color} | {color:green} the patch passed {color} |
| {color:red}-1{color} | {color:red} checkstyle {color} | {color:red} 0m 59s {color} | {color:red} Patch generated 3 new checkstyle issues in root (total was 52, now 52). {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green} 1m 20s {color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green} 0m 27s {color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} whitespace {color} | {color:green} 0m 0s {color} | {color:green} Patch has no whitespace issues. {color} |
| {color:green}+1{color} | {color:green} xml {color} | {color:green} 0m 0s {color} | {color:green} The patch has no ill-formed XML file. {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green} 2m 33s {color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 1m 9s {color} | {color:green} the patch passed with JDK v1.8.0_66 {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 1m 19s {color} | {color:green} the patch passed with JDK v1.7.0_91 {color} |
| {color:red}-1{color} | {color:red} unit {color} | {color:red} 7m 24s {color} | {color:red} hadoop-common in the patch failed with JDK v1.8.0_66. {color} |
| {color:green}+1{color} | {color:green} unit {color} | {color:green} 0m 12s {color} | {color:green} hadoop-aws in the patch passed with JDK v1.8.0_66. {color} |
| {color:green}+1{color} | {color:green} unit {color} | {color:green} 8m 16s {color} | {color:green} hadoop-common in the patch passed with JDK v1.7.0_91. {color} |
| {color:green}+1{color} | {color:green} unit {color} | {color:green} 0m 14s {color} | {color:green} hadoop-aws in the patch passed with JDK v1.7.0_91. {color} |
| {color:green}+1{color} | {color:green} asflicense {color} | {color:green} 0m 25s {color} | {color:green} Patch does not generate ASF License warnings. {color} |
| {color:black}{color} | {color:black} {color} | {color:black} 82m 4s {color} | {color:black} {color} |
\\
\\
|| Reason || Tests ||
| JDK v1.8.0_66 Failed junit tests | hadoop.fs.TestFsShellReturnCode |
\\
\\
|| Subsystem || Report/Notes ||
| Docker |  Image:yetus/hadoop:0ca8df7 |
| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12781367/HADOOP-12696.02.patch |
| JIRA Issue | HADOOP-12696 |
| Optional Tests |  asflicense  mvnsite  compile  javac  javadoc  mvninstall  unit  findbugs  checkstyle  xml  |
| uname | Linux c5ca694b3755 3.13.0-36-lowlatency #63-Ubuntu SMP PREEMPT Wed Sep 3 21:56:12 UTC 2014 x86_64 x86_64 x86_64 GNU/Linux |
| Build tool | maven |
| Personality | /testptch/hadoop/patchprocess/precommit/personality/provided.sh |
| git revision | trunk / 109e528 |
| Default Java | 1.7.0_91 |
| Multi-JDK versions |  /usr/lib/jvm/java-8-oracle:1.8.0_66 /usr/lib/jvm/java-7-openjdk-amd64:1.7.0_91 |
| findbugs | v3.0.0 |
| checkstyle | https://builds.apache.org/job/PreCommit-HADOOP-Build/8372/artifact/patchprocess/diff-checkstyle-root.txt |
| unit | https://builds.apache.org/job/PreCommit-HADOOP-Build/8372/artifact/patchprocess/patch-unit-hadoop-common-project_hadoop-common-jdk1.8.0_66.txt |
| unit test logs |  https://builds.apache.org/job/PreCommit-HADOOP-Build/8372/artifact/patchprocess/patch-unit-hadoop-common-project_hadoop-common-jdk1.8.0_66.txt |
| JDK v1.7.0_91  Test Results | https://builds.apache.org/job/PreCommit-HADOOP-Build/8372/testReport/ |
| modules | C: hadoop-common-project/hadoop-common hadoop-tools/hadoop-aws U: . |
| Max memory used | 76MB |
| Powered by | Apache Yetus 0.2.0-SNAPSHOT   http://yetus.apache.org |
| Console output | https://builds.apache.org/job/PreCommit-HADOOP-Build/8372/console |


This message was automatically generated.

","14/Jan/16 00:34;vinodkv;[~mattpaduano], please only use Target-version for expressing your intention. Committers set the fix-version at commit time. FYI.","16/Jan/16 00:14;raviprak;The changes look good to me. We are changing Exception types to subclasses in some cases so we should be fine. I'll commit Monday evening if there are no objections.
{code}
-------------------------------------------------------

-------------------------------------------------------
 T E S T S
-------------------------------------------------------
Running org.apache.hadoop.fs.contract.s3.TestS3ContractDelete
Tests run: 8, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 49.046 sec - in org.apache.hadoop.fs.contract.s3.TestS3ContractDelete
Running org.apache.hadoop.fs.contract.s3.TestS3ContractSeek
Tests run: 10, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 91.904 sec - in org.apache.hadoop.fs.contract.s3.TestS3ContractSeek
Running org.apache.hadoop.fs.contract.s3.TestS3ContractRename
Tests run: 6, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 56.517 sec - in org.apache.hadoop.fs.contract.s3.TestS3ContractRename
Running org.apache.hadoop.fs.contract.s3.TestS3ContractCreate
Tests run: 6, Failures: 0, Errors: 0, Skipped: 1, Time elapsed: 34.526 sec - in org.apache.hadoop.fs.contract.s3.TestS3ContractCreate
Running org.apache.hadoop.fs.contract.s3.TestS3ContractOpen
Tests run: 6, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 30.248 sec - in org.apache.hadoop.fs.contract.s3.TestS3ContractOpen
Running org.apache.hadoop.fs.contract.s3.TestS3ContractMkdir
Tests run: 5, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 32.245 sec - in org.apache.hadoop.fs.contract.s3.TestS3ContractMkdir
Running org.apache.hadoop.fs.contract.s3.TestS3ContractRootDir
Tests run: 6, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 26.864 sec - in org.apache.hadoop.fs.contract.s3.TestS3ContractRootDir

Results :

Tests run: 47, Failures: 0, Errors: 0, Skipped: 1
{code}
","16/Jan/16 00:20;raviprak;Also, with regards to the 1 skipped test, I found this helpful message in the logs:
{code}
2016-01-15 16:18:42,282 INFO  contract.ContractTestUtils (ContractTestUtils.java:skip(424)) - Skipping: Filesystem is an object store and newly created files are not immediately visible
{code}","18/Jan/16 19:01;raviprak;Also for s3n
{code}
-------------------------------------------------------
 T E S T S
-------------------------------------------------------
Java HotSpot(TM) 64-Bit Server VM warning: ignoring option MaxPermSize=768m; support was removed in 8.0
Running org.apache.hadoop.fs.contract.s3n.TestS3NContractRename
Tests run: 6, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 76.296 sec - in org.apache.hadoop.fs.contract.s3n.TestS3NContractRename
Java HotSpot(TM) 64-Bit Server VM warning: ignoring option MaxPermSize=768m; support was removed in 8.0
Running org.apache.hadoop.fs.contract.s3n.TestS3NContractOpen
Tests run: 6, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 39.855 sec - in org.apache.hadoop.fs.contract.s3n.TestS3NContractOpen
Java HotSpot(TM) 64-Bit Server VM warning: ignoring option MaxPermSize=768m; support was removed in 8.0
Running org.apache.hadoop.fs.contract.s3n.TestS3NContractRootDir
vi Tests run: 6, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 33.537 sec - in org.apache.hadoop.fs.contract.s3n.TestS3NContractRootDir
Java HotSpot(TM) 64-Bit Server VM warning: ignoring option MaxPermSize=768m; support was removed in 8.0
Running org.apache.hadoop.fs.contract.s3n.TestS3NContractDelete
Tests run: 8, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 84.402 sec - in org.apache.hadoop.fs.contract.s3n.TestS3NContractDelete
Java HotSpot(TM) 64-Bit Server VM warning: ignoring option MaxPermSize=768m; support was removed in 8.0
Running org.apache.hadoop.fs.contract.s3n.TestS3NContractCreate
Tests run: 6, Failures: 0, Errors: 0, Skipped: 3, Time elapsed: 43.637 sec - in org.apache.hadoop.fs.contract.s3n.TestS3NContractCreate
Java HotSpot(TM) 64-Bit Server VM warning: ignoring option MaxPermSize=768m; support was removed in 8.0
Running org.apache.hadoop.fs.contract.s3n.TestS3NContractSeek
Tests run: 10, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 95.472 sec - in org.apache.hadoop.fs.contract.s3n.TestS3NContractSeek
Java HotSpot(TM) 64-Bit Server VM warning: ignoring option MaxPermSize=768m; support was removed in 8.0
Running org.apache.hadoop.fs.contract.s3n.TestS3NContractMkdir
Tests run: 5, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 62.469 sec - in org.apache.hadoop.fs.contract.s3n.TestS3NContractMkdir

Results :

Tests run: 47, Failures: 0, Errors: 0, Skipped: 3
{code}
The skipped tests
{code}
2016-01-15 16:29:49,262 INFO  contract.ContractTestUtils (ContractTestUtils.java:skip(424)) - Skipping: Object store allows a file to overwrite a directory
2016-01-15 16:29:55,553 INFO  contract.ContractTestUtils (ContractTestUtils.java:skip(424)) - Skipping: Filesystem is an object store and newly created files are not immediately visible
2016-01-15 16:29:58,982 INFO  contract.ContractTestUtils (ContractTestUtils.java:skip(424)) - Skipping: blobstores can't distinguish empty directories from files
{code}

For s3a
{code}
-------------------------------------------------------
 T E S T S
-------------------------------------------------------
Java HotSpot(TM) 64-Bit Server VM warning: ignoring option MaxPermSize=768m; support was removed in 8.0
Running org.apache.hadoop.fs.contract.s3a.TestS3AContractMkdir
Tests run: 5, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 31.099 sec - in org.apache.hadoop.fs.contract.s3a.TestS3AContractMkdir
Java HotSpot(TM) 64-Bit Server VM warning: ignoring option MaxPermSize=768m; support was removed in 8.0
Running org.apache.hadoop.fs.contract.s3a.TestS3AContractRootDir
Tests run: 6, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 21.163 sec - in org.apache.hadoop.fs.contract.s3a.TestS3AContractRootDir
Java HotSpot(TM) 64-Bit Server VM warning: ignoring option MaxPermSize=768m; support was removed in 8.0
Running org.apache.hadoop.fs.contract.s3a.TestS3AContractDelete
Tests run: 8, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 49.361 sec - in org.apache.hadoop.fs.contract.s3a.TestS3AContractDelete
Java HotSpot(TM) 64-Bit Server VM warning: ignoring option MaxPermSize=768m; support was removed in 8.0
Running org.apache.hadoop.fs.contract.s3a.TestS3AContractRename
Tests run: 6, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 49.973 sec - in org.apache.hadoop.fs.contract.s3a.TestS3AContractRename
Java HotSpot(TM) 64-Bit Server VM warning: ignoring option MaxPermSize=768m; support was removed in 8.0
Running org.apache.hadoop.fs.contract.s3a.TestS3AContractOpen
Tests run: 6, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 27.859 sec - in org.apache.hadoop.fs.contract.s3a.TestS3AContractOpen
Java HotSpot(TM) 64-Bit Server VM warning: ignoring option MaxPermSize=768m; support was removed in 8.0
Running org.apache.hadoop.fs.contract.s3a.TestS3AContractSeek
Tests run: 10, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 60.267 sec - in org.apache.hadoop.fs.contract.s3a.TestS3AContractSeek
Java HotSpot(TM) 64-Bit Server VM warning: ignoring option MaxPermSize=768m; support was removed in 8.0
Running org.apache.hadoop.fs.contract.s3a.TestS3AContractCreate
Tests run: 6, Failures: 0, Errors: 0, Skipped: 3, Time elapsed: 30.839 sec - in org.apache.hadoop.fs.contract.s3a.TestS3AContractCreate

Results :

Tests run: 47, Failures: 0, Errors: 0, Skipped: 3
{code}
The skipped tests
{code}
org.apache.hadoop.fs.contract.s3a.TestS3AContractCreate-output.txt:2016-01-18 10:57:59,559 INFO  contract.ContractTestUtils (ContractTestUtils.java:skip(424)) - Skipping: Object store allows a file to overwrite a directory
org.apache.hadoop.fs.contract.s3a.TestS3AContractCreate-output.txt:2016-01-18 10:58:03,127 INFO  contract.ContractTestUtils (ContractTestUtils.java:skip(424)) - Skipping: Filesystem is an object store and newly created files are not immediately visible
org.apache.hadoop.fs.contract.s3a.TestS3AContractCreate-output.txt:2016-01-18 10:58:06,419 INFO  contract.ContractTestUtils (ContractTestUtils.java:skip(424)) - Skipping: blobstores can't distinguish empty directories from files
{code}
","19/Jan/16 22:03;raviprak;Thanks for the contribution Matt. I've committed this patch to trunk, branch-2 and branch-2.8.","19/Jan/16 22:50;hudson;FAILURE: Integrated in Hadoop-trunk-Commit #9138 (See [https://builds.apache.org/job/Hadoop-trunk-Commit/9138/])
HADOOP-12696. Add tests for S3FileSystem Contract. Contributed by Matt (raviprak: rev 1acc509b45d58c0eb7e83ea1ba13169410be0dbe)
* hadoop-tools/hadoop-aws/src/test/java/org/apache/hadoop/fs/contract/s3/TestS3ContractSeek.java
* hadoop-tools/hadoop-aws/src/test/java/org/apache/hadoop/fs/contract/s3/S3Contract.java
* hadoop-tools/hadoop-aws/src/test/java/org/apache/hadoop/fs/contract/s3/TestS3ContractRename.java
* hadoop-common-project/hadoop-common/CHANGES.txt
* hadoop-tools/hadoop-aws/src/test/java/org/apache/hadoop/fs/contract/s3/TestS3ContractCreate.java
* hadoop-tools/hadoop-aws/src/test/java/org/apache/hadoop/fs/contract/s3/TestS3ContractMkdir.java
* hadoop-common-project/hadoop-common/src/site/markdown/filesystem/testing.md
* hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3/S3FileSystem.java
* hadoop-tools/hadoop-aws/src/main/java/org/apache/hadoop/fs/s3/S3InputStream.java
* hadoop-tools/hadoop-aws/src/test/java/org/apache/hadoop/fs/contract/s3/TestS3ContractOpen.java
* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/contract/AbstractContractSeekTest.java
* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/contract/ContractOptions.java
* hadoop-tools/hadoop-aws/src/test/java/org/apache/hadoop/fs/contract/s3/TestS3ContractRootDir.java
* hadoop-tools/hadoop-aws/src/test/resources/contract/s3.xml
* hadoop-tools/hadoop-aws/src/test/java/org/apache/hadoop/fs/contract/s3/TestS3ContractDelete.java
","17/Feb/16 19:03;cnauroth;{{TestS3ContractRootDir}} has some failures when running on branch-2.  The tests pass on trunk.  I filed HADOOP-12815 for follow-up.  Could one of the original contributors here please take a look?  Thank you.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
TestTimedOutTestsListener#testThreadDumpAndDeadlocks sometimes times out,HADOOP-12736,12933618,Test,Closed,HADOOP,Hadoop Common,software,omalley,Hadoop Common is the common library for Apache Hadoop.,http://hadoop.apache.org/,Major,Fixed,xiaochen,xiaochen,xiaochen,23/Jan/16 18:51,30/Aug/16 01:19,12/Jan/21 11:55,25/Jan/16 05:02,,,,,2.6.4,2.7.3,2.8.0,3.0.0-alpha1,,,,,,,0,,,"Saw this test failure today, the {{@Test(timeout=500)}} seems too aggressive to me.
{noformat}
testThreadDumpAndDeadlocks(org.apache.hadoop.test.TestTimedOutTestsListener)  Time elapsed: 0.521 sec  <<< ERROR!
java.lang.Exception: test timed out after 500 milliseconds
	at jdk.internal.org.objectweb.asm.ByteVector.putShort(ByteVector.java:147)
	at jdk.internal.org.objectweb.asm.ClassWriter.toByteArray(ClassWriter.java:942)
	at java.lang.invoke.InvokerBytecodeGenerator.generateCustomizedCodeBytes(InvokerBytecodeGenerator.java:727)
	at java.lang.invoke.InvokerBytecodeGenerator.generateCustomizedCode(InvokerBytecodeGenerator.java:618)
	at java.lang.invoke.LambdaForm.compileToBytecode(LambdaForm.java:654)
	at java.lang.invoke.LambdaForm.prepare(LambdaForm.java:635)
	at java.lang.invoke.MethodHandle.<init>(MethodHandle.java:461)
	at java.lang.invoke.BoundMethodHandle.<init>(BoundMethodHandle.java:56)
	at java.lang.invoke.SimpleMethodHandle.<init>(SimpleMethodHandle.java:37)
	at java.lang.invoke.SimpleMethodHandle.make(SimpleMethodHandle.java:41)
	at java.lang.invoke.LambdaForm.createIdentityForms(LambdaForm.java:1778)
	at java.lang.invoke.LambdaForm.<clinit>(LambdaForm.java:1833)
	at java.lang.invoke.DirectMethodHandle.makePreparedLambdaForm(DirectMethodHandle.java:222)
	at java.lang.invoke.DirectMethodHandle.preparedLambdaForm(DirectMethodHandle.java:187)
	at java.lang.invoke.DirectMethodHandle.preparedLambdaForm(DirectMethodHandle.java:176)
	at java.lang.invoke.DirectMethodHandle.make(DirectMethodHandle.java:83)
	at java.lang.invoke.MethodHandles$Lookup.getDirectMethodCommon(MethodHandles.java:1656)
	at java.lang.invoke.MethodHandles$Lookup.getDirectMethodNoSecurityManager(MethodHandles.java:1613)
	at java.lang.invoke.MethodHandles$Lookup.getDirectMethodForConstant(MethodHandles.java:1798)
	at java.lang.invoke.MethodHandles$Lookup.linkMethodHandleConstant(MethodHandles.java:1747)
	at java.lang.invoke.MethodHandleNatives.linkMethodHandleConstant(MethodHandleNatives.java:477)
	at java.lang.UNIXProcess$Platform.get(UNIXProcess.java:155)
	at java.lang.UNIXProcess.<clinit>(UNIXProcess.java:168)
	at java.lang.ProcessImpl.start(ProcessImpl.java:130)
	at java.lang.ProcessBuilder.start(ProcessBuilder.java:1029)
	at org.apache.hadoop.util.Shell.runCommand(Shell.java:868)
	at org.apache.hadoop.util.Shell.run(Shell.java:838)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:1117)
	at org.apache.hadoop.util.Shell.checkIsBashSupported(Shell.java:716)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:705)
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:79)
	at org.apache.hadoop.test.TimedOutTestsListener.buildThreadDump(TimedOutTestsListener.java:98)
	at org.apache.hadoop.test.TimedOutTestsListener.buildThreadDiagnosticString(TimedOutTestsListener.java:73)
	at org.apache.hadoop.test.TimedOutTestsListener.testFailure(TimedOutTestsListener.java:62)
	at org.apache.hadoop.test.TestTimedOutTestsListener.testThreadDumpAndDeadlocks(TestTimedOutTestsListener.java:163)
{noformat}",,aajisaka,hudson,vinodkv,xiaochen,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"23/Jan/16 18:55;xiaochen;HADOOP-12736.01.patch;https://issues.apache.org/jira/secure/attachment/12784029/HADOOP-12736.01.patch",,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,2016-01-23 20:09:02.286,,,false,,,,,,,,,,,,,,,,,9223372036854775807,Reviewed,,,,Thu Aug 25 22:48:10 UTC 2016,,,,,,,"0|i2rw3r:",9223372036854775807,,,,,,,,,,,,,2.6.4,,,,,,,,,,"23/Jan/16 18:55;xiaochen;Patch 1 increases the timeout. The {{timeout}} on tests is to make sure we don't hang the whole job in case any individual test is faulty. No need to make it super aggressive and raise false alarm.","23/Jan/16 20:09;hadoopqa;| (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue} 0m 0s {color} | {color:blue} Docker mode activated. {color} |
| {color:green}+1{color} | {color:green} @author {color} | {color:green} 0m 0s {color} | {color:green} The patch does not contain any @author tags. {color} |
| {color:green}+1{color} | {color:green} test4tests {color} | {color:green} 0m 0s {color} | {color:green} The patch appears to include 1 new or modified test files. {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 8m 49s {color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 8m 0s {color} | {color:green} trunk passed with JDK v1.8.0_66 {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 8m 26s {color} | {color:green} trunk passed with JDK v1.7.0_91 {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green} 0m 17s {color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green} 1m 13s {color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green} 0m 14s {color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green} 2m 2s {color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 0m 58s {color} | {color:green} trunk passed with JDK v1.8.0_66 {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 1m 9s {color} | {color:green} trunk passed with JDK v1.7.0_91 {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 1m 36s {color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 6m 46s {color} | {color:green} the patch passed with JDK v1.8.0_66 {color} |
| {color:green}+1{color} | {color:green} javac {color} | {color:green} 6m 46s {color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 7m 41s {color} | {color:green} the patch passed with JDK v1.7.0_91 {color} |
| {color:green}+1{color} | {color:green} javac {color} | {color:green} 7m 41s {color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green} 0m 16s {color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green} 1m 7s {color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green} 0m 14s {color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} whitespace {color} | {color:green} 0m 0s {color} | {color:green} Patch has no whitespace issues. {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green} 2m 10s {color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 0m 58s {color} | {color:green} the patch passed with JDK v1.8.0_66 {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 1m 7s {color} | {color:green} the patch passed with JDK v1.7.0_91 {color} |
| {color:red}-1{color} | {color:red} unit {color} | {color:red} 7m 30s {color} | {color:red} hadoop-common in the patch failed with JDK v1.8.0_66. {color} |
| {color:green}+1{color} | {color:green} unit {color} | {color:green} 8m 8s {color} | {color:green} hadoop-common in the patch passed with JDK v1.7.0_91. {color} |
| {color:green}+1{color} | {color:green} asflicense {color} | {color:green} 0m 24s {color} | {color:green} Patch does not generate ASF License warnings. {color} |
| {color:black}{color} | {color:black} {color} | {color:black} 70m 22s {color} | {color:black} {color} |
\\
\\
|| Reason || Tests ||
| JDK v1.8.0_66 Failed junit tests | hadoop.metrics2.impl.TestGangliaMetrics |
\\
\\
|| Subsystem || Report/Notes ||
| Docker |  Image:yetus/hadoop:0ca8df7 |
| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12784029/HADOOP-12736.01.patch |
| JIRA Issue | HADOOP-12736 |
| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  findbugs  checkstyle  |
| uname | Linux c0981bad4c5f 3.13.0-36-lowlatency #63-Ubuntu SMP PREEMPT Wed Sep 3 21:56:12 UTC 2014 x86_64 x86_64 x86_64 GNU/Linux |
| Build tool | maven |
| Personality | /testptch/hadoop/patchprocess/precommit/personality/provided.sh |
| git revision | trunk / 99829eb |
| Default Java | 1.7.0_91 |
| Multi-JDK versions |  /usr/lib/jvm/java-8-oracle:1.8.0_66 /usr/lib/jvm/java-7-openjdk-amd64:1.7.0_91 |
| findbugs | v3.0.0 |
| unit | https://builds.apache.org/job/PreCommit-HADOOP-Build/8460/artifact/patchprocess/patch-unit-hadoop-common-project_hadoop-common-jdk1.8.0_66.txt |
| unit test logs |  https://builds.apache.org/job/PreCommit-HADOOP-Build/8460/artifact/patchprocess/patch-unit-hadoop-common-project_hadoop-common-jdk1.8.0_66.txt |
| JDK v1.7.0_91  Test Results | https://builds.apache.org/job/PreCommit-HADOOP-Build/8460/testReport/ |
| modules | C: hadoop-common-project/hadoop-common U: hadoop-common-project/hadoop-common |
| Max memory used | 77MB |
| Powered by | Apache Yetus 0.2.0-SNAPSHOT   http://yetus.apache.org |
| Console output | https://builds.apache.org/job/PreCommit-HADOOP-Build/8460/console |


This message was automatically generated.

","25/Jan/16 04:56;aajisaka;+1, committing this.","25/Jan/16 05:02;aajisaka;Committed this to trunk, branch-2, branch-2.8, branch-2.7, and branch-2.6. Thanks [~xiaochen] for the contribution!","25/Jan/16 05:15;hudson;FAILURE: Integrated in Hadoop-trunk-Commit #9177 (See [https://builds.apache.org/job/Hadoop-trunk-Commit/9177/])
HADOOP-12736. TestTimedOutTestsListener#testThreadDumpAndDeadlocks (aajisaka: rev 643227927a7d7974655627d7e97aae42600692ae)
* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/test/TestTimedOutTestsListener.java
* hadoop-common-project/hadoop-common/CHANGES.txt
","25/Jan/16 06:12;xiaochen;Thanks a lot [~ajisakaa]!","25/Aug/16 22:48;vinodkv;Closing the JIRA as part of 2.7.3 release.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Nightly build+test should run with ""continue on error"" for automated testing after successful build",HADOOP-7678,12524452,Test,Resolved,HADOOP,Hadoop Common,software,omalley,Hadoop Common is the common library for Apache Hadoop.,http://hadoop.apache.org/,Major,Fixed,aw,mattf,mattf,23/Sep/11 18:05,16/Aug/16 16:08,12/Jan/21 11:55,16/Aug/16 16:07,0.20.205.0,0.23.0,,,,,,,,,build,,,,0,,,"It appears that scripts for nightly build in Apache Jenkins will stop after unit testing if any unit tests fail.  Therefore, contribs, schedulers, and some other system-level automated tests don't ever run until the unit tests are clean.  This results in two-phase cleanup of broken builds, which wastes developers' time.  Please change them to run even in the presence of unit test errors, as long as the compile+packaging build successfully.

This jira does not relate to CI builds, which emphasize test-patch execution.",,aw,jeagles,mattf,raviprak,shahrs87,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,2014-04-10 15:59:55.969,,,false,,,,,,,,,,,,,,,,,14485,,,,,Tue Aug 16 16:07:47 UTC 2016,,,,,,,"0|i0aetz:",58676,,,,,,,,,,,,,1.3.0,,,,,,,,,,"20/Nov/12 21:49;mattf;moved target version to 1.2.0 upon publishing 1.1.1 RC.","14/May/13 05:02;mattf;Changed Target Version to 1.3.0 upon release of 1.2.0. Please change to 1.2.1 if you intend to submit a fix for branch-1.2.","10/Apr/14 15:59;shahrs87;Hey,
I was just watching the backlog of 0.23.x version and I came across this jira.
[~mattf]: Is this still an issue for 2.x ?
[~gkesavan]: Are you planning to fix this jira in 0.23.0 as mentioned in this jira ?","23/Apr/14 14:43;jeagles;Nightly builds are currently running against trunk, so re-targeting","16/Aug/16 16:07;aw;This was fixed by switching to Apache Yetus qbt for nightly builds. Closing.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Add custom JUnit4 test runner with configurable timeout,HADOOP-9330,12633757,Test,Resolved,HADOOP,Hadoop Common,software,omalley,Hadoop Common is the common library for Apache Hadoop.,http://hadoop.apache.org/,Major,Fixed,stevel@apache.org,stevel@apache.org,stevel@apache.org,23/Feb/13 18:51,29/Jun/16 10:54,12/Jan/21 11:55,29/Jun/16 03:41,3.0.0-alpha1,,,,3.0.0-alpha1,,,,,,test,,,,0,,,"HADOOP-9112 has added a requirement for all new test methods to declare a timeout, so that jenkins/maven builds will have better information on a timeout.

Hard coding timeouts into tests is dangerous as it will generate spurious failures on slower machines/networks and when debugging a test.

I propose providing a custom JUnit4 test runner that test cases can declare as their test runner; this can provide timeouts specified at run-time, rather than in-source.",,atm,aw,cdouglas,cmccabe,cos,cutting,Fan04290,hudson,jlowe,stevel@apache.org,tgraves,tucu00,vicaya,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,HADOOP-12439,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"11/Mar/13 19:09;stevel@apache.org;HADOOP-9330-timeouts-1.patch;https://issues.apache.org/jira/secure/attachment/12573149/HADOOP-9330-timeouts-1.patch",,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,2013-02-23 20:49:07.725,,,false,,,,,,,,,,,,,,,,,314252,,,,,Wed Jun 29 10:54:10 UTC 2016,,,,,,,"0|i1i89b:",314597,,,,,,,,,,,,,,,,,,,,,,,"23/Feb/13 18:56;stevel@apache.org;Discussions with the Maven Surefire team (https://issues.apache.org/jira/browse/HADOOP-9112) imply that we can use the {{@RunWith}} attribute in a test class to define a custom test runner for it.

This means we can
# Write our own test runner that picks up a default timeout from a system property.
# Define a base test class, {{HadoopTestBase}}, that declares its use of this.
# Set the maven build up to propagate a timeout via a system property.
# Have jenkins choose a timeout appropriate to it.

Doing this will obviate the need to place brittle test timeouts in source, and be easy to retrofit to existing test classes. 

Assuming all future test cases get built off a new base class (possibly with tuned YarnTestBase, HdfsTestBase classes), the base classes would have to go back into branch-1 if there was any goal of backporting new tests from trunk. Unless Ant can be set up to switch to the new test runner, the {{@RunWith}} attribute would have to stripped from the backported test cases.","23/Feb/13 20:49;cos;As I have commented elsewhere setting a time out in the runtime can be achievable through {{surefire.timeout}} property, can it not?","24/Feb/13 00:31;vicaya;bq. setting a time out in the runtime can be achievable through surefire.timeout property, can it not?

surefire.timeout is a test process timeout or per test class if fork mode is always, not _per_ _test_, which is the rationale for HADOOP-9112 in the first place.

bq. we can use the @RunWith attribute in a test class to define a custom test runner for it.

There is no need to use a custom test runner. org.junit.rules.Timeout is what you want. We can create a common base test class like this.
{code}
public class TestBase {
  @Rule public Timeout defaultTimeout = new Timeout(Integer.parseInt(
      System.getProperty(""test.default.timeout"", 100000)));
  ...
}
{code}","24/Feb/13 04:34;cos;Avoiding subclassing of a common test class is one of the main reason people are migrating away from Junit3, IMO. Do we really want to enforce subclassing?

As for 'per class' vs 'per testcase': if your test case has timed out then it will terminate the whole class run, won't it?","24/Feb/13 05:18;vicaya;bq. Do we really want to enforce subclassing?

No, you can use the @Test(timeout=seconds) just fine. You can add the default per test timeout rule to any test class as well. TestBase with a per test default timeout is just a convenience.

bq. if your test case has timed out then it will terminate the whole class run, won't it?

Please read the comments on HADOOP-9112 to find out why this is not desirable.","24/Feb/13 05:43;cos;Oh right... this is {{@Rule}}. Sorry, I misread your comment. Yes, this sounds like a proper way to go. Plus, we need to lose the enforcement in the {{test-patch}} - it is no go in the first place.","24/Feb/13 16:56;stevel@apache.org;@Luke: if that's all we need to do, that's all we need.

# We should be able to put this base test case into hadoop-common test & have it imported by the other projects -which all import the -test JAR.
# What name & package?

Konstantin: I thought the switch from JUnit3 to JUnit4 was driven by the goal of adding beforeclass/afterclass methods and so setup/teardown miniclusters only once per test class, not per test.

The added benefit we get is being able to skip, not just in attributes, but by raising {{AssumptionViolatedException}}, either from the {{assume()}}, method, or in your own code. I'm using that in some of my tests already.","24/Feb/13 22:07;tucu00;If using a @Rule/MethodRule Timeout I'd suggest 2 additional things:

* Have a @TestTimeout annotation as well to be able to set a timeout other than the default for particular test method.
* Instead having a system property set the default timeout, lets specify a timeout.ratio, with default 1, by doing this the ratio can be also applied to tests that have a custom timeout","24/Feb/13 22:55;cos;Alejandro, the functionality of {{@TestTimeout}} exists in JUnit4. It is done through {{@Test\{timeout=<number>\}}} as  far as I remember.","24/Feb/13 22:59;cos;bq. Konstantin: I thought the switch from JUnit3 to JUnit4 was driven by the goal of adding beforeclass/afterclass methods
Partially. However, the most pain has been caused by the need to subclass {{TestCase}} all the time. Oftentimes it blocked having a common pieces of the code being isolated in the same superclass for later use in the children, IIRC.","25/Feb/13 10:58;stevel@apache.org;@Konstantin: I see. Having a std test base with a timeout rule doesn't stop this provided all test cases add the same timeout rule. We could isolate the timeout extraction logic into a static method in the planned base class; other test cases could use that an their own {{@Rule}} declaration","25/Feb/13 17:05;tucu00;Cos, {{@Test{timeout = <> )}} exist, yes, if we can tweak that timeout to take a global ratio into account then we are good.

Agree with Steve that subclassing should be a convenience, not a requirement. If you subclass you get the @Rule setting for free, otherwise you have to do it yourself.

","11/Mar/13 19:09;stevel@apache.org;first cut: test class (without any tests underneath to verify that it works)","11/Mar/13 19:45;hadoopqa;{color:green}+1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12573149/HADOOP-9330-timeouts-1.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 1 new or modified test files.

    {color:green}+1 tests included appear to have a timeout.{color}

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  The javadoc tool did not generate any warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:green}+1 core tests{color}.  The patch passed unit tests in hadoop-common-project/hadoop-common.

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HADOOP-Build/2310//testReport/
Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/2310//console

This message is automatically generated.","25/Mar/13 17:35;revans2;The concept seems fine, but the Timeout rule and @Test(timeout=XXX) are not aware of each other.  This means that the effective timeout of any test is which ever is smaller.  I don't think that this is a real problem, just that the comments and the name of the member variable defaultTimout is slightly misleading. I also don't know if we have any tests that are intended to run for more than 100s.  If so they will always timeout after 100s unless they do not extend the HadoopBase, or we set the default to be higher.

Also, I don't know if there is anything we can do about this or not, but when we use both timeouts, the Timeout rule's backtrace, when it fails is close to useless.

{code}
testSleep(org.apache.hadoop.test.TestSomething)  Time elapsed: 1091 sec  <<< ERROR!
java.lang.Exception: test timed out after 1000 milliseconds
        at java.lang.Object.wait(Native Method)
        at java.lang.Thread.join(Thread.java:1194)
        at org.junit.internal.runners.statements.FailOnTimeout.evaluate(FailOnTimeout.java:36)
        at org.junit.internal.runners.statements.FailOnTimeout$1.run(FailOnTimeout.java:28)
{code}

It simply says that the code that ""timed out"" was a thread waiting for the actual test to finish running :) This is because there are actually two threads monitoring the test, instead of just one.

I realize that a lot of my complaints are perhaps things that need to just be addressed by the JUnit, I just want us to be fully aware of them as we go into this and document things appropriately, so we know what is happening when issues arise.","25/Mar/13 18:45;stevel@apache.org;I'm happy with having a very long default timeout -as it's purpose is to stop Jenkins hanging.

I personally think having any timeouts in individual tests is incredibly brittle for testing on different machines, so people should not be explicitly setting timeouts in tests except in specific cases, where somehow they can't just set the test runner properties to change the global default.

# What default do you think the base class should have? 100s is <2 minutes, which should be enough for most tests -are there any which regularly come close to that time on anyone's system? (that's excluding minicluster setup/teardown)/
# What documentation are you thinking of? Is there something on writing and running tests? If not, it may be time.","25/Mar/13 19:28;revans2;I agree that there should be something about writing and running tests, but I am not aware of it either.  I was thinking of just the javadocs for HadoopTestBase, but a dedicated wiki page or a subsection of HowToContribute would probably be better.  I agree that having timeout= in the code is brittle, and we probably want to start removing it once this goes in (along with the changes to test-patch.sh).

But in a follow on JIRA I was thinking we probably could support something similar to what [~vicaya] proposed.  It should not be that hard to add in our own timeout test runner that can look for an @Test annotation with a timeout, output a warning about the timeout, and then allow JUnit to run with that timeout.  We could also provide an @Timeout annotation that would let us specify a timeout multiplier that is X times the configured base timeout.  That way we can keep a 100s timeout and adjust it for tests that do take longer.

I am not tied to the idea though, and if it feels like too much work compared simply upping the default to something like 600s works we could do that instead. ","26/Apr/15 00:15;hadoopqa;\\
\\
| (/) *{color:green}+1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | pre-patch |   5m  6s | Pre-patch trunk compilation is healthy. |
| {color:green}+1{color} | @author |   0m  0s | The patch does not contain any @author tags. |
| {color:green}+1{color} | tests included |   0m  0s | The patch appears to include 1 new or modified test files. |
| {color:green}+1{color} | whitespace |   0m  0s | The patch has no lines that end in whitespace. |
| {color:green}+1{color} | javac |   7m 24s | There were no new javac warning messages. |
| {color:green}+1{color} | release audit |   0m 19s | The applied patch does not increase the total number of release audit warnings. |
| {color:green}+1{color} | checkstyle |   5m 25s | There were no new checkstyle issues. |
| {color:green}+1{color} | install |   1m 29s | mvn install still works. |
| {color:green}+1{color} | eclipse:eclipse |   0m 32s | The patch built with eclipse:eclipse. |
| {color:green}+1{color} | findbugs |   1m 38s | The patch does not introduce any new Findbugs (version 2.0.3) warnings. |
| {color:green}+1{color} | common tests |  23m  4s | Tests passed in hadoop-common. |
| | |  45m  0s | |
\\
\\
|| Subsystem || Report/Notes ||
| Patch URL | http://issues.apache.org/jira/secure/attachment/12573149/HADOOP-9330-timeouts-1.patch |
| Optional Tests | javac unit findbugs checkstyle |
| git revision | trunk / a00e001 |
| hadoop-common test log | https://builds.apache.org/job/PreCommit-HADOOP-Build/6180/artifact/patchprocess/testrun_hadoop-common.txt |
| Test Results | https://builds.apache.org/job/PreCommit-HADOOP-Build/6180/testReport/ |
| Console output | https://builds.apache.org/job/PreCommit-HADOOP-Build/6180/console |


This message was automatically generated.","28/Jun/16 14:51;hadoopqa;| (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 15s{color} | {color:blue} Docker mode activated. {color} |
| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |
| {color:green}+1{color} | {color:green} test4tests {color} | {color:green}  0m  0s{color} | {color:green} The patch appears to include 1 new or modified test files. {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  6m 56s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green}  6m 40s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 24s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  0m 59s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green}  0m 14s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  1m 24s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 48s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  0m 39s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green}  8m 23s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javac {color} | {color:green}  8m 23s{color} | {color:green} the patch passed {color} |
| {color:orange}-0{color} | {color:orange} checkstyle {color} | {color:orange}  0m 24s{color} | {color:orange} hadoop-common-project/hadoop-common: The patch generated 5 new + 0 unchanged - 0 fixed = 5 total (was 0) {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  0m 56s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green}  0m 14s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  1m 41s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 50s{color} | {color:green} the patch passed {color} |
| {color:red}-1{color} | {color:red} unit {color} | {color:red} 22m 33s{color} | {color:red} hadoop-common in the patch failed. {color} |
| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 21s{color} | {color:green} The patch does not generate ASF License warnings. {color} |
| {color:black}{color} | {color:black} {color} | {color:black} 55m 11s{color} | {color:black} {color} |
\\
\\
|| Reason || Tests ||
| Failed junit tests | hadoop.security.TestGroupsCaching |
|   | hadoop.ha.TestZKFailoverController |
| Timed out junit tests | org.apache.hadoop.http.TestHttpServer |
\\
\\
|| Subsystem || Report/Notes ||
| Docker |  Image:yetus/hadoop:85209cc |
| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12573149/HADOOP-9330-timeouts-1.patch |
| JIRA Issue | HADOOP-9330 |
| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  findbugs  checkstyle  |
| uname | Linux cf96a726ac58 3.13.0-36-lowlatency #63-Ubuntu SMP PREEMPT Wed Sep 3 21:56:12 UTC 2014 x86_64 x86_64 x86_64 GNU/Linux |
| Build tool | maven |
| Personality | /testptch/hadoop/patchprocess/precommit/personality/provided.sh |
| git revision | trunk / 23c3ff8 |
| Default Java | 1.8.0_91 |
| findbugs | v3.0.0 |
| checkstyle | https://builds.apache.org/job/PreCommit-HADOOP-Build/9887/artifact/patchprocess/diff-checkstyle-hadoop-common-project_hadoop-common.txt |
| unit | https://builds.apache.org/job/PreCommit-HADOOP-Build/9887/artifact/patchprocess/patch-unit-hadoop-common-project_hadoop-common.txt |
|  Test Results | https://builds.apache.org/job/PreCommit-HADOOP-Build/9887/testReport/ |
| modules | C: hadoop-common-project/hadoop-common U: hadoop-common-project/hadoop-common |
| Console output | https://builds.apache.org/job/PreCommit-HADOOP-Build/9887/console |
| Powered by | Apache Yetus 0.4.0-SNAPSHOT   http://yetus.apache.org |


This message was automatically generated.

","29/Jun/16 03:41;aw;+1 committed to trunk.

Thanks!","29/Jun/16 03:55;hudson;SUCCESS: Integrated in Hadoop-trunk-Commit #10030 (See [https://builds.apache.org/job/Hadoop-trunk-Commit/10030/])
HADOOP-9330. Add custom JUnit4 test runner with configurable timeout (aw: rev 610363559135a725499cf46e256424d16bec98a3)
* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/test/HadoopTestBase.java
","29/Jun/16 10:54;stevel@apache.org;hey,. thank you for reviewing my work. Now, I have a few more. Why not start with YARN-679, which is trying to do a robust service launcher to replace the pool of different ones we have today?",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
fix coverage  org.apache.hadoop.net,HADOOP-9321,12633341,Test,Resolved,HADOOP,Hadoop Common,software,omalley,Hadoop Common is the common library for Apache Hadoop.,http://hadoop.apache.org/,Major,Fixed,iveselovsky,aleksgor,aleksgor,21/Feb/13 07:29,29/Jun/16 03:55,12/Jan/21 11:55,29/Jun/16 03:37,2.3.0,3.0.0-alpha1,,,3.0.0-alpha1,,,,,,,,,,0,,,"fix coverage  org.apache.hadoop.net
HADOOP-9321-trunk.patch patch for trunk, branch-2, branch-0.23",,aklochkov,aleksgor,aw,hudson,iveselovsky,mitdesai,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"03/Apr/13 11:16;aleksgor;HADOOP-9321-trunk-a.patch;https://issues.apache.org/jira/secure/attachment/12576768/HADOOP-9321-trunk-a.patch","07/Oct/13 18:14;iveselovsky;HADOOP-9321-trunk-b.patch;https://issues.apache.org/jira/secure/attachment/12607200/HADOOP-9321-trunk-b.patch","29/Oct/13 15:09;iveselovsky;HADOOP-9321-trunk-d.patch;https://issues.apache.org/jira/secure/attachment/12610811/HADOOP-9321-trunk-d.patch","21/Feb/13 07:33;aleksgor;HADOOP-9321-trunk.patch;https://issues.apache.org/jira/secure/attachment/12570273/HADOOP-9321-trunk.patch",,,,,,,,,,,,,,,,,,,,4.0,,,,,,,,,,,,,,,,,,,,2013-02-21 09:25:29.834,,,false,,,,,,,,,,,,,,,,,313837,,,,,Wed Jun 29 03:55:24 UTC 2016,,,,,,,"0|i1i5p3:",314182,,,,,,,,,,,,,,,,,,,,,,,"21/Feb/13 09:25;hadoopqa;{color:green}+1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12570273/HADOOP-9321-trunk.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 1 new or modified test files.

  {color:red}-1 one of tests included doesn't have a timeout.{color}

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  The javadoc tool did not generate any warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:green}+1 core tests{color}.  The patch passed unit tests in hadoop-common-project/hadoop-common.

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HADOOP-Build/2217//testReport/
Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/2217//console

This message is automatically generated.","03/Apr/13 11:17;aleksgor;patch updated 
HADOOP-9321-trunk-a.patch patch for trunk, branch-2, branch-0.23","03/Apr/13 11:20;aleksgor;patch updated 
HADOOP-9321-trunk-b.patch patch for trunk, branch-2, branch-0.23","03/Apr/13 11:24;aleksgor;Comment about HADOOP-9321-trunk-b.patch is wrong .
true patch HADOOP-9321-trunk-a.patch ","03/Apr/13 19:41;hadoopqa;{color:green}+1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12576768/HADOOP-9321-trunk-a.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 1 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  The javadoc tool did not generate any warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:green}+1 core tests{color}.  The patch passed unit tests in hadoop-common-project/hadoop-common.

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HADOOP-Build/2405//testReport/
Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/2405//console

This message is automatically generated.","07/Oct/13 18:14;iveselovsky;Patch updated. It applies to both ""branch-2"" and ""trunk"".","07/Oct/13 18:55;hadoopqa;{color:green}+1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12607200/HADOOP-9321-trunk-b.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 1 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  The javadoc tool did not generate any warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:green}+1 core tests{color}.  The patch passed unit tests in hadoop-common-project/hadoop-common.

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HADOOP-Build/3189//testReport/
Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/3189//console

This message is automatically generated.","24/Oct/13 16:11;mitdesai;Ivan,
I reviewed the patch and here are some concerns that I have.
1) I see that you have imported everything under static.org.junit.Assert. Can we not just import only what we need? That is: assertFalse, assertTrue, assertSame & assertEquals. I tried with these changes and the tests works fine.

2) The comments describing the testSocksSocketFactory() and testStandardSocketFactory() are same. Can you change the one for the testStandardSocketFactory() so that the comments explains the tests properly?

3) In start(), the thread sleeps until the serverThread is running. Will the thread sleep forever if the serverThread does not start at all or dies instantly after it is created? I am not sure if the timeout helps overcome this problem.","29/Oct/13 15:08;iveselovsky;Hi, Mit, the patch updated.
itens 1),2) fixed.
Item 3) fixed by adding a timeout and checking of error absence during the ""server"" startup.
Besides, the following is fixed:
a) added check for exception in server thread;
b) server start method in not ""@Before"" since the server thread is needed only for 2 testcases of 4.
c) server runnable class made static and renamed accordingly to its type.
d) server thread is now joined in ""@After""","29/Oct/13 15:21;mitdesai;Thanks Ivan for the patch update. It looks fine to me.
+1","29/Oct/13 15:32;hadoopqa;{color:green}+1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12610809/HADOOP-9321-trunk-c.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 1 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  The javadoc tool did not generate any warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:green}+1 core tests{color}.  The patch passed unit tests in hadoop-common-project/hadoop-common.

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HADOOP-Build/3252//testReport/
Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/3252//console

This message is automatically generated.","29/Oct/13 15:45;hadoopqa;{color:green}+1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12610811/HADOOP-9321-trunk-d.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 1 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  The javadoc tool did not generate any warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:green}+1 core tests{color}.  The patch passed unit tests in hadoop-common-project/hadoop-common.

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HADOOP-Build/3253//testReport/
Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/3253//console

This message is automatically generated.","02/May/15 20:56;hadoopqa;\\
\\
| (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | pre-patch |   5m  8s | Pre-patch trunk compilation is healthy. |
| {color:green}+1{color} | @author |   0m  0s | The patch does not contain any @author tags. |
| {color:green}+1{color} | tests included |   0m  0s | The patch appears to include 1 new or modified test files. |
| {color:green}+1{color} | javac |   7m 27s | There were no new javac warning messages. |
| {color:green}+1{color} | release audit |   0m 19s | The applied patch does not increase the total number of release audit warnings. |
| {color:green}+1{color} | checkstyle |   1m  3s | There were no new checkstyle issues. |
| {color:red}-1{color} | whitespace |   0m  0s | The patch has 5  line(s) that end in whitespace. Use git apply --whitespace=fix. |
| {color:green}+1{color} | install |   1m 31s | mvn install still works. |
| {color:green}+1{color} | eclipse:eclipse |   0m 32s | The patch built with eclipse:eclipse. |
| {color:green}+1{color} | findbugs |   1m 39s | The patch does not introduce any new Findbugs (version 2.0.3) warnings. |
| {color:green}+1{color} | common tests |  22m 40s | Tests passed in hadoop-common. |
| | |  40m 24s | |
\\
\\
|| Subsystem || Report/Notes ||
| Patch URL | http://issues.apache.org/jira/secure/attachment/12610811/HADOOP-9321-trunk-d.patch |
| Optional Tests | javac unit findbugs checkstyle |
| git revision | trunk / 6ae2a0d |
| whitespace | https://builds.apache.org/job/PreCommit-HADOOP-Build/6421/artifact/patchprocess/whitespace.txt |
| hadoop-common test log | https://builds.apache.org/job/PreCommit-HADOOP-Build/6421/artifact/patchprocess/testrun_hadoop-common.txt |
| Test Results | https://builds.apache.org/job/PreCommit-HADOOP-Build/6421/testReport/ |
| Java | 1.7.0_55 |
| uname | Linux asf907.gq1.ygridcore.net 3.13.0-36-lowlatency #63-Ubuntu SMP PREEMPT Wed Sep 3 21:56:12 UTC 2014 x86_64 x86_64 x86_64 GNU/Linux |
| Console output | https://builds.apache.org/job/PreCommit-HADOOP-Build/6421/console |


This message was automatically generated.","28/Jun/16 14:35;hadoopqa;| (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 19s{color} | {color:blue} Docker mode activated. {color} |
| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |
| {color:green}+1{color} | {color:green} test4tests {color} | {color:green}  0m  0s{color} | {color:green} The patch appears to include 1 new or modified test files. {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  6m 56s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green}  6m 51s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 22s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  0m 57s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green}  0m 12s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  1m 24s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 44s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  0m 37s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green}  6m 24s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javac {color} | {color:green}  6m 24s{color} | {color:green} the patch passed {color} |
| {color:orange}-0{color} | {color:orange} checkstyle {color} | {color:orange}  0m 22s{color} | {color:orange} hadoop-common-project/hadoop-common: The patch generated 5 new + 3 unchanged - 1 fixed = 8 total (was 4) {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  0m 51s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green}  0m 13s{color} | {color:green} the patch passed {color} |
| {color:red}-1{color} | {color:red} whitespace {color} | {color:red}  0m  0s{color} | {color:red} The patch has 4 line(s) that end in whitespace. Use git apply --whitespace=fix. {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  1m 26s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 45s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} unit {color} | {color:green}  7m 59s{color} | {color:green} hadoop-common in the patch passed. {color} |
| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 21s{color} | {color:green} The patch does not generate ASF License warnings. {color} |
| {color:black}{color} | {color:black} {color} | {color:black} 38m  7s{color} | {color:black} {color} |
\\
\\
|| Subsystem || Report/Notes ||
| Docker |  Image:yetus/hadoop:85209cc |
| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12610811/HADOOP-9321-trunk-d.patch |
| JIRA Issue | HADOOP-9321 |
| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  findbugs  checkstyle  |
| uname | Linux ebcc3c693083 3.13.0-36-lowlatency #63-Ubuntu SMP PREEMPT Wed Sep 3 21:56:12 UTC 2014 x86_64 x86_64 x86_64 GNU/Linux |
| Build tool | maven |
| Personality | /testptch/hadoop/patchprocess/precommit/personality/provided.sh |
| git revision | trunk / 23c3ff8 |
| Default Java | 1.8.0_91 |
| findbugs | v3.0.0 |
| checkstyle | https://builds.apache.org/job/PreCommit-HADOOP-Build/9888/artifact/patchprocess/diff-checkstyle-hadoop-common-project_hadoop-common.txt |
| whitespace | https://builds.apache.org/job/PreCommit-HADOOP-Build/9888/artifact/patchprocess/whitespace-eol.txt |
|  Test Results | https://builds.apache.org/job/PreCommit-HADOOP-Build/9888/testReport/ |
| modules | C: hadoop-common-project/hadoop-common U: hadoop-common-project/hadoop-common |
| Console output | https://builds.apache.org/job/PreCommit-HADOOP-Build/9888/console |
| Powered by | Apache Yetus 0.4.0-SNAPSHOT   http://yetus.apache.org |


This message was automatically generated.

","29/Jun/16 03:37;aw;+1 committed to trunk.

Thanks!","29/Jun/16 03:55;hudson;SUCCESS: Integrated in Hadoop-trunk-Commit #10030 (See [https://builds.apache.org/job/Hadoop-trunk-Commit/10030/])
HADOOP-9321. fix coverage org.apache.hadoop.net (Ivan A. Veselovsky via (aw: rev 1faaa6907852b193cc5ac34f25d6ae41a1f10e61)
* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/ipc/TestSocketFactory.java
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"TestDNS#{testDefaultDnsServer,testNullDnsServer} failed intermittently",HADOOP-13101,12965313,Test,Open,HADOOP,Hadoop Common,software,omalley,Hadoop Common is the common library for Apache Hadoop.,http://hadoop.apache.org/,Major,,,xyao,xyao,05/May/16 16:03,17/May/16 04:21,12/Jan/21 11:55,,,,,,,,,,,,test,,,,0,,,"The test failed intermittently on [Jenkins|https://builds.apache.org/job/PreCommit-HDFS-Build/15366/artifact/patchprocess/patch-unit-hadoop-common-project_hadoop-common-jdk1.8.0_91.txt] with the following error.

{code}
Failed tests: 
  TestDNS.testDefaultDnsServer:134 
Expected: is ""dd12a7999c74""
     but: was ""localhost""
{code}

",,andrew.wang,arp,aw,demongaorui,iwasakims,junping_du,kihwal,liuml07,stevel@apache.org,xiaochen,xyao,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,2016-05-05 18:59:24.153,,,false,,,,,,,,,,,,,,,,,9223372036854775807,,,,,Tue May 17 04:21:08 UTC 2016,,,,,,,"0|i2x7rj:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,"05/May/16 18:59;liuml07;Thanks for filing this. I see {{TestDNS#testNullDnsServer}} is also failing (e.g.[PreCommit-HADOOP-Build/9285|https://builds.apache.org/job/PreCommit-HADOOP-Build/9285/testReport/org.apache.hadoop.net/TestDNS/testNullDnsServer/]), and seems related. Hope we can fix them together.

Error Message
{code}
Expected: is ""localhost""
     but: was ""8b7e00deed59""
{code}

Stacktrace
{code}
java.lang.AssertionError: 
Expected: is ""localhost""
     but: was ""8b7e00deed59""
	at org.hamcrest.MatcherAssert.assertThat(MatcherAssert.java:20)
	at org.junit.Assert.assertThat(Assert.java:865)
	at org.junit.Assert.assertThat(Assert.java:832)
	at org.apache.hadoop.net.TestDNS.testNullDnsServer(TestDNS.java:124)
{code}
Standard Output
{code}
2016-05-05 06:36:16,013 WARN  net.DNS (DNS.java:getHosts(268)) - Unable to determine hostname for interface lo
{code}","10/May/16 07:59;demongaorui;Hi, [~liuml07], [~xyao]. Which branch does these errors happened in? I run TestDNS in trunk branch, and all the tests passed.","10/May/16 14:05;xyao;[~demongaorui], this is from recent Jenkins run on trunk. It does not 100% repro on local test. ","11/May/16 20:49;liuml07;Hi [~demongaorui], please find this Jenkins pre-commit run (happend within ~12 hours) for detailed logs: https://builds.apache.org/job/PreCommit-HADOOP-Build/9361/testReport/org.apache.hadoop.net/TestDNS/testDefaultDnsServer/

Echo to [~xyao]'s comment, this bug is intermittent unit test failure and may not be reproduced consistently as it's maybe platform-, configuration-, and timing-dependent.","12/May/16 09:49;stevel@apache.org;I think it's one of the build machines","17/May/16 04:21;aw;I'm not sure how it can be one of the build machines when we run all of our unit tests for precommit in docker containers....",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
TestConfiguration currently has no tests for direct setter methods,HADOOP-8434,12558038,Test,Resolved,HADOOP,Hadoop Common,software,omalley,Hadoop Common is the common library for Apache Hadoop.,http://hadoop.apache.org/,Major,Fixed,phatak.dev,qwertymaniac,qwertymaniac,25/May/12 06:09,13/May/16 05:15,12/Jan/21 11:55,03/Jul/12 18:29,3.0.0-alpha1,,,,3.0.0-alpha1,,,,,,test,,,,0,newbie,,"Jan van der Lugt noticed this on HADOOP-8415.

bq. Just FYI, there are no tests for setFloat, setInt, setLong, etc. Might be better to add all of those at the same time.

Would be good to have (coverage-wise first, regression-wise second) explicit tests for the each of the setter methods, although other projects' tests do test this extensively.",,eli2,hudson,phatak.dev,qwertymaniac,sureshms,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"30/May/12 07:37;phatak.dev;HADOOP-8434-1.patch;https://issues.apache.org/jira/secure/attachment/12530175/HADOOP-8434-1.patch","03/Jul/12 18:25;sureshms;HADOOP-8434-2.patch;https://issues.apache.org/jira/secure/attachment/12534879/HADOOP-8434-2.patch","26/May/12 09:19;phatak.dev;HADOOP-8434.patch;https://issues.apache.org/jira/secure/attachment/12529853/HADOOP-8434.patch",,,,,,,,,,,,,,,,,,,,,3.0,,,,,,,,,,,,,,,,,,,,2012-05-26 09:19:39.445,,,false,,,,,,,,,,,,,,,,,246875,Reviewed,,,,Thu Jul 05 14:03:11 UTC 2012,,,,,,,"0|i07to7:",43574,,,,,,,,,,,,,,,,,,,,,,,"26/May/12 09:19;phatak.dev;Added test cases for explicit set methods.","29/May/12 08:48;hadoopqa;-1 overall.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12529853/HADOOP-8434.patch
  against trunk revision .

    +1 @author.  The patch does not contain any @author tags.

    +1 tests included.  The patch appears to include 1 new or modified test files.

    +1 javac.  The applied patch does not increase the total number of javac compiler warnings.

    +1 javadoc.  The javadoc tool did not generate any warning messages.

    +1 eclipse:eclipse.  The patch built with eclipse:eclipse.

    +1 findbugs.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    +1 release audit.  The applied patch does not increase the total number of release audit warnings.

    -1 core tests.  The patch failed these unit tests in hadoop-common-project/hadoop-common:

                  org.apache.hadoop.fs.viewfs.TestViewFsTrash

    +1 contrib tests.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HADOOP-Build/1045//testReport/
Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/1045//console

This message is automatically generated.","30/May/12 07:11;qwertymaniac;Thanks for the patch. I have just one code-style related nit:

bq. assertEquals(value,configuration.getBoolean(""value"",false));

As seen in the above example, please provide spaces between arguments as per the Sun coding guidelines we follow for Apache Hadoop.

Otherwise, looks good. +1 pending new patch and a jenkins re-run.","30/May/12 07:37;phatak.dev;updated patch according to the code-style convention","30/May/12 08:03;hadoopqa;+1 overall.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12530175/HADOOP-8434-1.patch
  against trunk revision .

    +1 @author.  The patch does not contain any @author tags.

    +1 tests included.  The patch appears to include 1 new or modified test files.

    +1 javac.  The applied patch does not increase the total number of javac compiler warnings.

    +1 javadoc.  The javadoc tool did not generate any warning messages.

    +1 eclipse:eclipse.  The patch built with eclipse:eclipse.

    +1 findbugs.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    +1 release audit.  The applied patch does not increase the total number of release audit warnings.

    +1 core tests.  The patch passed unit tests in hadoop-common-project/hadoop-common.

    +1 contrib tests.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HADOOP-Build/1056//testReport/
Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/1056//console

This message is automatically generated.","03/Jul/12 18:26;sureshms;Made a minor update to the patch - line was more than 80 columns and removed unnecessary IOExceptions (throws in the existing code and not in the code from the patch).","03/Jul/12 18:29;sureshms;I committed the patch. Thank you Madhukara for providing the patch.","04/Jul/12 19:56;hudson;Integrated in Hadoop-Common-trunk-Commit #2422 (See [https://builds.apache.org/job/Hadoop-Common-trunk-Commit/2422/])
    HADOOP-8434. Add tests for Configuration setter methods. Contributed by Madhukara Phatak. (Revision 1356864)

     Result = SUCCESS
suresh : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1356864
Files : 
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/CHANGES.txt
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/conf/TestConfiguration.java
","04/Jul/12 19:58;hudson;Integrated in Hadoop-Hdfs-trunk-Commit #2490 (See [https://builds.apache.org/job/Hadoop-Hdfs-trunk-Commit/2490/])
    HADOOP-8434. Add tests for Configuration setter methods. Contributed by Madhukara Phatak. (Revision 1356864)

     Result = SUCCESS
suresh : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1356864
Files : 
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/CHANGES.txt
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/conf/TestConfiguration.java
","04/Jul/12 20:47;hudson;Integrated in Hadoop-Mapreduce-trunk-Commit #2439 (See [https://builds.apache.org/job/Hadoop-Mapreduce-trunk-Commit/2439/])
    HADOOP-8434. Add tests for Configuration setter methods. Contributed by Madhukara Phatak. (Revision 1356864)

     Result = FAILURE
suresh : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1356864
Files : 
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/CHANGES.txt
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/conf/TestConfiguration.java
","05/Jul/12 11:39;hudson;Integrated in Hadoop-Hdfs-trunk #1094 (See [https://builds.apache.org/job/Hadoop-Hdfs-trunk/1094/])
    HADOOP-8434. Add tests for Configuration setter methods. Contributed by Madhukara Phatak. (Revision 1356864)

     Result = FAILURE
suresh : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1356864
Files : 
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/CHANGES.txt
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/conf/TestConfiguration.java
","05/Jul/12 14:03;hudson;Integrated in Hadoop-Mapreduce-trunk #1127 (See [https://builds.apache.org/job/Hadoop-Mapreduce-trunk/1127/])
    HADOOP-8434. Add tests for Configuration setter methods. Contributed by Madhukara Phatak. (Revision 1356864)

     Result = SUCCESS
suresh : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1356864
Files : 
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/CHANGES.txt
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/conf/TestConfiguration.java
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
enhance unit-test coverage of class org.apache.hadoop.security.NetgroupCache,HADOOP-9200,12627230,Test,Patch Available,HADOOP,Hadoop Common,software,omalley,Hadoop Common is the common library for Apache Hadoop.,http://hadoop.apache.org/,Major,,iveselovsky,iveselovsky,iveselovsky,11/Jan/13 18:48,12/May/16 21:16,12/Jan/21 11:55,,0.23.6,2.0.3-alpha,3.0.0-alpha1,,,,,,,,,,,,0,BB2015-05-TBR,,The class org.apache.hadoop.security.NetgroupCache has poor unit-test coverage. Enhance it.,,aklochkov,iveselovsky,kihwal,schu,tgraves,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,HADOOP-9436,,,,,,,"28/Mar/13 10:06;iveselovsky;HADOOP-9200-trunk--N2.patch;https://issues.apache.org/jira/secure/attachment/12575855/HADOOP-9200-trunk--N2.patch","11/Jan/13 19:11;iveselovsky;HADOOP-9200-trunk.patch;https://issues.apache.org/jira/secure/attachment/12564475/HADOOP-9200-trunk.patch",,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,2013-01-14 10:55:36.111,,,false,,,,,,,,,,,,,,,,,304000,,,,,Thu May 12 21:16:25 UTC 2016,,,,,,,"0|i17he7:",251787,,,,,,,,,,,,,,,,,,,,,,,"11/Jan/13 19:11;iveselovsky;The patch HADOOP-9200 is applicable to all 3 branches: trunk, branch-2, branch-0.23.","14/Jan/13 10:55;hadoopqa;{color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12564475/HADOOP-9200-trunk.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 2 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  The javadoc tool did not generate any warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:red}-1 core tests{color}.  The patch failed these unit tests in hadoop-common-project/hadoop-common:

                  org.apache.hadoop.ha.TestZKFailoverController

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HADOOP-Build/2035//testReport/
Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/2035//console

This message is automatically generated.","14/Jan/13 11:18;iveselovsky;The patch verification seems to be failed because org.apache.hadoop.ha.TestZKFailoverController is a flaky test.
The patch does not seem to affect this test anyhow.","18/Mar/13 22:11;kihwal;Review comments:
* TestNetGroupCaching.java : it needs the license header
* A change made in NetgroupCache.java may expose a new problem. Details follow.
* Don't forget to add a timeout to the test cases that are new or modified.

{code}
@@ -102,6 +102,8 @@
    */
   public static void clear() {
     netgroupToUsersMap.clear();
+    netgroupToUsersMapUpdated = true;
+    userToNetgroupsMap.clear();
   }
 
   /**
{code}

In the current code, netgroupToUsersMap is not cleared, so a user's loss of membership to a group or removal of a user will not take effect. So above change seems necessary. But since refresh() is not atomic, requests made during rebuilding of the data structures may incorrectly result in an access violation.  We could make cacheGroupsRefresh() and calls to NetgroupCache.getNetgroups() synchronized to solve this problem, but it will be better if refresh happens in background and the new mapping is swapped in as a last step of refresh, so that getGroups() calls are not blocked while refresh is going on. ","19/Mar/13 19:29;kihwal;I will file a separate jira to fix NetgroupCache implementation.","26/Mar/13 14:22;kihwal;I've created HADOOP-9436. I will post a patch with a basic test.","28/Mar/13 10:06;iveselovsky;Hi, Kihval, 
I'm attaching a new version of the patch where I have rewritten the implementation of NetgroupCache class. Please review it.
I believe, now the data access problems are solved without any blocking.","28/Mar/13 10:12;iveselovsky;I see that you already fixed H-9436, so now we probably need to choose which fix is better or merge them somehow.","29/Mar/13 01:55;hadoopqa;{color:green}+1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12575855/HADOOP-9200-trunk--N2.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 2 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  The javadoc tool did not generate any warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:green}+1 core tests{color}.  The patch passed unit tests in hadoop-common-project/hadoop-common.

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HADOOP-Build/2377//testReport/
Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/2377//console

This message is automatically generated.","29/Mar/13 16:57;kihwal;I will review you patch and probably combine with mine.","02/May/15 04:26;hadoopqa;\\
\\
| (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:red}-1{color} | patch |   0m  0s | The patch command could not apply the patch during dryrun. |
\\
\\
|| Subsystem || Report/Notes ||
| Patch URL | http://issues.apache.org/jira/secure/attachment/12575855/HADOOP-9200-trunk--N2.patch |
| Optional Tests | javadoc javac unit findbugs checkstyle |
| git revision | trunk / f1a152c |
| Console output | https://builds.apache.org/job/PreCommit-HADOOP-Build/6272/console |


This message was automatically generated.","02/May/15 04:30;hadoopqa;\\
\\
| (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:red}-1{color} | patch |   0m  0s | The patch command could not apply the patch during dryrun. |
\\
\\
|| Subsystem || Report/Notes ||
| Patch URL | http://issues.apache.org/jira/secure/attachment/12575855/HADOOP-9200-trunk--N2.patch |
| Optional Tests | javadoc javac unit findbugs checkstyle |
| git revision | trunk / f1a152c |
| Console output | https://builds.apache.org/job/PreCommit-HADOOP-Build/6293/console |


This message was automatically generated.","12/May/16 21:16;hadoopqa;| (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue} 0m 0s {color} | {color:blue} Docker mode activated. {color} |
| {color:red}-1{color} | {color:red} patch {color} | {color:red} 0m 7s {color} | {color:red} HADOOP-9200 does not apply to trunk. Rebase required? Wrong Branch? See https://wiki.apache.org/hadoop/HowToContribute for help. {color} |
\\
\\
|| Subsystem || Report/Notes ||
| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12575855/HADOOP-9200-trunk--N2.patch |
| JIRA Issue | HADOOP-9200 |
| Console output | https://builds.apache.org/job/PreCommit-HADOOP-Build/9397/console |
| Powered by | Apache Yetus 0.3.0-SNAPSHOT   http://yetus.apache.org |


This message was automatically generated.

",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Cover authentication with Kerberos ticket cache with unit tests ,HADOOP-9166,12625211,Test,Patch Available,HADOOP,Hadoop Common,software,omalley,Hadoop Common is the common library for Apache Hadoop.,http://hadoop.apache.org/,Major,,iveselovsky,iveselovsky,iveselovsky,25/Dec/12 12:04,12/May/16 20:59,12/Jan/21 11:55,,2.3.0,3.0.0-alpha1,,,,,,,,,,,,,0,BB2015-05-TBR,,,,aklochkov,daryn,iveselovsky,tgraves,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"23/Oct/13 11:10;iveselovsky;HADOOP-9166--branch-2-N11.patch;https://issues.apache.org/jira/secure/attachment/12609840/HADOOP-9166--branch-2-N11.patch","23/Oct/13 11:10;iveselovsky;HADOOP-9166--trunk-N11.patch;https://issues.apache.org/jira/secure/attachment/12609841/HADOOP-9166--trunk-N11.patch","11/Mar/13 11:39;dennisyv;HADOOP-9166-branch-0.23--N1.patch;https://issues.apache.org/jira/secure/attachment/12573073/HADOOP-9166-branch-0.23--N1.patch","27/Dec/12 11:42;iveselovsky;HADOOP-9166-branch-0.23--b.patch;https://issues.apache.org/jira/secure/attachment/12562460/HADOOP-9166-branch-0.23--b.patch","28/Dec/12 17:37;iveselovsky;HADOOP-9166-branch-0.23--c.patch;https://issues.apache.org/jira/secure/attachment/12562592/HADOOP-9166-branch-0.23--c.patch","11/Mar/13 11:39;dennisyv;HADOOP-9166-branch-2--N1.patch;https://issues.apache.org/jira/secure/attachment/12573074/HADOOP-9166-branch-2--N1.patch","27/Dec/12 11:42;iveselovsky;HADOOP-9166-branch-2--b.patch;https://issues.apache.org/jira/secure/attachment/12562461/HADOOP-9166-branch-2--b.patch","28/Dec/12 17:37;iveselovsky;HADOOP-9166-branch-2--c.patch;https://issues.apache.org/jira/secure/attachment/12562593/HADOOP-9166-branch-2--c.patch","11/Mar/13 11:39;dennisyv;HADOOP-9166-trunk--N2.patch;https://issues.apache.org/jira/secure/attachment/12573075/HADOOP-9166-trunk--N2.patch","11/Mar/13 15:25;dennisyv;HADOOP-9166-trunk--N4(1).patch;https://issues.apache.org/jira/secure/attachment/12573100/HADOOP-9166-trunk--N4%281%29.patch","12/Mar/13 12:39;dennisyv;HADOOP-9166-trunk--N7.patch;https://issues.apache.org/jira/secure/attachment/12573313/HADOOP-9166-trunk--N7.patch","18/Mar/13 14:42;dennisyv;HADOOP-9166-trunk--N8.patch;https://issues.apache.org/jira/secure/attachment/12574151/HADOOP-9166-trunk--N8.patch","27/Dec/12 11:42;iveselovsky;HADOOP-9166-trunk--b.patch;https://issues.apache.org/jira/secure/attachment/12562462/HADOOP-9166-trunk--b.patch","28/Dec/12 17:37;iveselovsky;HADOOP-9166-trunk--c.patch;https://issues.apache.org/jira/secure/attachment/12562594/HADOOP-9166-trunk--c.patch",,,,,,,,,,14.0,,,,,,,,,,,,,,,,,,,,2012-12-25 18:19:04.679,,,false,,,,,,,,,,,,,,,,,301755,,,,,Thu May 12 20:59:35 UTC 2016,,,,,,,"0|i16wb3:",248366,,,,,,,,,,,,,,,,,,,,,,,"25/Dec/12 17:44;iveselovsky;The patches are adding 1 test class with 2 test cases.","25/Dec/12 18:19;hadoopqa;{color:green}+1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12562355/HADOOP-9166-trunk.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 2 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  The javadoc tool did not generate any warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:green}+1 core tests{color}.  The patch passed unit tests in hadoop-common-project/hadoop-common.

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HADOOP-Build/1925//testReport/
Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/1925//console

This message is automatically generated.","27/Dec/12 11:42;iveselovsky;The version ""--b"" of the patches improves the test configuration.","27/Dec/12 13:07;hadoopqa;{color:green}+1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12562462/HADOOP-9166-trunk--b.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 2 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  The javadoc tool did not generate any warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:green}+1 core tests{color}.  The patch passed unit tests in hadoop-common-project/hadoop-common.

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HADOOP-Build/1928//testReport/
Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/1928//console

This message is automatically generated.","28/Dec/12 17:37;iveselovsky;The patches version ""--c"" adds tests of other methods of UGI class, + fixes some flakiness and inter-test influences in previously written tests.","28/Dec/12 18:08;hadoopqa;{color:green}+1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12562594/HADOOP-9166-trunk--c.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 2 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  The javadoc tool did not generate any warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:green}+1 core tests{color}.  The patch passed unit tests in hadoop-common-project/hadoop-common.

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HADOOP-Build/1934//testReport/
Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/1934//console

This message is automatically generated.","11/Mar/13 11:39;dennisyv;updated patches for trunk, branch-2, branch-0.23","11/Mar/13 12:15;hadoopqa;{color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12573075/HADOOP-9166-trunk--N2.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 2 new or modified test files.

  {color:red}-1 one of tests included doesn't have a timeout.{color}

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  The javadoc tool did not generate any warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

        {color:red}-1 release audit{color}.  The applied patch generated 1 release audit warnings.

    {color:green}+1 core tests{color}.  The patch passed unit tests in hadoop-common-project/hadoop-common.

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HADOOP-Build/2305//testReport/
Release audit warnings: https://builds.apache.org/job/PreCommit-HADOOP-Build/2305//artifact/trunk/patchprocess/patchReleaseAuditProblems.txt
Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/2305//console

This message is automatically generated.","11/Mar/13 15:25;dennisyv;updated trunk patch with license header & timeouts","12/Mar/13 12:39;dennisyv;added one more timeout","12/Mar/13 13:07;hadoopqa;{color:green}+1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12573313/HADOOP-9166-trunk--N7.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 2 new or modified test files.

    {color:green}+1 tests included appear to have a timeout.{color}

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  The javadoc tool did not generate any warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:green}+1 core tests{color}.  The patch passed unit tests in hadoop-common-project/hadoop-common.

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HADOOP-Build/2318//testReport/
Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/2318//console

This message is automatically generated.","18/Mar/13 14:42;dennisyv;fixed one more new merge-conflict","18/Mar/13 15:22;hadoopqa;{color:green}+1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12574151/HADOOP-9166-trunk--N8.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 2 new or modified test files.

    {color:green}+1 tests included appear to have a timeout.{color}

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  The javadoc tool did not generate any warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:green}+1 core tests{color}.  The patch passed unit tests in hadoop-common-project/hadoop-common.

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HADOOP-Build/2338//testReport/
Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/2338//console

This message is automatically generated.","30/Sep/13 20:37;daryn;This should be rebased on hadoop-minikdc.  This comment, if true, implies another jira should be filed so a test isn't required to work around another bug:
{quote}
// NB: must interrupt several times 
// because there are Thread#join() invocations in Shell.execCommand()
// that can ""eat"" the interrupted status:
{quote}","23/Oct/13 11:10;iveselovsky;patch reworked to MiniKdc. 
1) apacheds version used in MiniKdc module advanced to 2.0.0-M16-SNAPSHOT because only this version has enough client part (Kinit). Dependencies are changed accordingly.
2) test checking ticket renewal thread in UserGroupInformation dropped because it's too difficult to make that functionality work with MiniKdc.","23/Oct/13 11:43;hadoopqa;{color:green}+1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12609841/HADOOP-9166--trunk-N11.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 3 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  The javadoc tool did not generate any warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:green}+1 core tests{color}.  The patch passed unit tests in hadoop-common-project/hadoop-common hadoop-common-project/hadoop-minikdc.

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HADOOP-Build/3240//testReport/
Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/3240//console

This message is automatically generated.","02/May/15 04:35;hadoopqa;\\
\\
| (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:red}-1{color} | patch |   0m  0s | The patch command could not apply the patch during dryrun. |
\\
\\
|| Subsystem || Report/Notes ||
| Patch URL | http://issues.apache.org/jira/secure/attachment/12609841/HADOOP-9166--trunk-N11.patch |
| Optional Tests | javadoc javac unit findbugs checkstyle |
| git revision | trunk / f1a152c |
| Console output | https://builds.apache.org/job/PreCommit-HADOOP-Build/6322/console |


This message was automatically generated.","02/May/15 04:41;hadoopqa;\\
\\
| (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:red}-1{color} | patch |   0m  0s | The patch command could not apply the patch during dryrun. |
\\
\\
|| Subsystem || Report/Notes ||
| Patch URL | http://issues.apache.org/jira/secure/attachment/12609841/HADOOP-9166--trunk-N11.patch |
| Optional Tests | javadoc javac unit findbugs checkstyle |
| git revision | trunk / f1a152c |
| Console output | https://builds.apache.org/job/PreCommit-HADOOP-Build/6336/console |


This message was automatically generated.","12/May/16 20:59;hadoopqa;| (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue} 0m 0s {color} | {color:blue} Docker mode activated. {color} |
| {color:red}-1{color} | {color:red} patch {color} | {color:red} 0m 4s {color} | {color:red} HADOOP-9166 does not apply to trunk. Rebase required? Wrong Branch? See https://wiki.apache.org/hadoop/HowToContribute for help. {color} |
\\
\\
|| Subsystem || Report/Notes ||
| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12609841/HADOOP-9166--trunk-N11.patch |
| JIRA Issue | HADOOP-9166 |
| Console output | https://builds.apache.org/job/PreCommit-HADOOP-Build/9385/console |
| Powered by | Apache Yetus 0.3.0-SNAPSHOT   http://yetus.apache.org |


This message was automatically generated.

",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Jenkins test-patch timed out on a large patch touching files in multiple modules.,HADOOP-10532,12709858,Test,Resolved,HADOOP,Hadoop Common,software,omalley,Hadoop Common is the common library for Apache Hadoop.,http://hadoop.apache.org/,Major,Duplicate,jpmat,cnauroth,cnauroth,22/Apr/14 20:00,12/May/16 18:27,12/Jan/21 11:55,05/Nov/15 22:44,3.0.0-alpha1,,,,,,,,,,build,,,,0,,,"On HADOOP-10503, I had posted a consolidated patch touching multiple files across all sub-modules: Hadoop, HDFS, YARN and MapReduce.  The Jenkins test-patch runs for these consolidated patches timed out.  I also experimented with a dummy patch that simply added one-line comment changes to files.  This patch also timed out, which seems to indicate a bug in our automation rather than a problem with any patch in particular.",,aw,cnauroth,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,HADOOP-10503,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"22/Apr/14 20:03;cnauroth;PreCommit-HADOOP-Build-3821-consoleText.txt.gz;https://issues.apache.org/jira/secure/attachment/12641314/PreCommit-HADOOP-Build-3821-consoleText.txt.gz",,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,2015-04-29 01:58:41.168,,,false,,,,,,,,,,,,,,,,,388180,,,,,Thu Nov 05 22:44:10 UTC 2015,,,,,,,"0|i1uva7:",388437,,,,,,,,,,,,,,,,,,,,,,,"22/Apr/14 20:03;cnauroth;I'm attaching the full console log from one of the Jenkins runs that timed out.","29/Apr/15 01:58;aw;This is pretty much Working As Designed.  Jenkins has a setting for how long a given patch run should be.  If it goes over that value, it thinks the job is hung and kills it.

The problem we've got is that hadoop-hdfs unit tests runs for an extremely long time.  It would probably be well worth the effort to break it up from a single module to multiple modules, similarly to how yarn is currently designed.  This would limit the possibility of running over that time for the vast majority of patches.   We probably still couldn't run ALL of the unit tests, but those types of patches are extremely rare and/or can be broken up into multiple patches.","05/Nov/15 22:44;aw;Closing as a dupe.  test-patch has been replaced by Yetus.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Cover packages org.apache.hadoop.util.bloom, org.apache.hadoop.util.hash",HADOOP-9254,12629506,Test,Closed,HADOOP,Hadoop Common,software,omalley,Hadoop Common is the common library for Apache Hadoop.,http://hadoop.apache.org/,Major,Fixed,vbondarev,vbondarev,vbondarev,28/Jan/13 10:06,12/May/16 18:27,12/Jan/21 11:55,02/Oct/13 20:55,0.23.6,2.0.3-alpha,3.0.0-alpha1,,2.3.0,,,,,,,,,,0,,,,,aklochkov,eli,hudson,iveselovsky,jlowe,robsparker,vbondarev,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"31/Jan/13 10:48;vbondarev;HADOOP-9254-branch-0.23-a.patch;https://issues.apache.org/jira/secure/attachment/12567327/HADOOP-9254-branch-0.23-a.patch","02/Apr/13 13:58;vbondarev;HADOOP-9254-branch-0.23-c.patch;https://issues.apache.org/jira/secure/attachment/12576575/HADOOP-9254-branch-0.23-c.patch","31/Jan/13 10:48;vbondarev;HADOOP-9254-branch-2-a.patch;https://issues.apache.org/jira/secure/attachment/12567328/HADOOP-9254-branch-2-a.patch","02/Apr/13 13:58;vbondarev;HADOOP-9254-branch-2-b.patch;https://issues.apache.org/jira/secure/attachment/12576576/HADOOP-9254-branch-2-b.patch","31/Jan/13 10:48;vbondarev;HADOOP-9254-trunk-a.patch;https://issues.apache.org/jira/secure/attachment/12567329/HADOOP-9254-trunk-a.patch","02/Apr/13 13:58;vbondarev;HADOOP-9254-trunk-b.patch;https://issues.apache.org/jira/secure/attachment/12576577/HADOOP-9254-trunk-b.patch",,,,,,,,,,,,,,,,,,6.0,,,,,,,,,,,,,,,,,,,,2013-01-28 10:47:12.558,,,false,,,,,,,,,,,,,,,,,310002,Reviewed,,,,Thu Oct 03 14:00:12 UTC 2013,,,,,,,"0|i1hi1b:",310347,,,,,,,,,,,,,,,,,,,,,,,"28/Jan/13 10:47;hadoopqa;{color:green}+1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12566740/YAHOO-9254-trunk-a.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 3 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  The javadoc tool did not generate any warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:green}+1 core tests{color}.  The patch passed unit tests in hadoop-common-project/hadoop-common.

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HADOOP-Build/2100//testReport/
Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/2100//console

This message is automatically generated.","31/Jan/13 11:25;hadoopqa;{color:green}+1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12567329/HADOOP-9254-trunk-a.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 3 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  The javadoc tool did not generate any warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:green}+1 core tests{color}.  The patch passed unit tests in hadoop-common-project/hadoop-common.

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HADOOP-Build/2122//testReport/
Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/2122//console

This message is automatically generated.","02/Apr/13 14:28;hadoopqa;{color:green}+1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12576577/HADOOP-9254-trunk-b.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 3 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  The javadoc tool did not generate any warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:green}+1 core tests{color}.  The patch passed unit tests in hadoop-common-project/hadoop-common.

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HADOOP-Build/2399//testReport/
Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/2399//console

This message is automatically generated.","02/Oct/13 18:06;robsparker;Thanks [~vbondarev] for the patch.
+1 (non-binding) lgtm","02/Oct/13 20:38;jlowe;+1, lgtm.  One minor nit: BloomFilterCommonTester has an extra license comment in the middle of the imports which I'll cleanup on checkin.","02/Oct/13 20:55;jlowe;Thanks to Vadim for the contribution and Robert for the review!  I committed this to trunk and branch-2.","02/Oct/13 20:55;hudson;SUCCESS: Integrated in Hadoop-trunk-Commit #4518 (See [https://builds.apache.org/job/Hadoop-trunk-Commit/4518/])
HADOOP-9254. Cover packages org.apache.hadoop.util.bloom, org.apache.hadoop.util.hash. Contributed by Vadim Bondarev (jlowe: http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1528620)
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/CHANGES.txt
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/util/bloom
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/util/bloom/BloomFilterCommonTester.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/util/bloom/TestBloomFilters.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/util/hash
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/util/hash/TestHash.java
","03/Oct/13 10:58;hudson;FAILURE: Integrated in Hadoop-Yarn-trunk #351 (See [https://builds.apache.org/job/Hadoop-Yarn-trunk/351/])
HADOOP-9254. Cover packages org.apache.hadoop.util.bloom, org.apache.hadoop.util.hash. Contributed by Vadim Bondarev (jlowe: http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1528620)
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/CHANGES.txt
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/util/bloom
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/util/bloom/BloomFilterCommonTester.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/util/bloom/TestBloomFilters.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/util/hash
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/util/hash/TestHash.java
","03/Oct/13 13:30;hudson;SUCCESS: Integrated in Hadoop-Hdfs-trunk #1541 (See [https://builds.apache.org/job/Hadoop-Hdfs-trunk/1541/])
HADOOP-9254. Cover packages org.apache.hadoop.util.bloom, org.apache.hadoop.util.hash. Contributed by Vadim Bondarev (jlowe: http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1528620)
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/CHANGES.txt
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/util/bloom
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/util/bloom/BloomFilterCommonTester.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/util/bloom/TestBloomFilters.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/util/hash
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/util/hash/TestHash.java
","03/Oct/13 14:00;hudson;FAILURE: Integrated in Hadoop-Mapreduce-trunk #1567 (See [https://builds.apache.org/job/Hadoop-Mapreduce-trunk/1567/])
HADOOP-9254. Cover packages org.apache.hadoop.util.bloom, org.apache.hadoop.util.hash. Contributed by Vadim Bondarev (jlowe: http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1528620)
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/CHANGES.txt
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/util/bloom
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/util/bloom/BloomFilterCommonTester.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/util/bloom/TestBloomFilters.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/util/hash
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/util/hash/TestHash.java
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Add a plaintext fs -text test-case,HADOOP-8844,12609123,Test,Resolved,HADOOP,Hadoop Common,software,omalley,Hadoop Common is the common library for Apache Hadoop.,http://hadoop.apache.org/,Major,Fixed,aajisaka,qwertymaniac,qwertymaniac,25/Sep/12 20:52,12/May/16 18:27,12/Jan/21 11:55,06/Jul/13 02:17,2.0.0-alpha,,,,3.0.0-alpha1,,,,,,fs,,,,0,newbie,,"The TestDFSShell's textTest(…) currently tests all sorts of binary and compressed files, but doesn't test plaintext files. We should add one test for plaintext as well.",,aajisaka,adi2,eli,Fan04290,hudson,qwertymaniac,tlipcon,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"05/Jul/13 22:01;aajisaka;HADOOP-8844-1.patch;https://issues.apache.org/jira/secure/attachment/12591043/HADOOP-8844-1.patch",,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,2013-07-05 22:03:40.315,,,false,,,,,,,,,,,,,,,,,246630,Reviewed,,,,Sat Jul 06 14:08:25 UTC 2013,,,,,,,"0|i07s5j:",43328,,,,,,,,,,,,,,,,,,,,,,,"05/Jul/13 22:03;aajisaka;I attached a patch to add one test for plaintext.","05/Jul/13 23:59;hadoopqa;{color:green}+1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12591043/HADOOP-8844-1.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 1 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  The javadoc tool did not generate any warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:green}+1 core tests{color}.  The patch passed unit tests in hadoop-hdfs-project/hadoop-hdfs.

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HADOOP-Build/2746//testReport/
Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/2746//console

This message is automatically generated.","06/Jul/13 02:16;qwertymaniac;+1, this looks good! Committing to trunk.","06/Jul/13 02:17;qwertymaniac;Thanks for contributing this test Akira! Hope to see many more.","06/Jul/13 02:25;hudson;Integrated in Hadoop-trunk-Commit #4045 (See [https://builds.apache.org/job/Hadoop-trunk-Commit/4045/])
    HADOOP-8844. Add a plaintext fs -text test-case. Contributed by Akira AJISAKA. (harsh) (Revision 1500190)

     Result = SUCCESS
harsh : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1500190
Files : 
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/CHANGES.txt
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestDFSShell.java
","06/Jul/13 10:54;hudson;Integrated in Hadoop-Yarn-trunk #262 (See [https://builds.apache.org/job/Hadoop-Yarn-trunk/262/])
    HADOOP-8844. Add a plaintext fs -text test-case. Contributed by Akira AJISAKA. (harsh) (Revision 1500190)

     Result = SUCCESS
harsh : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1500190
Files : 
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/CHANGES.txt
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestDFSShell.java
","06/Jul/13 13:05;hudson;Integrated in Hadoop-Hdfs-trunk #1452 (See [https://builds.apache.org/job/Hadoop-Hdfs-trunk/1452/])
    HADOOP-8844. Add a plaintext fs -text test-case. Contributed by Akira AJISAKA. (harsh) (Revision 1500190)

     Result = FAILURE
harsh : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1500190
Files : 
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/CHANGES.txt
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestDFSShell.java
","06/Jul/13 14:08;hudson;Integrated in Hadoop-Mapreduce-trunk #1479 (See [https://builds.apache.org/job/Hadoop-Mapreduce-trunk/1479/])
    HADOOP-8844. Add a plaintext fs -text test-case. Contributed by Akira AJISAKA. (harsh) (Revision 1500190)

     Result = SUCCESS
harsh : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1500190
Files : 
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/CHANGES.txt
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestDFSShell.java
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
unit tests for the shell scripts,HADOOP-10854,12727962,Test,Resolved,HADOOP,Hadoop Common,software,omalley,Hadoop Common is the common library for Apache Hadoop.,http://hadoop.apache.org/,Major,Fixed,aw,aw,aw,17/Jul/14 16:16,12/May/16 18:26,12/Jan/21 11:55,31/Jul/15 21:36,3.0.0-alpha1,,,,3.0.0-alpha1,,,,,,scripts,,,,0,scripts,,"With HADOOP-9902 moving a lot of the core functionality to functions, we should build some unit tests for them.",,aw,busbey,cnauroth,hudson,omalley,pocky,sekikn,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,HADOOP-4059,HADOOP-6174,HADOOP-6383,,HADOOP-11745,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"17/Jul/15 21:44;aw;HADOOP-10854.00.patch;https://issues.apache.org/jira/secure/attachment/12745892/HADOOP-10854.00.patch","18/Jul/15 18:17;aw;HADOOP-10854.01.patch;https://issues.apache.org/jira/secure/attachment/12745966/HADOOP-10854.01.patch","19/Jul/15 04:59;aw;HADOOP-10854.02.patch;https://issues.apache.org/jira/secure/attachment/12745990/HADOOP-10854.02.patch","20/Jul/15 19:08;aw;HADOOP-10854.03.patch;https://issues.apache.org/jira/secure/attachment/12746153/HADOOP-10854.03.patch","24/Jul/15 20:27;aw;HADOOP-10854.04.patch;https://issues.apache.org/jira/secure/attachment/12747105/HADOOP-10854.04.patch","31/Jul/15 18:03;aw;HADOOP-10854.05.patch;https://issues.apache.org/jira/secure/attachment/12748209/HADOOP-10854.05.patch",,,,,,,,,,,,,,,,,,6.0,,,,,,,,,,,,,,,,,,,,2015-07-17 22:47:48.543,,,false,,,,,,,,,,,,,,,,,406067,,,,,Sat Aug 01 15:20:14 UTC 2015,,,,,,,"0|i1xvn3:",406087,,,,,,,,,,,,,,,,,,,,,,,"17/Jul/15 21:44;aw;-00:
* Initial version: directory layout, pom.xml changes for common
* a few bug fixes for things found along the way
* 30+ tests for some of hadoop-functions.sh
* requires bats installed
* optionally, perl + TAP::Harness + XML::Generator to convert TAP to JUnix XML for Jenkins' usage

To trigger:

 mvn test -Pshelltest

(It does *not* honor -DskipTests, so you can run mvn test -Pshelltest -DskipTests to just run the shell tests.  Running mvn test (no profile) will NOT trigger the shell tests.)

After discussing this was [~raviprak], it's probably better to do this in stages.  So let's do this initial version to lay the ground work. ","17/Jul/15 22:47;hadoopqa;\\
\\
| (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | pre-patch |  14m 55s | Pre-patch trunk compilation is healthy. |
| {color:green}+1{color} | @author |   0m  0s | The patch does not contain any @author tags. |
| {color:green}+1{color} | tests included |   0m  0s | The patch appears to include 11 new or modified test files. |
| {color:green}+1{color} | javac |   7m 41s | There were no new javac warning messages. |
| {color:green}+1{color} | javadoc |   9m 43s | There were no new javadoc warning messages. |
| {color:red}-1{color} | release audit |   0m 16s | The applied patch generated 1 release audit warnings. |
| {color:red}-1{color} | shellcheck |   0m  6s | The applied patch generated  3 new shellcheck (v0.3.3) issues (total was 25, now 28). |
| {color:green}+1{color} | whitespace |   0m  0s | The patch has no lines that end in whitespace. |
| {color:green}+1{color} | install |   1m 21s | mvn install still works. |
| {color:green}+1{color} | eclipse:eclipse |   0m 34s | The patch built with eclipse:eclipse. |
| {color:green}+1{color} | common tests |  22m 26s | Tests passed in hadoop-common. |
| | |  57m  6s | |
\\
\\
|| Subsystem || Report/Notes ||
| Patch URL | http://issues.apache.org/jira/secure/attachment/12745892/HADOOP-10854.00.patch |
| Optional Tests | shellcheck javadoc javac unit |
| git revision | trunk / 419c51d |
| Release Audit | https://builds.apache.org/job/PreCommit-HADOOP-Build/7297/artifact/patchprocess/patchReleaseAuditProblems.txt |
| shellcheck | https://builds.apache.org/job/PreCommit-HADOOP-Build/7297/artifact/patchprocess/diffpatchshellcheck.txt |
| hadoop-common test log | https://builds.apache.org/job/PreCommit-HADOOP-Build/7297/artifact/patchprocess/testrun_hadoop-common.txt |
| Test Results | https://builds.apache.org/job/PreCommit-HADOOP-Build/7297/testReport/ |
| Java | 1.7.0_55 |
| uname | Linux asf900.gq1.ygridcore.net 3.13.0-36-lowlatency #63-Ubuntu SMP PREEMPT Wed Sep 3 21:56:12 UTC 2014 x86_64 x86_64 x86_64 GNU/Linux |
| Console output | https://builds.apache.org/job/PreCommit-HADOOP-Build/7297/console |


This message was automatically generated.","18/Jul/15 06:51;sekikn;Great improvement for shell script quality assurance. Though I haven't read the entire code yet, some comments:

* In run-bats.sh, is ""mkdir -p $\{dir}/surefire-reports"" a mistake for ”mkdir -p $\{dir}?” surefire-reports/surefire-reports seems always empty.
* Can we include tap-to-junit-xml to our codebase in terms of the license?
","18/Jul/15 07:27;busbey;tap-to-junit-xml is licensed ""under the same terms as Perl itself"", which is either of GPL or Artistic. Including a GPL work is right out, but somehow we've never gotten a resolution on Artistic (ref LEGAL-64 and LEGAL-86).

If we optionally downloaded the file at build time then we'd be fine. Since we're including it in the source we'll have to check. I'd be happy to file the LEGAL ticket, but the legal affairs committee usually prefer when questions come from PMC members.","18/Jul/15 14:22;aw;bq. In run-bats.sh, is ""mkdir -p ${dir}/surefire-reports"" a mistake for ”mkdir -p ${dir}?” surefire-reports/surefire-reports seems always empty.

Yeah, that's a bug.  I'm going to change how this works anyway because of the ideas I have around HADOOP-12248 .

bq. tap-to-junit-xml

I actually pulled this from Apache SpamAssassin's source tree, where it's been living for a very long time.","18/Jul/15 14:37;busbey;I'll go ask SpamAssassin.","18/Jul/15 18:17;aw;-01:
* move tap-to-junit-xml to dev-support
* add tap-to-junit-xml to rat exclude list
* add more tests
* fix more bugs that those tests found
* rework tap -> xml process so that raw tap files are in a different dir
* fix some shellcheck issues","18/Jul/15 19:17;hadoopqa;\\
\\
| (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | pre-patch |  14m 43s | Pre-patch trunk compilation is healthy. |
| {color:green}+1{color} | @author |   0m  0s | The patch does not contain any @author tags. |
| {color:green}+1{color} | tests included |   0m  0s | The patch appears to include 16 new or modified test files. |
| {color:green}+1{color} | javac |   7m 33s | There were no new javac warning messages. |
| {color:green}+1{color} | javadoc |   9m 36s | There were no new javadoc warning messages. |
| {color:green}+1{color} | release audit |   0m 22s | The applied patch does not increase the total number of release audit warnings. |
| {color:red}-1{color} | shellcheck |   0m  6s | The applied patch generated  2 new shellcheck (v0.3.3) issues (total was 25, now 27). |
| {color:red}-1{color} | whitespace |   0m  0s | The patch has 1  line(s) that end in whitespace. Use git apply --whitespace=fix. |
| {color:green}+1{color} | install |   1m 22s | mvn install still works. |
| {color:green}+1{color} | eclipse:eclipse |   0m 34s | The patch built with eclipse:eclipse. |
| {color:green}+1{color} | common tests |  22m 19s | Tests passed in hadoop-common. |
| | |  56m 38s | |
\\
\\
|| Subsystem || Report/Notes ||
| Patch URL | http://issues.apache.org/jira/secure/attachment/12745966/HADOOP-10854.01.patch |
| Optional Tests | shellcheck javadoc javac unit |
| git revision | trunk / 419c51d |
| shellcheck | https://builds.apache.org/job/PreCommit-HADOOP-Build/7300/artifact/patchprocess/diffpatchshellcheck.txt |
| whitespace | https://builds.apache.org/job/PreCommit-HADOOP-Build/7300/artifact/patchprocess/whitespace.txt |
| hadoop-common test log | https://builds.apache.org/job/PreCommit-HADOOP-Build/7300/artifact/patchprocess/testrun_hadoop-common.txt |
| Test Results | https://builds.apache.org/job/PreCommit-HADOOP-Build/7300/testReport/ |
| Java | 1.7.0_55 |
| uname | Linux asf906.gq1.ygridcore.net 3.13.0-36-lowlatency #63-Ubuntu SMP PREEMPT Wed Sep 3 21:56:12 UTC 2014 x86_64 x86_64 x86_64 GNU/Linux |
| Console output | https://builds.apache.org/job/PreCommit-HADOOP-Build/7300/console |


This message was automatically generated.","19/Jul/15 04:59;aw;-02:
* more tests
* fix the whitespace problems
* fix the shellcheck errors against 0.3.8","19/Jul/15 05:03;aw;I'll likely pause here and start work on some of the other shell jiras since they're needed to do some of the other tests.","19/Jul/15 05:57;hadoopqa;\\
\\
| (/) *{color:green}+1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | pre-patch |  14m 41s | Pre-patch trunk compilation is healthy. |
| {color:green}+1{color} | @author |   0m  0s | The patch does not contain any @author tags. |
| {color:green}+1{color} | tests included |   0m  0s | The patch appears to include 28 new or modified test files. |
| {color:green}+1{color} | javac |   7m 33s | There were no new javac warning messages. |
| {color:green}+1{color} | javadoc |   9m 37s | There were no new javadoc warning messages. |
| {color:green}+1{color} | release audit |   0m 22s | The applied patch does not increase the total number of release audit warnings. |
| {color:green}+1{color} | shellcheck |   0m  5s | There were no new shellcheck (v0.3.3) issues. |
| {color:green}+1{color} | whitespace |   0m  1s | The patch has no lines that end in whitespace. |
| {color:green}+1{color} | install |   1m 20s | mvn install still works. |
| {color:green}+1{color} | eclipse:eclipse |   0m 33s | The patch built with eclipse:eclipse. |
| {color:green}+1{color} | common tests |  22m  9s | Tests passed in hadoop-common. |
| | |  56m 27s | |
\\
\\
|| Subsystem || Report/Notes ||
| Patch URL | http://issues.apache.org/jira/secure/attachment/12745990/HADOOP-10854.02.patch |
| Optional Tests | shellcheck javadoc javac unit |
| git revision | trunk / 176131f |
| hadoop-common test log | https://builds.apache.org/job/PreCommit-HADOOP-Build/7301/artifact/patchprocess/testrun_hadoop-common.txt |
| Test Results | https://builds.apache.org/job/PreCommit-HADOOP-Build/7301/testReport/ |
| Java | 1.7.0_55 |
| uname | Linux asf906.gq1.ygridcore.net 3.13.0-36-lowlatency #63-Ubuntu SMP PREEMPT Wed Sep 3 21:56:12 UTC 2014 x86_64 x86_64 x86_64 GNU/Linux |
| Console output | https://builds.apache.org/job/PreCommit-HADOOP-Build/7301/console |


This message was automatically generated.","20/Jul/15 19:08;aw;-03:
* remove the tap-to-junit-xml bits for now so this can get committed without worrying about licensing
* change how tap output is handled so that test-patch will have something to work with in the future","20/Jul/15 20:07;hadoopqa;\\
\\
| (/) *{color:green}+1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | pre-patch |  14m 46s | Pre-patch trunk compilation is healthy. |
| {color:green}+1{color} | @author |   0m  0s | The patch does not contain any @author tags. |
| {color:green}+1{color} | tests included |   0m  0s | The patch appears to include 28 new or modified test files. |
| {color:green}+1{color} | javac |   7m 43s | There were no new javac warning messages. |
| {color:green}+1{color} | javadoc |   9m 40s | There were no new javadoc warning messages. |
| {color:green}+1{color} | release audit |   0m 22s | The applied patch does not increase the total number of release audit warnings. |
| {color:green}+1{color} | shellcheck |   0m  5s | There were no new shellcheck (v0.3.3) issues. |
| {color:green}+1{color} | whitespace |   0m  1s | The patch has no lines that end in whitespace. |
| {color:green}+1{color} | install |   1m 21s | mvn install still works. |
| {color:green}+1{color} | eclipse:eclipse |   0m 32s | The patch built with eclipse:eclipse. |
| {color:green}+1{color} | common tests |  22m 20s | Tests passed in hadoop-common. |
| | |  56m 53s | |
\\
\\
|| Subsystem || Report/Notes ||
| Patch URL | http://issues.apache.org/jira/secure/attachment/12746153/HADOOP-10854.03.patch |
| Optional Tests | shellcheck javadoc javac unit |
| git revision | trunk / 98c2bc8 |
| hadoop-common test log | https://builds.apache.org/job/PreCommit-HADOOP-Build/7305/artifact/patchprocess/testrun_hadoop-common.txt |
| Test Results | https://builds.apache.org/job/PreCommit-HADOOP-Build/7305/testReport/ |
| Java | 1.7.0_55 |
| uname | Linux asf901.gq1.ygridcore.net 3.13.0-36-lowlatency #63-Ubuntu SMP PREEMPT Wed Sep 3 21:56:12 UTC 2014 x86_64 x86_64 x86_64 GNU/Linux |
| Console output | https://builds.apache.org/job/PreCommit-HADOOP-Build/7305/console |


This message was automatically generated.","21/Jul/15 18:39;busbey;+1 (non-binding). You have a preference between me getting legal-discuss signoff on artistic license vs the suggestion from dev@spamassassin that I get the original relicensed under ASLv2?","21/Jul/15 21:26;aw;Thanks for following up.  Given that Justin Mason is PMC Emeritus @ SpamAssassin, it's probably worthwhile to see if we can get him to relicense over the short term.  But I want to see if the rest of the SpamAssassin folks chime in on that thread, because they haven't really answered all the questions you pose.  Longer term, clearly getting a decision on Artistic would be a good thing for all of the ASF.","21/Jul/15 21:35;busbey;The difficult part for relicensing is that Justin isn't the copyright holder of the original version, so I'll have to track that other person down.","21/Jul/15 21:38;aw;True. Given that this is only useful for jenkins at this point... probably not worth pursuing at all then.  ","23/Jul/15 20:49;aw;So, this *only* executes if -Dskiptests is on the command line.  I'm at a loss as to why though. :(","23/Jul/15 21:06;busbey;just to confirm before I try to reproduce, it only runs when the command line is like {{mvn -Pshelltest -DskipTests clean test}}?","24/Jul/15 00:14;aw;Yeah, basically:

{{mvn test -Pshelltest -DskipTests}} will only run the shelltest.

{{mvn test -Pshelltest}} will only run the unit tests and not both.

I've got an updated version of this patch that:

a) won't fail maven if bats isn't installed
b) moves the phase for shelltest to process-test-classes.  This gets run after test-compile and before test.  This fixes the {{mvn test -Pshelltest}}  case, but it's still less than ideal.","24/Jul/15 20:27;aw;-04:
* no longer fail when bats isn't installed, despite the fact it probably should
* set the phase to run before the actual test phase so that mvn test -Pshelltest works","24/Jul/15 22:10;hadoopqa;\\
\\
| (/) *{color:green}+1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | pre-patch |  15m 55s | Pre-patch trunk compilation is healthy. |
| {color:green}+1{color} | @author |   0m  0s | The patch does not contain any @author tags. |
| {color:green}+1{color} | tests included |   0m  0s | The patch appears to include 28 new or modified test files. |
| {color:green}+1{color} | javac |   7m 49s | There were no new javac warning messages. |
| {color:green}+1{color} | javadoc |  10m 28s | There were no new javadoc warning messages. |
| {color:green}+1{color} | release audit |   0m 23s | The applied patch does not increase the total number of release audit warnings. |
| {color:green}+1{color} | shellcheck |   0m  6s | There were no new shellcheck (v0.3.3) issues. |
| {color:green}+1{color} | whitespace |   0m  1s | The patch has no lines that end in whitespace. |
| {color:green}+1{color} | install |   1m 21s | mvn install still works. |
| {color:green}+1{color} | eclipse:eclipse |   0m 32s | The patch built with eclipse:eclipse. |
| {color:green}+1{color} | common tests |  23m  7s | Tests passed in hadoop-common. |
| | |  59m 45s | |
\\
\\
|| Subsystem || Report/Notes ||
| Patch URL | http://issues.apache.org/jira/secure/attachment/12747105/HADOOP-10854.04.patch |
| Optional Tests | shellcheck javadoc javac unit |
| git revision | trunk / 83fe34a |
| hadoop-common test log | https://builds.apache.org/job/PreCommit-HADOOP-Build/7337/artifact/patchprocess/testrun_hadoop-common.txt |
| Test Results | https://builds.apache.org/job/PreCommit-HADOOP-Build/7337/testReport/ |
| Java | 1.7.0_55 |
| uname | Linux asf904.gq1.ygridcore.net 3.13.0-36-lowlatency #63-Ubuntu SMP PREEMPT Wed Sep 3 21:56:12 UTC 2014 x86_64 x86_64 x86_64 GNU/Linux |
| Console output | https://builds.apache.org/job/PreCommit-HADOOP-Build/7337/console |


This message was automatically generated.","24/Jul/15 22:42;busbey;{quote}
 * no longer fail when bats isn't installed, despite the fact it probably should
{quote}

Is failing with a nice error message only when {{-Pshelltest}} and no bats a problem for some reason? I'm just curious; I'd be happy to submit a follow on patch that did this with the enforcer plugin, for example, so that the failure was in the validate phase instead of test (or process-test-classes as the case may be).","25/Jul/15 00:01;aw;I think it's a problem because the people who will need unit testing the most are most likely the ones who won't have it installed.  I mean, even simple things like ""hey, keep the case statements alphabetized"" has been an uphill battle.  Manipulating global vars is downright dangerous for most of Hadoop's committers.","25/Jul/15 00:33;busbey;I could make the enforcer plugin recognize that bats isn't installed and point folks to an installation HOWTO. That would leave things equally bad for the uninformed (i.e. those who don't pass {{-Pshelltest}}) while giving those at least willing to work on improving a pointer on how to move towards better.","25/Jul/15 03:19;aw;Actually, if the code doesn't fail if bats isn't installed, then is there any reason not to have it turned on by default?  This would allow us to put up a big ""Yo, if you are testing shell code, install bats"" message.","30/Jul/15 15:39;aw;This patch currently conflicts with HADOOP-12249 .  It'd be better for HADOOP-12249 to be committed first and then this patch updated.","31/Jul/15 18:03;aw;-05:
* removed the generate usage tests in leue of HADOOP-12249
* enable profile by default since it is no longer a fatal error if they can't run","31/Jul/15 19:39;hadoopqa;\\
\\
| (/) *{color:green}+1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | pre-patch |  15m  3s | Pre-patch trunk compilation is healthy. |
| {color:green}+1{color} | @author |   0m  0s | The patch does not contain any @author tags. |
| {color:green}+1{color} | tests included |   0m  0s | The patch appears to include 27 new or modified test files. |
| {color:green}+1{color} | javac |   7m 40s | There were no new javac warning messages. |
| {color:green}+1{color} | javadoc |   9m 41s | There were no new javadoc warning messages. |
| {color:green}+1{color} | release audit |   0m 22s | The applied patch does not increase the total number of release audit warnings. |
| {color:green}+1{color} | shellcheck |   0m  6s | There were no new shellcheck (v0.3.3) issues. |
| {color:green}+1{color} | whitespace |   0m  1s | The patch has no lines that end in whitespace. |
| {color:green}+1{color} | install |   1m 20s | mvn install still works. |
| {color:green}+1{color} | eclipse:eclipse |   0m 33s | The patch built with eclipse:eclipse. |
| {color:green}+1{color} | common tests |  22m 18s | Tests passed in hadoop-common. |
| | |  57m  7s | |
\\
\\
|| Subsystem || Report/Notes ||
| Patch URL | http://issues.apache.org/jira/secure/attachment/12748209/HADOOP-10854.05.patch |
| Optional Tests | shellcheck javadoc javac unit |
| git revision | trunk / d0e0ba8 |
| hadoop-common test log | https://builds.apache.org/job/PreCommit-HADOOP-Build/7387/artifact/patchprocess/testrun_hadoop-common.txt |
| Test Results | https://builds.apache.org/job/PreCommit-HADOOP-Build/7387/testReport/ |
| Java | 1.7.0_55 |
| uname | Linux asf901.gq1.ygridcore.net 3.13.0-36-lowlatency #63-Ubuntu SMP PREEMPT Wed Sep 3 21:56:12 UTC 2014 x86_64 x86_64 x86_64 GNU/Linux |
| Console output | https://builds.apache.org/job/PreCommit-HADOOP-Build/7387/console |


This message was automatically generated.","31/Jul/15 20:55;omalley;+1 looks good, Allen.","31/Jul/15 21:36;aw;Thanks!

Committed to trunk.

I'll start opening up other JIRAs for adding remaining tests and doing some re-organization of executables to enable testing.","01/Aug/15 00:04;hudson;FAILURE: Integrated in Hadoop-trunk-Commit #8253 (See [https://builds.apache.org/job/Hadoop-trunk-Commit/8253/])
HADOOP-10854. unit tests for the shell scripts (aw) (aw: rev a890a31529cc625326cd3749a4960ad7c02fc6fe)
* hadoop-common-project/hadoop-common/src/test/scripts/run-bats.sh
* hadoop-common-project/hadoop-common/src/test/scripts/hadoop_ssh.bats
* hadoop-common-project/hadoop-common/src/test/scripts/hadoop_add_classpath.bats
* hadoop-common-project/hadoop-common/src/test/scripts/hadoop_bootstrap.bats
* hadoop-common-project/hadoop-common/src/test/scripts/hadoop_translate_cygwin_path.bats
* hadoop-common-project/hadoop-common/src/test/scripts/hadoop_finalize_libpaths.bats
* hadoop-common-project/hadoop-common/src/test/scripts/hadoop_finalize_catalina_opts.bats
* hadoop-common-project/hadoop-common/pom.xml
* hadoop-common-project/hadoop-common/src/test/scripts/hadoop_shellprofile.bats
* hadoop-common-project/hadoop-common/src/test/scripts/hadoop-functions_test_helper.bash
* hadoop-common-project/hadoop-common/src/test/scripts/hadoop_finalize_hadoop_opts.bats
* hadoop-common-project/hadoop-common/src/test/scripts/hadoop_add_javalibpath.bats
* hadoop-common-project/hadoop-common/src/test/scripts/hadoop_add_to_classpath_userpath.bats
* hadoop-common-project/hadoop-common/src/test/scripts/hadoop_deprecate_envvar.bats
* hadoop-common-project/hadoop-common/src/test/scripts/hadoop_slaves.bats
* hadoop-common-project/hadoop-common/src/test/scripts/hadoop_rotate_log.bats
* hadoop-common-project/hadoop-common/src/main/bin/hadoop-functions.sh
* hadoop-common-project/hadoop-common/src/test/scripts/hadoop_os_tricks.bats
* hadoop-common-project/hadoop-common/src/test/scripts/hadoop_validate_classname.bats
* hadoop-common-project/hadoop-common/src/test/scripts/hadoop_basic_init.bats
* hadoop-common-project/hadoop-common/CHANGES.txt
* dev-support/docker/Dockerfile
* hadoop-common-project/hadoop-common/src/test/scripts/hadoop_add_ldlibpath.bats
* hadoop-common-project/hadoop-common/src/test/scripts/hadoop_finalize.bats
* hadoop-common-project/hadoop-common/src/test/scripts/hadoop_add_common_to_classpath.bats
* hadoop-common-project/hadoop-common/src/test/scripts/hadoop_add_colonpath.bats
* hadoop-common-project/hadoop-common/src/test/scripts/hadoop_add_param.bats
* hadoop-common-project/hadoop-common/src/test/scripts/hadoop_finalize_hadoop_heap.bats
* hadoop-common-project/hadoop-common/src/test/scripts/hadoop_java_setup.bats
* hadoop-common-project/hadoop-common/src/test/scripts/hadoop_confdir.bats
* hadoop-common-project/hadoop-common/src/test/scripts/hadoop_finalize_classpath.bats
* BUILDING.txt
","01/Aug/15 11:44;hudson;FAILURE: Integrated in Hadoop-Yarn-trunk #1004 (See [https://builds.apache.org/job/Hadoop-Yarn-trunk/1004/])
HADOOP-10854. unit tests for the shell scripts (aw) (aw: rev a890a31529cc625326cd3749a4960ad7c02fc6fe)
* hadoop-common-project/hadoop-common/src/test/scripts/hadoop_rotate_log.bats
* hadoop-common-project/hadoop-common/src/test/scripts/hadoop_add_common_to_classpath.bats
* hadoop-common-project/hadoop-common/src/test/scripts/hadoop_add_colonpath.bats
* hadoop-common-project/hadoop-common/src/test/scripts/hadoop_finalize_catalina_opts.bats
* hadoop-common-project/hadoop-common/src/test/scripts/hadoop_finalize_libpaths.bats
* hadoop-common-project/hadoop-common/src/test/scripts/hadoop_finalize_hadoop_opts.bats
* hadoop-common-project/hadoop-common/src/test/scripts/run-bats.sh
* hadoop-common-project/hadoop-common/src/test/scripts/hadoop_validate_classname.bats
* BUILDING.txt
* hadoop-common-project/hadoop-common/src/test/scripts/hadoop_deprecate_envvar.bats
* hadoop-common-project/hadoop-common/src/test/scripts/hadoop_os_tricks.bats
* dev-support/docker/Dockerfile
* hadoop-common-project/hadoop-common/src/test/scripts/hadoop_bootstrap.bats
* hadoop-common-project/hadoop-common/src/test/scripts/hadoop_ssh.bats
* hadoop-common-project/hadoop-common/src/test/scripts/hadoop_finalize_classpath.bats
* hadoop-common-project/hadoop-common/src/test/scripts/hadoop_add_classpath.bats
* hadoop-common-project/hadoop-common/src/test/scripts/hadoop_add_param.bats
* hadoop-common-project/hadoop-common/src/test/scripts/hadoop_add_javalibpath.bats
* hadoop-common-project/hadoop-common/src/test/scripts/hadoop_add_to_classpath_userpath.bats
* hadoop-common-project/hadoop-common/src/test/scripts/hadoop_finalize.bats
* hadoop-common-project/hadoop-common/src/test/scripts/hadoop_add_ldlibpath.bats
* hadoop-common-project/hadoop-common/src/test/scripts/hadoop_slaves.bats
* hadoop-common-project/hadoop-common/CHANGES.txt
* hadoop-common-project/hadoop-common/src/test/scripts/hadoop_confdir.bats
* hadoop-common-project/hadoop-common/src/test/scripts/hadoop_finalize_hadoop_heap.bats
* hadoop-common-project/hadoop-common/src/test/scripts/hadoop_java_setup.bats
* hadoop-common-project/hadoop-common/src/test/scripts/hadoop-functions_test_helper.bash
* hadoop-common-project/hadoop-common/src/test/scripts/hadoop_translate_cygwin_path.bats
* hadoop-common-project/hadoop-common/src/main/bin/hadoop-functions.sh
* hadoop-common-project/hadoop-common/pom.xml
* hadoop-common-project/hadoop-common/src/test/scripts/hadoop_basic_init.bats
* hadoop-common-project/hadoop-common/src/test/scripts/hadoop_shellprofile.bats
","01/Aug/15 11:58;hudson;SUCCESS: Integrated in Hadoop-Yarn-trunk-Java8 #274 (See [https://builds.apache.org/job/Hadoop-Yarn-trunk-Java8/274/])
HADOOP-10854. unit tests for the shell scripts (aw) (aw: rev a890a31529cc625326cd3749a4960ad7c02fc6fe)
* hadoop-common-project/hadoop-common/src/test/scripts/hadoop_deprecate_envvar.bats
* hadoop-common-project/hadoop-common/src/test/scripts/hadoop_slaves.bats
* hadoop-common-project/hadoop-common/src/test/scripts/hadoop_finalize_hadoop_opts.bats
* hadoop-common-project/hadoop-common/src/test/scripts/hadoop_finalize.bats
* hadoop-common-project/hadoop-common/src/test/scripts/hadoop_add_common_to_classpath.bats
* hadoop-common-project/hadoop-common/src/test/scripts/hadoop_add_ldlibpath.bats
* hadoop-common-project/hadoop-common/src/test/scripts/hadoop_finalize_hadoop_heap.bats
* hadoop-common-project/hadoop-common/src/test/scripts/hadoop_finalize_classpath.bats
* hadoop-common-project/hadoop-common/src/test/scripts/hadoop_finalize_catalina_opts.bats
* hadoop-common-project/hadoop-common/src/test/scripts/hadoop_confdir.bats
* hadoop-common-project/hadoop-common/src/test/scripts/hadoop_java_setup.bats
* dev-support/docker/Dockerfile
* hadoop-common-project/hadoop-common/src/test/scripts/run-bats.sh
* hadoop-common-project/hadoop-common/src/test/scripts/hadoop_ssh.bats
* hadoop-common-project/hadoop-common/src/test/scripts/hadoop_shellprofile.bats
* hadoop-common-project/hadoop-common/src/test/scripts/hadoop_add_javalibpath.bats
* hadoop-common-project/hadoop-common/src/test/scripts/hadoop_rotate_log.bats
* hadoop-common-project/hadoop-common/src/test/scripts/hadoop_add_to_classpath_userpath.bats
* hadoop-common-project/hadoop-common/src/test/scripts/hadoop_add_param.bats
* hadoop-common-project/hadoop-common/src/test/scripts/hadoop_finalize_libpaths.bats
* BUILDING.txt
* hadoop-common-project/hadoop-common/src/test/scripts/hadoop_bootstrap.bats
* hadoop-common-project/hadoop-common/src/main/bin/hadoop-functions.sh
* hadoop-common-project/hadoop-common/src/test/scripts/hadoop_basic_init.bats
* hadoop-common-project/hadoop-common/src/test/scripts/hadoop_translate_cygwin_path.bats
* hadoop-common-project/hadoop-common/pom.xml
* hadoop-common-project/hadoop-common/CHANGES.txt
* hadoop-common-project/hadoop-common/src/test/scripts/hadoop_add_classpath.bats
* hadoop-common-project/hadoop-common/src/test/scripts/hadoop_validate_classname.bats
* hadoop-common-project/hadoop-common/src/test/scripts/hadoop_add_colonpath.bats
* hadoop-common-project/hadoop-common/src/test/scripts/hadoop-functions_test_helper.bash
* hadoop-common-project/hadoop-common/src/test/scripts/hadoop_os_tricks.bats
","01/Aug/15 13:47;hudson;FAILURE: Integrated in Hadoop-Mapreduce-trunk #2220 (See [https://builds.apache.org/job/Hadoop-Mapreduce-trunk/2220/])
HADOOP-10854. unit tests for the shell scripts (aw) (aw: rev a890a31529cc625326cd3749a4960ad7c02fc6fe)
* hadoop-common-project/hadoop-common/src/test/scripts/hadoop_rotate_log.bats
* hadoop-common-project/hadoop-common/src/test/scripts/hadoop_confdir.bats
* hadoop-common-project/hadoop-common/src/test/scripts/hadoop_slaves.bats
* hadoop-common-project/hadoop-common/src/test/scripts/hadoop_finalize.bats
* hadoop-common-project/hadoop-common/src/test/scripts/hadoop_add_classpath.bats
* hadoop-common-project/hadoop-common/src/test/scripts/run-bats.sh
* hadoop-common-project/hadoop-common/src/test/scripts/hadoop_finalize_hadoop_heap.bats
* hadoop-common-project/hadoop-common/src/test/scripts/hadoop_deprecate_envvar.bats
* BUILDING.txt
* hadoop-common-project/hadoop-common/CHANGES.txt
* hadoop-common-project/hadoop-common/src/test/scripts/hadoop_ssh.bats
* hadoop-common-project/hadoop-common/src/test/scripts/hadoop_add_colonpath.bats
* hadoop-common-project/hadoop-common/src/test/scripts/hadoop_bootstrap.bats
* hadoop-common-project/hadoop-common/src/test/scripts/hadoop_finalize_hadoop_opts.bats
* hadoop-common-project/hadoop-common/src/test/scripts/hadoop-functions_test_helper.bash
* hadoop-common-project/hadoop-common/src/test/scripts/hadoop_add_ldlibpath.bats
* hadoop-common-project/hadoop-common/src/test/scripts/hadoop_finalize_libpaths.bats
* hadoop-common-project/hadoop-common/src/test/scripts/hadoop_add_common_to_classpath.bats
* hadoop-common-project/hadoop-common/src/test/scripts/hadoop_translate_cygwin_path.bats
* hadoop-common-project/hadoop-common/src/test/scripts/hadoop_shellprofile.bats
* hadoop-common-project/hadoop-common/src/test/scripts/hadoop_add_javalibpath.bats
* hadoop-common-project/hadoop-common/src/test/scripts/hadoop_finalize_classpath.bats
* hadoop-common-project/hadoop-common/src/test/scripts/hadoop_add_to_classpath_userpath.bats
* hadoop-common-project/hadoop-common/src/test/scripts/hadoop_add_param.bats
* hadoop-common-project/hadoop-common/src/test/scripts/hadoop_os_tricks.bats
* dev-support/docker/Dockerfile
* hadoop-common-project/hadoop-common/src/test/scripts/hadoop_finalize_catalina_opts.bats
* hadoop-common-project/hadoop-common/src/test/scripts/hadoop_java_setup.bats
* hadoop-common-project/hadoop-common/src/test/scripts/hadoop_basic_init.bats
* hadoop-common-project/hadoop-common/pom.xml
* hadoop-common-project/hadoop-common/src/test/scripts/hadoop_validate_classname.bats
* hadoop-common-project/hadoop-common/src/main/bin/hadoop-functions.sh
","01/Aug/15 14:19;hudson;FAILURE: Integrated in Hadoop-Hdfs-trunk #2201 (See [https://builds.apache.org/job/Hadoop-Hdfs-trunk/2201/])
HADOOP-10854. unit tests for the shell scripts (aw) (aw: rev a890a31529cc625326cd3749a4960ad7c02fc6fe)
* hadoop-common-project/hadoop-common/src/test/scripts/hadoop_add_to_classpath_userpath.bats
* hadoop-common-project/hadoop-common/src/test/scripts/hadoop_ssh.bats
* hadoop-common-project/hadoop-common/src/test/scripts/hadoop_basic_init.bats
* hadoop-common-project/hadoop-common/src/test/scripts/hadoop_finalize.bats
* hadoop-common-project/hadoop-common/src/test/scripts/hadoop_finalize_hadoop_opts.bats
* hadoop-common-project/hadoop-common/src/test/scripts/hadoop_validate_classname.bats
* hadoop-common-project/hadoop-common/src/test/scripts/hadoop_add_param.bats
* hadoop-common-project/hadoop-common/src/test/scripts/hadoop_shellprofile.bats
* hadoop-common-project/hadoop-common/src/test/scripts/hadoop_confdir.bats
* hadoop-common-project/hadoop-common/src/test/scripts/hadoop_add_ldlibpath.bats
* hadoop-common-project/hadoop-common/src/main/bin/hadoop-functions.sh
* hadoop-common-project/hadoop-common/src/test/scripts/hadoop_os_tricks.bats
* hadoop-common-project/hadoop-common/src/test/scripts/hadoop_slaves.bats
* hadoop-common-project/hadoop-common/src/test/scripts/hadoop_translate_cygwin_path.bats
* hadoop-common-project/hadoop-common/src/test/scripts/run-bats.sh
* hadoop-common-project/hadoop-common/src/test/scripts/hadoop_add_javalibpath.bats
* BUILDING.txt
* hadoop-common-project/hadoop-common/src/test/scripts/hadoop_rotate_log.bats
* hadoop-common-project/hadoop-common/src/test/scripts/hadoop_add_classpath.bats
* hadoop-common-project/hadoop-common/src/test/scripts/hadoop_java_setup.bats
* hadoop-common-project/hadoop-common/src/test/scripts/hadoop_finalize_hadoop_heap.bats
* hadoop-common-project/hadoop-common/pom.xml
* hadoop-common-project/hadoop-common/src/test/scripts/hadoop_finalize_catalina_opts.bats
* hadoop-common-project/hadoop-common/src/test/scripts/hadoop_deprecate_envvar.bats
* dev-support/docker/Dockerfile
* hadoop-common-project/hadoop-common/src/test/scripts/hadoop_add_colonpath.bats
* hadoop-common-project/hadoop-common/src/test/scripts/hadoop_add_common_to_classpath.bats
* hadoop-common-project/hadoop-common/CHANGES.txt
* hadoop-common-project/hadoop-common/src/test/scripts/hadoop_bootstrap.bats
* hadoop-common-project/hadoop-common/src/test/scripts/hadoop_finalize_libpaths.bats
* hadoop-common-project/hadoop-common/src/test/scripts/hadoop-functions_test_helper.bash
* hadoop-common-project/hadoop-common/src/test/scripts/hadoop_finalize_classpath.bats
","01/Aug/15 14:29;hudson;FAILURE: Integrated in Hadoop-Hdfs-trunk-Java8 #263 (See [https://builds.apache.org/job/Hadoop-Hdfs-trunk-Java8/263/])
HADOOP-10854. unit tests for the shell scripts (aw) (aw: rev a890a31529cc625326cd3749a4960ad7c02fc6fe)
* hadoop-common-project/hadoop-common/src/test/scripts/hadoop_validate_classname.bats
* hadoop-common-project/hadoop-common/src/test/scripts/hadoop_translate_cygwin_path.bats
* hadoop-common-project/hadoop-common/src/test/scripts/hadoop_confdir.bats
* dev-support/docker/Dockerfile
* hadoop-common-project/hadoop-common/src/test/scripts/hadoop_finalize_catalina_opts.bats
* hadoop-common-project/hadoop-common/src/test/scripts/hadoop_add_classpath.bats
* hadoop-common-project/hadoop-common/pom.xml
* hadoop-common-project/hadoop-common/src/test/scripts/hadoop_basic_init.bats
* hadoop-common-project/hadoop-common/src/test/scripts/hadoop_add_ldlibpath.bats
* hadoop-common-project/hadoop-common/src/test/scripts/hadoop_rotate_log.bats
* hadoop-common-project/hadoop-common/src/main/bin/hadoop-functions.sh
* hadoop-common-project/hadoop-common/src/test/scripts/hadoop_finalize_classpath.bats
* hadoop-common-project/hadoop-common/src/test/scripts/hadoop_os_tricks.bats
* hadoop-common-project/hadoop-common/src/test/scripts/hadoop_shellprofile.bats
* BUILDING.txt
* hadoop-common-project/hadoop-common/src/test/scripts/hadoop-functions_test_helper.bash
* hadoop-common-project/hadoop-common/src/test/scripts/hadoop_add_to_classpath_userpath.bats
* hadoop-common-project/hadoop-common/src/test/scripts/hadoop_finalize_libpaths.bats
* hadoop-common-project/hadoop-common/src/test/scripts/hadoop_java_setup.bats
* hadoop-common-project/hadoop-common/src/test/scripts/hadoop_add_param.bats
* hadoop-common-project/hadoop-common/src/test/scripts/hadoop_add_colonpath.bats
* hadoop-common-project/hadoop-common/src/test/scripts/hadoop_add_common_to_classpath.bats
* hadoop-common-project/hadoop-common/src/test/scripts/run-bats.sh
* hadoop-common-project/hadoop-common/src/test/scripts/hadoop_finalize_hadoop_opts.bats
* hadoop-common-project/hadoop-common/src/test/scripts/hadoop_finalize.bats
* hadoop-common-project/hadoop-common/src/test/scripts/hadoop_finalize_hadoop_heap.bats
* hadoop-common-project/hadoop-common/src/test/scripts/hadoop_deprecate_envvar.bats
* hadoop-common-project/hadoop-common/src/test/scripts/hadoop_slaves.bats
* hadoop-common-project/hadoop-common/src/test/scripts/hadoop_ssh.bats
* hadoop-common-project/hadoop-common/src/test/scripts/hadoop_add_javalibpath.bats
* hadoop-common-project/hadoop-common/src/test/scripts/hadoop_bootstrap.bats
* hadoop-common-project/hadoop-common/CHANGES.txt
","01/Aug/15 15:20;hudson;SUCCESS: Integrated in Hadoop-Mapreduce-trunk-Java8 #271 (See [https://builds.apache.org/job/Hadoop-Mapreduce-trunk-Java8/271/])
HADOOP-10854. unit tests for the shell scripts (aw) (aw: rev a890a31529cc625326cd3749a4960ad7c02fc6fe)
* hadoop-common-project/hadoop-common/src/test/scripts/hadoop_os_tricks.bats
* hadoop-common-project/hadoop-common/src/test/scripts/hadoop_finalize_classpath.bats
* hadoop-common-project/hadoop-common/src/test/scripts/hadoop_rotate_log.bats
* hadoop-common-project/hadoop-common/src/test/scripts/hadoop_add_classpath.bats
* BUILDING.txt
* hadoop-common-project/hadoop-common/src/test/scripts/hadoop_ssh.bats
* hadoop-common-project/hadoop-common/src/test/scripts/hadoop_finalize_libpaths.bats
* hadoop-common-project/hadoop-common/src/test/scripts/hadoop_validate_classname.bats
* hadoop-common-project/hadoop-common/src/test/scripts/hadoop_add_javalibpath.bats
* hadoop-common-project/hadoop-common/src/test/scripts/hadoop_add_to_classpath_userpath.bats
* hadoop-common-project/hadoop-common/src/test/scripts/hadoop_java_setup.bats
* hadoop-common-project/hadoop-common/pom.xml
* hadoop-common-project/hadoop-common/src/test/scripts/hadoop_finalize_catalina_opts.bats
* hadoop-common-project/hadoop-common/src/main/bin/hadoop-functions.sh
* dev-support/docker/Dockerfile
* hadoop-common-project/hadoop-common/src/test/scripts/hadoop_finalize_hadoop_opts.bats
* hadoop-common-project/hadoop-common/src/test/scripts/hadoop_add_common_to_classpath.bats
* hadoop-common-project/hadoop-common/src/test/scripts/hadoop_confdir.bats
* hadoop-common-project/hadoop-common/src/test/scripts/hadoop_basic_init.bats
* hadoop-common-project/hadoop-common/src/test/scripts/hadoop_deprecate_envvar.bats
* hadoop-common-project/hadoop-common/src/test/scripts/hadoop-functions_test_helper.bash
* hadoop-common-project/hadoop-common/src/test/scripts/run-bats.sh
* hadoop-common-project/hadoop-common/src/test/scripts/hadoop_bootstrap.bats
* hadoop-common-project/hadoop-common/src/test/scripts/hadoop_add_param.bats
* hadoop-common-project/hadoop-common/src/test/scripts/hadoop_finalize_hadoop_heap.bats
* hadoop-common-project/hadoop-common/src/test/scripts/hadoop_slaves.bats
* hadoop-common-project/hadoop-common/src/test/scripts/hadoop_add_colonpath.bats
* hadoop-common-project/hadoop-common/src/test/scripts/hadoop_add_ldlibpath.bats
* hadoop-common-project/hadoop-common/CHANGES.txt
* hadoop-common-project/hadoop-common/src/test/scripts/hadoop_shellprofile.bats
* hadoop-common-project/hadoop-common/src/test/scripts/hadoop_finalize.bats
* hadoop-common-project/hadoop-common/src/test/scripts/hadoop_translate_cygwin_path.bats
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Cover package org.apache.hadoop.io with unit tests,HADOOP-9199,12627209,Test,Closed,HADOOP,Hadoop Common,software,omalley,Hadoop Common is the common library for Apache Hadoop.,http://hadoop.apache.org/,Major,Fixed,aklochkov,vbondarev,vbondarev,11/Jan/13 16:59,12/May/16 18:26,12/Jan/21 11:55,08/Oct/13 19:48,0.23.6,2.0.3-alpha,3.0.0-alpha1,,2.3.0,,,,,,,,,,0,,,,,aklochkov,hudson,iveselovsky,jeagles,robsparker,sureshms,tgraves,vbondarev,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"11/Jan/13 17:06;vbondarev;HADOOP-9199-branch-0.23-a.patch;https://issues.apache.org/jira/secure/attachment/12564439/HADOOP-9199-branch-0.23-a.patch","17/Jan/13 10:00;vbondarev;HADOOP-9199-branch-0.23-b.patch;https://issues.apache.org/jira/secure/attachment/12565301/HADOOP-9199-branch-0.23-b.patch","24/Jan/13 07:18;vbondarev;HADOOP-9199-branch-0.23-c.patch;https://issues.apache.org/jira/secure/attachment/12566263/HADOOP-9199-branch-0.23-c.patch","02/Apr/13 13:44;vbondarev;HADOOP-9199-branch-0.23-e.patch;https://issues.apache.org/jira/secure/attachment/12576572/HADOOP-9199-branch-0.23-e.patch","11/Jan/13 17:06;vbondarev;HADOOP-9199-branch-2-a.patch;https://issues.apache.org/jira/secure/attachment/12564440/HADOOP-9199-branch-2-a.patch","17/Jan/13 10:00;vbondarev;HADOOP-9199-branch-2-b.patch;https://issues.apache.org/jira/secure/attachment/12565302/HADOOP-9199-branch-2-b.patch","24/Jan/13 07:18;vbondarev;HADOOP-9199-branch-2-c.patch;https://issues.apache.org/jira/secure/attachment/12566264/HADOOP-9199-branch-2-c.patch","02/Apr/13 13:44;vbondarev;HADOOP-9199-branch-2-e.patch;https://issues.apache.org/jira/secure/attachment/12576573/HADOOP-9199-branch-2-e.patch","04/Oct/13 00:06;aklochkov;HADOOP-9199-trunk--n6.patch;https://issues.apache.org/jira/secure/attachment/12606686/HADOOP-9199-trunk--n6.patch","04/Oct/13 18:23;aklochkov;HADOOP-9199-trunk--n7.patch;https://issues.apache.org/jira/secure/attachment/12606853/HADOOP-9199-trunk--n7.patch","17/Jan/13 07:53;vbondarev;HADOOP-9199-trunk-a.patch;https://issues.apache.org/jira/secure/attachment/12565287/HADOOP-9199-trunk-a.patch","17/Jan/13 10:00;vbondarev;HADOOP-9199-trunk-b.patch;https://issues.apache.org/jira/secure/attachment/12565303/HADOOP-9199-trunk-b.patch","24/Jan/13 07:18;vbondarev;HADOOP-9199-trunk-c.patch;https://issues.apache.org/jira/secure/attachment/12566265/HADOOP-9199-trunk-c.patch","02/Apr/13 13:44;vbondarev;HADOOP-9199-trunk-e.patch;https://issues.apache.org/jira/secure/attachment/12576574/HADOOP-9199-trunk-e.patch",,,,,,,,,,14.0,,,,,,,,,,,,,,,,,,,,2013-01-11 17:56:05.079,,,false,,,,,,,,,,,,,,,,,303979,,,,,Wed Oct 09 13:34:15 UTC 2013,,,,,,,"0|i17h9b:",251765,,,,,,,,,,,,,,,,,,,,,,,"11/Jan/13 17:56;hadoopqa;{color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12564441/HADOOP-9199-trunk-a.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 16 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  The javadoc tool did not generate any warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:red}-1 core tests{color}.  The patch failed these unit tests in hadoop-common-project/hadoop-common:

                  org.apache.hadoop.ha.TestZKFailoverController

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HADOOP-Build/2026//testReport/
Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/2026//console

This message is automatically generated.","11/Jan/13 18:39;sureshms;Can you please add a brief description of changes you are making in this patch?","11/Jan/13 18:41;sureshms;One more quick comment looking at the patch - please add brief description to every test on what it is testing. Tests become harder to understand and maintain without this.","14/Jan/13 09:29;vbondarev;add description in issue or in test source code ?","14/Jan/13 13:10;vbondarev;Classes           Method                              Desc
  
TestArrayFile       testArrayFileIteration              test ArrayFile.Reader methods next(); reader reader.seek() in range and out of range.

TestArrayWritable   testArrayWritableStringConstructor  test ArrayWritable constructor with String[] as a parameter
                    testNullArgument                    test TextArrayWritable with null parameter
                    testArrayWritableToArray            test TextArrayWritable toArray() method


TestBloomMapFile    testBloomMapFileConstructors        test all BloomMapFile.Writer available constructors.
                    testDeleteFile                      test method BloomMapFile.delete.  
                    testGetBloomMapFile                 test BloomMapFile.Reader method get(Writable wr) in range and out of range.
                    testIOExceptionInWriterConstructor  test BloomMapFile.Reader constructor with throw IOException in filesystem.getFileSystem(conf);

TestBooleanWritable testCommonMethods                   test methods hashCode(), equals(), compareTo() against instance of type BooleanWritable

TestBytesWritable   testObjectCommonMethods             test methods compareTo(), toString(), equals() against instance of type ByteWritable


TestCompressedWritable testCompressedWritableWriteHeader test CompressedWritable write(DataOutputBuffer) method 
                       testCompressedWritableReadFields  test CompressedWritable readFields() method

TestEnumSetWritable    testEnumSetWritableEquals         test equals() method against instance of type EnumSetWritable
                       testEnumSetWritableWriteRead      test EnumSetWritable write(DataOutputBuffer out) and iteration by TestEnumSet through iterator().


TestMapFile            
                       testDeprecatedConstructors        test all available constructor of type MapFile.Writer.
                       testDescOrderWithThrowExceptionWriterAppend test MapFile.Writer method append(Writable wr) in desc order (2, 1);
                       testFix                           test MapFile.fix() method which attempts to re-creating MapFile index.
                       testGetClosestOnCurrentApi        test method reader.getClosest(WritableComparable wrc) variations.
                       testKeyLessWriterCreation         test MapFile.Writer constructor without varargs paramereters (SequenceFile.Writer.Option... opts).
                       testKeyValueClasses               test on verification key and value classes for MapFile.Writer type.
                       testMainMethodMapFile             test for static void main() method.
                       testMidKeyOnCurrentApi            test MapFile.Reader method reader.midKey() which get key in the middle of the file.
                       testOnFinalKey                    test MapFile.Reader method reader.finalKey() which get key in the end of file.
                       testPathExplosionWriterCreation   test IOException in MapFile.Writer constructor
                       testReaderKeyIteration            test MapFile.Reader method reader.next(key, value) for iteration.
                       testReaderWithWrongKeyClass       test MapFile.Reader method reader.getClosest() whith wrond class key
                       testReaderWithWrongValueClass     test MapFile.Writer method writer.append() with wrong type key instance
                       testRename                        test MapFile.rename() method
                       testRenameWithException           test MapFile.rename() method with throw IOException 
                       testRenameWithFalse               test MapFile.rename() method with FleSystem.rename return false
                       testWriteWithFailDirCreation      test MapFile.Writer constructor with throw IOException
TestMultipleIOException
                       testEmptyParamIOException         test MultipleIOException.createIOException() method
                       testSingleParamIOException        test MultipleIOException.testSingleParamIOException() method 
                       testMultipleIOException           test MultipleIOException.createIOException() method

TestNullWritable                
                       testNullableWritable              test uncovered methods in class NullWritable

TestOutputBuffer       testOutputBufferWithoutResize     test OutputBuffer methods write(InputStream in, int), out.getData()                        
                       testOutputBufferReset             test just like previous only with adding out.reset() call

TestSetFile            testSetFileAccessMethods          test SetFile.Reader next(), get() combination method

TestText               testBytesToCodePoint              test static method Text.bytesToCodePoint();
                       testCharAt                        test Text class method charAt(i) in range and out of range
                       testReadWriteOperations           test Text readFields()/write() methods combination
                       testUtf8Length                    test Text.utf8Length() static method
                       testbytesToCodePointWithInvalidUTF test static method with invalid utf value (throw BufferUnderflowException)

TestTwoDArrayWritable  test2DArrayConstructor            test  TwoDArrayWritable constructor with Text[][] parameter
                       test2DArrayToArray                test  TwoDArrayWritable toArray() method
                       test2DArrayWriteRead              test  TwoDArrayWritable methods combination                      
                       testIllegalAccessException        test  IllegalAccessException in TwoDArrayWritable.readFields() method
                       testInstantiationException        test  InstantiationException in TwoDArrayWritable.readFields() method


TestVLongWritable      testReadFields                    test VLongWritable.readFields(in) method          
                       testSetGetVLong                   test VLongWritable combination of methods set()/get() equals(), compareTo()


TestWritableComparator  
                        testReadTypes                    test static methods readUnsignedShort()/readVInt()/readVLong with different parameters
                        testShouldThrowsException        test WritableComparator.compare with Exception
                        testWritableComparator           test WritableComparator.compare with >, <, = results
","14/Jan/13 13:13;vbondarev;test method description","14/Jan/13 13:14;vbondarev;look at test method description in attach","14/Jan/13 13:23;hadoopqa;{color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12564699/Test_Desc
  against trunk revision .

    {color:red}-1 patch{color}.  The patch command could not apply the patch.

Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/2038//console

This message is automatically generated.","17/Jan/13 08:31;hadoopqa;{color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12565287/HADOOP-9199-trunk-a.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 16 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  The javadoc tool did not generate any warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

        {color:red}-1 release audit{color}.  The applied patch generated 6 release audit warnings.

    {color:green}+1 core tests{color}.  The patch passed unit tests in hadoop-common-project/hadoop-common.

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HADOOP-Build/2063//testReport/
Release audit warnings: https://builds.apache.org/job/PreCommit-HADOOP-Build/2063//artifact/trunk/patchprocess/patchReleaseAuditProblems.txt
Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/2063//console

This message is automatically generated.","17/Jan/13 10:36;hadoopqa;{color:green}+1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12565303/HADOOP-9199-trunk-b.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 16 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  The javadoc tool did not generate any warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:green}+1 core tests{color}.  The patch passed unit tests in hadoop-common-project/hadoop-common.

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HADOOP-Build/2064//testReport/
Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/2064//console

This message is automatically generated.","17/Jan/13 23:40;sureshms;Sorry, I had lost track of this jira.

bq. add description in issue or in test source code ?
Javadoc to the test method, to describe briefly what the test is testing.","24/Jan/13 07:47;hadoopqa;{color:green}+1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12566265/HADOOP-9199-trunk-c.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 16 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  The javadoc tool did not generate any warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:green}+1 core tests{color}.  The patch passed unit tests in hadoop-common-project/hadoop-common.

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HADOOP-Build/2083//testReport/
Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/2083//console

This message is automatically generated.","02/Apr/13 13:33;hadoopqa;{color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12576561/HADOOP-9199-branch-0.23-e.patch
  against trunk revision .

    {color:red}-1 patch{color}.  The patch command could not apply the patch.

Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/2396//console

This message is automatically generated.","02/Apr/13 14:18;hadoopqa;{color:green}+1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12576574/HADOOP-9199-trunk-e.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 16 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  The javadoc tool did not generate any warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:green}+1 core tests{color}.  The patch passed unit tests in hadoop-common-project/hadoop-common.

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HADOOP-Build/2398//testReport/
Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/2398//console

This message is automatically generated.","02/Oct/13 15:14;robsparker;[~vbondarev] thanks for the patch, one small change:

for the TestEnumWritable#testEnumSetWritableWriteRead:

    The readFields operation should go to a new EnumWritableSet so the source in not contaminated by the read.  For example:
 {code}
      EnumSetWritable<TestEnumSet> eset = 
          new EnumSetWritable<TestEnumSet>(EnumSet.of(TestEnumSet.APPEND, 
                 TestEnumSet.CREATE), TestEnumSet.class);
      EnumSetWritable<TestEnumSet> oset = new EnumSetWritable<TestEnumSet>();
      eset.write(out);
      in.reset(out.getData(), out.getLength());
      oset.readFields(in); 

      EnumSet<TestEnumSet> result = oset.get();
{code}","04/Oct/13 00:06;aklochkov;Updated the patch according to Robert's comment. The same patch is applicable to branch-2.","04/Oct/13 00:42;hadoopqa;{color:green}+1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12606686/HADOOP-9199-trunk--n6.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 16 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  The javadoc tool did not generate any warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:green}+1 core tests{color}.  The patch passed unit tests in hadoop-common-project/hadoop-common.

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HADOOP-Build/3166//testReport/
Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/3166//console

This message is automatically generated.","04/Oct/13 16:54;robsparker;[~aklochkov] mvn test -Dtest=TestMapFile; mvn test -Dtest=TestMapFile shows the that TestMapFile is not quite cleaning up.  Additionally the '/' is missing between the ""test.build.data"" dir and the test file name.  


{code}
Running org.apache.hadoop.io.TestMapFile
Tests run: 20, Failures: 3, Errors: 0, Skipped: 0, Time elapsed: 4.362 sec <<< FAILURE! - in org.apache.hadoop.io.TestMapFile
testRenameWithFalse(org.apache.hadoop.io.TestMapFile)  Time elapsed: 2.37 sec  <<< FAILURE!
junit.framework.AssertionFailedError: testRenameWithFalse invalid IOExceptionMessage error !!!
	at junit.framework.Assert.fail(Assert.java:50)
	at junit.framework.Assert.assertTrue(Assert.java:20)
	at org.apache.hadoop.io.TestMapFile.testRenameWithFalse(TestMapFile.java:255)

testRename(org.apache.hadoop.io.TestMapFile)  Time elapsed: 0.04 sec  <<< FAILURE!
junit.framework.AssertionFailedError: testRename error java.io.IOException: Target /home/rparker/Y/hadoop-gitdev/hadoop-common-project/hadoop-common/target/test/datatest-new.mapfile/datatest-old.mapfile is a directory
	at junit.framework.Assert.fail(Assert.java:50)
	at org.apache.hadoop.io.TestMapFile.testRename(TestMapFile.java:199)

testRenameWithException(org.apache.hadoop.io.TestMapFile)  Time elapsed: 0.037 sec  <<< FAILURE!
junit.framework.ComparisonFailure: testRenameWithException invalid IOExceptionMessage !!! expected:<[Target /home/rparker/Y/hadoop-gitdev/hadoop-common-project/hadoop-common/target/test/datatest-new.mapfile/datatest-old.mapfile is a directory]> but was:<[Can't rename file]>
	at junit.framework.Assert.assertEquals(Assert.java:85)
	at org.apache.hadoop.io.TestMapFile.testRenameWithException(TestMapFile.java:229)


Results :

Failed tests: 
  TestMapFile.testRenameWithFalse:255 testRenameWithFalse invalid IOExceptionMessage error !!!
  TestMapFile.testRename:199 testRename error java.io.IOException: Target /home/rparker/Y/hadoop-gitdev/hadoop-common-project/hadoop-common/target/test/datatest-new.mapfile/datatest-old.mapfile is a directory
  TestMapFile.testRenameWithException:229 testRenameWithException invalid IOExceptionMessage !!! expected:<[Target /home/rparker/Y/hadoop-gitdev/hadoop-common-project/hadoop-common/target/test/datatest-new.mapfile/datatest-old.mapfile is a directory]> but was:<[Can't rename file]>

Tests run: 20, Failures: 3, Errors: 0, Skipped: 0
{code}


The '/' is missing in several other tests (TestArrayFile,TestBloomMapFile),. I used to notice the difference between TestSetFile (which is correct) and TestMapFile

{code}
grep  test.build.data hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/TestArrayFile.java hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/TestArrayWritable.java hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/TestBloomMapFile.java hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/TestBooleanWritable.java hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/TestBytesWritable.java hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/TestEnumSetWritable.java hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/TestMapFile.java hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/TestSetFile.java hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/TestText.java hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/TestCompressedWritable.java hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/TestMultipleIOException.java hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/TestNullWritable.java hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/TestOutputBuffer.java hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/TestTwoDArrayWritable.java hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/TestVLongWritable.java hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/TestWritableComparator.java
{code}

Thanks for correcting the >80 lines and please remove the tabs.  Sorry I missed these items on the first review.
","04/Oct/13 18:23;aklochkov;Robert, thanks for capturing all these! Uploading the patch with fixes.","04/Oct/13 19:03;hadoopqa;{color:green}+1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12606853/HADOOP-9199-trunk--n7.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 16 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  The javadoc tool did not generate any warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:green}+1 core tests{color}.  The patch passed unit tests in hadoop-common-project/hadoop-common.

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HADOOP-Build/3171//testReport/
Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/3171//console

This message is automatically generated.","07/Oct/13 17:29;robsparker;Thanks [~andrey]. 
+1 (non-binding)
lgtm","08/Oct/13 19:35;jeagles;putting this into 2.3 and 3.0","08/Oct/13 19:47;hudson;SUCCESS: Integrated in Hadoop-trunk-Commit #4566 (See [https://builds.apache.org/job/Hadoop-trunk-Commit/4566/])
HADOOP-9199. Cover package org.apache.hadoop.io with unit tests (Andrey Klochkov via jeagles) (jeagles: http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1530404)
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/CHANGES.txt
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/TestArrayFile.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/TestArrayWritable.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/TestBloomMapFile.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/TestBooleanWritable.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/TestBytesWritable.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/TestEnumSetWritable.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/TestMapFile.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/TestSetFile.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/TestText.java
","09/Oct/13 11:00;hudson;SUCCESS: Integrated in Hadoop-Yarn-trunk #357 (See [https://builds.apache.org/job/Hadoop-Yarn-trunk/357/])
HADOOP-9199. Cover package org.apache.hadoop.io with unit tests (Andrey Klochkov via jeagles) (jeagles: http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1530404)
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/CHANGES.txt
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/TestArrayFile.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/TestArrayWritable.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/TestBloomMapFile.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/TestBooleanWritable.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/TestBytesWritable.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/TestEnumSetWritable.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/TestMapFile.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/TestSetFile.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/TestText.java
","09/Oct/13 13:04;hudson;FAILURE: Integrated in Hadoop-Mapreduce-trunk #1573 (See [https://builds.apache.org/job/Hadoop-Mapreduce-trunk/1573/])
HADOOP-9199. Cover package org.apache.hadoop.io with unit tests (Andrey Klochkov via jeagles) (jeagles: http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1530404)
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/CHANGES.txt
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/TestArrayFile.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/TestArrayWritable.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/TestBloomMapFile.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/TestBooleanWritable.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/TestBytesWritable.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/TestEnumSetWritable.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/TestMapFile.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/TestSetFile.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/TestText.java
","09/Oct/13 13:34;hudson;SUCCESS: Integrated in Hadoop-Hdfs-trunk #1547 (See [https://builds.apache.org/job/Hadoop-Hdfs-trunk/1547/])
HADOOP-9199. Cover package org.apache.hadoop.io with unit tests (Andrey Klochkov via jeagles) (jeagles: http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1530404)
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/CHANGES.txt
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/TestArrayFile.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/TestArrayWritable.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/TestBloomMapFile.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/TestBooleanWritable.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/TestBytesWritable.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/TestEnumSetWritable.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/TestMapFile.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/TestSetFile.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/TestText.java
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
fix race conditions and add URL support to smart-apply-patch.sh,HADOOP-11781,12787135,Test,Resolved,HADOOP,Hadoop Common,software,omalley,Hadoop Common is the common library for Apache Hadoop.,http://hadoop.apache.org/,Major,Fixed,raymie,aw,aw,31/Mar/15 19:54,12/May/16 18:25,12/Jan/21 11:55,08/Apr/15 17:06,3.0.0-alpha1,,,,3.0.0-alpha1,,,,,,test,,,,0,,,smart-apply-patch.sh has a few race conditions and is just generally crufty.  It should really be rewritten.,,aw,hudson,kihwal,raymie,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"02/Apr/15 00:29;raymie;HADOOP-11781-01.patch;https://issues.apache.org/jira/secure/attachment/12708866/HADOOP-11781-01.patch","02/Apr/15 07:22;raymie;HADOOP-11781-02.patch;https://issues.apache.org/jira/secure/attachment/12708928/HADOOP-11781-02.patch","03/Apr/15 06:34;raymie;HADOOP-11781-03.patch;https://issues.apache.org/jira/secure/attachment/12709187/HADOOP-11781-03.patch",,,,,,,,,,,,,,,,,,,,,3.0,,,,,,,,,,,,,,,,,,,,2015-04-02 00:29:16.068,,,false,,,,,,,,,,,,,,,,,9223372036854775807,,,,,Thu Apr 09 18:32:56 UTC 2015,,,,,,,"0|i27lyn:",9223372036854775807,"Now auto-downloads patch from issue-id; fixed race conditions; fixed bug affecting some patches.",,,,,,,,,,,,,,,,,,,,,,"02/Apr/15 00:29;raymie;-01: cleaned up a race-condition with file names (c.f. HADOOP-11746).  Added feature to take a URL and JIRA issue-identifier instead of a patch filename, so one can more quickly apply patches (we want to quickly check the backlog of patches hundreds of patches to find ones that no longer apply -- this feature will help). ","02/Apr/15 07:22;raymie;-02: applied previous version to all 926 issues in the ""patch avail"" state.  This test uncovered a bug that is fixed by this version.  (BTW, 448 of those patches successfully apply, 478 fail to.)","02/Apr/15 08:04;hadoopqa;{color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12708928/HADOOP-11781-02.patch
  against trunk revision 867d5d2.

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:red}-1 tests included{color}.  The patch doesn't appear to include any new or modified tests.
                        Please justify why no new tests are needed for this patch.
                        Also please list what manual steps were performed to verify this patch.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  There were no new javadoc warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 2.0.3) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:green}+1 core tests{color}.  The patch passed unit tests in .

Test results: https://builds.apache.org/job/PreCommit-HADOOP-Build/6049//testReport/
Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/6049//console

This message is automatically generated.","02/Apr/15 15:23;aw;This is awesome! Changed the summary and description so we can push this in sooner rather than later.

One nit:  let's change the {{sort | uniq}}'s to {{sort -u}} so it runs a little faster.","03/Apr/15 06:34;raymie;-03: made sort -u change.","03/Apr/15 07:13;hadoopqa;{color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12709187/HADOOP-11781-03.patch
  against trunk revision 72f6bd4.

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:red}-1 tests included{color}.  The patch doesn't appear to include any new or modified tests.
                        Please justify why no new tests are needed for this patch.
                        Also please list what manual steps were performed to verify this patch.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  There were no new javadoc warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 2.0.3) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:green}+1 core tests{color}.  The patch passed unit tests in .

Test results: https://builds.apache.org/job/PreCommit-HADOOP-Build/6056//testReport/
Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/6056//console

This message is automatically generated.","08/Apr/15 17:06;aw;+1 committed to trunk.

Thanks!","08/Apr/15 17:45;hudson;FAILURE: Integrated in Hadoop-trunk-Commit #7532 (See [https://builds.apache.org/job/Hadoop-trunk-Commit/7532/])
HADOOP-11781. fix race conditions and add URL support to smart-apply-patch.sh (Raymie Stata via aw) (aw: rev f4b3fc56210824037344d403f1ad0f033961a2db)
* hadoop-common-project/hadoop-common/CHANGES.txt
* dev-support/smart-apply-patch.sh
","09/Apr/15 10:41;hudson;FAILURE: Integrated in Hadoop-Yarn-trunk-Java8 #158 (See [https://builds.apache.org/job/Hadoop-Yarn-trunk-Java8/158/])
HADOOP-11781. fix race conditions and add URL support to smart-apply-patch.sh (Raymie Stata via aw) (aw: rev f4b3fc56210824037344d403f1ad0f033961a2db)
* hadoop-common-project/hadoop-common/CHANGES.txt
* dev-support/smart-apply-patch.sh
","09/Apr/15 11:34;hudson;FAILURE: Integrated in Hadoop-Hdfs-trunk #2090 (See [https://builds.apache.org/job/Hadoop-Hdfs-trunk/2090/])
HADOOP-11781. fix race conditions and add URL support to smart-apply-patch.sh (Raymie Stata via aw) (aw: rev f4b3fc56210824037344d403f1ad0f033961a2db)
* hadoop-common-project/hadoop-common/CHANGES.txt
* dev-support/smart-apply-patch.sh
","09/Apr/15 11:35;hudson;FAILURE: Integrated in Hadoop-Hdfs-trunk-Java8 #149 (See [https://builds.apache.org/job/Hadoop-Hdfs-trunk-Java8/149/])
HADOOP-11781. fix race conditions and add URL support to smart-apply-patch.sh (Raymie Stata via aw) (aw: rev f4b3fc56210824037344d403f1ad0f033961a2db)
* hadoop-common-project/hadoop-common/CHANGES.txt
* dev-support/smart-apply-patch.sh
","09/Apr/15 11:56;hudson;SUCCESS: Integrated in Hadoop-Yarn-trunk #892 (See [https://builds.apache.org/job/Hadoop-Yarn-trunk/892/])
HADOOP-11781. fix race conditions and add URL support to smart-apply-patch.sh (Raymie Stata via aw) (aw: rev f4b3fc56210824037344d403f1ad0f033961a2db)
* dev-support/smart-apply-patch.sh
* hadoop-common-project/hadoop-common/CHANGES.txt
","09/Apr/15 18:14;hudson;FAILURE: Integrated in Hadoop-Mapreduce-trunk-Java8 #159 (See [https://builds.apache.org/job/Hadoop-Mapreduce-trunk-Java8/159/])
HADOOP-11781. fix race conditions and add URL support to smart-apply-patch.sh (Raymie Stata via aw) (aw: rev f4b3fc56210824037344d403f1ad0f033961a2db)
* hadoop-common-project/hadoop-common/CHANGES.txt
* dev-support/smart-apply-patch.sh
","09/Apr/15 18:32;hudson;FAILURE: Integrated in Hadoop-Mapreduce-trunk #2108 (See [https://builds.apache.org/job/Hadoop-Mapreduce-trunk/2108/])
HADOOP-11781. fix race conditions and add URL support to smart-apply-patch.sh (Raymie Stata via aw) (aw: rev f4b3fc56210824037344d403f1ad0f033961a2db)
* dev-support/smart-apply-patch.sh
* hadoop-common-project/hadoop-common/CHANGES.txt
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
enhance unit-test coverage of class org.apache.hadoop.fs.FileContext,HADOOP-9078,12617128,Test,Closed,HADOOP,Hadoop Common,software,omalley,Hadoop Common is the common library for Apache Hadoop.,http://hadoop.apache.org/,Major,Fixed,iveselovsky,iveselovsky,iveselovsky,21/Nov/12 16:23,12/May/16 18:25,12/Jan/21 11:55,16/Oct/13 22:47,0.23.6,2.0.3-alpha,3.0.0-alpha1,,2.3.0,,,,,,,,,,0,,,,,aklochkov,eli,hudson,iveselovsky,jeagles,jlowe,robsparker,sureshms,tgraves,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"16/Jan/13 13:23;iveselovsky;HADOOP-9078--b.patch;https://issues.apache.org/jira/secure/attachment/12565119/HADOOP-9078--b.patch","28/Nov/12 18:11;iveselovsky;HADOOP-9078-branch-0.23.patch;https://issues.apache.org/jira/secure/attachment/12555204/HADOOP-9078-branch-0.23.patch","28/Mar/13 10:14;dennisyv;HADOOP-9078-branch-2--N1.patch;https://issues.apache.org/jira/secure/attachment/12575856/HADOOP-9078-branch-2--N1.patch","29/Mar/13 16:52;iveselovsky;HADOOP-9078-branch-2--N2.patch;https://issues.apache.org/jira/secure/attachment/12576106/HADOOP-9078-branch-2--N2.patch","06/Jun/13 12:36;iveselovsky;HADOOP-9078-branch-2--N3.patch;https://issues.apache.org/jira/secure/attachment/12586489/HADOOP-9078-branch-2--N3.patch","26/Jun/13 15:05;dennisyv;HADOOP-9078-branch-2--N4.patch;https://issues.apache.org/jira/secure/attachment/12589758/HADOOP-9078-branch-2--N4.patch","11/Jan/13 16:33;iveselovsky;HADOOP-9078-branch-2--b.patch;https://issues.apache.org/jira/secure/attachment/12564436/HADOOP-9078-branch-2--b.patch","16/Jan/13 13:23;iveselovsky;HADOOP-9078-branch-2--c.patch;https://issues.apache.org/jira/secure/attachment/12565118/HADOOP-9078-branch-2--c.patch","28/Nov/12 18:11;iveselovsky;HADOOP-9078-branch-2.patch;https://issues.apache.org/jira/secure/attachment/12555205/HADOOP-9078-branch-2.patch","08/Dec/12 20:45;dennisyv;HADOOP-9078-patch-from-[trunk-gd]-to-[fb-HADOOP-9078-trunk-gd]-N1.patch;https://issues.apache.org/jira/secure/attachment/12560042/HADOOP-9078-patch-from-%5Btrunk-gd%5D-to-%5Bfb-HADOOP-9078-trunk-gd%5D-N1.patch","28/Mar/13 10:14;dennisyv;HADOOP-9078-trunk--N1.patch;https://issues.apache.org/jira/secure/attachment/12575857/HADOOP-9078-trunk--N1.patch","29/Mar/13 16:52;iveselovsky;HADOOP-9078-trunk--N2.patch;https://issues.apache.org/jira/secure/attachment/12576107/HADOOP-9078-trunk--N2.patch","09/Apr/13 12:09;iveselovsky;HADOOP-9078-trunk--N6.patch;https://issues.apache.org/jira/secure/attachment/12577786/HADOOP-9078-trunk--N6.patch","06/Jun/13 12:36;iveselovsky;HADOOP-9078-trunk--N8.patch;https://issues.apache.org/jira/secure/attachment/12586490/HADOOP-9078-trunk--N8.patch","16/Oct/13 15:37;robsparker;HADOOP-9078-trunk--N9.patch;https://issues.apache.org/jira/secure/attachment/12608724/HADOOP-9078-trunk--N9.patch","28/Nov/12 18:12;iveselovsky;HADOOP-9078.patch;https://issues.apache.org/jira/secure/attachment/12555206/HADOOP-9078.patch",,,,,,,,16.0,,,,,,,,,,,,,,,,,,,,2012-12-08 20:45:27.528,,,false,,,,,,,,,,,,,,,,,259328,,,,,Thu Oct 17 14:28:55 UTC 2013,,,,,,,"0|i0lodz:",124601,,,,,,,,,,,,,,,,,,,,,,,"28/Nov/12 18:12;iveselovsky;""HADOOP-9078"" is for trunk, other patches are for the branches respectively.","08/Dec/12 20:45;dennisyv;resubmitting after fixing merge conflict with commit:
""HDFS-4260 Fix HDFS tests to set test dir to a valid HDFS path as opposed to the local build path (Chris Nauroth via Sanjay)""
on file 
hadoop-common-project\hadoop-common\src\test\java\org\apache\hadoop\fs\FileContextTestHelper.java ","08/Dec/12 21:06;dennisyv;HADOOP-9078-patch-from-[trunk-gd]-to-[fb-HADOOP-9078-trunk-gd]-N1.patch
is for trunk","13/Dec/12 11:25;hadoopqa;{color:green}+1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12560042/HADOOP-9078-patch-from-%5Btrunk-gd%5D-to-%5Bfb-HADOOP-9078-trunk-gd%5D-N1.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 6 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  The javadoc tool did not generate any warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:green}+1 core tests{color}.  The patch passed unit tests in hadoop-common-project/hadoop-common hadoop-hdfs-project/hadoop-hdfs.

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HADOOP-Build/1852//testReport/
Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/1852//console

This message is automatically generated.","11/Jan/13 16:33;iveselovsky;The patches of version ""--b"" fix merge conflicts with some incoming changes.","11/Jan/13 16:43;hadoopqa;{color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12564436/HADOOP-9078-branch-2--b.patch
  against trunk revision .

    {color:red}-1 patch{color}.  The patch command could not apply the patch.

Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/2025//console

This message is automatically generated.","11/Jan/13 18:41;iveselovsky;Re-attaching the patch for trunk to check the patch verification (previous verification took patch for branch-2). ","16/Jan/13 13:23;iveselovsky;Remaking patch for branch-2 (version ""c""): merge with incoming changes. ","16/Jan/13 15:28;hadoopqa;{color:green}+1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12565119/HADOOP-9078--b.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 6 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  The javadoc tool did not generate any warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:green}+1 core tests{color}.  The patch passed unit tests in hadoop-common-project/hadoop-common hadoop-hdfs-project/hadoop-hdfs.

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HADOOP-Build/2056//testReport/
Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/2056//console

This message is automatically generated.","28/Mar/13 10:14;dennisyv;resolved merge conflicts on branch-2 and trunk (one conflict in imports)","29/Mar/13 03:27;hadoopqa;{color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12575857/HADOOP-9078-trunk--N1.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 6 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  The javadoc tool did not generate any warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:red}-1 core tests{color}.  The patch failed these unit tests in hadoop-common-project/hadoop-common hadoop-hdfs-project/hadoop-hdfs:

                  org.apache.hadoop.fs.TestFcHdfsSymlink

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HADOOP-Build/2378//testReport/
Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/2378//console

This message is automatically generated.","29/Mar/13 16:52;iveselovsky;Added new versions of the patches that fix problems in tests caused by fix HADOOP-9357.","29/Mar/13 18:49;hadoopqa;{color:green}+1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12576107/HADOOP-9078-trunk--N2.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 8 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  The javadoc tool did not generate any warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:green}+1 core tests{color}.  The patch passed unit tests in hadoop-common-project/hadoop-common hadoop-hdfs-project/hadoop-hdfs.

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HADOOP-Build/2381//testReport/
Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/2381//console

This message is automatically generated.","09/Apr/13 12:09;iveselovsky;new patch for trunk:
1) fixed merge conflict;
2) reverted changes complementary to fix H-9357 since that fix was rolled back from trunk;","09/Apr/13 14:11;hadoopqa;{color:green}+1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12577786/HADOOP-9078-trunk--N6.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 6 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  The javadoc tool did not generate any warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:green}+1 core tests{color}.  The patch passed unit tests in hadoop-common-project/hadoop-common hadoop-hdfs-project/hadoop-hdfs.

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HADOOP-Build/2430//testReport/
Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/2430//console

This message is automatically generated.","06/Jun/13 12:36;iveselovsky;Patches for ""branch-2"" and ""trunk"" are updated because of merge over incoming changes.","06/Jun/13 14:40;hadoopqa;{color:green}+1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12586490/HADOOP-9078-trunk--N8.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 6 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  The javadoc tool did not generate any warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:green}+1 core tests{color}.  The patch passed unit tests in hadoop-common-project/hadoop-common hadoop-hdfs-project/hadoop-hdfs.

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HADOOP-Build/2609//testReport/
Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/2609//console

This message is automatically generated.","26/Jun/13 15:05;dennisyv;fixed merge conflict with fresh changes on branch-2","26/Jun/13 17:21;hadoopqa;{color:green}+1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12589758/HADOOP-9078-branch-2--N4.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 6 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  The javadoc tool did not generate any warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:green}+1 core tests{color}.  The patch passed unit tests in hadoop-common-project/hadoop-common hadoop-hdfs-project/hadoop-hdfs.

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HADOOP-Build/2705//testReport/
Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/2705//console

This message is automatically generated.","01/Oct/13 21:51;robsparker;Thanks [~dennisyv] and [~iveselovsky] for the patches.  Both the branch-2 and trunk patches apply to trunk fine (as all the affected files are identical in both branch-2 and trunk). But patches are different, for example FileContextMainOperationsBaseTest.java is different for testWorkingDirectory.  Please reconcile these patches so they are making the same change. ","08/Oct/13 14:13;iveselovsky;Hi, Robert,
please use patch HADOOP-9078-trunk--N8.patch for both ""branch-2"" and ""trunk"". 
In the past there was some difference, but now this patch equally applicable to both the branches. ","16/Oct/13 15:39;robsparker;[~iveselovsky], thanks for the patch.
I corrected a spelling error and an unused import to create N9.
lgtm +1 (non-binding)","16/Oct/13 18:07;hadoopqa;{color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12608724/HADOOP-9078-trunk--N9.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 5 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  The javadoc tool did not generate any warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:red}-1 core tests{color}.  The patch failed these unit tests in hadoop-common-project/hadoop-common hadoop-hdfs-project/hadoop-hdfs:

                  org.apache.hadoop.metrics2.impl.TestMetricsSystemImpl

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HADOOP-Build/3229//testReport/
Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/3229//console

This message is automatically generated.","16/Oct/13 22:42;jeagles;Thanks Ivan and Robert.","16/Oct/13 23:04;hudson;SUCCESS: Integrated in Hadoop-trunk-Commit #4619 (See [https://builds.apache.org/job/Hadoop-trunk-Commit/4619/])
HADOOP-9078. enhance unit-test coverage of class org.apache.hadoop.fs.FileContext (Ivan A. Veselovsky via jeagles) (jeagles: http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1532928)
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/CHANGES.txt
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/FileContextMainOperationsBaseTest.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/FileContextPermissionBase.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/TestLocalFSFileContextMainOperations.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/viewfs/TestFcMainOperationsLocalFs.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/TestHDFSFileContextMainOperations.java
","17/Oct/13 11:00;hudson;SUCCESS: Integrated in Hadoop-Yarn-trunk #365 (See [https://builds.apache.org/job/Hadoop-Yarn-trunk/365/])
HADOOP-9078. enhance unit-test coverage of class org.apache.hadoop.fs.FileContext (Ivan A. Veselovsky via jeagles) (jeagles: http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1532928)
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/CHANGES.txt
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/FileContextMainOperationsBaseTest.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/FileContextPermissionBase.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/TestLocalFSFileContextMainOperations.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/viewfs/TestFcMainOperationsLocalFs.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/TestHDFSFileContextMainOperations.java
","17/Oct/13 13:19;hudson;FAILURE: Integrated in Hadoop-Hdfs-trunk #1555 (See [https://builds.apache.org/job/Hadoop-Hdfs-trunk/1555/])
HADOOP-9078. enhance unit-test coverage of class org.apache.hadoop.fs.FileContext (Ivan A. Veselovsky via jeagles) (jeagles: http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1532928)
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/CHANGES.txt
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/FileContextMainOperationsBaseTest.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/FileContextPermissionBase.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/TestLocalFSFileContextMainOperations.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/viewfs/TestFcMainOperationsLocalFs.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/TestHDFSFileContextMainOperations.java
","17/Oct/13 14:28;hudson;FAILURE: Integrated in Hadoop-Mapreduce-trunk #1581 (See [https://builds.apache.org/job/Hadoop-Mapreduce-trunk/1581/])
HADOOP-9078. enhance unit-test coverage of class org.apache.hadoop.fs.FileContext (Ivan A. Veselovsky via jeagles) (jeagles: http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1532928)
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/CHANGES.txt
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/FileContextMainOperationsBaseTest.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/FileContextPermissionBase.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/TestLocalFSFileContextMainOperations.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/viewfs/TestFcMainOperationsLocalFs.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/TestHDFSFileContextMainOperations.java
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
enhance unit-test coverage of package o.a.h.metrics2,HADOOP-9291,12631277,Test,Closed,HADOOP,Hadoop Common,software,omalley,Hadoop Common is the common library for Apache Hadoop.,http://hadoop.apache.org/,Major,Fixed,iveselovsky,iveselovsky,iveselovsky,07/Feb/13 15:28,12/May/16 18:24,12/Jan/21 11:55,22/Oct/13 03:50,2.3.0,3.0.0-alpha1,,,2.3.0,,,,,,,,,,0,,,,,aajisaka,aklochkov,hudson,iveselovsky,jeagles,jlowe,nroberts,ozawa,robsparker,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"04/Oct/13 19:21;iveselovsky;HADOOP-9291--N7.patch;https://issues.apache.org/jira/secure/attachment/12606865/HADOOP-9291--N7.patch","16/Oct/13 19:41;iveselovsky;HADOOP-9291--N8.patch;https://issues.apache.org/jira/secure/attachment/12608787/HADOOP-9291--N8.patch","08/Feb/13 11:52;iveselovsky;HADOOP-9291-branch-0.23--N4.patch;https://issues.apache.org/jira/secure/attachment/12568556/HADOOP-9291-branch-0.23--N4.patch","08/Feb/13 11:52;iveselovsky;HADOOP-9291-trunk--N4.patch;https://issues.apache.org/jira/secure/attachment/12568557/HADOOP-9291-trunk--N4.patch","28/Feb/13 18:01;iveselovsky;HADOOP-9291-trunk--N5.patch;https://issues.apache.org/jira/secure/attachment/12571441/HADOOP-9291-trunk--N5.patch","10/Apr/13 15:51;iveselovsky;HADOOP-9291-trunk--N6.patch;https://issues.apache.org/jira/secure/attachment/12578024/HADOOP-9291-trunk--N6.patch","01/Mar/13 13:14;iveselovsky;HADOOP-9291-trunk--N6.patch;https://issues.apache.org/jira/secure/attachment/12571576/HADOOP-9291-trunk--N6.patch",,,,,,,,,,,,,,,,,7.0,,,,,,,,,,,,,,,,,,,,2013-02-08 12:36:10.106,,,false,,,,,,,,,,,,,,,,,311773,,,,,Tue Oct 22 13:50:32 UTC 2013,,,,,,,"0|i1hsyn:",312119,,,,,,,,,,,,,,,,,,,,,,,"08/Feb/13 11:52;iveselovsky;patch for trunk is also applicable to branch ""branch-2"".","08/Feb/13 12:36;hadoopqa;{color:green}+1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12568557/HADOOP-9291-trunk--N4.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 2 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  The javadoc tool did not generate any warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:green}+1 core tests{color}.  The patch passed unit tests in hadoop-common-project/hadoop-common.

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HADOOP-Build/2165//testReport/
Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/2165//console

This message is automatically generated.","28/Feb/13 18:01;iveselovsky;small correction to the patch for trunk.","28/Feb/13 18:45;hadoopqa;{color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12571441/HADOOP-9291-trunk--N5.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 2 new or modified test files.

  {color:red}-1 one of tests included doesn't have a timeout.{color}

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  The javadoc tool did not generate any warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:green}+1 core tests{color}.  The patch passed unit tests in hadoop-common-project/hadoop-common.

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HADOOP-Build/2245//testReport/
Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/2245//console

This message is automatically generated.","01/Mar/13 13:14;iveselovsky;added timeout for the added test to satisfy the patch verification requirement.","01/Mar/13 13:55;hadoopqa;{color:green}+1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12571576/HADOOP-9291-trunk--N6.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 2 new or modified test files.

    {color:green}+1 tests included appear to have a timeout.{color}

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  The javadoc tool did not generate any warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:green}+1 core tests{color}.  The patch passed unit tests in hadoop-common-project/hadoop-common.

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HADOOP-Build/2250//testReport/
Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/2250//console

This message is automatically generated.","10/Apr/13 15:51;iveselovsky;N6: trunk version of the patch updated because of merge over HADOOP-9467.","10/Apr/13 16:33;hadoopqa;{color:green}+1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12578024/HADOOP-9291-trunk--N6.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 2 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  The javadoc tool did not generate any warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:green}+1 core tests{color}.  The patch passed unit tests in hadoop-common-project/hadoop-common.

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HADOOP-Build/2438//testReport/
Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/2438//console

This message is automatically generated.","02/Oct/13 15:58;robsparker;[~iveselovsky], unfortunately the patch is stale, sorry for the delay in reviewing.","04/Oct/13 19:21;iveselovsky;Robert, sure, the patch is updated (HADOOP-9291--N7.patch).
It is equally applicable to trunk and branch-2.","04/Oct/13 20:42;hadoopqa;{color:green}+1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12606865/HADOOP-9291--N7.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 2 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  The javadoc tool did not generate any warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:green}+1 core tests{color}.  The patch passed unit tests in hadoop-common-project/hadoop-common.

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HADOOP-Build/3173//testReport/
Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/3173//console

This message is automatically generated.","14/Oct/13 18:30;nroberts;Ivan, thanks for the update. A couple of comments on the patch. 
# In the following code I don't think there is any guarantee on the order of the tags or the metrics (In fact I saw it fail once because testTag2 was emitted first). The ""testMetrics2=1"" part of the comment is also not correct.
{code}
   // Check the out file content. Should be something like the following:
    //1360244820087 test1.testRecord1: Context=test1, testTag1=testTagValue1, testTag2=testTagValue2, Hostname=myhost, testMetric1=1, testMetric2=1
    //1360244820089 test1.testRecord2: Context=test1, testTag22=testTagValue22, Hostname=myhost
    Pattern expectedContentPattern = Pattern.compile(
       ""^\\d+\\s+test1.testRecord1:\\s+Context=test1,\\s+testTag1=testTagValue1,"" +
       ""\\s+testTag2=testTagValue2,\\s+Hostname=.*,\\s+testMetric1=1,\\s+testMetric2=2"" +
    	 ""$[\\n\\r]*^\\d+\\s+test1.testRecord2:\\s+Context=test1,"" +
    	 ""\\s+testTag22=testTagValue22,\\s+Hostname=.*$[\\n\\r]*"", 
    		Pattern.MULTILINE);
    System.out.println(expectedContentPattern.matcher(outFileContent).matches());
    assertTrue(expectedContentPattern.matcher(outFileContent).matches());
{code}

# This is minor - In TestpatternFilter, it might have been nice to have shouldAccept(wl, tags) actually specifically state which elements of the array are supposed to be accepted vs. rejected (currently it just counts the number of accepts/rejects and assumes the right ones were accepted/rejected). I think there are enough test case combinations that we would catch something wrong, but I didn't study it long enough to be 100% convinced of that.","16/Oct/13 19:42;iveselovsky;Nathan, thanks for review. The patch is updated with the corrections: HADOOP-9291--N8.patch","16/Oct/13 20:47;hadoopqa;{color:green}+1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12608787/HADOOP-9291--N8.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 2 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  The javadoc tool did not generate any warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:green}+1 core tests{color}.  The patch passed unit tests in hadoop-common-project/hadoop-common.

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HADOOP-Build/3231//testReport/
Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/3231//console

This message is automatically generated.","18/Oct/13 13:24;nroberts;Thanks Ivan. Updated patch (N8) looks good to me. +1
","22/Oct/13 03:50;jeagles;Changes look good. Putting these changes into 2.3.0 and 3.0.0. Thanks everybody.","22/Oct/13 03:57;hudson;SUCCESS: Integrated in Hadoop-trunk-Commit #4640 (See [https://builds.apache.org/job/Hadoop-trunk-Commit/4640/])
HADOOP-9291. enhance unit-test coverage of package o.a.h.metrics2 (Ivan A. Veselovsky via jeagles) (jeagles: http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1534474)
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/CHANGES.txt
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/metrics2/filter/AbstractPatternFilter.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/metrics2/package-info.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/metrics2/filter/TestPatternFilter.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/metrics2/sink/TestFileSink.java
","22/Oct/13 11:01;hudson;SUCCESS: Integrated in Hadoop-Yarn-trunk #370 (See [https://builds.apache.org/job/Hadoop-Yarn-trunk/370/])
HADOOP-9291. enhance unit-test coverage of package o.a.h.metrics2 (Ivan A. Veselovsky via jeagles) (jeagles: http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1534474)
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/CHANGES.txt
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/metrics2/filter/AbstractPatternFilter.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/metrics2/package-info.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/metrics2/filter/TestPatternFilter.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/metrics2/sink/TestFileSink.java
","22/Oct/13 11:35;hudson;FAILURE: Integrated in Hadoop-Hdfs-trunk #1560 (See [https://builds.apache.org/job/Hadoop-Hdfs-trunk/1560/])
HADOOP-9291. enhance unit-test coverage of package o.a.h.metrics2 (Ivan A. Veselovsky via jeagles) (jeagles: http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1534474)
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/CHANGES.txt
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/metrics2/filter/AbstractPatternFilter.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/metrics2/package-info.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/metrics2/filter/TestPatternFilter.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/metrics2/sink/TestFileSink.java
","22/Oct/13 13:50;hudson;FAILURE: Integrated in Hadoop-Mapreduce-trunk #1586 (See [https://builds.apache.org/job/Hadoop-Mapreduce-trunk/1586/])
HADOOP-9291. enhance unit-test coverage of package o.a.h.metrics2 (Ivan A. Veselovsky via jeagles) (jeagles: http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1534474)
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/CHANGES.txt
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/metrics2/filter/AbstractPatternFilter.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/metrics2/package-info.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/metrics2/filter/TestPatternFilter.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/metrics2/sink/TestFileSink.java
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Improve code coverage of RMAdminCLI,HADOOP-9598,12649278,Test,Closed,HADOOP,Hadoop Common,software,omalley,Hadoop Common is the common library for Apache Hadoop.,http://hadoop.apache.org/,Major,Fixed,aklochkov,aleksgor,aleksgor,24/May/13 08:26,12/May/16 18:24,12/Jan/21 11:55,23/Oct/13 04:16,2.0.5-alpha,3.0.0-alpha1,,,2.3.0,,,,,,,,,,0,,,,,aklochkov,aleksgor,hudson,iveselovsky,jeagles,jlowe,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"16/Oct/13 02:08;aklochkov;HADOOP-9598--n3.patch;https://issues.apache.org/jira/secure/attachment/12608635/HADOOP-9598--n3.patch","19/Jun/13 06:06;aleksgor;HADOOP-9598-branch-0.23-v1.patch;https://issues.apache.org/jira/secure/attachment/12588545/HADOOP-9598-branch-0.23-v1.patch","24/May/13 08:27;aleksgor;HADOOP-9598-branch-0.23.patch;https://issues.apache.org/jira/secure/attachment/12584658/HADOOP-9598-branch-0.23.patch","16/Oct/13 02:17;aklochkov;HADOOP-9598-branch-2--n3.patch;https://issues.apache.org/jira/secure/attachment/12608636/HADOOP-9598-branch-2--n3.patch","19/Jun/13 06:06;aleksgor;HADOOP-9598-trunk-v1.patch;https://issues.apache.org/jira/secure/attachment/12588546/HADOOP-9598-trunk-v1.patch","27/Jun/13 12:49;aleksgor;HADOOP-9598-trunk-v2.patch;https://issues.apache.org/jira/secure/attachment/12589897/HADOOP-9598-trunk-v2.patch","24/May/13 08:27;aleksgor;HADOOP-9598-trunk.patch;https://issues.apache.org/jira/secure/attachment/12584659/HADOOP-9598-trunk.patch",,,,,,,,,,,,,,,,,7.0,,,,,,,,,,,,,,,,,,,,2013-05-24 08:44:33.512,,,false,,,,,,,,,,,,,,,,,329605,,,,,Wed Oct 23 14:05:24 UTC 2013,,,,,,,"0|i1kv5z:",329940,,,,,,,,,,,,,,,,,,,,,,,"24/May/13 08:29;aleksgor;patch HADOOP-9598-branch-0.23.patch for branch-0.23
patch HADOOP-9598-trunk.patch for branch-2 and trunk

","24/May/13 08:44;hadoopqa;{color:green}+1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12584659/HADOOP-9598-trunk.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 2 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  The javadoc tool did not generate any warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:green}+1 core tests{color}.  The patch passed unit tests in hadoop-yarn-project/hadoop-yarn/hadoop-yarn-client.

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HADOOP-Build/2564//testReport/
Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/2564//console

This message is automatically generated.","19/Jun/13 06:07;aleksgor;patches were updated.

patch HADOOP-9598-branch-0.23-v1.patch for branch-0.23
patch HADOOP-9598-trunk-v1.patch for branch-2 and trunk","19/Jun/13 07:16;hadoopqa;{color:green}+1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12588546/HADOOP-9598-trunk-v1.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 2 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  The javadoc tool did not generate any warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:green}+1 core tests{color}.  The patch passed unit tests in hadoop-yarn-project/hadoop-yarn/hadoop-yarn-client.

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HADOOP-Build/2673//testReport/
Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/2673//console

This message is automatically generated.","27/Jun/13 12:49;aleksgor;branch for trunk was changed
patch HADOOP-9598-branch-0.23-v1.patch for branch-0.23
patch HADOOP-9598-trunk-v2.patch for branch-2 and trunk","27/Jun/13 13:08;hadoopqa;{color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12589897/HADOOP-9598-trunk-v2.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 2 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  The javadoc tool did not generate any warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:red}-1 core tests{color}.  The patch failed these unit tests in hadoop-yarn-project/hadoop-yarn/hadoop-yarn-client:

                  org.apache.hadoop.yarn.client.api.impl.TestNMClient

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HADOOP-Build/2707//testReport/
Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/2707//console

This message is automatically generated.","16/Oct/13 02:08;aklochkov;Rebased and simplified the patch.","16/Oct/13 02:17;aklochkov;attaching a patch applicable to branch-2","16/Oct/13 02:30;hadoopqa;{color:green}+1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12608635/HADOOP-9598--n3.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 1 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  The javadoc tool did not generate any warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:green}+1 core tests{color}.  The patch passed unit tests in hadoop-yarn-project/hadoop-yarn/hadoop-yarn-client.

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HADOOP-Build/3223//testReport/
Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/3223//console

This message is automatically generated.","16/Oct/13 02:40;hadoopqa;{color:green}+1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12608636/HADOOP-9598-branch-2--n3.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 1 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  The javadoc tool did not generate any warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:green}+1 core tests{color}.  The patch passed unit tests in hadoop-yarn-project/hadoop-yarn/hadoop-yarn-client.

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HADOOP-Build/3224//testReport/
Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/3224//console

This message is automatically generated.","23/Oct/13 04:14;jeagles;+1 Changes improve the coverage of RMAdminCLI. Thanks Aleksey and Andrey.","23/Oct/13 04:17;hudson;SUCCESS: Integrated in Hadoop-trunk-Commit #4648 (See [https://builds.apache.org/job/Hadoop-trunk-Commit/4648/])
HADOOP-9598. Improve code coverage of RMAdminCLI (Aleksey Gorshkov and Andrey Klochkov via jeagles) (jeagles: http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1534905)
* /hadoop/common/trunk/hadoop-yarn-project/CHANGES.txt
* /hadoop/common/trunk/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-client/src/main/java/org/apache/hadoop/yarn/client/cli/RMAdminCLI.java
* /hadoop/common/trunk/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-client/src/test/java/org/apache/hadoop/yarn/client/TestRMAdminCLI.java
","23/Oct/13 10:43;hudson;FAILURE: Integrated in Hadoop-Yarn-trunk #371 (See [https://builds.apache.org/job/Hadoop-Yarn-trunk/371/])
HADOOP-9598. Improve code coverage of RMAdminCLI (Aleksey Gorshkov and Andrey Klochkov via jeagles) (jeagles: http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1534905)
* /hadoop/common/trunk/hadoop-yarn-project/CHANGES.txt
* /hadoop/common/trunk/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-client/src/main/java/org/apache/hadoop/yarn/client/cli/RMAdminCLI.java
* /hadoop/common/trunk/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-client/src/test/java/org/apache/hadoop/yarn/client/TestRMAdminCLI.java
","23/Oct/13 11:35;hudson;FAILURE: Integrated in Hadoop-Hdfs-trunk #1561 (See [https://builds.apache.org/job/Hadoop-Hdfs-trunk/1561/])
HADOOP-9598. Improve code coverage of RMAdminCLI (Aleksey Gorshkov and Andrey Klochkov via jeagles) (jeagles: http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1534905)
* /hadoop/common/trunk/hadoop-yarn-project/CHANGES.txt
* /hadoop/common/trunk/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-client/src/main/java/org/apache/hadoop/yarn/client/cli/RMAdminCLI.java
* /hadoop/common/trunk/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-client/src/test/java/org/apache/hadoop/yarn/client/TestRMAdminCLI.java
","23/Oct/13 14:05;hudson;FAILURE: Integrated in Hadoop-Mapreduce-trunk #1587 (See [https://builds.apache.org/job/Hadoop-Mapreduce-trunk/1587/])
HADOOP-9598. Improve code coverage of RMAdminCLI (Aleksey Gorshkov and Andrey Klochkov via jeagles) (jeagles: http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1534905)
* /hadoop/common/trunk/hadoop-yarn-project/CHANGES.txt
* /hadoop/common/trunk/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-client/src/main/java/org/apache/hadoop/yarn/client/cli/RMAdminCLI.java
* /hadoop/common/trunk/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-client/src/test/java/org/apache/hadoop/yarn/client/TestRMAdminCLI.java
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Add tests that validate winutils chmod behavior on folders,HADOOP-9525,12645125,Test,Closed,HADOOP,Hadoop Common,software,omalley,Hadoop Common is the common library for Apache Hadoop.,http://hadoop.apache.org/,Major,Fixed,ivanmi,ivanmi,ivanmi,29/Apr/13 03:04,12/May/16 18:24,12/Jan/21 11:55,29/Mar/14 06:39,3.0.0-alpha1,,,,2.4.0,,,,,,test,util,,,0,,,As part of HADOOP-9413 and HDFS-4610 I realized that we don't have tests that validate the behavior of winutils chmod on folders. It would be good to add additional tests to both validate the functionality and use them as means to document some subtle differences in behavior between Unix and Windows chmod.,,cnauroth,Fan04290,hudson,ivanmi,stevel@apache.org,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"23/Mar/14 18:46;ivanmi;HADOOP-9525.2.patch;https://issues.apache.org/jira/secure/attachment/12636258/HADOOP-9525.2.patch","29/Apr/13 03:08;ivanmi;HADOOP-9525.patch;https://issues.apache.org/jira/secure/attachment/12580925/HADOOP-9525.patch",,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,2013-05-01 17:33:20.094,,,false,,,,,,,,,,,,,,,,,325487,Reviewed,,,,Sun Mar 30 14:07:28 UTC 2014,,,,,,,"0|i1k5k7:",325832,,,,,,,,,,,,,2.4.0,,,,,,,,,,"29/Apr/13 03:08;ivanmi;Attaching first iteration for early review. Want to spend a bit more time on this before it is committed.","01/May/13 17:33;stevel@apache.org;Test should downgrade to a skip when !windows; you can use the @Assume() condition. See https://issues.apache.org/jira/browse/HADOOP-9427","02/May/13 01:45;ivanmi;bq. Test should downgrade to a skip when !windows; you can use the @Assume() condition.
Thanks Steve, sounds good, will make this change to TestWinUtils in the next iteration. ","23/Mar/14 18:46;ivanmi;Polishing up the original patch. ","23/Mar/14 19:46;hadoopqa;{color:green}+1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12636258/HADOOP-9525.2.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 1 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  There were no new javadoc warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:green}+1 core tests{color}.  The patch passed unit tests in hadoop-common-project/hadoop-common.

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HADOOP-Build/3697//testReport/
Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/3697//console

This message is automatically generated.","24/Mar/14 17:49;cnauroth;+1 for the patch.  Thank you, Ivan.","29/Mar/14 05:36;ivanmi;Thanks Chris for the review, will commit the patch shortly. ","29/Mar/14 06:39;ivanmi;I committed the patch to trunk, branch-2 and branch-2.4.","29/Mar/14 12:17;hudson;SUCCESS: Integrated in Hadoop-trunk-Commit #5430 (See [https://builds.apache.org/job/Hadoop-trunk-Commit/5430/])
HADOOP-9525. Add tests that validate winutils chmod behavior on folders. Contributed by Ivan Mitic. (ivanmi: http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1582958)
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/CHANGES.txt
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/util/TestWinUtils.java
","29/Mar/14 13:32;hudson;FAILURE: Integrated in Hadoop-Mapreduce-trunk #1741 (See [https://builds.apache.org/job/Hadoop-Mapreduce-trunk/1741/])
HADOOP-9525. Add tests that validate winutils chmod behavior on folders. Contributed by Ivan Mitic. (ivanmi: http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1582958)
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/CHANGES.txt
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/util/TestWinUtils.java
","30/Mar/14 11:21;hudson;SUCCESS: Integrated in Hadoop-Yarn-trunk #524 (See [https://builds.apache.org/job/Hadoop-Yarn-trunk/524/])
HADOOP-9525. Add tests that validate winutils chmod behavior on folders. Contributed by Ivan Mitic. (ivanmi: http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1582958)
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/CHANGES.txt
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/util/TestWinUtils.java
","30/Mar/14 14:07;hudson;FAILURE: Integrated in Hadoop-Hdfs-trunk #1716 (See [https://builds.apache.org/job/Hadoop-Hdfs-trunk/1716/])
HADOOP-9525. Add tests that validate winutils chmod behavior on folders. Contributed by Ivan Mitic. (ivanmi: http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1582958)
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/CHANGES.txt
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/util/TestWinUtils.java
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Parallel testing hadoop-common,HADOOP-9287,12631015,Test,Closed,HADOOP,Hadoop Common,software,omalley,Hadoop Common is the common library for Apache Hadoop.,http://hadoop.apache.org/,Major,Fixed,aklochkov,ozawa,ozawa,06/Feb/13 06:32,12/May/16 18:23,12/Jan/21 11:55,30/May/13 22:47,3.0.0-alpha1,,,,2.1.0-beta,,,,,,test,,,,0,,,"The maven surefire plugin supports parallel testing feature. By using it, the tests can be run more faster.
",,aklochkov,bpodgursky,cdouglas,cnauroth,eli,hudson,ivanmi,jlowe,ozawa,schu,tgraves,tomwhite,vicaya,vinodkv,wuzesheng,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,HADOOP-9638,,,,,,,,,,"18/Mar/13 07:46;ozawa;HADOOP-9287--N3.patch;https://issues.apache.org/jira/secure/attachment/12574123/HADOOP-9287--N3.patch","11/Mar/13 16:08;aklochkov;HADOOP-9287--N3.patch;https://issues.apache.org/jira/secure/attachment/12573108/HADOOP-9287--N3.patch","29/Mar/13 21:48;aklochkov;HADOOP-9287--N4.patch;https://issues.apache.org/jira/secure/attachment/12576172/HADOOP-9287--N4.patch","16/Apr/13 04:35;aklochkov;HADOOP-9287--N5.patch;https://issues.apache.org/jira/secure/attachment/12578866/HADOOP-9287--N5.patch","24/May/13 21:00;aklochkov;HADOOP-9287--N6.patch;https://issues.apache.org/jira/secure/attachment/12584759/HADOOP-9287--N6.patch","29/May/13 17:58;aklochkov;HADOOP-9287--N7.patch;https://issues.apache.org/jira/secure/attachment/12585264/HADOOP-9287--N7.patch","31/May/13 21:13;aklochkov;HADOOP-9287-branch-2--N1.patch;https://issues.apache.org/jira/secure/attachment/12585667/HADOOP-9287-branch-2--N1.patch","06/Feb/13 06:44;ozawa;HADOOP-9287.1.patch;https://issues.apache.org/jira/secure/attachment/12568176/HADOOP-9287.1.patch","19/Feb/13 22:24;aklochkov;HADOOP-9287.patch;https://issues.apache.org/jira/secure/attachment/12570012/HADOOP-9287.patch","15/Feb/13 23:29;aklochkov;HADOOP-9287.patch;https://issues.apache.org/jira/secure/attachment/12569614/HADOOP-9287.patch",,,,,,,,,,,,,,10.0,,,,,,,,,,,,,,,,,,,,2013-02-06 16:41:24.285,,,false,,,,,,,,,,,,,,,,,311511,Reviewed,,,,Tue Jun 11 17:03:41 UTC 2013,,,,,,,"0|i1hrcf:",311857,,,,,,,,,,,,,2.1.0-beta,,,,,,,,,,"06/Feb/13 06:44;ozawa;Supports parallel testing.","06/Feb/13 16:41;cnauroth;It would be great to speed up the tests, but we might need to make some changes in our test code to guarantee that each test is isolated from any other tests that could be running in parallel.

One example is {{TestLocalFSFileContextMainOperations}} and {{TestFcMainOperationsLocalFs}}.  Both of these are subclasses of {{FileContextMainOperationsBaseTest}}.  The base class contains the logic for setting up the test root directory:

{code}
  static {
    File testBuildData = new File(System.getProperty(""test.build.data"",
                                    ""build/test/data""));
    Path localFsRootPath = new Path(testBuildData.getAbsolutePath(), 
                                    ""root-uri"");
    LOCAL_FS_ROOT_PATH = localFsRootPath.makeQualified(LocalFileSystem.NAME, null);
  }
{code}

If I understand the behavior of <parallel>classes</parallel>, then it means {{TestLocalFSFileContextMainOperations}} and {{TestFcMainOperationsLocalFs}} could get scheduled for parallel execution, and they both would operate on the same {{LOCAL_FS_ROOT_PATH}}.  The tests could interfere with each other by creating or deleting unexpected files and cause spurious test failures.

This is just one example off the top of my head.  There could be other test isolation issues.
","08/Feb/13 23:53;aklochkov;By coincidence I've been working on this recently. As Chris is pointing out, just turning on parallel testing in Surefire would lead to various problems as current tests are not ready to be used this way. So what I did is fixed hadoop-common-project/hadoop-common and hadoop-hdfs-project/hadoop-hdfs to allow such execution, and the results seem positive.

The amount of changes required to remove contention among tests is not small, but the changes are straightforward. Parallel execution may be turned on by activating profile ""parallel-tests"". Number of forks to use may be tuned using -DtestsThreadCount (4 is the default). 

Most of changes in hadoop-common are related to FileContextTestHelper and FileSystemTestHelper -- some static methods are transformed into instance methods, to make tests use different directories by default. Tests which depend on these classes are changed accordingly.

Most of changes in hadoop-hdfs are related to MiniDFSCluster. Earlier, most of tests used the same dir to place MiniDFSCluster data. The modifications make every MiniDFSCluster instance to use a new dir (by default). When several instances need to use the same dir, it needs to be set explicitly using MiniDFSCluster.Builds.dfsBaseDir(dfsBaseDir). 

As I know MiniDFSCluster is used in other projects like HBase so changing it's API and default behavior may lead to issues there. So I left all existing methods intact, marking some of them as deprecated, and introduced an environment var which switches new behavior on, and by default the old single dir behavior is active. 

Currently it takes 7min to run hadoop-common tests with 4 parallel forks on my 4core laptop, vs 15min in sequential mode. For hdfs it's 42min vs 1hr 39min. It may give even a bigger improvement if used on a CI node with many cores. 

I'm still in process of testing this. In particular, I'm going to verify projects which depend on Mini cluster infrastructure like HBase, Pig and Hive.

My existing patch is for both hadoop-common and hadoop-hdfs. The tests in these modules are coupled and changing one without changing the other wouldn't work. Tsuyoshi, do you mind if I change the title of this task adding HDFS and reassign it to myself? 
","09/Feb/13 05:54;cnauroth;Tsuyoshi and Andrey, thank you for investigating this.  The speedup sounds impressive!

When you're ready to publish the patch, I'd like to make sure that we test on Windows too.  More specifically, I'd like to test the effect of merging it to branch-trunk-win.  If you don't have access to a Windows VM, I'd be happy to test the patch myself.

One thing we've noticed during Windows compatibility work is that some of the test code had race conditions that would cause failures on Windows that were not showing up at all on Linux, just due to differences in the way the OS chooses to schedule threads.  Running the parallel tests on both Linux and Windows is more likely to reveal race conditions.
","12/Feb/13 08:12;ozawa;Andrey,

Your experience is very helpful for me. The improvement rate is very significant, so we shold get done this work :-)

I've assigned this ticket to you, so please go ahead your work. I'll do work about Hadoop/MapReduce. About HDFS, I created separete ticket(HDFS-4491). 

Chris, 

OK, we'll notify you when our patches get ready.
Thanks for your help!","15/Feb/13 23:29;aklochkov;Overview of changes in the patch:

# Many static methods in FileContextTestHelper and FileSystemTestHelper are transformed into instance methods. Clients are updated accordingly.
# Fixes in tests which used hard-coded paths for temporary data. These paths were modified to to avoid contention with other tests.
# Changes in org.apache.hadoop.ha tests to avoid contention when choosing ports for ZK
# A few fixes in hadoop-hdfs, hadoop-tools which are required due to changes in hadoop-common","16/Feb/13 01:44;hadoopqa;{color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12569614/HADOOP-9287.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 52 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  The javadoc tool did not generate any warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:red}-1 core tests{color}.  The patch failed these unit tests in hadoop-common-project/hadoop-common hadoop-hdfs-project/hadoop-hdfs hadoop-tools/hadoop-distcp hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager:

                  org.apache.hadoop.tools.mapred.TestUniformSizeInputFormat

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HADOOP-Build/2197//testReport/
Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/2197//console

This message is automatically generated.","19/Feb/13 22:24;aklochkov;Updated patch by getting back some paths of the form ""/tmp/TestXXX"" which were not related to local file system but where used for DFS operations, so there's no need to change this. Thanks to [~cnauroth] for reviewing related patch at HDFS-4491","20/Feb/13 00:26;hadoopqa;{color:green}+1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12570012/HADOOP-9287.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 52 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  The javadoc tool did not generate any warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:green}+1 core tests{color}.  The patch passed unit tests in hadoop-common-project/hadoop-common hadoop-hdfs-project/hadoop-hdfs hadoop-tools/hadoop-distcp hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager.

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HADOOP-Build/2207//testReport/
Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/2207//console

This message is automatically generated.","11/Mar/13 16:08;aklochkov;The patch is updated with a few additional fixes.","11/Mar/13 18:07;hadoopqa;{color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12573108/HADOOP-9287--N3.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 52 new or modified test files.

  {color:red}-1 one of tests included doesn't have a timeout.{color}

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  The javadoc tool did not generate any warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:red}-1 core tests{color}.  The patch failed these unit tests in hadoop-common-project/hadoop-common hadoop-hdfs-project/hadoop-hdfs hadoop-tools/hadoop-distcp hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager:

                  org.apache.hadoop.hdfs.server.datanode.TestDataDirs

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HADOOP-Build/2309//testReport/
Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/2309//console

This message is automatically generated.","11/Mar/13 20:36;aklochkov;The patch affects a lot of tests and setting timeout for all of them shouldn't be done as part of this patch.
TestDataDirs is broken in trunk currently, seems like it's caused by HADOOP-8973","18/Mar/13 07:46;ozawa;Thanks for your work, Andrey!

The attached patch is exactly same one by Andrey Klochkov. I've confirmed however, that it works well now, so I attach it again.","18/Mar/13 07:55;ozawa;Andrey, I reviewed your patch after attaching.
I found some points the patch should be fixed - let's split your patch into 4 patches:

1. tests about hadoop-tools
2. tests about hadoop-hdfs-project
3. tests about hadoop-yarn-project
4. tests about hadoop-common

I think mixing changes against different projects in one patch causes confusing, so it should be splited.","18/Mar/13 09:58;hadoopqa;{color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12574123/HADOOP-9287--N3.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 52 new or modified test files.

  {color:red}-1 one of tests included doesn't have a timeout.{color}

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  The javadoc tool did not generate any warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:green}+1 core tests{color}.  The patch passed unit tests in hadoop-common-project/hadoop-common hadoop-hdfs-project/hadoop-hdfs hadoop-tools/hadoop-distcp hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager.

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HADOOP-Build/2336//testReport/
Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/2336//console

This message is automatically generated.","18/Mar/13 16:24;aklochkov;Tsuyoshi, the changes in this patch are done to enable parallel execution in hadoop-common only. Some code in dependent projects has to be changed due to dependencies. If the patch is separated, individual smaller patches will make the project non compilable.","29/Mar/13 21:48;aklochkov;Updating the patch according to changes in trunk","30/Mar/13 00:31;hadoopqa;{color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12576172/HADOOP-9287--N4.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 52 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  The javadoc tool did not generate any warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:red}-1 core tests{color}.  The patch failed these unit tests in hadoop-common-project/hadoop-common hadoop-hdfs-project/hadoop-hdfs hadoop-tools/hadoop-distcp hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager:

                  org.apache.hadoop.fs.TestFcHdfsSymlink

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HADOOP-Build/2385//testReport/
Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/2385//console

This message is automatically generated.","01/Apr/13 23:29;aklochkov;TestFcHdfsSymlink is broken in trunk","16/Apr/13 04:35;aklochkov;Updating the patch according to changes in trunk","16/Apr/13 06:51;hadoopqa;{color:green}+1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12578866/HADOOP-9287--N5.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 52 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  The javadoc tool did not generate any warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:green}+1 core tests{color}.  The patch passed unit tests in hadoop-common-project/hadoop-common hadoop-hdfs-project/hadoop-hdfs hadoop-tools/hadoop-distcp hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-resourcemanager.

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HADOOP-Build/2449//testReport/
Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/2449//console

This message is automatically generated.","01/May/13 20:58;jlowe;Thanks for working on this, Andrey.  Overall patch looks good, and I agree the HDFS test changes are tightly coupled with the changes in common.  It would be a pain to tackle these changes in separate JIRAs, and since it's only modifying tests I'm inclined to keep that as one patch.  However the changes to the hadoop-yarn tests have little to do with parallel testing in the hadoop-common project and could trivially be separated.  Could you please move these to a separate YARN JIRA?

[~cnauroth], have you had a chance to kick the tires on this patch for Windows?  Given that the tests do not run in parallel by default, I don't believe the concern about race conditions will affect the Windows build unless it explicitly asks for a parallel test run.  However it would be good to get another datapoint to see if the tests run successfully in parallel on Windows or if there's a test collision that only seems to happen on that platform.","03/May/13 19:46;cnauroth;[~jlowe], thanks for pinging me on this.  I expect I'll get a chance to try out the current patch within the next few days.","04/May/13 16:52;ivanmi;Thanks folks for working on this! The community will find this super useful!

I went over the patch and the approach from the patch and have a couple of suggestions/comments:
 - As part of this effort, it would be good to enumerate patterns that can cause concurrent tests to fail (you guys must know them already :)). One is local file system conflict. Another could be conflict on ports. This would be of great help for future development so that the community can keep a watch on those.
 - Instead of changing individual tests to use unique test folder paths, couldn't we just reconfigure test.build.data from the outside (from maven)? This would make tests changes minimal/unnecessary in most cases. The general guideline is to have all tests write local files under test.build.data, so if we have tests that violate this, that's a bug.


IMO, it would be really good if we could have a clear set of guidelines that would allow us to reconfigure tests from the outside and have them run in parallel with no conflicts. Not sure how much effort this is, so just putting it on the table. Hope this helps!
","13/May/13 04:26;vinodkv;bq. As part of this effort, it would be good to enumerate patterns that can cause concurrent tests to fail
+1

Definitely separate the yarn changes, create a new ticket at https://issues.apache.org/jira/browse/YARN. Tx.","20/May/13 16:18;cnauroth;Everyone, I apologize for my delay on this.  I intend to run the parallel testing patches on Windows tonight and report back tomorrow.","21/May/13 16:39;cnauroth;{quote}
As part of this effort, it would be good to enumerate patterns that can cause concurrent tests to fail
{quote}

This sounds like good material for the code review checklist.  http://wiki.apache.org/hadoop/CodeReviewChecklist

{quote}
Instead of changing individual tests to use unique test folder paths, couldn't we just reconfigure test.build.data from the outside (from maven)?
{quote}

This would be very convenient, but unfortunately, I can't think of a way to make it work.  The problem is that our pom.xml code hands over control to maven-surefire-plugin, which then iterates through each test suite class and executes them.  When execution enters maven-surefire-plugin, the Maven properties are frozen at a specific state.  I don't believe there is any way for our pom.xml code to take back control from maven-surefire-plugin between test suite iterations to generate a different unique ID.  Maybe a custom JUnit runner could do it?  At that point, it might be more trouble than it's worth.  Does anyone else have ideas on this?  I'm also not aware of any built-in unique ID property or external plugins that generate unique IDs, so we might end up needing to code another custom plugin of our own.

{quote}
Chris Nauroth, have you had a chance to kick the tires on this patch for Windows?
{quote}

Results look good so far.  First, I ran the tests without the parallel-tests profile enabled.  As expected, this caused no harm to the test results on Windows.  That's a great sign!

Next, I enabled parallel-tests with the default thread count of 4.  Performance improvement was similar to what is reported here: from ~15 minutes down to ~8 minutes, and this is on a fairly wimpy VM.  I did see some new failures though:

# There were failures due to test timeouts in TestCopyPreserveFlag (testPutWithP, testPutWithoutP, testGetWithP, testGetWithoutP), and TestLocalFileSystem (testWorkingDirectory, testCopy).  These all have very short timeouts (1s).  I suspect that multi-threaded execution introduced a bit of context-switching overhead that just barely pushed it over the timeout.  I recommend increasing these timeouts to 10s.  Unfortunately, this suggests that timeout settings + parallel execution could be another source of flaky test results in the future.
# {{TestTFileNoneCodecsByteArrays#testFailureNegativeLength_3}} failed with an EOFException, which makes me think that 2 tests tried to share a file or directory and saw unexpected data.  This inherits from a base class, and I see that the code changes in the base class should have prevented a sharing problem, but perhaps we missed something.  I think we ought to investigate this one before committing.  It's probably not a Windows problem, but rather just a coincidence that the problem manifested on a Windows machine.

[~aklochkov], thanks again for sticking with this issue and responding to the feedback.  This is going to be a big help for developer productivity.  I got pretty excited when the common tests finished so quickly on my machine!  :-)","21/May/13 20:14;ivanmi;Thanks Chris! 

I spent some time reading over the maven parallel test execution and run into the following:
http://maven.apache.org/surefire/maven-surefire-plugin/examples/fork-options-and-parallel-execution.html

Looks like there is a way to specify distinct property values using the pre-defined surefire.forkNumber property.

I went ahead and tried this out, and it seems to provide the behavior we need. For the prototyping purposes I added the following profile to hadoop common pom.xml without other changes:
{noformat}
    <profile>
      <id>parallel-tests</id>
      <build>
        <plugins>
          <plugin>
            <groupId>org.apache.maven.plugins</groupId>
            <artifactId>maven-surefire-plugin</artifactId>
            <version>2.14.1</version>
            <configuration>
              <forkMode>perthread</forkMode>
              <threadCount>4</threadCount>
              <reuseForks>false</reuseForks>
              <parallel>classes</parallel>
              <argLine>-Xmx1024m -XX:+HeapDumpOnOutOfMemoryError -DminiClusterDedicatedDirs=true</argLine>
              <systemPropertyVariables>
                <test.build.data>I:\tmp$<curlybrace>surefire.forkNumber<curlybrace></test.build.data>
              </systemPropertyVariables>
            </configuration>
          </plugin>
        </plugins>
      </build>
    </profile>
{noformat}

And the common test runtime decreased on my dev workstation from 17 minutes to less than 5 minutes! Nice!

I noticed 4 additional test case failures in parallel mode (out of the total of 1969), did not investigate yet.

Additional parameter you’ll notice I’m passing above is reuseForks=false. Otherwise, the same process is reused across test suites. reuseForks will provide additional perf benefit however, it can also cause problems. Default {{mvn test}} also does not reuse the process (if I’m not mistaken), so this seems like the right thing to do as the first step.

There is one catch though, hadoop tests seem to expect that test.build.data exist, so we’ll have to somehow create test folders before we initiate the test run. “Brute force” approach is to always create for example N predefined test.build.data dirs, test.build.data1, test.build.data2, etc. We might be able to do better though.

Let me know what you think. 

","21/May/13 20:45;cnauroth;Ivan, that sounds promising.  I was not aware of surefire.forkNumber.  Thanks for investigating!","24/May/13 19:35;aklochkov;> Definitely separate the yarn changes, create a new ticket at https://issues.apache.org/jira/browse/YARN. Tx.

All changes in YARN code introduced in this patch are required because YARN test classes depend on classes from hadoop-common. If we extract these changes somewhere else, this patch would lead to a non-compilable code. ","24/May/13 20:09;jlowe;bq. All changes in YARN code introduced in this patch are required because YARN test classes depend on classes from hadoop-common. If we extract these changes somewhere else, this patch would lead to a non-compilable code. 

That doesn't seem to be the case.  I extracted the changes under hadoop-yarn-project into a separate patch, applied just that patch to trunk, and trunk built just fine.

Even if that were the case, it's better to track the changes for YARN under a separate JIRA that is dependent upon this one being integrated.  The only reason we aren't doing the same for HDFS is that those changes are intertwined.  We can't commit just the common changes without breaking the HDFS build and vice-versa.  That is not the case with the YARN changes, as the patch builds just fine without them.  Since they are independent changes, they should be tracked in their respective projects.","24/May/13 20:59;aklochkov;Indeed, I was wrong and the changes in YARN are not necessary in this patch. Seems these changes are not needed at all as yarn tests are not supposed to be run in parallel. Eliminating these from the patch. Thanks Jason!","24/May/13 23:04;hadoopqa;{color:green}+1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12584759/HADOOP-9287--N6.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 49 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  The javadoc tool did not generate any warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:green}+1 core tests{color}.  The patch passed unit tests in hadoop-common-project/hadoop-common hadoop-hdfs-project/hadoop-hdfs hadoop-tools/hadoop-distcp.

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HADOOP-Build/2571//testReport/
Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/2571//console

This message is automatically generated.","28/May/13 15:16;jlowe;Thanks for updating the patch, Andrey.  Do we want to discard the YARN changes altogether rather than track them separately?  Even though the YARN tests may not run parallel today, those changes would be useful if that situation changes in the future.

Back to the patch, did you have a chance to investigate the [two issues|https://issues.apache.org/jira/browse/HADOOP-9287?focusedCommentId=13663101&page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-13663101] that [~cnauroth] brought up?

","29/May/13 17:58;aklochkov;[~cnauroth], thanks for catching the issues with TestCopyPreserveFlag/TestLocalFileSystem and TestTFileNoneCodecsByteArrays. I fixed the 1st case according to your suggestion, increasing timeouts up to 10s. In the 2nd case, it turned out that TestTFileNoneCodecsByteArrays and TestTFileNoneCodecsStreams used the same file for temporary output, so I fixed all descendants of TestTFileStream and TestTFileByteArrays to use class names instead of hard-coded values, for tmp file names. ","29/May/13 18:48;aklochkov;[~jlowe], making YARN tests to run in parallel doesn't seem important today, and I'd say it's better to introduce changes for that when it happens to be needed. Just look at the amount of updates I'm putting here just to keep the patch up to date :-)","29/May/13 20:13;hadoopqa;{color:green}+1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12585264/HADOOP-9287--N7.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 58 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  The javadoc tool did not generate any warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:green}+1 core tests{color}.  The patch passed unit tests in hadoop-common-project/hadoop-common hadoop-hdfs-project/hadoop-hdfs hadoop-tools/hadoop-distcp.

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HADOOP-Build/2578//testReport/
Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/2578//console

This message is automatically generated.","30/May/13 16:10;jlowe;+1, lgtm.  Waiting a bit before committing to give [~cnauroth] a chance to verify he's happy with the changes.","30/May/13 17:14;cnauroth;I'm out for several weeks, but please feel free to proceed.  It sounds like prior issues have been addressed.  Thank you very much for this big contribution that will increase developer productivity!","30/May/13 22:47;jlowe;Thanks, Andrey!  I committed this to trunk.

The patch did not apply to branch-2, so if there is interest in parallel testing for 2.x we'll need a separate patch.","30/May/13 22:55;hudson;Integrated in Hadoop-trunk-Commit #3815 (See [https://builds.apache.org/job/Hadoop-trunk-Commit/3815/])
    HADOOP-9287. Parallel-testing hadoop-common. Contributed by Andrey Klochkov (Revision 1488040)

     Result = SUCCESS
jlowe : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1488040
Files : 
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/CHANGES.txt
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/pom.xml
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/conf/TestConfiguration.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/conf/TestConfigurationDeprecation.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/FCStatisticsBaseTest.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/FSMainOperationsBaseTest.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/FileContextCreateMkdirBaseTest.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/FileContextMainOperationsBaseTest.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/FileContextPermissionBase.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/FileContextSymlinkBaseTest.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/FileContextTestHelper.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/FileContextUtilBase.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/FileSystemTestHelper.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/TestFSMainOperationsLocalFileSystem.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/TestFcLocalFsPermission.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/TestFileContextDeleteOnExit.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/TestLocalFSFileContextMainOperations.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/TestLocalFSFileContextSymlink.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/TestLocalFileSystem.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/TestLocalFsFCStatistics.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/shell/TestCopyPreserveFlag.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/viewfs/TestChRootedFileSystem.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/viewfs/TestChRootedFs.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/viewfs/TestFSMainOperationsLocalFileSystem.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/viewfs/TestFcCreateMkdirLocalFs.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/viewfs/TestFcMainOperationsLocalFs.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/viewfs/TestFcPermissionsLocalFs.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/viewfs/TestViewFileSystemDelegation.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/viewfs/TestViewFileSystemLocalFileSystem.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/viewfs/TestViewFileSystemWithAuthorityLocalFileSystem.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/viewfs/TestViewFsTrash.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/viewfs/ViewFileSystemBaseTest.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/viewfs/ViewFileSystemTestSetup.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/viewfs/ViewFsBaseTest.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/viewfs/ViewFsTestSetup.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/ha/ClientBaseWithFixes.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/TestSequenceFile.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/TestSequenceFileSerialization.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/file/tfile/TestTFileByteArrays.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/file/tfile/TestTFileJClassComparatorByteArrays.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/file/tfile/TestTFileLzoCodecsByteArrays.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/file/tfile/TestTFileLzoCodecsStreams.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/file/tfile/TestTFileNoneCodecsByteArrays.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/file/tfile/TestTFileNoneCodecsJClassComparatorByteArrays.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/file/tfile/TestTFileNoneCodecsStreams.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/file/tfile/TestTFileStreams.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/metrics2/impl/TestMetricsSystemImpl.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/TestFcHdfsCreateMkdir.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/TestFcHdfsPermission.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/TestFcHdfsSetUMask.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/TestFcHdfsSymlink.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/TestHDFSFileContextMainOperations.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/viewfs/TestViewFileSystemAtHdfsRoot.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/viewfs/TestViewFileSystemHdfs.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/viewfs/TestViewFsAtHdfsRoot.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/viewfs/TestViewFsDefaultValue.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/viewfs/TestViewFsFileStatusHdfs.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/viewfs/TestViewFsHdfs.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/web/TestFSMainOperationsWebHdfs.java
* /hadoop/common/trunk/hadoop-project/pom.xml
* /hadoop/common/trunk/hadoop-tools/hadoop-distcp/src/test/java/org/apache/hadoop/tools/TestDistCpViewFs.java
","30/May/13 22:56;vinodkv;+1 for getting this into branch-2 assuming it isn't going to create a lot of pain.","30/May/13 23:38;aklochkov;It's not painful to create a patch for branch-2. I'll do some additional testing and submit it here.","31/May/13 10:50;hudson;Integrated in Hadoop-Yarn-trunk #226 (See [https://builds.apache.org/job/Hadoop-Yarn-trunk/226/])
    HADOOP-9287. Parallel-testing hadoop-common. Contributed by Andrey Klochkov (Revision 1488040)

     Result = SUCCESS
jlowe : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1488040
Files : 
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/CHANGES.txt
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/pom.xml
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/conf/TestConfiguration.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/conf/TestConfigurationDeprecation.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/FCStatisticsBaseTest.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/FSMainOperationsBaseTest.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/FileContextCreateMkdirBaseTest.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/FileContextMainOperationsBaseTest.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/FileContextPermissionBase.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/FileContextSymlinkBaseTest.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/FileContextTestHelper.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/FileContextUtilBase.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/FileSystemTestHelper.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/TestFSMainOperationsLocalFileSystem.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/TestFcLocalFsPermission.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/TestFileContextDeleteOnExit.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/TestLocalFSFileContextMainOperations.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/TestLocalFSFileContextSymlink.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/TestLocalFileSystem.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/TestLocalFsFCStatistics.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/shell/TestCopyPreserveFlag.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/viewfs/TestChRootedFileSystem.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/viewfs/TestChRootedFs.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/viewfs/TestFSMainOperationsLocalFileSystem.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/viewfs/TestFcCreateMkdirLocalFs.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/viewfs/TestFcMainOperationsLocalFs.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/viewfs/TestFcPermissionsLocalFs.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/viewfs/TestViewFileSystemDelegation.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/viewfs/TestViewFileSystemLocalFileSystem.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/viewfs/TestViewFileSystemWithAuthorityLocalFileSystem.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/viewfs/TestViewFsTrash.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/viewfs/ViewFileSystemBaseTest.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/viewfs/ViewFileSystemTestSetup.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/viewfs/ViewFsBaseTest.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/viewfs/ViewFsTestSetup.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/ha/ClientBaseWithFixes.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/TestSequenceFile.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/TestSequenceFileSerialization.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/file/tfile/TestTFileByteArrays.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/file/tfile/TestTFileJClassComparatorByteArrays.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/file/tfile/TestTFileLzoCodecsByteArrays.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/file/tfile/TestTFileLzoCodecsStreams.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/file/tfile/TestTFileNoneCodecsByteArrays.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/file/tfile/TestTFileNoneCodecsJClassComparatorByteArrays.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/file/tfile/TestTFileNoneCodecsStreams.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/file/tfile/TestTFileStreams.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/metrics2/impl/TestMetricsSystemImpl.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/TestFcHdfsCreateMkdir.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/TestFcHdfsPermission.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/TestFcHdfsSetUMask.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/TestFcHdfsSymlink.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/TestHDFSFileContextMainOperations.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/viewfs/TestViewFileSystemAtHdfsRoot.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/viewfs/TestViewFileSystemHdfs.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/viewfs/TestViewFsAtHdfsRoot.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/viewfs/TestViewFsDefaultValue.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/viewfs/TestViewFsFileStatusHdfs.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/viewfs/TestViewFsHdfs.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/web/TestFSMainOperationsWebHdfs.java
* /hadoop/common/trunk/hadoop-project/pom.xml
* /hadoop/common/trunk/hadoop-tools/hadoop-distcp/src/test/java/org/apache/hadoop/tools/TestDistCpViewFs.java
","31/May/13 13:13;hudson;Integrated in Hadoop-Hdfs-trunk #1416 (See [https://builds.apache.org/job/Hadoop-Hdfs-trunk/1416/])
    HADOOP-9287. Parallel-testing hadoop-common. Contributed by Andrey Klochkov (Revision 1488040)

     Result = FAILURE
jlowe : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1488040
Files : 
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/CHANGES.txt
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/pom.xml
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/conf/TestConfiguration.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/conf/TestConfigurationDeprecation.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/FCStatisticsBaseTest.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/FSMainOperationsBaseTest.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/FileContextCreateMkdirBaseTest.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/FileContextMainOperationsBaseTest.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/FileContextPermissionBase.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/FileContextSymlinkBaseTest.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/FileContextTestHelper.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/FileContextUtilBase.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/FileSystemTestHelper.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/TestFSMainOperationsLocalFileSystem.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/TestFcLocalFsPermission.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/TestFileContextDeleteOnExit.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/TestLocalFSFileContextMainOperations.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/TestLocalFSFileContextSymlink.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/TestLocalFileSystem.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/TestLocalFsFCStatistics.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/shell/TestCopyPreserveFlag.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/viewfs/TestChRootedFileSystem.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/viewfs/TestChRootedFs.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/viewfs/TestFSMainOperationsLocalFileSystem.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/viewfs/TestFcCreateMkdirLocalFs.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/viewfs/TestFcMainOperationsLocalFs.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/viewfs/TestFcPermissionsLocalFs.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/viewfs/TestViewFileSystemDelegation.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/viewfs/TestViewFileSystemLocalFileSystem.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/viewfs/TestViewFileSystemWithAuthorityLocalFileSystem.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/viewfs/TestViewFsTrash.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/viewfs/ViewFileSystemBaseTest.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/viewfs/ViewFileSystemTestSetup.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/viewfs/ViewFsBaseTest.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/viewfs/ViewFsTestSetup.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/ha/ClientBaseWithFixes.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/TestSequenceFile.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/TestSequenceFileSerialization.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/file/tfile/TestTFileByteArrays.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/file/tfile/TestTFileJClassComparatorByteArrays.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/file/tfile/TestTFileLzoCodecsByteArrays.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/file/tfile/TestTFileLzoCodecsStreams.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/file/tfile/TestTFileNoneCodecsByteArrays.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/file/tfile/TestTFileNoneCodecsJClassComparatorByteArrays.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/file/tfile/TestTFileNoneCodecsStreams.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/file/tfile/TestTFileStreams.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/metrics2/impl/TestMetricsSystemImpl.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/TestFcHdfsCreateMkdir.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/TestFcHdfsPermission.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/TestFcHdfsSetUMask.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/TestFcHdfsSymlink.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/TestHDFSFileContextMainOperations.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/viewfs/TestViewFileSystemAtHdfsRoot.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/viewfs/TestViewFileSystemHdfs.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/viewfs/TestViewFsAtHdfsRoot.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/viewfs/TestViewFsDefaultValue.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/viewfs/TestViewFsFileStatusHdfs.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/viewfs/TestViewFsHdfs.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/web/TestFSMainOperationsWebHdfs.java
* /hadoop/common/trunk/hadoop-project/pom.xml
* /hadoop/common/trunk/hadoop-tools/hadoop-distcp/src/test/java/org/apache/hadoop/tools/TestDistCpViewFs.java
","31/May/13 14:07;hudson;Integrated in Hadoop-Mapreduce-trunk #1442 (See [https://builds.apache.org/job/Hadoop-Mapreduce-trunk/1442/])
    HADOOP-9287. Parallel-testing hadoop-common. Contributed by Andrey Klochkov (Revision 1488040)

     Result = SUCCESS
jlowe : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1488040
Files : 
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/CHANGES.txt
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/pom.xml
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/conf/TestConfiguration.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/conf/TestConfigurationDeprecation.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/FCStatisticsBaseTest.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/FSMainOperationsBaseTest.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/FileContextCreateMkdirBaseTest.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/FileContextMainOperationsBaseTest.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/FileContextPermissionBase.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/FileContextSymlinkBaseTest.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/FileContextTestHelper.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/FileContextUtilBase.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/FileSystemTestHelper.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/TestFSMainOperationsLocalFileSystem.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/TestFcLocalFsPermission.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/TestFileContextDeleteOnExit.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/TestLocalFSFileContextMainOperations.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/TestLocalFSFileContextSymlink.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/TestLocalFileSystem.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/TestLocalFsFCStatistics.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/shell/TestCopyPreserveFlag.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/viewfs/TestChRootedFileSystem.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/viewfs/TestChRootedFs.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/viewfs/TestFSMainOperationsLocalFileSystem.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/viewfs/TestFcCreateMkdirLocalFs.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/viewfs/TestFcMainOperationsLocalFs.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/viewfs/TestFcPermissionsLocalFs.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/viewfs/TestViewFileSystemDelegation.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/viewfs/TestViewFileSystemLocalFileSystem.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/viewfs/TestViewFileSystemWithAuthorityLocalFileSystem.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/viewfs/TestViewFsTrash.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/viewfs/ViewFileSystemBaseTest.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/viewfs/ViewFileSystemTestSetup.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/viewfs/ViewFsBaseTest.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/viewfs/ViewFsTestSetup.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/ha/ClientBaseWithFixes.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/TestSequenceFile.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/TestSequenceFileSerialization.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/file/tfile/TestTFileByteArrays.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/file/tfile/TestTFileJClassComparatorByteArrays.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/file/tfile/TestTFileLzoCodecsByteArrays.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/file/tfile/TestTFileLzoCodecsStreams.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/file/tfile/TestTFileNoneCodecsByteArrays.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/file/tfile/TestTFileNoneCodecsJClassComparatorByteArrays.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/file/tfile/TestTFileNoneCodecsStreams.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/file/tfile/TestTFileStreams.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/metrics2/impl/TestMetricsSystemImpl.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/TestFcHdfsCreateMkdir.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/TestFcHdfsPermission.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/TestFcHdfsSetUMask.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/TestFcHdfsSymlink.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/TestHDFSFileContextMainOperations.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/viewfs/TestViewFileSystemAtHdfsRoot.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/viewfs/TestViewFileSystemHdfs.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/viewfs/TestViewFsAtHdfsRoot.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/viewfs/TestViewFsDefaultValue.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/viewfs/TestViewFsFileStatusHdfs.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/viewfs/TestViewFsHdfs.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/web/TestFSMainOperationsWebHdfs.java
* /hadoop/common/trunk/hadoop-project/pom.xml
* /hadoop/common/trunk/hadoop-tools/hadoop-distcp/src/test/java/org/apache/hadoop/tools/TestDistCpViewFs.java
","31/May/13 21:13;aklochkov;Attaching a patch for branch-2.","03/Jun/13 16:30;jlowe;+1, branch-2 patch looks good to me.  I'll commit this to branch-2 later today to give others a chance to comment.","04/Jun/13 00:31;jlowe;Thanks, Andrey!  I committed the branch-2 patch.","04/Jun/13 00:45;hudson;Integrated in Hadoop-trunk-Commit #3850 (See [https://builds.apache.org/job/Hadoop-trunk-Commit/3850/])
    Move HADOOP-9287 in CHANGES.txt after committing to branch-2 (Revision 1489258)

     Result = SUCCESS
jlowe : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1489258
Files : 
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/CHANGES.txt
","04/Jun/13 10:50;hudson;Integrated in Hadoop-Yarn-trunk #230 (See [https://builds.apache.org/job/Hadoop-Yarn-trunk/230/])
    Move HADOOP-9287 in CHANGES.txt after committing to branch-2 (Revision 1489258)

     Result = FAILURE
jlowe : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1489258
Files : 
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/CHANGES.txt
","04/Jun/13 13:03;hudson;Integrated in Hadoop-Hdfs-trunk #1420 (See [https://builds.apache.org/job/Hadoop-Hdfs-trunk/1420/])
    Move HADOOP-9287 in CHANGES.txt after committing to branch-2 (Revision 1489258)

     Result = FAILURE
jlowe : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1489258
Files : 
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/CHANGES.txt
","04/Jun/13 14:06;hudson;Integrated in Hadoop-Mapreduce-trunk #1446 (See [https://builds.apache.org/job/Hadoop-Mapreduce-trunk/1446/])
    Move HADOOP-9287 in CHANGES.txt after committing to branch-2 (Revision 1489258)

     Result = SUCCESS
jlowe : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1489258
Files : 
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/CHANGES.txt
","11/Jun/13 17:03;cnauroth;I just submitted HADOOP-9638 for a regression that I discovered related to this patch.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Cover package org.apache.hadoop.hdfs.server.common with tests,HADOOP-9314,12632797,Test,Resolved,HADOOP,Hadoop Common,software,omalley,Hadoop Common is the common library for Apache Hadoop.,http://hadoop.apache.org/,Major,Duplicate,,vbondarev,vbondarev,18/Feb/13 08:14,12/May/16 18:22,12/Jan/21 11:55,21/Feb/13 08:54,0.23.6,2.0.3-alpha,3.0.0-alpha1,,,,,,,,,,,,0,,,,,aklochkov,snihalani,vbondarev,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,2013-02-20 17:20:23.78,,,false,,,,,,,,,,,,,,,,,313293,,,,,Thu Feb 21 07:39:01 UTC 2013,,,,,,,"0|i1i2c7:",313638,,,,,,,,,,,,,,,,,,,,,,,"20/Feb/13 17:20;snihalani;[~vbondarev], We do we have both HADOOP-9314 & HADOOP-9268 ?","20/Feb/13 20:18;vbondarev;was replaced in https://issues.apache.org/jira/browse/HDFS-4512","21/Feb/13 07:39;vbondarev;The issue was moved to HDFS JIRA space  https://issues.apache.org/jira/browse/HDFS-4512. Please delete both tickets (9314, 9268).",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Cover package org.apache.hadoop.io.compress.zlib with unit tests,HADOOP-9233,12628683,Test,Closed,HADOOP,Hadoop Common,software,omalley,Hadoop Common is the common library for Apache Hadoop.,http://hadoop.apache.org/,Major,Fixed,vbondarev,vbondarev,vbondarev,22/Jan/13 09:43,12/May/16 18:22,12/Jan/21 11:55,11/Apr/13 21:28,0.23.6,2.0.3-alpha,3.0.0-alpha1,,0.23.8,2.1.0-beta,,,,,,,,,0,,,,,aklochkov,cdouglas,hudson,iveselovsky,jlowe,vbondarev,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"02/Apr/13 13:38;vbondarev;HADOOP-9233-branch-0.23-b.patch;https://issues.apache.org/jira/secure/attachment/12576568/HADOOP-9233-branch-0.23-b.patch","06/Feb/13 12:43;vbondarev;HADOOP-9233-branch-2-a.patch;https://issues.apache.org/jira/secure/attachment/12568214/HADOOP-9233-branch-2-a.patch","02/Apr/13 13:38;vbondarev;HADOOP-9233-branch-2-b.patch;https://issues.apache.org/jira/secure/attachment/12576569/HADOOP-9233-branch-2-b.patch","06/Feb/13 12:43;vbondarev;HADOOP-9233-trunk-a.patch;https://issues.apache.org/jira/secure/attachment/12568215/HADOOP-9233-trunk-a.patch","02/Apr/13 13:38;vbondarev;HADOOP-9233-trunk-b.patch;https://issues.apache.org/jira/secure/attachment/12576570/HADOOP-9233-trunk-b.patch","08/Apr/13 12:00;vbondarev;HADOOP-9233-trunk-c.patch;https://issues.apache.org/jira/secure/attachment/12577518/HADOOP-9233-trunk-c.patch","09/Apr/13 11:58;vbondarev;HADOOP-9233-trunk-d.patch;https://issues.apache.org/jira/secure/attachment/12577783/HADOOP-9233-trunk-d.patch",,,,,,,,,,,,,,,,,7.0,,,,,,,,,,,,,,,,,,,,2013-01-22 10:36:42.728,,,false,,,,,,,,,,,,,,,,,307208,Reviewed,,,,Fri Apr 12 14:05:48 UTC 2013,,,,,,,"0|i1ahxb:",269370,,,,,,,,,,,,,,,,,,,,,,,"22/Jan/13 10:36;hadoopqa;{color:green}+1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12565925/YAHOO-9233-trunk-a.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 3 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  The javadoc tool did not generate any warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:green}+1 core tests{color}.  The patch passed unit tests in hadoop-common-project/hadoop-common.

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HADOOP-Build/2077//testReport/
Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/2077//console

This message is automatically generated.","31/Jan/13 11:26;hadoopqa;{color:green}+1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12567332/HADOOP-9233-trunk-a.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 3 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  The javadoc tool did not generate any warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:green}+1 core tests{color}.  The patch passed unit tests in hadoop-common-project/hadoop-common.

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HADOOP-Build/2123//testReport/
Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/2123//console

This message is automatically generated.","06/Feb/13 13:26;hadoopqa;{color:green}+1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12568215/HADOOP-9233-trunk-a.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 3 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  The javadoc tool did not generate any warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:green}+1 core tests{color}.  The patch passed unit tests in hadoop-common-project/hadoop-common.

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HADOOP-Build/2156//testReport/
Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/2156//console

This message is automatically generated.","02/Apr/13 14:17;hadoopqa;{color:green}+1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12576570/HADOOP-9233-trunk-b.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 3 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  The javadoc tool did not generate any warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:green}+1 core tests{color}.  The patch passed unit tests in hadoop-common-project/hadoop-common.

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HADOOP-Build/2397//testReport/
Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/2397//console

This message is automatically generated.","05/Apr/13 22:39;jlowe;Thanks for posting a patch for this, Vadim.  A few comments:

CompressDecompressTester.java:
* The {{Visitor}} interface has exactly one class that implements it, exactly one instance of that class, and exactly one function that calls the interface.  This seems like abstraction layers that are making the code harder to read and not adding any value, or do you have future expansion plans for this?  It would be a lot simpler to just have a static function that takes compressor object and returns a boolean on whether it's available.

TestCompressorDecompressor.java:
* Nit: Any reason why line 110 isn't just:
{code}
  byte[] array = new byte[size];
{code}
* Rather than an explicit array with values from 0x0-0xF, can't we just use the value returned from {{rnd.nextInt(15)}} directly?
* There are a number of unused imports.

TestZlibCompressorDecompressor.java:
* There are a number of unused imports.
* In {{testZlibCompressorDecompressorWithConfiguration}} and {{testZlibCompressorDecompressorSetDictionary}} we are using {{assertFalse}} on a condition that was just checked by the {{if}} statement as false so this assert will never fire.

Also note that it's unnecessary to post separate patches for branch-2 and branch-0.23 if the trunk patch will apply to them as well.","08/Apr/13 12:04;vbondarev;New patch version was attached.
","08/Apr/13 15:07;hadoopqa;{color:green}+1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12577518/HADOOP-9233-trunk-c.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 3 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  The javadoc tool did not generate any warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:green}+1 core tests{color}.  The patch passed unit tests in hadoop-common-project/hadoop-common.

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HADOOP-Build/2426//testReport/
Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/2426//console

This message is automatically generated.","08/Apr/13 20:50;jlowe;Thanks for the update, Vadim.  Another issue I ran into while trying out the patch is running the unit tests when native code support is not compiled.  TestCompressorDecompressor fails in this case:

{noformat}
java.lang.UnsatisfiedLinkError: org.apache.hadoop.io.compress.zlib.ZlibCompressor.init(III)J
	at org.apache.hadoop.io.compress.zlib.ZlibCompressor.init(Native Method)
	at org.apache.hadoop.io.compress.zlib.ZlibCompressor.<init>(ZlibCompressor.java:228)
	at org.apache.hadoop.io.compress.zlib.ZlibCompressor.<init>(ZlibCompressor.java:198)
	at org.apache.hadoop.io.compress.TestCompressorDecompressor.testCompressorDecompressor(TestCompressorDecompressor.java:44)
{noformat}

We can't construct a {{ZlibCompressor}} or {{ZlibDecompressor}} without native code support, which is why {{ZlibFactory}} hides this in its {{getZlibCompressor}} and {{getZlibDecompressor}} methods.  We either need to use those methods (with conf settings to get the two types we want) or have the code conditionally exclude the native codec support based on {{ZLibFactory#isNativeZlibLoaded}}.

Arguably the acceptor function should also be checking this otherwise we run the risk of the native code being loaded but zlib libraries are for some reason unavailable.","09/Apr/13 12:04;vbondarev;1.ZlibCompressor/ZlibDecompressor was replaced in TestZlibCompressorDecompressor class
2.Used ZlibFactory for check on native code   
3.Created static function ""generate"" instead ByteGenerator class","10/Apr/13 16:08;hadoopqa;{color:green}+1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12577783/HADOOP-9233-trunk-d.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 3 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  The javadoc tool did not generate any warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:green}+1 core tests{color}.  The patch passed unit tests in hadoop-common-project/hadoop-common.

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HADOOP-Build/2436//testReport/
Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/2436//console

This message is automatically generated.","11/Apr/13 21:15;jlowe;+1, lgtm.  There are still unused imports in CompressDecompressTester which I'll cleanup during the commit.","11/Apr/13 21:25;hudson;Integrated in Hadoop-trunk-Commit #3600 (See [https://builds.apache.org/job/Hadoop-trunk-Commit/3600/])
    HADOOP-9233. Cover package org.apache.hadoop.io.compress.zlib with unit tests. Contributed by Vadim Bondarev (Revision 1467090)

     Result = SUCCESS
jlowe : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1467090
Files : 
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/CHANGES.txt
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/compress/CompressDecompressTester.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/compress/TestCompressorDecompressor.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/compress/zlib
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/compress/zlib/TestZlibCompressorDecompressor.java
","11/Apr/13 21:28;jlowe;Thansk, Vadim!  I committed this to trunk, branch-2, and branch-0.23.","12/Apr/13 10:49;hudson;Integrated in Hadoop-Yarn-trunk #181 (See [https://builds.apache.org/job/Hadoop-Yarn-trunk/181/])
    HADOOP-9233. Cover package org.apache.hadoop.io.compress.zlib with unit tests. Contributed by Vadim Bondarev (Revision 1467090)

     Result = SUCCESS
jlowe : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1467090
Files : 
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/CHANGES.txt
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/compress/CompressDecompressTester.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/compress/TestCompressorDecompressor.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/compress/zlib
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/compress/zlib/TestZlibCompressorDecompressor.java
","12/Apr/13 12:41;hudson;Integrated in Hadoop-Hdfs-0.23-Build #579 (See [https://builds.apache.org/job/Hadoop-Hdfs-0.23-Build/579/])
    svn merge -c 1467090 FIXES: HADOOP-9233. Cover package org.apache.hadoop.io.compress.zlib with unit tests. Contributed by Vadim Bondarev (Revision 1467102)

     Result = SUCCESS
jlowe : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1467102
Files : 
* /hadoop/common/branches/branch-0.23/hadoop-common-project/hadoop-common/CHANGES.txt
* /hadoop/common/branches/branch-0.23/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/compress/CompressDecompressTester.java
* /hadoop/common/branches/branch-0.23/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/compress/TestCompressorDecompressor.java
* /hadoop/common/branches/branch-0.23/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/compress/zlib
* /hadoop/common/branches/branch-0.23/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/compress/zlib/TestZlibCompressorDecompressor.java
","12/Apr/13 13:06;hudson;Integrated in Hadoop-Hdfs-trunk #1370 (See [https://builds.apache.org/job/Hadoop-Hdfs-trunk/1370/])
    HADOOP-9233. Cover package org.apache.hadoop.io.compress.zlib with unit tests. Contributed by Vadim Bondarev (Revision 1467090)

     Result = FAILURE
jlowe : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1467090
Files : 
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/CHANGES.txt
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/compress/CompressDecompressTester.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/compress/TestCompressorDecompressor.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/compress/zlib
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/compress/zlib/TestZlibCompressorDecompressor.java
","12/Apr/13 14:05;hudson;Integrated in Hadoop-Mapreduce-trunk #1397 (See [https://builds.apache.org/job/Hadoop-Mapreduce-trunk/1397/])
    HADOOP-9233. Cover package org.apache.hadoop.io.compress.zlib with unit tests. Contributed by Vadim Bondarev (Revision 1467090)

     Result = SUCCESS
jlowe : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1467090
Files : 
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/CHANGES.txt
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/compress/CompressDecompressTester.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/compress/TestCompressorDecompressor.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/compress/zlib
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/compress/zlib/TestZlibCompressorDecompressor.java
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Improve code coverage in org.apache.hadoop.fs.ftp,HADOOP-9345,12634574,Test,Patch Available,HADOOP,Hadoop Common,software,omalley,Hadoop Common is the common library for Apache Hadoop.,http://hadoop.apache.org/,Major,,aklochkov,aleksgor,aleksgor,28/Feb/13 08:19,12/May/16 18:21,12/Jan/21 11:55,,0.23.7,2.1.0-beta,3.0.0-alpha1,,,,,,,,,,,,0,BB2015-05-TBR,,"fix coverage  org.apache.hadoop.fs.ftp
patch YARN-434-trunk.patch for trunk, branch-2, branch-0.23",fix coverage  org.apache.hadoop.fs.ftp,aklochkov,aleksgor,iveselovsky,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"16/Oct/13 00:07;aklochkov;HADOOP-9345--n2.patch;https://issues.apache.org/jira/secure/attachment/12608611/HADOOP-9345--n2.patch","16/Oct/13 00:53;aklochkov;HADOOP-9345--n3.patch;https://issues.apache.org/jira/secure/attachment/12608622/HADOOP-9345--n3.patch","28/Feb/13 08:21;aleksgor;YARN-434-trunk.patch;https://issues.apache.org/jira/secure/attachment/12571375/YARN-434-trunk.patch",,,,,,,,,,,,,,,,,,,,,3.0,,,,,,,,,,,,,,,,,,,,2013-02-28 08:56:43.631,,,false,,,,,,,,,,,,,,,,,315067,,,,,Sat May 02 19:20:44 UTC 2015,,,,,,,"0|i1ida7:",315411,,,,,,,,,,,,,,,,,,,,,,,"28/Feb/13 08:56;hadoopqa;{color:green}+1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12571375/YARN-434-trunk.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 1 new or modified test files.

    {color:green}+1 tests included appear to have a timeout.{color}

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  The javadoc tool did not generate any warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:green}+1 core tests{color}.  The patch passed unit tests in hadoop-common-project/hadoop-common.

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-YARN-Build/446//testReport/
Console output: https://builds.apache.org/job/PreCommit-YARN-Build/446//console

This message is automatically generated.","28/Feb/13 11:05;hadoopqa;{color:green}+1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12571375/YARN-434-trunk.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 1 new or modified test files.

    {color:green}+1 tests included appear to have a timeout.{color}

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  The javadoc tool did not generate any warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:green}+1 core tests{color}.  The patch passed unit tests in hadoop-common-project/hadoop-common.

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HADOOP-Build/2240//testReport/
Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/2240//console

This message is automatically generated.","16/Oct/13 00:07;aklochkov;Renamed, rebased and cleaned up the patch.","16/Oct/13 00:43;hadoopqa;{color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12608611/HADOOP-9345--n2.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 1 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  The javadoc tool did not generate any warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:red}-1 core tests{color}.  The patch failed these unit tests in hadoop-common-project/hadoop-common:

                  org.apache.hadoop.fs.ftp.TestFtpClient

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HADOOP-Build/3221//testReport/
Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/3221//console

This message is automatically generated.","16/Oct/13 00:53;aklochkov;Uploading patch with increased timeouts in tests","16/Oct/13 01:35;hadoopqa;{color:green}+1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12608622/HADOOP-9345--n3.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 1 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  The javadoc tool did not generate any warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:green}+1 core tests{color}.  The patch passed unit tests in hadoop-common-project/hadoop-common.

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HADOOP-Build/3222//testReport/
Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/3222//console

This message is automatically generated.","02/May/15 19:20;hadoopqa;\\
\\
| (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | pre-patch |  14m 47s | Pre-patch trunk compilation is healthy. |
| {color:green}+1{color} | @author |   0m  0s | The patch does not contain any @author tags. |
| {color:green}+1{color} | tests included |   0m  0s | The patch appears to include 1 new or modified test files. |
| {color:green}+1{color} | javac |   7m 32s | There were no new javac warning messages. |
| {color:green}+1{color} | javadoc |   9m 39s | There were no new javadoc warning messages. |
| {color:green}+1{color} | release audit |   0m 22s | The applied patch does not increase the total number of release audit warnings. |
| {color:green}+1{color} | checkstyle |   1m  9s | There were no new checkstyle issues. |
| {color:green}+1{color} | whitespace |   0m  0s | The patch has no lines that end in whitespace. |
| {color:green}+1{color} | install |   1m 30s | mvn install still works. |
| {color:green}+1{color} | eclipse:eclipse |   0m 32s | The patch built with eclipse:eclipse. |
| {color:green}+1{color} | findbugs |   1m 40s | The patch does not introduce any new Findbugs (version 2.0.3) warnings. |
| {color:red}-1{color} | common tests |  23m 19s | Tests failed in hadoop-common. |
| | |  60m 35s | |
\\
\\
|| Reason || Tests ||
| Failed unit tests | hadoop.fs.ftp.TestFtpClient |
\\
\\
|| Subsystem || Report/Notes ||
| Patch URL | http://issues.apache.org/jira/secure/attachment/12608622/HADOOP-9345--n3.patch |
| Optional Tests | javadoc javac unit findbugs checkstyle |
| git revision | trunk / 6ae2a0d |
| hadoop-common test log | https://builds.apache.org/job/PreCommit-HADOOP-Build/6406/artifact/patchprocess/testrun_hadoop-common.txt |
| Test Results | https://builds.apache.org/job/PreCommit-HADOOP-Build/6406/testReport/ |
| Java | 1.7.0_55 |
| uname | Linux asf900.gq1.ygridcore.net 3.13.0-36-lowlatency #63-Ubuntu SMP PREEMPT Wed Sep 3 21:56:12 UTC 2014 x86_64 x86_64 x86_64 GNU/Linux |
| Console output | https://builds.apache.org/job/PreCommit-HADOOP-Build/6406/console |


This message was automatically generated.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
coverage fixing for org.apache.hadoop.tools.rumen,HADOOP-9219,12628015,Test,Closed,HADOOP,Hadoop Common,software,omalley,Hadoop Common is the common library for Apache Hadoop.,http://hadoop.apache.org/,Major,Fixed,aleksgor,aleksgor,aleksgor,17/Jan/13 10:02,12/May/16 18:21,12/Jan/21 11:55,11/Apr/14 16:10,0.23.6,2.0.3-alpha,3.0.0-alpha1,,,,,,,,tools,,,,0,,,"coverage fixing for org.apache.hadoop.tools.rumen 
HADOOP-9219-trunk.patch for trunk, brunch-2 and branch-0.23
",,aklochkov,aleksgor,ikatsov,iveselovsky,jeagles,raviprak,tgraves,,,,,,,,,,,,,,,,,,,604800,604800,,0%,604800,604800,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"08/Feb/13 11:35;aleksgor;HADOOP-9219-trunk-a.patch;https://issues.apache.org/jira/secure/attachment/12568555/HADOOP-9219-trunk-a.patch","03/Apr/13 10:38;aleksgor;HADOOP-9219-trunk-b.patch;https://issues.apache.org/jira/secure/attachment/12576761/HADOOP-9219-trunk-b.patch","25/Jan/13 07:10;aleksgor;HADOOP-9219-trunk.patch;https://issues.apache.org/jira/secure/attachment/12566470/HADOOP-9219-trunk.patch",,,,,,,,,,,,,,,,,,,,,3.0,,,,,,,,,,,,,,,,,,,,2013-01-17 15:46:40.407,,,false,,,,,,,,,,,,,,,,,304863,,,,,Fri Apr 11 16:10:20 UTC 2014,,,,,,,"0|i17wh3:",254230,,,,,,,,,,,,,0.23.11,,,,,,,,,,"17/Jan/13 15:46;hadoopqa;{color:green}+1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12565336/HADOOP-9219-trunk.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 12 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  The javadoc tool did not generate any warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:green}+1 core tests{color}.  The patch passed unit tests in hadoop-tools/hadoop-rumen.

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HADOOP-Build/2065//testReport/
Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/2065//console

This message is automatically generated.","25/Jan/13 07:24;hadoopqa;{color:green}+1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12566470/HADOOP-9219-trunk.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 12 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  The javadoc tool did not generate any warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:green}+1 core tests{color}.  The patch passed unit tests in hadoop-tools/hadoop-rumen.

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HADOOP-Build/2092//testReport/
Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/2092//console

This message is automatically generated.","08/Feb/13 11:38;aleksgor;patch update
HADOOP-9219-trunk-a.patch for trunk, branch-2, branch-0.23 
","08/Feb/13 11:54;hadoopqa;{color:green}+1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12568555/HADOOP-9219-trunk-a.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 13 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  The javadoc tool did not generate any warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:green}+1 core tests{color}.  The patch passed unit tests in hadoop-tools/hadoop-rumen.

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HADOOP-Build/2164//testReport/
Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/2164//console

This message is automatically generated.","03/Apr/13 10:38;aleksgor;update patch","03/Apr/13 11:07;aleksgor;patch updated 
HADOOP-9219-trunk-b.patch for trunk, brunch-2 and branch-0.23","03/Apr/13 20:48;hadoopqa;{color:green}+1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12576761/HADOOP-9219-trunk-b.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 13 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  The javadoc tool did not generate any warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:green}+1 core tests{color}.  The patch passed unit tests in hadoop-tools/hadoop-rumen.

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HADOOP-Build/2406//testReport/
Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/2406//console

This message is automatically generated.","04/Oct/13 23:41;aklochkov;The patch is ridiculously large as it contains loads of data in static files. It doesn't make sense to put it into the source repo. The test should be reworked.","14/Oct/13 21:12;aklochkov;I submitted a patch for MAPREDUCE-3860 which restores old Rumen tests. Those old tests cover pretty much all Rumen codebase so as soon as MAPREDUCE-3860 is accepted, this Jira may be closed as non actual anymore.","11/Apr/14 16:10;jeagles;Duping this issue to MAPREDUCE-3860 as per Andrey's comment.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
jenkins patchprocess links are broken,HADOOP-11084,12740643,Test,Resolved,HADOOP,Hadoop Common,software,omalley,Hadoop Common is the common library for Apache Hadoop.,http://hadoop.apache.org/,Major,Fixed,arp,cmccabe,cmccabe,10/Sep/14 23:21,12/May/16 18:21,12/Jan/21 11:55,29/Sep/14 18:20,,,,,3.0.0-alpha1,,,,,,scripts,,,,0,,,jenkins patchprocess links of the form {{https://builds.apache.org/job/PreCommit-HADOOP-Build/<build_id>//artifact/trunk/patchprocess/diffJavadocWarnings.txt}} and so forth are dead links.  We should fix them to reflect the new source layout after git.,,andrew.wang,arp,cmccabe,hudson,kasha,kkambatl,ozawa,raviprak,stevel@apache.org,yzhangal,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,HADOOP-11074,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"10/Sep/14 23:26;cmccabe;HADOOP-11084.001.patch;https://issues.apache.org/jira/secure/attachment/12667894/HADOOP-11084.001.patch","29/Sep/14 04:00;arp;HADOOP-11084.002.patch;https://issues.apache.org/jira/secure/attachment/12671738/HADOOP-11084.002.patch","29/Sep/14 17:40;arp;HADOOP-11084.003.patch;https://issues.apache.org/jira/secure/attachment/12671828/HADOOP-11084.003.patch",,,,,,,,,,,,,,,,,,,,,3.0,,,,,,,,,,,,,,,,,,,,2014-09-11 00:01:22.972,,,false,,,,,,,,,,,,,,,,,9223372036854775807,Reviewed,,,,Wed Oct 29 19:25:22 UTC 2014,,,,,,,"0|i1zwl3:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,"11/Sep/14 00:01;hadoopqa;{color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12667894/HADOOP-11084.001.patch
  against trunk revision 5ec7fcd.

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 1 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:red}-1 javadoc{color}.  The javadoc tool appears to have generated 2 warning messages.
        See https://builds.apache.org/job/PreCommit-HADOOP-Build/4694//artifact/trunk/patchprocess/diffJavadocWarnings.txt for details.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 2.0.3) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:green}+1 core tests{color}.  The patch passed unit tests in hadoop-common-project/hadoop-nfs.

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HADOOP-Build/4694//testReport/
Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/4694//console

This message is automatically generated.","11/Sep/14 00:39;kkambatl;We should other builds too - HDFS, YARN, MapReduce ","18/Sep/14 20:27;stevel@apache.org;+1 committed. I left out the javadoc change","18/Sep/14 23:39;cmccabe;Thanks, [~steve_l@iseran.com].  I hope that this fixes things... unfortunately it's tough to test this kind of change since jenkins runs with the previous {{test-patch.sh}}.

[~kasha]: I'm not sure how {{test-patch.sh}} could deal with the {{patchJavacWarnings.txt}} file showing up in a different directory than {{PreCommit-HADOOP-Build-patchprocess}}.  I guess one way we could do it is by adding a new environment variable that Jenkins passes in to {{test-patch.sh}}.  The other way is we could do a search through path components of {{$PATCH_DIR}} for directories ending in 'patchprocess' and symlink the first one we found to 'patchprocess' (effectively restoring the old scheme where this was always under {{$BUILD_URL/artifact/patchprocess/diffJavadocWarnings.txt}}).","19/Sep/14 11:34;hudson;SUCCESS: Integrated in Hadoop-Yarn-trunk #685 (See [https://builds.apache.org/job/Hadoop-Yarn-trunk/685/])
HADOOP-11084 jenkins patchprocess links are broken (stevel: rev 474f116f57b9f8467226b739f4d6a660882e923a)
* dev-support/test-patch.sh
","19/Sep/14 13:47;hudson;FAILURE: Integrated in Hadoop-Mapreduce-trunk #1901 (See [https://builds.apache.org/job/Hadoop-Mapreduce-trunk/1901/])
HADOOP-11084 jenkins patchprocess links are broken (stevel: rev 474f116f57b9f8467226b739f4d6a660882e923a)
* dev-support/test-patch.sh
","19/Sep/14 13:51;hudson;FAILURE: Integrated in Hadoop-Hdfs-trunk #1876 (See [https://builds.apache.org/job/Hadoop-Hdfs-trunk/1876/])
HADOOP-11084 jenkins patchprocess links are broken (stevel: rev 474f116f57b9f8467226b739f4d6a660882e923a)
* dev-support/test-patch.sh
","19/Sep/14 17:35;cmccabe;Is there any possibility that we could start putting stuff in:
{code}
$BASE_URL/<build_id>//artifact/trunk/patchprocess/diffJavadocWarnings.txt
{code}

again?

Since the {{$BASE_URL}} already contains a string like ""PreCommit-HADOOP-Build"", it seems like putting that string another time into the path doesn't add any more information, and makes it really hard to write a correct script to locate the build products.  What do you guys think?","20/Sep/14 18:37;stevel@apache.org;If it's easier to do, go back to it. I'll update jenkins with whatever values you want added ","29/Sep/14 04:00;arp;Patch to fix the findbugs link.","29/Sep/14 04:28;hadoopqa;{color:green}+1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12671738/HADOOP-11084.002.patch
  against trunk revision b38e52b.

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 1 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  There were no new javadoc warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 2.0.3) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:green}+1 core tests{color}.  The patch passed unit tests in .

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HADOOP-Build/4823//testReport/
Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/4823//console

This message is automatically generated.","29/Sep/14 17:25;andrew.wang;I noticed that there are still a lot of ""PreCommit-HADOOP-Build-patchprocess"" strings in test-patch.sh, should all of these be updated to be just ""patchprocess""? e.g. javac, rat.","29/Sep/14 17:40;arp;Wasn't very sure about those since I didn't have examples of good links to compare against for Javadoc, rat and javac warnings.

Updated patch to fix them also.","29/Sep/14 17:43;andrew.wang;Thanks Arpit, I can provide one of my recent runs as an example:

https://issues.apache.org/jira/browse/HDFS-7077?focusedCommentId=14147555&page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-14147555

The new URL worked for these javac and rat links, so I think it's correct.","29/Sep/14 17:47;arp;Thanks for the link and verification Andrew.","29/Sep/14 18:08;hadoopqa;{color:green}+1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12671828/HADOOP-11084.003.patch
  against trunk revision 84b9c63.

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 1 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  There were no new javadoc warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 2.0.3) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:green}+1 core tests{color}.  The patch passed unit tests in .

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HADOOP-Build/4827//testReport/
Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/4827//console

This message is automatically generated.","29/Sep/14 18:11;andrew.wang;+1 LGTM","29/Sep/14 18:20;arp;Thank you for the quick review. I committed it to trunk.","29/Sep/14 18:22;hudson;FAILURE: Integrated in Hadoop-trunk-Commit #6141 (See [https://builds.apache.org/job/Hadoop-trunk-Commit/6141/])
HADOOP-11084. Jenkins patchprocess links are broken. (Arpit Agarwal) (arp: rev 9e985e6b9432725dc6ee702333a257e05e357957)
* dev-support/test-patch.sh
","29/Sep/14 18:43;cmccabe;Thanks, [~arpitagarwal].","30/Sep/14 11:37;hudson;FAILURE: Integrated in Hadoop-Yarn-trunk #696 (See [https://builds.apache.org/job/Hadoop-Yarn-trunk/696/])
HADOOP-11084. Jenkins patchprocess links are broken. (Arpit Agarwal) (arp: rev 9e985e6b9432725dc6ee702333a257e05e357957)
* dev-support/test-patch.sh
","30/Sep/14 14:16;hudson;SUCCESS: Integrated in Hadoop-Hdfs-trunk #1887 (See [https://builds.apache.org/job/Hadoop-Hdfs-trunk/1887/])
HADOOP-11084. Jenkins patchprocess links are broken. (Arpit Agarwal) (arp: rev 9e985e6b9432725dc6ee702333a257e05e357957)
* dev-support/test-patch.sh
","30/Sep/14 15:10;hudson;FAILURE: Integrated in Hadoop-Mapreduce-trunk #1912 (See [https://builds.apache.org/job/Hadoop-Mapreduce-trunk/1912/])
HADOOP-11084. Jenkins patchprocess links are broken. (Arpit Agarwal) (arp: rev 9e985e6b9432725dc6ee702333a257e05e357957)
* dev-support/test-patch.sh
","01/Oct/14 23:48;ozawa;Hi, the links about findbugs are sometimes broken on some jiras(e.g. YARN-2312, HADOOP-11032). On my local environment, I confirmed that I cannot find the findbugs warning with the patches. Do you have any idea about this problem?","02/Oct/14 19:51;cmccabe;bq. Hi, the links about findbugs are sometimes broken on some jiras(e.g. YARN-2312, HADOOP-11032). On my local environment, I confirmed that I cannot find the findbugs warning with the patches. Do you have any idea about this problem?

I don't know what's going on on HADOOP-11032, but it's weird.  From looking at the console, the build aborted in the middle with ""hudson.remoting.RequestAbortedException: hudson.remoting.RequestAbortedException: java.io.IOException: Unexpected termination of the channel"".  This looks a lot like a Jenkins / build host problem... someone with shell access might need to look into why we've been hitting so many of these failures recently.  I don't think it's a test-patch.sh problem since the whole patchprocess dir seems to be missing (build aborted in the middle before it could be created?)","29/Oct/14 06:17;yzhangal;HI Guys,

Thanks for the earlier discussion and work on this issue. I am seeing invalid link:

https://builds.apache.org/job/PreCommit-HADOOP-Build/4975//artifact/patchprocess/diffJavacWarnings.txt

So looks like something is still broken. Would anyone please take a further look? I can create a new jira if necessary.

Thanks.


","29/Oct/14 18:30;andrew.wang;Hi Yongjun, I made some additional edits yesterday to try and fix this, and I see that recent runs do have correct artifacts, e.g. 

https://builds.apache.org/job/PreCommit-HADOOP-Build/4978/

So, I think things are working. If you still see broken links or missing artifacts in future builds, please ping us again.

","29/Oct/14 18:39;yzhangal;Thanks a lot [~andrew.wang]!
","29/Oct/14 19:25;cmccabe;Thanks, Andrew.  It's good to have those URLs working again.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Cover package org.apache.hadoop.hdfs.server.common  with tests,HADOOP-9268,12630112,Test,Resolved,HADOOP,Hadoop Common,software,omalley,Hadoop Common is the common library for Apache Hadoop.,http://hadoop.apache.org/,Major,Duplicate,,vbondarev,vbondarev,31/Jan/13 10:52,12/May/16 18:21,12/Jan/21 11:55,21/Feb/13 08:55,0.23.6,2.0.3-alpha,3.0.0-alpha1,,,,,,,,,,,,0,,,,,aklochkov,vbondarev,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"31/Jan/13 10:56;vbondarev;HADOOP-9268-branch-0.23-a.patch;https://issues.apache.org/jira/secure/attachment/12567336/HADOOP-9268-branch-0.23-a.patch","31/Jan/13 10:56;vbondarev;HADOOP-9268-branch-2-a.patch;https://issues.apache.org/jira/secure/attachment/12567337/HADOOP-9268-branch-2-a.patch","31/Jan/13 10:56;vbondarev;HADOOP-9268-trunk-a.patch;https://issues.apache.org/jira/secure/attachment/12567338/HADOOP-9268-trunk-a.patch",,,,,,,,,,,,,,,,,,,,,3.0,,,,,,,,,,,,,,,,,,,,2013-01-31 12:35:02.908,,,false,,,,,,,,,,,,,,,,,310608,,,,,Mon Feb 18 08:14:09 UTC 2013,,,,,,,"0|i1hlrz:",310953,,,,,,,,,,,,,,,,,,,,,,,"31/Jan/13 12:35;hadoopqa;{color:green}+1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12567338/HADOOP-9268-trunk-a.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 1 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  The javadoc tool did not generate any warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:green}+1 core tests{color}.  The patch passed unit tests in hadoop-hdfs-project/hadoop-hdfs.

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HADOOP-Build/2124//testReport/
Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/2124//console

This message is automatically generated.","18/Feb/13 08:14;vbondarev;replace in hdfs project",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Cover package org.apache.hadoop.compress.Snappy,HADOOP-9225,12628185,Test,Closed,HADOOP,Hadoop Common,software,omalley,Hadoop Common is the common library for Apache Hadoop.,http://hadoop.apache.org/,Major,Fixed,aklochkov,vbondarev,vbondarev,18/Jan/13 10:29,12/May/16 18:21,12/Jan/21 11:55,04/Oct/13 21:04,0.23.6,2.0.3-alpha,3.0.0-alpha1,,2.3.0,,,,,,,,,,0,,,,,aklochkov,cmccabe,hudson,iveselovsky,jlowe,nroberts,robsparker,vbondarev,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"03/Oct/13 23:11;aklochkov;HADOOP-9225--n4.patch;https://issues.apache.org/jira/secure/attachment/12606675/HADOOP-9225--n4.patch","18/Jan/13 10:32;vbondarev;HADOOP-9225-branch-0.23-a.patch;https://issues.apache.org/jira/secure/attachment/12565459/HADOOP-9225-branch-0.23-a.patch","18/Jan/13 10:32;vbondarev;HADOOP-9225-branch-2-a.patch;https://issues.apache.org/jira/secure/attachment/12565460/HADOOP-9225-branch-2-a.patch","21/Jan/13 08:14;vbondarev;HADOOP-9225-branch-2-b.patch;https://issues.apache.org/jira/secure/attachment/12565747/HADOOP-9225-branch-2-b.patch","02/Apr/13 16:30;vbondarev;HADOOP-9225-branch-2-c.patch;https://issues.apache.org/jira/secure/attachment/12576598/HADOOP-9225-branch-2-c.patch","18/Jan/13 10:32;vbondarev;HADOOP-9225-trunk-a.patch;https://issues.apache.org/jira/secure/attachment/12565461/HADOOP-9225-trunk-a.patch","21/Jan/13 08:14;vbondarev;HADOOP-9225-trunk-b.patch;https://issues.apache.org/jira/secure/attachment/12565748/HADOOP-9225-trunk-b.patch","02/Apr/13 16:30;vbondarev;HADOOP-9225-trunk-c.patch;https://issues.apache.org/jira/secure/attachment/12576599/HADOOP-9225-trunk-c.patch","04/Oct/13 19:48;nroberts;HADOOP-9225.patch;https://issues.apache.org/jira/secure/attachment/12606875/HADOOP-9225.patch",,,,,,,,,,,,,,,9.0,,,,,,,,,,,,,,,,,,,,2013-01-18 11:08:37.443,,,false,,,,,,,,,,,,,,,,,305311,Reviewed,,,,Sat Oct 05 14:22:16 UTC 2013,,,,,,,"0|i18bkv:",256678,,,,,,,,,,,,,,,,,,,,,,,"18/Jan/13 10:51;vbondarev;Since there is on dependency on snappy native library in project and it's not builded in mvn project we should :

1. download from http://snappy.googlecode.com/files/snappy-1.0.5.tar.gz and build. 
Default installation folder for snappy is {/usr/local/lib}

2. before build do   export LD_LIBRARY_PATH=/usr/local/lib {snappy default installation directory}

","18/Jan/13 11:08;hadoopqa;{color:green}+1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12565461/HADOOP-9225-trunk-a.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 1 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  The javadoc tool did not generate any warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:green}+1 core tests{color}.  The patch passed unit tests in hadoop-common-project/hadoop-common.

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HADOOP-Build/2070//testReport/
Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/2070//console

This message is automatically generated.","18/Jan/13 19:53;cmccabe;Hi Vadim,

Thanks for writing this test.  We can always use more testing.

{code}
+  private static boolean isNativeSnappyLoadable() {
+    try {
+      boolean loaded = SnappyDecompressor.isNativeCodeLoaded();
+      return loaded;
+    } catch (Throwable t) {
+      log.warn(""Failed to load snappy: "", t);
+      return false;
+    }
+  }
{code}

Is this needed, given that you have this code earlier?

{code}
+  @Before
+  public void before() {
+    assumeTrue(NativeCodeLoader.isNativeCodeLoaded()
+        && NativeCodeLoader.buildSupportsSnappy());
...
{code}","21/Jan/13 08:53;hadoopqa;{color:green}+1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12565748/HADOOP-9225-trunk-b.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 1 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  The javadoc tool did not generate any warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:green}+1 core tests{color}.  The patch passed unit tests in hadoop-common-project/hadoop-common.

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HADOOP-Build/2074//testReport/
Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/2074//console

This message is automatically generated.","21/Jan/13 09:48;vbondarev;Yes, you are right. Now a do correct check of snappy support.","02/Apr/13 17:07;hadoopqa;{color:green}+1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12576599/HADOOP-9225-trunk-c.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 1 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  The javadoc tool did not generate any warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:green}+1 core tests{color}.  The patch passed unit tests in hadoop-common-project/hadoop-common.

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HADOOP-Build/2400//testReport/
Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/2400//console

This message is automatically generated.","02/Oct/13 16:09;nroberts;+1 on patch. Reasonable set of tests and verified with and without snappy available.","02/Oct/13 20:17;jlowe;Patch looks pretty good overall, but I'm confused as to how the comment raised by [~cmccabe] was addressed.  The test is trying to load the snappy library manually which seems a bit odd, since it's making some assumptions as to how the snappy support is supposed to be loaded.  I noticed NativeLibraryChecker is essentially checking NativeCodeLoader.isNativeCodeLoaded() && NativeCodeLoader.buildSupportsSnappy() && SnappyCodec.isNativeCodeLoaded() for Snappy support, which can probably be simplified to just SnappyCodec.isNativeCodeLoaded().  Is there a reason we shouldn't be doing the same in this test?","03/Oct/13 23:11;aklochkov;Removed manual loading of the library and simplified the check. Verified on OSX (all tests are skipped), non-native Linux build, native Linux build with/without Snappy support.","03/Oct/13 23:11;aklochkov;The same patch is applicable to branch-2.","03/Oct/13 23:53;hadoopqa;{color:green}+1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12606675/HADOOP-9225--n4.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 1 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  The javadoc tool did not generate any warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:green}+1 core tests{color}.  The patch passed unit tests in hadoop-common-project/hadoop-common.

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HADOOP-Build/3165//testReport/
Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/3165//console

This message is automatically generated.","04/Oct/13 19:48;nroberts;I think the latest patch fails when the build has snappy available, but the runtime does not. Correct me if this isn't true. I think Jason's suggestion of just checking SnappyCodec.isNativeCodeLoaded()  makes sense and will catch all the cases where these tests should be skipped. I attached a patch with that change.
","04/Oct/13 20:33;aklochkov;Somehow SnappyCodec.isNativeCodecLoaded didn't work for me yesterday but now is working just fine. Agree on the change. ","04/Oct/13 20:51;jlowe;+1 lgtm, committing this shortly.","04/Oct/13 21:04;jlowe;Thanks Vadim, Andrey, and Nathan for the contribution and Colin for reviewing!  I committed this to trunk and branch-2.","04/Oct/13 21:14;hadoopqa;{color:green}+1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12606875/HADOOP-9225.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 1 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  The javadoc tool did not generate any warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:green}+1 core tests{color}.  The patch passed unit tests in hadoop-common-project/hadoop-common.

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HADOOP-Build/3175//testReport/
Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/3175//console

This message is automatically generated.","04/Oct/13 21:40;hudson;SUCCESS: Integrated in Hadoop-trunk-Commit #4540 (See [https://builds.apache.org/job/Hadoop-trunk-Commit/4540/])
HADOOP-9225. Cover package org.apache.hadoop.compress.Snappy. Contributed by Vadim Bondarev, Andrey Klochkov and Nathan Roberts (jlowe: http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1529296)
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/CHANGES.txt
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/compress/snappy
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/compress/snappy/TestSnappyCompressorDecompressor.java
","05/Oct/13 11:00;hudson;SUCCESS: Integrated in Hadoop-Yarn-trunk #353 (See [https://builds.apache.org/job/Hadoop-Yarn-trunk/353/])
HADOOP-9225. Cover package org.apache.hadoop.compress.Snappy. Contributed by Vadim Bondarev, Andrey Klochkov and Nathan Roberts (jlowe: http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1529296)
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/CHANGES.txt
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/compress/snappy
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/compress/snappy/TestSnappyCompressorDecompressor.java
","05/Oct/13 13:30;hudson;SUCCESS: Integrated in Hadoop-Hdfs-trunk #1543 (See [https://builds.apache.org/job/Hadoop-Hdfs-trunk/1543/])
HADOOP-9225. Cover package org.apache.hadoop.compress.Snappy. Contributed by Vadim Bondarev, Andrey Klochkov and Nathan Roberts (jlowe: http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1529296)
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/CHANGES.txt
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/compress/snappy
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/compress/snappy/TestSnappyCompressorDecompressor.java
","05/Oct/13 14:22;hudson;FAILURE: Integrated in Hadoop-Mapreduce-trunk #1569 (See [https://builds.apache.org/job/Hadoop-Mapreduce-trunk/1569/])
HADOOP-9225. Cover package org.apache.hadoop.compress.Snappy. Contributed by Vadim Bondarev, Andrey Klochkov and Nathan Roberts (jlowe: http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1529296)
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/CHANGES.txt
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/compress/snappy
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/compress/snappy/TestSnappyCompressorDecompressor.java
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Cover package with org.apache.hadoop.io.lz4 unit tests,HADOOP-9222,12628172,Test,Closed,HADOOP,Hadoop Common,software,omalley,Hadoop Common is the common library for Apache Hadoop.,http://hadoop.apache.org/,Major,Fixed,vbondarev,vbondarev,vbondarev,18/Jan/13 08:04,12/May/16 18:21,12/Jan/21 11:55,11/Apr/13 20:39,0.23.6,2.0.3-alpha,3.0.0-alpha1,,0.23.8,2.1.0-beta,,,,,,,,,0,,,"Add test class TestLz4CompressorDecompressor with method for Lz4Compressor, Lz4Decompressor testing ",,aklochkov,hudson,iveselovsky,jlowe,vbondarev,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"18/Jan/13 08:06;vbondarev;HADOOP-9222-branch-0.23-a.patch;https://issues.apache.org/jira/secure/attachment/12565447/HADOOP-9222-branch-0.23-a.patch","02/Apr/13 13:28;vbondarev;HADOOP-9222-branch-0.23-b.patch;https://issues.apache.org/jira/secure/attachment/12576562/HADOOP-9222-branch-0.23-b.patch","18/Jan/13 08:06;vbondarev;HADOOP-9222-branch-2-a.patch;https://issues.apache.org/jira/secure/attachment/12565448/HADOOP-9222-branch-2-a.patch","02/Apr/13 13:28;vbondarev;HADOOP-9222-branch-2-b.patch;https://issues.apache.org/jira/secure/attachment/12576563/HADOOP-9222-branch-2-b.patch","18/Jan/13 08:06;vbondarev;HADOOP-9222-trunk-a.patch;https://issues.apache.org/jira/secure/attachment/12565449/HADOOP-9222-trunk-a.patch","02/Apr/13 13:28;vbondarev;HADOOP-9222-trunk-b.patch;https://issues.apache.org/jira/secure/attachment/12576564/HADOOP-9222-trunk-b.patch","09/Apr/13 12:52;vbondarev;HADOOP-9222-trunk-c.patch;https://issues.apache.org/jira/secure/attachment/12577789/HADOOP-9222-trunk-c.patch",,,,,,,,,,,,,,,,,7.0,,,,,,,,,,,,,,,,,,,,2013-01-18 09:04:31.73,,,false,,,,,,,,,,,,,,,,,305068,Reviewed,,,,Fri Apr 12 14:05:48 UTC 2013,,,,,,,"0|i1889z:",256143,,,,,,,,,,,,,,,,,,,,,,,"18/Jan/13 09:04;hadoopqa;{color:green}+1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12565449/HADOOP-9222-trunk-a.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 1 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  The javadoc tool did not generate any warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:green}+1 core tests{color}.  The patch passed unit tests in hadoop-common-project/hadoop-common.

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HADOOP-Build/2069//testReport/
Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/2069//console

This message is automatically generated.","02/Apr/13 13:58;hadoopqa;{color:green}+1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12576564/HADOOP-9222-trunk-b.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 1 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  The javadoc tool did not generate any warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:green}+1 core tests{color}.  The patch passed unit tests in hadoop-common-project/hadoop-common.

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HADOOP-Build/2395//testReport/
Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/2395//console

This message is automatically generated.","08/Apr/13 22:05;jlowe;Thanks for the patch, Vadim.  Overall it looks good.  Just a small nit similar to HADOOP-9233 that the {{BytesGenerator}} class can be replaced with a static function that simply returns a new byte array filled with a series of Random.nextInt(16).

Also, would it be better to use {{Lz4Codec.isNativeCodeLoaded}} rather than the {{NativeCodeLoader}} method directly?","09/Apr/13 12:54;vbondarev;New patch version is available
1. BytesGenerator class was been replaced with a static ""generate"" function
2. Lz4Codec.isNativeCodeLoaded instead NativeCodeLoader methods","10/Apr/13 16:10;hadoopqa;{color:green}+1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12577789/HADOOP-9222-trunk-c.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 1 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  The javadoc tool did not generate any warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:green}+1 core tests{color}.  The patch passed unit tests in hadoop-common-project/hadoop-common.

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HADOOP-Build/2437//testReport/
Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/2437//console

This message is automatically generated.","11/Apr/13 20:15;jlowe;+1, lgtm.  A few nits which I will cleanup on checkin:

* package should be org.apache.hadoop.io.compress.lz4 to be consistent with other lz4 source
* unused imports after the latest changes","11/Apr/13 20:25;hudson;Integrated in Hadoop-trunk-Commit #3598 (See [https://builds.apache.org/job/Hadoop-trunk-Commit/3598/])
    HADOOP-9222. Cover package with org.apache.hadoop.io.lz4 unit tests. Contributed by Vadim Bondarev (Revision 1467072)

     Result = SUCCESS
jlowe : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1467072
Files : 
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/CHANGES.txt
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/compress/lz4
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/compress/lz4/TestLz4CompressorDecompressor.java
","11/Apr/13 20:39;jlowe;Thanks, Vadim!  I committed this to trunk, branch-2, and branch-0.23.","12/Apr/13 10:49;hudson;Integrated in Hadoop-Yarn-trunk #181 (See [https://builds.apache.org/job/Hadoop-Yarn-trunk/181/])
    HADOOP-9222. Cover package with org.apache.hadoop.io.lz4 unit tests. Contributed by Vadim Bondarev (Revision 1467072)

     Result = SUCCESS
jlowe : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1467072
Files : 
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/CHANGES.txt
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/compress/lz4
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/compress/lz4/TestLz4CompressorDecompressor.java
","12/Apr/13 12:42;hudson;Integrated in Hadoop-Hdfs-0.23-Build #579 (See [https://builds.apache.org/job/Hadoop-Hdfs-0.23-Build/579/])
    svn merge -c 1467072 FIXES: HADOOP-9222. Cover package with org.apache.hadoop.io.lz4 unit tests. Contributed by Vadim Bondarev (Revision 1467080)

     Result = SUCCESS
jlowe : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1467080
Files : 
* /hadoop/common/branches/branch-0.23/hadoop-common-project/hadoop-common/CHANGES.txt
* /hadoop/common/branches/branch-0.23/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/compress/lz4
* /hadoop/common/branches/branch-0.23/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/compress/lz4/TestLz4CompressorDecompressor.java
","12/Apr/13 13:06;hudson;Integrated in Hadoop-Hdfs-trunk #1370 (See [https://builds.apache.org/job/Hadoop-Hdfs-trunk/1370/])
    HADOOP-9222. Cover package with org.apache.hadoop.io.lz4 unit tests. Contributed by Vadim Bondarev (Revision 1467072)

     Result = FAILURE
jlowe : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1467072
Files : 
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/CHANGES.txt
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/compress/lz4
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/compress/lz4/TestLz4CompressorDecompressor.java
","12/Apr/13 14:05;hudson;Integrated in Hadoop-Mapreduce-trunk #1397 (See [https://builds.apache.org/job/Hadoop-Mapreduce-trunk/1397/])
    HADOOP-9222. Cover package with org.apache.hadoop.io.lz4 unit tests. Contributed by Vadim Bondarev (Revision 1467072)

     Result = SUCCESS
jlowe : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1467072
Files : 
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/CHANGES.txt
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/compress/lz4
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/compress/lz4/TestLz4CompressorDecompressor.java
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Add unit test for MiniKDC to issue tickets for >1 persons in the same instance,HADOOP-13027,12959035,Test,Open,HADOOP,Hadoop Common,software,omalley,Hadoop Common is the common library for Apache Hadoop.,http://hadoop.apache.org/,Major,,jiajia,jiajia,jiajia,15/Apr/16 02:35,15/Apr/16 03:09,12/Jan/21 11:55,,,,,,,,,,,,,,,,0,,,"As discussed in HADOOP-12911, we should verify MiniKDC can issue tickets for >1 persons in the same instance.",,drankye,jiajia,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,HADOOP-12911,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,9223372036854775807,,,,,2016-04-15 02:35:01.0,,,,,,,"0|i2w5mf:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Improve TestKMS,HADOOP-12546,12910101,Test,Patch Available,HADOOP,Hadoop Common,software,omalley,Hadoop Common is the common library for Apache Hadoop.,http://hadoop.apache.org/,Major,,templedf,templedf,templedf,03/Nov/15 19:06,06/Jan/16 23:23,12/Jan/21 11:55,,2.7.1,,,,,,,,,,test,,,,0,,,"The TestKMS class has some issues:

* It swallows some exceptions' stack traces
* It swallows some exceptions altogether
* Some of the tests aren't as tight as they could be
* Asserts lack messages
* Code style is a bit hodgepodge

This JIRA is to clean all that up.",,stevel@apache.org,templedf,xiaochen,zhz,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,HADOOP-12509,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"03/Nov/15 19:06;templedf;HADOOP-12546.001.patch;https://issues.apache.org/jira/secure/attachment/12770383/HADOOP-12546.001.patch","30/Nov/15 20:21;templedf;HADOOP-12546.002.patch;https://issues.apache.org/jira/secure/attachment/12774880/HADOOP-12546.002.patch","30/Nov/15 22:21;templedf;HADOOP-12546.003.patch;https://issues.apache.org/jira/secure/attachment/12774895/HADOOP-12546.003.patch",,,,,,,,,,,,,,,,,,,,,3.0,,,,,,,,,,,,,,,,,,,,2015-11-03 20:11:46.542,,,false,,,,,,,,,,,,,,,,,9223372036854775807,,,,,Wed Jan 06 23:23:15 UTC 2016,,,,,,,"0|i2nwbr:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,"03/Nov/15 19:08;templedf;This JIRA will make HADOOP-12509 easier to track down next time it shows up.","03/Nov/15 20:11;hadoopqa;| (/) *{color:green}+1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue} 0m 7s {color} | {color:blue} docker + precommit patch detected. {color} |
| {color:green}+1{color} | {color:green} @author {color} | {color:green} 0m 0s {color} | {color:green} The patch does not contain any @author tags. {color} |
| {color:green}+1{color} | {color:green} test4tests {color} | {color:green} 0m 0s {color} | {color:green} The patch appears to include 1 new or modified test files. {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 3m 47s {color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 5m 30s {color} | {color:green} trunk passed with JDK v1.8.0_60 {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 5m 10s {color} | {color:green} trunk passed with JDK v1.7.0_79 {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green} 0m 8s {color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green} 0m 15s {color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green} 0m 27s {color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 0m 12s {color} | {color:green} trunk passed with JDK v1.8.0_60 {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 0m 14s {color} | {color:green} trunk passed with JDK v1.7.0_79 {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 0m 18s {color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 4m 30s {color} | {color:green} the patch passed with JDK v1.8.0_60 {color} |
| {color:green}+1{color} | {color:green} javac {color} | {color:green} 4m 30s {color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 4m 42s {color} | {color:green} the patch passed with JDK v1.7.0_79 {color} |
| {color:green}+1{color} | {color:green} javac {color} | {color:green} 4m 42s {color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green} 0m 7s {color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green} 0m 13s {color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} whitespace {color} | {color:green} 0m 0s {color} | {color:green} Patch has no whitespace issues. {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green} 0m 34s {color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 0m 12s {color} | {color:green} the patch passed with JDK v1.8.0_60 {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 0m 13s {color} | {color:green} the patch passed with JDK v1.7.0_79 {color} |
| {color:green}+1{color} | {color:green} unit {color} | {color:green} 1m 49s {color} | {color:green} hadoop-kms in the patch passed with JDK v1.8.0_60. {color} |
| {color:green}+1{color} | {color:green} unit {color} | {color:green} 1m 52s {color} | {color:green} hadoop-kms in the patch passed with JDK v1.7.0_79. {color} |
| {color:green}+1{color} | {color:green} asflicense {color} | {color:green} 0m 22s {color} | {color:green} Patch does not generate ASF License warnings. {color} |
| {color:black}{color} | {color:black} {color} | {color:black} 31m 44s {color} | {color:black} {color} |
\\
\\
|| Subsystem || Report/Notes ||
| Docker | Client=1.7.1 Server=1.7.1 Image:test-patch-base-hadoop-date2015-11-03 |
| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12770383/HADOOP-12546.001.patch |
| JIRA Issue | HADOOP-12546 |
| Optional Tests |  asflicense  javac  javadoc  mvninstall  unit  findbugs  checkstyle  compile  |
| uname | Linux 522d670cc4bf 3.13.0-36-lowlatency #63-Ubuntu SMP PREEMPT Wed Sep 3 21:56:12 UTC 2014 x86_64 x86_64 x86_64 GNU/Linux |
| Build tool | maven |
| Personality | /home/jenkins/jenkins-slave/workspace/PreCommit-HADOOP-Build/patchprocess/apache-yetus-1a9afee/precommit/personality/hadoop.sh |
| git revision | trunk / 0783184 |
| Default Java | 1.7.0_79 |
| Multi-JDK versions |  /usr/lib/jvm/java-8-oracle:1.8.0_60 /usr/lib/jvm/java-7-openjdk-amd64:1.7.0_79 |
| findbugs | v3.0.0 |
| JDK v1.7.0_79  Test Results | https://builds.apache.org/job/PreCommit-HADOOP-Build/8014/testReport/ |
| modules | C: hadoop-common-project/hadoop-kms U: hadoop-common-project/hadoop-kms |
| Max memory used | 225MB |
| Powered by | Apache Yetus   http://yetus.apache.org |
| Console output | https://builds.apache.org/job/PreCommit-HADOOP-Build/8014/console |


This message was automatically generated.

","24/Nov/15 11:59;stevel@apache.org;looks almost ready to go, except you should be checking IOE.toString(), not getMessage(), as that may actually be null.

I recommend you switch to {{GenericTestUtils.assertExceptionContains()}} there for both the robustness and the way on any failure it includes the stack trace/exception caught in the new failure
","30/Nov/15 20:21;templedf;[~stevel], I extended {{GenericTestUtils}} to allow for a multi-string exception message check, since that's most of what I am testing in the test class.  There were still a couple of cases where the logic was too complicated to offload, but I did switch those cases to using {{toString()}} instead of {{getMessage()}}.","30/Nov/15 22:12;hadoopqa;| (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue} 0m 0s {color} | {color:blue} Docker mode activated. {color} |
| {color:green}+1{color} | {color:green} @author {color} | {color:green} 0m 1s {color} | {color:green} The patch does not contain any @author tags. {color} |
| {color:green}+1{color} | {color:green} test4tests {color} | {color:green} 0m 0s {color} | {color:green} The patch appears to include 2 new or modified test files. {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 10m 0s {color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 13m 11s {color} | {color:green} trunk passed with JDK v1.8.0_66 {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 11m 28s {color} | {color:green} trunk passed with JDK v1.7.0_85 {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green} 0m 26s {color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green} 1m 48s {color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green} 0m 34s {color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green} 3m 1s {color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 1m 31s {color} | {color:green} trunk passed with JDK v1.8.0_66 {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 1m 37s {color} | {color:green} trunk passed with JDK v1.7.0_85 {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 2m 30s {color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 12m 39s {color} | {color:green} the patch passed with JDK v1.8.0_66 {color} |
| {color:green}+1{color} | {color:green} javac {color} | {color:green} 12m 39s {color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 11m 25s {color} | {color:green} the patch passed with JDK v1.7.0_85 {color} |
| {color:green}+1{color} | {color:green} javac {color} | {color:green} 11m 25s {color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green} 0m 28s {color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green} 1m 44s {color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green} 0m 36s {color} | {color:green} the patch passed {color} |
| {color:red}-1{color} | {color:red} whitespace {color} | {color:red} 0m 0s {color} | {color:red} The patch has 1 line(s) that end in whitespace. Use git apply --whitespace=fix. {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green} 3m 15s {color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 1m 41s {color} | {color:green} the patch passed with JDK v1.8.0_66 {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 1m 44s {color} | {color:green} the patch passed with JDK v1.7.0_85 {color} |
| {color:red}-1{color} | {color:red} unit {color} | {color:red} 9m 32s {color} | {color:red} hadoop-common in the patch failed with JDK v1.8.0_66. {color} |
| {color:green}+1{color} | {color:green} unit {color} | {color:green} 2m 16s {color} | {color:green} hadoop-kms in the patch passed with JDK v1.8.0_66. {color} |
| {color:red}-1{color} | {color:red} unit {color} | {color:red} 7m 56s {color} | {color:red} hadoop-common in the patch failed with JDK v1.7.0_85. {color} |
| {color:green}+1{color} | {color:green} unit {color} | {color:green} 2m 1s {color} | {color:green} hadoop-kms in the patch passed with JDK v1.7.0_85. {color} |
| {color:green}+1{color} | {color:green} asflicense {color} | {color:green} 0m 27s {color} | {color:green} Patch does not generate ASF License warnings. {color} |
| {color:black}{color} | {color:black} {color} | {color:black} 103m 38s {color} | {color:black} {color} |
\\
\\
|| Reason || Tests ||
| JDK v1.8.0_66 Failed junit tests | hadoop.fs.TestLocalFsFCStatistics |
|   | hadoop.ipc.TestRPCWaitForProxy |
|   | hadoop.metrics2.impl.TestMetricsSystemImpl |
| JDK v1.7.0_85 Failed junit tests | hadoop.security.ssl.TestReloadingX509TrustManager |
\\
\\
|| Subsystem || Report/Notes ||
| Docker |  Image:yetus/hadoop:0ca8df7 |
| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12774880/HADOOP-12546.002.patch |
| JIRA Issue | HADOOP-12546 |
| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  findbugs  checkstyle  |
| uname | Linux 3cb2ef4a505e 3.13.0-36-lowlatency #63-Ubuntu SMP PREEMPT Wed Sep 3 21:56:12 UTC 2014 x86_64 x86_64 x86_64 GNU/Linux |
| Build tool | maven |
| Personality | /testptch/hadoop/patchprocess/precommit/personality/provided.sh |
| git revision | trunk / 43acf9a |
| findbugs | v3.0.0 |
| whitespace | https://builds.apache.org/job/PreCommit-HADOOP-Build/8166/artifact/patchprocess/whitespace-eol.txt |
| unit | https://builds.apache.org/job/PreCommit-HADOOP-Build/8166/artifact/patchprocess/patch-unit-hadoop-common-project_hadoop-common-jdk1.8.0_66.txt |
| unit | https://builds.apache.org/job/PreCommit-HADOOP-Build/8166/artifact/patchprocess/patch-unit-hadoop-common-project_hadoop-common-jdk1.7.0_85.txt |
| unit test logs |  https://builds.apache.org/job/PreCommit-HADOOP-Build/8166/artifact/patchprocess/patch-unit-hadoop-common-project_hadoop-common-jdk1.8.0_66.txt https://builds.apache.org/job/PreCommit-HADOOP-Build/8166/artifact/patchprocess/patch-unit-hadoop-common-project_hadoop-common-jdk1.7.0_85.txt |
| JDK v1.7.0_85  Test Results | https://builds.apache.org/job/PreCommit-HADOOP-Build/8166/testReport/ |
| modules | C: hadoop-common-project/hadoop-common hadoop-common-project/hadoop-kms U: hadoop-common-project |
| Max memory used | 76MB |
| Powered by | Apache Yetus   http://yetus.apache.org |
| Console output | https://builds.apache.org/job/PreCommit-HADOOP-Build/8166/console |


This message was automatically generated.

","30/Nov/15 22:21;templedf;Crap.  Missed some whitespace.","30/Nov/15 23:50;hadoopqa;| (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue} 0m 0s {color} | {color:blue} Docker mode activated. {color} |
| {color:green}+1{color} | {color:green} @author {color} | {color:green} 0m 0s {color} | {color:green} The patch does not contain any @author tags. {color} |
| {color:green}+1{color} | {color:green} test4tests {color} | {color:green} 0m 0s {color} | {color:green} The patch appears to include 2 new or modified test files. {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 7m 55s {color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 8m 30s {color} | {color:green} trunk passed with JDK v1.8.0_66 {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 9m 12s {color} | {color:green} trunk passed with JDK v1.7.0_85 {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green} 0m 22s {color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green} 1m 26s {color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green} 0m 28s {color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green} 2m 21s {color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 1m 8s {color} | {color:green} trunk passed with JDK v1.8.0_66 {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 1m 23s {color} | {color:green} trunk passed with JDK v1.7.0_85 {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 2m 3s {color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 8m 33s {color} | {color:green} the patch passed with JDK v1.8.0_66 {color} |
| {color:green}+1{color} | {color:green} javac {color} | {color:green} 8m 33s {color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 9m 17s {color} | {color:green} the patch passed with JDK v1.7.0_85 {color} |
| {color:green}+1{color} | {color:green} javac {color} | {color:green} 9m 17s {color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green} 0m 23s {color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green} 1m 25s {color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green} 0m 30s {color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} whitespace {color} | {color:green} 0m 0s {color} | {color:green} Patch has no whitespace issues. {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green} 2m 44s {color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 1m 9s {color} | {color:green} the patch passed with JDK v1.8.0_66 {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 1m 23s {color} | {color:green} the patch passed with JDK v1.7.0_85 {color} |
| {color:red}-1{color} | {color:red} unit {color} | {color:red} 7m 47s {color} | {color:red} hadoop-common in the patch failed with JDK v1.8.0_66. {color} |
| {color:green}+1{color} | {color:green} unit {color} | {color:green} 1m 32s {color} | {color:green} hadoop-kms in the patch passed with JDK v1.8.0_66. {color} |
| {color:green}+1{color} | {color:green} unit {color} | {color:green} 8m 21s {color} | {color:green} hadoop-common in the patch passed with JDK v1.7.0_85. {color} |
| {color:green}+1{color} | {color:green} unit {color} | {color:green} 1m 36s {color} | {color:green} hadoop-kms in the patch passed with JDK v1.7.0_85. {color} |
| {color:green}+1{color} | {color:green} asflicense {color} | {color:green} 0m 23s {color} | {color:green} Patch does not generate ASF License warnings. {color} |
| {color:black}{color} | {color:black} {color} | {color:black} 81m 15s {color} | {color:black} {color} |
\\
\\
|| Reason || Tests ||
| JDK v1.8.0_66 Failed junit tests | hadoop.metrics2.impl.TestGangliaMetrics |
|   | hadoop.ipc.TestIPC |
\\
\\
|| Subsystem || Report/Notes ||
| Docker |  Image:yetus/hadoop:0ca8df7 |
| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12774895/HADOOP-12546.003.patch |
| JIRA Issue | HADOOP-12546 |
| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  findbugs  checkstyle  |
| uname | Linux ee45bddfcf80 3.13.0-36-lowlatency #63-Ubuntu SMP PREEMPT Wed Sep 3 21:56:12 UTC 2014 x86_64 x86_64 x86_64 GNU/Linux |
| Build tool | maven |
| Personality | /testptch/hadoop/patchprocess/precommit/personality/provided.sh |
| git revision | trunk / 43acf9a |
| findbugs | v3.0.0 |
| unit | https://builds.apache.org/job/PreCommit-HADOOP-Build/8168/artifact/patchprocess/patch-unit-hadoop-common-project_hadoop-common-jdk1.8.0_66.txt |
| unit test logs |  https://builds.apache.org/job/PreCommit-HADOOP-Build/8168/artifact/patchprocess/patch-unit-hadoop-common-project_hadoop-common-jdk1.8.0_66.txt |
| JDK v1.7.0_85  Test Results | https://builds.apache.org/job/PreCommit-HADOOP-Build/8168/testReport/ |
| modules | C: hadoop-common-project/hadoop-common hadoop-common-project/hadoop-kms U: hadoop-common-project |
| Max memory used | 75MB |
| Powered by | Apache Yetus   http://yetus.apache.org |
| Console output | https://builds.apache.org/job/PreCommit-HADOOP-Build/8168/console |


This message was automatically generated.

","08/Dec/15 22:55;templedf;[~steve_l], the updated patch is posted.","05/Jan/16 22:49;xiaochen;I've seen some intermittent failures of TestKMS (testKMSProvider specifically), and this JIRA looks to be helpful on exposing more details of it. I reviewed through Patch 03, looks good to me, +1 (non-binding). Thanks [~templedf] and [~stevel@apache.org].","06/Jan/16 21:31;zhz;03 patch LGTM as well. [~templedf] Do you mind rebasing the patch?","06/Jan/16 22:39;templedf;TestKMS hasn't changed since Feb.  It shouldn't need a rebase.","06/Jan/16 23:23;zhz;I think the conflict is from HADOOP-12682. I tried applying v03 patch but failed.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
TestWebDelegationToken is flaky,HADOOP-11439,12763179,Test,Resolved,HADOOP,Hadoop Common,software,omalley,Hadoop Common is the common library for Apache Hadoop.,http://hadoop.apache.org/,Major,Duplicate,xieliang007,xieliang007,xieliang007,22/Dec/14 07:10,09/Dec/15 21:25,12/Jan/21 11:55,09/Dec/15 21:25,2.7.0,,,,,,,,,,security,test,,,0,,,"see https://builds.apache.org/job/PreCommit-HDFS-Build/9101//testReport/org.apache.hadoop.security.token.delegation.web/TestWebDelegationToken/testDelegationTokenAuthenticatorCallsWithQueryString/

through we have set the port to 0 in 
{code}
  protected Server createJettyServer() {
    try {
      InetAddress localhost = InetAddress.getLocalHost();
      ServerSocket ss = new ServerSocket(0, 50, localhost);
      int port = ss.getLocalPort();
      ss.close();
      jetty = new Server(0);
      jetty.getConnectors()[0].setHost(""localhost"");
      jetty.getConnectors()[0].setPort(port);
{code}

but in a QA robot env, it still could see the new random port be grab by other testing case or third party applicatons just between ""ss.close"" and ""jetty.start()"" call. so we still need a BindException retry here probably.",,xiaochen,xieliang007,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,HADOOP-12417,,,,HADOOP-11486,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,2015-12-09 21:25:54.81,,,false,,,,,,,,,,,,,,,,,9223372036854775807,,,,,Wed Dec 09 21:25:54 UTC 2015,,,,,,,"0|i23oef:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,"09/Dec/15 21:25;xiaochen;I believe this has been fixed by HADOOP-12417, resolving as dup. Thanks [~xieliang007] for reporting.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
ant test-patch fails with Required Args Missing.,HADOOP-9965,12668788,Test,Resolved,HADOOP,Hadoop Common,software,omalley,Hadoop Common is the common library for Apache Hadoop.,http://hadoop.apache.org/,Major,Won't Fix,,cnauroth,cnauroth,16/Sep/13 15:21,05/Nov/15 22:36,12/Jan/21 11:55,05/Nov/15 22:36,1.2.1,,,,,,,,,,build,,,,0,,,"Running the ant test-patch process on branch-1 fails with the message ""Required Args Missing"".  It appears that test-patch.sh is not parsing the arguments from the command line correctly.",,aajisaka,aw,cnauroth,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,2015-11-05 22:36:01.043,,,false,,,,,,,,,,,,,,,,,348722,,,,,Thu Nov 05 22:36:01 UTC 2015,,,,,,,"0|i1o4p3:",349019,,,,,,,,,,,,,1.3.0,,,,,,,,,,"16/Sep/13 15:27;cnauroth;It appears that this was introduced by HADOOP-9573.  If I revert that patch, then test-patch works for me.  [~gkesavan] or [~mattf], do you have any thoughts on this?

I'm running test-patch in developer mode with the following command line, which has worked for me in the past.

ant -Dforrest.home=/Users/chris/apache-forrest-0.9 -Dfindbugs.home=/Users/chris/findbugs-1.3.9 -Declipse.home=/Users/chris/eclipse -Dpatch.file=/Users/chris/patch/HDFS-5211.1.patch test-patch

I didn't try Jenkins mode, so I don't know if that also has a problem.

From some very quick troubleshooting, I can tell that all variables are empty when execution reaches the following code, so all of the -z checks are true.

{code}
  [[ -z $JENKINS ]] && echo ""Developer mode""  && \
    [[ -z ""$PATCH_FILE"" || -z ""$PATCH_DIR"" || -z ""$FINDBUGS_HOME"" \
         || -z ""$FORREST_HOME"" || -z ""$ECLIPSE_HOME"" ]] \
         && echo ""Required Args Missing"" && usage
   [[ ! -d ""$PATCH_DIR"" ]] && mkdir -p ""$PATCH_DIR""
{code}

Something else that could be problematic is the following line in build.xml that passes ""test-test-patch.sh"" as an argument.

{code}
<target name=""test-patch"" depends=""patch.check,findbugs.check,forrest.check"">
  <exec executable=""bash"" failonerror=""true"">
    <arg value=""${basedir}/src/test/bin/test-patch.sh""/>
    <arg line=""${basedir}/src/test/bin/test-test-patch.sh""/>
    <arg line=""--patch-dir=${patch.dir} --patch-file=${patch.file}""/>
    <arg line=""--findbugs-home ${findbugs.home} --forrest-home ${forrest.home}""/>
    <arg line=""--eclipse-home ${eclipse.home}""/>
 </exec>
</target>
{code}
","05/Nov/15 22:36;aw;Closing as won't fix.  test-patch has been replaced by Yetus.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Unit test TestSwiftFileSystemLsOperations#testListEmptyRoot and testListNonEmptyRoot failure.,HADOOP-10351,12696311,Test,Patch Available,HADOOP,Hadoop Common,software,omalley,Hadoop Common is the common library for Apache Hadoop.,http://hadoop.apache.org/,Major,,,jwang302,jwang302,20/Feb/14 17:58,03/Nov/15 22:58,12/Jan/21 11:55,,2.3.0,,,,,,,,,,fs/swift,test,,,1,,,"TestSwiftFileSystemLsOperations#testListEmptyRoot and testLisNontEmptyRoot fails because the unit test TestFSMainOperationsSwift creates the testing directory test.build.dir through its parent class. But during the parent classes tearDown, only the test.build.dir/test directory is deleted leaving the test.build.dir in the container. However, tests TestSwiftFileSystemLsOperations#testListEmptyRoot and testListEmptyRoot do not expect the directory to exists in the container thus causing the failure.

  TestSwiftFileSystemLsOperations.testListEmptyRoot:126->Assert.assertEquals:472->Assert.assertEquals:128->Assert.failNotEquals:647->Assert.fail:93 Non-empty root/[00] SwiftFileStatus{ path=swift://container1.service/home; isDirectory=true; length=0; blocksize=33554432; modification_time=1392850893440}
 expected:<0> but was:<1>
  TestSwiftFileSystemLsOperations.testListNonEmptyRoot:137->Assert.assertEquals:472->Assert.assertEquals:128->Assert.failNotEquals:647->Assert.fail:93 Wrong #of root children/[00] SwiftFileStatus{ path=swift://container1.service/home; isDirectory=true; length=0; blocksize=33554432; modification_time=1392850893440}
[01] SwiftFileStatus{ path=swift://patchtest.softlayer/test; isDirectory=true; length=0; blocksize=33554432; modification_time=1392851462990}
 expected:<1> but was:<2>
",,jwang302,kazuki,ramtinb,stevel@apache.org,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"08/Jun/14 01:06;jwang302;HADOOP-10351.patch;https://issues.apache.org/jira/secure/attachment/12648841/HADOOP-10351.patch",,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,2014-06-06 18:15:52.013,,,false,,,,,,,,,,,,,,,,,374787,,,,,Tue Nov 03 22:58:25 UTC 2015,,,,,,,"0|i1sl3b:",375087,,,,,,,,,,,,,,,,,,,,,,,"21/Feb/14 06:26;jwang302;Patch attached overriding the parent class tearDown method to make sure the whole test directory is completely deleted from the swift container.","06/Jun/14 18:15;stevel@apache.org;This is interesting: I've not seen this in my tests -but it sounds like the ordering of tests defines this.

Fix-wise, I think it's better to have the tests themselves be more robust by doing a delete(""/"", true) before the rest of the work.
This stops us worrying about teardown in external tests, and just forces the object store into the desired state before the run.

Do want to supply that patch?","08/Jun/14 01:10;jwang302;Thanks Steve. Updated the patch to make sure those tests start with a clean root directory in the container.","08/Aug/14 12:47;kazuki;I encountered this problem too.
Attached patch is works fine.","03/Nov/15 21:41;ramtinb;+1 (non binding)","03/Nov/15 22:58;hadoopqa;| (/) *{color:green}+1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue} 0m 6s {color} | {color:blue} docker + precommit patch detected. {color} |
| {color:green}+1{color} | {color:green} @author {color} | {color:green} 0m 0s {color} | {color:green} The patch does not contain any @author tags. {color} |
| {color:green}+1{color} | {color:green} test4tests {color} | {color:green} 0m 0s {color} | {color:green} The patch appears to include 1 new or modified test files. {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 3m 0s {color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 0m 11s {color} | {color:green} trunk passed with JDK v1.8.0_60 {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 0m 13s {color} | {color:green} trunk passed with JDK v1.7.0_79 {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green} 0m 8s {color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green} 0m 12s {color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green} 0m 30s {color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 0m 13s {color} | {color:green} trunk passed with JDK v1.8.0_60 {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 0m 15s {color} | {color:green} trunk passed with JDK v1.7.0_79 {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 0m 14s {color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 0m 11s {color} | {color:green} the patch passed with JDK v1.8.0_60 {color} |
| {color:green}+1{color} | {color:green} javac {color} | {color:green} 0m 11s {color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 0m 13s {color} | {color:green} the patch passed with JDK v1.7.0_79 {color} |
| {color:green}+1{color} | {color:green} javac {color} | {color:green} 0m 13s {color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green} 0m 8s {color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green} 0m 12s {color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} whitespace {color} | {color:green} 0m 0s {color} | {color:green} Patch has no whitespace issues. {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green} 0m 39s {color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 0m 13s {color} | {color:green} the patch passed with JDK v1.8.0_60 {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 0m 14s {color} | {color:green} the patch passed with JDK v1.7.0_79 {color} |
| {color:green}+1{color} | {color:green} unit {color} | {color:green} 0m 12s {color} | {color:green} hadoop-openstack in the patch passed with JDK v1.8.0_60. {color} |
| {color:green}+1{color} | {color:green} unit {color} | {color:green} 0m 12s {color} | {color:green} hadoop-openstack in the patch passed with JDK v1.7.0_79. {color} |
| {color:green}+1{color} | {color:green} asflicense {color} | {color:green} 0m 23s {color} | {color:green} Patch does not generate ASF License warnings. {color} |
| {color:black}{color} | {color:black} {color} | {color:black} 8m 37s {color} | {color:black} {color} |
\\
\\
|| Subsystem || Report/Notes ||
| Docker | Client=1.7.1 Server=1.7.1 Image:test-patch-base-hadoop-date2015-11-03 |
| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12648841/HADOOP-10351.patch |
| JIRA Issue | HADOOP-10351 |
| Optional Tests |  asflicense  javac  javadoc  mvninstall  unit  findbugs  checkstyle  compile  |
| uname | Linux 3d5f8e84581f 3.13.0-36-lowlatency #63-Ubuntu SMP PREEMPT Wed Sep 3 21:56:12 UTC 2014 x86_64 x86_64 x86_64 GNU/Linux |
| Build tool | maven |
| Personality | /home/jenkins/jenkins-slave/workspace/PreCommit-HADOOP-Build/patchprocess/apache-yetus-1a9afee/precommit/personality/hadoop.sh |
| git revision | trunk / dac0463 |
| Default Java | 1.7.0_79 |
| Multi-JDK versions |  /usr/lib/jvm/java-8-oracle:1.8.0_60 /usr/lib/jvm/java-7-openjdk-amd64:1.7.0_79 |
| findbugs | v3.0.0 |
| JDK v1.7.0_79  Test Results | https://builds.apache.org/job/PreCommit-HADOOP-Build/8017/testReport/ |
| modules | C: hadoop-tools/hadoop-openstack U: hadoop-tools/hadoop-openstack |
| Max memory used | 227MB |
| Powered by | Apache Yetus   http://yetus.apache.org |
| Console output | https://builds.apache.org/job/PreCommit-HADOOP-Build/8017/console |


This message was automatically generated.

",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Allow TestCLI to be run against a cluster,HADOOP-7730,12526357,Test,Resolved,HADOOP,Hadoop Common,software,omalley,Hadoop Common is the common library for Apache Hadoop.,http://hadoop.apache.org/,Major,Won't Fix,cos,cos,cos,09/Oct/11 05:31,07/Oct/15 19:49,12/Jan/21 11:55,07/Oct/15 19:49,0.20.205.0,0.22.0,,,0.22.1,,,,,,test,,,,0,,,Use the same CLI test to test cluster bits (see HDFS-1762 for more info),,Fan04290,mattf,rvs,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"09/Oct/11 05:33;cos;HADOOP-7730.patch;https://issues.apache.org/jira/secure/attachment/12498335/HADOOP-7730.patch","11/Oct/11 18:58;cos;HADOOP-7730.trunk.patch;https://issues.apache.org/jira/secure/attachment/12498647/HADOOP-7730.trunk.patch","11/Oct/11 18:56;cos;HADOOP-7730.trunk.patch;https://issues.apache.org/jira/secure/attachment/12498645/HADOOP-7730.trunk.patch",,,,,,,,,,,,,,,,,,,,,3.0,,,,,,,,,,,,,,,,,,,,2011-10-11 06:06:26.317,,,false,,,,,,,,,,,,,,,,,50916,Reviewed,,,,Tue May 14 05:01:58 UTC 2013,,,,,,,"0|i0hvfb:",102353,The resolution has been done in the Bigtop a few years ago. Closing this one as of irrelevant to the project.,,,,,,,,,,,,0.22.1,1.3.0,,,,,,,,,"09/Oct/11 05:33;cos;Moving common patch from hdfs ticket.","11/Oct/11 06:06;shv;+1","11/Oct/11 18:45;cos;I have just committed it.","11/Oct/11 18:56;cos;This patch needs to be reworked a little bit for the trunk","11/Oct/11 18:58;cos;Wrong base for the trunk patch","11/Oct/11 21:43;hudson;Integrated in Hadoop-Common-22-branch #91 (See [https://builds.apache.org/job/Hadoop-Common-22-branch/91/])
    HADOOP-7730. Allow TestCLI to be run against a cluster. Contributed by Tom White, Konstantin Boudnik.

cos : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1182018
Files : 
* /hadoop/common/branches/branch-0.22/common/CHANGES.txt
* /hadoop/common/branches/branch-0.22/common/src/test/core/org/apache/hadoop/cli/CLITestHelper.java
* /hadoop/common/branches/branch-0.22/common/src/test/core/org/apache/hadoop/cli/util/CommandExecutor.java
","31/Oct/11 21:43;rvs;Can we, please, port this to 0.20.205 ?","31/Oct/11 22:06;cos;There's nothing to port really, I suspect: original patch should work (or mostly work). It is up to the next RM to include this fix or now.","01/Nov/11 08:17;mattf;Reopened for port to 0.20.206, per request from Roman.","20/Mar/12 04:13;cos;Do we need to apply it to 1.0.2 and resolve?","23/Jul/12 07:58;mattf;Please propose an applicable patch and get it committed to branch-1.
Thank you.","14/May/13 05:01;mattf;Changed Target Version to 1.3.0 upon release of 1.2.0. Please change to 1.2.1 if you intend to submit a fix for branch-1.2.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
TestRPCCallBenchmark#testBenchmarkWithWritable fails with RTE,HADOOP-8157,12545769,Test,Closed,HADOOP,Hadoop Common,software,omalley,Hadoop Common is the common library for Apache Hadoop.,http://hadoop.apache.org/,Major,Fixed,tlipcon,eli2,eli2,09/Mar/12 04:36,28/Sep/15 20:58,12/Jan/21 11:55,22/Mar/12 00:49,0.24.0,,,,0.23.7,2.0.0-alpha,,,,,,,,,0,,,"Saw TestRPCCallBenchmark#testBenchmarkWithWritable fail with the following on jenkins:
Caused by: java.lang.RuntimeException: IPC server unable to read call parameters: readObject can't find class java.lang.String
",,clarkyzl,hudson,jlowe,tlipcon,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"21/Mar/12 21:07;tlipcon;hadoop-8157.txt;https://issues.apache.org/jira/secure/attachment/12519315/hadoop-8157.txt",,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,2012-03-09 06:11:24.226,,,false,,,,,,,,,,,,,,,,,230952,Reviewed,,,,Thu Jan 17 12:36:33 UTC 2013,,,,,,,"0|i07uvb:",43768,,,,,,,,,,,,,0.23.3,0.24.0,,,,,,,,,"09/Mar/12 04:37;eli2;Full stacktrace:

{noformat}
java.lang.RuntimeException: Deferred
	at org.apache.hadoop.test.MultithreadedTestUtil$TestContext.checkException(MultithreadedTestUtil.java:129)
	at org.apache.hadoop.test.MultithreadedTestUtil$TestContext.waitFor(MultithreadedTestUtil.java:120)
	at org.apache.hadoop.ipc.RPCCallBenchmark.run(RPCCallBenchmark.java:274)
	at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:69)
	at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:83)
	at org.apache.hadoop.ipc.TestRPCCallBenchmark.testBenchmarkWithWritable(TestRPCCallBenchmark.java:30)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:44)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:15)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:41)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:20)
	at org.junit.internal.runners.statements.FailOnTimeout$1.run(FailOnTimeout.java:28)
Caused by: java.lang.RuntimeException: IPC server unable to read call parameters: readObject can't find class java.lang.String
	at org.apache.hadoop.ipc.Client.call(Client.java:1159)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:225)
	at $Proxy8.echo(Unknown Source)
	at org.apache.hadoop.ipc.RPCCallBenchmark$4.doEcho(RPCCallBenchmark.java:398)
	at org.apache.hadoop.ipc.RPCCallBenchmark$2.doAnAction(RPCCallBenchmark.java:358)
	at org.apache.hadoop.test.MultithreadedTestUtil$RepeatingTestThread.doWork(MultithreadedTestUtil.java:219)
	at org.apache.hadoop.test.MultithreadedTestUtil$TestingThread.run(MultithreadedTestUtil.java:187)
{noformat}

Standard out:
{noformat}
2012-03-09 04:25:00,114 WARN  ipc.Server (Server.java:processData(1562)) - Unable to read call parameters for client 67.195.138.24on connection protocol org.apache.hadoop.ipc.TestRPC$TestProtocol for rpcKind RPC_WRITABLE
java.lang.RuntimeException: readObject can't find class java.lang.String
	at org.apache.hadoop.io.ObjectWritable.loadClass(ObjectWritable.java:372)
	at org.apache.hadoop.io.ObjectWritable.readObject(ObjectWritable.java:223)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invocation.readFields(WritableRpcEngine.java:156)
	at org.apache.hadoop.ipc.Server$Connection.processData(Server.java:1560)
	at org.apache.hadoop.ipc.Server$Connection.processOneRpc(Server.java:1515)
	at org.apache.hadoop.ipc.Server$Connection.readAndProcess(Server.java:1369)
	at org.apache.hadoop.ipc.Server$Listener.doRead(Server.java:684)
	at org.apache.hadoop.ipc.Server$Listener$Reader.doRunLoop(Server.java:483)
	at org.apache.hadoop.ipc.Server$Listener$Reader.run(Server.java:458)
Caused by: java.lang.ClassNotFoundException: Class java.lang.String not found
	at org.apache.hadoop.conf.Configuration.getClassByName(Configuration.java:1151)
	at org.apache.hadoop.io.ObjectWritable.loadClass(ObjectWritable.java:368)
	... 8 more
2012-03-09 04:25:00,121 ERROR test.MultithreadedTestUtil (MultithreadedTestUtil.java:threadFailed(140)) - Failed!
java.lang.RuntimeException: IPC server unable to read call parameters: readObject can't find class java.lang.String
	at org.apache.hadoop.ipc.Client.call(Client.java:1159)
	at org.apache.hadoop.ipc.WritableRpcEngine$Invoker.invoke(WritableRpcEngine.java:225)
	at $Proxy8.echo(Unknown Source)
	at org.apache.hadoop.ipc.RPCCallBenchmark$4.doEcho(RPCCallBenchmark.java:398)
	at org.apache.hadoop.ipc.RPCCallBenchmark$2.doAnAction(RPCCallBenchmark.java:358)
	at org.apache.hadoop.test.MultithreadedTestUtil$RepeatingTestThread.doWork(MultithreadedTestUtil.java:219)
	at org.apache.hadoop.test.MultithreadedTestUtil$TestingThread.run(MultithreadedTestUtil.java:187)
2012-03-09 04:25:00,123 INFO  ipc.Server (Server.java:stop(1909)) - Stopping server on 12345
2012-03-09 04:25:00,124 WARN  ipc.Server (Server.java:processResponse(953)) - IPC Server Responder, call 
{noformat}
","09/Mar/12 06:11;tlipcon;This failure is super-goofy. My hunch is it's something to do with non-threadsafe use of classloaders or some other bad synchronization, but I don't have much to go on. Any ideas?","21/Mar/12 20:59;tlipcon;I think I understand this bug. It's probably due to an error in HADOOP-6502. Patch and explanation en route.","21/Mar/12 21:07;tlipcon;I believe the problem is this:
The cache added by HADOOP-6502 used a ""null"" value in the map as a negative cache entry for a class not found. However, it uses a WeakHashMap to avoid leaking references. The semantics of WeakHashMap are such that we could hit the following scenario:

- check ""containsKey()"" for a given key, see it was there
- GC runs and clears that key from the map
- call ""get"" and return null.
- Now we think it was a negative cache entry and throw ClassNotFoundException

The fix here is to stop using nulls to cache the ""not found"" result. Instead, we insert a special sentinel value as a negative cache entry.

Unfortunately it's diffcult to reproduce this on my box, but we've seen TestRPCCallBenchmark fail on Hudson a lot without this patch. So if we commit this, and we stop seeing the failures, we'll know we fixed the bug.","21/Mar/12 21:21;eli2;+1   Nice find, patch lgtm","21/Mar/12 22:28;hadoopqa;-1 overall.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12519315/hadoop-8157.txt
  against trunk revision .

    +1 @author.  The patch does not contain any @author tags.

    -1 tests included.  The patch doesn't appear to include any new or modified tests.
                        Please justify why no new tests are needed for this patch.
                        Also please list what manual steps were performed to verify this patch.

    +1 javadoc.  The javadoc tool did not generate any warning messages.

    +1 javac.  The applied patch does not increase the total number of javac compiler warnings.

    +1 eclipse:eclipse.  The patch built with eclipse:eclipse.

    +1 findbugs.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    +1 release audit.  The applied patch does not increase the total number of release audit warnings.

    +1 core tests.  The patch passed unit tests in .

    +1 contrib tests.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HADOOP-Build/741//testReport/
Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/741//console

This message is automatically generated.","22/Mar/12 00:49;tlipcon;Committed to 0.23 and trunk","22/Mar/12 01:09;hudson;Integrated in Hadoop-Common-trunk-Commit #1914 (See [https://builds.apache.org/job/Hadoop-Common-trunk-Commit/1914/])
    HADOOP-8157. Fix race condition in Configuration that could cause spurious ClassNotFoundExceptions after a GC. Contributed by Todd Lipcon. (Revision 1303634)

     Result = SUCCESS
todd : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1303634
Files : 
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/CHANGES.txt
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/conf/Configuration.java
","22/Mar/12 01:13;hudson;Integrated in Hadoop-Hdfs-trunk-Commit #1988 (See [https://builds.apache.org/job/Hadoop-Hdfs-trunk-Commit/1988/])
    HADOOP-8157. Fix race condition in Configuration that could cause spurious ClassNotFoundExceptions after a GC. Contributed by Todd Lipcon. (Revision 1303634)

     Result = SUCCESS
todd : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1303634
Files : 
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/CHANGES.txt
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/conf/Configuration.java
","22/Mar/12 01:18;hudson;Integrated in Hadoop-Hdfs-0.23-Commit #704 (See [https://builds.apache.org/job/Hadoop-Hdfs-0.23-Commit/704/])
    HADOOP-8157. Fix race condition in Configuration that could cause spurious ClassNotFoundExceptions after a GC. Contributed by Todd Lipcon. (Revision 1303633)

     Result = SUCCESS
todd : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1303633
Files : 
* /hadoop/common/branches/branch-0.23/hadoop-common-project/hadoop-common/CHANGES.txt
* /hadoop/common/branches/branch-0.23/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/conf/Configuration.java
","22/Mar/12 01:23;hudson;Integrated in Hadoop-Common-0.23-Commit #713 (See [https://builds.apache.org/job/Hadoop-Common-0.23-Commit/713/])
    HADOOP-8157. Fix race condition in Configuration that could cause spurious ClassNotFoundExceptions after a GC. Contributed by Todd Lipcon. (Revision 1303633)

     Result = SUCCESS
todd : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1303633
Files : 
* /hadoop/common/branches/branch-0.23/hadoop-common-project/hadoop-common/CHANGES.txt
* /hadoop/common/branches/branch-0.23/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/conf/Configuration.java
","22/Mar/12 01:42;hudson;Integrated in Hadoop-Mapreduce-trunk-Commit #1923 (See [https://builds.apache.org/job/Hadoop-Mapreduce-trunk-Commit/1923/])
    HADOOP-8157. Fix race condition in Configuration that could cause spurious ClassNotFoundExceptions after a GC. Contributed by Todd Lipcon. (Revision 1303634)

     Result = ABORTED
todd : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1303634
Files : 
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/CHANGES.txt
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/conf/Configuration.java
","22/Mar/12 01:51;hudson;Integrated in Hadoop-Mapreduce-0.23-Commit #721 (See [https://builds.apache.org/job/Hadoop-Mapreduce-0.23-Commit/721/])
    HADOOP-8157. Fix race condition in Configuration that could cause spurious ClassNotFoundExceptions after a GC. Contributed by Todd Lipcon. (Revision 1303633)

     Result = ABORTED
todd : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1303633
Files : 
* /hadoop/common/branches/branch-0.23/hadoop-common-project/hadoop-common/CHANGES.txt
* /hadoop/common/branches/branch-0.23/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/conf/Configuration.java
","22/Mar/12 12:59;hudson;Integrated in Hadoop-Hdfs-trunk #992 (See [https://builds.apache.org/job/Hadoop-Hdfs-trunk/992/])
    HADOOP-8157. Fix race condition in Configuration that could cause spurious ClassNotFoundExceptions after a GC. Contributed by Todd Lipcon. (Revision 1303634)

     Result = FAILURE
todd : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1303634
Files : 
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/CHANGES.txt
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/conf/Configuration.java
","22/Mar/12 13:08;hudson;Integrated in Hadoop-Hdfs-0.23-Build #205 (See [https://builds.apache.org/job/Hadoop-Hdfs-0.23-Build/205/])
    HADOOP-8157. Fix race condition in Configuration that could cause spurious ClassNotFoundExceptions after a GC. Contributed by Todd Lipcon. (Revision 1303633)

     Result = SUCCESS
todd : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1303633
Files : 
* /hadoop/common/branches/branch-0.23/hadoop-common-project/hadoop-common/CHANGES.txt
* /hadoop/common/branches/branch-0.23/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/conf/Configuration.java
","22/Mar/12 13:17;hudson;Integrated in Hadoop-Mapreduce-0.23-Build #233 (See [https://builds.apache.org/job/Hadoop-Mapreduce-0.23-Build/233/])
    HADOOP-8157. Fix race condition in Configuration that could cause spurious ClassNotFoundExceptions after a GC. Contributed by Todd Lipcon. (Revision 1303633)

     Result = FAILURE
todd : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1303633
Files : 
* /hadoop/common/branches/branch-0.23/hadoop-common-project/hadoop-common/CHANGES.txt
* /hadoop/common/branches/branch-0.23/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/conf/Configuration.java
","22/Mar/12 13:58;hudson;Integrated in Hadoop-Mapreduce-trunk #1027 (See [https://builds.apache.org/job/Hadoop-Mapreduce-trunk/1027/])
    HADOOP-8157. Fix race condition in Configuration that could cause spurious ClassNotFoundExceptions after a GC. Contributed by Todd Lipcon. (Revision 1303634)

     Result = SUCCESS
todd : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1303634
Files : 
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/CHANGES.txt
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/conf/Configuration.java
","16/Jan/13 21:28;jlowe;Even though the JIRA said it was merged into 0.23, this was one of those JIRAs that was ""lost"" when branch-0.23 became branch-2 and branch-0.23 was recreated.

Ran across it on 0.23 and noticed it wasn't fixed, so I pulled it into branch-0.23.  Again.  ;-)  Thanks, Todd!","17/Jan/13 12:36;hudson;Integrated in Hadoop-Hdfs-0.23-Build #497 (See [https://builds.apache.org/job/Hadoop-Hdfs-0.23-Build/497/])
    svn merge -c 1303634 FIXES: HADOOP-8157. Fix race condition in Configuration that could cause spurious ClassNotFoundExceptions after a GC. Contributed by Todd Lipcon. (Revision 1434412)

     Result = FAILURE
jlowe : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1434412
Files : 
* /hadoop/common/branches/branch-0.23/hadoop-common-project/hadoop-common/CHANGES.txt
* /hadoop/common/branches/branch-0.23/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/conf/Configuration.java
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
test-patch.sh doesn't run all tests,HADOOP-8964,12613091,Test,Resolved,HADOOP,Hadoop Common,software,omalley,Hadoop Common is the common library for Apache Hadoop.,http://hadoop.apache.org/,Major,Won't Fix,vinodkv,vinodkv,vinodkv,23/Oct/12 02:28,27/Jun/15 17:55,12/Jan/21 11:55,27/Jun/15 17:55,,,,,,,,,,,build,,,,0,,,"test-patch.sh tries to be smart but with bad results. When it runs tests, say on each commit, it only runs tests only from modules which have corresponding changes. This is a cause of concern for downstream modules. We ran into multiple issues in the past because of this, the most recent of it being YARN-179.",,adi2,aw,eli,jlowe,kasha,kkambatl,raviprak,revans2,sureshms,tomwhite,vinodkv,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,2012-10-23 15:10:44.471,,,false,,,,,,,,,,,,,,,,,250491,,,,,Sat Jun 27 17:55:10 UTC 2015,,,,,,,"0|i0ayvz:",61925,,,,,,,,,,,,,,,,,,,,,,,"23/Oct/12 02:29;vinodkv;This may have been done to avoid running all tests which can take a long time, but under each project root (common/hdfs/mapreduce/yarn), we should run all tests from all sub-modules in the whole tree?

If nothing, I'd like to modify to run all tests under all modules of yarn.","23/Oct/12 15:10;revans2;We had a lot of speedup in the tests by doing this.  The problem is that running all tests takes hours.  This means that JIRAs start to back up and fill up the queues.  I am fine with changing it so it runs all of the tests for the top level project, like if it is in YARN it runs everything in YARN.  But if we want to enable all of the tests to run we first need to classify the tests between true unit tests that should be run as part of check-in/pre-commit and integration tests that take longer but should not be run as part of the pre-commit. i.e. anything that uses a minicluster. ","23/Oct/12 15:32;tomwhite;There was some discussion on this on http://mail-archives.aurora.apache.org/mod_mbox/hadoop-common-dev/201204.mbox/%3CCAF-WD4TvKwYpuuQ9ibxv4UZ8B2BEhXnpfKb5mq3D-pwVKSHOzA@mail.gmail.com%3E and HADOOP-8308.

I like the direction that Bobby is suggesting. We could use Maven's distinction between unit and integration tests ({{mvn test}} vs {{mvn integration-test}}).","23/Oct/12 22:24;vinodkv;I am definitely for not running mapreduce tests when a common patch gets checked in. But if YARN common lib changes, I definitely want to run RM and NM tests. I understand that not running everything speeds things up, but we have correctness issues when we don't run downstream tests.

Is it okay to just run all tests in case of YARN for the shorter term, they don't take more than 10 mins for now? Separating integration tests into their own suite is a bigger effort.","25/Oct/12 19:37;tomwhite;Vinod - that seems reasonable to me.","27/Jun/15 17:55;aw;at this point, i'm closing this as won't fix.  the nightly runs pretty much for the purpose of doing a full test run and should really be used for this type of intense testing.  (for example, hadoop-tools is particularly problematic since it would require everything to get built!)",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
test-patch.sh triggered full hdfs unit tests when it shouldn't,HADOOP-12023,12832356,Test,Resolved,HADOOP,Hadoop Common,software,omalley,Hadoop Common is the common library for Apache Hadoop.,http://hadoop.apache.org/,Major,Duplicate,,aw,aw,23/May/15 15:48,27/Jun/15 17:26,12/Jan/21 11:55,27/Jun/15 17:26,,,,,,,,,,,test,,,,0,,,"On HDFS-7991, the HDFS-7991-shellpart.patch triggered a full hdfs unit test run despite not having any java code.  The determine test rules need to be verified to work correctly for patches like that.",,aw,busbey,sekikn,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,2015-05-23 18:54:44.79,,,false,,,,,,,,,,,,,,,,,9223372036854775807,,,,,Sat Jun 27 17:26:49 UTC 2015,,,,,,,"0|i2f513:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,"23/May/15 18:54;busbey;what's the heuristic to use here? exempt src/main/bin? or build a whitelist of kinds of main code that need javac? I guess the latter would work to make sure we rebuild where there are changes to src/main/java or protobuf / thrift specs?","23/May/15 18:55;busbey;maybe we should rename the 'javac' check to 'maven_compile' or some such? I'm thinking of ruby or python assets in a project that still uses maven. Changes to those probably mean we'd need to run tests.","23/May/15 20:05;aw;Yeah, I'm not really sure what to do here to fix this in the immediate term other than either a white list or a black list.  It's clear that src/main is too broad.  I know that for a general solution, HADOOP-11929 probably should replace all of this logic.","27/Jun/15 17:26;aw;I'm going to close this as a dupe of HADOOP-12113 since the logic problem that caused this issue is now replaceable by the projects.  I've opened  HADOOP-12138 to fix the Hadoop-specific logic case.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
test-patch.sh should have an xml plugin,HADOOP-12031,12832559,Test,Resolved,HADOOP,Hadoop Common,software,omalley,Hadoop Common is the common library for Apache Hadoop.,http://hadoop.apache.org/,Major,Implemented,sekikn,aw,aw,25/May/15 18:44,25/Jun/15 01:29,12/Jan/21 11:55,25/Jun/15 01:29,,,,,,,,,,,build,,,,1,newbie,test-patch,HADOOP-11178 demonstrates why there is a need to verify xml files on a patch change.,,aw,busbey,sekikn,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"26/May/15 23:17;sekikn;HADOOP-12031.001.patch;https://issues.apache.org/jira/secure/attachment/12735441/HADOOP-12031.001.patch","26/May/15 23:36;sekikn;HADOOP-12031.002.patch;https://issues.apache.org/jira/secure/attachment/12735458/HADOOP-12031.002.patch","27/May/15 23:43;sekikn;HADOOP-12031.003.patch;https://issues.apache.org/jira/secure/attachment/12735733/HADOOP-12031.003.patch","29/May/15 00:06;sekikn;HADOOP-12031.004.patch;https://issues.apache.org/jira/secure/attachment/12736003/HADOOP-12031.004.patch","29/May/15 21:40;sekikn;HADOOP-12031.005.patch;https://issues.apache.org/jira/secure/attachment/12736247/HADOOP-12031.005.patch",,,,,,,,,,,,,,,,,,,5.0,,,,,,,,,,,,,,,,,,,,2015-05-26 23:17:49.008,,,false,,,,,,,,,,,,,,,,,9223372036854775807,,,,,Fri May 29 22:03:40 UTC 2015,,,,,,,"0|i2f69b:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,"26/May/15 23:17;sekikn;Attaching a patch. One concern is, this plugin depends on Python currently. I assume we can use Python in most build environment, but please advise if there is a more portable and not-so-hard way to validate XML.","26/May/15 23:20;hadoopqa;(!) A patch to test-patch or smart-apply-patch has been detected. 
Re-executing against the patched versions to perform further tests. 
The console is at https://builds.apache.org/job/PreCommit-HADOOP-Build/6832/console in case of problems.","26/May/15 23:21;hadoopqa;\\
\\
| (/) *{color:green}+1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | reexec |   0m  0s | dev-support patch detected. |
| {color:blue}0{color} | pre-patch |   0m  0s | Pre-patch trunk compilation is healthy. |
| {color:blue}0{color} | @author |   0m  0s | Skipping @author checks as test-patch has been patched. |
| {color:green}+1{color} | release audit |   0m 15s | The applied patch does not increase the total number of release audit warnings. |
| {color:green}+1{color} | shellcheck |   0m  4s | There were no new shellcheck (v0.3.3) issues. |
| {color:green}+1{color} | whitespace |   0m  0s | The patch has no lines that end in whitespace. |
| {color:green}+1{color} | whitespace |   0m  0s | The patch has no ill-formed XML file. |
| | |   0m 23s | |
\\
\\
|| Subsystem || Report/Notes ||
| Patch URL | http://issues.apache.org/jira/secure/attachment/12735441/HADOOP-12031.001.patch |
| Optional Tests | shellcheck |
| git revision | trunk / cdbd66b |
| Java | 1.7.0_55 |
| uname | Linux asf902.gq1.ygridcore.net 3.13.0-36-lowlatency #63-Ubuntu SMP PREEMPT Wed Sep 3 21:56:12 UTC 2014 x86_64 x86_64 x86_64 GNU/Linux |
| Console output | https://builds.apache.org/job/PreCommit-HADOOP-Build/6832/console |


This message was automatically generated.","26/May/15 23:36;sekikn;-02:

* remove trailing whitespace
* fix wrong display for subsystem (see above)","26/May/15 23:40;hadoopqa;(!) A patch to test-patch or smart-apply-patch has been detected. 
Re-executing against the patched versions to perform further tests. 
The console is at https://builds.apache.org/job/PreCommit-HADOOP-Build/6833/console in case of problems.","26/May/15 23:41;hadoopqa;\\
\\
| (/) *{color:green}+1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | reexec |   0m  0s | dev-support patch detected. |
| {color:blue}0{color} | pre-patch |   0m  0s | Pre-patch trunk compilation is healthy. |
| {color:blue}0{color} | @author |   0m  0s | Skipping @author checks as test-patch has been patched. |
| {color:green}+1{color} | release audit |   0m 15s | The applied patch does not increase the total number of release audit warnings. |
| {color:green}+1{color} | shellcheck |   0m  4s | There were no new shellcheck (v0.3.3) issues. |
| {color:green}+1{color} | whitespace |   0m  0s | The patch has no lines that end in whitespace. |
| {color:green}+1{color} | XML well-formedness |   0m  0s | The patch has no ill-formed XML file. |
| | |   0m 23s | |
\\
\\
|| Subsystem || Report/Notes ||
| Patch URL | http://issues.apache.org/jira/secure/attachment/12735458/HADOOP-12031.002.patch |
| Optional Tests | shellcheck |
| git revision | trunk / cdbd66b |
| Java | 1.7.0_55 |
| uname | Linux asf902.gq1.ygridcore.net 3.13.0-36-lowlatency #63-Ubuntu SMP PREEMPT Wed Sep 3 21:56:12 UTC 2014 x86_64 x86_64 x86_64 GNU/Linux |
| Console output | https://builds.apache.org/job/PreCommit-HADOOP-Build/6833/console |


This message was automatically generated.","27/May/15 00:44;sekikn;whitespace plugin seems not to be able to detect the trailing whitespace in the first patch at line 33. But I don't know why for now.","27/May/15 05:44;busbey;{quote}
One concern is, this plugin depends on Python currently. I assume we can use Python in most build environment, but please advise if there is a more portable and not-so-hard way to validate XML.
{quote}

Relying on python is problematic. If you stick with it, you'll need to detect and gracefully degrade when the version you need isn't present.

If we're just checking well-formed-ness, how about using xmllint?","27/May/15 06:58;sekikn;Thanks [~busbey]. As you pointed out, I realized that 002.patch does not work on Python 2.6-, because except ... as ... statement is supported from 2.6.1.
So I'm planning:

* If xmllint is available, use it
* If not, try to validate using Python. In that case, use sys.exc_info() instead of except ... as ... statement. It makes the plugin to work on Python at least 2.1+ (including 3.x).
","27/May/15 23:43;sekikn;-03:

* use xmllint rather than python, if available
* make the python code compatible with 2.1+
* rename the variable $j in for loop to $i","28/May/15 00:57;aw;I guess there's nothing we can leverage that ships with the JVM is there?","28/May/15 01:11;hadoopqa;(!) A patch to test-patch or smart-apply-patch has been detected. 
Re-executing against the patched versions to perform further tests. 
The console is at https://builds.apache.org/job/PreCommit-HADOOP-Build/6849/console in case of problems.","28/May/15 01:12;hadoopqa;\\
\\
| (/) *{color:green}+1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | reexec |   0m  0s | dev-support patch detected. |
| {color:blue}0{color} | pre-patch |   0m  0s | Pre-patch trunk compilation is healthy. |
| {color:blue}0{color} | @author |   0m  0s | Skipping @author checks as test-patch has been patched. |
| {color:green}+1{color} | release audit |   0m 22s | The applied patch does not increase the total number of release audit warnings. |
| {color:green}+1{color} | shellcheck |   0m  5s | There were no new shellcheck (v0.3.3) issues. |
| {color:green}+1{color} | whitespace |   0m  0s | The patch has no lines that end in whitespace. |
| {color:green}+1{color} | XML well-formedness |   0m  0s | The patch has no ill-formed XML file. |
| | |   0m 30s | |
\\
\\
|| Subsystem || Report/Notes ||
| Patch URL | http://issues.apache.org/jira/secure/attachment/12735733/HADOOP-12031.003.patch |
| Optional Tests | shellcheck |
| git revision | trunk / 5450413 |
| Java | 1.7.0_55 |
| uname | Linux asf903.gq1.ygridcore.net 3.13.0-36-lowlatency #63-Ubuntu SMP PREEMPT Wed Sep 3 21:56:12 UTC 2014 x86_64 x86_64 x86_64 GNU/Linux |
| Console output | https://builds.apache.org/job/PreCommit-HADOOP-Build/6849/console |


This message was automatically generated.","28/May/15 03:42;aw;OK, definitely a bug here.  It looks like xmlwellformed_postapply isn't checking to see if it actually needs to execute via verify_needed_test.","28/May/15 03:51;aw;Also: XML well-formedness is *really* long, especially in the JIRA table.  Can we abbreviate that and the test name to be just xml? ","28/May/15 04:43;busbey;{quote}
I guess there's nothing we can leverage that ships with the JVM is there?
{quote}

interesting suggestion. there isn't any cli tool that comes out of the box AFAICT.

However, we could write a simple utility to do this using [DocumentBuilder|http://docs.oracle.com/javase/7/docs/api/javax/xml/parsers/DocumentBuilder.html] for well-formedness and when a Schema is specified [the validation package|http://docs.oracle.com/javase/7/docs/api/javax/xml/validation/package-summary.html] for more specifics. Looking at the docs, I think we could make it work for Java 5+.","28/May/15 08:21;sekikn;Thank you very much, [~aw] [~busbey]. Thanks to your comments, I realize we can use Java's scripting feature to make the plugin more simple and platform independent. I tried this idea on OpenJDK 1.6 and 1.7, and it seems to work fine.

{code}
# cat a.xml
<configuration/>
# cat b.xml
<configuration>
# /usr/lib/jvm/java-1.6.0-openjdk-1.6.0.35.x86_64/bin/jrunscript -e 'XMLDocument(arguments[0])' a.xml
# echo $?
0
# /usr/lib/jvm/java-1.6.0-openjdk-1.6.0.35.x86_64/bin/jrunscript -e 'XMLDocument(arguments[0])' b.xml
[Fatal Error] b.xml:2:1: XML document structures must start and end within the same entity.
script error: sun.org.mozilla.javascript.WrappedException: Wrapped org.xml.sax.SAXParseException; systemId: file:///tmp/b.xml; lineNumber: 2; columnNumber: 1; XML document structures must start and end within the same entity. (<system-init>#714) in <system-init> at line number 714
# echo $?
10
# /usr/lib/jvm/java-1.7.0-openjdk-1.7.0.79.x86_64/bin/jrunscript -e 'XMLDocument(arguments[0])' a.xml
# echo $?
0
# /usr/lib/jvm/java-1.7.0-openjdk-1.7.0.79.x86_64/bin/jrunscript -e 'XMLDocument(arguments[0])' b.xml
[Fatal Error] b.xml:2:1: XML document structures must start and end within the same entity.
script error: sun.org.mozilla.javascript.WrappedException: Wrapped org.xml.sax.SAXParseException; systemId: file:///tmp/b.xml; lineNumber: 2; columnNumber: 1; XML document structures must start and end within the same entity. (<system-init>#714) in <system-init> at line number 714
# echo $?
10
{code}

Since Java 8 replaced jrunscript with jjs, I must do some work such as version detection, but it is not difficult.

Other comments also make sense to me. I'll fix them.","29/May/15 00:06;sekikn;-04 (wip):

* instead of xmllint and python, use jvm feature to confirm that xml is well-formed
* cover other Allen's comments

-TODO:

* pre-check for executable's existence
* test on Java8 environment (I tested it only on Java7 for now)","29/May/15 01:04;hadoopqa;(!) A patch to test-patch or smart-apply-patch has been detected. 
Re-executing against the patched versions to perform further tests. 
The console is at https://builds.apache.org/job/PreCommit-HADOOP-Build/6862/console in case of problems.","29/May/15 01:05;hadoopqa;\\
\\
| (/) *{color:green}+1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | reexec |   0m  0s | dev-support patch detected. |
| {color:blue}0{color} | pre-patch |   0m  0s | Pre-patch trunk compilation is healthy. |
| {color:blue}0{color} | @author |   0m  0s | Skipping @author checks as test-patch has been patched. |
| {color:green}+1{color} | release audit |   0m 14s | The applied patch does not increase the total number of release audit warnings. |
| {color:green}+1{color} | shellcheck |   0m  5s | There were no new shellcheck (v0.3.3) issues. |
| {color:green}+1{color} | whitespace |   0m  0s | The patch has no lines that end in whitespace. |
| | |   0m 22s | |
\\
\\
|| Subsystem || Report/Notes ||
| Patch URL | http://issues.apache.org/jira/secure/attachment/12736003/HADOOP-12031.004.patch |
| Optional Tests | shellcheck |
| git revision | trunk / 788bfa0 |
| Java | 1.7.0_55 |
| uname | Linux asf909.gq1.ygridcore.net 3.13.0-36-lowlatency #63-Ubuntu SMP PREEMPT Wed Sep 3 21:56:12 UTC 2014 x86_64 x86_64 x86_64 GNU/Linux |
| Console output | https://builds.apache.org/job/PreCommit-HADOOP-Build/6862/console |


This message was automatically generated.","29/May/15 21:40;sekikn;I made a mistake. jrunscript is still shipped with Java8 (though the internal engine is replaced with Nashorn), so version detection is unnecessary.

-05:

* always use jrunscript to simplify the code
* pre-check for the executable's existence
* tested on both Java 7 and 8 

I think it's ready for commit.","29/May/15 22:03;hadoopqa;(!) A patch to test-patch or smart-apply-patch has been detected. 
Re-executing against the patched versions to perform further tests. 
The console is at https://builds.apache.org/job/PreCommit-HADOOP-Build/6871/console in case of problems.","29/May/15 22:03;hadoopqa;\\
\\
| (/) *{color:green}+1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | reexec |   0m  0s | dev-support patch detected. |
| {color:blue}0{color} | pre-patch |   0m  0s | Pre-patch trunk compilation is healthy. |
| {color:blue}0{color} | @author |   0m  0s | Skipping @author checks as test-patch has been patched. |
| {color:green}+1{color} | release audit |   0m 15s | The applied patch does not increase the total number of release audit warnings. |
| {color:green}+1{color} | shellcheck |   0m  5s | There were no new shellcheck (v0.3.3) issues. |
| {color:green}+1{color} | whitespace |   0m  0s | The patch has no lines that end in whitespace. |
| | |   0m 23s | |
\\
\\
|| Subsystem || Report/Notes ||
| Patch URL | http://issues.apache.org/jira/secure/attachment/12736247/HADOOP-12031.005.patch |
| Optional Tests | shellcheck |
| git revision | trunk / 7673d4f |
| Java | 1.7.0_55 |
| uname | Linux asf900.gq1.ygridcore.net 3.13.0-36-lowlatency #63-Ubuntu SMP PREEMPT Wed Sep 3 21:56:12 UTC 2014 x86_64 x86_64 x86_64 GNU/Linux |
| Console output | https://builds.apache.org/job/PreCommit-HADOOP-Build/6871/console |


This message was automatically generated.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
test-patch.sh should provide a way to override the default dockerfile,HADOOP-12024,12832357,Test,Resolved,HADOOP,Hadoop Common,software,omalley,Hadoop Common is the common library for Apache Hadoop.,http://hadoop.apache.org/,Major,Won't Fix,,aw,aw,23/May/15 15:49,02/Jun/15 02:01,12/Jan/21 11:55,02/Jun/15 02:01,,,,,,,,,,,,,,,0,,,"Followup from HADOOP-11933, provide a way to override the Dockerfile on the command line.",,aw,raviprak,sekikn,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,HADOOP-11933,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,9223372036854775807,,,,,2015-05-23 15:49:44.0,,,,,,,"0|i2f51b:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"test-patch.sh needs per-project, per-branch maven repos",HADOOP-12025,12832358,Test,Resolved,HADOOP,Hadoop Common,software,omalley,Hadoop Common is the common library for Apache Hadoop.,http://hadoop.apache.org/,Major,Won't Fix,,aw,aw,23/May/15 15:50,02/Jun/15 02:01,12/Jan/21 11:55,02/Jun/15 02:01,,,,,,,,,,,,,,,0,,,Follow-up from HADOOP-11933.,,aw,busbey,sekikn,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,HADOOP-11933,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,2015-05-23 18:56:50.314,,,false,,,,,,,,,,,,,,,,,9223372036854775807,,,,,Sat May 23 20:38:44 UTC 2015,,,,,,,"0|i2f51j:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,"23/May/15 18:56;busbey;is there a reason we can't share a single maven repo and just give coordinates for what to blow away between runs?","23/May/15 19:56;aw;Maven, as a caching technology, is fundamentally broken.  It provides zero locking.  Which means that multiple maven repo operations being performed simultaneously will stomp all over each other.  So matter what tricks one can play with the pom.xml, artifact naming, etc, it just takes one job doing a dependency:purge-local-repository or replacing a jar while another maven operation is running a unit tests to make everything go haywire. 

So any coordination or external locking to prevent this from happening would have be done for every single project that runs on the same set of hosts. 

It's just easier to use docker to virtually mount different directories to prevent this from happening.  So while there is still a risk, it's significantly reduced.","23/May/15 20:38;busbey;Sounds good. The only other thing I can think of would be if we got a Jenkins plugin to handle managing a pool of caches for a job. But if one doesn't already exist it's not worth doing right now.

FWIW, the brief check I did of other solutions to this just ensure there's a fresh repo for every test run.","23/May/15 20:38;busbey;s/fresh/unique",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
run test-patch.sh in a docker container under Jenkins,HADOOP-11933,12827852,Test,Resolved,HADOOP,Hadoop Common,software,omalley,Hadoop Common is the common library for Apache Hadoop.,http://hadoop.apache.org/,Major,Won't Fix,aw,aw,aw,06/May/15 23:02,02/Jun/15 02:01,12/Jan/21 11:55,02/Jun/15 02:00,,,,,,,,,,,,,,,3,,,"because of how hard it is to control the content of the Jenkins environment, it would be beneficial to run it in a docker container so that we can have tight control of the environment",,apurtell,arp,aw,busbey,cnauroth,hsaputra,kasha,ndimiduk,nielsbasjes,ramtinb,raviprak,sekikn,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,HBASE-13672,INFRA-10333,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,HADOOP-12000,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,2015-05-07 18:26:25.151,,,false,,,,,,,,,,,,,,,,,9223372036854775807,,,,,Tue Jun 02 02:00:06 UTC 2015,,,,,,,"0|i2ee7j:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,"07/May/15 05:05;aw;I've got a patch I'm testing, but it appears that the docker registry has dropped the image we were pulling from the public repo.  So I need to fix that now too.  Grr.","07/May/15 17:53;aw;-00:
* initial patch.
* Uses --docker flag to trigger
* Does not use a shared m2 cache
* also fixes the current docker dev build setup (i'll pull this out in a separate jira here in a bit)
* re-arranges some things in test-patch.sh to make certain debugging cases easier
","07/May/15 18:02;aw;Oh, FYI: I haven't tested this under Jenkins yet.  The JIRA cli stuff is installed as part of the Docker image, but not wired in yet.","07/May/15 18:26;hadoopqa;(!) A patch to test-patch or smart-apply-patch has been detected. 
Re-executing against the patched versions to perform further tests. 
The console is at https://builds.apache.org/job/PreCommit-HADOOP-Build/6523/console in case of problems.","07/May/15 18:26;hadoopqa;\\
\\
| (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | reexec |   0m  0s | dev-support patch detected. |
| {color:blue}0{color} | pre-patch |   0m  0s | Pre-patch trunk compilation is healthy. |
| {color:blue}0{color} | @author |   0m  0s | Skipping @author checks as test-patch has been patched. |
| {color:red}-1{color} | release audit |   0m  8s | The applied patch generated 1 release audit warnings. |
| {color:blue}0{color} | shellcheck |   0m  8s | Shellcheck was not available. |
| {color:green}+1{color} | whitespace |   0m  0s | The patch has no lines that end in whitespace. |
| | |   0m 11s | |
\\
\\
|| Subsystem || Report/Notes ||
| Java | 1.7.0_55 |
| uname | Linux asf907.gq1.ygridcore.net 3.13.0-36-lowlatency #63-Ubuntu SMP PREEMPT Wed Sep 3 21:56:12 UTC 2014 x86_64 x86_64 x86_64 GNU/Linux |
| Patch URL | http://issues.apache.org/jira/secure/attachment/12731233/HADOOP-11933.00.patch |
| Optional Tests | shellcheck |
| git revision | trunk / daf3e4e |
| Release Audit | https://builds.apache.org/job/PreCommit-HADOOP-Build/6523/artifact/patchprocess/patchReleaseAuditProblems.txt |
| Console output | https://builds.apache.org/job/PreCommit-HADOOP-Build/6523/console |


This message was automatically generated.","07/May/15 18:59;aw;[~owen.omalley] suggested using COW to handle the .m2 dir.  Doing some digging seems to indicate this is a much desired feature of docker, but isn't really well implemented outside of the image file.  (... and building an image with all of .m2 doesn't sound like a good idea. lol)

Other suggestions are to use overlayfs from within the client so I might try that.","08/May/15 03:27;aw;-01:
* jira cli command is wired up.
* lots of subtle bug fixes
* removed *some* of the assumptions in the code, but there is still a pretty tight binding on a few things
* fixed license file problems
* better support for removing old images
* now sudo -n all docker commands, which I think will be required by jenkins
* fixed the perm problems, so now .m2 is imported from host (overlayfs wasn't working for me)
* protect docker mode from when the patchprocess dir isn't inside the basedir
* prevent jira msg firing off if the jira password isn't set
","08/May/15 18:45;busbey;/cc [~dimaspivak]","11/May/15 22:20;aw;I've got a newer version of this patch I'm currently testing on Jenkins in my throw-away JIRA.  Once it works sufficiently, I'll upload the new version here.  (The throwaway version forces the system to use Docker during re-exec.  That's obviously bad for the real patch.)","12/May/15 03:35;aw;-02:
* rebased
* Work around the incredibly stupid $USER setting on the jenkins account
* Remove sudo since jenkins as the ability to execute it without it
* re-arrange the directories a bit so we have a Well Known Location in the container
* Try to genericize it a bit more, including passing in the project name
* Add an entry to the table to show when we are running in a container for the test run
* Pass in the build url on the command line
* clean up all the new shellcheck errors generated by the newer shellcheck version this patch uses
* --docker => turn on docker support
* --dockermode => running in a docker container
* re-arrange the patch dir bits so we can test for relational location first
* move close_jira_footer to open_jira_footer so that those entries are filled in first

*NOTE*: The HADOOP precommit job has been modified to have the --docker flag for test-patch.sh to enable testing of this patch in a docker container. :)","12/May/15 03:40;hadoopqa;(!) A patch to test-patch or smart-apply-patch has been detected. 
Re-executing against the patched versions to perform further tests. 
The console is at https://builds.apache.org/job/PreCommit-HADOOP-Build/6620/console in case of problems.","12/May/15 03:41;hadoopqa;\\
\\
| (/) *{color:green}+1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | reexec |   0m  0s | dev-support patch detected. |
| {color:blue}0{color} | pre-patch |   0m  0s | Pre-patch trunk compilation is healthy. |
| {color:blue}0{color} | @author |   0m  0s | Skipping @author checks as test-patch has been patched. |
| {color:green}+1{color} | release audit |   0m 16s | The applied patch does not increase the total number of release audit warnings. |
| {color:green}+1{color} | shellcheck |   0m  9s | There were no new shellcheck (v0.3.7) issues. |
| {color:green}+1{color} | whitespace |   0m  0s | The patch has no lines that end in whitespace. |
| | |   0m 28s | |
\\
\\
|| Subsystem || Report/Notes ||
| Java | 1.7.0_80 |
| uname | Linux 29d8e3040b6d 3.13.0-36-lowlatency #63-Ubuntu SMP PREEMPT Wed Sep 3 21:56:12 UTC 2014 x86_64 x86_64 x86_64 GNU/Linux |
| Docker | Enabled |
| Patch URL | http://issues.apache.org/jira/secure/attachment/12732117/HADOOP-11933.02.patch |
| Optional Tests | shellcheck |
| git revision | trunk / 3d28611 |
| Console output | https://builds.apache.org/job/PreCommit-HADOOP-Build/6620/console |


This message was automatically generated.","12/May/15 03:52;aw;FWIW, the only concern I have right now with this code is if it is doing the proper thing to clean up old, unused containers in a safe way.  ","12/May/15 04:25;aw;(To expand on that, for me, it generally keeps 2 images active after a run, but it would be good to have someone confirm that independently.)","12/May/15 16:36;busbey;what does one need to check? I guess a login on the jenkins boxes?","12/May/15 17:15;aw;-03:
* Rewrote the image management bits to be much more reliable, thorough, and complete.
* Added the docker version to the footer
* shared maven cache now configurable from command line
* NOTE: this will cause *ONE* shellcheck 0.3.7 error that is a false positive.  There is no way to fix this without other weird things happen.  This clearly a bug in shellcheck.","12/May/15 17:32;hadoopqa;(!) A patch to test-patch or smart-apply-patch has been detected. 
Re-executing against the patched versions to perform further tests. 
The console is at https://builds.apache.org/job/PreCommit-HADOOP-Build/6669/console in case of problems.","12/May/15 17:52;aw;bq. what does one need to check? I guess a login on the jenkins boxes?

Either that or run it locally.  But at this point, I've determined that no one is taking care to clean up images on the jenkins hosts themselves.  A lot of that is Docker's image management, because it certainly doesn't help.  The new code is waaaaaay better about cleaning out dead/broken build bits.  I'm not that worried about it anymore.  

I'm pretty much ready to commit.  I don't think there will be any fallout, but any time you mess with this stuff, there always is... lol","12/May/15 18:53;aw;dang it. wrong window.  I'll re-run.","12/May/15 18:58;hadoopqa;(!) A patch to test-patch or smart-apply-patch has been detected. 
Re-executing against the patched versions to perform further tests. 
The console is at https://builds.apache.org/job/PreCommit-HADOOP-Build/6672/console in case of problems.","12/May/15 18:59;hadoopqa;\\
\\
| (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | reexec |   0m  0s | dev-support patch detected. |
| {color:blue}0{color} | pre-patch |   0m  0s | Pre-patch trunk compilation is healthy. |
| {color:blue}0{color} | @author |   0m  0s | Skipping @author checks as test-patch has been patched. |
| {color:green}+1{color} | release audit |   0m 16s | The applied patch does not increase the total number of release audit warnings. |
| {color:red}-1{color} | shellcheck |   0m  9s | The applied patch generated  1 new shellcheck (v0.3.7) issues (total was 60, now 48). |
| {color:green}+1{color} | whitespace |   0m  0s | The patch has no lines that end in whitespace. |
| | |   0m 29s | |
\\
\\
|| Subsystem || Report/Notes ||
| Java | 1.7.0_80 |
| uname | Linux b7b7e7188d1c 3.13.0-36-lowlatency #63-Ubuntu SMP PREEMPT Wed Sep 3 21:56:12 UTC 2014 x86_64 x86_64 x86_64 GNU/Linux |
| Docker | C=1.6.1/S=1.6.1 |
| Patch URL | http://issues.apache.org/jira/secure/attachment/12732289/HADOOP-11933.03.patch |
| Optional Tests | shellcheck |
| git revision | trunk / fe0df59 |
| shellcheck | https://builds.apache.org/job/PreCommit-HADOOP-Build/6672/artifact/patchprocess/diffpatchshellcheck.txt |
| Console output | https://builds.apache.org/job/PreCommit-HADOOP-Build/6672/console |


This message was automatically generated.","12/May/15 19:26;aw;As pointed out above, the shellcheck error is expected. ","13/May/15 23:55;aw;So there are a few things that could be done to improve this patch on the functionality side.  The question is: do I push them to the side while I wait for someone to review and commit or should I update this patch?","14/May/15 16:01;busbey;Is there a ticket ref for hte shellcheck bug?

If the improvements aren't critical, I'd say push them to a follow on.","14/May/15 16:05;aw;bq. Is there a ticket ref for hte shellcheck bug?

Not yet.  I want to try to build an easier reproducible test case before I send it to them.

bq. If the improvements aren't critical, I'd say push them to a follow on.

One of them I had in mind was removing the requirement of the patchprocess directory to be relative to the git checkout.  So you might consider that one critical to the nifi use case. ;)","14/May/15 16:12;busbey;{quote}
bq. If the improvements aren't critical, I'd say push them to a follow on.
One of them I had in mind was removing the requirement of the patchprocess directory to be relative to the git checkout. So you might consider that one critical to the nifi use case. 
{quote}

I'd like that, but I can just have the nifi tester not use docker for now, right? the docker stuff is more needed for HBase ATM (HBASE-12497), but even in that case it just enables new things I want rather then current functionality in the project's forked precommit tester.

I think HADOOP-11929 is the only blocker for Nifi officially starting to use things.","14/May/15 16:26;aw;As I suspected, I was able to greatly simplify the test case.  Bug filed: https://github.com/koalaman/shellcheck/issues/375

","20/May/15 04:16;aw;-04:
* jdk 7 and 8 are now in the image
* maven opts moved out of dockerfile and into the test-patch launcher
* --java-home can now control the JVM used in the docker image
* --reexec mode now works properly
* parameterized test-patch-docker.sh
* docker commands now honor --debug
* images now stamped with the last git commit EXCEPT if test-patch, etc are patched.  then it uses a date.  as a result...
* much more aggressive image cleaning in jenkins mode
* fixed the shellcheck edge case error
* after many experiments, we always import the maven repo.  we can always revisit this, but for the most part, there just isn't anyway to win here without a lot of pain and/or better organization amongst all potential jenkins users
* much cleanup of hard-coded paths. in fact...
* now support docker mode if patch-dir isn't relative
* now report the docker tagged image name in the footer
* some general function re-arrangement to try and speed up when we can switch to docker mode

It isn't in this patch, but with a bit more work, it should be possible to run the nightlies in this environment as well.  Theoretically, it should be a lot easier to do that work now.","20/May/15 04:20;hadoopqa;(!) A patch to test-patch or smart-apply-patch has been detected. 
Re-executing against the patched versions to perform further tests. 
The console is at https://builds.apache.org/job/PreCommit-HADOOP-Build/6782/console in case of problems.","20/May/15 04:21;hadoopqa;\\
\\
| (/) *{color:green}+1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | reexec |   0m  0s | dev-support patch detected. |
| {color:blue}0{color} | pre-patch |   0m  0s | Pre-patch trunk compilation is healthy. |
| {color:blue}0{color} | @author |   0m  0s | Skipping @author checks as test-patch has been patched. |
| {color:green}+1{color} | release audit |   0m 15s | The applied patch does not increase the total number of release audit warnings. |
| {color:green}+1{color} | shellcheck |   0m  9s | There were no new shellcheck (v0.3.7) issues. |
| {color:green}+1{color} | whitespace |   0m  0s | The patch has no lines that end in whitespace. |
| | |   0m 28s | |
\\
\\
|| Subsystem || Report/Notes ||
| Java | 1.7.0_80 |
| uname | Linux c52e6f61da74 3.13.0-36-lowlatency #63-Ubuntu SMP PREEMPT Wed Sep 3 21:56:12 UTC 2014 x86_64 x86_64 x86_64 GNU/Linux |
| Docker | C=1.6.1/S=1.6.1/I:test-patch-base-hadoop-date2015-05-20-04 |
| Patch URL | http://issues.apache.org/jira/secure/attachment/12734058/HADOOP-11933.04.patch |
| git revision | trunk / ce53c8e |
| Optional Tests | shellcheck |
| Console output | https://builds.apache.org/job/PreCommit-HADOOP-Build/6782/console |


This message was automatically generated.","20/May/15 15:10;busbey;{quote}
+      --java-home)
+        JAVA_HOME=${i#*=}
{quote}

Doesn't this need to do the --java-home=*) thing that the other options do?","20/May/15 15:20;busbey;{code}
+function cleanup_apache_jenkins_docker
+{
+  # On Jenkins, do some cleanup of old stuff since
+  # no body else seems to be
+
{code}

{code}
+  # make a base image, if it isn't available
+  dockercmd build -t ""${baseimagename}"" ""${BINDIR}""
+
+  # using the base image, make one that is patch specific
{code}

Can we add some timing in here so we know how much time patch-tester is spending on docker maintenance?","20/May/15 15:25;busbey;{code}
+      --build-url=*)
+        BUILD_URL=${i#*=}
+      ;;
{code}

no help for this option?","20/May/15 15:48;aw;Woops, yes, I must have missed that in my rebase.","20/May/15 15:52;aw;Technically, it's meant to be private for test-patch since the API for Jenkins to set it was always via an env var.  But documenting it wouldn't be bad I guess in case we want to switch Jenkins over to be parameterized too.","20/May/15 15:53;aw;Good idea.  Do we want a global time or a per-step time?  Global is certainly going to be easier.","20/May/15 18:03;busbey;If the two steps are ""time spent cleaning up"" and ""time spent getting to a build-specific image"", then per step. I don't think how long each of the implementation bits for those two categories are useful for now.","20/May/15 18:22;aw;I wired up timing and learned the following:

* docker image clean up takes less than a second unless there are a lot in play.

* docker image creation only takes up more than a minute if the cache is completely empty.

So I'm going to return one time for the whole docker launch bit, since the cleanup is miniscule. ","20/May/15 19:19;aw;-05:
* Cover Sean's feedback
* rexec time is now accurate, using the same trick
","20/May/15 19:49;hadoopqa;(!) A patch to test-patch or smart-apply-patch has been detected. 
Re-executing against the patched versions to perform further tests. 
The console is at https://builds.apache.org/job/PreCommit-HADOOP-Build/6791/console in case of problems.","20/May/15 19:50;hadoopqa;\\
\\
| (/) *{color:green}+1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | reexec |   0m  0s | dev-support patch detected. |
| {color:blue}0{color} | docker |   0m  4s | docker mode |
| {color:blue}0{color} | pre-patch |   0m  0s | Pre-patch trunk compilation is healthy. |
| {color:blue}0{color} | @author |   0m  0s | Skipping @author checks as test-patch has been patched. |
| {color:green}+1{color} | release audit |   0m 17s | The applied patch does not increase the total number of release audit warnings. |
| {color:green}+1{color} | shellcheck |   0m  9s | There were no new shellcheck (v0.3.7) issues. |
| {color:green}+1{color} | whitespace |   0m  1s | The patch has no lines that end in whitespace. |
| | |   0m 39s | |
\\
\\
|| Subsystem || Report/Notes ||
| Java | 1.7.0_80 |
| uname | Linux 6445bdeb5c34 3.13.0-36-lowlatency #63-Ubuntu SMP PREEMPT Wed Sep 3 21:56:12 UTC 2014 x86_64 x86_64 x86_64 GNU/Linux |
| Docker | C=1.6.1/S=1.6.1/I:test-patch-base-hadoop-date2015-05-20-19 |
| Patch URL | http://issues.apache.org/jira/secure/attachment/12734203/HADOOP-11933.05.patch |
| git revision | trunk / 4aa730c |
| Optional Tests | shellcheck |
| Console output | https://builds.apache.org/job/PreCommit-HADOOP-Build/6791/console |


This message was automatically generated.","21/May/15 18:32;busbey;{code}
+
+""${tpbin}"" \
+   --dockermode ${TESTPATCHMODE} \
+   --basedir=""${BASEDIR}"" \
{code}

{code}
+      --dockermode)
+        DOCKERMODE=true
+      ;;
{code}

How do these two work together? from what I can tell, the parsing says dockermode takes no args, but it looks like we're invoking it with one (and no =).","21/May/15 18:52;aw;I'm playing shell games. :D

--dockermode is a standalone option that says ""hey, we were invoked underneath docker, don't spawn another one"" TESTPATCHMODE has all of the user passed parameters.  We then append --basedir, etc to *override* the values in TESTPATCHMODE.

So this code is adding --dockermode to the parameter list.  If you want, I can move --dockermode to be after TESTPATCHMODE if it makes it cleaner.  Or maybe just a comment here, warning of the black magic in the works.","21/May/15 19:02;busbey;The note here is enough I think. I should have done more work to trace back what ends up in TESTPATCHMODE. If it comes up again we can always add a comment.

+1 lgtm.","21/May/15 21:49;raviprak;Thanks for all the work Allen! I love the idea of reproducible builds.

One of my prime concerns with this patch is security. There is horribly little in the way of security while pulling down images. Can we please atleast pass in the image / dockerfile as a command line option? Also we are curling and wgetting http instead of https. Could you please also write documentation for several functions missing it?
","21/May/15 23:03;aw;bq. There is horribly little in the way of security while pulling down images. Can we please atleast pass in the image / dockerfile as a command line option? 

I was originally going to do this but decided to do it as a follow-on JIRA at a later date.  The key problem is that we need all of the test-patch-docker bits in the same directory. We need to essentially copy the standard bits and then the provided file to the processing dir then launch docker against that.  That requires quite a bit of testing esp with --reexec mode.  It's also worth noting that using this on the Jenkins hosts prevents the ability to actually precommit test the test-patch-docker bits.   So, it's on my to-do list but a lower priority vs. everything else.  I really wanted to get this in without this functionality to unblock other, higher priority items.

bq. Also we are curling and wgetting http instead of https. 

Good catch.  I'll update the dev Dockerfile as well.

bq. Could you please also write documentation for several functions missing it?

Sure. Just be aware that they are private to the test-patch-docker script.","22/May/15 00:34;aw;-06:
* [~raviprak]'s issues, except custom dockerfile support","22/May/15 00:39;hadoopqa;(!) A patch to test-patch or smart-apply-patch has been detected. 
Re-executing against the patched versions to perform further tests. 
The console is at https://builds.apache.org/job/PreCommit-HADOOP-Build/6799/console in case of problems.","22/May/15 00:45;hadoopqa;\\
\\
| (/) *{color:green}+1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | reexec |   0m  0s | dev-support patch detected. |
| {color:blue}0{color} | docker |   5m 55s | docker mode |
| {color:blue}0{color} | pre-patch |   0m  0s | Pre-patch trunk compilation is healthy. |
| {color:blue}0{color} | @author |   0m  0s | Skipping @author checks as test-patch has been patched. |
| {color:green}+1{color} | release audit |   0m 18s | The applied patch does not increase the total number of release audit warnings. |
| {color:green}+1{color} | shellcheck |   0m  8s | There were no new shellcheck (v0.3.7) issues. |
| {color:green}+1{color} | whitespace |   0m  1s | The patch has no lines that end in whitespace. |
| | |   6m 32s | |
\\
\\
|| Subsystem || Report/Notes ||
| Java | 1.7.0_80 |
| uname | Linux 53c5cb7b3495 3.13.0-36-lowlatency #63-Ubuntu SMP PREEMPT Wed Sep 3 21:56:12 UTC 2014 x86_64 x86_64 x86_64 GNU/Linux |
| Docker | C=1.6.1/S=1.6.1/I:test-patch-base-hadoop-date2015-05-22-00 |
| Patch URL | http://issues.apache.org/jira/secure/attachment/12734706/HADOOP-11933.06.patch |
| git revision | trunk / 53fafcf |
| Optional Tests | shellcheck |
| Console output | https://builds.apache.org/job/PreCommit-HADOOP-Build/6799/console |


This message was automatically generated.","22/May/15 01:06;aw;bq.  	docker 	5m 55s 	docker mode 

:D","28/May/15 20:34;busbey;Bump. Everything look good now [~raviprak]?","29/May/15 01:49;aw;-07:
* rebase","29/May/15 02:37;hadoopqa;(!) A patch to test-patch or smart-apply-patch has been detected. 
Re-executing against the patched versions to perform further tests. 
The console is at https://builds.apache.org/job/PreCommit-HADOOP-Build/6865/console in case of problems.","29/May/15 02:44;hadoopqa;\\
\\
| (/) *{color:green}+1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | reexec |   0m  0s | dev-support patch detected. |
| {color:blue}0{color} | docker |   6m 13s | docker mode |
| {color:blue}0{color} | pre-patch |   0m  0s | Pre-patch trunk compilation is healthy. |
| {color:blue}0{color} | @author |   0m  0s | Skipping @author checks as test-patch has been patched. |
| {color:green}+1{color} | release audit |   0m 18s | The applied patch does not increase the total number of release audit warnings. |
| {color:green}+1{color} | shellcheck |   0m 10s | There were no new shellcheck (v0.3.7) issues. |
| {color:green}+1{color} | whitespace |   0m  0s | The patch has no lines that end in whitespace. |
| | |   6m 50s | |
\\
\\
|| Subsystem || Report/Notes ||
| Java | 1.7.0_80 |
| uname | Linux 4950d66f8708 3.13.0-36-lowlatency #63-Ubuntu SMP PREEMPT Wed Sep 3 21:56:12 UTC 2014 x86_64 x86_64 x86_64 GNU/Linux |
| Docker | C=1.6.1/S=1.6.1/I:test-patch-base-hadoop-date2015-05-29-02 |
| Patch URL | http://issues.apache.org/jira/secure/attachment/12736020/HADOOP-11933.07.patch |
| git revision | trunk / d725dd8 |
| Optional Tests | shellcheck |
| Console output | https://builds.apache.org/job/PreCommit-HADOOP-Build/6865/console |


This message was automatically generated.","29/May/15 21:25;raviprak;I am a 0 on this change. I'd be a +1 with https://issues.apache.org/jira/browse/HADOOP-12024 . https://titanous.com/posts/docker-insecurity (although a while ago) has spooked me enough to be careful. I'd request another pair of eyes.","01/Jun/15 18:29;cnauroth;Hi [~aw].  How do the results look from {{mvn test}} runs within the Docker container?  The last time I tried, the test runs weren't reliable enough to use for pre-commit.  I was using boot2docker on Mac though, which has known performance limitations, so that could have been the entire problem.","01/Jun/15 18:37;aw;On Linux, significantly better with the test runs I did a month or whatever ago. ","01/Jun/15 18:45;cnauroth;Great, thanks!

In that case, I think I'm going to pause work on HADOOP-11984 (concurrent JUnit processes) until this one gets in.  My sense is that this one is closer to getting committed.  I'm still playing whack-a-mole on a few tests in HADOOP-11984.

I'll put this into my review queue.  If someone else beats me to it on the +1 though, then please feel free to commit.","02/Jun/15 02:00;aw;Closing as won't fix.  I'm going to stop work on test-patch in hadoop.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Ability to retrigger Hudson QA bot without re-uploading patch,HADOOP-7107,12495610,Test,Resolved,HADOOP,Hadoop Common,software,omalley,Hadoop Common is the common library for Apache Hadoop.,http://hadoop.apache.org/,Major,Implemented,,tlipcon,tlipcon,14/Jan/11 18:03,26/Apr/15 01:12,12/Jan/21 11:55,26/Apr/15 01:12,,,,,,,,,,,test,,,,0,,,"Currently to retrigger the test-patch bot you have to upload a new patch. This doesn't work well for a couple cases:
- sometimes a build fails due to issues on a build machine (eg all tests timed out) and you want to give it another go
- sometimes a test sits in ""patch available"" state for a couple weeks and it would be good to re-verify the patch before committing

Committers can retrigger from the Hudson UI, but we should have something that any contributor can use. I would suggest a magic string to put in a comment (eg ""@hudson.build"") which the script would watch for and trigger on",,atm,aw,cutting,Fan04290,jpallas,tlipcon,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,2015-04-26 01:12:53.803,,,false,,,,,,,,,,,,,,,,,127525,,,,,Sun Apr 26 01:12:53 UTC 2015,,,,,,,"0|i0hy0v:",102774,,,,,,,,,,,,,,,,,,,,,,,"26/Apr/15 01:12;aw;Cancel+submit pair usually works. Closing as implemented.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Fix SymlinkBaseTest#testCreateLinkUsingPartQualPath2,HADOOP-11432,12762754,Test,Closed,HADOOP,Hadoop Common,software,omalley,Hadoop Common is the common library for Apache Hadoop.,http://hadoop.apache.org/,Major,Fixed,xieliang007,xieliang007,xieliang007,19/Dec/14 03:34,10/Apr/15 20:04,12/Jan/21 11:55,31/Jan/15 03:00,2.7.0,,,,2.7.0,,,,,,fs,,,,0,,,"seems it's a regression from HADOOP-11409, but weird to me it that why this testing could pass by QA robot at that jira.  it failed always in my dev box now w/o the change:)",,hudson,jira.shegalov,xieliang007,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"19/Dec/14 03:37;xieliang007;HADOOP-11432-001.txt;https://issues.apache.org/jira/secure/attachment/12688233/HADOOP-11432-001.txt","07/Jan/15 06:13;xieliang007;HADOOP-11432-002.txt;https://issues.apache.org/jira/secure/attachment/12690500/HADOOP-11432-002.txt","27/Jan/15 03:35;xieliang007;HADOOP-11432-003.txt;https://issues.apache.org/jira/secure/attachment/12694697/HADOOP-11432-003.txt",,,,,,,,,,,,,,,,,,,,,3.0,,,,,,,,,,,,,,,,,,,,2014-12-19 04:55:06.635,,,false,,,,,,,,,,,,,,,,,9223372036854775807,Reviewed,,,,Sat Jan 31 15:22:18 UTC 2015,,,,,,,"0|i23ltb:",9223372036854775807,,,,,,,,,,,,,2.7.0,,,,,,,,,,"19/Dec/14 03:37;xieliang007;[~jlowe], [~jira.shegalov], could you take a look at it? thanks!

here is the related code:
{code}
commit d6446b274c5ebdcc2c1c154f524eb2d0274689bf
Author: Gera Shegalov <gera@apache.org>
Date:   Mon Dec 15 15:56:35 2014 -0800

    HADOOP-11409.002.patch

diff --git a/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/AbstractFileSystem.java b/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/AbstractFileSystem.java
index a9a19cd..f8ae27b 100644
--- a/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/AbstractFileSystem.java
+++ b/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/AbstractFileSystem.java
....
-      throw new UnsupportedFileSystemException(
-          ""No AbstractFileSystem for scheme: "" + uri.getScheme());
+      throw new UnsupportedFileSystemException(String.format(
+          ""%s=null: No AbstractFileSystem configured for scheme: %s"",
+          fsImplConf, uri.getScheme()));
{code}","19/Dec/14 04:55;hadoopqa;{color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12688233/HADOOP-11432-001.txt
  against trunk revision 6635ccd.

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 1 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  There were no new javadoc warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:red}-1 findbugs{color}.  The patch appears to introduce 2 new Findbugs (version 2.0.3) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:green}+1 core tests{color}.  The patch passed unit tests in hadoop-common-project/hadoop-common.

Test results: https://builds.apache.org/job/PreCommit-HADOOP-Build/5309//testReport/
Findbugs warnings: https://builds.apache.org/job/PreCommit-HADOOP-Build/5309//artifact/patchprocess/newPatchFindbugsWarningshadoop-common.html
Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/5309//console

This message is automatically generated.","19/Dec/14 06:13;xieliang007;the findbugs waring is not related with current jira, will create another jira to track","06/Jan/15 21:25;jira.shegalov;[~xieliang007] Thank you for the patch. We can make this test more robust against future changes by having a public @VisibleForTesting error message method. On the other hand, is the message important here or testing for instanceof UnsupportedFileSystem would suffice? ","07/Jan/15 06:14;xieliang007;Hi [~jira.shegalov], thanks for the review, how about v2?","07/Jan/15 07:12;hadoopqa;{color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12690500/HADOOP-11432-002.txt
  against trunk revision 788ee35.

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 1 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  There were no new javadoc warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 2.0.3) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:green}+1 core tests{color}.  The patch passed unit tests in hadoop-common-project/hadoop-common.

Test results: https://builds.apache.org/job/PreCommit-HADOOP-Build/5374//testReport/
Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/5374//console

This message is automatically generated.","27/Jan/15 00:38;jira.shegalov;Hi [~xieliang007], Sorry for the delay. I assume from your patch that you insist the exception text is essential for the test. If so, would it make sense to make {{noAbstractFileSystemConfigured}} a simple constant? ","27/Jan/15 03:35;xieliang007;like v3? :)","27/Jan/15 04:34;hadoopqa;{color:green}+1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12694697/HADOOP-11432-003.txt
  against trunk revision 6f9fe76.

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 1 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  There were no new javadoc warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 2.0.3) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:green}+1 core tests{color}.  The patch passed unit tests in hadoop-common-project/hadoop-common.

Test results: https://builds.apache.org/job/PreCommit-HADOOP-Build/5485//testReport/
Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/5485//console

This message is automatically generated.","27/Jan/15 04:57;jira.shegalov;Thanks for updating the patch, [~xieliang007]. +1, especially if we make it comply with coding conventions for constants, maybe NO_ABSTRACT_FS_ERROR :) I should have been more explicit.","27/Jan/15 04:58;jira.shegalov;I can do it on commit if you are ok with that.","27/Jan/15 05:13;xieliang007;I'm ok, thank you:)","27/Jan/15 05:13;xieliang007;I'm ok, thank you:)","31/Jan/15 02:52;hudson;FAILURE: Integrated in Hadoop-trunk-Commit #6975 (See [https://builds.apache.org/job/Hadoop-trunk-Commit/6975/])
HADOOP-11432. Fix SymlinkBaseTest#testCreateLinkUsingPartQualPath2. (Liang Xie via gera) (gera: rev 26c2de36e2dd1b2ddedc155e49fb2ec31366d5f8)
* hadoop-common-project/hadoop-common/CHANGES.txt
* hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/AbstractFileSystem.java
* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/SymlinkBaseTest.java
","31/Jan/15 03:00;jira.shegalov;Thanks [~xieliang007] for the contribution. Committed to trunk and branch-2.","31/Jan/15 11:31;hudson;FAILURE: Integrated in Hadoop-Yarn-trunk-Java8 #90 (See [https://builds.apache.org/job/Hadoop-Yarn-trunk-Java8/90/])
HADOOP-11432. Fix SymlinkBaseTest#testCreateLinkUsingPartQualPath2. (Liang Xie via gera) (gera: rev 26c2de36e2dd1b2ddedc155e49fb2ec31366d5f8)
* hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/AbstractFileSystem.java
* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/SymlinkBaseTest.java
* hadoop-common-project/hadoop-common/CHANGES.txt
","31/Jan/15 11:35;hudson;FAILURE: Integrated in Hadoop-Yarn-trunk #824 (See [https://builds.apache.org/job/Hadoop-Yarn-trunk/824/])
HADOOP-11432. Fix SymlinkBaseTest#testCreateLinkUsingPartQualPath2. (Liang Xie via gera) (gera: rev 26c2de36e2dd1b2ddedc155e49fb2ec31366d5f8)
* hadoop-common-project/hadoop-common/CHANGES.txt
* hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/AbstractFileSystem.java
* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/SymlinkBaseTest.java
","31/Jan/15 14:12;hudson;FAILURE: Integrated in Hadoop-Hdfs-trunk #2022 (See [https://builds.apache.org/job/Hadoop-Hdfs-trunk/2022/])
HADOOP-11432. Fix SymlinkBaseTest#testCreateLinkUsingPartQualPath2. (Liang Xie via gera) (gera: rev 26c2de36e2dd1b2ddedc155e49fb2ec31366d5f8)
* hadoop-common-project/hadoop-common/CHANGES.txt
* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/SymlinkBaseTest.java
* hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/AbstractFileSystem.java
","31/Jan/15 14:14;hudson;FAILURE: Integrated in Hadoop-Hdfs-trunk-Java8 #87 (See [https://builds.apache.org/job/Hadoop-Hdfs-trunk-Java8/87/])
HADOOP-11432. Fix SymlinkBaseTest#testCreateLinkUsingPartQualPath2. (Liang Xie via gera) (gera: rev 26c2de36e2dd1b2ddedc155e49fb2ec31366d5f8)
* hadoop-common-project/hadoop-common/CHANGES.txt
* hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/AbstractFileSystem.java
* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/SymlinkBaseTest.java
","31/Jan/15 15:02;hudson;FAILURE: Integrated in Hadoop-Mapreduce-trunk-Java8 #91 (See [https://builds.apache.org/job/Hadoop-Mapreduce-trunk-Java8/91/])
HADOOP-11432. Fix SymlinkBaseTest#testCreateLinkUsingPartQualPath2. (Liang Xie via gera) (gera: rev 26c2de36e2dd1b2ddedc155e49fb2ec31366d5f8)
* hadoop-common-project/hadoop-common/CHANGES.txt
* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/SymlinkBaseTest.java
* hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/AbstractFileSystem.java
","31/Jan/15 15:22;hudson;FAILURE: Integrated in Hadoop-Mapreduce-trunk #2041 (See [https://builds.apache.org/job/Hadoop-Mapreduce-trunk/2041/])
HADOOP-11432. Fix SymlinkBaseTest#testCreateLinkUsingPartQualPath2. (Liang Xie via gera) (gera: rev 26c2de36e2dd1b2ddedc155e49fb2ec31366d5f8)
* hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/AbstractFileSystem.java
* hadoop-common-project/hadoop-common/CHANGES.txt
* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/SymlinkBaseTest.java
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Remove redundant tests in TestOsSecureRandom,HADOOP-11125,12741568,Test,Closed,HADOOP,Hadoop Common,software,omalley,Hadoop Common is the common library for Apache Hadoop.,http://hadoop.apache.org/,Major,Fixed,ooyamams,yuzhihong@gmail.com,yuzhihong@gmail.com,15/Sep/14 19:22,10/Apr/15 20:04,12/Jan/21 11:55,18/Dec/14 19:00,,,,,2.7.0,,,,,,,,,,0,newbie,,"From https://builds.apache.org/job/Hadoop-Mapreduce-trunk/1897/console :
{code}
Running org.apache.hadoop.crypto.random.TestOsSecureRandom
Tests run: 7, Failures: 0, Errors: 1, Skipped: 0, Time elapsed: 120.516 sec <<< FAILURE! - in org.apache.hadoop.crypto.random.TestOsSecureRandom
testOsSecureRandomSetConf(org.apache.hadoop.crypto.random.TestOsSecureRandom)  Time elapsed: 120.013 sec  <<< ERROR!
java.lang.Exception: test timed out after 120000 milliseconds
	at java.io.FileInputStream.readBytes(Native Method)
	at java.io.FileInputStream.read(FileInputStream.java:220)
	at java.io.BufferedInputStream.read1(BufferedInputStream.java:256)
	at java.io.BufferedInputStream.read(BufferedInputStream.java:317)
	at sun.nio.cs.StreamDecoder.readBytes(StreamDecoder.java:264)
	at sun.nio.cs.StreamDecoder.implRead(StreamDecoder.java:306)
	at sun.nio.cs.StreamDecoder.read(StreamDecoder.java:158)
	at java.io.InputStreamReader.read(InputStreamReader.java:167)
	at java.io.BufferedReader.fill(BufferedReader.java:136)
	at java.io.BufferedReader.read1(BufferedReader.java:187)
	at java.io.BufferedReader.read(BufferedReader.java:261)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.parseExecResult(Shell.java:715)
	at org.apache.hadoop.util.Shell.runCommand(Shell.java:524)
	at org.apache.hadoop.util.Shell.run(Shell.java:455)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:702)
	at org.apache.hadoop.crypto.random.TestOsSecureRandom.testOsSecureRandomSetConf(TestOsSecureRandom.java:149)
{code}",,aajisaka,hitliuyi,hudson,kihwal,ooyamams,wheat9,yuzhihong@gmail.com,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"27/Sep/14 11:43;ooyamams;HADOOP-11125-1.patch;https://issues.apache.org/jira/secure/attachment/12671639/HADOOP-11125-1.patch",,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,2014-09-24 21:57:51.687,,,false,,,,,,,,,,,,,,,,,9223372036854775807,Reviewed,,,,Fri Dec 19 15:25:32 UTC 2014,,,,,,,"0|i2027z:",9223372036854775807,,,,,,,,,,,,,2.7.0,,,,,,,,,,"24/Sep/14 21:57;kihwal;movef from mapreduce to common.","25/Sep/14 03:03;hitliuyi;{{TestOsSecureRandom#testOsSecureRandomSetConf}} doesn't assert anything and is not necessary, we can simply remove this test.","27/Sep/14 05:35;aajisaka;+1 (non-binding) to remove this test.","27/Sep/14 11:43;ooyamams;Upload patch to remove TestOsSecureRandom#testOsSecureRandomSetConf.","27/Sep/14 11:47;aajisaka;LGTM, +1 (non-binding) pending Jenkins.","27/Sep/14 12:38;hadoopqa;{color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12671639/HADOOP-11125-1.patch
  against trunk revision 5f16c98.

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 1 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  There were no new javadoc warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 2.0.3) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:red}-1 core tests{color}.  The patch failed these unit tests in hadoop-common-project/hadoop-common:

                  org.apache.hadoop.ha.TestZKFailoverControllerStress

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HADOOP-Build/4818//testReport/
Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/4818//console

This message is automatically generated.","18/Dec/14 09:07;aajisaka;+1. The test failure is unrelated to the patch.","18/Dec/14 10:05;hadoopqa;{color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12671639/HADOOP-11125-1.patch
  against trunk revision 1050d42.

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 1 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  There were no new javadoc warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:red}-1 findbugs{color}.  The patch appears to introduce 3 new Findbugs (version 2.0.3) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:green}+1 core tests{color}.  The patch passed unit tests in hadoop-common-project/hadoop-common.

Test results: https://builds.apache.org/job/PreCommit-HADOOP-Build/5300//testReport/
Findbugs warnings: https://builds.apache.org/job/PreCommit-HADOOP-Build/5300//artifact/patchprocess/newPatchFindbugsWarningshadoop-common.html
Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/5300//console

This message is automatically generated.","18/Dec/14 12:25;hitliuyi;+1, the reason I have given in HADOOP-11424 too.","18/Dec/14 18:56;wheat9;I'll commit this patch shortly.","18/Dec/14 19:00;wheat9;I've committed the patch to trunk and branch-2. Thanks [~ooyamams] for the contribution.","18/Dec/14 19:03;hudson;FAILURE: Integrated in Hadoop-trunk-Commit #6747 (See [https://builds.apache.org/job/Hadoop-trunk-Commit/6747/])
HADOOP-11125. Remove redundant tests in TestOsSecureRandom. Contributed by Masanori Oyama. (wheat9: rev abb2ebbc3a58506d01e8450aaf713a47ed4a4446)
* hadoop-common-project/hadoop-common/CHANGES.txt
* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/crypto/random/TestOsSecureRandom.java
","19/Dec/14 04:17;ooyamams;Thanks Akira AJISAKA , Yi Liu and Haohui Mai !
I'm glad to contribute to Hadoop!","19/Dec/14 10:41;hudson;FAILURE: Integrated in Hadoop-Yarn-trunk-Java8 #46 (See [https://builds.apache.org/job/Hadoop-Yarn-trunk-Java8/46/])
HADOOP-11125. Remove redundant tests in TestOsSecureRandom. Contributed by Masanori Oyama. (wheat9: rev abb2ebbc3a58506d01e8450aaf713a47ed4a4446)
* hadoop-common-project/hadoop-common/CHANGES.txt
* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/crypto/random/TestOsSecureRandom.java
","19/Dec/14 10:44;hudson;FAILURE: Integrated in Hadoop-Yarn-trunk #780 (See [https://builds.apache.org/job/Hadoop-Yarn-trunk/780/])
HADOOP-11125. Remove redundant tests in TestOsSecureRandom. Contributed by Masanori Oyama. (wheat9: rev abb2ebbc3a58506d01e8450aaf713a47ed4a4446)
* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/crypto/random/TestOsSecureRandom.java
* hadoop-common-project/hadoop-common/CHANGES.txt
","19/Dec/14 14:34;hudson;FAILURE: Integrated in Hadoop-Hdfs-trunk #1978 (See [https://builds.apache.org/job/Hadoop-Hdfs-trunk/1978/])
HADOOP-11125. Remove redundant tests in TestOsSecureRandom. Contributed by Masanori Oyama. (wheat9: rev abb2ebbc3a58506d01e8450aaf713a47ed4a4446)
* hadoop-common-project/hadoop-common/CHANGES.txt
* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/crypto/random/TestOsSecureRandom.java
","19/Dec/14 14:37;hudson;FAILURE: Integrated in Hadoop-Hdfs-trunk-Java8 #43 (See [https://builds.apache.org/job/Hadoop-Hdfs-trunk-Java8/43/])
HADOOP-11125. Remove redundant tests in TestOsSecureRandom. Contributed by Masanori Oyama. (wheat9: rev abb2ebbc3a58506d01e8450aaf713a47ed4a4446)
* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/crypto/random/TestOsSecureRandom.java
* hadoop-common-project/hadoop-common/CHANGES.txt
","19/Dec/14 15:05;hudson;FAILURE: Integrated in Hadoop-Mapreduce-trunk-Java8 #47 (See [https://builds.apache.org/job/Hadoop-Mapreduce-trunk-Java8/47/])
HADOOP-11125. Remove redundant tests in TestOsSecureRandom. Contributed by Masanori Oyama. (wheat9: rev abb2ebbc3a58506d01e8450aaf713a47ed4a4446)
* hadoop-common-project/hadoop-common/CHANGES.txt
* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/crypto/random/TestOsSecureRandom.java
","19/Dec/14 15:25;hudson;FAILURE: Integrated in Hadoop-Mapreduce-trunk #1997 (See [https://builds.apache.org/job/Hadoop-Mapreduce-trunk/1997/])
HADOOP-11125. Remove redundant tests in TestOsSecureRandom. Contributed by Masanori Oyama. (wheat9: rev abb2ebbc3a58506d01e8450aaf713a47ed4a4446)
* hadoop-common-project/hadoop-common/CHANGES.txt
* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/crypto/random/TestOsSecureRandom.java
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Tests for encryption/decryption with IV calculation overflow,HADOOP-11358,12759924,Test,Closed,HADOOP,Hadoop Common,software,omalley,Hadoop Common is the common library for Apache Hadoop.,http://hadoop.apache.org/,Major,Fixed,hitliuyi,hitliuyi,hitliuyi,06/Dec/14 00:24,10/Apr/15 20:04,12/Jan/21 11:55,18/Dec/14 01:47,2.6.0,,,,2.7.0,,,,,,security,test,,,0,,,"As discussed in HADOOP-11343, add more tests to cover encryption/decryption with IV calculation overflow",,andrew.wang,hitliuyi,hudson,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"17/Dec/14 02:30;hitliuyi;HADOOP-11358.001.patch;https://issues.apache.org/jira/secure/attachment/12687650/HADOOP-11358.001.patch",,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,2014-12-17 03:36:33.48,,,false,,,,,,,,,,,,,,,,,9223372036854775807,Reviewed,,,,Thu Dec 18 15:35:08 UTC 2014,,,,,,,"0|i2352v:",9223372036854775807,,,,,,,,,,,,,2.7.0,,,,,,,,,,"17/Dec/14 02:30;hitliuyi;Sorry for the late update.
In the patch, we cover tests for real encryption/decryption with IV calculation overflow. I make it by using {{CryptoInputStream}} and {{CryptoOutputStream}} directly instead of creating an encryption zone.
The seek in _cryptoCodecTest_ will go to call {{calculateIV}}, so it can cover the test scenario that we desired.

The patch can cover both JCE implementation and OpenSSL implementation.

BTW, I have tried this test without patch of HADOOP-11343, it will fail.

Hi [~andrew.wang], could you help to review it? thanks.","17/Dec/14 03:36;hadoopqa;{color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12687650/HADOOP-11358.001.patch
  against trunk revision e996a1b.

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 1 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  There were no new javadoc warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:red}-1 findbugs{color}.  The patch appears to introduce 3 new Findbugs (version 2.0.3) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:red}-1 core tests{color}.  The patch failed these unit tests in hadoop-common-project/hadoop-common:

                  org.apache.hadoop.crypto.random.TestOsSecureRandom

Test results: https://builds.apache.org/job/PreCommit-HADOOP-Build/5285//testReport/
Findbugs warnings: https://builds.apache.org/job/PreCommit-HADOOP-Build/5285//artifact/patchprocess/newPatchFindbugsWarningshadoop-common.html
Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/5285//console

This message is automatically generated.","18/Dec/14 00:33;hitliuyi;The findbugs and tests failure are not related.","18/Dec/14 00:38;andrew.wang;+1 LGTM thanks Yi","18/Dec/14 01:36;hitliuyi;Thanks Andrew for review, will commit shortly.","18/Dec/14 01:47;hitliuyi;committed to trunk and branch-2","18/Dec/14 01:52;hudson;FAILURE: Integrated in Hadoop-trunk-Commit #6745 (See [https://builds.apache.org/job/Hadoop-trunk-Commit/6745/])
HADOOP-11358. Tests for encryption/decryption with IV calculation overflow. (yliu) (yliu: rev 1050d424a27707414f1b60d1cbe45f9726caa8b2)
* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/crypto/TestCryptoCodec.java
* hadoop-common-project/hadoop-common/CHANGES.txt
","18/Dec/14 10:42;hudson;FAILURE: Integrated in Hadoop-Yarn-trunk-Java8 #45 (See [https://builds.apache.org/job/Hadoop-Yarn-trunk-Java8/45/])
HADOOP-11358. Tests for encryption/decryption with IV calculation overflow. (yliu) (yliu: rev 1050d424a27707414f1b60d1cbe45f9726caa8b2)
* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/crypto/TestCryptoCodec.java
* hadoop-common-project/hadoop-common/CHANGES.txt
","18/Dec/14 10:43;hudson;FAILURE: Integrated in Hadoop-Yarn-trunk #779 (See [https://builds.apache.org/job/Hadoop-Yarn-trunk/779/])
HADOOP-11358. Tests for encryption/decryption with IV calculation overflow. (yliu) (yliu: rev 1050d424a27707414f1b60d1cbe45f9726caa8b2)
* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/crypto/TestCryptoCodec.java
* hadoop-common-project/hadoop-common/CHANGES.txt
","18/Dec/14 14:39;hudson;FAILURE: Integrated in Hadoop-Hdfs-trunk-Java8 #42 (See [https://builds.apache.org/job/Hadoop-Hdfs-trunk-Java8/42/])
HADOOP-11358. Tests for encryption/decryption with IV calculation overflow. (yliu) (yliu: rev 1050d424a27707414f1b60d1cbe45f9726caa8b2)
* hadoop-common-project/hadoop-common/CHANGES.txt
* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/crypto/TestCryptoCodec.java
","18/Dec/14 14:40;hudson;FAILURE: Integrated in Hadoop-Hdfs-trunk #1977 (See [https://builds.apache.org/job/Hadoop-Hdfs-trunk/1977/])
HADOOP-11358. Tests for encryption/decryption with IV calculation overflow. (yliu) (yliu: rev 1050d424a27707414f1b60d1cbe45f9726caa8b2)
* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/crypto/TestCryptoCodec.java
* hadoop-common-project/hadoop-common/CHANGES.txt
","18/Dec/14 15:11;hudson;FAILURE: Integrated in Hadoop-Mapreduce-trunk-Java8 #46 (See [https://builds.apache.org/job/Hadoop-Mapreduce-trunk-Java8/46/])
HADOOP-11358. Tests for encryption/decryption with IV calculation overflow. (yliu) (yliu: rev 1050d424a27707414f1b60d1cbe45f9726caa8b2)
* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/crypto/TestCryptoCodec.java
* hadoop-common-project/hadoop-common/CHANGES.txt
","18/Dec/14 15:35;hudson;FAILURE: Integrated in Hadoop-Mapreduce-trunk #1996 (See [https://builds.apache.org/job/Hadoop-Mapreduce-trunk/1996/])
HADOOP-11358. Tests for encryption/decryption with IV calculation overflow. (yliu) (yliu: rev 1050d424a27707414f1b60d1cbe45f9726caa8b2)
* hadoop-common-project/hadoop-common/CHANGES.txt
* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/crypto/TestCryptoCodec.java
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Enable Kerberos profiled UTs to run with IBM JAVA,HADOOP-10421,12703260,Test,Resolved,HADOOP,Hadoop Common,software,omalley,Hadoop Common is the common library for Apache Hadoop.,http://hadoop.apache.org/,Major,Duplicate,jwang302,jwang302,jwang302,24/Mar/14 17:54,01/Mar/15 07:23,12/Jan/21 11:55,01/Mar/15 07:23,2.4.1,,,,,,,,,,security,test,,,3,,,"KerberosTestUtils in hadoop-auth does not support IBM JAVA, which has different Krb5LoginModule configuration options.",,aw,benoyantony,jwang302,lukebrowning,mihaic,sangameshs,vicaya,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"22/Sep/14 21:18;jwang302;HADOOP-10421.patch;https://issues.apache.org/jira/secure/attachment/12670504/HADOOP-10421.patch",,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,2014-09-22 23:31:42.917,,,false,,,,,,,,,,,,,,,,,381598,,,,,Sun Mar 01 07:23:58 UTC 2015,,,,,,,"0|i1tqu7:",381873,,,,,,,,,,,,,,,,,,,,,,,"22/Sep/14 21:22;jwang302;The attached patch adding IBM JAVA Kerberos support for hadoop-auth unit tests. The change in KerberosTestUtils.java is the same as HADOOP-9446 KerberosAuthenticationHandler change. The patch also added the property value test.dir in hadoop-project/pom.xml.","22/Sep/14 23:31;hadoopqa;{color:green}+1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12670504/HADOOP-10421.patch
  against trunk revision 23e17ce.

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 1 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  There were no new javadoc warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 2.0.3) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:green}+1 core tests{color}.  The patch passed unit tests in hadoop-common-project/hadoop-auth.

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HADOOP-Build/4787//testReport/
Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/4787//console

This message is automatically generated.","28/Oct/14 18:59;lukebrowning;Any idea when this will be reviewed and committed?

Thanks,
Luke","10/Dec/14 09:55;sangameshs;Hi,

Attached patch hasn't made into the hadoop trunk yet. Any idea when this defect be closed??

Thanks,
Sangamesh","01/Mar/15 07:23;aw;Closing as a dupe of HADOOP-10774, which was committed.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Create a CryptoCodec test that verifies interoperability between the JCE and OpenSSL implementations,HADOOP-11060,12738893,Test,Closed,HADOOP,Hadoop Common,software,omalley,Hadoop Common is the common library for Apache Hadoop.,http://hadoop.apache.org/,Major,Fixed,hitliuyi,tucu00,tucu00,03/Sep/14 19:55,01/Dec/14 03:10,12/Jan/21 11:55,04/Sep/14 16:23,2.6.0,,,,2.6.0,,,,,,security,,,,0,,,"We should have a test that verifies writing with one codec implementation and reading with other works, including some random seeks. This should be tested in both directions.
",,andrew.wang,hitliuyi,hudson,tucu00,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"04/Sep/14 09:09;hitliuyi;HADOOP-11060.001.patch;https://issues.apache.org/jira/secure/attachment/12666444/HADOOP-11060.001.patch",,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,2014-09-04 09:09:49.378,,,false,,,,,,,,,,,,,,,,,9223372036854775807,Reviewed,,,,Fri Sep 05 13:48:03 UTC 2014,,,,,,,"0|i1zn73:",9223372036854775807,,,,,,,,,,,,,2.6.0,,,,,,,,,,"04/Sep/14 09:09;hitliuyi;Update the tests.
1. Encrypt using JCE and decrypt using OpenSSL, and vice versa
2. Seek to some position and test decrypt.","04/Sep/14 10:08;hadoopqa;{color:green}+1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12666444/HADOOP-11060.001.patch
  against trunk revision 8f1a668.

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 2 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  There were no new javadoc warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 2.0.3) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:green}+1 core tests{color}.  The patch passed unit tests in hadoop-common-project/hadoop-common.

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HADOOP-Build/4647//testReport/
Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/4647//console

This message is automatically generated.","04/Sep/14 16:20;tucu00;+1","04/Sep/14 16:23;tucu00;Thanks Yi. Committed to trunk and branch-2.","05/Sep/14 11:28;hudson;SUCCESS: Integrated in Hadoop-Yarn-trunk #671 (See [https://builds.apache.org/job/Hadoop-Yarn-trunk/671/])
HADOOP-11060. Create a CryptoCodec test that verifies interoperability between the JCE and OpenSSL implementations. (hitliuyi via tucu) (tucu: rev b69a48c988c147abf192e36c99e2d4aecc116339)
* hadoop-common-project/hadoop-common/CHANGES.txt
* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/crypto/TestCryptoCodec.java
* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/crypto/TestCryptoStreams.java
","05/Sep/14 13:45;hudson;FAILURE: Integrated in Hadoop-Hdfs-trunk #1862 (See [https://builds.apache.org/job/Hadoop-Hdfs-trunk/1862/])
HADOOP-11060. Create a CryptoCodec test that verifies interoperability between the JCE and OpenSSL implementations. (hitliuyi via tucu) (tucu: rev b69a48c988c147abf192e36c99e2d4aecc116339)
* hadoop-common-project/hadoop-common/CHANGES.txt
* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/crypto/TestCryptoStreams.java
* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/crypto/TestCryptoCodec.java
","05/Sep/14 13:48;hudson;FAILURE: Integrated in Hadoop-Mapreduce-trunk #1887 (See [https://builds.apache.org/job/Hadoop-Mapreduce-trunk/1887/])
HADOOP-11060. Create a CryptoCodec test that verifies interoperability between the JCE and OpenSSL implementations. (hitliuyi via tucu) (tucu: rev b69a48c988c147abf192e36c99e2d4aecc116339)
* hadoop-common-project/hadoop-common/CHANGES.txt
* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/crypto/TestCryptoStreams.java
* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/crypto/TestCryptoCodec.java
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Hadoop streaming test TestStreamXmlMultipleRecords fails on Windows,HADOOP-11253,12751947,Test,Closed,HADOOP,Hadoop Common,software,omalley,Hadoop Common is the common library for Apache Hadoop.,http://hadoop.apache.org/,Major,Fixed,vvasudev,vvasudev,vvasudev,31/Oct/14 11:42,01/Dec/14 03:09,12/Jan/21 11:55,31/Oct/14 18:55,,,,,2.6.0,,,,,,tools,,,,0,,,"All the tests in TestStreamXmlMultipleRecords fail on Windows with errors similar to this -

{noformat}
java.lang.AssertionError: null
	at org.junit.Assert.fail(Assert.java:86)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertTrue(Assert.java:52)
	at org.apache.hadoop.streaming.TestStreaming.assertOutput(TestStreaming.java:177)
	at org.apache.hadoop.streaming.TestStreaming.checkOutput(TestStreaming.java:166)
	at org.apache.hadoop.streaming.TestStreaming.testCommandLine(TestStreaming.java:201)
	at org.apache.hadoop.streaming.TestStreamXmlMultipleRecords.testStreamXmlMultiInnerFast(TestStreamXmlMultipleRecords.java:113)
{noformat}",,hudson,vvasudev,wheat9,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"31/Oct/14 11:48;vvasudev;apache-hadoop-11253.0.patch;https://issues.apache.org/jira/secure/attachment/12678459/apache-hadoop-11253.0.patch",,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,2014-10-31 12:27:05.522,,,false,,,,,,,,,,,,,,,,,9223372036854775807,Reviewed,,,,Sat Nov 01 15:14:58 UTC 2014,,,,,,,"0|i21tbb:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,"31/Oct/14 11:48;vvasudev;Uploaded patch with fix. Root cause is to do with the way quotes are handled in the Windows shell vs Linux. Using the qq string function fixes it.","31/Oct/14 12:27;hadoopqa;{color:green}+1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12678459/apache-hadoop-11253.0.patch
  against trunk revision d1828d9.

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 1 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  There were no new javadoc warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 2.0.3) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:green}+1 core tests{color}.  The patch passed unit tests in hadoop-tools/hadoop-streaming.

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HADOOP-Build/4994//testReport/
Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/4994//console

This message is automatically generated.","31/Oct/14 18:50;wheat9;+1. I'll commit it shortly.","31/Oct/14 18:55;wheat9;I've committed the patch to trunk, branch-2 and branch-2.6. Thanks [~vvasudev] for the contribution.","31/Oct/14 19:03;hudson;FAILURE: Integrated in Hadoop-trunk-Commit #6410 (See [https://builds.apache.org/job/Hadoop-trunk-Commit/6410/])
HADOOP-11253. Hadoop streaming test TestStreamXmlMultipleRecords fails on Windows. Contributed by Varun Vasudev. (wheat9: rev f1a149e9166aa9af715d6a270eaba454b065b669)
* hadoop-common-project/hadoop-common/CHANGES.txt
* hadoop-tools/hadoop-streaming/src/test/java/org/apache/hadoop/streaming/TestStreamXmlMultipleRecords.java
","01/Nov/14 11:50;hudson;SUCCESS: Integrated in Hadoop-Yarn-trunk #730 (See [https://builds.apache.org/job/Hadoop-Yarn-trunk/730/])
HADOOP-11253. Hadoop streaming test TestStreamXmlMultipleRecords fails on Windows. Contributed by Varun Vasudev. (wheat9: rev f1a149e9166aa9af715d6a270eaba454b065b669)
* hadoop-tools/hadoop-streaming/src/test/java/org/apache/hadoop/streaming/TestStreamXmlMultipleRecords.java
* hadoop-common-project/hadoop-common/CHANGES.txt
","01/Nov/14 14:18;hudson;SUCCESS: Integrated in Hadoop-Hdfs-trunk #1919 (See [https://builds.apache.org/job/Hadoop-Hdfs-trunk/1919/])
HADOOP-11253. Hadoop streaming test TestStreamXmlMultipleRecords fails on Windows. Contributed by Varun Vasudev. (wheat9: rev f1a149e9166aa9af715d6a270eaba454b065b669)
* hadoop-tools/hadoop-streaming/src/test/java/org/apache/hadoop/streaming/TestStreamXmlMultipleRecords.java
* hadoop-common-project/hadoop-common/CHANGES.txt
","01/Nov/14 15:14;hudson;FAILURE: Integrated in Hadoop-Mapreduce-trunk #1944 (See [https://builds.apache.org/job/Hadoop-Mapreduce-trunk/1944/])
HADOOP-11253. Hadoop streaming test TestStreamXmlMultipleRecords fails on Windows. Contributed by Varun Vasudev. (wheat9: rev f1a149e9166aa9af715d6a270eaba454b065b669)
* hadoop-tools/hadoop-streaming/src/test/java/org/apache/hadoop/streaming/TestStreamXmlMultipleRecords.java
* hadoop-common-project/hadoop-common/CHANGES.txt
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Credential Provider related Unit Tests Failure on Windows,HADOOP-11073,12739732,Test,Closed,HADOOP,Hadoop Common,software,omalley,Hadoop Common is the common library for Apache Hadoop.,http://hadoop.apache.org/,Major,Fixed,xyao,xyao,xyao,06/Sep/14 22:46,01/Dec/14 03:09,12/Jan/21 11:55,08/Sep/14 16:33,2.4.1,,,,2.6.0,,,,,,security,,,,0,,,"Reported by: Xiaomara and investigated by [~cnauroth].

The credential provider related unit tests failed on Windows. The tests try to set up a URI by taking the build test directory and concatenating it with other strings containing the rest of the URI format, i.e.:

{code}
  public void testFactory() throws Exception {
    Configuration conf = new Configuration();
    conf.set(CredentialProviderFactory.CREDENTIAL_PROVIDER_PATH,
        UserProvider.SCHEME_NAME + "":///,"" +
            JavaKeyStoreProvider.SCHEME_NAME + ""://file"" + tmpDir + ""/test.jks"");
{code}

This logic is incorrect on Windows, because the file path separator will be '\', which violates URI syntax. Forward slash is not permitted. 

The proper fix is to always do path/URI construction through the org.apache.hadoop.fs.Path class, specifically using the constructors that take explicit parent and child arguments.

The affected unit tests are:

{code}
* TestKeyProviderFactory
* TestLdapGroupsMapping
* TestCredentialProviderFactory
* KeyStoreTestUtil
* TestSSLFactory
{code}
",,cnauroth,xyao,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"07/Sep/14 03:40;xyao;HADOOP-11073.0.patch;https://issues.apache.org/jira/secure/attachment/12667062/HADOOP-11073.0.patch","07/Sep/14 04:59;xyao;HADOOP-11073.1.patch;https://issues.apache.org/jira/secure/attachment/12667064/HADOOP-11073.1.patch",,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,2014-09-07 04:15:54.408,,,false,,,,,,,,,,,,,,,,,9223372036854775807,Reviewed,,,,Mon Sep 08 16:33:12 UTC 2014,,,,,,,"0|i1zrn3:",9223372036854775807,,,,,,,,,,,,,2.6.0,,,,,,,,,,"07/Sep/14 04:15;cnauroth;Hi, [~xyao].  This patch looks good.  I think we just have one more test case to correct.  I still see a failure in {{TestKeyProviderFactory#testGetProviderViaURI}}.","07/Sep/14 04:59;xyao;Good catch. I've fixed in my Windows VM but forget to attach the latest. New patch attached.","07/Sep/14 05:48;xyao;There are some additional fixes needed for TestSSLFactory. I will post updated patch. ","07/Sep/14 15:50;cnauroth;Hi, [~xyao].  I tried patch v1 on both Mac and Windows.  All tests passed, including {{TestSSLFactory}}, so I'd be +1 for this patch (pending Jenkins run).  Do you still see a problem in {{TestSSLFactory}}?","07/Sep/14 16:38;hadoopqa;{color:green}+1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12667064/HADOOP-11073.1.patch
  against trunk revision a23144f.

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 5 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  There were no new javadoc warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 2.0.3) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:green}+1 core tests{color}.  The patch passed unit tests in hadoop-common-project/hadoop-common.

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HADOOP-Build/4666//testReport/
Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/4666//console

This message is automatically generated.","07/Sep/14 18:26;xyao;I hit error in the following test on my Windows VM. Maybe it is just specific to my setup.

{code}

TestSSLFactory#testNoClientCertsInitialization 

java.security.cert.CertificateException: Subject class type invalid.
info.set(X509CertInfo.SUBJECT, new CertificateSubjectName(owner));     <---owner = ""CN=localhost, O=server"" --->

Stack: 
	at sun.security.x509.X509CertInfo.setSubject(X509CertInfo.java:888)
	at sun.security.x509.X509CertInfo.set(X509CertInfo.java:415)
	at org.apache.hadoop.security.ssl.KeyStoreTestUtil.generateCertificate(KeyStoreTestUtil.java:96)
	at org.apache.hadoop.security.ssl.KeyStoreTestUtil.setupSSLConfig(KeyStoreTestUtil.java:268)
	at org.apache.hadoop.security.ssl.TestSSLFactory.createConfiguration(TestSSLFactory.java:64)
	at org.apache.hadoop.security.ssl.TestSSLFactory.testNoClientCertsInitialization(TestSSLFactory.java:338)
{code}
","08/Sep/14 04:35;cnauroth;[~xyao], is there any chance that you're running JDK 8 on your Windows VM?  I noticed this bug report on OpenJDK 8:

https://bugs.openjdk.java.net/browse/JDK-8040820

I'm running OpenJDK 1.7.0_55, and the test passes for me.  Version 8 isn't officially supported yet, so as long as it passes with version 7, I think we're OK to commit this patch.  Please let me know.  Thanks!","08/Sep/14 04:59;xyao;Yes, I'm running JDK 1.8.0_20 on WS 2012. Agree that we should commit this patch. ","08/Sep/14 16:33;cnauroth;I committed this to trunk and branch-2.  Xiaoyu, thank you for providing this patch.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
TestNMSimulator fails sometimes due to timing issue,HADOOP-11241,12751027,Test,Closed,HADOOP,Hadoop Common,software,omalley,Hadoop Common is the common library for Apache Hadoop.,http://hadoop.apache.org/,Major,Fixed,vvasudev,vvasudev,vvasudev,28/Oct/14 08:26,01/Dec/14 03:07,12/Jan/21 11:55,01/Nov/14 01:06,,,,,2.6.0,,,,,,,,,,0,,,"TestNMSimulator fails sometimes due to timing issues. From a failure -
{noformat}
2014-10-16 23:21:42,343 INFO  resourcemanager.ResourceTrackerService (ResourceTrackerService.java:registerNodeManager(337)) - NodeManager from node node1(cmPort: 0 httpPort: 80) registered with capability: <memory:10240, vCores:10>, assigned nodeId node1:0
2014-10-16 23:21:42,397 ERROR delegation.AbstractDelegationTokenSecretManager (AbstractDelegationTokenSecretManager.java:run(642)) - ExpiredTokenRemover received java.lang.InterruptedException: sleep interrupted
2014-10-16 23:21:42,400 INFO  rmnode.RMNodeImpl (RMNodeImpl.java:handle(423)) - node1:0 Node Transitioned from NEW to RUNNING
2014-10-16 23:21:42,404 INFO  fair.FairScheduler (FairScheduler.java:addNode(825)) - Added node node1:0 cluster capacity: <memory:10240, vCores:10>
2014-10-16 23:21:42,407 INFO  mortbay.log (Slf4jLog.java:info(67)) - Stopped HttpServer2$SelectChannelConnectorWithSafeStartup@localhost:18088
2014-10-16 23:21:42,409 ERROR delegation.AbstractDelegationTokenSecretManager (AbstractDelegationTokenSecretManager.java:run(642)) - ExpiredTokenRemover received java.lang.InterruptedException: sleep interrupted
2014-10-16 23:21:42,410 INFO  ipc.Server (Server.java:stop(2437)) - Stopping server on 18032
2014-10-16 23:21:42,412 INFO  ipc.Server (Server.java:run(706)) - Stopping IPC Server listener on 18032
2014-10-16 23:21:42,412 INFO  ipc.Server (Server.java:run(832)) - Stopping IPC Server Responder
{noformat}",,hudson,junping_du,vvasudev,zjshen,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"28/Oct/14 09:03;vvasudev;apache-hadoop-11241.0.patch;https://issues.apache.org/jira/secure/attachment/12677568/apache-hadoop-11241.0.patch",,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,2014-10-29 00:01:26.406,,,false,,,,,,,,,,,,,,,,,9223372036854775807,Reviewed,,,,Sat Nov 01 15:14:58 UTC 2014,,,,,,,"0|i21nqn:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,"28/Oct/14 08:28;vvasudev;Attached patch with fix.","28/Oct/14 09:03;vvasudev;Renaming patch file","29/Oct/14 00:01;hadoopqa;{color:green}+1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12677568/apache-hadoop-11241.0.patch
  against trunk revision 8984e9b.

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 1 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  There were no new javadoc warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 2.0.3) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:green}+1 core tests{color}.  The patch passed unit tests in hadoop-tools/hadoop-sls.

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HADOOP-Build/4973//testReport/
Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/4973//console

This message is automatically generated.","29/Oct/14 06:23;vvasudev;Thanks for the build fix [~cmccabe].","29/Oct/14 09:08;junping_du;Thanks [~vvasudev] for the patch!
+1. Patch looks good. Will commit it soon.","01/Nov/14 00:56;zjshen;Junping is offline, and has the network issue with the git repository. I'll go ahead to commit the patch.","01/Nov/14 01:06;zjshen;Committed it to trunk, branch-2 and branch-2.6. Thanks Varun for the patch, and Junping for the review!","01/Nov/14 01:11;hudson;FAILURE: Integrated in Hadoop-trunk-Commit #6418 (See [https://builds.apache.org/job/Hadoop-trunk-Commit/6418/])
HADOOP-11241. Fixed intermittent TestNMSimulator failure due to timing issue. Contributed by Varun Vasudev. (zjshen: rev 260ab6d5f462d0fe1a4312cbba1c098141e3870e)
* hadoop-common-project/hadoop-common/CHANGES.txt
* hadoop-tools/hadoop-sls/src/test/java/org/apache/hadoop/yarn/sls/nodemanager/TestNMSimulator.java
","01/Nov/14 11:50;hudson;SUCCESS: Integrated in Hadoop-Yarn-trunk #730 (See [https://builds.apache.org/job/Hadoop-Yarn-trunk/730/])
HADOOP-11241. Fixed intermittent TestNMSimulator failure due to timing issue. Contributed by Varun Vasudev. (zjshen: rev 260ab6d5f462d0fe1a4312cbba1c098141e3870e)
* hadoop-tools/hadoop-sls/src/test/java/org/apache/hadoop/yarn/sls/nodemanager/TestNMSimulator.java
* hadoop-common-project/hadoop-common/CHANGES.txt
","01/Nov/14 14:18;hudson;SUCCESS: Integrated in Hadoop-Hdfs-trunk #1919 (See [https://builds.apache.org/job/Hadoop-Hdfs-trunk/1919/])
HADOOP-11241. Fixed intermittent TestNMSimulator failure due to timing issue. Contributed by Varun Vasudev. (zjshen: rev 260ab6d5f462d0fe1a4312cbba1c098141e3870e)
* hadoop-common-project/hadoop-common/CHANGES.txt
* hadoop-tools/hadoop-sls/src/test/java/org/apache/hadoop/yarn/sls/nodemanager/TestNMSimulator.java
","01/Nov/14 15:14;hudson;FAILURE: Integrated in Hadoop-Mapreduce-trunk #1944 (See [https://builds.apache.org/job/Hadoop-Mapreduce-trunk/1944/])
HADOOP-11241. Fixed intermittent TestNMSimulator failure due to timing issue. Contributed by Varun Vasudev. (zjshen: rev 260ab6d5f462d0fe1a4312cbba1c098141e3870e)
* hadoop-common-project/hadoop-common/CHANGES.txt
* hadoop-tools/hadoop-sls/src/test/java/org/apache/hadoop/yarn/sls/nodemanager/TestNMSimulator.java
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
script to that would let us checkout code from different repos,HADOOP-6697,12461689,Test,Resolved,HADOOP,Hadoop Common,software,omalley,Hadoop Common is the common library for Apache Hadoop.,http://hadoop.apache.org/,Major,Won't Fix,,gkesavan,gkesavan,09/Apr/10 16:37,30/Jul/14 17:38,12/Jan/21 11:55,30/Jul/14 17:38,,,,,,,,,,,build,,,,0,,,"To write a shell script that would let us checkout code from two different repository , where we cant use svn:externals.",,aw,cutting,jeffbowles,tlipcon,tomwhite,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,2010-04-09 17:33:08.275,,,false,,,,,,,,,,,,,,,,,127365,,,,,Wed Jul 30 17:38:45 UTC 2014,,,,,,,"0|i0hzmf:",103033,"A simple piece of shell-script plumbing, so that you can invoke a single-script to take a specific action (loading a secondary GIT or SVN repository prior to running a build, possibly to load your build-scripts from a second-source that has different IP restrictions).",,,,,,,,,,,,,,,,,,,,,,"09/Apr/10 17:33;hadoopqa;-1 overall.  Here are the results of testing the latest attachment 
  http://issues.apache.org
  against trunk revision 932115.

    +1 @author.  The patch does not contain any @author tags.

    -1 tests included.  The patch doesn't appear to include any new or modified tests.
                        Please justify why no new tests are needed for this patch.
                        Also please list what manual steps were performed to verify this patch.

    -1 patch.  The patch command could not apply the patch.

Console output: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch-h4.grid.sp2.yahoo.net/456/console

This message is automatically generated.","09/Apr/10 17:40;cutting;Can you explain this more?","18/Aug/10 21:52;jghoman;Canceling patch available status, since there's no patch.","30/Jul/14 17:38;aw;Closing as Won't Fix.

Can we move to git or mercurial yet? Please please please....",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Add missing Junit tests for Hadoop-6314,HADOOP-6316,12438278,Test,Resolved,HADOOP,Hadoop Common,software,omalley,Hadoop Common is the common library for Apache Hadoop.,http://hadoop.apache.org/,Major,Won't Fix,,raviphulari,raviphulari,16/Oct/09 08:39,29/Jul/14 18:47,12/Jan/21 11:55,29/Jul/14 18:47,,,,,,,,,,,,,,,0,,,,,Fan04290,garymurry,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,127213,,,,,2009-10-16 08:39:54.0,,,,,,,"0|i0i12f:",103267,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Use aspects to introduce new methods required for testing,HADOOP-6197,12433263,Test,Resolved,HADOOP,Hadoop Common,software,omalley,Hadoop Common is the common library for Apache Hadoop.,http://hadoop.apache.org/,Major,Fixed,cos,cos,cos,17/Aug/09 20:49,23/Jul/14 21:14,12/Jan/21 11:55,23/Jul/14 21:14,0.22.0,,,,,,,,,,security,test,,,0,,,"HADOOP-6176 introduces two new methods which are essentially required for testing purposes. However, this bring a permanent modifications to the production code.

The same result can be reached by using aspect development. Thus the modifications will be brought in by byte code instrumentation and will exist only during the testing cycles.",,aw,kzhang,nidaley,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,HADOOP-6176,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,HADOOP-6204,,,,,,,"13/Nov/09 21:10;cos;HADOOP-6197.patch;https://issues.apache.org/jira/secure/attachment/12424899/HADOOP-6197.patch","07/Sep/09 19:41;cos;HADOOP-6197.patch;https://issues.apache.org/jira/secure/attachment/12418842/HADOOP-6197.patch","17/Aug/09 20:54;cos;HADOOP-6197.patch;https://issues.apache.org/jira/secure/attachment/12416798/HADOOP-6197.patch","17/Aug/09 20:54;cos;HADOOP-6197.sh;https://issues.apache.org/jira/secure/attachment/12416797/HADOOP-6197.sh",,,,,,,,,,,,,,,,,,,,4.0,,,,,,,,,,,,,,,,,,,,2009-08-18 04:18:28.392,,,false,,,,,,,,,,,,,,,,,127168,,,,,Wed Jul 23 21:14:16 UTC 2014,,,,,,,"0|i0i1k7:",103347,,,,,,,,,,,,,,,,,,,,,,,"17/Aug/09 20:54;cos;These two files show the essence of needed modifications. New aspect will instrument {{AccessTokenHandler}} class with two required methods. Thus, these aren't needed any longer in the source code of {{AccessTokenHandler}}.

At this time, the patch can't be applied because Common project doesn't use the fault injection framework introduced for HDFS (see HDFS-435). However, as soon as the framework will be ported over to the Common, we'll be able to use this very method of code instrumentation.

Also, the patch might require some extra fine tuning like moving some tests from a 'normal' test list into 'fault-injected' test list.","18/Aug/09 04:18;vinodkv;bq. However, as soon as the framework will be ported over to the Common, we'll be able to use this very method of code instrumentation.
Is there any JIRA issue already opened for this?","18/Aug/09 16:26;cos;Not yet. I'll link this JIRA as soon as I'll have a new one for fault injection 
framework's porting.
","07/Sep/09 19:41;cos;As fault injection framework is being ported to the Common I have a chance to actually verify the suggested patch and find some issues with it.

Fixed now.","13/Nov/09 20:46;cos;Although there's no tests to use this new injected API it seems that everything is in place and ready for commit.","13/Nov/09 20:54;hadoopqa;-1 overall.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12418842/HADOOP-6197.patch
  against trunk revision 835967.

    +1 @author.  The patch does not contain any @author tags.

    +1 tests included.  The patch appears to include 3 new or modified tests.

    -1 patch.  The patch command could not apply the patch.

Console output: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch-h4.grid.sp2.yahoo.net/137/console

This message is automatically generated.","13/Nov/09 21:10;cos;Synch'ed up with trunk","23/Jul/14 21:14;aw;Probably stale.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Create tests for scripts to verify basic user experience, i.e. version, etc.",HADOOP-6174,12431938,Test,Resolved,HADOOP,Hadoop Common,software,omalley,Hadoop Common is the common library for Apache Hadoop.,http://hadoop.apache.org/,Major,Duplicate,,cos,cos,31/Jul/09 21:10,23/Jul/14 20:43,12/Jan/21 11:55,23/Jul/14 20:43,,,,,,,,,,,,,,,0,,,"As per HADOOP-6172 we need to have a set of scripts to verify the correctness of some very basic functionality accessible through bin/ scripts. 
",,hammer,hong.tang,szetszwo,yhemanth,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,HADOOP-6222,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,2009-07-31 21:22:22.722,,,false,,,,,,,,,,,,,,,,,127161,,,,,Wed Oct 14 01:40:30 UTC 2009,,,,,,,"0|i0i1nb:",103361,,,,,,,,,,,,,,,,,,,,,,,"31/Jul/09 21:22;nidaley;Hopefully TestCLI can be enhanced for these.","13/Oct/09 11:02;steve_l;One way to do this is through antunit and then with ant tasks to <exec> the scripts. This test framework will push out results in the same XML format as junit XML, and let Ant handle the heavy lifting of starting processes, terminating them afterwards, etc. ","14/Oct/09 01:40;cos;In fact we have TestCLI for this sort of things.  It already JUnit aware and you can simply write your tests in XM format which will be parsed and executed by TestCLI.

Also, this little framework is going to be ported to Common from HDFS at some point (see HADOOP-6222)
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Add tests that try starting the various hadoop command line scripts,HADOOP-4059,12403600,Test,Resolved,HADOOP,Hadoop Common,software,omalley,Hadoop Common is the common library for Apache Hadoop.,http://hadoop.apache.org/,Major,Duplicate,,stevel@apache.org,steve_l,03/Sep/08 10:20,18/Jul/14 22:47,12/Jan/21 11:55,18/Jul/14 22:47,0.19.0,,,,,,,,,,test,,,,0,,,"Hadoop has lots of tests that start clusters, but I don't see any that test the command line scripts working. Which means that changes to the scripts and the code behind them may not get picked up rapidly, and regressions won't get picked up by Hudson and apportioned to the specific patches.

Propose:
* an abstract test case that can exec scripts on startup; wait for them to finish, kill them if they take too long
* test cases for every service (namenode, tasktracker, datanode, etc)
* tests that try invalid commands, -help options
* tests that start the services, assert that they are live, and shut them down",,aw,cutting,Fan04290,nidaley,,,,,,,,,,,,,,,,,,,,,,259200,259200,,0%,259200,259200,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,2008-09-03 10:51:21.844,,,false,,,,,,,,,,,,,,,,,126294,,,,,Fri Jul 18 22:47:31 UTC 2014,,,,,,,"0|i0i97z:",104588,,,,,,,,,,,,,,,,,,,,,,,"03/Sep/08 10:51;steve_l;This may actually be easiest to test using AntUnit, as ant has much of the process management code needed: http://ant.apache.org/antlibs/antunit/

It could be added as a contribs/ section that has nothing but tests that get run in a series of test build files. The various entry points do have to run in their own process (we can't call JobTracker.main() etc) as the tests really do have to check the scripts end-to-end. Go via main() in a sandbox to catch System.exit() and you aren't testing the scripts any more, which always create more trouble than 50 lines of code really should

","03/Sep/08 16:21;nidaley;FYI, I think org.apache.hadoop.cli.TestCLI tests some of this.","03/Sep/08 22:04;steve_l;I hadnt looked at that before..yes, there is some good code there to drive it off XML files not java code. But the current tests dont run the scripts to start/stop cluster services, just the FS operations. I need tests for the services. testCLI seems a good starting point for some of this.

Incidentally, I've worked on past projects where the XML Files generated a different test case for junit; there is a trick to doing this (static TestSuite method), which then results in separate test reports for every command in the file. We could use this trick again.","18/Jul/14 22:47;aw;marking this as a duplicate of one of the followups to HADOOP-9902!",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
back to back testing of codecs,HADOOP-535,12349983,Test,Open,HADOOP,Hadoop Common,software,omalley,Hadoop Common is the common library for Apache Hadoop.,http://hadoop.apache.org/,Major,,acmurthy,omalley,omalley,14/Sep/06 23:04,17/Jul/14 16:03,12/Jan/21 11:55,,,,,,,,,,,,io,,,,0,,,"We should write some unit tests that use codecs back to back doing writing and then reading.

compressed block1, compressed block 2, compressed block3, ...

that will check that the compression codecs are consuming the entire block when they read.",,aw,qwertymaniac,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,2014-07-17 16:03:38.854,,,false,,,,,,,,,,,,,,,,,92404,,,,,Thu Jul 17 16:03:38 UTC 2014,,,,,,,"0|i0inzz:",106982,,,,,,,,,,,,,,,,,,,,,,,"17/Jul/14 16:03;aw;This was done years ago, wasn't it?",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Make TestTrash compatible with HADOOP-10461 .,HADOOP-10464,12706869,Test,Open,HADOOP,Hadoop Common,software,omalley,Hadoop Common is the common library for Apache Hadoop.,http://hadoop.apache.org/,Major,,,jayunit100,jayunit100,06/Apr/14 19:04,06/Apr/14 19:04,12/Jan/21 11:55,,,,,,,,,,,,,,,,0,,,"The current TestTrash implementation is like a  static utility class

{noformat}

 public static void trashShell(final Configuration conf, final Path base,
      FileSystem trashRootFs, Path trashRoot)

{noformat} 

It should be refactored to be a ""pure"" unit test that can be transparently integrated into TestSuites which don't have any prior knowledge of the tests it defines.",,jayunit100,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,385192,,,,,2014-04-06 19:04:04.0,,,,,,,"0|i1ucxb:",385459,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Bring RawLocalFileSystem test coverage to 100%,HADOOP-10463,12706607,Test,Open,HADOOP,Hadoop Common,software,omalley,Hadoop Common is the common library for Apache Hadoop.,http://hadoop.apache.org/,Major,,jayunit100,jayunit100,jayunit100,04/Apr/14 11:14,04/Apr/14 11:14,12/Jan/21 11:55,,,,,,,,,,,,fs,,,,0,,,"RawLocalFileSystem coverage is at about 80% (measured with cobertura) at the moment.  

A few notable untested code paths are:

* primitiveMkdir
* markSupported
* int read() 

Lets get it as close as possible to 100% coverage.  In the process of analyzing existing abstract tests which exersize RawLocalFileSystem,  we will also pave the way for HADOOP-10461.",,jayunit100,stevel@apache.org,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,384930,,,,,2014-04-04 11:14:05.0,,,,,,,"0|i1ubb3:",385197,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
convert hadoop-auth testcases requiring kerberos to use minikdc,HADOOP-9866,12663330,Test,Closed,HADOOP,Hadoop Common,software,omalley,Hadoop Common is the common library for Apache Hadoop.,http://hadoop.apache.org/,Major,Fixed,ywskycn,tucu00,tucu00,13/Aug/13 00:28,24/Feb/14 20:58,12/Jan/21 11:55,19/Aug/13 23:21,2.3.0,,,,2.3.0,,,,,,test,,,,0,,,,,daryn,drankye,hudson,sureshms,tucu00,ywskycn,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"16/Aug/13 17:58;ywskycn;HADOOP-9866.patch;https://issues.apache.org/jira/secure/attachment/12598504/HADOOP-9866.patch","14/Aug/13 22:13;ywskycn;HADOOP-9866.patch;https://issues.apache.org/jira/secure/attachment/12598070/HADOOP-9866.patch",,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,2013-08-13 13:49:41.92,,,false,,,,,,,,,,,,,,,,,343331,Reviewed,,,,Wed Sep 11 20:15:41 UTC 2013,,,,,,,"0|i1n7jj:",343635,,,,,,,,,,,,,,,,,,,,,,,"13/Aug/13 13:49;daryn;Also converting {{TestSaslRPC}} would be great but given the title perhaps it should be another jira.

How much time overhead does the minikdc add to test execution times?","13/Aug/13 15:08;tucu00;[~daryn], minikdc takes 3secs to start/stop. IMO We should convert testcases that exercise security components only. There are a few testscase through out the codebase that have a kerberos profile and are disabled by default (hadoop-auth & httpfs). I'm starting with those. Agree, doing the SaslRPC ones make sense as well, but I'd do them as different JIRAs. Do you want to take a stab to the SaslRPC, it should be quite simple (I've been using minikdc to test some thrift services doing both client/server stuff -all in the same process- and it works like a charm).","14/Aug/13 22:13;ywskycn;Upload a patch that enables and updates all kerberos testcases in hadoop-auth by using Hadoop-MiniKdc.","14/Aug/13 22:37;hadoopqa;{color:green}+1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12598070/HADOOP-9866.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 13 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  The javadoc tool did not generate any warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:green}+1 core tests{color}.  The patch passed unit tests in hadoop-common-project/hadoop-auth.

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HADOOP-Build/2981//testReport/
Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/2981//console

This message is automatically generated.","15/Aug/13 23:43;tucu00;Feedback on the patch:

There are several changes which are false changes due to reformatting, please undo all those.

All test methods you are modifying should have a time out: @Test(timeout=####) where #### is milliseconds. I guess setting them to 1 min should be safe, else set it to 10 times the time the test takes locally.
 
AuthenticatorTestCase: undo import changes to use class wildcard '*'

KerberosTestUtils: the getKeytabFile() path should be under target now that we create the keytabs on the fly, doing new File(System.getProperty(""build.directory"", ""target""), UUID.randomUUID()) and creating that dir would do (I believe MiniKDC is using similar logic)

KerberosTestUtils: we can get rid of all the system properties getting of KEYTAB, REALM, CLIENT_PRINCIPAL, SERVER_PRINCIPAL, KEYTAB_FILE and use hardcoded values as we now do everything within the MiniKDC scope.

TestKerberosName: if we need keep the krb5.conf file in test/resources  for this test, you'll have to set/unset the system properties setting the realm/krb5.conf.



","16/Aug/13 17:59;ywskycn;update a new pacth according [~tucu00] comments.

For TestKerberosName, we don't need the krb5.conf. Only set system properties (realm and host) @Before and clear them in @After.","16/Aug/13 18:17;hadoopqa;{color:green}+1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12598504/HADOOP-9866.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 13 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  The javadoc tool did not generate any warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:green}+1 core tests{color}.  The patch passed unit tests in hadoop-common-project/hadoop-auth.

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HADOOP-Build/2996//testReport/
Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/2996//console

This message is automatically generated.","19/Aug/13 21:10;tucu00;Wei, several of the newly added @Test annotations don't have the timeout set. Other than that patch looks good.","19/Aug/13 21:41;ywskycn;new patch add timeout for all test functions.","19/Aug/13 21:42;sureshms;bq. Wei, several of the newly added @Test annotations don't have the timeout set. Other than that patch looks good.
Setting timeout is no longer a requirement for tests.","19/Aug/13 22:08;hadoopqa;{color:green}+1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12598840/HADOOP-9866.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 13 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  The javadoc tool did not generate any warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:green}+1 core tests{color}.  The patch passed unit tests in hadoop-common-project/hadoop-auth.

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HADOOP-Build/3004//testReport/
Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/3004//console

This message is automatically generated.","19/Aug/13 22:29;tucu00;+1.

[~sureshms], missed that change (again). what made us have a change of heart on this?","19/Aug/13 22:52;sureshms;bq.  missed that change (again). what made us have a change of heart on this?
See HADOOP-9112, the endless pain of Jenkins -1s as a result of it, some discussions related to how flawed/artificial the requirement of adding @Timeout is...
","19/Aug/13 22:57;tucu00;OK, I'll commit the prev patch then (without timeouts) and I'll delete the last one.","19/Aug/13 23:17;hudson;SUCCESS: Integrated in Hadoop-trunk-Commit #4294 (See [https://builds.apache.org/job/Hadoop-trunk-Commit/4294/])
HADOOP-9866. convert hadoop-auth testcases requiring kerberos to use minikdc. (ywskycn via tucu) (tucu: http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1515657)
* /hadoop/common/trunk/hadoop-common-project/hadoop-auth/pom.xml
* /hadoop/common/trunk/hadoop-common-project/hadoop-auth/src/test/java/org/apache/hadoop/security/authentication/KerberosTestUtils.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-auth/src/test/java/org/apache/hadoop/security/authentication/client/AuthenticatorTestCase.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-auth/src/test/java/org/apache/hadoop/security/authentication/client/TestAuthenticatedURL.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-auth/src/test/java/org/apache/hadoop/security/authentication/client/TestKerberosAuthenticator.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-auth/src/test/java/org/apache/hadoop/security/authentication/client/TestPseudoAuthenticator.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-auth/src/test/java/org/apache/hadoop/security/authentication/server/TestAltKerberosAuthenticationHandler.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-auth/src/test/java/org/apache/hadoop/security/authentication/server/TestAuthenticationFilter.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-auth/src/test/java/org/apache/hadoop/security/authentication/server/TestAuthenticationToken.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-auth/src/test/java/org/apache/hadoop/security/authentication/server/TestKerberosAuthenticationHandler.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-auth/src/test/java/org/apache/hadoop/security/authentication/server/TestPseudoAuthenticationHandler.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-auth/src/test/java/org/apache/hadoop/security/authentication/util/TestKerberosName.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-auth/src/test/java/org/apache/hadoop/security/authentication/util/TestKerberosUtil.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-auth/src/test/java/org/apache/hadoop/security/authentication/util/TestSigner.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-auth/src/test/resources/krb5.conf
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/CHANGES.txt
","19/Aug/13 23:21;tucu00;Thanks Wei. Committed to trunk and branch-2.","20/Aug/13 10:57;hudson;SUCCESS: Integrated in Hadoop-Yarn-trunk #307 (See [https://builds.apache.org/job/Hadoop-Yarn-trunk/307/])
HADOOP-9866. convert hadoop-auth testcases requiring kerberos to use minikdc. (ywskycn via tucu) (tucu: http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1515657)
* /hadoop/common/trunk/hadoop-common-project/hadoop-auth/pom.xml
* /hadoop/common/trunk/hadoop-common-project/hadoop-auth/src/test/java/org/apache/hadoop/security/authentication/KerberosTestUtils.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-auth/src/test/java/org/apache/hadoop/security/authentication/client/AuthenticatorTestCase.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-auth/src/test/java/org/apache/hadoop/security/authentication/client/TestAuthenticatedURL.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-auth/src/test/java/org/apache/hadoop/security/authentication/client/TestKerberosAuthenticator.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-auth/src/test/java/org/apache/hadoop/security/authentication/client/TestPseudoAuthenticator.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-auth/src/test/java/org/apache/hadoop/security/authentication/server/TestAltKerberosAuthenticationHandler.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-auth/src/test/java/org/apache/hadoop/security/authentication/server/TestAuthenticationFilter.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-auth/src/test/java/org/apache/hadoop/security/authentication/server/TestAuthenticationToken.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-auth/src/test/java/org/apache/hadoop/security/authentication/server/TestKerberosAuthenticationHandler.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-auth/src/test/java/org/apache/hadoop/security/authentication/server/TestPseudoAuthenticationHandler.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-auth/src/test/java/org/apache/hadoop/security/authentication/util/TestKerberosName.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-auth/src/test/java/org/apache/hadoop/security/authentication/util/TestKerberosUtil.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-auth/src/test/java/org/apache/hadoop/security/authentication/util/TestSigner.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-auth/src/test/resources/krb5.conf
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/CHANGES.txt
","20/Aug/13 13:29;hudson;SUCCESS: Integrated in Hadoop-Hdfs-trunk #1497 (See [https://builds.apache.org/job/Hadoop-Hdfs-trunk/1497/])
HADOOP-9866. convert hadoop-auth testcases requiring kerberos to use minikdc. (ywskycn via tucu) (tucu: http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1515657)
* /hadoop/common/trunk/hadoop-common-project/hadoop-auth/pom.xml
* /hadoop/common/trunk/hadoop-common-project/hadoop-auth/src/test/java/org/apache/hadoop/security/authentication/KerberosTestUtils.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-auth/src/test/java/org/apache/hadoop/security/authentication/client/AuthenticatorTestCase.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-auth/src/test/java/org/apache/hadoop/security/authentication/client/TestAuthenticatedURL.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-auth/src/test/java/org/apache/hadoop/security/authentication/client/TestKerberosAuthenticator.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-auth/src/test/java/org/apache/hadoop/security/authentication/client/TestPseudoAuthenticator.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-auth/src/test/java/org/apache/hadoop/security/authentication/server/TestAltKerberosAuthenticationHandler.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-auth/src/test/java/org/apache/hadoop/security/authentication/server/TestAuthenticationFilter.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-auth/src/test/java/org/apache/hadoop/security/authentication/server/TestAuthenticationToken.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-auth/src/test/java/org/apache/hadoop/security/authentication/server/TestKerberosAuthenticationHandler.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-auth/src/test/java/org/apache/hadoop/security/authentication/server/TestPseudoAuthenticationHandler.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-auth/src/test/java/org/apache/hadoop/security/authentication/util/TestKerberosName.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-auth/src/test/java/org/apache/hadoop/security/authentication/util/TestKerberosUtil.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-auth/src/test/java/org/apache/hadoop/security/authentication/util/TestSigner.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-auth/src/test/resources/krb5.conf
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/CHANGES.txt
","20/Aug/13 14:47;hudson;FAILURE: Integrated in Hadoop-Mapreduce-trunk #1524 (See [https://builds.apache.org/job/Hadoop-Mapreduce-trunk/1524/])
HADOOP-9866. convert hadoop-auth testcases requiring kerberos to use minikdc. (ywskycn via tucu) (tucu: http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1515657)
* /hadoop/common/trunk/hadoop-common-project/hadoop-auth/pom.xml
* /hadoop/common/trunk/hadoop-common-project/hadoop-auth/src/test/java/org/apache/hadoop/security/authentication/KerberosTestUtils.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-auth/src/test/java/org/apache/hadoop/security/authentication/client/AuthenticatorTestCase.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-auth/src/test/java/org/apache/hadoop/security/authentication/client/TestAuthenticatedURL.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-auth/src/test/java/org/apache/hadoop/security/authentication/client/TestKerberosAuthenticator.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-auth/src/test/java/org/apache/hadoop/security/authentication/client/TestPseudoAuthenticator.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-auth/src/test/java/org/apache/hadoop/security/authentication/server/TestAltKerberosAuthenticationHandler.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-auth/src/test/java/org/apache/hadoop/security/authentication/server/TestAuthenticationFilter.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-auth/src/test/java/org/apache/hadoop/security/authentication/server/TestAuthenticationToken.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-auth/src/test/java/org/apache/hadoop/security/authentication/server/TestKerberosAuthenticationHandler.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-auth/src/test/java/org/apache/hadoop/security/authentication/server/TestPseudoAuthenticationHandler.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-auth/src/test/java/org/apache/hadoop/security/authentication/util/TestKerberosName.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-auth/src/test/java/org/apache/hadoop/security/authentication/util/TestKerberosUtil.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-auth/src/test/java/org/apache/hadoop/security/authentication/util/TestSigner.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-auth/src/test/resources/krb5.conf
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/CHANGES.txt
","10/Sep/13 23:37;drankye;bq. Also converting TestSaslRPC would be great but given the title perhaps it should be another jira.

So do we have such jira? To convert TestSaslRPC, and maybe even more, do you think it makes sense to create a SecuredMiniCluster(MiniCluster + MiniKdc)?","11/Sep/13 20:15;drankye;Regarding secured MiniCluster, opened HADOOP-9952 for the discussion.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Adding ticket cache login test for UGI by using MiniKdc,HADOOP-9943,12667533,Test,Open,HADOOP,Hadoop Common,software,omalley,Hadoop Common is the common library for Apache Hadoop.,http://hadoop.apache.org/,Major,,drankye,drankye,drankye,09/Sep/13 09:05,09/Sep/13 09:08,12/Jan/21 11:55,,,,,,,,,,,,security,,,,0,,,This will add a ticket cache login test for UGI by using MiniKdc.,,benoyantony,drankye,jiajia,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,HADOOP-9893,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,347470,,,,,2013-09-09 09:05:29.0,,,,,,,"0|i1nwzz:",347769,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
TestWritableName fails with Open JDK 7,HADOOP-9175,12625736,Test,Closed,HADOOP,Hadoop Common,software,omalley,Hadoop Common is the common library for Apache Hadoop.,http://hadoop.apache.org/,Major,Fixed,arp,arp,arp,02/Jan/13 22:11,15/May/13 05:16,12/Jan/21 11:55,02/Jan/13 23:16,1-win,,,,1.2.0,,,,,,test,,,,0,,,"TestWritableName.testAddName fails due to a test order execution dependency on testSetName.

java.io.IOException: WritableName can't load class: mystring
at org.apache.hadoop.io.WritableName.getClass(WritableName.java:73)
at org.apache.hadoop.io.TestWritableName.testAddName(TestWritableName.java:92)
Caused by: java.lang.ClassNotFoundException: mystring
at java.net.URLClassLoader$1.run(URLClassLoader.java:366)
at java.net.URLClassLoader$1.run(URLClassLoader.java:355)
at java.security.AccessController.doPrivileged(Native Method)
at java.net.URLClassLoader.findClass(URLClassLoader.java:354)
at java.lang.ClassLoader.loadClass(ClassLoader.java:423)
at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:308)
at java.lang.ClassLoader.loadClass(ClassLoader.java:356)
at java.lang.Class.forName0(Native Method)
at java.lang.Class.forName(Class.java:264)
at org.apache.hadoop.conf.Configuration.getClassByName(Configuration.java:820)
at org.apache.hadoop.io.WritableName.getClass(WritableName.java:71)",,arp,brandonli,mattf,sureshms,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"02/Jan/13 22:13;arp;HADOOP-9175.patch;https://issues.apache.org/jira/secure/attachment/12562981/HADOOP-9175.patch",,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,2013-01-02 22:26:27.095,,,false,,,,,,,,,,,,,,,,,302287,Reviewed,,,,Wed May 15 05:16:10 UTC 2013,,,,,,,"0|i16zx3:",248954,,,,,,,,,,,,,,,,,,,,,,,"02/Jan/13 22:13;arp;Fixed dependency by merging the two test cases into a single one.","02/Jan/13 22:26;brandonli;+1. The patch looks good.","02/Jan/13 23:11;sureshms;Related jira in trunk HADOOP-8697. Also this does not seem Windows specific, so updating the Summary accordingly.","02/Jan/13 23:16;sureshms;+1 for the patch. Committed to branch-1.

Thank you Arpit.","15/May/13 05:16;mattf;Closed upon release of Hadoop 1.2.0.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
TestSecurityUtil fails on Open JDK 7,HADOOP-9174,12625735,Test,Closed,HADOOP,Hadoop Common,software,omalley,Hadoop Common is the common library for Apache Hadoop.,http://hadoop.apache.org/,Major,Fixed,arp,arp,arp,02/Jan/13 22:09,15/May/13 05:15,12/Jan/21 11:55,02/Jan/13 23:05,1-win,,,,1.2.0,,,,,,test,,,,0,,,"TestSecurityUtil.TestBuildTokenServiceSockAddr fails due to implicit dependency on the test case execution order.

Testcase: testBuildTokenServiceSockAddr took 0.003 sec
	Caused an ERROR
expected:<[127.0.0.1]:123> but was:<[localhost]:123>
	at org.apache.hadoop.security.TestSecurityUtil.testBuildTokenServiceSockAddr(TestSecurityUtil.java:133)


Similar bug exists in TestSecurityUtil.testBuildDTServiceName.

The root cause is that a helper routine (verifyAddress) used by some test cases has a side effect. It resets a static variable (SecurityUtil.useIpForTokenService). 

The broken test cases assume that the flag will be set to true when they are invoked. The fix is to explicitly initialize the flag to its expected value instead of depending on the execution order.",,arp,brandonli,mattf,sureshms,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"02/Jan/13 22:15;arp;HADOOP-9174.patch;https://issues.apache.org/jira/secure/attachment/12562982/HADOOP-9174.patch",,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,2013-01-02 22:49:27.216,,,false,,,,,,,,,,,,,,,,,302286,Reviewed,,,,Wed May 15 05:15:56 UTC 2013,,,,,,,"0|i16zwv:",248953,,,,,,,,,,,,,1.2.0,,,,,,,,,,"02/Jan/13 22:15;arp;Fix to reset SecurityUtil.setTokenServiceUseIp to a predictable value before running the tests.","02/Jan/13 22:49;brandonli;+1. The patch looks good.
Please update the JIRA description with the root cause you mentioned offline.","02/Jan/13 22:54;arp;Thanks Brandon, updated as suggested.","02/Jan/13 23:00;sureshms;+1. There were similar test failures fixed in trunk. Is this change also required for trunk?","02/Jan/13 23:04;sureshms;A similar change for JDK7 was made in trunk in HADOOP-8693.","02/Jan/13 23:05;sureshms;I committed this to branch-1. ","02/Jan/13 23:17;arp;Thanks Suresh, and for the linking the related fix in trunk.","15/May/13 05:15;mattf;Closed upon release of Hadoop 1.2.0.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Add automated test for the RPC IP addr change detection and reconnect feature,HADOOP-7492,12516132,Test,Open,HADOOP,Hadoop Common,software,omalley,Hadoop Common is the common library for Apache Hadoop.,http://hadoop.apache.org/,Major,,kihwal,kihwal,kihwal,01/Aug/11 23:09,02/May/13 02:29,12/Jan/21 11:55,,0.23.0,,,,,,,,,,ipc,,,,0,,,"Make sure HADOOP-7472 is forward ported to 0.23 by adding an automated test.
",,atm,cutting,eli,eli2,nroberts,qwertymaniac,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,HADOOP-7537,,,,,,,"22/Aug/11 17:20;kihwal;TestRPCAddressChange-1.patch;https://issues.apache.org/jira/secure/attachment/12491230/TestRPCAddressChange-1.patch","11/Aug/11 20:08;kihwal;TestRPCAddressChange.patch;https://issues.apache.org/jira/secure/attachment/12490161/TestRPCAddressChange.patch",,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,2011-08-19 22:45:36.057,,,false,,,,,,,,,,,,,,,,,64001,,,,,Thu Jan 26 00:50:05 UTC 2012,,,,,,,"0|i0hw5r:",102472,,,,,,,,,,,,,,,,,,,,,,,"11/Aug/11 18:46;kihwal;HADOOP-7472 has been committed to TRUNK. The testing of IP address change detection was done manually, but we will have a way to automate the test with HADOOP-7537. ","11/Aug/11 20:08;kihwal;{{Test output - requires PowerMockito}}

{noformat}
2011-08-11 14:03:03,281 INFO  ipc.Server (Server.java:run(349)) - Starting Socket Reader #1 for port 49429
2011-08-11 14:03:03,311 INFO  ipc.Server (Server.java:run(642)) - IPC Server Responder: starting
2011-08-11 14:03:03,314 INFO  ipc.Server (Server.java:run(473)) - IPC Server listener on 49429: starting
2011-08-11 14:03:03,315 INFO  ipc.Server (Server.java:run(1466)) - IPC Server handler 0 on 49429: starting
2011-08-11 14:03:03,318 INFO  ipc.Server (Server.java:run(349)) - Starting Socket Reader #1 for port 34748
2011-08-11 14:03:03,319 INFO  ipc.Server (Server.java:run(642)) - IPC Server Responder: starting
2011-08-11 14:03:03,319 INFO  ipc.Server (Server.java:run(473)) - IPC Server listener on 34748: starting
2011-08-11 14:03:03,331 INFO  ipc.Server (Server.java:run(1466)) - IPC Server handler 0 on 34748: starting
2011-08-11 14:03:05,301 INFO  ipc.Server (Server.java:stop(1715)) - Stopping server on 49429
2011-08-11 14:03:05,302 INFO  ipc.Server (Server.java:run(1539)) - IPC Server handler 0 on 49429: exiting
2011-08-11 14:03:05,302 INFO  ipc.Server (Server.java:run(505)) - Stopping IPC Server listener on 49429
2011-08-11 14:03:05,303 INFO  ipc.Server (Server.java:run(647)) - Stopping IPC Server Responder
2011-08-11 14:03:06,382 INFO  ipc.Client (Client.java:handleConnectionFailure(670)) - Retrying connect to server: localhost.localdomain/127.0.0.1:49429. Already tried 0 time(s).
2011-08-11 14:03:07,400 INFO  ipc.Client (Client.java:handleConnectionFailure(670)) - Retrying connect to server: localhost.localdomain/127.0.0.1:49429. Already tried 1 time(s).
2011-08-11 14:03:07,413 WARN  ipc.Client (Client.java:updateAddress(422)) - Address change detected. Old: localhost.localdomain/127.0.0.1:49429 New: /127.0.0.1:34748
2011-08-11 14:03:08,426 INFO  ipc.Client (Client.java:handleConnectionFailure(670)) - Retrying connect to server: /127.0.0.1:34748. Already tried 0 time(s).
2011-08-11 14:03:08,490 INFO  ipc.Server (Server.java:stop(1715)) - Stopping server on 34748
2011-08-11 14:03:08,490 INFO  ipc.Server (Server.java:run(1539)) - IPC Server handler 0 on 34748: exiting
2011-08-11 14:03:08,490 INFO  ipc.Server (Server.java:run(505)) - Stopping IPC Server listener on 34748
2011-08-11 14:03:08,491 INFO  ipc.Server (Server.java:run(647)) - Stopping IPC Server Responder
{noformat}","11/Aug/11 20:18;kihwal;In the attached patch, the constructor of InetSocketAddress is mocked to return wrong or correct address. It requires PowerMock to run. I will make it ""patch available"" once HADOOP-7537 is resolved.","19/Aug/11 22:45;sureshms;Comments:
# Can you please add in testAddrChange() method comments what the behavior at the client that is being tested, instead of terse, ""address change detection by the RPC client"". Description that covers, RPC client on seeing connection failure, re-resolves the address and connects to the new address would be good. This will make the test easy for others to understand.
# Can you please set in conf, ""ipc.client.connect.max.retries"" to 10 (even though default is 10, which might change) to ensure more than two attempts are made for the test to pass. done in two retries? Also along with whenNew could you add a comment that return old address for two retry attempts and resolve to a new address in the third attempt?
# Nit: LocaTestServer#call() has indentation issues
# Nit: Please add to class javadoc ""Unit tests for RPC addr change detection in {@link Client}
# Nit: typo attemp 
","22/Aug/11 17:20;kihwal;The new patch incorporates Suresh's review comments.","23/Aug/11 19:32;kihwal;Given the state of HADOOP-7537, this test might not make it. I will wait until Daryn's changes and then think about other ways of testing it.","25/Jan/12 18:05;sureshms;Kihwals, why is this marked a blocker?","26/Jan/12 00:50;kihwal;A while back one of the reviewers asked to file this and mark it as a blocker. I guess the situation has changed.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
[Herriot]: Generic method for adding/modifying the attributes for new configuration.,HADOOP-6836,12467662,Test,Closed,HADOOP,Hadoop Common,software,omalley,Hadoop Common is the common library for Apache Hadoop.,http://hadoop.apache.org/,Major,Fixed,vinaythota,iyappans,iyappans,23/Jun/10 05:07,02/May/13 02:29,12/Jan/21 11:55,14/Jul/10 18:50,0.21.0,,,,0.21.0,,,,,,test,,,,0,,,"HADOP-6772 deals with 
Common utilities for system tests.
1. A method for restarting the daemon with new configuration.
c throws Exception; 

2. A method for restarting the daemon with default configuration.
public void restart() throws Exception;

3. A method for waiting until daemon is stop.
public void waitForClusterToStop() throws Exception;

In this  some variables are made of String, instead of Long. Those needs ot be changed too. So, can this method 
""public static void restartClusterWithNewConfig(Hashtable<String,Long> props, String confFile) throws Exception;""
be generalized to accepts string too. All otehr methods should work as usual.

",,balajirg,cos,garymurry,iyappans,vinaythota,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,HADOOP-6332,,,,,,,"25/Jun/10 08:14;vinaythota;6836-ydist-security.patch;https://issues.apache.org/jira/secure/attachment/12448032/6836-ydist-security.patch","25/Jun/10 08:14;vinaythota;HADOOP-6836.patch;https://issues.apache.org/jira/secure/attachment/12448033/HADOOP-6836.patch",,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,2010-06-23 08:59:31.286,,,false,,,,,,,,,,,,,,,,,127417,Reviewed,,,,Thu Jul 15 11:13:13 UTC 2010,,,,,,,"0|i0hz27:",102942,,,,,,,,,,,herriot,,,,,,,,,,,,"23/Jun/10 08:59;vinaythota;Patch for yahoo distribution security branch.","25/Jun/10 08:14;vinaythota;Patches for both trunk and yahoo dist security branch.","28/Jun/10 10:16;iyappans;+1 for the patch","29/Jun/10 20:50;cos;Patch looks good. +1 
Please do the usual patch verification through Hudson (submit the patch) to make sure all is cool.
","09/Jul/10 19:30;vinaythota;Cos, patch is working fine and I don't see any issues.Please commit into trunk.","09/Jul/10 21:41;cos;Vinay, usual verification means running a patch through {{test-patch}} process. One can do it by clicking on 'Submit patch' link in a JIRA.","12/Jul/10 21:34;hadoopqa;-1 overall.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12448033/HADOOP-6836.patch
  against trunk revision 962998.

    +1 @author.  The patch does not contain any @author tags.

    +1 tests included.  The patch appears to include 3 new or modified tests.

    -1 javadoc.  The javadoc tool appears to have generated 1 warning messages.

    +1 javac.  The applied patch does not increase the total number of javac compiler warnings.

    +1 findbugs.  The patch does not introduce any new Findbugs warnings.

    +1 release audit.  The applied patch does not increase the total number of release audit warnings.

    +1 core tests.  The patch passed core unit tests.

    +1 contrib tests.  The patch passed contrib unit tests.

Test results: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch-h4.grid.sp2.yahoo.net/608/testReport/
Findbugs warnings: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch-h4.grid.sp2.yahoo.net/608/artifact/trunk/build/test/findbugs/newPatchFindbugsWarnings.html
Checkstyle results: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch-h4.grid.sp2.yahoo.net/608/artifact/trunk/build/test/checkstyle-errors.html
Console output: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch-h4.grid.sp2.yahoo.net/608/console

This message is automatically generated.","14/Jul/10 11:47;vinaythota;I can see there are 6 javadoc warnings and all of them are related to warning: sun.security.krb5.Config.So, I don't think the patch could raise the number of java doc warning considering the scope of the patch.
","14/Jul/10 18:24;cos;+1 patch looks good. The warnings are apparently unrelated. Will commit it shortly.","14/Jul/10 18:50;cos;I have committed this. Thanks Vinay.","14/Jul/10 19:04;hudson;Integrated in Hadoop-Common-trunk-Commit #325 (See [http://hudson.zones.apache.org/hudson/job/Hadoop-Common-trunk-Commit/325/])
    HADOOP-6836. [Herriot]: Generic method for adding/modifying the attributes for new configuration. Contributed by Vinay Thota.
","15/Jul/10 11:13;hudson;Integrated in Hadoop-Common-trunk #393 (See [http://hudson.zones.apache.org/hudson/job/Hadoop-Common-trunk/393/])
    HADOOP-6836. [Herriot]: Generic method for adding/modifying the attributes for new configuration. Contributed by Vinay Thota.
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Representative mix of jobs for large cluster throughput benchmarking,HADOOP-2369,12384108,Test,Closed,HADOOP,Hadoop Common,software,omalley,Hadoop Common is the common library for Apache Hadoop.,http://hadoop.apache.org/,Major,Fixed,runping,cdouglas,cdouglas,06/Dec/07 19:38,02/May/13 02:29,12/Jan/21 11:55,09/Jan/08 01:00,,,,,0.16.0,,,,,,test,,,,0,,,The benchmarking load will consist of a set of map/reduce jobs of varying types and sizes. The mix of jobs will emulate observed user loads on large Hadoop clusters.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,HADOOP-2233,,,,,,,"11/Dec/07 23:52;cdouglas;gridmix-0.patch;https://issues.apache.org/jira/secure/attachment/12371469/gridmix-0.patch","17/Dec/07 23:29;cdouglas;gridmix-1.patch;https://issues.apache.org/jira/secure/attachment/12371832/gridmix-1.patch",,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,2007-12-06 21:21:19.199,,,false,,,,,,,,,,,,,,,,,125547,,,,,Wed Jan 09 01:00:21 UTC 2008,,,,,,,"0|i0igav:",105735,,,,,,,,,,,,,,,,,,,,,,,"06/Dec/07 21:21;hadoopqa;+1 overall.  Here are the results of testing the latest attachment 
http://issues.apache.org/jira/secure/attachment/12371168/gridmix-0.patch
against trunk revision r601824.

    @author +1.  The patch does not contain any @author tags.

    javadoc +1.  The javadoc tool did not generate any warning messages.

    javac +1.  The applied patch does not generate any new compiler warnings.

    findbugs +1.  The patch does not introduce any new Findbugs warnings.

    core tests +1.  The patch passed core unit tests.

    contrib tests +1.  The patch passed contrib unit tests.

Test results: http://lucene.zones.apache.org:8080/hudson/job/Hadoop-Patch/1284/testReport/
Findbugs warnings: http://lucene.zones.apache.org:8080/hudson/job/Hadoop-Patch/1284/artifact/trunk/build/test/findbugs/newPatchFindbugsWarnings.html
Checkstyle results: http://lucene.zones.apache.org:8080/hudson/job/Hadoop-Patch/1284/artifact/trunk/build/test/checkstyle-errors.html
Console output: http://lucene.zones.apache.org:8080/hudson/job/Hadoop-Patch/1284/console

This message is automatically generated.","11/Dec/07 23:52;cdouglas;Removed junk file genFileData.sh","12/Dec/07 00:30;runping;+1","17/Dec/07 23:29;cdouglas;Updated to reflect changes to HADOOP-2233 (i.e. moved GenericMRLoadGenerator from examples to test)","18/Dec/07 02:16;hadoopqa;-1 overall.  Here are the results of testing the latest attachment 
http://issues.apache.org/jira/secure/attachment/12371832/gridmix-1.patch
against trunk revision r604999.

    @author +1.  The patch does not contain any @author tags.

    javadoc +1.  The javadoc tool did not generate any warning messages.

    javac +1.  The applied patch does not generate any new compiler warnings.

    findbugs +1.  The patch does not introduce any new Findbugs warnings.

    core tests +1.  The patch passed core unit tests.

    contrib tests -1.  The patch failed contrib unit tests.

Test results: http://lucene.zones.apache.org:8080/hudson/job/Hadoop-Patch/1374/testReport/
Findbugs warnings: http://lucene.zones.apache.org:8080/hudson/job/Hadoop-Patch/1374/artifact/trunk/build/test/findbugs/newPatchFindbugsWarnings.html
Checkstyle results: http://lucene.zones.apache.org:8080/hudson/job/Hadoop-Patch/1374/artifact/trunk/build/test/checkstyle-errors.html
Console output: http://lucene.zones.apache.org:8080/hudson/job/Hadoop-Patch/1374/console

This message is automatically generated.","19/Dec/07 02:37;hadoopqa;+1 overall.  Here are the results of testing the latest attachment 
http://issues.apache.org/jira/secure/attachment/12371832/gridmix-1.patch
against trunk revision r605299.

    @author +1.  The patch does not contain any @author tags.

    javadoc +1.  The javadoc tool did not generate any warning messages.

    javac +1.  The applied patch does not generate any new compiler warnings.

    findbugs +1.  The patch does not introduce any new Findbugs warnings.

    core tests +1.  The patch passed core unit tests.

    contrib tests +1.  The patch passed contrib unit tests.

Test results: http://lucene.zones.apache.org:8080/hudson/job/Hadoop-Patch/1388/testReport/
Findbugs warnings: http://lucene.zones.apache.org:8080/hudson/job/Hadoop-Patch/1388/artifact/trunk/build/test/findbugs/newPatchFindbugsWarnings.html
Checkstyle results: http://lucene.zones.apache.org:8080/hudson/job/Hadoop-Patch/1388/artifact/trunk/build/test/checkstyle-errors.html
Console output: http://lucene.zones.apache.org:8080/hudson/job/Hadoop-Patch/1388/console

This message is automatically generated.","09/Jan/08 01:00;cdouglas;I just committed this. Thanks Runping!",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Print thread dumps when hadoop-common tests fail,HADOOP-9217,12627740,Test,Closed,HADOOP,Hadoop Common,software,omalley,Hadoop Common is the common library for Apache Hadoop.,http://hadoop.apache.org/,Major,Fixed,aklochkov,aklochkov,aklochkov,15/Jan/13 21:39,15/Feb/13 13:12,12/Jan/21 11:55,24/Jan/13 20:23,0.23.5,2.0.2-alpha,,,0.23.6,2.0.3-alpha,,,,,test,,,,0,,,"Printing thread dumps when tests fail due to timeouts was introduced in HADOOP-8755, but was enabled in M/R, HDFS and Yarn only. 
It makes sense to enable in hadoop-common as well. In particular, TestZKFailoverController seems to be one of the most flaky tests in trunk currently and having thread dumps may help debugging this.",,aklochkov,atm,hudson,kihwal,sureshms,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,HADOOP-9242,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"24/Jan/13 19:35;aklochkov;HADOOP-9217-fix1.patch;https://issues.apache.org/jira/secure/attachment/12566354/HADOOP-9217-fix1.patch","15/Jan/13 21:43;aklochkov;HADOOP-9217.patch;https://issues.apache.org/jira/secure/attachment/12565014/HADOOP-9217.patch",,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,2013-01-15 22:26:18.707,,,false,,,,,,,,,,,,,,,,,304528,Reviewed,,,,Thu Jan 24 20:23:55 UTC 2013,,,,,,,"0|i17n5z:",252722,,,,,,,,,,,,,0.23.6,2.0.3-alpha,,,,,,,,,"15/Jan/13 21:43;aklochkov;The patch can be applied to all 3 branches (trunk, branch-2 and branch-0.23)","15/Jan/13 22:26;hadoopqa;{color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12565014/HADOOP-9217.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:red}-1 tests included{color}.  The patch doesn't appear to include any new or modified tests.
                        Please justify why no new tests are needed for this patch.
                        Also please list what manual steps were performed to verify this patch.

      {color:red}-1 javac{color}.  The applied patch generated 2022 javac compiler warnings (more than the trunk's current 2014 warnings).

    {color:green}+1 javadoc{color}.  The javadoc tool did not generate any warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:green}+1 core tests{color}.  The patch passed unit tests in hadoop-common-project/hadoop-common.

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HADOOP-Build/2050//testReport/
Javac warnings: https://builds.apache.org/job/PreCommit-HADOOP-Build/2050//artifact/trunk/patchprocess/diffJavacWarnings.txt
Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/2050//console

This message is automatically generated.","15/Jan/13 22:29;aklochkov;No tests are necessary as this is a change in build scripts.","15/Jan/13 22:31;sureshms;+1 for the change.","15/Jan/13 22:42;sureshms;Committed the patch to trunk, branch-2 and 0.23.

Thank you Andrey.","15/Jan/13 22:45;hudson;Integrated in Hadoop-trunk-Commit #3245 (See [https://builds.apache.org/job/Hadoop-trunk-Commit/3245/])
    HADOOP-9217. Print thread dumps when hadoop-common tests fail. Contributed by Andrey Klochkov. (Revision 1433713)

     Result = SUCCESS
suresh : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1433713
Files : 
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/CHANGES.txt
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/pom.xml
","16/Jan/13 10:47;hudson;Integrated in Hadoop-Yarn-trunk #98 (See [https://builds.apache.org/job/Hadoop-Yarn-trunk/98/])
    HADOOP-9217. Print thread dumps when hadoop-common tests fail. Contributed by Andrey Klochkov. (Revision 1433713)

     Result = SUCCESS
suresh : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1433713
Files : 
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/CHANGES.txt
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/pom.xml
","16/Jan/13 12:36;hudson;Integrated in Hadoop-Hdfs-0.23-Build #496 (See [https://builds.apache.org/job/Hadoop-Hdfs-0.23-Build/496/])
    HADOOP-9217. Merging change 1433713 from trunk (Revision 1433718)

     Result = FAILURE
suresh : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1433718
Files : 
* /hadoop/common/branches/branch-0.23/hadoop-common-project/hadoop-common/CHANGES.txt
* /hadoop/common/branches/branch-0.23/hadoop-common-project/hadoop-common/pom.xml
","16/Jan/13 12:55;hudson;Integrated in Hadoop-Hdfs-trunk #1287 (See [https://builds.apache.org/job/Hadoop-Hdfs-trunk/1287/])
    HADOOP-9217. Print thread dumps when hadoop-common tests fail. Contributed by Andrey Klochkov. (Revision 1433713)

     Result = FAILURE
suresh : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1433713
Files : 
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/CHANGES.txt
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/pom.xml
","16/Jan/13 14:05;hudson;Integrated in Hadoop-Mapreduce-trunk #1315 (See [https://builds.apache.org/job/Hadoop-Mapreduce-trunk/1315/])
    HADOOP-9217. Print thread dumps when hadoop-common tests fail. Contributed by Andrey Klochkov. (Revision 1433713)

     Result = FAILURE
suresh : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1433713
Files : 
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/CHANGES.txt
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/pom.xml
","24/Jan/13 19:35;aklochkov;Unfortunately with this patch I introduced a duplicated configuration of Surefire plugin in hadoop-common/pom.xml, effectively discarding a part of configuration. Attaching a patch which fixes this.","24/Jan/13 20:07;hadoopqa;{color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12566354/HADOOP-9217-fix1.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:red}-1 tests included{color}.  The patch doesn't appear to include any new or modified tests.
                        Please justify why no new tests are needed for this patch.
                        Also please list what manual steps were performed to verify this patch.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  The javadoc tool did not generate any warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:green}+1 core tests{color}.  The patch passed unit tests in hadoop-common-project/hadoop-common.

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HADOOP-Build/2085//testReport/
Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/2085//console

This message is automatically generated.","24/Jan/13 20:15;atm;Hey Andrey, thanks a lot for noticing this and providing a fix. Since this is a newly-discovered bug, I think we should open a new JIRA for this change.","24/Jan/13 20:18;aklochkov;Good point, I'll open a separate one. Thanks.","24/Jan/13 20:23;aklochkov;HADOOP-9242 is created to track the additional fix",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Cover uncovered methods of class UserGroupInformation,HADOOP-9170,12625347,Test,Resolved,HADOOP,Hadoop Common,software,omalley,Hadoop Common is the common library for Apache Hadoop.,http://hadoop.apache.org/,Major,Invalid,iveselovsky,iveselovsky,iveselovsky,27/Dec/12 17:57,28/Dec/12 15:36,12/Jan/21 11:55,28/Dec/12 15:36,,,,,,,,,,,,,,,0,,,"methods of class UserGroupInformation
#addToken(null)
#print()
#main(String[])
are not covered by tests. Cover them.",,iveselovsky,sureshms,WHAA,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,301889,,,,,Fri Dec 28 15:36:41 UTC 2012,,,,,,,"0|i16x8f:",248516,,,,,,,,,,,,,,,,,,,,,,,"28/Dec/12 15:36;iveselovsky;This change merged into fix HADOOP-9166 since these two changes appear to overlap in some branches, and the patches were conflicting with each other.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Coverage fixing for org.apache.hadoop.mapreduce.jobhistory ,HADOOP-9138,12623692,Test,Resolved,HADOOP,Hadoop Common,software,omalley,Hadoop Common is the common library for Apache Hadoop.,http://hadoop.apache.org/,Major,Invalid,,aleksgor,aleksgor,13/Dec/12 09:17,13/Dec/12 12:44,12/Jan/21 11:55,13/Dec/12 12:44,0.2.0,0.23.0,,,,,,,,,,,,,0,,,Should be deleted,,aklochkov,aleksgor,jlowe,tgraves,WHAA,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,297421,,,,,2012-12-13 09:17:17.0,,,,,,,"0|i14ojb:",235440,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Test that the topology script is always passed IP addresses,HADOOP-7422,12511418,Test,Open,HADOOP,Hadoop Common,software,omalley,Hadoop Common is the common library for Apache Hadoop.,http://hadoop.apache.org/,Major,,,eli,eli,23/Jun/11 23:10,25/Nov/12 02:17,12/Jan/21 11:55,,,,,,,,,,,,test,,,,0,newbie,,"Now that HADOOP-6682 has been fixed, Hadoop should always pass the topology script an IP address rather than a hostname. We should write a test that covers this (specifically that DNSToSwitchMapping#resolve is always passed IP addresses) so users can safely write topology scripts that don't handle hostnames.   ",,adi2,ashishgandhi,atm,eli,junping_du,sarutak,tlipcon,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,2012-11-25 01:52:59.239,,,false,,,,,,,,,,,,,,,,,70127,,,,,Sun Nov 25 02:17:31 UTC 2012,,,,,,,"0|i0hwk7:",102537,,,,,,,,,,,,,,,,,,,,,,,"25/Nov/12 01:52;ashishgandhi;I'd like to work on this. Since this will be my first time trying to do something like this I wanted to ask if there's a process or some etiquette I should follow. I have cloned the Hadoop repository mirror from GitHub.","25/Nov/12 02:17;ashishgandhi;Found http://wiki.apache.org/hadoop/HowToContribute.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Extend TestShell to cover Windows shell commands,HADOOP-8601,12599050,Test,Resolved,HADOOP,Hadoop Common,software,omalley,Hadoop Common is the common library for Apache Hadoop.,http://hadoop.apache.org/,Major,Invalid,chuanliu,chuanliu,chuanliu,16/Jul/12 23:43,06/Nov/12 00:02,12/Jan/21 11:55,06/Nov/12 00:02,1-win,,,,1-win,,,,,,,,,,0,,,"The existing unit test only covers Linux shell commands. Since we begin to support Windows and use completely different commands on Windows, it make sense to extend TestShell to cover Windows use cases.",,chuanliu,daryn,sureshms,WHAA,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,HADOOP-8453,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,2012-11-06 00:02:02.557,,,false,,,,,,,,,,,,,,,,,246778,,,,,Tue Nov 06 00:02:02 UTC 2012,,,,,,,"0|i07t2n:",43477,,,,,,,,,,,,,,,,,,,,,,,"05/Nov/12 17:26;chuanliu;With HADOOP-8972, we will test Windows shell commands with a separate test: TestWinUtils, and this JIRA is no longer needed.","06/Nov/12 00:02;sureshms;Changing the resolution to Invalid.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
enabling clover coverage reports fails hadoop unit test compilation,HADOOP-7942,12536539,Test,Closed,HADOOP,Hadoop Common,software,omalley,Hadoop Common is the common library for Apache Hadoop.,http://hadoop.apache.org/,Major,Fixed,jnp,gkesavan,gkesavan,28/Dec/11 23:28,17/Oct/12 18:27,12/Jan/21 11:55,23/Aug/12 23:00,1.1.0,,,,1.1.0,,,,,,,,,,0,,,"enabling clover reports fails compiling the following junit tests.
link to the console output of jerkins :
https://builds.apache.org/view/G-L/view/Hadoop/job/Hadoop-1-Code-Coverage/13/console



{noformat}
[javac] /tmp/clover50695626838999169.tmp/org/apache/hadoop/security/TestUserGroupInformation.java:224: cannot find symbol
......
    [javac] /tmp/clover50695626838999169.tmp/org/apache/hadoop/security/TestUserGroupInformation.java:225: cannot find symbol
......

 [javac] /tmp/clover50695626838999169.tmp/org/apache/hadoop/security/TestJobCredentials.java:67: cannot find symbol
    [javac] symbol  : class T 
......
[javac] /tmp/clover50695626838999169.tmp/org/apache/hadoop/security/TestJobCredentials.java:68: cannot find symbol
    [javac] symbol  : class T
.....
[javac] /tmp/clover50695626838999169.tmp/org/apache/hadoop/fs/TestFileSystem.java:653: cannot find symbol
    [javac] symbol  : class T
.....
[javac]         ^
    [javac] Note: Some input files use or override a deprecated API.
    [javac] Note: Recompile with -Xlint:deprecation for details.
    [javac] 5 errors
    [javac] 63 warnings

{noformat}

","https://builds.apache.org/view/G-L/view/Hadoop/job/Hadoop-1-Code-Coverage/13/console
",mattf,qwertymaniac,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"29/Dec/11 00:27;jnp;HADOOP-7942.branch-1.patch;https://issues.apache.org/jira/secure/attachment/12508809/HADOOP-7942.branch-1.patch",,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,2011-12-29 00:27:04.929,,,false,,,,,,,,,,,,,,,,,222222,,,,,Wed Oct 17 18:27:23 UTC 2012,,,,,,,"0|i07w13:",43956,,,,,,,,,,,,,,,,,,,,,,,"29/Dec/11 00:27;jnp;This problem is due to a bug in javac which  is fixed in java 7. The attached patch should work around it.","29/Dec/11 01:39;gkesavan;+1 this patch fixes the junit test compilation failures.","29/Dec/11 01:56;jnp;Committed to branch-1.","15/Jan/12 06:53;qwertymaniac;If this is done, please mark as resolved or update the target and fix versions appropriately please.","15/Jan/12 06:54;qwertymaniac;Adding Fix version for branch-1, but keeping open for OP to resolve with confidence that this does not affect (or isn't needed) on other branches.","23/Aug/12 23:00;mattf;Seems like no one has observed a need for this in other branches in six months.  Resolving as part of 1.1.0 release cleanup.","17/Oct/12 18:27;mattf;Closed upon release of Hadoop-1.1.0.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Tests failures on the ARM hosts ,HADOOP-8769,12606276,Test,Open,HADOOP,Hadoop Common,software,omalley,Hadoop Common is the common library for Apache Hadoop.,http://hadoop.apache.org/,Major,,,eli,eli,05/Sep/12 18:09,02/Oct/12 19:07,12/Jan/21 11:55,,2.0.0-alpha,,,,,,,,,,build,,,,0,,,"I created a [jenkins job|https://builds.apache.org/job/Hadoop-trunk-ARM] that runs on the ARM machines. The local build is now working and running tests (thanks Gavin!), however there are 40 test failures, looks like most are due to host configuration issues. ",,eli,scurrilous,v_ganeshraju,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,2012-10-02 19:07:15.438,,,false,,,,,,,,,,,,,,,,,242043,,,,,Tue Oct 02 19:07:15 UTC 2012,,,,,,,"0|i02i7b:",12550,,,,,,,,,,,,,,,,,,,,,,,"05/Sep/12 18:09;eli;Here's a recent run: https://builds.apache.org/job/Hadoop-trunk-ARM/lastCompletedBuild/testReport","02/Oct/12 19:07;scurrilous;This job has been failing due to a configuration issue for the last week or so, e.g. https://builds.apache.org/job/Hadoop-trunk-ARM/39/console:

bq. [ERROR] Could not create local repository at /x1/hudson/.m2/repository -> [Help 1]

Do you know what the problem is? And is there some way I can help fix these issues? For instance, I'd like to be able to initiate a build as JDK7 unit test fixes are committed.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Allow tests to control token service value,HADOOP-8283,12551077,Test,Closed,HADOOP,Hadoop Common,software,omalley,Hadoop Common is the common library for Apache Hadoop.,http://hadoop.apache.org/,Major,Fixed,daryn,daryn,daryn,16/Apr/12 15:32,07/Sep/12 21:01,12/Jan/21 11:55,16/Apr/12 16:12,0.23.0,,,,0.23.3,2.0.2-alpha,,,,,test,,,,0,,,Tests in projects other than common need to be able to change whether the token service uses an ip or a host.,,Fan04290,revans2,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"16/Apr/12 15:34;daryn;HADOOP-8283.patch;https://issues.apache.org/jira/secure/attachment/12522789/HADOOP-8283.patch",,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,2012-04-16 15:55:38.135,,,false,,,,,,,,,,,,,,,,,235941,,,,,Tue Apr 17 14:03:44 UTC 2012,,,,,,,"0|i07uan:",43675,,,,,,,,,,,,,0.23.3,,,,,,,,,,"16/Apr/12 15:34;daryn;Expose {{SecurityUtil.setTokenServiceUseIp}}.","16/Apr/12 15:55;hadoopqa;+1 overall.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12522789/HADOOP-8283.patch
  against trunk revision .

    +1 @author.  The patch does not contain any @author tags.

    +1 tests included.  The patch appears to include 1 new or modified test files.

    +1 javadoc.  The javadoc tool did not generate any warning messages.

    +1 javac.  The applied patch does not increase the total number of javac compiler warnings.

    +1 eclipse:eclipse.  The patch built with eclipse:eclipse.

    +1 findbugs.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    +1 release audit.  The applied patch does not increase the total number of release audit warnings.

    +1 core tests.  The patch passed unit tests in .

    +1 contrib tests.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HADOOP-Build/855//testReport/
Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/855//console

This message is automatically generated.","16/Apr/12 16:07;revans2;The patch looks good to me.  +1","16/Apr/12 16:12;revans2;Thanks Daryn.  I put this into trunk, branch-2, and branch-0.23","16/Apr/12 16:15;hudson;Integrated in Hadoop-Hdfs-trunk-Commit #2148 (See [https://builds.apache.org/job/Hadoop-Hdfs-trunk-Commit/2148/])
    HADOOP-8283. Allow tests to control token service value (Daryn Sharp via bobby) (Revision 1326668)

     Result = SUCCESS
bobby : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1326668
Files : 
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/CHANGES.txt
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/security/SecurityUtilTestHelper.java
","16/Apr/12 16:17;hudson;Integrated in Hadoop-Common-trunk-Commit #2075 (See [https://builds.apache.org/job/Hadoop-Common-trunk-Commit/2075/])
    HADOOP-8283. Allow tests to control token service value (Daryn Sharp via bobby) (Revision 1326668)

     Result = SUCCESS
bobby : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1326668
Files : 
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/CHANGES.txt
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/security/SecurityUtilTestHelper.java
","16/Apr/12 16:57;hudson;Integrated in Hadoop-Mapreduce-trunk-Commit #2089 (See [https://builds.apache.org/job/Hadoop-Mapreduce-trunk-Commit/2089/])
    HADOOP-8283. Allow tests to control token service value (Daryn Sharp via bobby) (Revision 1326668)

     Result = ABORTED
bobby : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1326668
Files : 
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/CHANGES.txt
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/security/SecurityUtilTestHelper.java
","17/Apr/12 12:42;hudson;Integrated in Hadoop-Hdfs-0.23-Build #230 (See [https://builds.apache.org/job/Hadoop-Hdfs-0.23-Build/230/])
    svn merge -c 1326668 from trunk. FIXES: HADOOP-8283. Allow tests to control token service value (Daryn Sharp via bobby) (Revision 1326671)

     Result = UNSTABLE
bobby : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1326671
Files : 
* /hadoop/common/branches/branch-0.23/hadoop-common-project/hadoop-common/CHANGES.txt
* /hadoop/common/branches/branch-0.23/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/security/SecurityUtilTestHelper.java
","17/Apr/12 13:00;hudson;Integrated in Hadoop-Hdfs-trunk #1017 (See [https://builds.apache.org/job/Hadoop-Hdfs-trunk/1017/])
    HADOOP-8283. Allow tests to control token service value (Daryn Sharp via bobby) (Revision 1326668)

     Result = FAILURE
bobby : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1326668
Files : 
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/CHANGES.txt
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/security/SecurityUtilTestHelper.java
","17/Apr/12 14:03;hudson;Integrated in Hadoop-Mapreduce-trunk #1052 (See [https://builds.apache.org/job/Hadoop-Mapreduce-trunk/1052/])
    HADOOP-8283. Allow tests to control token service value (Daryn Sharp via bobby) (Revision 1326668)

     Result = FAILURE
bobby : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1326668
Files : 
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/CHANGES.txt
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/security/SecurityUtilTestHelper.java
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Auto HA: Refactor tests and add stress tests,HADOOP-8228,12548747,Test,Resolved,HADOOP,Hadoop Common,software,omalley,Hadoop Common is the common library for Apache Hadoop.,http://hadoop.apache.org/,Major,Fixed,tlipcon,tlipcon,tlipcon,29/Mar/12 21:57,30/Mar/12 20:31,12/Jan/21 11:55,30/Mar/12 20:31,Auto Failover (HDFS-3042),,,,Auto Failover (HDFS-3042),,,,,,auto-failover,ha,test,,0,,,"It's important that the ZKFailoverController be robust and not contain race conditions, etc. One strategy to find potential races is to add stress tests which exercise the code as fast as possible. This JIRA is to implement some test cases of this style.",,atm,bikassaha,Fan04290,mingjielai,WHAA,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"30/Mar/12 19:47;tlipcon;hadoop-8228.txt;https://issues.apache.org/jira/secure/attachment/12520655/hadoop-8228.txt","30/Mar/12 06:08;tlipcon;hadoop-8228.txt;https://issues.apache.org/jira/secure/attachment/12520571/hadoop-8228.txt","30/Mar/12 04:55;tlipcon;hadoop-8228.txt;https://issues.apache.org/jira/secure/attachment/12520565/hadoop-8228.txt","29/Mar/12 22:31;tlipcon;hadoop-8228.txt;https://issues.apache.org/jira/secure/attachment/12520522/hadoop-8228.txt",,,,,,,,,,,,,,,,,,,,4.0,,,,,,,,,,,,,,,,,,,,2012-03-30 18:45:28.212,,,false,,,,,,,,,,,,,,,,,233844,Reviewed,,,,Fri Mar 30 20:31:26 UTC 2012,,,,,,,"0|i018zj:",5225,,,,,,,,,,,,,Auto Failover (HDFS-3042),,,,,,,,,,"29/Mar/12 22:31;tlipcon;This test-only patch does the following:
- refactors much of the TestZKFailoverController code into a ""MiniZKFCCluster"" class, which allows tests to start and stop a pair of electable dummy services. There is no semantic change to TestZKFailoverController, but the patch is big just to move to the new API
- adds TestZKFailoverControllerStress, which contains several new stress tests for failover, session expiration, etc
- adds a DummySharedResource which keeps track of its ""owner"". When one of the dummy services becomes active, it takes control of the resource. When it goes standby, it releases control. If two services try to take the resource at the same time, it will throw an exception and record the violation. The MiniZKFCCluster checks that there were no violations in its shutdown method.","30/Mar/12 04:55;tlipcon;New rev includes code which covers the retry-on-disconnect mechanisms in the elector, as well as many of the error handling paths. While running a stress test, it has the ZK server disconnect all of its clients every 50ms. This causes outstanding ZK calls to get a {{Disconnected}} error and have to handle it.

I verified with Clover that this covers the retry code paths and various failure cases while writing/reading the breadcrumb node, etc.","30/Mar/12 06:08;tlipcon;Slight fix to the fencing setup in the dummy HA service. Fencing wasn't properly releasing the DummySharedResource, so some of the earlier tests started failing. Fixed it to add a FenceMethod which marks the DummySharedResource as released.","30/Mar/12 18:45;atm;This is some great cleanup, Todd. The new test/testing API look good.

One question: are you positive that the ordering of the two @After methods either doesn't matter, or is guaranteed to happen in the right order?

One comment: maybe use a deterministic random seed for the Random instances you're using? Or at least log the amount of time that the test is sleeping for and what it's throwing? I realize that the test won't be deterministic regardless, but it will be really tough to try to reproduce test failures caused by a particular ZK disconnect pattern or health check failure pattern if we have no idea what that pattern was.

+1 once those are addressed","30/Mar/12 19:45;tlipcon;bq. One question: are you positive that the ordering of the two @After methods either doesn't matter, or is guaranteed to happen in the right order?

The order of the two @After methods is nondeterministic. But, in this case, it's only important that our @After method runs before the superclass (ClientBase)'s tearDown. JUnit does guarantee the ordering in this case.

bq. One comment: maybe use a deterministic random seed for the Random instances you're using? Or at least log the amount of time that the test is sleeping for and what it's throwing?
Good point. I added additional logging for when it throws exceptions, and for when it expires sessions. I don't think the deterministic seed helps things, since the interleaving is still non-deterministic (that's part of the value of these tests :) )","30/Mar/12 19:47;tlipcon;New rev addresses the above.

I also noticed that testRandomHealthAndDisconnects was only having one of the two services randomly throw the errors. I fixed it so now both throw errors. The test still passes, though I'll run it through a longer run before committing","30/Mar/12 19:55;atm;Thanks for addressing my comments, Todd.

+1, the latest patch looks good to me.","30/Mar/12 20:31;tlipcon;Committed to HDFS-3042 branch. Thanks for reviewing, Aaron. I also ran the tests here with STRESS_RUNTIME_SECS bumped to 120s a couple times before committing.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Add more symlink tests that cover intermediate links,HADOOP-7783,12529391,Test,Closed,HADOOP,Hadoop Common,software,omalley,Hadoop Common is the common library for Apache Hadoop.,http://hadoop.apache.org/,Major,Fixed,eli,eli,eli,30/Oct/11 01:51,08/Feb/12 00:26,12/Jan/21 11:55,21/Nov/11 07:29,0.21.0,0.22.0,0.23.0,,0.22.0,,,,,,fs,,,,0,,,This covers the tests for HDFS-2514.,,Fan04290,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,HDFS-2514,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"30/Oct/11 01:54;eli;hadoop-7783-1.patch;https://issues.apache.org/jira/secure/attachment/12501487/hadoop-7783-1.patch","02/Nov/11 03:30;eli;hadoop-7783-2.patch;https://issues.apache.org/jira/secure/attachment/12501904/hadoop-7783-2.patch",,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,2011-11-02 03:43:14.98,,,false,,,,,,,,,,,,,,,,,215251,Reviewed,,,,Mon Nov 21 21:43:19 UTC 2011,,,,,,,"0|i09ipr:",53465,,,,,,,,,,,,,0.22.0,0.23.1,,,,,,,,,"30/Oct/11 01:54;eli;Patch attached. Adds tests and makes some improvements to the readability of the relevant code/javadocs.","02/Nov/11 03:30;eli;Attached patch is ready for review.","02/Nov/11 03:43;hadoopqa;-1 overall.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12501904/hadoop-7783-2.patch
  against trunk revision .

    +1 @author.  The patch does not contain any @author tags.

    +1 tests included.  The patch appears to include 6 new or modified tests.

    +1 javadoc.  The javadoc tool did not generate any warning messages.

    +1 javac.  The applied patch does not increase the total number of javac compiler warnings.

    -1 findbugs.  The patch appears to introduce 7 new Findbugs (version 1.3.9) warnings.

    +1 release audit.  The applied patch does not increase the total number of release audit warnings.

    +1 core tests.  The patch passed unit tests in .

    +1 contrib tests.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HADOOP-Build/352//testReport/
Findbugs warnings: https://builds.apache.org/job/PreCommit-HADOOP-Build/352//artifact/trunk/hadoop-common-project/patchprocess/newPatchFindbugsWarningshadoop-common.html
Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/352//console

This message is automatically generated.","02/Nov/11 04:14;eli;The findbugs warnings are unrelated, filed HADOOP-7796.","21/Nov/11 07:14;hudson;Integrated in Hadoop-Hdfs-trunk-Commit #1372 (See [https://builds.apache.org/job/Hadoop-Hdfs-trunk-Commit/1372/])
    HADOOP-7783. Add more symlink tests that cover intermediate links. Contributed by Eli Collins

eli : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1204376
Files : 
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/CHANGES.txt
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/AbstractFileSystem.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/FileContext.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/Path.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/FileContextSymlinkBaseTest.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/TestPath.java
","21/Nov/11 07:18;hudson;Integrated in Hadoop-Hdfs-0.23-Commit #190 (See [https://builds.apache.org/job/Hadoop-Hdfs-0.23-Commit/190/])
    HADOOP-7783. svn merge -c 1204376 from trunk

eli : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1204377
Files : 
* /hadoop/common/branches/branch-0.23
* /hadoop/common/branches/branch-0.23/hadoop-common-project
* /hadoop/common/branches/branch-0.23/hadoop-common-project/hadoop-auth
* /hadoop/common/branches/branch-0.23/hadoop-common-project/hadoop-common
* /hadoop/common/branches/branch-0.23/hadoop-common-project/hadoop-common/CHANGES.txt
* /hadoop/common/branches/branch-0.23/hadoop-common-project/hadoop-common/src/main/docs
* /hadoop/common/branches/branch-0.23/hadoop-common-project/hadoop-common/src/main/java
* /hadoop/common/branches/branch-0.23/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/AbstractFileSystem.java
* /hadoop/common/branches/branch-0.23/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/FileContext.java
* /hadoop/common/branches/branch-0.23/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/Path.java
* /hadoop/common/branches/branch-0.23/hadoop-common-project/hadoop-common/src/test/core
* /hadoop/common/branches/branch-0.23/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/FileContextSymlinkBaseTest.java
* /hadoop/common/branches/branch-0.23/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/TestPath.java
* /hadoop/common/branches/branch-0.23/hadoop-hdfs-project/hadoop-hdfs
* /hadoop/common/branches/branch-0.23/hadoop-hdfs-project/hadoop-hdfs/src/main/java
* /hadoop/common/branches/branch-0.23/hadoop-hdfs-project/hadoop-hdfs/src/main/native
* /hadoop/common/branches/branch-0.23/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode
* /hadoop/common/branches/branch-0.23/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/hdfs
* /hadoop/common/branches/branch-0.23/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/secondary
* /hadoop/common/branches/branch-0.23/hadoop-hdfs-project/hadoop-hdfs/src/test/hdfs
* /hadoop/common/branches/branch-0.23/hadoop-mapreduce-project
* /hadoop/common/branches/branch-0.23/hadoop-mapreduce-project/.gitignore
* /hadoop/common/branches/branch-0.23/hadoop-mapreduce-project/CHANGES.txt
* /hadoop/common/branches/branch-0.23/hadoop-mapreduce-project/bin
* /hadoop/common/branches/branch-0.23/hadoop-mapreduce-project/conf
* /hadoop/common/branches/branch-0.23/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/resources/mapred-default.xml
* /hadoop/common/branches/branch-0.23/hadoop-mapreduce-project/src/c++
* /hadoop/common/branches/branch-0.23/hadoop-mapreduce-project/src/contrib
* /hadoop/common/branches/branch-0.23/hadoop-mapreduce-project/src/contrib/block_forensics
* /hadoop/common/branches/branch-0.23/hadoop-mapreduce-project/src/contrib/build-contrib.xml
* /hadoop/common/branches/branch-0.23/hadoop-mapreduce-project/src/contrib/build.xml
* /hadoop/common/branches/branch-0.23/hadoop-mapreduce-project/src/contrib/data_join
* /hadoop/common/branches/branch-0.23/hadoop-mapreduce-project/src/contrib/eclipse-plugin
* /hadoop/common/branches/branch-0.23/hadoop-mapreduce-project/src/contrib/index
* /hadoop/common/branches/branch-0.23/hadoop-mapreduce-project/src/contrib/streaming
* /hadoop/common/branches/branch-0.23/hadoop-mapreduce-project/src/contrib/vaidya
* /hadoop/common/branches/branch-0.23/hadoop-mapreduce-project/src/examples
* /hadoop/common/branches/branch-0.23/hadoop-mapreduce-project/src/java
* /hadoop/common/branches/branch-0.23/hadoop-mapreduce-project/src/test/mapred
* /hadoop/common/branches/branch-0.23/hadoop-mapreduce-project/src/test/mapred/org/apache/hadoop/fs
* /hadoop/common/branches/branch-0.23/hadoop-mapreduce-project/src/test/mapred/org/apache/hadoop/hdfs
* /hadoop/common/branches/branch-0.23/hadoop-mapreduce-project/src/test/mapred/org/apache/hadoop/io/FileBench.java
* /hadoop/common/branches/branch-0.23/hadoop-mapreduce-project/src/test/mapred/org/apache/hadoop/io/TestSequenceFileMergeProgress.java
* /hadoop/common/branches/branch-0.23/hadoop-mapreduce-project/src/test/mapred/org/apache/hadoop/ipc
* /hadoop/common/branches/branch-0.23/hadoop-mapreduce-project/src/test/mapred/org/apache/hadoop/security/authorize/TestServiceLevelAuthorization.java
* /hadoop/common/branches/branch-0.23/hadoop-mapreduce-project/src/test/mapred/org/apache/hadoop/test/MapredTestDriver.java
* /hadoop/common/branches/branch-0.23/hadoop-mapreduce-project/src/webapps/job
","21/Nov/11 07:24;hudson;Integrated in Hadoop-Common-0.23-Commit #193 (See [https://builds.apache.org/job/Hadoop-Common-0.23-Commit/193/])
    HADOOP-7783. svn merge -c 1204376 from trunk

eli : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1204377
Files : 
* /hadoop/common/branches/branch-0.23
* /hadoop/common/branches/branch-0.23/hadoop-common-project
* /hadoop/common/branches/branch-0.23/hadoop-common-project/hadoop-auth
* /hadoop/common/branches/branch-0.23/hadoop-common-project/hadoop-common
* /hadoop/common/branches/branch-0.23/hadoop-common-project/hadoop-common/CHANGES.txt
* /hadoop/common/branches/branch-0.23/hadoop-common-project/hadoop-common/src/main/docs
* /hadoop/common/branches/branch-0.23/hadoop-common-project/hadoop-common/src/main/java
* /hadoop/common/branches/branch-0.23/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/AbstractFileSystem.java
* /hadoop/common/branches/branch-0.23/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/FileContext.java
* /hadoop/common/branches/branch-0.23/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/Path.java
* /hadoop/common/branches/branch-0.23/hadoop-common-project/hadoop-common/src/test/core
* /hadoop/common/branches/branch-0.23/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/FileContextSymlinkBaseTest.java
* /hadoop/common/branches/branch-0.23/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/TestPath.java
* /hadoop/common/branches/branch-0.23/hadoop-hdfs-project/hadoop-hdfs
* /hadoop/common/branches/branch-0.23/hadoop-hdfs-project/hadoop-hdfs/src/main/java
* /hadoop/common/branches/branch-0.23/hadoop-hdfs-project/hadoop-hdfs/src/main/native
* /hadoop/common/branches/branch-0.23/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode
* /hadoop/common/branches/branch-0.23/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/hdfs
* /hadoop/common/branches/branch-0.23/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/secondary
* /hadoop/common/branches/branch-0.23/hadoop-hdfs-project/hadoop-hdfs/src/test/hdfs
* /hadoop/common/branches/branch-0.23/hadoop-mapreduce-project
* /hadoop/common/branches/branch-0.23/hadoop-mapreduce-project/.gitignore
* /hadoop/common/branches/branch-0.23/hadoop-mapreduce-project/CHANGES.txt
* /hadoop/common/branches/branch-0.23/hadoop-mapreduce-project/bin
* /hadoop/common/branches/branch-0.23/hadoop-mapreduce-project/conf
* /hadoop/common/branches/branch-0.23/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/resources/mapred-default.xml
* /hadoop/common/branches/branch-0.23/hadoop-mapreduce-project/src/c++
* /hadoop/common/branches/branch-0.23/hadoop-mapreduce-project/src/contrib
* /hadoop/common/branches/branch-0.23/hadoop-mapreduce-project/src/contrib/block_forensics
* /hadoop/common/branches/branch-0.23/hadoop-mapreduce-project/src/contrib/build-contrib.xml
* /hadoop/common/branches/branch-0.23/hadoop-mapreduce-project/src/contrib/build.xml
* /hadoop/common/branches/branch-0.23/hadoop-mapreduce-project/src/contrib/data_join
* /hadoop/common/branches/branch-0.23/hadoop-mapreduce-project/src/contrib/eclipse-plugin
* /hadoop/common/branches/branch-0.23/hadoop-mapreduce-project/src/contrib/index
* /hadoop/common/branches/branch-0.23/hadoop-mapreduce-project/src/contrib/streaming
* /hadoop/common/branches/branch-0.23/hadoop-mapreduce-project/src/contrib/vaidya
* /hadoop/common/branches/branch-0.23/hadoop-mapreduce-project/src/examples
* /hadoop/common/branches/branch-0.23/hadoop-mapreduce-project/src/java
* /hadoop/common/branches/branch-0.23/hadoop-mapreduce-project/src/test/mapred
* /hadoop/common/branches/branch-0.23/hadoop-mapreduce-project/src/test/mapred/org/apache/hadoop/fs
* /hadoop/common/branches/branch-0.23/hadoop-mapreduce-project/src/test/mapred/org/apache/hadoop/hdfs
* /hadoop/common/branches/branch-0.23/hadoop-mapreduce-project/src/test/mapred/org/apache/hadoop/io/FileBench.java
* /hadoop/common/branches/branch-0.23/hadoop-mapreduce-project/src/test/mapred/org/apache/hadoop/io/TestSequenceFileMergeProgress.java
* /hadoop/common/branches/branch-0.23/hadoop-mapreduce-project/src/test/mapred/org/apache/hadoop/ipc
* /hadoop/common/branches/branch-0.23/hadoop-mapreduce-project/src/test/mapred/org/apache/hadoop/security/authorize/TestServiceLevelAuthorization.java
* /hadoop/common/branches/branch-0.23/hadoop-mapreduce-project/src/test/mapred/org/apache/hadoop/test/MapredTestDriver.java
* /hadoop/common/branches/branch-0.23/hadoop-mapreduce-project/src/webapps/job
","21/Nov/11 07:25;hudson;Integrated in Hadoop-Common-trunk-Commit #1299 (See [https://builds.apache.org/job/Hadoop-Common-trunk-Commit/1299/])
    HADOOP-7783. Add more symlink tests that cover intermediate links. Contributed by Eli Collins

eli : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1204376
Files : 
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/CHANGES.txt
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/AbstractFileSystem.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/FileContext.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/Path.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/FileContextSymlinkBaseTest.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/TestPath.java
","21/Nov/11 07:28;hudson;Integrated in Hadoop-Mapreduce-0.23-Commit #204 (See [https://builds.apache.org/job/Hadoop-Mapreduce-0.23-Commit/204/])
    HADOOP-7783. svn merge -c 1204376 from trunk

eli : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1204377
Files : 
* /hadoop/common/branches/branch-0.23
* /hadoop/common/branches/branch-0.23/hadoop-common-project
* /hadoop/common/branches/branch-0.23/hadoop-common-project/hadoop-auth
* /hadoop/common/branches/branch-0.23/hadoop-common-project/hadoop-common
* /hadoop/common/branches/branch-0.23/hadoop-common-project/hadoop-common/CHANGES.txt
* /hadoop/common/branches/branch-0.23/hadoop-common-project/hadoop-common/src/main/docs
* /hadoop/common/branches/branch-0.23/hadoop-common-project/hadoop-common/src/main/java
* /hadoop/common/branches/branch-0.23/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/AbstractFileSystem.java
* /hadoop/common/branches/branch-0.23/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/FileContext.java
* /hadoop/common/branches/branch-0.23/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/Path.java
* /hadoop/common/branches/branch-0.23/hadoop-common-project/hadoop-common/src/test/core
* /hadoop/common/branches/branch-0.23/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/FileContextSymlinkBaseTest.java
* /hadoop/common/branches/branch-0.23/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/TestPath.java
* /hadoop/common/branches/branch-0.23/hadoop-hdfs-project/hadoop-hdfs
* /hadoop/common/branches/branch-0.23/hadoop-hdfs-project/hadoop-hdfs/src/main/java
* /hadoop/common/branches/branch-0.23/hadoop-hdfs-project/hadoop-hdfs/src/main/native
* /hadoop/common/branches/branch-0.23/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode
* /hadoop/common/branches/branch-0.23/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/hdfs
* /hadoop/common/branches/branch-0.23/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/secondary
* /hadoop/common/branches/branch-0.23/hadoop-hdfs-project/hadoop-hdfs/src/test/hdfs
* /hadoop/common/branches/branch-0.23/hadoop-mapreduce-project
* /hadoop/common/branches/branch-0.23/hadoop-mapreduce-project/.gitignore
* /hadoop/common/branches/branch-0.23/hadoop-mapreduce-project/CHANGES.txt
* /hadoop/common/branches/branch-0.23/hadoop-mapreduce-project/bin
* /hadoop/common/branches/branch-0.23/hadoop-mapreduce-project/conf
* /hadoop/common/branches/branch-0.23/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/resources/mapred-default.xml
* /hadoop/common/branches/branch-0.23/hadoop-mapreduce-project/src/c++
* /hadoop/common/branches/branch-0.23/hadoop-mapreduce-project/src/contrib
* /hadoop/common/branches/branch-0.23/hadoop-mapreduce-project/src/contrib/block_forensics
* /hadoop/common/branches/branch-0.23/hadoop-mapreduce-project/src/contrib/build-contrib.xml
* /hadoop/common/branches/branch-0.23/hadoop-mapreduce-project/src/contrib/build.xml
* /hadoop/common/branches/branch-0.23/hadoop-mapreduce-project/src/contrib/data_join
* /hadoop/common/branches/branch-0.23/hadoop-mapreduce-project/src/contrib/eclipse-plugin
* /hadoop/common/branches/branch-0.23/hadoop-mapreduce-project/src/contrib/index
* /hadoop/common/branches/branch-0.23/hadoop-mapreduce-project/src/contrib/streaming
* /hadoop/common/branches/branch-0.23/hadoop-mapreduce-project/src/contrib/vaidya
* /hadoop/common/branches/branch-0.23/hadoop-mapreduce-project/src/examples
* /hadoop/common/branches/branch-0.23/hadoop-mapreduce-project/src/java
* /hadoop/common/branches/branch-0.23/hadoop-mapreduce-project/src/test/mapred
* /hadoop/common/branches/branch-0.23/hadoop-mapreduce-project/src/test/mapred/org/apache/hadoop/fs
* /hadoop/common/branches/branch-0.23/hadoop-mapreduce-project/src/test/mapred/org/apache/hadoop/hdfs
* /hadoop/common/branches/branch-0.23/hadoop-mapreduce-project/src/test/mapred/org/apache/hadoop/io/FileBench.java
* /hadoop/common/branches/branch-0.23/hadoop-mapreduce-project/src/test/mapred/org/apache/hadoop/io/TestSequenceFileMergeProgress.java
* /hadoop/common/branches/branch-0.23/hadoop-mapreduce-project/src/test/mapred/org/apache/hadoop/ipc
* /hadoop/common/branches/branch-0.23/hadoop-mapreduce-project/src/test/mapred/org/apache/hadoop/security/authorize/TestServiceLevelAuthorization.java
* /hadoop/common/branches/branch-0.23/hadoop-mapreduce-project/src/test/mapred/org/apache/hadoop/test/MapredTestDriver.java
* /hadoop/common/branches/branch-0.23/hadoop-mapreduce-project/src/webapps/job
","21/Nov/11 07:29;eli;I've committed this and merged to 22 and 23.","21/Nov/11 07:55;hudson;Integrated in Hadoop-Mapreduce-trunk-Commit #1321 (See [https://builds.apache.org/job/Hadoop-Mapreduce-trunk-Commit/1321/])
    HADOOP-7783. Add more symlink tests that cover intermediate links. Contributed by Eli Collins

eli : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1204376
Files : 
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/CHANGES.txt
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/AbstractFileSystem.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/FileContext.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/Path.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/FileContextSymlinkBaseTest.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/TestPath.java
","21/Nov/11 13:05;hudson;Integrated in Hadoop-Mapreduce-0.23-Build #100 (See [https://builds.apache.org/job/Hadoop-Mapreduce-0.23-Build/100/])
    HADOOP-7783. svn merge -c 1204376 from trunk

eli : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1204377
Files : 
* /hadoop/common/branches/branch-0.23
* /hadoop/common/branches/branch-0.23/hadoop-common-project
* /hadoop/common/branches/branch-0.23/hadoop-common-project/hadoop-auth
* /hadoop/common/branches/branch-0.23/hadoop-common-project/hadoop-common
* /hadoop/common/branches/branch-0.23/hadoop-common-project/hadoop-common/CHANGES.txt
* /hadoop/common/branches/branch-0.23/hadoop-common-project/hadoop-common/src/main/docs
* /hadoop/common/branches/branch-0.23/hadoop-common-project/hadoop-common/src/main/java
* /hadoop/common/branches/branch-0.23/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/AbstractFileSystem.java
* /hadoop/common/branches/branch-0.23/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/FileContext.java
* /hadoop/common/branches/branch-0.23/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/Path.java
* /hadoop/common/branches/branch-0.23/hadoop-common-project/hadoop-common/src/test/core
* /hadoop/common/branches/branch-0.23/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/FileContextSymlinkBaseTest.java
* /hadoop/common/branches/branch-0.23/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/TestPath.java
* /hadoop/common/branches/branch-0.23/hadoop-hdfs-project/hadoop-hdfs
* /hadoop/common/branches/branch-0.23/hadoop-hdfs-project/hadoop-hdfs/src/main/java
* /hadoop/common/branches/branch-0.23/hadoop-hdfs-project/hadoop-hdfs/src/main/native
* /hadoop/common/branches/branch-0.23/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode
* /hadoop/common/branches/branch-0.23/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/hdfs
* /hadoop/common/branches/branch-0.23/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/secondary
* /hadoop/common/branches/branch-0.23/hadoop-hdfs-project/hadoop-hdfs/src/test/hdfs
* /hadoop/common/branches/branch-0.23/hadoop-mapreduce-project
* /hadoop/common/branches/branch-0.23/hadoop-mapreduce-project/.gitignore
* /hadoop/common/branches/branch-0.23/hadoop-mapreduce-project/CHANGES.txt
* /hadoop/common/branches/branch-0.23/hadoop-mapreduce-project/bin
* /hadoop/common/branches/branch-0.23/hadoop-mapreduce-project/conf
* /hadoop/common/branches/branch-0.23/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/resources/mapred-default.xml
* /hadoop/common/branches/branch-0.23/hadoop-mapreduce-project/src/c++
* /hadoop/common/branches/branch-0.23/hadoop-mapreduce-project/src/contrib
* /hadoop/common/branches/branch-0.23/hadoop-mapreduce-project/src/contrib/block_forensics
* /hadoop/common/branches/branch-0.23/hadoop-mapreduce-project/src/contrib/build-contrib.xml
* /hadoop/common/branches/branch-0.23/hadoop-mapreduce-project/src/contrib/build.xml
* /hadoop/common/branches/branch-0.23/hadoop-mapreduce-project/src/contrib/data_join
* /hadoop/common/branches/branch-0.23/hadoop-mapreduce-project/src/contrib/eclipse-plugin
* /hadoop/common/branches/branch-0.23/hadoop-mapreduce-project/src/contrib/index
* /hadoop/common/branches/branch-0.23/hadoop-mapreduce-project/src/contrib/streaming
* /hadoop/common/branches/branch-0.23/hadoop-mapreduce-project/src/contrib/vaidya
* /hadoop/common/branches/branch-0.23/hadoop-mapreduce-project/src/examples
* /hadoop/common/branches/branch-0.23/hadoop-mapreduce-project/src/java
* /hadoop/common/branches/branch-0.23/hadoop-mapreduce-project/src/test/mapred
* /hadoop/common/branches/branch-0.23/hadoop-mapreduce-project/src/test/mapred/org/apache/hadoop/fs
* /hadoop/common/branches/branch-0.23/hadoop-mapreduce-project/src/test/mapred/org/apache/hadoop/hdfs
* /hadoop/common/branches/branch-0.23/hadoop-mapreduce-project/src/test/mapred/org/apache/hadoop/io/FileBench.java
* /hadoop/common/branches/branch-0.23/hadoop-mapreduce-project/src/test/mapred/org/apache/hadoop/io/TestSequenceFileMergeProgress.java
* /hadoop/common/branches/branch-0.23/hadoop-mapreduce-project/src/test/mapred/org/apache/hadoop/ipc
* /hadoop/common/branches/branch-0.23/hadoop-mapreduce-project/src/test/mapred/org/apache/hadoop/security/authorize/TestServiceLevelAuthorization.java
* /hadoop/common/branches/branch-0.23/hadoop-mapreduce-project/src/test/mapred/org/apache/hadoop/test/MapredTestDriver.java
* /hadoop/common/branches/branch-0.23/hadoop-mapreduce-project/src/webapps/job
","21/Nov/11 13:17;hudson;Integrated in Hadoop-Common-22-branch #97 (See [https://builds.apache.org/job/Hadoop-Common-22-branch/97/])
    HADOOP-7783. svn merge -c 1204376 from trunk

eli : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1204379
Files : 
* /hadoop/common/branches/branch-0.22/common/src/java/org/apache/hadoop/fs/AbstractFileSystem.java
* /hadoop/common/branches/branch-0.22/common/src/java/org/apache/hadoop/fs/FileContext.java
* /hadoop/common/branches/branch-0.22/common/src/java/org/apache/hadoop/fs/Path.java
* /hadoop/common/branches/branch-0.22/common/src/test/core/org/apache/hadoop/fs/FileContextSymlinkBaseTest.java
* /hadoop/common/branches/branch-0.22/common/src/test/core/org/apache/hadoop/fs/TestPath.java
","21/Nov/11 13:28;hudson;Integrated in Hadoop-Mapreduce-trunk #904 (See [https://builds.apache.org/job/Hadoop-Mapreduce-trunk/904/])
    HADOOP-7783. Add more symlink tests that cover intermediate links. Contributed by Eli Collins

eli : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1204376
Files : 
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/CHANGES.txt
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/AbstractFileSystem.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/FileContext.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/Path.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/FileContextSymlinkBaseTest.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/TestPath.java
","21/Nov/11 14:15;hudson;Integrated in Hadoop-Hdfs-0.23-Build #83 (See [https://builds.apache.org/job/Hadoop-Hdfs-0.23-Build/83/])
    HADOOP-7783. svn merge -c 1204376 from trunk

eli : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1204377
Files : 
* /hadoop/common/branches/branch-0.23
* /hadoop/common/branches/branch-0.23/hadoop-common-project
* /hadoop/common/branches/branch-0.23/hadoop-common-project/hadoop-auth
* /hadoop/common/branches/branch-0.23/hadoop-common-project/hadoop-common
* /hadoop/common/branches/branch-0.23/hadoop-common-project/hadoop-common/CHANGES.txt
* /hadoop/common/branches/branch-0.23/hadoop-common-project/hadoop-common/src/main/docs
* /hadoop/common/branches/branch-0.23/hadoop-common-project/hadoop-common/src/main/java
* /hadoop/common/branches/branch-0.23/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/AbstractFileSystem.java
* /hadoop/common/branches/branch-0.23/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/FileContext.java
* /hadoop/common/branches/branch-0.23/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/Path.java
* /hadoop/common/branches/branch-0.23/hadoop-common-project/hadoop-common/src/test/core
* /hadoop/common/branches/branch-0.23/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/FileContextSymlinkBaseTest.java
* /hadoop/common/branches/branch-0.23/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/TestPath.java
* /hadoop/common/branches/branch-0.23/hadoop-hdfs-project/hadoop-hdfs
* /hadoop/common/branches/branch-0.23/hadoop-hdfs-project/hadoop-hdfs/src/main/java
* /hadoop/common/branches/branch-0.23/hadoop-hdfs-project/hadoop-hdfs/src/main/native
* /hadoop/common/branches/branch-0.23/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/datanode
* /hadoop/common/branches/branch-0.23/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/hdfs
* /hadoop/common/branches/branch-0.23/hadoop-hdfs-project/hadoop-hdfs/src/main/webapps/secondary
* /hadoop/common/branches/branch-0.23/hadoop-hdfs-project/hadoop-hdfs/src/test/hdfs
* /hadoop/common/branches/branch-0.23/hadoop-mapreduce-project
* /hadoop/common/branches/branch-0.23/hadoop-mapreduce-project/.gitignore
* /hadoop/common/branches/branch-0.23/hadoop-mapreduce-project/CHANGES.txt
* /hadoop/common/branches/branch-0.23/hadoop-mapreduce-project/bin
* /hadoop/common/branches/branch-0.23/hadoop-mapreduce-project/conf
* /hadoop/common/branches/branch-0.23/hadoop-mapreduce-project/hadoop-mapreduce-client/hadoop-mapreduce-client-core/src/main/resources/mapred-default.xml
* /hadoop/common/branches/branch-0.23/hadoop-mapreduce-project/src/c++
* /hadoop/common/branches/branch-0.23/hadoop-mapreduce-project/src/contrib
* /hadoop/common/branches/branch-0.23/hadoop-mapreduce-project/src/contrib/block_forensics
* /hadoop/common/branches/branch-0.23/hadoop-mapreduce-project/src/contrib/build-contrib.xml
* /hadoop/common/branches/branch-0.23/hadoop-mapreduce-project/src/contrib/build.xml
* /hadoop/common/branches/branch-0.23/hadoop-mapreduce-project/src/contrib/data_join
* /hadoop/common/branches/branch-0.23/hadoop-mapreduce-project/src/contrib/eclipse-plugin
* /hadoop/common/branches/branch-0.23/hadoop-mapreduce-project/src/contrib/index
* /hadoop/common/branches/branch-0.23/hadoop-mapreduce-project/src/contrib/streaming
* /hadoop/common/branches/branch-0.23/hadoop-mapreduce-project/src/contrib/vaidya
* /hadoop/common/branches/branch-0.23/hadoop-mapreduce-project/src/examples
* /hadoop/common/branches/branch-0.23/hadoop-mapreduce-project/src/java
* /hadoop/common/branches/branch-0.23/hadoop-mapreduce-project/src/test/mapred
* /hadoop/common/branches/branch-0.23/hadoop-mapreduce-project/src/test/mapred/org/apache/hadoop/fs
* /hadoop/common/branches/branch-0.23/hadoop-mapreduce-project/src/test/mapred/org/apache/hadoop/hdfs
* /hadoop/common/branches/branch-0.23/hadoop-mapreduce-project/src/test/mapred/org/apache/hadoop/io/FileBench.java
* /hadoop/common/branches/branch-0.23/hadoop-mapreduce-project/src/test/mapred/org/apache/hadoop/io/TestSequenceFileMergeProgress.java
* /hadoop/common/branches/branch-0.23/hadoop-mapreduce-project/src/test/mapred/org/apache/hadoop/ipc
* /hadoop/common/branches/branch-0.23/hadoop-mapreduce-project/src/test/mapred/org/apache/hadoop/security/authorize/TestServiceLevelAuthorization.java
* /hadoop/common/branches/branch-0.23/hadoop-mapreduce-project/src/test/mapred/org/apache/hadoop/test/MapredTestDriver.java
* /hadoop/common/branches/branch-0.23/hadoop-mapreduce-project/src/webapps/job
","21/Nov/11 14:41;hudson;Integrated in Hadoop-Hdfs-trunk #870 (See [https://builds.apache.org/job/Hadoop-Hdfs-trunk/870/])
    HADOOP-7783. Add more symlink tests that cover intermediate links. Contributed by Eli Collins

eli : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1204376
Files : 
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/CHANGES.txt
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/AbstractFileSystem.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/FileContext.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/Path.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/FileContextSymlinkBaseTest.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/TestPath.java
","21/Nov/11 19:27;shv;Eli, you forgot to update CHANGES.txt for 0.22 commit.","21/Nov/11 19:56;eli;Fixed.","21/Nov/11 21:43;hudson;Integrated in Hadoop-Common-22-branch #98 (See [https://builds.apache.org/job/Hadoop-Common-22-branch/98/])
    Add HADOOP-7783 to CHANGES.txt

eli : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1204671
Files : 
* /hadoop/common/branches/branch-0.22/common/CHANGES.txt
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
test for ByteWritable comparator,HADOOP-6934,12472782,Test,Closed,HADOOP,Hadoop Common,software,omalley,Hadoop Common is the common library for Apache Hadoop.,http://hadoop.apache.org/,Major,Fixed,oae,oae,oae,28/Aug/10 17:49,12/Dec/11 06:19,12/Jan/21 11:55,02/Sep/10 06:28,0.21.1,0.22.0,,,0.21.1,0.22.0,,,,,record,,,,0,,,"The test for the ByteWritable comparator bug (see HADOOP-6928), which is already fixed in 0.21.",,garymurry,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,HADOOP-6928,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"02/Sep/10 02:00;eli;h-6934-2.patch;https://issues.apache.org/jira/secure/attachment/12453649/h-6934-2.patch","28/Aug/10 17:55;oae;h-6934.patch;https://issues.apache.org/jira/secure/attachment/12453357/h-6934.patch",,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,2010-08-31 20:58:42.073,,,false,,,,,,,,,,,,,,,,,127455,Reviewed,,,,Wed Sep 15 17:31:24 UTC 2010,,,,,,,"0|i0hyp3:",102883,,,,,,,,,,,,,,,,,,,,,,,"28/Aug/10 17:55;oae;Patch [^h-6934.patch] with the test attached.","31/Aug/10 20:58;gkesavan;re-submiting to test hudson patch testing","02/Sep/10 02:00;eli;+1  (same test from HADOOP-6934)

Updated patch to be junit-4 style.","02/Sep/10 06:28;eli;I've commited this (it just adds a test and that test passes).  Thanks Johannes!","02/Sep/10 06:44;hudson;Integrated in Hadoop-Common-trunk-Commit #372 (See [https://hudson.apache.org/hudson/job/Hadoop-Common-trunk-Commit/372/])
    HADOOP-6934. Test for ByteWritable comparator. Contributed by Johannes Zillmann.
","02/Sep/10 11:19;hudson;Integrated in Hadoop-Common-trunk #441 (See [https://hudson.apache.org/hudson/job/Hadoop-Common-trunk/441/])
    HADOOP-6934. Test for ByteWritable comparator. Contributed by Johannes Zillmann.
","03/Sep/10 06:32;omalley;Shouldn't this be fixed in the 0.21 branch too?","15/Sep/10 16:25;eli;Yes, I'll merge it.","15/Sep/10 17:31;eli;I merged this into 21.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Create a test method for adding file systems during tests.,HADOOP-7024,12479540,Test,Closed,HADOOP,Hadoop Common,software,omalley,Hadoop Common is the common library for Apache Hadoop.,http://hadoop.apache.org/,Major,Fixed,kzhang,kzhang,kzhang,10/Nov/10 00:04,12/Dec/11 06:19,12/Jan/21 11:55,11/Nov/10 22:36,0.22.0,,,,0.22.0,,,,,,test,,,,0,,,It allows a (mocked) filesystem object to be added to cache for testing purposes. This is used by HDFS-1187.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,HDFS-1187,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"10/Nov/10 00:04;kzhang;c1178-03.patch;https://issues.apache.org/jira/secure/attachment/12459200/c1178-03.patch","11/Nov/10 21:35;kzhang;c1178-04.patch;https://issues.apache.org/jira/secure/attachment/12459385/c1178-04.patch",,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,2010-11-10 00:35:50.872,,,false,,,,,,,,,,,,,,,,,127493,Reviewed,,,,Fri Nov 12 17:59:45 UTC 2010,,,,,,,"0|i0hybb:",102821,,,,,,,,,,,,,,,,,,,,,,,"10/Nov/10 00:35;hadoopqa;-1 overall.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12459200/c1178-03.patch
  against trunk revision 1032730.

    +1 @author.  The patch does not contain any @author tags.

    -1 tests included.  The patch doesn't appear to include any new or modified tests.
                        Please justify why no new tests are needed for this patch.
                        Also please list what manual steps were performed to verify this patch.

    +1 javadoc.  The javadoc tool did not generate any warning messages.

    +1 javac.  The applied patch does not increase the total number of javac compiler warnings.

    +1 findbugs.  The patch does not introduce any new Findbugs warnings.

    +1 release audit.  The applied patch does not increase the total number of release audit warnings.

    +1 core tests.  The patch passed core unit tests.

    +1 contrib tests.  The patch passed contrib unit tests.

    +1 system test framework.  The patch passed system test framework compile.

Test results: https://hudson.apache.org/hudson/job/PreCommit-HADOOP-Build/83//testReport/
Findbugs warnings: https://hudson.apache.org/hudson/job/PreCommit-HADOOP-Build/83//artifact/trunk/build/test/findbugs/newPatchFindbugsWarnings.html
Console output: https://hudson.apache.org/hudson/job/PreCommit-HADOOP-Build/83//console

This message is automatically generated.","10/Nov/10 00:44;kzhang;It's an internal method for unit testing only and will be used by TestDelegationTokenFetcher in HDFS. ","10/Nov/10 23:57;cos;Would it be more appropriate to have this potentially dangerous method to have a package private visibility and then add a public wrapper in a test utility class?","11/Nov/10 21:35;kzhang;Cos, thanks for your suggestion. I'm attaching a new patch to address it. Please review.","11/Nov/10 22:00;hadoopqa;+1 overall.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12459385/c1178-04.patch
  against trunk revision 1033812.

    +1 @author.  The patch does not contain any @author tags.

    +1 tests included.  The patch appears to include 3 new or modified tests.

    +1 javadoc.  The javadoc tool did not generate any warning messages.

    +1 javac.  The applied patch does not increase the total number of javac compiler warnings.

    +1 findbugs.  The patch does not introduce any new Findbugs warnings.

    +1 release audit.  The applied patch does not increase the total number of release audit warnings.

    +1 core tests.  The patch passed core unit tests.

    +1 contrib tests.  The patch passed contrib unit tests.

    +1 system test framework.  The patch passed system test framework compile.

Test results: https://hudson.apache.org/hudson/job/PreCommit-HADOOP-Build/92//testReport/
Findbugs warnings: https://hudson.apache.org/hudson/job/PreCommit-HADOOP-Build/92//artifact/trunk/build/test/findbugs/newPatchFindbugsWarnings.html
Console output: https://hudson.apache.org/hudson/job/PreCommit-HADOOP-Build/92//console

This message is automatically generated.","11/Nov/10 22:25;jghoman;Great suggestion Cos.  +1 on the patch.","11/Nov/10 22:36;jghoman;I've committed this.  Resolving as fixed.  Thanks, Kan!","12/Nov/10 06:04;cos;Sorry, missed the comments - patch looks great! Thanks Kan.","12/Nov/10 11:27;hudson;Integrated in Hadoop-Common-trunk #510 (See [https://hudson.apache.org/hudson/job/Hadoop-Common-trunk/510/])
    HADOOP-7024. Create a test method for adding file systems during tests.  Contributed by Kan Zhang.
","12/Nov/10 17:59;hudson;Integrated in Hadoop-Common-trunk-Commit #422 (See [https://hudson.apache.org/hudson/job/Hadoop-Common-trunk-Commit/422/])
    ",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Add native gzip read/write coverage to TestCodec ,HADOOP-6803,12466018,Test,Closed,HADOOP,Hadoop Common,software,omalley,Hadoop Common is the common library for Apache Hadoop.,http://hadoop.apache.org/,Major,Fixed,eli,eli,eli,02/Jun/10 23:11,12/Dec/11 06:19,12/Jan/21 11:55,18/Aug/10 21:59,0.22.0,,,,0.22.0,,,,,,io,,,,0,,,"Looking at ZlibCompressor I noticed that the finished member is never modified, and is therefore always false. This means ZlibCompressor#finished will always return false so CompressorStream#close loops indefinitely in finish:

{code} 
      while (!compressor.finished()) {
        compress();
      }
{code}

I modifed TestCodec#testGzipCodecWrite to also cover writing using the native lib and confirmed the hang with jstack. The fix is simple, ZlibCompressor should record when it's been finished.",,cdouglas,Fan04290,hammer,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"02/Jun/10 23:12;eli;hadoop-6803-1.patch;https://issues.apache.org/jira/secure/attachment/12446195/hadoop-6803-1.patch","03/Jun/10 00:14;eli;hadoop-6803-2.patch;https://issues.apache.org/jira/secure/attachment/12446204/hadoop-6803-2.patch","17/Aug/10 22:25;eli;hadoop-6803-3.patch;https://issues.apache.org/jira/secure/attachment/12452333/hadoop-6803-3.patch",,,,,,,,,,,,,,,,,,,,,3.0,,,,,,,,,,,,,,,,,,,,2010-06-02 23:36:44.686,,,false,,,,,,,,,,,,,,,,,127405,Reviewed,,,,Thu Aug 19 11:21:20 UTC 2010,,,,,,,"0|i0hz6f:",102961,,,,,,,,,,,,,,,,,,,,,,,"02/Jun/10 23:12;eli;Patch attached.","02/Jun/10 23:15;eli;I confirmed the test passes locally with the native lib built.  On hudson the native test should warn and bail if the native library is not built when the test is run.","02/Jun/10 23:36;cdouglas;Isn't the {{finished}} member set by the JNI code?","03/Jun/10 00:11;eli;Your right, I forgot that methods not fields have the ""native"" modifier. The ""finish"" field is read from the native code and ""finished"" is updated there so it looks like it should work.   What's strange is if I revert the change to ZlibCompressor it passes now, earlier when I first added the test and ran with the native lib it hung with jstack showing the following:

{code}
""main"" prio=10 tid=0x0000000040b19000 nid=0x36f0 runnable [0x00007f1257588000]
   java.lang.Thread.State: RUNNABLE
        at org.apache.hadoop.io.compress.zlib.ZlibCompressor.deflateBytesDirect(Native Method)
        at org.apache.hadoop.io.compress.zlib.ZlibCompressor.compress(ZlibCompressor.java:359)
        - locked <0x00007f12495063e0> (a org.apache.hadoop.io.compress.GzipCodec$GzipZlibCompressor)
        at org.apache.hadoop.io.compress.CompressorStream.compress(CompressorStream.java:76)
        at org.apache.hadoop.io.compress.CompressorStream.finish(CompressorStream.java:86)
        at org.apache.hadoop.io.compress.CompressorStream.close(CompressorStream.java:97)
        at sun.nio.cs.StreamEncoder.implClose(StreamEncoder.java:301)
        at sun.nio.cs.StreamEncoder.close(StreamEncoder.java:130)
        - locked <0x00007f12495167c8> (a java.io.OutputStreamWriter)
        at java.io.OutputStreamWriter.close(OutputStreamWriter.java:216)
        at java.io.BufferedWriter.close(BufferedWriter.java:248)
        - locked <0x00007f12495167c8> (a java.io.OutputStreamWriter)
        at org.apache.hadoop.io.compress.TestCodec.testGzipCodecWrite(TestCodec.java:653)
{code}
","03/Jun/10 00:14;eli;Attached patch. Reverts the ZlibCompressor change, keeps the test.  Thanks Chris.","03/Jun/10 00:17;eli;I figured it out. In the earlier change I had remove the synchronized modifier from ZlibCompressor#finished which would cause the jvm to miss the update from the jni code.  ","03/Jun/10 19:25;hadoopqa;+1 overall.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12446204/hadoop-6803-2.patch
  against trunk revision 951081.

    +1 @author.  The patch does not contain any @author tags.

    +1 tests included.  The patch appears to include 3 new or modified tests.

    +1 javadoc.  The javadoc tool did not generate any warning messages.

    +1 javac.  The applied patch does not increase the total number of javac compiler warnings.

    +1 findbugs.  The patch does not introduce any new Findbugs warnings.

    +1 release audit.  The applied patch does not increase the total number of release audit warnings.

    +1 core tests.  The patch passed core unit tests.

    +1 contrib tests.  The patch passed contrib unit tests.

Test results: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch-h1.grid.sp2.yahoo.net/75/testReport/
Findbugs warnings: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch-h1.grid.sp2.yahoo.net/75/artifact/trunk/build/test/findbugs/newPatchFindbugsWarnings.html
Checkstyle results: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch-h1.grid.sp2.yahoo.net/75/artifact/trunk/build/test/checkstyle-errors.html
Console output: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch-h1.grid.sp2.yahoo.net/75/console

This message is automatically generated.","17/Aug/10 22:25;eli;Updated patch resolves with trunk.","17/Aug/10 22:46;tomwhite;+1 Looks good.","18/Aug/10 21:59;tomwhite;I've just committed this. Thanks Eli!","18/Aug/10 22:22;hudson;Integrated in Hadoop-Common-trunk-Commit #360 (See [https://hudson.apache.org/hudson/job/Hadoop-Common-trunk-Commit/360/])
    HADOOP-6803. Add native gzip read/write coverage to TestCodec. Contributed by Eli Collins.
","19/Aug/10 11:21;hudson;Integrated in Hadoop-Common-trunk #428 (See [https://hudson.apache.org/hudson/job/Hadoop-Common-trunk/428/])
    HADOOP-6803. Add native gzip read/write coverage to TestCodec. Contributed by Eli Collins.
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Add TestPath tests to cover dot, dot dot, and slash normalization",HADOOP-7034,12479900,Test,Closed,HADOOP,Hadoop Common,software,omalley,Hadoop Common is the common library for Apache Hadoop.,http://hadoop.apache.org/,Major,Fixed,eli,eli,eli,14/Nov/10 07:31,12/Dec/11 06:18,12/Jan/21 11:55,15/Nov/10 04:58,0.22.0,,,,0.22.0,,,,,,fs,,,,0,,,"Add tests for the current path normalization for dot, dot dot, and slash in TestPath (from HDFS-836).",,Fan04290,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"14/Nov/10 07:34;eli;hadoop-7034-1.patch;https://issues.apache.org/jira/secure/attachment/12459548/hadoop-7034-1.patch",,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,2010-11-14 08:02:46.093,,,false,,,,,,,,,,,,,,,,,127500,Reviewed,,,,Tue Nov 16 11:23:22 UTC 2010,,,,,,,"0|i0hy9r:",102814,,,,,,,,,,,,,,,,,,,,,,,"14/Nov/10 07:34;eli;Patch attached.  This is pretty trivial, just adds three asserts to TestPath#testNormalize.  TestPath passes.  ","14/Nov/10 08:02;hadoopqa;-1 overall.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12459548/hadoop-7034-1.patch
  against trunk revision 1034480.

    +1 @author.  The patch does not contain any @author tags.

    +1 tests included.  The patch appears to include 3 new or modified tests.

    -1 javadoc.  The javadoc tool appears to have generated 1 warning messages.

    +1 javac.  The applied patch does not increase the total number of javac compiler warnings.

    +1 findbugs.  The patch does not introduce any new Findbugs warnings.

    +1 release audit.  The applied patch does not increase the total number of release audit warnings.

    +1 core tests.  The patch passed core unit tests.

    +1 contrib tests.  The patch passed contrib unit tests.

    +1 system test framework.  The patch passed system test framework compile.

Test results: https://hudson.apache.org/hudson/job/PreCommit-HADOOP-Build/102//testReport/
Findbugs warnings: https://hudson.apache.org/hudson/job/PreCommit-HADOOP-Build/102//artifact/trunk/build/test/findbugs/newPatchFindbugsWarnings.html
Console output: https://hudson.apache.org/hudson/job/PreCommit-HADOOP-Build/102//console

This message is automatically generated.","14/Nov/10 09:18;eli;Not sure what the javadoc warning is about, I see 7 warnings with and w/o my change. ","14/Nov/10 20:39;cos;+1 patch looks good.","15/Nov/10 04:58;eli;Thanks Cos.  I've committed this.","15/Nov/10 05:24;hudson;Integrated in Hadoop-Common-trunk-Commit #423 (See [https://hudson.apache.org/hudson/job/Hadoop-Common-trunk-Commit/423/])
    HADOOP-7034. Add TestPath tests to cover dot, dot dot, and slash normalization. Contributed by Eli Collins
","16/Nov/10 11:23;hudson;Integrated in Hadoop-Common-trunk #514 (See [https://hudson.apache.org/hudson/job/Hadoop-Common-trunk/514/])
    ",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Move -fs usage tests from hdfs into common,HADOOP-7230,12504569,Test,Closed,HADOOP,Hadoop Common,software,omalley,Hadoop Common is the common library for Apache Hadoop.,http://hadoop.apache.org/,Major,Fixed,daryn,daryn,daryn,18/Apr/11 17:25,15/Nov/11 00:50,12/Jan/21 11:55,18/Apr/11 21:23,0.23.0,,,,0.23.0,,,,,,test,,,,0,,,"The -fs usage tests are in hdfs which causes an unnecessary synchronization of a common & hdfs bug when changing the text.  The usages have no ties to hdfs, so they should be moved into common.",,atm,szetszwo,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,HDFS-1844,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"18/Apr/11 17:34;daryn;HADOOP-7230.patch;https://issues.apache.org/jira/secure/attachment/12476633/HADOOP-7230.patch",,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,2011-04-18 19:34:54.52,,,false,,,,,,,,,,,,,,,,,92166,Reviewed,,,,Fri Apr 22 11:12:25 UTC 2011,,,,,,,"0|i09kb3:",53723,,,,,,,,,,,,,,,,,,,,,,,"18/Apr/11 17:34;daryn;Copy all the fs -help tests into common.  Will remove from hdfs after this change is committed.","18/Apr/11 19:34;atm;Thanks a lot for this, Daryn. I've reviewed the code and it looks good to me.","18/Apr/11 19:37;atm;Also, I don't think the precommit Hudson job is working at the moment for common, so you might want to run it and paste the results here yourself.","18/Apr/11 20:53;daryn;     [exec] +1 overall.  
     [exec] 
     [exec]     +1 @author.  The patch does not contain any @author tags.
     [exec] 
     [exec]     +1 tests included.  The patch appears to include 61 new or modified tests.
     [exec] 
     [exec]     +1 javadoc.  The javadoc tool did not generate any warning messages.
     [exec] 
     [exec]     +1 javac.  The applied patch does not increase the total number of javac compiler warnings.
     [exec] 
     [exec]     +1 findbugs.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.
     [exec] 
     [exec]     +1 release audit.  The applied patch does not increase the total number of release audit warnings.
     [exec] 
     [exec]     +1 system test framework.  The patch passed system test framework compile.","18/Apr/11 21:00;atm;+1","18/Apr/11 21:10;hadoopqa;+1 overall.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12476633/HADOOP-7230.patch
  against trunk revision 1092853.

    +1 @author.  The patch does not contain any @author tags.

    +1 tests included.  The patch appears to include 61 new or modified tests.

    +1 javadoc.  The javadoc tool did not generate any warning messages.

    +1 javac.  The applied patch does not increase the total number of javac compiler warnings.

    +1 findbugs.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    +1 release audit.  The applied patch does not increase the total number of release audit warnings.

    +1 core tests.  The patch passed core unit tests.

    +1 contrib tests.  The patch passed contrib unit tests.

    +1 system test framework.  The patch passed system test framework compile.

Test results: https://hudson.apache.org/hudson/job/PreCommit-HADOOP-Build/350//testReport/
Findbugs warnings: https://hudson.apache.org/hudson/job/PreCommit-HADOOP-Build/350//artifact/trunk/build/test/findbugs/newPatchFindbugsWarnings.html
Console output: https://hudson.apache.org/hudson/job/PreCommit-HADOOP-Build/350//console

This message is automatically generated.","18/Apr/11 21:23;szetszwo;I have committed this.  Thanks, Daryn!

Thanks also Aaron for reviewing it.","18/Apr/11 21:33;hudson;Integrated in Hadoop-Common-trunk-Commit #558 (See [https://hudson.apache.org/hudson/job/Hadoop-Common-trunk-Commit/558/])
    HADOOP-7230. Move ""fs -help"" shell command tests from HDFS to COMMOM.  Contributed by Daryn Sharp
","22/Apr/11 11:12;hudson;Integrated in Hadoop-Common-trunk #666 (See [https://builds.apache.org/hudson/job/Hadoop-Common-trunk/666/])
    HADOOP-7230. Move ""fs -help"" shell command tests from HDFS to COMMOM.  Contributed by Daryn Sharp
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Add test utility for writing multi-threaded tests,HADOOP-7298,12507560,Test,Closed,HADOOP,Hadoop Common,software,omalley,Hadoop Common is the common library for Apache Hadoop.,http://hadoop.apache.org/,Major,Fixed,tlipcon,tlipcon,tlipcon,18/May/11 05:20,15/Nov/11 00:50,12/Jan/21 11:55,25/Jul/11 21:11,0.22.0,,,,0.22.0,0.23.0,,,,,test,,,,0,,,"A lot of our tests spawn off multiple threads in order to check various synchronization issues, etc. It's often tedious to write these kinds of tests because you have to manually propagate exceptions back to the main thread, etc.

In HBase we have developed a testing utility which makes writing these kinds of tests much easier. I'd like to copy that utility into Hadoop so we can use it here as well.",,atm,cdouglas,devaraj,eli,Fan04290,mattf,qwertymaniac,sudhan65,sureshms,,,,,,,,,,,,,,,,,,,,,,,,,MAPREDUCE-1347,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"19/Jul/11 13:23;qwertymaniac;hadoop-7298.txt;https://issues.apache.org/jira/secure/attachment/12487006/hadoop-7298.txt","25/Jun/11 09:16;qwertymaniac;hadoop-7298.txt;https://issues.apache.org/jira/secure/attachment/12483809/hadoop-7298.txt","18/May/11 05:45;tlipcon;hadoop-7298.txt;https://issues.apache.org/jira/secure/attachment/12479550/hadoop-7298.txt",,,,,,,,,,,,,,,,,,,,,3.0,,,,,,,,,,,,,,,,,,,,2011-05-19 08:43:31.936,,,false,,,,,,,,,,,,,,,,,66899,Reviewed,,,,Tue Jul 26 19:48:36 UTC 2011,,,,,,,"0|i09k0f:",53675,,,,,,,,,,,,,,,,,,,,,,,"18/May/11 05:23;tlipcon;The HBase class lives here:
http://svn.apache.org/repos/asf/hbase/trunk/src/test/java/org/apache/hadoop/hbase/MultithreadedTestUtil.java

For an example usage, see testLABThreading in the following test:
http://svn.apache.org/repos/asf/hbase/trunk/src/test/java/org/apache/hadoop/hbase/regionserver/TestMemStoreLAB.java","18/May/11 05:45;tlipcon;Cleaned up the hbase utility a bit and added test cases for the test utility.

I think this will make a nice building block to build some stress/fuzz tests for the namenode for HDFS-988. But, no need to commit it until such a test is ready.","19/May/11 08:43;sureshms;Todd, given that this is a utility based on which tests are going to be written, can you add javadoc and possibly examples or brief description on how to use it.","25/Jun/11 09:16;qwertymaniac;Ditto code patch attached, with following changes:

+JavaDocs
-Whitespaces","25/Jun/11 09:43;hadoopqa;+1 overall.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12483809/hadoop-7298.txt
  against trunk revision 1139476.

    +1 @author.  The patch does not contain any @author tags.

    +1 tests included.  The patch appears to include 4 new or modified tests.

    +1 javadoc.  The javadoc tool did not generate any warning messages.

    +1 javac.  The applied patch does not increase the total number of javac compiler warnings.

    +1 findbugs.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    +1 release audit.  The applied patch does not increase the total number of release audit warnings.

    +1 core tests.  The patch passed core unit tests.

    +1 system test framework.  The patch passed system test framework compile.

Test results: https://builds.apache.org/job/PreCommit-HADOOP-Build/673//testReport/
Findbugs warnings: https://builds.apache.org/job/PreCommit-HADOOP-Build/673//artifact/trunk/build/test/findbugs/newPatchFindbugsWarnings.html
Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/673//console

This message is automatically generated.","28/Jun/11 19:42;tlipcon;Looks good to me. Suresh, mind looking at this latest patch? Harsh's patch for MAPREDUCE-1347 depends on this.","08/Jul/11 11:35;sureshms;+1","13/Jul/11 05:43;cos;Todd, won't class {{TestThread}} be picked up by ant junit task? I'd suggest to change it {{ThreadTest}} to avoid it.","19/Jul/11 13:23;qwertymaniac;Refactored {{TestThread}} to {{TestingThread}}. Updating the MAPREDUCE-1347 patch accordingly.","19/Jul/11 13:42;hadoopqa;+1 overall.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12487006/hadoop-7298.txt
  against trunk revision 1147971.

    +1 @author.  The patch does not contain any @author tags.

    +1 tests included.  The patch appears to include 4 new or modified tests.

    +1 javadoc.  The javadoc tool did not generate any warning messages.

    +1 javac.  The applied patch does not increase the total number of javac compiler warnings.

    +1 findbugs.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    +1 release audit.  The applied patch does not increase the total number of release audit warnings.

    +1 core tests.  The patch passed core unit tests.

    +1 system test framework.  The patch passed system test framework compile.

Test results: https://builds.apache.org/job/PreCommit-HADOOP-Build/746//testReport/
Findbugs warnings: https://builds.apache.org/job/PreCommit-HADOOP-Build/746//artifact/trunk/build/test/findbugs/newPatchFindbugsWarnings.html
Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/746//console

This message is automatically generated.","25/Jul/11 08:30;qwertymaniac;If there are no more comments, and things look good in this patch, then can this go in so MAPREDUCE-1347 may be re-reviewed+resolved as well?

Thanks for all the reviews! :)","25/Jul/11 21:11;tlipcon;Committed to trunk and 22. (22 since it's only test code and necessary for the bug fix MAPREDUCE-1347)","25/Jul/11 21:26;hudson;Integrated in Hadoop-Common-trunk-Commit #698 (See [https://builds.apache.org/job/Hadoop-Common-trunk-Commit/698/])
    HADOOP-7298. Add test utility for writing multi-threaded tests. Contributed by Todd Lipcon and Harsh J Chouraria.

todd : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1150910
Files : 
* /hadoop/common/trunk/common/CHANGES.txt
* /hadoop/common/trunk/common/src/test/core/org/apache/hadoop/test/MultithreadedTestUtil.java
* /hadoop/common/trunk/common/src/test/core/org/apache/hadoop/test/TestMultithreadedTestUtil.java
","25/Jul/11 21:43;hudson;Integrated in Hadoop-Common-22-branch #66 (See [https://builds.apache.org/job/Hadoop-Common-22-branch/66/])
    HADOOP-7298. Add test utility for writing multi-threaded tests. Contributed by Todd Lipcon and Harsh J Chouraria.

todd : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1150912
Files : 
* /hadoop/common/branches/branch-0.22/common/CHANGES.txt
* /hadoop/common/branches/branch-0.22/common/src/test/core/org/apache/hadoop/test/MultithreadedTestUtil.java
* /hadoop/common/branches/branch-0.22/common/src/test/core/org/apache/hadoop/test/TestMultithreadedTestUtil.java
","26/Jul/11 11:15;hudson;Integrated in Hadoop-Common-trunk #758 (See [https://builds.apache.org/job/Hadoop-Common-trunk/758/])
    HADOOP-7298. Add test utility for writing multi-threaded tests. Contributed by Todd Lipcon and Harsh J Chouraria.

todd : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1150910
Files : 
* /hadoop/common/trunk/common/CHANGES.txt
* /hadoop/common/trunk/common/src/test/core/org/apache/hadoop/test/MultithreadedTestUtil.java
* /hadoop/common/trunk/common/src/test/core/org/apache/hadoop/test/TestMultithreadedTestUtil.java
","26/Jul/11 18:26;jrottinghuis;Todd, in the waitFor method why do you keep a count of finished and then wait in a loop?
Wouldn't a CountDownLatch work at least as well?

A problem I'm seeing in many tests is that they sleep for some # seconds in a loop.
For one single test that does not seem to matter too much, but adding it all up that would result in a lot of unnecessary waiting. If one waits x seconds in a loop, then on average 1/2 x of time is wasted. The total quite of tests runs in about 4 hours (on 0.20-security) even when I throw bigger hardware at it.
When a CountDownLatch is used to coordinate between threads (either to signal that work can start, or that threads have finished) then there is no such additional waiting.","26/Jul/11 19:48;tlipcon;When a thread finishes, it calls notify(). So, if the main thread is waiting, it will be woken up.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Test DiskChecker's functionality in identifying bad directories (Part 2 of testing DiskChecker),HADOOP-7431,12512018,Test,Closed,HADOOP,Hadoop Common,software,omalley,Hadoop Common is the common library for Apache Hadoop.,http://hadoop.apache.org/,Major,Not A Problem,qwertymaniac,qwertymaniac,qwertymaniac,28/Jun/11 16:33,15/Nov/11 00:50,12/Jan/21 11:55,25/Jul/11 08:57,0.23.0,,,,0.23.0,,,,,,test,util,,,0,test,,Add a test for the DiskChecker#checkDir method used in other projects (HDFS).,,eli,qwertymaniac,tlipcon,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,HADOOP-6566,,,,HDFS-2137,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,67054,,,,,Mon Jul 25 08:57:34 UTC 2011,,,,,,,"0|i0hwjj:",102534,,,,,,,,,,,,,,,,,,,,,,,"28/Jun/11 16:34;qwertymaniac;Related to HDFS-2111 (Which tests the downstream functionality with a DataNode)","30/Jun/11 19:26;qwertymaniac;TestDiskChecker was already added with adequate tests via HADOOP-6566 into trunk. The HDFS-2111 change covers a downstream regression test, so no further action should be required here.","25/Jul/11 08:57;qwertymaniac;See my earlier comment. This was already covered.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Run Hadoop sort benchmark on Amazon EC2,HADOOP-4382,12406063,Test,Resolved,HADOOP,Hadoop Common,software,omalley,Hadoop Common is the common library for Apache Hadoop.,http://hadoop.apache.org/,Major,Won't Fix,tomwhite,tomwhite,tomwhite,09/Oct/08 08:10,11/Aug/11 18:26,12/Jan/21 11:55,11/Aug/11 18:26,,,,,,,,,,,contrib/cloud,,,,1,,,"By running a benchmark on EC2 we can see how well Hadoop performs, how to tune it, and how performance changes between releases.",,cutting,cwensel,enis,hammer,nidaley,pacoid,philip,WHAA,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,HADOOP-4745,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"27/Nov/08 13:33;tomwhite;hadoop-4382-v2.patch;https://issues.apache.org/jira/secure/attachment/12394849/hadoop-4382-v2.patch","26/Nov/08 17:39;tomwhite;hadoop-4382.patch;https://issues.apache.org/jira/secure/attachment/12394766/hadoop-4382.patch",,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,2008-11-26 22:37:25.055,,,false,,,,,,,,,,,,,,,,,65393,Reviewed,,,,Thu Aug 11 18:26:01 UTC 2011,,,,,,,"0|i0i7rr:",104353,,,,,,,,,,,,,,,,,,,,,,,"26/Nov/08 17:39;tomwhite;A script that:

1. Launches a cluster on EC2
2. Waits for the cluster and Hadoop daemons to start
3. Runs a small sort job to warm up the cluster
4. Runs a sort job and emits the job duration
5. Terminates the cluster

Running on an 8 node cluster it took 2742 seconds to sort 32GB of data using the default hadoop-site.xml that the EC2 scripts use. This could be improved by using better settings. 

There are several improvements that could be made to the script, in particular in detecting when the cluster is ready to go (the current script waits until 90% of the nodes are up then waits 1 minute for Hadoop to start). There are more ideas here: http://www.nabble.com/Auto-shutdown-for-EC2-clusters-td20132561.html It would also be good to do multiple runs, discard the first and compute an average.

This should be a good basis for running a regular EC2 benchmark from Hudson.

Comments welcome.","26/Nov/08 17:46;tomwhite;I should say that the 8 node cluster used large EC2 instances (and the namenode/jobtracker is not included in the 8 nodes).","26/Nov/08 22:37;nidaley;Looks good Tom.  A couple comments:

- should we also run sortvalidation to ensure the sort actually worked?
- what bin dir are you putting the script in?
- perhaps name the script sort-benchmark
- add a line to echo the # minutes into a file as follows for Hudson plot:
{quote}
sort_minutes=`expr ${sort_duration} / 60`
echo ""YVALUE=${sort_minutes}"" > sort_minutes.properties
{quote}","26/Nov/08 22:41;nidaley;Argh, Jira wiki notation ate my code snippet.

{noformat}
sort_minutes=`expr ${sort_duration} / 60`
echo ""YVALUE=${sort_minutes}"" > sort_minutes.properties
{noformat}

","27/Nov/08 13:33;tomwhite;Thanks for the comments Nigel.

New patch incorporating the suggestions. (I've created the patch from the base of Hadoop this time, so the script goes in src/contrib/ec2/bin.)","01/Dec/08 17:12;nidaley;+1","11/Aug/11 18:26;eli;Covered by apache whirr",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Isolation Runner,HADOOP-7415,12511230,Test,Resolved,HADOOP,Hadoop Common,software,omalley,Hadoop Common is the common library for Apache Hadoop.,http://hadoop.apache.org/,Major,Invalid,,rajesh210687,rajesh210687,22/Jun/11 12:12,11/Aug/11 17:46,12/Jan/21 11:55,11/Aug/11 17:46,0.20.0,,,,,,,,,,,,,,0,,,"I am running Isolation Runner. I followed the procedure given in the book Hadoop The Definitive Guide.
But it is giving :
Exception in thread ""main"" java.lang.RuntimeException: java.lang.RuntimeException: java.lang.ClassNotFoundException.

",Using ubuntu machine,WHAA,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,65432,,,,,2011-06-22 12:12:33.0,,,,,,,"0|i0hwl3:",102541,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Add FileContext API tests for checking exceptions,HADOOP-6595,12457211,Test,Open,HADOOP,Hadoop Common,software,omalley,Hadoop Common is the common library for Apache Hadoop.,http://hadoop.apache.org/,Major,,sureshms,sureshms,sureshms,23/Feb/10 20:24,13/Jan/11 02:19,12/Jan/21 11:55,,0.22.0,,,,,,,,,,,,,,0,,,FileContext has many tests that checks exceptions thrown in the API. These tests need to be organized and new tests need to be added to check all the exceptions thrown by the APIs.,,cos,eli,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,127332,,,,,2010-02-23 20:24:39.0,,,,,,,"0|i0hzx3:",103081,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Add NN LoadGenerator as a Multi-threaded test for Hadoop File systems,HADOOP-7037,12480018,Test,Open,HADOOP,Hadoop Common,software,omalley,Hadoop Common is the common library for Apache Hadoop.,http://hadoop.apache.org/,Major,,,sanjay.radia,sanjay.radia,16/Nov/10 00:11,16/Nov/10 00:15,12/Jan/21 11:55,,,,,,,,,,,,,,,,0,,,,,hammer,nidaley,tlipcon,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,127502,,,,,Tue Nov 16 00:14:39 UTC 2010,,,,,,,"0|i0hy93:",102811,,,,,,,,,,,,,,,,,,,,,,,"16/Nov/10 00:14;sanjay.radia;The NN LoadGenarator is a good multi-threaded test. It uncovered Hadoop-7015 bug.
We should add LoadGenerator as a multi-threaded commit test.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
jiracli fails to upload test-patch comments to jira,HADOOP-6705,12462093,Test,Closed,HADOOP,Hadoop Common,software,omalley,Hadoop Common is the common library for Apache Hadoop.,http://hadoop.apache.org/,Major,Fixed,gkesavan,gkesavan,gkesavan,14/Apr/10 23:09,24/Aug/10 20:42,12/Jan/21 11:55,16/Apr/10 20:12,,,,,0.21.0,,,,,,build,,,,0,,,"     [exec] ======================================================================
     [exec]     Adding comment to Jira.
     [exec] ======================================================================
     [exec] ======================================================================
     [exec] 
     [exec] 
     [exec] Failed to connect to: http://issues.apache.org/jira/rpc/soap/jirasoapservice-v2?wsdl
     [exec] Failed to connect to: http://issues.apache.org/jira/rpc/soap/jirasoapservice-v2?wsdl
     [exec] Failed to connect to: http://issues.apache.org/jira/rpc/soap/jirasoapservice-v2?wsdl
     [exec]   % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"14/Apr/10 23:29;gkesavan;ASF.LICENSE.NOT.GRANTED--HADOOP-6705.PATCH;https://issues.apache.org/jira/secure/attachment/12441780/ASF.LICENSE.NOT.GRANTED--HADOOP-6705.PATCH",,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,2010-04-15 03:21:21.367,,,false,,,,,,,,,,,,,,,,,127368,,,,,Fri Apr 16 20:14:21 UTC 2010,,,,,,,"0|i0hzkv:",103026,,,,,,,,,,,,,,,,,,,,,,,"14/Apr/10 23:29;gkesavan;I ve configured a different version of jira cli that works with the current jira version. This patch would help the test-patch script to 
work with the new jiracli
","14/Apr/10 23:31;gkesavan;this patch cant be tested with test-patch. This is not going to change the current build system except for that it would be using a different version of jiracli.","15/Apr/10 03:21;hudson;Integrated in Hadoop-Common-trunk-Commit #220 (See [http://hudson.zones.apache.org/hudson/job/Hadoop-Common-trunk-Commit/220/])
    HADOOP-6705. Fix to work with 1.5 version of jiracli
","15/Apr/10 16:35;hudson;Integrated in Hadoop-Mapreduce-trunk #287 (See [http://hudson.zones.apache.org/hudson/job/Hadoop-Mapreduce-trunk/287/])
    HADOOP-6705. Fix to work with 1.5 version of jiracli
","16/Apr/10 20:14;gkesavan;Addin in the right component for jira",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Add more tests to FileContextSymlinkBaseTest that cover intermediate symlinks in paths,HADOOP-6563,12456097,Test,Closed,HADOOP,Hadoop Common,software,omalley,Hadoop Common is the common library for Apache Hadoop.,http://hadoop.apache.org/,Major,Fixed,eli,eli,eli,12/Feb/10 02:13,24/Aug/10 20:42,12/Jan/21 11:55,30/Apr/10 21:41,0.22.0,,,,0.21.0,,,,,,fs,test,,,0,,,"Intermediate symlinks in paths are covered by the tests that use /linkToDir/file, /linkToDir/subDir, etc  eg testCreateVia* in FileContextSymlinkBaseTest. I'll add additional tests to cover other basic operations on paths like /dir/linkToSomeDir/file beyond create() and open().",,Fan04290,sureshms,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"13/Apr/10 22:10;eli;ASF.LICENSE.NOT.GRANTED--hadoop-6563-2.patch;https://issues.apache.org/jira/secure/attachment/12441659/ASF.LICENSE.NOT.GRANTED--hadoop-6563-2.patch","08/Apr/10 02:20;eli;hadoop-6563-1.patch;https://issues.apache.org/jira/secure/attachment/12441102/hadoop-6563-1.patch","27/Apr/10 23:24;eli;hadoop-6563-3.patch;https://issues.apache.org/jira/secure/attachment/12443020/hadoop-6563-3.patch","28/Apr/10 00:00;eli;hadoop-6563-4.patch;https://issues.apache.org/jira/secure/attachment/12443025/hadoop-6563-4.patch","29/Apr/10 04:31;eli;hadoop-6563-5.patch;https://issues.apache.org/jira/secure/attachment/12443160/hadoop-6563-5.patch",,,,,,,,,,,,,,,,,,,5.0,,,,,,,,,,,,,,,,,,,,2010-04-08 02:48:33.817,,,false,,,,,,,,,,,,,,,,,127322,Reviewed,,,,Fri Apr 30 21:41:52 UTC 2010,,,,,,,"0|i0i013:",103099,,,,,,,,,,,,,,,,,,,,,,,"08/Apr/10 02:20;eli;Attached patch adds test coverage for intermediate symlinks in paths, and fixes a bug these tests uncovered. 

It also adds a lot of rename unit tests so that the full set of behavior with symlinks, and it conforms to the posix behavior (modulo the overwrite option which is not present in {{rename(2)}}). Here's the current FileContext#rename behavior, renaming *source* to *dest* on HDFS, augmented with symlinks:

* If *source* does not exist then a FileNotFoundException is thrown.
* If *dest* does not exist then *source* is renamed *dest*. If *source* is a symlink then the symlink itself is renamed, not the link target.
* If *dest* exists and is a non-empty directory then an IOException is thrown.
* If *dest* exists and the OVERWRITE option is not given then an IOException is thrown.
* If *dest* exists and the OVERWRITE option is given then the behavior depends on the type of *source* and *dest*:

||Source||    Dest||    Result||
|fileA  |    fileB|     Renames *fileA* to *fileB*|
|       |     dirB|     Fails: both need to be file or directory|
|       |    linkB|     *fileA* is renamed *linkB* (regardless of what *linkB* points to)|
|dirA   |    fileB|     Fails: both need to be file or directory|
|       |     dirB|     Renames *dirA* to *dirB* (*dirB* is empty)|
|       |    linkB|     Fails: both need to be file or directory|
|linkA  |    fileB|     Renames *linkA* to *fileB*|
|       |     dirB|     Fails: *dirB* is a directory|
|       |    linkB|     Renames *linkA* to *linkB* (regardless of what *linkB* points to)|
","08/Apr/10 02:48;hadoopqa;-1 overall.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12441102/hadoop-6563-1.patch
  against trunk revision 931226.

    +1 @author.  The patch does not contain any @author tags.

    +1 tests included.  The patch appears to include 6 new or modified tests.

    -1 javadoc.  The javadoc tool appears to have generated 1 warning messages.

    +1 javac.  The applied patch does not increase the total number of javac compiler warnings.

    +1 findbugs.  The patch does not introduce any new Findbugs warnings.

    +1 release audit.  The applied patch does not increase the total number of release audit warnings.

    +1 core tests.  The patch passed core unit tests.

    +1 contrib tests.  The patch passed contrib unit tests.

Test results: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch-h4.grid.sp2.yahoo.net/447/testReport/
Findbugs warnings: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch-h4.grid.sp2.yahoo.net/447/artifact/trunk/build/test/findbugs/newPatchFindbugsWarnings.html
Checkstyle results: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch-h4.grid.sp2.yahoo.net/447/artifact/trunk/build/test/checkstyle-errors.html
Console output: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch-h4.grid.sp2.yahoo.net/447/console

This message is automatically generated.","13/Apr/10 22:10;eli;Fixes the javadoc warning.","16/Apr/10 22:14;sureshms;Eli, does this functionality comply with rename specification of posix? It is available at http://www.opengroup.org/onlinepubs/000095399/functions/rename.html.
","16/Apr/10 23:49;eli;Yes.  See the initial comment for the caveat ""conforms to the posix behavior (modulo the overwrite option which is not present in rename(2))"".","27/Apr/10 22:06;eli;Kicking hudson.","27/Apr/10 22:45;hadoopqa;-1 overall.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12441659/hadoop-6563-2.patch
  against trunk revision 938590.

    +1 @author.  The patch does not contain any @author tags.

    +1 tests included.  The patch appears to include 6 new or modified tests.

    -1 patch.  The patch command could not apply the patch.

Console output: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch-h4.grid.sp2.yahoo.net/484/console

This message is automatically generated.","27/Apr/10 23:24;eli;Attached patch merges with trunk.","27/Apr/10 23:39;hadoopqa;-1 overall.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12443020/hadoop-6563-3.patch
  against trunk revision 938590.

    +1 @author.  The patch does not contain any @author tags.

    +1 tests included.  The patch appears to include 6 new or modified tests.

    +1 javadoc.  The javadoc tool did not generate any warning messages.

    -1 javac.  The patch appears to cause tar ant target to fail.

    +1 findbugs.  The patch does not introduce any new Findbugs warnings.

    +1 release audit.  The applied patch does not increase the total number of release audit warnings.

    -1 core tests.  The patch failed core unit tests.

    -1 contrib tests.  The patch failed contrib unit tests.

Test results: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch-h1.grid.sp2.yahoo.net/57/testReport/
Findbugs warnings: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch-h1.grid.sp2.yahoo.net/57/artifact/trunk/build/test/findbugs/newPatchFindbugsWarnings.html
Checkstyle results: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch-h1.grid.sp2.yahoo.net/57/artifact/trunk/build/test/checkstyle-errors.html
Console output: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch-h1.grid.sp2.yahoo.net/57/console

This message is automatically generated.","28/Apr/10 00:00;eli;Right patch this time - sorry for the noise.","28/Apr/10 00:18;hadoopqa;+1 overall.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12443025/hadoop-6563-4.patch
  against trunk revision 938590.

    +1 @author.  The patch does not contain any @author tags.

    +1 tests included.  The patch appears to include 6 new or modified tests.

    +1 javadoc.  The javadoc tool did not generate any warning messages.

    +1 javac.  The applied patch does not increase the total number of javac compiler warnings.

    +1 findbugs.  The patch does not introduce any new Findbugs warnings.

    +1 release audit.  The applied patch does not increase the total number of release audit warnings.

    +1 core tests.  The patch passed core unit tests.

    +1 contrib tests.  The patch passed contrib unit tests.

Test results: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch-h1.grid.sp2.yahoo.net/59/testReport/
Findbugs warnings: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch-h1.grid.sp2.yahoo.net/59/artifact/trunk/build/test/findbugs/newPatchFindbugsWarnings.html
Checkstyle results: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch-h1.grid.sp2.yahoo.net/59/artifact/trunk/build/test/checkstyle-errors.html
Console output: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch-h1.grid.sp2.yahoo.net/59/console

This message is automatically generated.","28/Apr/10 06:08;sureshms;Modified the table you have a little bit. Hopefully it has more clarity:
||Source||Dest||Result||
|fileA|fileB|fileB is removed. fileA is renamed fileB|
| |dirB|Fails: both need to be file or directory|
| |linkB|linkB is removed (regardles of what it points to). fileA is renamed linkB|
|dirA|fileB|Fails: both need to be file or directory|
| |dirB|dirB is deleted(if empty). dirA is renamed to dirB|
| |linkB|Fails: if Source is a directory, then Dest must be a directory|
|linkA|fileB|fileB is deleted. linkA renamed to fileB|
| |dirB|if Dest is a directory then Source must be a directory|
| |linkB|linkB is removed (regardless of what it points to. linkA is renamed to linkB|

Comments:
# typo danling
# testRenameSymlinkToFileItLinksTo - when rename fails, should the test check for exception? Is this part of another jira?
# Why is creating dangling links allowed?
# Tests are hard to follow without additional descprition in the test methods what is being tested and what is expected. It took me a while to follow the tests.

","29/Apr/10 00:06;sureshms;Ignore my comment 3, since symlinks should allow creation of dangling links.","29/Apr/10 04:31;eli;The updated table is more clear, thanks. Modified tests like testRenameSymlinkToFileItLinksTo check the particular exception thrown (like the tests that cover renaming a file, directory, etc to itself). Added additional comments to the tests and fixed the typo. Patch attached.
","30/Apr/10 18:25;sureshms;+1 for the patch.","30/Apr/10 20:03;sureshms;resubmitting the patch to trigger hudson tests.","30/Apr/10 20:28;hadoopqa;-1 overall.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12443160/hadoop-6563-5.patch
  against trunk revision 939510.

    +1 @author.  The patch does not contain any @author tags.

    +1 tests included.  The patch appears to include 6 new or modified tests.

    +1 javadoc.  The javadoc tool did not generate any warning messages.

    +1 javac.  The applied patch does not increase the total number of javac compiler warnings.

    +1 findbugs.  The patch does not introduce any new Findbugs warnings.

    +1 release audit.  The applied patch does not increase the total number of release audit warnings.

    -1 core tests.  The patch failed core unit tests.

    +1 contrib tests.  The patch passed contrib unit tests.

Test results: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch-h4.grid.sp2.yahoo.net/491/testReport/
Findbugs warnings: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch-h4.grid.sp2.yahoo.net/491/artifact/trunk/build/test/findbugs/newPatchFindbugsWarnings.html
Checkstyle results: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch-h4.grid.sp2.yahoo.net/491/artifact/trunk/build/test/checkstyle-errors.html
Console output: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch-h4.grid.sp2.yahoo.net/491/console

This message is automatically generated.","30/Apr/10 21:19;eli;The TestFilterFileSystem failure is unrelated to this change, fails on trunk after HADOOP-6709. I'll track that down.","30/Apr/10 21:41;sureshms;I committed the patch. Thank you Eli.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Enable asserts for tests by default,HADOOP-6309,12437879,Test,Closed,HADOOP,Hadoop Common,software,omalley,Hadoop Common is the common library for Apache Hadoop.,http://hadoop.apache.org/,Major,Fixed,eli,eli,eli,12/Oct/09 16:58,24/Aug/10 20:40,12/Jan/21 11:55,13/Oct/09 20:02,,,,,0.21.0,,,,,,build,,,,0,,,What do people think of making the tests run with java asserts enabled by default?,,aaa,boryas,cos,cutting,garymurry,hammer,nidaley,szetszwo,tlipcon,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"12/Oct/09 20:32;eli;hadoop6309-common.patch;https://issues.apache.org/jira/secure/attachment/12421901/hadoop6309-common.patch",,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,2009-10-12 17:24:46.876,,,false,,,,,,,,,,,,,,,,,127212,Reviewed,,,,Wed May 05 22:02:35 UTC 2010,,,,,,,"0|i0i133:",103270,,,,,,,,,,,,,,,,,,,,,,,"12/Oct/09 17:24;nidaley;+1 on the idea.","12/Oct/09 17:34;shv;This would be very useful. I found several bugs running tests with asserts. Also in many cases asserts help tests fail early.","12/Oct/09 17:38;szetszwo;> What do people think of making the tests run with java asserts enabled by default?
+1","12/Oct/09 18:08;tlipcon;Big +1. We should also open a ticket to add asserts in various places where we've shied away from error checking due to performance concerns.

Note that we'll need to fix an assertion failure currently triggered by TestAccessTokenWithDFS before committing the -ea addition.","12/Oct/09 20:32;eli;Attached a patch for enabling java asserts by default for tests in common.  Ran ant test runs w/o assertion failure on trunk@823756. Verified this same change on the hdfs tree running TestAccessTokenWithDFS causes the assert to fire. Will upload patches for hdfs and mapreduce. Lemme know if these need separate jiras, otherwise will post them here.  Will also file jiras for any asserts that fail.","12/Oct/09 21:00;cos;Yes, they better have separate JIRAs (being separate projects). And link them all together.","12/Oct/09 21:27;eli;Thanks Konstantin, filed HDFS-697 and MAPREDUCE-1092.  

Tested the patch attached to this jira by adding an assert false; to Configuration.java and made sure TestConfiguration failed as expected. ","12/Oct/09 21:28;eli;Tests run w/o assertion failure on trunk.","12/Oct/09 21:40;szetszwo;+1 patch looks good.","12/Oct/09 21:47;hadoopqa;+1 overall.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12421901/hadoop6309-common.patch
  against trunk revision 823756.

    +1 @author.  The patch does not contain any @author tags.

    -1 tests included.  The patch doesn't appear to include any new or modified tests.
                        Please justify why no new tests are needed for this patch.
                        Also please list what manual steps were performed to verify this patch.

    +1 javadoc.  The javadoc tool did not generate any warning messages.

    +1 javac.  The applied patch does not increase the total number of javac compiler warnings.

    +1 findbugs.  The patch does not introduce any new Findbugs warnings.

    +1 release audit.  The applied patch does not increase the total number of release audit warnings.

    +1 core tests.  The patch passed core unit tests.

    +1 contrib tests.  The patch passed contrib unit tests.

Test results: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch-h4.grid.sp2.yahoo.net/83/testReport/
Findbugs warnings: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch-h4.grid.sp2.yahoo.net/83/artifact/trunk/build/test/findbugs/newPatchFindbugsWarnings.html
Checkstyle results: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch-h4.grid.sp2.yahoo.net/83/artifact/trunk/build/test/checkstyle-errors.html
Console output: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch-h4.grid.sp2.yahoo.net/83/console

This message is automatically generated.","12/Oct/09 22:33;szetszwo;How about we commit this to 0.21 and above?  Any thought?","12/Oct/09 22:39;cos;You mean get it into the trunk and backport to 0.21? +1","12/Oct/09 22:41;cos;Also, for accounting purposes it'd by good to have a comment about {{-1}} in the Hudson's report. It is clear why there's no additional tests in this patch, however later on it will require an extra effort to find out why the patch has been committed with negative rating.","12/Oct/09 23:44;szetszwo;> You mean get it into the trunk and backport to 0.21? +1

Exactly.

I will wait until tomorrow before committing this .  See if anyone has comments.","13/Oct/09 20:02;szetszwo;No new tests needed because the patch only changes build.xml.

I have committed this to 0.21 and above.  Thanks, Eli!","13/Oct/09 20:09;hudson;Integrated in Hadoop-Common-trunk-Commit #60 (See [http://hudson.zones.apache.org/hudson/job/Hadoop-Common-trunk-Commit/60/])
    . Change build.xml to run tests with java asserts.  Contributed by Eli Collins
","05/May/10 22:00;eli;Per HDFS-697 and MAPREDUCE-1092 should we just enable the asserts as part of the unit tests for now?","05/May/10 22:02;eli;Actually that's what this change did, sorry for the noise.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Unit tests for FileSystemContextUtil.,HADOOP-6260,12435866,Test,Closed,HADOOP,Hadoop Common,software,omalley,Hadoop Common is the common library for Apache Hadoop.,http://hadoop.apache.org/,Major,Fixed,garymurry,garymurry,garymurry,16/Sep/09 19:11,24/Aug/10 20:39,12/Jan/21 11:55,19/Sep/09 01:04,0.21.0,,,,0.21.0,,,,,,fs,,,,0,,,This Jira is to add the unit tests associated with HADOOP-4952.,,cos,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"19/Sep/09 00:42;sureshms;HADOOP-6260.1.patch;https://issues.apache.org/jira/secure/attachment/12420115/HADOOP-6260.1.patch","19/Sep/09 00:39;sureshms;HADOOP-6260.1.patch;https://issues.apache.org/jira/secure/attachment/12420113/HADOOP-6260.1.patch","19/Sep/09 00:02;garymurry;HADOOP-6260.patch;https://issues.apache.org/jira/secure/attachment/12420111/HADOOP-6260.patch","18/Sep/09 23:10;garymurry;HADOOP-6260.patch;https://issues.apache.org/jira/secure/attachment/12420103/HADOOP-6260.patch","18/Sep/09 22:39;garymurry;HADOOP-6260.patch;https://issues.apache.org/jira/secure/attachment/12420094/HADOOP-6260.patch","18/Sep/09 18:25;garymurry;HADOOP-6260.patch;https://issues.apache.org/jira/secure/attachment/12420059/HADOOP-6260.patch","17/Sep/09 20:22;garymurry;List_glob_TestPlan.html;https://issues.apache.org/jira/secure/attachment/12419926/List_glob_TestPlan.html",,,,,,,,,,,,,,,,,7.0,,,,,,,,,,,,,,,,,,,,2009-09-18 21:51:24.357,,,false,,,,,,,,,,,,,,,,,127191,Reviewed,,,,Sat Sep 19 11:09:28 UTC 2009,,,,,,,"0|i0i1bb:",103307,,,,,,,,,,,,,,,,,,,,,,,"18/Sep/09 21:51;sureshms;Comments:
# Some new classes are missing the banner
# Add a comment to the class to briefly describe what the test is doing
# Use log instead of system.out.println
","18/Sep/09 22:39;garymurry;Attached a new patch I believe addresses Suresh's comments.","18/Sep/09 23:01;hadoopqa;-1 overall.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12420094/HADOOP-6260.patch
  against trunk revision 816794.

    +1 @author.  The patch does not contain any @author tags.

    +1 tests included.  The patch appears to include 97 new or modified tests.

    +1 javadoc.  The javadoc tool did not generate any warning messages.

    +1 javac.  The applied patch does not increase the total number of javac compiler warnings.

    +1 findbugs.  The patch does not introduce any new Findbugs warnings.

    +1 release audit.  The applied patch does not increase the total number of release audit warnings.

    -1 core tests.  The patch failed core unit tests.

    +1 contrib tests.  The patch passed contrib unit tests.

Test results: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch-h1.grid.sp2.yahoo.net/11/testReport/
Findbugs warnings: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch-h1.grid.sp2.yahoo.net/11/artifact/trunk/build/test/findbugs/newPatchFindbugsWarnings.html
Checkstyle results: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch-h1.grid.sp2.yahoo.net/11/artifact/trunk/build/test/checkstyle-errors.html
Console output: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch-h1.grid.sp2.yahoo.net/11/console

This message is automatically generated.","18/Sep/09 23:10;garymurry;The previous patch passed on windows but was killing Hudson.  I changed ""/test/..."" to ""test/...""","18/Sep/09 23:29;cos;few comments:
- lot of duplicated string literals. Move them to be the class' member or something. It also will make assertion structure smaller and easier to read (see my comment to HADOOP-6261
- in the messages like {{Can't run test}} it makes sense to add test name - makes it easier to analyze
- {{catch}} and {{finally}} are suppose to start next to the closing curve bracket (in the same line, not in the next one)

Other than that it seems pretty good I think!","18/Sep/09 23:31;hadoopqa;-1 overall.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12420103/HADOOP-6260.patch
  against trunk revision 816794.

    +1 @author.  The patch does not contain any @author tags.

    +1 tests included.  The patch appears to include 15 new or modified tests.

    +1 javadoc.  The javadoc tool did not generate any warning messages.

    +1 javac.  The applied patch does not increase the total number of javac compiler warnings.

    +1 findbugs.  The patch does not introduce any new Findbugs warnings.

    +1 release audit.  The applied patch does not increase the total number of release audit warnings.

    -1 core tests.  The patch failed core unit tests.

    +1 contrib tests.  The patch passed contrib unit tests.

Test results: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch-h1.grid.sp2.yahoo.net/13/testReport/
Findbugs warnings: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch-h1.grid.sp2.yahoo.net/13/artifact/trunk/build/test/findbugs/newPatchFindbugsWarnings.html
Checkstyle results: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch-h1.grid.sp2.yahoo.net/13/artifact/trunk/build/test/checkstyle-errors.html
Console output: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch-h1.grid.sp2.yahoo.net/13/console

This message is automatically generated.","19/Sep/09 00:02;garymurry;This patch addresses cos's comments.","19/Sep/09 00:39;sureshms;Attaching new patch that incorporates new recursive version of mkdir.","19/Sep/09 00:42;sureshms;New patch that includes missing files","19/Sep/09 00:59;sureshms;Hudson is stuck. Ran test manually. All tests pass.","19/Sep/09 00:59;jghoman;test-patch is good:
{noformat}
     [exec] +1 overall.  
     [exec] 
     [exec]     +1 @author.  The patch does not contain any @author tags.
     [exec] 
     [exec]     +1 tests included.  The patch appears to include 15 new or modified tests.
     [exec] 
     [exec]     +1 javadoc.  The javadoc tool did not generate any warning messages.
     [exec] 
     [exec]     +1 javac.  The applied patch does not increase the total number of javac compiler warnings.
     [exec] 
     [exec]     +1 findbugs.  The patch does not introduce any new Findbugs warnings.
     [exec] 
     [exec]     +1 release audit.  The applied patch does not increase the total number of release audit warnings.
{noformat}","19/Sep/09 01:04;sureshms;Just committed the patch. Thanks Gary.","19/Sep/09 01:19;hudson;Integrated in Hadoop-Common-trunk-Commit #45 (See [http://hudson.zones.apache.org/hudson/job/Hadoop-Common-trunk-Commit/45/])
    . Add additional unit tests for FileContext util methods. Contributed by Gary Murray.
","19/Sep/09 11:09;hudson;Integrated in Hadoop-Common-trunk #102 (See [http://hudson.zones.apache.org/hudson/job/Hadoop-Common-trunk/102/])
    . Add additional unit tests for FileContext util methods. Contributed by Gary Murray.
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Core doesn't have TestCommonCLI facility,HADOOP-6222,12434330,Test,Closed,HADOOP,Hadoop Common,software,omalley,Hadoop Common is the common library for Apache Hadoop.,http://hadoop.apache.org/,Major,Fixed,cos,boryas,boryas,28/Aug/09 22:49,24/Aug/10 20:39,12/Jan/21 11:55,15/Dec/09 20:02,,,,,0.21.0,,,,,,test,,,,0,,,"TestCLI is a base class, which cannot run FS type of commands.
We need a ""copy"" of TestHDFSCLI as TestCommonCLI to be able to test CLI stuff in common.

I suggest we create TestCommonCLI.java in hadoop-common",,chaitk,cos,garymurry,jghoman,raviphulari,,,,,,,,,,,,,,,,,,,,,,,,,,,,,HDFS-832,HADOOP-6316,,,,,,,,,,,,,,,,HADOOP-6409,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"11/Dec/09 21:56;cos;HADOOP-6222.hdfs-part.patch;https://issues.apache.org/jira/secure/attachment/12427779/HADOOP-6222.hdfs-part.patch","06/Dec/09 02:16;cos;HADOOP-6222.hdfs-part.patch;https://issues.apache.org/jira/secure/attachment/12427086/HADOOP-6222.hdfs-part.patch","05/Dec/09 23:50;cos;HADOOP-6222.hdfs-part.patch;https://issues.apache.org/jira/secure/attachment/12427074/HADOOP-6222.hdfs-part.patch","15/Dec/09 00:51;cos;HADOOP-6222.patch;https://issues.apache.org/jira/secure/attachment/12427985/HADOOP-6222.patch","11/Dec/09 21:56;cos;HADOOP-6222.patch;https://issues.apache.org/jira/secure/attachment/12427778/HADOOP-6222.patch","06/Dec/09 02:16;cos;HADOOP-6222.patch;https://issues.apache.org/jira/secure/attachment/12427085/HADOOP-6222.patch","05/Dec/09 23:50;cos;HADOOP-6222.patch;https://issues.apache.org/jira/secure/attachment/12427073/HADOOP-6222.patch","23/Nov/09 20:55;cos;HADOOP-6222.patch;https://issues.apache.org/jira/secure/attachment/12425880/HADOOP-6222.patch","22/Nov/09 02:26;cos;HADOOP-6222.patch;https://issues.apache.org/jira/secure/attachment/12425747/HADOOP-6222.patch","23/Nov/09 20:55;cos;HADOOP-6222_hdfs_part.patch;https://issues.apache.org/jira/secure/attachment/12425881/HADOOP-6222_hdfs_part.patch","22/Nov/09 02:26;cos;HADOOP-6222_hdfs_part.patch;https://issues.apache.org/jira/secure/attachment/12425748/HADOOP-6222_hdfs_part.patch",,,,,,,,,,,,,11.0,,,,,,,,,,,,,,,,,,,,2009-08-31 18:48:09.037,,,false,,,,,,,,,,,,,,,,,127178,Reviewed,,,,Tue Jan 12 02:02:57 UTC 2010,,,,,,,"0|i0i1gn:",103331,,,,,,,,,,,,,,,,,,,,,,,"31/Aug/09 18:48;cos;It sounds great, but it shouldn't be a literal 'copy' cause it's a sure way for code duplication and creating a very different version of the little framework in the future.

In the past, I was able to pull-off TestCLI from HDFS and make it independent for the sake of Owl project. I'm pretty sure something similar has to be repeated in this case.","31/Aug/09 20:55;boryas;I agree with Konstantin that we shouldn't copy the code. 
But since we need to support both FS and DFSADMIN commands in common, we may need to either move most of the functionality from TestHDFSCLI to TestCLI or create another class (something like TestShellCLI), move FS/DFSADMIN command processing into it and extend it for HDFS.","21/Nov/09 23:28;cos;Closer examination of the classes hierarchy showed that DFSAdminCmd processing can't be moved to Coomon without moving DFSAdmin as well. Moving that class up to the Common is clearly undesirable.","22/Nov/09 02:26;cos;Just for the time being I'm posting two patches (for Common and HDFS) to the same JIRA. I'll open new JIRA for HDFS later on.

Common patch will have to be applied first and the after core-test jar is propagated through the central repository HDFS patch will have to be applied. Otherwise, HDFS build will be broken with missing classes compilation error.

I've moved FsCmd related code to Common and have generalized instantiation of Fs and Dfs commands wherever possible ","23/Nov/09 19:14;boryas;Do we really need DFSAdminCmdExecutor class in this case? Can't we just use CLICommands.FSCmdExecutor in both cases?","23/Nov/09 20:55;cos;Addressing Boris' comment - makes sense.","05/Dec/09 23:50;cos;New version of the patch addresses all concerns of this JIRA's subtasks:
- {{TestCLI}} is renamed to {{CLITestHelper}} to avoid it being picked up by JUnit
- tests are converted to JUnit4 format
- check for 0-length test suite is added (thanks Todd)
 Also, it fixes {{TestStorageRestore}} which has direct dependencies from {{TestHDFSCLI}}.

Because this patch affects both Common and HDFS there isn't easy way to test HDFS part of it through test-patch unless Common's is committed. I've build and successfully tested Common with the patch in place. Then, using fresh hadoop-core-test.jar I've ran {{TestHDFSCLI}} and {{TestStorageRestore}} on the patched version of HDFS. All tests were executed successfully.

Also, I have ran {{test-patch}} locally for the Common's modification and it was Ok except for one warning caused by the fact that patch doesn't reflect renaming of {{TestCLI}} - it something which has to be done trough SVN.","06/Dec/09 02:16;cos;Making factory classes abstract.","11/Dec/09 00:59;boryas;HADOOP-6222.patch
1. patch file names start with ../common/src, and it should start with src
2. don't we need at least one test in common to test this?

HADOOP-6222.hdfs-part.patch
1. Nit. no new line at the end of CMDFactoryDFS.java
2. in testStorageRestore - assert<False,True> calls should have different messages for different cases. Right now they all say ""after check call""....
3.Nit. TestHDFSCli has unremoved comment in execute() method.","11/Dec/09 21:56;cos;Addressing Boris' comments but one:
- the problem with a test in current Common is that all existing CLI tests require MiniDFSCluster to be executed. Which is clearly doesn't fit Common testing paradigm.

I also have ran TestMRCLI with new common-test.jar and hdfs-test.jar and everything passed as is without any modifications on MR side.","11/Dec/09 22:43;cos;I've ran local test-patch verification for Common part and all seems cool:
{noformat}
There appear to be 1 release audit warnings before the patch and 0 release audit warnings after applying the patch.

-1 overall.
    +1 @author.  The patch does not contain any @author tags.
    +1 tests included.  The patch appears to include 12 new or modified tests.
    +1 javadoc.  The javadoc tool did not generate any warning messages.
    -1 javac.  The patch appears to cause tar ant target to fail.
    +1 findbugs.  The patch does not introduce any new Findbugs warnings.
    +1 release audit.  The applied patch does not increase the total number of release audit warnings.
{noformat}

The warning shown is related to the TestCLI class renaming, which has to be addressed by SVN not patch program. Tests ran just fine.

There two ways of integrating this:
- do verification of HDFS part as soon as Common is committed (will cause HDFS builds to fail until its respective part is committed)
- commit both at once (no problem is expected in this case)

I'd suggest to go with latter approach.
","15/Dec/09 00:51;cos;After an exchange with Boris I've added a trivial test for {{fs -help}} command to the patch. Now it has one test case to demonstrate that the refactoring works as expected.

It should be clear though that only the tests which do not require a cluster to be up and running and can run with a local filesystem can be placed into Common. Otherwise they are going to fail.","15/Dec/09 00:55;cos;Seems to be Ok to run it through the verification process one more time.","15/Dec/09 01:34;hadoopqa;+1 overall.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12427985/HADOOP-6222.patch
  against trunk revision 890588.

    +1 @author.  The patch does not contain any @author tags.

    +1 tests included.  The patch appears to include 23 new or modified tests.

    +1 javadoc.  The javadoc tool did not generate any warning messages.

    +1 javac.  The applied patch does not increase the total number of javac compiler warnings.

    +1 findbugs.  The patch does not introduce any new Findbugs warnings.

    +1 release audit.  The applied patch does not increase the total number of release audit warnings.

    +1 core tests.  The patch passed core unit tests.

    +1 contrib tests.  The patch passed contrib unit tests.

Test results: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch-h4.grid.sp2.yahoo.net/204/testReport/
Findbugs warnings: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch-h4.grid.sp2.yahoo.net/204/artifact/trunk/build/test/findbugs/newPatchFindbugsWarnings.html
Checkstyle results: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch-h4.grid.sp2.yahoo.net/204/artifact/trunk/build/test/checkstyle-errors.html
Console output: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch-h4.grid.sp2.yahoo.net/204/console

This message is automatically generated.","15/Dec/09 18:37;boryas;+1","15/Dec/09 20:02;cos;I've just committed this. 
NB: this commit will cause HDFS builds to fail for a short time. I have a separate patch for HDFS which will be tested and committed shortly after this one is integrated into new Common snapshot.","15/Dec/09 20:10;hudson;Integrated in Hadoop-Common-trunk-Commit #117 (See [http://hudson.zones.apache.org/hudson/job/Hadoop-Common-trunk-Commit/117/])
    . Core doesn't have TestCommonCLI facility. Contributed by Konstantin Boudnik.
","16/Dec/09 04:09;hudson;Integrated in Hadoop-Hdfs-trunk-Commit #148 (See [http://hudson.zones.apache.org/hudson/job/Hadoop-Hdfs-trunk-Commit/148/])
    HDFS-832. HDFS side of . Contributed by Konstantin Boudnik.
","16/Dec/09 11:10;hudson;Integrated in Hadoop-Common-trunk #189 (See [http://hudson.zones.apache.org/hudson/job/Hadoop-Common-trunk/189/])
    . Core doesn't have TestCommonCLI facility. Contributed by Konstantin Boudnik.
","16/Dec/09 13:51;hudson;Integrated in Hadoop-Hdfs-trunk #172 (See [http://hudson.zones.apache.org/hudson/job/Hadoop-Hdfs-trunk/172/])
    HDFS-832. HDFS side of . Contributed by Konstantin Boudnik.
","16/Dec/09 22:01;hudson;Integrated in Hdfs-Patch-h5.grid.sp2.yahoo.net #148 (See [http://hudson.zones.apache.org/hudson/job/Hdfs-Patch-h5.grid.sp2.yahoo.net/148/])
    ","12/Jan/10 02:02;hudson;Integrated in Hdfs-Patch-h2.grid.sp2.yahoo.net #94 (See [http://hudson.zones.apache.org/hudson/job/Hdfs-Patch-h2.grid.sp2.yahoo.net/94/])
    ",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Adding a couple private methods to AccessTokenHandler for testing purposes,HADOOP-6176,12432205,Test,Closed,HADOOP,Hadoop Common,software,omalley,Hadoop Common is the common library for Apache Hadoop.,http://hadoop.apache.org/,Major,Fixed,kzhang,kzhang,kzhang,04/Aug/09 21:19,24/Aug/10 20:39,12/Jan/21 11:55,07/Aug/09 21:41,,,,,0.21.0,,,,,,security,,,,0,,,"To support some test cases being added as part of HDFS-409, a couple private methods need to be added to AccessTokenHandler. One is for setting token lifetime and another is checking if a token has expired.",,Fan04290,szetszwo,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,HDFS-409,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"22/Dec/09 22:47;jnp;HADOOP-6176-0_20.2.patch;https://issues.apache.org/jira/secure/attachment/12428771/HADOOP-6176-0_20.2.patch","04/Aug/09 21:26;kzhang;core-03.patch;https://issues.apache.org/jira/secure/attachment/12415521/core-03.patch",,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,2009-08-06 08:42:55.569,,,false,,,,,,,,,,,,,,,,,37212,Reviewed,,,,Tue Dec 22 22:48:34 UTC 2009,,,,,,,"0|i02ruv:",14114,,,,,,,,,,,,,,,,,,,,,,,"06/Aug/09 08:42;hadoopqa;+1 overall.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12415521/core-03.patch
  against trunk revision 800919.

    +1 @author.  The patch does not contain any @author tags.

    +1 tests included.  The patch appears to include 3 new or modified tests.

    +1 javadoc.  The javadoc tool did not generate any warning messages.

    +1 javac.  The applied patch does not increase the total number of javac compiler warnings.

    +1 findbugs.  The patch does not introduce any new Findbugs warnings.

    +1 release audit.  The applied patch does not increase the total number of release audit warnings.

    +1 core tests.  The patch passed core unit tests.

    +1 contrib tests.  The patch passed contrib unit tests.

Test results: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch-vesta.apache.org/592/testReport/
Findbugs warnings: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch-vesta.apache.org/592/artifact/trunk/build/test/findbugs/newPatchFindbugsWarnings.html
Checkstyle results: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch-vesta.apache.org/592/artifact/trunk/build/test/checkstyle-errors.html
Console output: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch-vesta.apache.org/592/console

This message is automatically generated.","06/Aug/09 18:45;jghoman;+1 with a readability nit: it may be nice to explicitly state in a comment that the tests are needed to expose otherwise private methods for testing.  May be a reasonable assumption to make on the reader's part, but clarity is always a good thing.","07/Aug/09 18:55;cos;There was an idea to express the essence of this modification via aspects. However, in order to deliver this functionality in a most timely manner this effort will be carried on separately. I might be filing a separate JIRA for it if a preliminary investigation will show that such approach is viable.
 ","07/Aug/09 21:41;szetszwo;I have committed this.  Thanks, Kan!","08/Aug/09 13:04;hudson;Integrated in Hadoop-Common-trunk #48 (See [http://hudson.zones.apache.org/hudson/job/Hadoop-Common-trunk/48/])
    . Add a couple package private methods to AccessTokenHandler for testing.  Contributed by Kan Zhang
","22/Dec/09 22:48;jnp;Patch for hadoop 20 is added.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
TestFileOuputFormat can use LOCAL_MR instead of CLUSTER_MR,HADOOP-5955,12426878,Test,Closed,HADOOP,Hadoop Common,software,omalley,Hadoop Common is the common library for Apache Hadoop.,http://hadoop.apache.org/,Major,Fixed,jothipn,jothipn,jothipn,02/Jun/09 04:38,24/Aug/10 20:38,12/Jan/21 11:55,03/Jun/09 04:05,,,,,0.21.0,,,,,,test,,,,0,,,TestFileOutputFormat can use local MR instead of MiniMR. This brings down the execution time from 32 seconds to 3 seconds,,garymurry,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"02/Jun/09 04:39;jothipn;hadoop-5955.patch;https://issues.apache.org/jira/secure/attachment/12409634/hadoop-5955.patch",,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,2009-06-03 04:05:58.752,,,false,,,,,,,,,,,,,,,,,127114,Reviewed,,,,Wed Jun 03 04:05:58 UTC 2009,,,,,,,"0|i0i28n:",103457,,,,,,,,,,,,,,,,,,,,,,,"02/Jun/09 04:39;jothipn;Patch to make FOF use LOCAL_MR","03/Jun/09 04:05;ddas;I just committed this. Thanks, Jothi!",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Modify TestJavaSerialization to use LocalJobRunner instead of MiniMR/DFS cluster,HADOOP-5948,12426812,Test,Closed,HADOOP,Hadoop Common,software,omalley,Hadoop Common is the common library for Apache Hadoop.,http://hadoop.apache.org/,Major,Fixed,jothipn,jothipn,jothipn,01/Jun/09 07:53,24/Aug/10 20:38,12/Jan/21 11:55,03/Jun/09 05:43,,,,,0.21.0,,,,,,test,,,,0,,,TestJavaSerialization currently uses MiniMR/DFS cluster. This test can be done with local job runner also. This reduces the run time of the test from 61 seconds to 6 seconds.,,garymurry,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"01/Jun/09 07:59;jothipn;hadoop-5948.patch;https://issues.apache.org/jira/secure/attachment/12409543/hadoop-5948.patch",,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,2009-06-01 14:57:20.632,,,false,,,,,,,,,,,,,,,,,127112,Reviewed,,,,Thu Jun 11 19:59:25 UTC 2009,,,,,,,"0|i0i29r:",103462,,,,,,,,,,,,,,,,,,,,,,,"01/Jun/09 07:59;jothipn;Patch that changes the test not to use MiniMR","01/Jun/09 14:57;hadoopqa;-1 overall.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12409543/hadoop-5948.patch
  against trunk revision 780567.

    +1 @author.  The patch does not contain any @author tags.

    +1 tests included.  The patch appears to include 3 new or modified tests.

    +1 javadoc.  The javadoc tool did not generate any warning messages.

    +1 javac.  The applied patch does not increase the total number of javac compiler warnings.

    +1 findbugs.  The patch does not introduce any new Findbugs warnings.

    +1 Eclipse classpath. The patch retains Eclipse classpath integrity.

    +1 release audit.  The applied patch does not increase the total number of release audit warnings.

    +1 core tests.  The patch passed core unit tests.

    -1 contrib tests.  The patch failed contrib unit tests.

Test results: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch-vesta.apache.org/445/testReport/
Findbugs warnings: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch-vesta.apache.org/445/artifact/trunk/build/test/findbugs/newPatchFindbugsWarnings.html
Checkstyle results: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch-vesta.apache.org/445/artifact/trunk/build/test/checkstyle-errors.html
Console output: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch-vesta.apache.org/445/console

This message is automatically generated.","01/Jun/09 21:16;philip;+1 on making tests faster.

{quote}
   private static String TEST_ROOT_DIR =
    new File(System.getProperty(""test.build.data"", ""/tmp"")).toURI()
    .toString().replace(' ', '+');
{quote}

Definitely off-topic, but I've seen this line, in many different incantations, throughout the code base.  Is this something that could be added to UtilsForTest.java once and for all?  Do you know why the string replacement is necessary?","02/Jun/09 08:09;jothipn;bq. Definitely off-topic, but I've seen this line, in many different incantations, throughout the code base. Is this something that could be added to UtilsForTest.java once and for all? Do you know why the string replacement is necessary?

I do not think the string replacement is necessary. My guess is that this must have been added by somebody who had spaces in their test.build.data and has ever since found its way into all other test cases. I could be wrong though!","03/Jun/09 05:43;ddas;I just committed this. Thanks, Jothi!","11/Jun/09 19:59;hudson;Integrated in Hadoop-trunk #863 (See [http://hudson.zones.apache.org/hudson/job/Hadoop-trunk/863/])
    ",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Failing contrib tests should not stop the build,HADOOP-5457,12416358,Test,Closed,HADOOP,Hadoop Common,software,omalley,Hadoop Common is the common library for Apache Hadoop.,http://hadoop.apache.org/,Major,Fixed,gkesavan,cdouglas,cdouglas,07/Mar/09 03:54,24/Aug/10 20:36,12/Jan/21 11:55,10/Jun/09 06:22,0.20.0,,,,0.21.0,,,,,,test,,,,0,,,"If one or more of the unit tests in HdfsProxy fail, none of the subsequent test suites are run. All of the unit tests should run, regardless of previous projects' status.",,hammer,kzhang,yhemanth,zhiyong1,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,HADOOP-6506,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"22/Jan/10 10:47;yhemanth;Hadoop-5457-y20.patch;https://issues.apache.org/jira/secure/attachment/12431103/Hadoop-5457-y20.patch","04/Jun/09 12:05;gkesavan;Hadoop-5457.patch;https://issues.apache.org/jira/secure/attachment/12409873/Hadoop-5457.patch",,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,2009-05-15 09:39:27.141,,,false,,,,,,,,,,,,,,,,,37194,Reviewed,,,,Fri Jan 22 23:13:35 UTC 2010,,,,,,,"0|i02rpz:",14092,"Fixed the build to make sure that all the unit tests in contrib are run, regardless of the success/failure status of the previous projects' tests.",,,,,,,,,,,,,,,,,,,,,,"11/Mar/09 08:29;cdouglas;[ edit - Removing Chukwa from description, since it is no longer in contrib ]","15/May/09 09:39;yhemanth;Seems a build issue. Same thing happened yesterday when I was testing HADOOP-5828. Streaming tests were failing (for some time now on trunk) and it wasn't executing any other contrib tests. Needed to remove the offending tests to run everything again.","04/Jun/09 12:05;gkesavan;this patch fixes this issue and would run all the contrib unit tests.
tnx
","04/Jun/09 22:42;hadoopqa;-1 overall.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12409873/Hadoop-5457.patch
  against trunk revision 781739.

    +1 @author.  The patch does not contain any @author tags.

    +1 tests included.  The patch appears to include 4 new or modified tests.

    +1 javadoc.  The javadoc tool did not generate any warning messages.

    +1 javac.  The applied patch does not increase the total number of javac compiler warnings.

    +1 findbugs.  The patch does not introduce any new Findbugs warnings.

    +1 Eclipse classpath. The patch retains Eclipse classpath integrity.

    +1 release audit.  The applied patch does not increase the total number of release audit warnings.

    -1 core tests.  The patch failed core unit tests.

    -1 contrib tests.  The patch failed contrib unit tests.

Test results: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch-vesta.apache.org/462/testReport/
Findbugs warnings: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch-vesta.apache.org/462/artifact/trunk/build/test/findbugs/newPatchFindbugsWarnings.html
Checkstyle results: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch-vesta.apache.org/462/artifact/trunk/build/test/checkstyle-errors.html
Console output: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch-vesta.apache.org/462/console

This message is automatically generated.","05/Jun/09 05:42;gkesavan;I tested test-contrib locally, it ran contrib tests for all the contrib components though ""org.apache.hadoop.mapred.TestQueueCapacities"" FAILED timeout.","05/Jun/09 05:49;sharadag;+1 patch looks fine.","05/Jun/09 05:50;nidaley;+1.  Looks good.","22/Jan/10 10:47;yhemanth;Patch for earlier version of Hadoop. Not for commit here.","22/Jan/10 23:13;cos;It seems to me that the problem still exists and is fully addressed by the patch in HADOOP-6506",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Add tests for checking exceptions thrown from FileContext for different file system implementation,HADOOP-6736,12463369,Test,Open,HADOOP,Hadoop Common,software,omalley,Hadoop Common is the common library for Apache Hadoop.,http://hadoop.apache.org/,Major,,sureshms,sureshms,sureshms,29/Apr/10 20:29,13/May/10 09:45,12/Jan/21 11:55,,,,,,,,,,,,,,,,0,,,Need a test to check if the right exceptions are thrown by the FileContext for different file system implementations.,,eli,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,127378,,,,,2010-04-29 20:29:05.0,,,,,,,"0|i0hzgv:",103008,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Benchmark overhead of RPC session establishment ,HADOOP-6637,12459430,Test,Resolved,HADOOP,Hadoop Common,software,omalley,Hadoop Common is the common library for Apache Hadoop.,http://hadoop.apache.org/,Major,Fixed,shv,shv,shv,17/Mar/10 20:50,20/Mar/10 11:16,12/Jan/21 11:55,20/Mar/10 02:34,0.20.2,,,,0.20.3,,,,,,benchmarks,,,,0,,,"Measure the latency of RPC session establishments through three mechanisms: 
# simple - no auth 
# kerberos authentication
# delegation token  authentication",,bcwalrus,cutting,gnawux,hammer,hong.tang,philip,tlipcon,WHAA,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"20/Mar/10 02:22;shv;miniRPCBenchmark-20-100.patch;https://issues.apache.org/jira/secure/attachment/12439348/miniRPCBenchmark-20-100.patch","17/Mar/10 23:39;shv;miniRPCBenchmark-20.patch;https://issues.apache.org/jira/secure/attachment/12439097/miniRPCBenchmark-20.patch","20/Mar/10 02:16;shv;miniRPCBenchmark-21.patch;https://issues.apache.org/jira/secure/attachment/12439346/miniRPCBenchmark-21.patch","20/Mar/10 02:16;shv;miniRPCBenchmark.patch;https://issues.apache.org/jira/secure/attachment/12439345/miniRPCBenchmark.patch","17/Mar/10 23:40;shv;miniRPCBenchmark.patch;https://issues.apache.org/jira/secure/attachment/12439099/miniRPCBenchmark.patch","17/Mar/10 22:12;shv;miniRPCBenchmark.patch;https://issues.apache.org/jira/secure/attachment/12439087/miniRPCBenchmark.patch",,,,,,,,,,,,,,,,,,6.0,,,,,,,,,,,,,,,,,,,,2010-03-17 22:14:50.891,,,false,,,,,,,,,,,,,,,,,4232,Reviewed,,,,Sat Mar 20 11:16:40 UTC 2010,,,,,,,"0|i00yb3:",3490,,,,,,,,,,,,,,,,,,,,,,,"17/Mar/10 22:12;shv;The patch includes MiniRPCBenchmark, the test, and the change to the script file, which makes the benchmark runnable using 
{code}
bin/hadoop org.apache.hadoop.ipc.MiniRPCBenchmark
{code}
An excerpt from JavaDoc:
{{MiniRPCBenchmark}} measures time to establish an RPC connection to a secure RPC server. It sequentially establishes connections the specified number of times, and calculates the average time taken to connect. The time to connect includes the server side authentication time. 
The benchmark supports three authentication methods:
# simple - no authentication. In order to enter this mode the configuration file {{core-site.xml}} should specify {{hadoop.security.authentication = simple}}. This is the default mode.
# kerberos - kerberos authentication. In order to enter this mode the configuration file {{core-site.xml}} should specify {{hadoop.security.authentication = kerberos}} and the argument string should provide qualifying keytabFile and userName parameters.
# delegation token - authentication using delegation token. In order to enter this mode the benchmark should provide all the mentioned parameters for kerberos authentication plus the useToken argument option. 

Input arguments:
* numIterations - number of connections to establish
* keytabFile - keytab file for kerberos authentication
* userName - principal name for kerberos authentication
* useToken - should be specified for delegation token authentication
* logLevel - logging level, see Level","17/Mar/10 22:14;tlipcon;Hey Konstantin,

Will you be posting a table of the results here too? Should be very interesting.","17/Mar/10 23:24;sureshms;Minor comment - rename TestMiniRPCBencmark.java to TestMiniRPCBenchmark.java (missing 'h')
 ","17/Mar/10 23:39;shv;A similar becnhmark for the 0.20 branch. It only runs in non-authenticated mode, because obviously there is no security there yet. But we will be able to compare how much overhead the security code adds when we don't use it.","17/Mar/10 23:40;shv;Fixed the typo, and slightly improved JavaDoc.
Todd. I am planning to post results, yes.","18/Mar/10 03:30;hadoopqa;+1 overall.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12439099/miniRPCBenchmark.patch
  against trunk revision 923619.

    +1 @author.  The patch does not contain any @author tags.

    +1 tests included.  The patch appears to include 10 new or modified tests.

    +1 javadoc.  The javadoc tool did not generate any warning messages.

    +1 javac.  The applied patch does not increase the total number of javac compiler warnings.

    +1 findbugs.  The patch does not introduce any new Findbugs warnings.

    +1 release audit.  The applied patch does not increase the total number of release audit warnings.

    +1 core tests.  The patch passed core unit tests.

    +1 contrib tests.  The patch passed contrib unit tests.

Test results: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch-h1.grid.sp2.yahoo.net/36/testReport/
Findbugs warnings: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch-h1.grid.sp2.yahoo.net/36/artifact/trunk/build/test/findbugs/newPatchFindbugsWarnings.html
Checkstyle results: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch-h1.grid.sp2.yahoo.net/36/artifact/trunk/build/test/checkstyle-errors.html
Console output: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch-h1.grid.sp2.yahoo.net/36/console

This message is automatically generated.","19/Mar/10 19:22;shv;I ran the benchmark on three versions of hadoop 
# 0.20.1, which does not have any security code, and therefore kerberos and delegation token authentications are not applicable there.
# 0.20.100, which contains the latest state of security implementation
# 0.22.trunk, which does not have all the latest security patches applied at the time of benchmarking (just for the reference)

The benchmark creates a connection to the RPC server 1000 times. Each time the RPC server authenticates the client using one of the three authentication methods (no authentication, kerberos, delegation token). The result if the average latency of the connection request.

The table below shows that 
- when security is turned off the the new code still adds 14% overhead.
- The overhead for kerberos authentication is predictably huge.
- The delegation token authentication was intended as a fast alternative to kerberos. It is somewhat faster, but not as nearly as the non-secure version. This should definitely be the focus of future optimizations.
- 0.22 is 1-2% slower compared to 0.20.100. It is expected to catch up with it, when all latest security contributions are ported to the trunk.

||Version||No security||Kerberos||Delegation Tooken||
|0.20.1  |0.920| | |
|0.20.100|1.047 (+14%)|44.670|42.615|
|0.22    |1.597 (+73%)|45.148|43.455|
","19/Mar/10 22:03;shv;A minor correction to JavaDoc, and a merge with current trunk.","20/Mar/10 02:16;shv;Reflecting changes to the security branch and adding a patch for 0.21.","20/Mar/10 02:16;jnp;+1","20/Mar/10 02:31;hudson;Integrated in Hadoop-Common-trunk-Commit #205 (See [http://hudson.zones.apache.org/hudson/job/Hadoop-Common-trunk-Commit/205/])
    . Benchmark for establishing RPC session. Contributed by Konstantin Shvachko.
","20/Mar/10 02:34;shv;I just committed this.
The patch would not be possible without Jitendra's help on delegation token issues. Thank you Jitendra.","20/Mar/10 11:16;hudson;Integrated in Hadoop-Common-trunk #282 (See [http://hudson.zones.apache.org/hudson/job/Hadoop-Common-trunk/282/])
    . Benchmark for establishing RPC session. Contributed by Konstantin Shvachko.
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Add checkstyle target to ant build file,HADOOP-1051,12363825,Test,Closed,HADOOP,Hadoop Common,software,omalley,Hadoop Common is the common library for Apache Hadoop.,http://hadoop.apache.org/,Major,Fixed,tomwhite,tomwhite,tomwhite,28/Feb/07 20:36,03/Feb/10 04:10,12/Jan/21 11:55,02/Mar/07 20:37,0.11.2,,,,0.12.0,,,,,,build,test,,,0,,,"As discussed in HADOOP-948, add a target to allow people to run style checks on the codebase.",,Fan04290,qwertymaniac,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,HIVE-990,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"28/Feb/07 20:43;tomwhite;checkstyle-errors.html;https://issues.apache.org/jira/secure/attachment/12352266/checkstyle-errors.html","02/Mar/07 13:35;tomwhite;checkstyle-v2.patch;https://issues.apache.org/jira/secure/attachment/12352428/checkstyle-v2.patch","28/Feb/07 20:42;tomwhite;checkstyle.patch;https://issues.apache.org/jira/secure/attachment/12352265/checkstyle.patch",,,,,,,,,,,,,,,,,,,,,3.0,,,,,,,,,,,,,,,,,,,,2007-02-28 21:11:05.487,,,false,,,,,,,,,,,,,,,,,125116,,,,,Fri Mar 02 20:37:19 UTC 2007,,,,,,,"0|i0ildj:",106557,,,,,,,,,,,,,,,,,,,,,,,"28/Feb/07 20:42;tomwhite;This patch adds a ""checkstyle"" target that is independent of other targets. We might want to add it to the ""test"" target in the future, but for now the idea is that contributors can run it to see if their changes introduce style errors. Similarly, committers can run it to see if patches increase the number of warnings. 

This is a candidate for adding to the Hudson build too.

The current set of styles that is checked is a cutdown copy of the Sun coding conventions. (It is cutdown since there were a number of checks to do with whitespace that had hundreds of violations, so I removed them for the moment.) We can add or remove checks over time.","28/Feb/07 20:43;tomwhite;Here is a sample report for the codebase produced by the checkstyle target.","28/Feb/07 20:45;tomwhite;I forgot to mention that you need to download checkstyle 4.3 and install the ""all"" jar in the lib directory before using the new target.","28/Feb/07 21:11;hadoopqa;-1, because the patch command could not apply the latest attachment http://issues.apache.org/jira/secure/attachment/12352266/checkstyle-errors.html as a patch to trunk revision http://svn.apache.org/repos/asf/lucene/hadoop/trunk/512944. Please note that this message is automatically generated and may represent a problem with the automation system and not the patch. Results are at http://lucene.zones.apache.org:8080/hudson/job/Hadoop-Patch","01/Mar/07 20:37;cutting;+0

It might be useful to add this.  A patch should ideally not increase the number of style warnings.  But, first, we'll need to agree on the default settings, which will be contentious.  For example, I find the following warnings spurious:

'cast' is not followed by whitespace.
'+' should be on a new line.
'||' should be on a new line.
'1024' is a magic number.
'0xffff' is a magic number.
Using the '.*' form of import should be avoided - org.apache.commons.logging.*.

I'm even okay with if's that don't have braces when there's no 'else' clause.  Indentation tells the story there quite well and it's not a source of errors or misunderstandings.  But I suspect there are those who will argue with that.

On the other hand, I'm bothered by lines over 80 columns and non-2-space indentation (the testing of which you've disabled) while many others are apparently not.  However I've managed to collaborate on projects with such people for many years, without any serious problems.

Reasonable people differ about these things.  I fear we could waste a lot of time bickering about the standard style definition at the expense of getting things done.  Selective enforcement by committers, with all its pitfalls, may be a more pragmatic route.
","01/Mar/07 20:54;dbowen;+1.  I like the idea of doing this.  Following code conventions makes code easier to read and to modify.  

It would be good to get the indentation consistent.  I don't like the 2-space convention (I much prefer 4-space) but I'd rather have 2-space everywhere than the current situation where the spacing is inconsistent.

Can the checkstyle jar be checked into the lib directory so that people don't have to download it?


","01/Mar/07 21:03;cutting;> Can the checkstyle jar be checked into the lib directory so that people don't have to download it?

No.  It's available under the LGPL, and Apache policy prohibts redistribution of LGPL'd stuff.

http://people.apache.org/~cliffs/3party.html

","01/Mar/07 23:28;dbowen;Here's the config change to add indentation checking:

        <module name=""Indentation"">
          <property name=""basicOffset"" value=""2"" />
          <property name=""caseIndent"" value=""2"" />
        </module>

(The default sun_checks.xml does not check indentation.)

","02/Mar/07 13:35;tomwhite;I too don't want to waste time arguing over which set of checks to enforce. Instead I would suggest a lowest common denominator set of checks which are broadly uncontentious, and which committers can run against patches at their own discretion to check that they are basically OK.

This second patch remove's Doug's spurious warnings and adds David's change for indentation checking.

I take the point about reasonable people differing on these issues, which is why I would not integrate this into the build tool and instead give the committers the final say.","02/Mar/07 13:42;tomwhite;> I'll fix the patch process to omit *.html and *.htm attachments when
> choosing a patch file.

Is it worth excluding attached files that don't have an ASF license granted too?","02/Mar/07 17:57;cutting;> Is it worth excluding attached files that don't have an ASF license granted too?

Or, if they're patches, adding -1 for that reason?

Also, rather than checking for other file types, couldn't we instead check that something's indeed a patch file, and ignore all non-patch attachments?  The unix 'file' command does a good job of identifying patches as 'RCS/CVS diff output text'.
","02/Mar/07 20:37;cutting;These rules look fine to me, so I committed this.  Thanks, Tom!

(I also made it so that subversion will ignore files named 'checkstyle*' in the lib directory, so that we won't accidentally check this LGPL'd jar in.)
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Only the S3 test extends FileSystemContractBaseTest; the other FS tests do not",HADOOP-6500,12446256,Test,Resolved,HADOOP,Hadoop Common,software,omalley,Hadoop Common is the common library for Apache Hadoop.,http://hadoop.apache.org/,Major,Duplicate,,bobcgausa,bobcgausa,21/Jan/10 19:45,26/Jan/10 21:27,12/Jan/21 11:55,26/Jan/10 21:27,0.20.1,,,,,,,,,,test,,,,0,,,"TestChecksumFileSystem etc does not extend FileSystemContractBaseTest
In fact, ChecksumFileSystem doesn't pass the ContractBaseTest","Fedora, java 1.6.0_17, hadoop 20.1",cos,tomwhite,WHAA,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,2010-01-26 21:27:08.099,,,false,,,,,,,,,,,,,,,,,127297,,,,,Tue Jan 26 21:27:08 UTC 2010,,,,,,,"0|i0i08v:",103134,,,,,,,,,,,,,,,,,,,,,,,"26/Jan/10 21:27;jghoman;This issue is currently being handled by HDFS-303.  Closing as duplicate.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Use /tmp for test root directory in FileContextTestHelper,HADOOP-6455,12443716,Test,Resolved,HADOOP,Hadoop Common,software,omalley,Hadoop Common is the common library for Apache Hadoop.,http://hadoop.apache.org/,Major,Duplicate,eli,eli,eli,18/Dec/09 01:49,18/Dec/09 18:03,12/Jan/21 11:55,18/Dec/09 18:03,,,,,,,,,,,,,,,0,,,"Per other tests set the test root directory to /tmp rather than /user.  Testing: 
- TestLocalFSFileContextMainOperations now passes when run from eclipse (rather than access non-existant directory).
- ant test-core still passes",,hammer,jghoman,sanjay.radia,WHAA,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"18/Dec/09 02:05;eli;hadoop-6455.patch;https://issues.apache.org/jira/secure/attachment/12428390/hadoop-6455.patch","18/Dec/09 01:50;eli;hadoop-6455.patch;https://issues.apache.org/jira/secure/attachment/12428388/hadoop-6455.patch",,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,2009-12-18 02:00:38.936,,,false,,,,,,,,,,,,,,,,,127274,,,,,Fri Dec 18 18:03:10 UTC 2009,,,,,,,"0|i0i0fr:",103165,,,,,,,,,,,,,,,,,,,,,,,"18/Dec/09 02:00;hadoopqa;-1 overall.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12428388/hadoop-6455.patch
  against trunk revision 892066.

    +1 @author.  The patch does not contain any @author tags.

    +1 tests included.  The patch appears to include 5 new or modified tests.

    -1 patch.  The patch command could not apply the patch.

Console output: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch-h1.grid.sp2.yahoo.net/32/console

This message is automatically generated.","18/Dec/09 02:05;eli;This time w/o prefix.","18/Dec/09 02:27;jghoman;There has been quite a bit of discussion about why /tmp is not a good idea (HADOOP:5916).  Is there any reason this code shouldn't standarize on buidl/test/data, as other tests have?","18/Dec/09 02:29;jghoman;Hmmm... make that HADOOP-5916","18/Dec/09 02:31;hadoopqa;+1 overall.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12428390/hadoop-6455.patch
  against trunk revision 892066.

    +1 @author.  The patch does not contain any @author tags.

    +1 tests included.  The patch appears to include 5 new or modified tests.

    +1 javadoc.  The javadoc tool did not generate any warning messages.

    +1 javac.  The applied patch does not increase the total number of javac compiler warnings.

    +1 findbugs.  The patch does not introduce any new Findbugs warnings.

    +1 release audit.  The applied patch does not increase the total number of release audit warnings.

    +1 core tests.  The patch passed core unit tests.

    +1 contrib tests.  The patch passed contrib unit tests.

Test results: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch-h4.grid.sp2.yahoo.net/221/testReport/
Findbugs warnings: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch-h4.grid.sp2.yahoo.net/221/artifact/trunk/build/test/findbugs/newPatchFindbugsWarnings.html
Checkstyle results: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch-h4.grid.sp2.yahoo.net/221/artifact/trunk/build/test/checkstyle-errors.html
Console output: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch-h4.grid.sp2.yahoo.net/221/console

This message is automatically generated.","18/Dec/09 18:03;eli;Thanks for the pointer Jakob, I'll close this as a dupe of HADOOP-5916 and comment there.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Test behavior of very large (32GB) name nodes,HADOOP-3192,12393203,Test,Resolved,HADOOP,Hadoop Common,software,omalley,Hadoop Common is the common library for Apache Hadoop.,http://hadoop.apache.org/,Major,Fixed,,chansler,chansler,05/Apr/08 00:54,20/Nov/09 23:57,12/Jan/21 11:55,20/Nov/09 23:57,,,,,0.20.0,,,,,,,,,,0,,,"Define measure of whether very large name nodes behave well.
Perform necessary test on a real host.",,cutting,WHAA,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,125829,,,,,Fri Nov 20 23:57:58 UTC 2009,,,,,,,"0|i0id27:",105210,,,,,,,,,,,,,,,,,,,,,,,"20/Nov/09 23:57;chansler;Some large cluster are running with 34GB!",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Add funtional tests for hadoop fs -df. ,HADOOP-6379,12440985,Test,Open,HADOOP,Hadoop Common,software,omalley,Hadoop Common is the common library for Apache Hadoop.,http://hadoop.apache.org/,Major,,,raviphulari,raviphulari,17/Nov/09 23:08,17/Nov/09 23:17,12/Jan/21 11:55,,,,,,,,,,,,,,,,0,,,"TestHDFSCli  is missing functional tests for -df command. 
This Jira will add more functional tests for *hadoop fs -df* command.",,garymurry,hammer,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,127244,,,,,2009-11-17 23:08:25.0,,,,,,,"0|i0i0r3:",103216,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
streaming should have a jnuit test that catches any api changes in current working directories,HADOOP-703,12355189,Test,Closed,HADOOP,Hadoop Common,software,omalley,Hadoop Common is the common library for Apache Hadoop.,http://hadoop.apache.org/,Major,Cannot Reproduce,mahadev,mahadev,mahadev,09/Nov/06 18:33,08/Jul/09 17:05,12/Jan/21 11:55,09/May/08 22:27,,,,,,,,,,,,,,,0,,,the current working directores were changes in 0.7.2 which broke applications that ran on streaming. We should have a junit test that catches these api changes.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,124940,,,,,Mon Apr 21 20:46:03 UTC 2008,,,,,,,"0|i0hxv3:",102748,,,,,,,,,,,,,,,,,,,,,,,"21/Apr/08 20:46;mahadev;This issue has been resolved with our unit tests checking for any changes in the environment execution of the tasks.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
multiple spills/reducers test case for mergeParts() needed,HADOOP-4688,12408846,Test,Closed,HADOOP,Hadoop Common,software,omalley,Hadoop Common is the common library for Apache Hadoop.,http://hadoop.apache.org/,Major,Fixed,cdouglas,yurip,yurip,19/Nov/08 19:01,08/Jul/09 16:53,12/Jan/21 11:55,08/Dec/08 19:43,0.19.1,,,,0.20.0,,,,,,,,,,0,,,"The first  patch version (incorrect) for http://issues.apache.org/jira/browse/HADOOP-4614 exposed a problem that existing tests do not exercise some code paths of MapOutputBuffer::mergeParts().  In particular, we need a test that would validate output when numSpills >1 and partitions >1.

This might be a test that has more than 1 reducer and forces multiple first level (map) spills by setting *io.sort.mb* (and possibly *io.sort.spill.percent*) to small values.",,nidaley,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"01/Dec/08 18:57;cdouglas;4688-0.patch;https://issues.apache.org/jira/secure/attachment/12395029/4688-0.patch",,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,2008-11-20 00:07:30.007,,,false,,,,,,,,,,,,,,,,,126668,Reviewed,,,,Tue Dec 09 15:32:44 UTC 2008,,,,,,,"0|i0i6pb:",104180,,,,,,,,,,,,,,,,,,,,,,,"20/Nov/08 00:07;nidaley;+1 to such a test!","22/Nov/08 16:28;hudson;Integrated in Hadoop-trunk #668 (See [http://hudson.zones.apache.org/hudson/job/Hadoop-trunk/668/])
    . Update CHANGES.txt for moving this back to 0.18.3.
","01/Dec/08 18:57;cdouglas;Modified MiniMRDFSSort to spill multiple times","08/Dec/08 02:30;hadoopqa;-1 overall.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12395029/4688-0.patch
  against trunk revision 723918.

    +1 @author.  The patch does not contain any @author tags.

    +1 tests included.  The patch appears to include 3 new or modified tests.

    +1 javadoc.  The javadoc tool did not generate any warning messages.

    +1 javac.  The applied patch does not increase the total number of javac compiler warnings.

    +1 findbugs.  The patch does not introduce any new Findbugs warnings.

    +1 Eclipse classpath. The patch retains Eclipse classpath integrity.

    -1 core tests.  The patch failed core unit tests.

    -1 contrib tests.  The patch failed contrib unit tests.

Test results: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch/3682/testReport/
Findbugs warnings: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch/3682/artifact/trunk/build/test/findbugs/newPatchFindbugsWarnings.html
Checkstyle results: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch/3682/artifact/trunk/build/test/checkstyle-errors.html
Console output: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch/3682/console

This message is automatically generated.","08/Dec/08 02:45;cdouglas;Neither test failure is related. (HADOOP-4716, Chukwa test timeout)","08/Dec/08 10:04;jothipn;+1","08/Dec/08 19:43;cdouglas;I just committed this","09/Dec/08 15:32;hudson;Integrated in Hadoop-trunk #683 (See [http://hudson.zones.apache.org/hudson/job/Hadoop-trunk/683/])
    . Modify the MiniMRDFSSort unit test to spill multiple times,
exercising the map-side merge code.
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Add a unit test to test faulty setup task and cleanup task killing the job,HADOOP-4505,12407078,Test,Closed,HADOOP,Hadoop Common,software,omalley,Hadoop Common is the common library for Apache Hadoop.,http://hadoop.apache.org/,Major,Fixed,amareshwari,amareshwari,amareshwari,23/Oct/08 11:41,08/Jul/09 16:53,12/Jan/21 11:55,12/Nov/08 16:48,0.19.0,,,,0.20.0,,,,,,,,,,0,,,We should have a unit test which tests faulty setup task or cleanup task of the job eventually kills the job.,,Fan04290,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"24/Oct/08 06:36;amareshwari;patch-4505.txt;https://issues.apache.org/jira/secure/attachment/12392768/patch-4505.txt",,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,2008-10-30 19:16:59.661,,,false,,,,,,,,,,,,,,,,,126578,Reviewed,,,,Thu Nov 13 02:11:28 UTC 2008,,,,,,,"0|i0i79z:",104273,,,,,,,,,,,,,,,,,,,,,,,"24/Oct/08 06:36;amareshwari;Patch adding the unit test","24/Oct/08 08:52;amareshwari;test-patch result:
{noformat}
     [exec] +1 overall.
     [exec]
     [exec]     +1 @author.  The patch does not contain any @author tags.
     [exec]
     [exec]     +1 tests included.  The patch appears to include 3 new or modified tests.
     [exec]
     [exec]     +1 javadoc.  The javadoc tool did not generate any warning messages.
     [exec]
     [exec]     +1 javac.  The applied patch does not increase the total number of javac compiler warnings.
     [exec]
     [exec]     +1 findbugs.  The patch does not introduce any new Findbugs warnings.
     [exec]
     [exec]     +1 Eclipse classpath. The patch retains Eclipse classpath integrity.
     [exec]
{noformat}
All core and contrib tests passed on machine.","30/Oct/08 10:25;amareshwari;submitting to hudson again","30/Oct/08 19:16;hadoopqa;-1 overall.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12392768/patch-4505.txt
  against trunk revision 709040.

    +1 @author.  The patch does not contain any @author tags.

    +1 tests included.  The patch appears to include 3 new or modified tests.

    +1 javadoc.  The javadoc tool did not generate any warning messages.

    +1 javac.  The applied patch does not increase the total number of javac compiler warnings.

    +1 findbugs.  The patch does not introduce any new Findbugs warnings.

    +1 Eclipse classpath. The patch retains Eclipse classpath integrity.

    -1 core tests.  The patch failed core unit tests.

    +1 contrib tests.  The patch passed contrib unit tests.

Test results: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch/3512/testReport/
Findbugs warnings: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch/3512/artifact/trunk/build/test/findbugs/newPatchFindbugsWarnings.html
Checkstyle results: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch/3512/artifact/trunk/build/test/checkstyle-errors.html
Console output: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch/3512/console

This message is automatically generated.","31/Oct/08 04:08;amareshwari;Test failure is not related to the patch. The patch just adds a unit test. it doesn't  touch the core code. 
All the core and contrib tests pass on my machine.","12/Nov/08 16:48;johanoskarsson;I just committed this. Thanks Amareshwari!","13/Nov/08 02:11;hudson;Integrated in Hadoop-trunk #659 (See [http://hudson.zones.apache.org/hudson/job/Hadoop-trunk/659/])
    . Add a unit test to test faulty setup task and cleanup task killing the job. (Amareshwari Sriramadasu via johan)
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Add a unit test for applications creating symlinks in wokring  directory,HADOOP-4458,12406776,Test,Closed,HADOOP,Hadoop Common,software,omalley,Hadoop Common is the common library for Apache Hadoop.,http://hadoop.apache.org/,Major,Fixed,amareshwari,amareshwari,amareshwari,20/Oct/08 06:28,08/Jul/09 16:53,12/Jan/21 11:55,16/Dec/08 10:52,,,,,0.20.0,,,,,,test,,,,0,,,There should be a unit test for applications creating symlinks. The test should give the configuration for creating symlinks and verify the symlinks are created during the task's executation. ,,Fan04290,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"27/Nov/08 08:46;amareshwari;patch-4458.txt;https://issues.apache.org/jira/secure/attachment/12394824/patch-4458.txt",,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,2008-11-29 21:49:06.273,,,false,,,,,,,,,,,,,,,,,126558,Reviewed,,,,Tue Dec 16 10:52:01 UTC 2008,,,,,,,"0|i0i7ef:",104293,,,,,,,,,,,,,,,,,,,,,,,"27/Nov/08 08:46;amareshwari;Adding the test for DistributeCache with symlinks","29/Nov/08 21:49;hadoopqa;+1 overall.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12394824/patch-4458.txt
  against trunk revision 721415.

    +1 @author.  The patch does not contain any @author tags.

    +1 tests included.  The patch appears to include 31 new or modified tests.

    +1 javadoc.  The javadoc tool did not generate any warning messages.

    +1 javac.  The applied patch does not increase the total number of javac compiler warnings.

    +1 findbugs.  The patch does not introduce any new Findbugs warnings.

    +1 Eclipse classpath. The patch retains Eclipse classpath integrity.

    +1 core tests.  The patch passed core unit tests.

    +1 contrib tests.  The patch passed contrib unit tests.

Test results: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch/3671/testReport/
Findbugs warnings: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch/3671/artifact/trunk/build/test/findbugs/newPatchFindbugsWarnings.html
Checkstyle results: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch/3671/artifact/trunk/build/test/checkstyle-errors.html
Console output: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch/3671/console

This message is automatically generated.","16/Dec/08 10:52;cdouglas;+1

I just committed this. Thanks Amareshwari",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
simple distributed dfs random data writer & sort example applications,HADOOP-187,12332988,Test,Closed,HADOOP,Hadoop Common,software,omalley,Hadoop Common is the common library for Apache Hadoop.,http://hadoop.apache.org/,Major,Fixed,omalley,omalley,omalley,02/May/06 12:30,08/Jul/09 16:51,12/Jan/21 11:55,03/May/06 01:49,0.1.1,,,,0.2.0,,,,,,,,,,0,,,"These are the examples/benchmark programs that I've been using to test Hadoop map/reduce with. The first is a program that runs 10 maps/node and each map writes 1 gig of random data to a dfs file as a SequenceFile of BytesWritable/BytesWritable.

The second uses the identity map and reduce to sort the data and write it out to dfs.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"02/May/06 12:31;omalley;sort-write.patch;https://issues.apache.org/jira/secure/attachment/12326128/sort-write.patch",,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,2006-05-03 01:49:00.0,,,false,,,,,,,,,,,,,,,,,124679,,,,,Wed May 03 01:49:00 UTC 2006,,,,,,,"0|i0ipvr:",107287,,,,,,,,,,,,,,,,,,,,,,,"03/May/06 01:49;cutting;I just committed this.  Thanks, Owen.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
hadoop doesn't take advatage of distributed compiting in TestDFSIO,HADOOP-72,12330102,Test,Closed,HADOOP,Hadoop Common,software,omalley,Hadoop Common is the common library for Apache Hadoop.,http://hadoop.apache.org/,Major,Won't Fix,,shv,shv,10/Mar/06 04:39,08/Jul/09 16:51,12/Jan/21 11:55,22/Apr/06 00:27,,,,,0.2.0,,,,,,fs,,,,0,,,"TestDFSIO runs N map jobs, each either writing to or reading from a separate file of the same size, 
and collects statistical information on its performance. 
The reducer further calculates the overall statistics for all maps. 
It outputs the following data:
- read or write test
- date and time the test finished   
- number of files
- total number of bytes processed
- overall throughput in mb/sec
- average IO rate in mb/sec per file

__Results__
I run 7 iterations of the test one after another on a cluster of ~200 nodes. 
The file size is the same in all cases 320Mb. 
The number of files tried is 1,2,4,8,16,32,64.
The log file with statistics is attached.
It looks like we don't have any distributed computing here at all.
The total execution time increases proportionally to the total size of data both for writes and reads.
Another thing is that the io ratio for read is higher than the write rate just gradually.
For comparison I attach time measuring for the same ios performed on the same cluster but sequentially in a simple loop.
This is the summary:

Files	map/red time	sequential time
 1		49			  34 
 2		86			  69
 4		158			131
 8		299			266
16		569			532
32		1131
64		2218

This doesn't look good, unless there is something wrong with my test (attached) or the cluster settings.
",200 node cluster,eli,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"11/Mar/06 10:37;shv;TestDFSIO.java;https://issues.apache.org/jira/secure/attachment/12324049/TestDFSIO.java","11/Mar/06 10:37;shv;TestDFSIO_results.log;https://issues.apache.org/jira/secure/attachment/12324050/TestDFSIO_results.log","10/Mar/06 04:43;shv;TestDFSIO_results_200_node_cluster.log;https://issues.apache.org/jira/secure/attachment/12323990/TestDFSIO_results_200_node_cluster.log","10/Mar/06 04:43;shv;TestDFSIO_results_sequential.log;https://issues.apache.org/jira/secure/attachment/12323991/TestDFSIO_results_sequential.log",,,,,,,,,,,,,,,,,,,,4.0,,,,,,,,,,,,,,,,,,,,2006-03-10 06:59:30.0,,,false,,,,,,,,,,,,,,,,,124621,,,,,Sat Apr 22 00:27:50 UTC 2006,,,,,,,"0|i0dxf3:",79344,,,,,,,,,,,,,,,,,,,,,,,"10/Mar/06 06:59;cutting;Did you look at the web ui to see how many map tasks were used to execute this?  My suspicion is that only a single map task is used.  A SequenceFile cannot be split into chunks smaller than 2k.  With less than 64 files, your single input file is probably less than 2k.  You could instead use a text input file, which can be split into smaller chunks, or you could use a custom getSplits() implementation that actually parses the input file, or you could use a much larger number of files.","11/Mar/06 10:37;shv;TestDFSIO is modified to create one input file for each map task.
That way it works in parallel.
Everything is getting very slow when the the number of writes is close to or 
larger than the size of the cluster.
","22/Apr/06 00:27;cutting;This was caused by a misunderstanding.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Performance benchmark to compare HDFS with local utilities,HADOOP-3189,12393200,Test,Closed,HADOOP,Hadoop Common,software,omalley,Hadoop Common is the common library for Apache Hadoop.,http://hadoop.apache.org/,Major,Duplicate,,chansler,chansler,05/Apr/08 00:44,08/Jul/09 16:43,12/Jan/21 11:55,09/Apr/08 12:27,,,,,,,,,,,test,,,,0,,,"Test to compare performance of HDFS with local utilities like {{cat}} and {{dd}}.
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,HADOOP-2342,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,2008-04-09 12:27:54.371,,,false,,,,,,,,,,,,,,,,,125828,,,,,Wed Apr 09 12:27:54 UTC 2008,,,,,,,"0|i0id2f:",105211,,,,,,,,,,,,,,,,,,,,,,,"09/Apr/08 12:27;omalley;This was done as HADOOP-2342.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
create a micro-benchmark for measure local-file versus hdfs read,HADOOP-2342,12383843,Test,Closed,HADOOP,Hadoop Common,software,omalley,Hadoop Common is the common library for Apache Hadoop.,http://hadoop.apache.org/,Major,Fixed,omalley,omalley,omalley,04/Dec/07 00:28,08/Jul/09 16:42,12/Jan/21 11:55,25/Jan/08 22:20,,,,,0.16.0,,,,,,,,,,0,,,We should have a benchmark that measures reading a 10g file from hdfs and from local disk.,,johanoskarsson,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"25/Jan/08 05:16;omalley;2342-1.patch;https://issues.apache.org/jira/secure/attachment/12374004/2342-1.patch","05/Dec/07 22:03;omalley;throughput.patch;https://issues.apache.org/jira/secure/attachment/12371075/throughput.patch",,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,2007-12-04 19:01:50.468,,,false,,,,,,,,,,,,,,,,,125542,,,,,Sat Jan 26 12:36:20 UTC 2008,,,,,,,"0|i0igdb:",105746,,,,,,,,,,,,,,,,,,,,,,,"04/Dec/07 18:57;omalley;The numbers I'm seeing for reads and writes on 10GB are:

Raw Local FS    write: 152       read: 79
Local FS             write: 203       read: 78
mini-DFS            write: 269       read: 134

which suggests that writing checksums is pretty expensive and that HADOOP-2144 is reproducible. ","04/Dec/07 19:01;rangadi;Doesn't LocalFS do Checksums too? Read on Local FS is as fast as Raw Local.","04/Dec/07 19:04;cutting;> which suggests that writing checksums is pretty expensive

But reading checksums does not seem to be too expensive, which is nice to see.  However HDFS reads are *much* slower than local reads, which is worrisome.  That seems to be the biggest outlier in your data: checksums add ~25%, while non-local reads adds ~90%.","05/Dec/07 19:33;omalley;This benchmark reads and writes files using java.io, RawLocalFileSystem, LocalFileSystem, and HDFS and reports the time.","05/Dec/07 21:15;hadoopqa;+1 overall.  Here are the results of testing the latest attachment 
http://issues.apache.org/jira/secure/attachment/12371063/throughput.patch
against trunk revision r601491.

    @author +1.  The patch does not contain any @author tags.

    javadoc +1.  The javadoc tool did not generate any warning messages.

    javac +1.  The applied patch does not generate any new compiler warnings.

    findbugs +1.  The patch does not introduce any new Findbugs warnings.

    core tests +1.  The patch passed core unit tests.

    contrib tests +1.  The patch passed contrib unit tests.

Test results: http://lucene.zones.apache.org:8080/hudson/job/Hadoop-Patch/1274/testReport/
Findbugs warnings: http://lucene.zones.apache.org:8080/hudson/job/Hadoop-Patch/1274/artifact/trunk/build/test/findbugs/newPatchFindbugsWarnings.html
Checkstyle results: http://lucene.zones.apache.org:8080/hudson/job/Hadoop-Patch/1274/artifact/trunk/build/test/checkstyle-errors.html
Console output: http://lucene.zones.apache.org:8080/hudson/job/Hadoop-Patch/1274/console

This message is automatically generated.","05/Dec/07 22:03;omalley;I forgot to restart the time on the local read and write.","05/Dec/07 22:03;omalley;Need to be re-reviewed by QA.","05/Dec/07 23:52;hadoopqa;-1 overall.  Here are the results of testing the latest attachment 
http://issues.apache.org/jira/secure/attachment/12371075/throughput.patch
against trunk revision r601518.

    @author +1.  The patch does not contain any @author tags.

    javadoc +1.  The javadoc tool did not generate any warning messages.

    javac +1.  The applied patch does not generate any new compiler warnings.

    findbugs +1.  The patch does not introduce any new Findbugs warnings.

    core tests +1.  The patch passed core unit tests.

    contrib tests -1.  The patch failed contrib unit tests.

Test results: http://lucene.zones.apache.org:8080/hudson/job/Hadoop-Patch/1276/testReport/
Findbugs warnings: http://lucene.zones.apache.org:8080/hudson/job/Hadoop-Patch/1276/artifact/trunk/build/test/findbugs/newPatchFindbugsWarnings.html
Checkstyle results: http://lucene.zones.apache.org:8080/hudson/job/Hadoop-Patch/1276/artifact/trunk/build/test/checkstyle-errors.html
Console output: http://lucene.zones.apache.org:8080/hudson/job/Hadoop-Patch/1276/console

This message is automatically generated.","07/Dec/07 17:28;tomwhite;I built a distribution with this patch and got the following error. It looks like MiniDFSCluster and NameNode are loaded by different classloaders which causes the package access on createNameNode to fail.

>bin/hadoop jar hadoop-0.16.0-dev-test.jar dfsthroughput
Local = /tmp/hadoop-tom/mapred/temp
Writing local time: 246
Reading local time: 219
Writing raw time: 225
Reading raw time: 216
Writing checked time: 219
Reading checked time: 238
java.lang.IllegalAccessError: tried to access method org.apache.hadoop.dfs.NameNode.createNameNode([Ljava/lang/String;Lorg/apache/hadoop/conf/Configuration;)Lorg/apache/hadoop/dfs/NameNode; from class org.apache.hadoop.dfs.MiniDFSCluster
        at org.apache.hadoop.dfs.MiniDFSCluster.<init>(MiniDFSCluster.java:179)
        at org.apache.hadoop.dfs.MiniDFSCluster.<init>(MiniDFSCluster.java:118)
        at org.apache.hadoop.dfs.MiniDFSCluster.<init>(MiniDFSCluster.java:90)
        at org.apache.hadoop.dfs.BenchmarkThroughput.main(BenchmarkThroughput.java:190)
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
        at java.lang.reflect.Method.invoke(Method.java:585)
        at org.apache.hadoop.util.ProgramDriver$ProgramDescription.invoke(ProgramDriver.java:68)
        at org.apache.hadoop.util.ProgramDriver.driver(ProgramDriver.java:139)
        at org.apache.hadoop.test.AllTestDriver.main(AllTestDriver.java:75)
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
        at java.lang.reflect.Method.invoke(Method.java:585)
        at org.apache.hadoop.util.RunJar.main(RunJar.java:155)","19/Dec/07 16:47;tomwhite;I got the same error running the same distribution on Linux too. One fix would be to make the createNameNode method public, but I'd rather find another way if possible.","11/Jan/08 00:53;cdouglas;I ran this on MacOS (jdk1.5.0_13), Linux (jdk1.5.0_08 and jdk1.6.0), and Windows (jdk1.6.0) using the latest trunk and cannot reproduce this case.

Tom: Are you still seeing this issue?","18/Jan/08 01:40;cdouglas;The patch no longer applies to trunk (AllTestDriver has new items).

* Using ToolBase/ToolRunner would pick up its functionality, including:
** It would be useful for the file size and buffer size to be configurable through the config/generic options
** Noting the rep param in the usage might also be helpful","25/Jan/08 05:16;omalley;Here is an update to trunk and switch to use Tool. Thanks, Chris!","25/Jan/08 18:29;hadoopqa;-1 overall.  Here are the results of testing the latest attachment 
http://issues.apache.org/jira/secure/attachment/12374004/2342-1.patch
against trunk revision 614721.

    @author +1.  The patch does not contain any @author tags.

    javadoc +1.  The javadoc tool did not generate any warning messages.

    javac +1.  The applied patch does not generate any new compiler warnings.

    findbugs +1.  The patch does not introduce any new Findbugs warnings.

    core tests -1.  The patch failed core unit tests.

    contrib tests -1.  The patch failed contrib unit tests.

Test results: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch/1678/testReport/
Findbugs warnings: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch/1678/artifact/trunk/build/test/findbugs/newPatchFindbugsWarnings.html
Checkstyle results: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch/1678/artifact/trunk/build/test/checkstyle-errors.html
Console output: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch/1678/console

This message is automatically generated.","25/Jan/08 22:20;nidaley;Test failures were irrelevant to this patch.  I just committed this.  Thanks Owen!","26/Jan/08 12:36;hudson;Integrated in Hadoop-trunk #380 (See [http://hudson.zones.apache.org/hudson/job/Hadoop-trunk/380/])",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
junit test for HADOOP-59: support generic command-line options,HADOOP-411,12347106,Test,Closed,HADOOP,Hadoop Common,software,omalley,Hadoop Common is the common library for Apache Hadoop.,http://hadoop.apache.org/,Major,Fixed,hairong,hairong,hairong,01/Aug/06 22:00,08/Jul/09 16:41,12/Jan/21 11:55,02/Aug/06 18:09,0.4.0,,,,0.5.0,,,,,,,,,,0,,,This issue will proivde Junit test cases for HADOOP-59.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"01/Aug/06 22:03;hairong;testcases59.patch;https://issues.apache.org/jira/secure/attachment/12337933/testcases59.patch",,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,2006-08-02 18:09:43.0,,,false,,,,,,,,,,,,,,,,,124790,,,,,Wed Aug 02 18:39:58 UTC 2006,,,,,,,"0|i0ionr:",107089,,,,,,,,,,,,,,,,,,,,,,,"02/Aug/06 18:09;cutting;I just committed this.  Thanks, Hairong!","02/Aug/06 18:39;cutting;This writes files in the conf directory that it does not remove.  It would be better to write these in the build directory.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
add a unit test for multiple datanodes in a machine,HADOOP-382,12346569,Test,Closed,HADOOP,Hadoop Common,software,omalley,Hadoop Common is the common library for Apache Hadoop.,http://hadoop.apache.org/,Major,Fixed,milindb,yarnon,yarnon,24/Jul/06 18:41,08/Jul/09 16:41,12/Jan/21 11:55,08/Nov/06 21:35,0.8.0,,,,0.9.0,,,,,,,,,,0,,,"recently we saw a bug present itself only when multiple data nodes are started on a single machine.
A unit test that starts multiple data nodes would expose such bugs before they happen in a real installation.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"08/Nov/06 00:19;milindb;multi-dn-test.patch;https://issues.apache.org/jira/secure/attachment/12344522/multi-dn-test.patch",,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,2006-11-08 00:19:21.0,,,false,,,,,,,,,,,,,,,,,51000,,,,,Wed Nov 08 21:35:13 UTC 2006,,,,,,,"0|i0iotr:",107116,,,,,,,,,,,,,,,,,,,,,,,"08/Nov/06 00:19;milindb;This patch modifies the MiniDFSCluster to optionally specify starting multiple datanodes in separate threads.","08/Nov/06 00:19;milindb;Patch submitted.","08/Nov/06 21:35;cutting;I just committed this.  Thanks, Milind!",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Implement -setSpaceQuota and -clrSpaceQuota tests on directory using globbing  ,HADOOP-5538,12417352,Test,Closed,HADOOP,Hadoop Common,software,omalley,Hadoop Common is the common library for Apache Hadoop.,http://hadoop.apache.org/,Major,Duplicate,raviphulari,raviphulari,raviphulari,20/Mar/09 06:29,23/Apr/09 19:25,12/Jan/21 11:55,27/Mar/09 07:20,0.19.2,,,,,,,,,,test,,,,0,,,"TestCLI.java  for testing Command Line Interface is missing  tests for -setSpaceQuota on directory using globbing , and -clrSpaceQuota on directory using globbing . ",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,127026,,,,,Fri Mar 27 07:20:29 UTC 2009,,,,,,,"0|i0i3hb:",103658,,,,,,,,,,,,,,,,,,,,,,,"27/Mar/09 07:20;raviphulari;Already filed similar issue with Hadoop-5080

http://issues.apache.org/jira/browse/HADOOP-5080",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Create a mock MapReduce cluster simulator to test schedulers,HADOOP-5005,12412063,Test,Open,HADOOP,Hadoop Common,software,omalley,Hadoop Common is the common library for Apache Hadoop.,http://hadoop.apache.org/,Major,,,matei,matei,09/Jan/09 17:50,10/Jan/09 07:55,12/Jan/21 11:55,,,,,,,,,,,,test,,,,0,,,"Currently the Hadoop schedulers use a FakeTaskTrackerManager to run tests which is both messy and doesn't really simulate trackers going up and down, tasks finishing at different times, faiulres, etc. It would be nice to have a simulated MapReduce cluster where tasks really do take different amounts of (simulated) time, trackers may be slow, tasks can be made to fail, etc. The existing TaskTrackerManager interface given to the schedulers, plus perhaps a mockable clock (e.g. the FairScheduler.Clock class) should be enough to do all this. The end result will be easier-to-write and more complex scheduler tests.",,cdouglas,eli,hammer,matei,nidaley,omalley,vivekr,yhemanth,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,2009-01-10 03:39:07.301,,,false,,,,,,,,,,,,,,,,,126873,,,,,Sat Jan 10 07:55:31 UTC 2009,,,,,,,"0|i0i5d3:",103963,,,,,,,,,,,,,,,,,,,,,,,"10/Jan/09 03:39;yhemanth;Matei, we recently built a MiniMR based cluster for the capacity scheduler. Please look at HADOOP-4830. Can you see if that's along the lines you wanted ? If yes, maybe we can explore changing that to support schedulers generically.","10/Jan/09 07:55;matei;I actually saw that, but this is meant to be a cluster that just simulates the nodes rather than running tasktrackers in their own threads. This should allow for faster tests and more tests. It's an idea I was talking about to Owen, Sameer and Eric the other day, but not necessarily a short-term goal.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
contrib/data_join needs unit tests,HADOOP-3587,12398463,Test,Closed,HADOOP,Hadoop Common,software,omalley,Hadoop Common is the common library for Apache Hadoop.,http://hadoop.apache.org/,Major,Fixed,cdouglas,cdouglas,cdouglas,17/Jun/08 22:58,20/Nov/08 23:38,12/Jan/21 11:55,02/Jul/08 21:37,0.17.0,,,,0.19.0,,,,,,test,,,,0,,,"To insure against future incompatibility, there should be unit tests for the contrib/data_join framework.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,HADOOP-3526,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"28/Jun/08 01:53;cdouglas;3587-0.patch;https://issues.apache.org/jira/secure/attachment/12384880/3587-0.patch",,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,2008-06-28 20:23:29.477,,,false,,,,,,,,,,,,,,,,,126048,Reviewed,,,,Thu Jul 03 12:35:45 UTC 2008,,,,,,,"0|i0ib5b:",104900,,,,,,,,,,,,,,,,,,,,,,,"28/Jun/08 20:23;hadoopqa;-1 overall.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12384880/3587-0.patch
  against trunk revision 672376.

    +1 @author.  The patch does not contain any @author tags.

    +1 tests included.  The patch appears to include 4 new or modified tests.

    -1 patch.  The patch command could not apply the patch.

Console output: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch/2762/console

This message is automatically generated.","29/Jun/08 10:48;hadoopqa;-1 overall.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12384880/3587-0.patch
  against trunk revision 672376.

    +1 @author.  The patch does not contain any @author tags.

    +1 tests included.  The patch appears to include 4 new or modified tests.

    +1 javadoc.  The javadoc tool did not generate any warning messages.

    +1 javac.  The applied patch does not increase the total number of javac compiler warnings.

    +1 findbugs.  The patch does not introduce any new Findbugs warnings.

    +1 release audit.  The applied patch does not increase the total number of release audit warnings.

    +1 core tests.  The patch passed core unit tests.

    -1 contrib tests.  The patch failed contrib unit tests.

Test results: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch/2769/testReport/
Findbugs warnings: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch/2769/artifact/trunk/build/test/findbugs/newPatchFindbugsWarnings.html
Checkstyle results: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch/2769/artifact/trunk/build/test/checkstyle-errors.html
Console output: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch/2769/console

This message is automatically generated.","02/Jul/08 21:34;runping;
The patch looks good to me.

Runping
","02/Jul/08 21:37;cdouglas;I just committed this.","03/Jul/08 12:35;hudson;Integrated in Hadoop-trunk #537 (See [http://hudson.zones.apache.org/hudson/job/Hadoop-trunk/537/])",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Develop tests to test the DFS command line interface,HADOOP-3100,12392396,Test,Closed,HADOOP,Hadoop Common,software,omalley,Hadoop Common is the common library for Apache Hadoop.,http://hadoop.apache.org/,Major,Fixed,mukundm,mukundm,mukundm,27/Mar/08 00:30,22/Aug/08 19:50,12/Jan/21 11:55,01/Jul/08 21:10,0.16.1,0.17.0,,,0.18.0,,,,,,test,,,,0,,,"Develop tests to test the DFS command line interface. The DFS commands to test are:

           [-ls <path>]
           [-lsr <path>]
           [-du <path>]
           [-dus <path>]
           [-mv <src> <dst>]
           [-cp <src> <dst>]
           [-rm <path>]
           [-rmr <path>]
           [-expunge]
           [-put <localsrc> <dst>]
           [-copyFromLocal <localsrc> <dst>]
           [-moveFromLocal <localsrc> <dst>]
           [-get [-crc] <src> <localdst>]
           [-getmerge <src> <localdst> [addnl]]
           [-cat <src>]
           [-copyToLocal [-crc] <src> <localdst>]
           [-moveToLocal [-crc] <src> <localdst>]
           [-mkdir <path>]
           [-setrep [-R] [-w] <rep> <path/file>]
           [-touchz <path>]
           [-test -[ezd] <path>]
           [-stat [format] <path>]
           [-tail [-f] <file>]",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"24/Jun/08 20:40;mukundm;H3100.patch;https://issues.apache.org/jira/secure/attachment/12384623/H3100.patch","17/Jun/08 22:26;mukundm;H3100.patch;https://issues.apache.org/jira/secure/attachment/12384159/H3100.patch","03/May/08 19:21;nidaley;H3100.patch;https://issues.apache.org/jira/secure/attachment/12381373/H3100.patch","30/Apr/08 17:32;mukundm;H3100.patch;https://issues.apache.org/jira/secure/attachment/12381203/H3100.patch","30/Apr/08 17:18;mukundm;H3100.patch;https://issues.apache.org/jira/secure/attachment/12381202/H3100.patch","27/Mar/08 00:59;mukundm;H3100.patch;https://issues.apache.org/jira/secure/attachment/12378675/H3100.patch",,,,,,,,,,,,,,,,,,6.0,,,,,,,,,,,,,,,,,,,,2008-03-27 00:43:21.896,,,false,,,,,,,,,,,,,,,,,125788,,,,,Wed Jul 02 13:27:55 UTC 2008,,,,,,,"0|i0idjj:",105288,,,,,,,,,,,,,,,,,,,,,,,"27/Mar/08 00:43;mahadev;most of these are tested in TestDFSShell .... testErrOut() method. ","27/Mar/08 00:59;mukundm;Initial patch with the test driver code and test cases for:
ls
lsr
du
dus
mv

There are 31 test cases which perform 100 validations

The test cases (input commands and expected output) are defined in the testConf.xml file. This is the file that will be updated with other test cases.","30/Apr/08 17:18;mukundm;Here is an updated patch. It includes changes to the test driver and additional tests. Thanks to Karam and Ramya for the additional tests. There are 139 tests with 283 validations being done. 

The tests have been run on Windows, Mac and Linux. It adds < 30 seconds on linux/mac and 3 mins to the unit tests runtime on windows. 

I have run the ant test-patch target and there were no errors reported.
[exec] +1 overall.  

[exec]     @author +1.  The patch does not contain any @author tags.

[exec]     tests included +1.  The patch appears to include 323 new or modified tests.

[exec]     javadoc +1.  The javadoc tool did not generate any warning messages.

[exec]     javac +1.  The applied patch does not generate any new javac compiler warnings.

[exec]     findbugs +1.  The patch does not introduce any new Findbugs warnings.



Here are test cases being covered and the output from the test:

2008-04-30 09:45:55,298 INFO  cli.TestCLI (TestCLI.java:displayResults(170)) - Detailed results:
2008-04-30 09:45:55,299 INFO  cli.TestCLI (TestCLI.java:displayResults(171)) - ----------------------------------

2008-04-30 09:45:55,299 INFO  cli.TestCLI (TestCLI.java:displayResults(215)) - Summary results:
2008-04-30 09:45:55,299 INFO  cli.TestCLI (TestCLI.java:displayResults(216)) - ----------------------------------

2008-04-30 09:45:55,300 INFO  cli.TestCLI (TestCLI.java:displayResults(236)) -                Testing mode: test
2008-04-30 09:45:55,300 INFO  cli.TestCLI (TestCLI.java:displayResults(237)) - 
2008-04-30 09:45:55,300 INFO  cli.TestCLI (TestCLI.java:displayResults(238)) -              Overall result: +++ PASS +++
2008-04-30 09:45:55,300 INFO  cli.TestCLI (TestCLI.java:displayResults(240)) -                # Tests pass: 139 (100%)
2008-04-30 09:45:55,303 INFO  cli.TestCLI (TestCLI.java:displayResults(242)) -                # Tests fail: 0 (0%)
2008-04-30 09:45:55,304 INFO  cli.TestCLI (TestCLI.java:displayResults(244)) -          # Validations done: 283 (each test may do multiple validations)
2008-04-30 09:45:55,304 INFO  cli.TestCLI (TestCLI.java:displayResults(247)) - 
2008-04-30 09:45:55,304 INFO  cli.TestCLI (TestCLI.java:displayResults(248)) - Failing tests:
2008-04-30 09:45:55,305 INFO  cli.TestCLI (TestCLI.java:displayResults(249)) - --------------
2008-04-30 09:45:55,305 INFO  cli.TestCLI (TestCLI.java:displayResults(261)) - NONE
2008-04-30 09:45:55,305 INFO  cli.TestCLI (TestCLI.java:displayResults(265)) - 
2008-04-30 09:45:55,306 INFO  cli.TestCLI (TestCLI.java:displayResults(266)) - Passing tests:
2008-04-30 09:45:55,306 INFO  cli.TestCLI (TestCLI.java:displayResults(267)) - --------------
2008-04-30 09:45:55,306 INFO  cli.TestCLI (TestCLI.java:displayResults(271)) - 1: ls: file using absolute path
2008-04-30 09:45:55,306 INFO  cli.TestCLI (TestCLI.java:displayResults(271)) - 2: ls: file using relative path
2008-04-30 09:45:55,306 INFO  cli.TestCLI (TestCLI.java:displayResults(271)) - 3: ls: files using globbing
2008-04-30 09:45:55,307 INFO  cli.TestCLI (TestCLI.java:displayResults(271)) - 4: ls: directory using absolute path
2008-04-30 09:45:55,307 INFO  cli.TestCLI (TestCLI.java:displayResults(271)) - 5: ls: directory using relative path
2008-04-30 09:45:55,307 INFO  cli.TestCLI (TestCLI.java:displayResults(271)) - 6: ls: directory using globbing
2008-04-30 09:45:55,307 INFO  cli.TestCLI (TestCLI.java:displayResults(271)) - 7: ls: file/directory that does not exist in /
2008-04-30 09:45:55,307 INFO  cli.TestCLI (TestCLI.java:displayResults(271)) - 8: ls: file/directory that does not exist in home directory (/user/username)
2008-04-30 09:45:55,308 INFO  cli.TestCLI (TestCLI.java:displayResults(271)) - 9: lsr: files/directories using absolute path
2008-04-30 09:45:55,308 INFO  cli.TestCLI (TestCLI.java:displayResults(271)) - 10: lsr: files/directories using relative path
2008-04-30 09:45:55,308 INFO  cli.TestCLI (TestCLI.java:displayResults(271)) - 11: lsr: files/directories using globbing
2008-04-30 09:45:55,308 INFO  cli.TestCLI (TestCLI.java:displayResults(271)) - 12: lsr: file/directory that does not exist in /
2008-04-30 09:45:55,308 INFO  cli.TestCLI (TestCLI.java:displayResults(271)) - 13: lsr: file/directory that does not exist in home directory (/user/username)
2008-04-30 09:45:55,308 INFO  cli.TestCLI (TestCLI.java:displayResults(271)) - 14: du: file using absolute path
2008-04-30 09:45:55,309 INFO  cli.TestCLI (TestCLI.java:displayResults(271)) - 15: du: file using relative path
2008-04-30 09:45:55,313 INFO  cli.TestCLI (TestCLI.java:displayResults(271)) - 16: du: files using globbing
2008-04-30 09:45:55,314 INFO  cli.TestCLI (TestCLI.java:displayResults(271)) - 17: du: directory using absolute path
2008-04-30 09:45:55,314 INFO  cli.TestCLI (TestCLI.java:displayResults(271)) - 18: du: directory using relative path
2008-04-30 09:45:55,314 INFO  cli.TestCLI (TestCLI.java:displayResults(271)) - 19: du: directory using globbing
2008-04-30 09:45:55,314 INFO  cli.TestCLI (TestCLI.java:displayResults(271)) - 20: dus: directories/files using absolute path
2008-04-30 09:45:55,315 INFO  cli.TestCLI (TestCLI.java:displayResults(271)) - 21: dus: directories/files using relative path
2008-04-30 09:45:55,315 INFO  cli.TestCLI (TestCLI.java:displayResults(271)) - 22: dus: directories/files using globbing
2008-04-30 09:45:55,315 INFO  cli.TestCLI (TestCLI.java:displayResults(271)) - 23: mv: file (absolute path) to file (absolute path)
2008-04-30 09:45:55,315 INFO  cli.TestCLI (TestCLI.java:displayResults(271)) - 24: mv: file (absolute path) to file (relative path)
2008-04-30 09:45:55,315 INFO  cli.TestCLI (TestCLI.java:displayResults(271)) - 25: mv: file (absolute path) to directory (absolute path); keep the same name at the destination
2008-04-30 09:45:55,315 INFO  cli.TestCLI (TestCLI.java:displayResults(271)) - 26: mv: file (absolute path) to directory (absolute path); keep the same name at the destination [ TIED to previous test ]
2008-04-30 09:45:55,315 INFO  cli.TestCLI (TestCLI.java:displayResults(271)) - 27: mv: file (absolute path) to directory (absolute path); change the name at the destination
2008-04-30 09:45:55,316 INFO  cli.TestCLI (TestCLI.java:displayResults(271)) - 28: mv: file (absolute path) to directory (absolute path); change the name at the destination [ TIED to previous test ]
2008-04-30 09:45:55,316 INFO  cli.TestCLI (TestCLI.java:displayResults(271)) - 29: mv: files (absolute path) to directory (absolute path) using globbing
2008-04-30 09:45:55,316 INFO  cli.TestCLI (TestCLI.java:displayResults(271)) - 30: mv: files (absolute path) to directory (absolute path) using globbing [ TIED to previous test ]
2008-04-30 09:45:55,316 INFO  cli.TestCLI (TestCLI.java:displayResults(271)) - 31: mv: file (relative) to file (relative)
2008-04-30 09:45:55,316 INFO  cli.TestCLI (TestCLI.java:displayResults(271)) - 32: cp: file (absolute path) to file (absolute path)
2008-04-30 09:45:55,316 INFO  cli.TestCLI (TestCLI.java:displayResults(271)) - 33: cp: file (absolute path) to file (relative path)
2008-04-30 09:45:55,316 INFO  cli.TestCLI (TestCLI.java:displayResults(271)) - 34: cp: file (relative path) to file (absolute path)
2008-04-30 09:45:55,317 INFO  cli.TestCLI (TestCLI.java:displayResults(271)) - 35: cp: file (relative path) to file (relative path)
2008-04-30 09:45:55,317 INFO  cli.TestCLI (TestCLI.java:displayResults(271)) - 36: cp: file (absolute path) to directory (absolute path); keep the same name at the destination
2008-04-30 09:45:55,317 INFO  cli.TestCLI (TestCLI.java:displayResults(271)) - 37: cp: file (absolute path) to directory (absolute path); change the name at the destination
2008-04-30 09:45:55,317 INFO  cli.TestCLI (TestCLI.java:displayResults(271)) - 38: cp: files to directory (absolute path) using globbing
2008-04-30 09:45:55,317 INFO  cli.TestCLI (TestCLI.java:displayResults(271)) - 39: cp: files to directory (absolute path) without globbing
2008-04-30 09:45:55,318 INFO  cli.TestCLI (TestCLI.java:displayResults(271)) - 40: cp: copying non existent file (absolute path)
2008-04-30 09:45:55,318 INFO  cli.TestCLI (TestCLI.java:displayResults(271)) - 41: cp: copying non existent file (relative path)
2008-04-30 09:45:55,318 INFO  cli.TestCLI (TestCLI.java:displayResults(271)) - 42: cp: files to an existent file using globbing
2008-04-30 09:45:55,318 INFO  cli.TestCLI (TestCLI.java:displayResults(271)) - 43: cp: files to an existent file without globbing
2008-04-30 09:45:55,318 INFO  cli.TestCLI (TestCLI.java:displayResults(271)) - 44: cp: files to a non existent directory using globbing
2008-04-30 09:45:55,318 INFO  cli.TestCLI (TestCLI.java:displayResults(271)) - 45: cp: files to a non existent directory without globbing
2008-04-30 09:45:55,318 INFO  cli.TestCLI (TestCLI.java:displayResults(271)) - 46: rm: removing a file (absolute path) 
2008-04-30 09:45:55,319 INFO  cli.TestCLI (TestCLI.java:displayResults(271)) - 47: rm: removing a file (relative path) 
2008-04-30 09:45:55,319 INFO  cli.TestCLI (TestCLI.java:displayResults(271)) - 48: rm: removing files by globbing (absolute path) 
2008-04-30 09:45:55,319 INFO  cli.TestCLI (TestCLI.java:displayResults(271)) - 49: rm: removing files by globbing (relative path) 
2008-04-30 09:45:55,319 INFO  cli.TestCLI (TestCLI.java:displayResults(271)) - 50: rm: removing a directory (absolute path) 
2008-04-30 09:45:55,319 INFO  cli.TestCLI (TestCLI.java:displayResults(271)) - 51: rm: removing a directory (relative path) 
2008-04-30 09:45:55,319 INFO  cli.TestCLI (TestCLI.java:displayResults(271)) - 52: rm: removing a nonexistent file (absolute path) 
2008-04-30 09:45:55,319 INFO  cli.TestCLI (TestCLI.java:displayResults(271)) - 53: rm: removing a nonexistent file (relative path) 
2008-04-30 09:45:55,320 INFO  cli.TestCLI (TestCLI.java:displayResults(271)) - 54: rmr: removing a file (absolute path) 
2008-04-30 09:45:55,320 INFO  cli.TestCLI (TestCLI.java:displayResults(271)) - 55: rmr: removing a file (relative path) 
2008-04-30 09:45:55,320 INFO  cli.TestCLI (TestCLI.java:displayResults(271)) - 56: rmr: removing a directory (absolute path) 
2008-04-30 09:45:55,320 INFO  cli.TestCLI (TestCLI.java:displayResults(271)) - 57: rmr: removing a directory (relative path) 
2008-04-30 09:45:55,320 INFO  cli.TestCLI (TestCLI.java:displayResults(271)) - 58: rmr: removing directories by globbing (absolute path) 
2008-04-30 09:45:55,320 INFO  cli.TestCLI (TestCLI.java:displayResults(271)) - 59: rmr: removing directories by globbing (relative path) 
2008-04-30 09:45:55,320 INFO  cli.TestCLI (TestCLI.java:displayResults(271)) - 60: rmr: removing a nonexistent file (absolute path) 
2008-04-30 09:45:55,321 INFO  cli.TestCLI (TestCLI.java:displayResults(271)) - 61: rmr: removing a nonexistent file (relative path) 
2008-04-30 09:45:55,321 INFO  cli.TestCLI (TestCLI.java:displayResults(271)) - 62: put: putting file into a file (absolute path)
2008-04-30 09:45:55,321 INFO  cli.TestCLI (TestCLI.java:displayResults(271)) - 63: put: putting file into a file (relative path)
2008-04-30 09:45:55,321 INFO  cli.TestCLI (TestCLI.java:displayResults(271)) - 64: put: putting file into a directory(absolute path)
2008-04-30 09:45:55,321 INFO  cli.TestCLI (TestCLI.java:displayResults(271)) - 65: put: putting file into a directory(relative path)
2008-04-30 09:45:55,322 INFO  cli.TestCLI (TestCLI.java:displayResults(271)) - 66: put: putting many files into an existing directory(absolute path)
2008-04-30 09:45:55,322 INFO  cli.TestCLI (TestCLI.java:displayResults(271)) - 67: put: putting many files into an existing directory(relative path)
2008-04-30 09:45:55,322 INFO  cli.TestCLI (TestCLI.java:displayResults(271)) - 68: put: putting non existent file(absolute path)
2008-04-30 09:45:55,322 INFO  cli.TestCLI (TestCLI.java:displayResults(271)) - 69: put: putting non existent file(relative path)
2008-04-30 09:45:55,322 INFO  cli.TestCLI (TestCLI.java:displayResults(271)) - 70: put: putting file into an already existing destination(absolute path)
2008-04-30 09:45:55,322 INFO  cli.TestCLI (TestCLI.java:displayResults(271)) - 71: put: putting file into an already existing destination(relative path)
2008-04-30 09:45:55,322 INFO  cli.TestCLI (TestCLI.java:displayResults(271)) - 72: put: putting many files into an existing file
2008-04-30 09:45:55,323 INFO  cli.TestCLI (TestCLI.java:displayResults(271)) - 73: put: putting many files into a non existent directory
2008-04-30 09:45:55,323 INFO  cli.TestCLI (TestCLI.java:displayResults(271)) - 74: copyFromLocal: copying file into a file (absolute path)
2008-04-30 09:45:55,323 INFO  cli.TestCLI (TestCLI.java:displayResults(271)) - 75: copyFromLocal: copying file into a file (relative path)
2008-04-30 09:45:55,323 INFO  cli.TestCLI (TestCLI.java:displayResults(271)) - 76: copyFromLocal: copying file into a directory(absolute path)
2008-04-30 09:45:55,323 INFO  cli.TestCLI (TestCLI.java:displayResults(271)) - 77: copyFromLocal: copying file into a directory(relative path)
2008-04-30 09:45:55,323 INFO  cli.TestCLI (TestCLI.java:displayResults(271)) - 78: copyFromLocal: copying many files into an existing directory(absolute path)
2008-04-30 09:45:55,323 INFO  cli.TestCLI (TestCLI.java:displayResults(271)) - 79: copyFromLocal: copying many files into an existing directory(relative path)
2008-04-30 09:45:55,323 INFO  cli.TestCLI (TestCLI.java:displayResults(271)) - 80: copyFromLocal: copying non existent file(absolute path)
2008-04-30 09:45:55,324 INFO  cli.TestCLI (TestCLI.java:displayResults(271)) - 81: copyFromLocal: copying non existent file(relative path)
2008-04-30 09:45:55,324 INFO  cli.TestCLI (TestCLI.java:displayResults(271)) - 82: copyFromLocal: copying file into an already existing destination(absolute path)
2008-04-30 09:45:55,324 INFO  cli.TestCLI (TestCLI.java:displayResults(271)) - 83: copyFromLocal: copying file into an already existing destination(relative path)
2008-04-30 09:45:55,324 INFO  cli.TestCLI (TestCLI.java:displayResults(271)) - 84: copyFromLocal: copying many files into an existing file
2008-04-30 09:45:55,324 INFO  cli.TestCLI (TestCLI.java:displayResults(271)) - 85: copyFromLocal: copying many files into a non existent directory
2008-04-30 09:45:55,325 INFO  cli.TestCLI (TestCLI.java:displayResults(271)) - 86: get: getting non existent(absolute path)
2008-04-30 09:45:55,325 INFO  cli.TestCLI (TestCLI.java:displayResults(271)) - 87: get: getting non existent file(relative path)
2008-04-30 09:45:55,325 INFO  cli.TestCLI (TestCLI.java:displayResults(271)) - 88: cat: contents of file(absolute path)
2008-04-30 09:45:55,325 INFO  cli.TestCLI (TestCLI.java:displayResults(271)) - 89: cat: contents of file(relative path)
2008-04-30 09:45:55,325 INFO  cli.TestCLI (TestCLI.java:displayResults(271)) - 90: cat: contents of files(absolute path) using globbing
2008-04-30 09:45:55,326 INFO  cli.TestCLI (TestCLI.java:displayResults(271)) - 91: cat: contents of files(relative path) using globbing
2008-04-30 09:45:55,326 INFO  cli.TestCLI (TestCLI.java:displayResults(271)) - 92: cat: contents of files(absolute path) without globbing
2008-04-30 09:45:55,326 INFO  cli.TestCLI (TestCLI.java:displayResults(271)) - 93: cat: contents of files(relative path) without globbing
2008-04-30 09:45:55,326 INFO  cli.TestCLI (TestCLI.java:displayResults(271)) - 94: cat: contents of file(absolute path) that does not exist
2008-04-30 09:45:55,326 INFO  cli.TestCLI (TestCLI.java:displayResults(271)) - 95: cat: contents of file(relative path) that does not exist
2008-04-30 09:45:55,326 INFO  cli.TestCLI (TestCLI.java:displayResults(271)) - 96: cat: contents of directory(absolute path)
2008-04-30 09:45:55,326 INFO  cli.TestCLI (TestCLI.java:displayResults(271)) - 97: cat: contents of directory(relative path)
2008-04-30 09:45:55,327 INFO  cli.TestCLI (TestCLI.java:displayResults(271)) - 98: copyToLocal: non existent relative path
2008-04-30 09:45:55,327 INFO  cli.TestCLI (TestCLI.java:displayResults(271)) - 99: copyToLocal: non existent absolute path
2008-04-30 09:45:55,327 INFO  cli.TestCLI (TestCLI.java:displayResults(271)) - 100: mkdir: creating directory (absolute path) 
2008-04-30 09:45:55,327 INFO  cli.TestCLI (TestCLI.java:displayResults(271)) - 101: mkdir: creating directory (relative path) 
2008-04-30 09:45:55,327 INFO  cli.TestCLI (TestCLI.java:displayResults(271)) - 102: mkdir: creating many directories (absolute path) 
2008-04-30 09:45:55,327 INFO  cli.TestCLI (TestCLI.java:displayResults(271)) - 103: mkdir: creating many directories (relative path) 
2008-04-30 09:45:55,327 INFO  cli.TestCLI (TestCLI.java:displayResults(271)) - 104: mkdir: creating a directory with the name of an already existing directory
2008-04-30 09:45:55,328 INFO  cli.TestCLI (TestCLI.java:displayResults(271)) - 105: mkdir: creating a directory with the name of an already existing file
2008-04-30 09:45:55,328 INFO  cli.TestCLI (TestCLI.java:displayResults(271)) - 106: setrep: existent file (absolute path)
2008-04-30 09:45:55,328 INFO  cli.TestCLI (TestCLI.java:displayResults(271)) - 107: setrep: existent file (relative path)
2008-04-30 09:45:55,328 INFO  cli.TestCLI (TestCLI.java:displayResults(271)) - 108: setrep: existent directory (absolute path)
2008-04-30 09:45:55,328 INFO  cli.TestCLI (TestCLI.java:displayResults(271)) - 109: setrep: existent directory (relative path)
2008-04-30 09:45:55,329 INFO  cli.TestCLI (TestCLI.java:displayResults(271)) - 110: setrep: non existent file (absolute path)
2008-04-30 09:45:55,329 INFO  cli.TestCLI (TestCLI.java:displayResults(271)) - 111: setrep: non existent file (relative path)
2008-04-30 09:45:55,329 INFO  cli.TestCLI (TestCLI.java:displayResults(271)) - 112: touchz: touching file (absolute path) 
2008-04-30 09:45:55,329 INFO  cli.TestCLI (TestCLI.java:displayResults(271)) - 113: touchz: touching file(relative path) 
2008-04-30 09:45:55,329 INFO  cli.TestCLI (TestCLI.java:displayResults(271)) - 114: touchz: touching many files 
2008-04-30 09:45:55,329 INFO  cli.TestCLI (TestCLI.java:displayResults(271)) - 115: touchz: touching already existing file 
2008-04-30 09:45:55,329 INFO  cli.TestCLI (TestCLI.java:displayResults(271)) - 116: test: non existent file (absolute path)
2008-04-30 09:45:55,329 INFO  cli.TestCLI (TestCLI.java:displayResults(271)) - 117: test: non existent file (relative path)
2008-04-30 09:45:55,330 INFO  cli.TestCLI (TestCLI.java:displayResults(271)) - 118: test: non existent directory (absolute path)
2008-04-30 09:45:55,330 INFO  cli.TestCLI (TestCLI.java:displayResults(271)) - 119: test: non existent directory (relative path)
2008-04-30 09:45:55,330 INFO  cli.TestCLI (TestCLI.java:displayResults(271)) - 120: stat: statistics about file(absolute path)
2008-04-30 09:45:55,330 INFO  cli.TestCLI (TestCLI.java:displayResults(271)) - 121: stat: statistics about file(relative path)
2008-04-30 09:45:55,330 INFO  cli.TestCLI (TestCLI.java:displayResults(271)) - 122: stat: statistics about directory(absolute path)
2008-04-30 09:45:55,330 INFO  cli.TestCLI (TestCLI.java:displayResults(271)) - 123: stat: statistics about directory(relative path)
2008-04-30 09:45:55,330 INFO  cli.TestCLI (TestCLI.java:displayResults(271)) - 124: stat: statistics about files (absolute path) using globbing
2008-04-30 09:45:55,331 INFO  cli.TestCLI (TestCLI.java:displayResults(271)) - 125: stat: statistics about files (relative path) using globbing
2008-04-30 09:45:55,331 INFO  cli.TestCLI (TestCLI.java:displayResults(271)) - 126: stat: statistics about file or directory(absolute path) that does not exist
2008-04-30 09:45:55,331 INFO  cli.TestCLI (TestCLI.java:displayResults(271)) - 127: stat: statistics about file or directory(relative path) that does not exist 
2008-04-30 09:45:55,331 INFO  cli.TestCLI (TestCLI.java:displayResults(271)) - 128: tail: contents of file(absolute path)
2008-04-30 09:45:55,331 INFO  cli.TestCLI (TestCLI.java:displayResults(271)) - 129: tail: contents of file(relative path)
2008-04-30 09:45:55,331 INFO  cli.TestCLI (TestCLI.java:displayResults(271)) - 130: tail: contents of files(absolute path) using globbing
2008-04-30 09:45:55,332 INFO  cli.TestCLI (TestCLI.java:displayResults(271)) - 131: tail: contents of files(relative path) using globbing
2008-04-30 09:45:55,332 INFO  cli.TestCLI (TestCLI.java:displayResults(271)) - 132: tail: contents of file(absolute path) that does not exist
2008-04-30 09:45:55,332 INFO  cli.TestCLI (TestCLI.java:displayResults(271)) - 133: tail: contents of file(relative path) that does not exist
2008-04-30 09:45:55,332 INFO  cli.TestCLI (TestCLI.java:displayResults(271)) - 134: tail: contents of directory(absolute path) 
2008-04-30 09:45:55,332 INFO  cli.TestCLI (TestCLI.java:displayResults(271)) - 135: tail: contents of directory(relative path)
2008-04-30 09:45:55,332 INFO  cli.TestCLI (TestCLI.java:displayResults(271)) - 136: moveFromLocal: moving non existent file(absolute path)
2008-04-30 09:45:55,332 INFO  cli.TestCLI (TestCLI.java:displayResults(271)) - 137: moveFromLocal: moving non existent file(relative path)
2008-04-30 09:45:55,333 INFO  cli.TestCLI (TestCLI.java:displayResults(271)) - 138: moveFromLocal: moving many files into an existing file
2008-04-30 09:45:55,333 INFO  cli.TestCLI (TestCLI.java:displayResults(271)) - 139: moveFromLocal: moving many files into a non existent directory
","30/Apr/08 19:20;hadoopqa;-1 overall.  Here are the results of testing the latest attachment 
http://issues.apache.org/jira/secure/attachment/12381203/H3100.patch
against trunk revision 645773.

    @author +1.  The patch does not contain any @author tags.

    tests included +1.  The patch appears to include 327 new or modified tests.

    patch -1.  The patch command could not apply the patch.

Console output: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch/2353/console

This message is automatically generated.","03/May/08 19:21;nidaley;Update patch for trunk","04/May/08 08:05;hadoopqa;-1 overall.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12381373/H3100.patch
  against trunk revision .

    +1 @author.  The patch does not contain any @author tags.

    +1 tests included.  The patch appears to include 327 new or modified tests.

    +1 javadoc.  The javadoc tool did not generate any warning messages.

    +1 javac.  The applied patch does not increase the total number of javac compiler warnings.

    +1 findbugs.  The patch does not introduce any new Findbugs warnings.

    -1 release audit.  The applied patch generated 213 release audit warnings (more than the trunk's current 207 warnings).

    -1 core tests.  The patch failed core unit tests.

    +1 contrib tests.  The patch passed contrib unit tests.

Test results: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch/2389/testReport/
Release audit warnings: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch/2389/artifact/trunk/current/releaseAuditDiffWarnings.txt
Findbugs warnings: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch/2389/artifact/trunk/build/test/findbugs/newPatchFindbugsWarnings.html
Checkstyle results: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch/2389/artifact/trunk/build/test/checkstyle-errors.html
Console output: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch/2389/console

This message is automatically generated.","22/May/08 16:42;mukundm;Canceling patch as it needs an update for trunk due to command like output changes in trunk","17/Jun/08 22:26;mukundm;Updated patch to work with changes in 0.18.0","18/Jun/08 00:03;hadoopqa;-1 overall.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12384159/H3100.patch
  against trunk revision 668832.

    +1 @author.  The patch does not contain any @author tags.

    +1 tests included.  The patch appears to include 327 new or modified tests.

    +1 javadoc.  The javadoc tool did not generate any warning messages.

    +1 javac.  The applied patch does not increase the total number of javac compiler warnings.

    +1 findbugs.  The patch does not introduce any new Findbugs warnings.

    -1 release audit.  The applied patch generated 209 release audit warnings (more than the trunk's current 203 warnings).

    -1 core tests.  The patch failed core unit tests.

    +1 contrib tests.  The patch passed contrib unit tests.

Test results: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch/2674/testReport/
Release audit warnings: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch/2674/artifact/trunk/current/releaseAuditDiffWarnings.txt
Findbugs warnings: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch/2674/artifact/trunk/build/test/findbugs/newPatchFindbugsWarnings.html
Checkstyle results: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch/2674/artifact/trunk/build/test/checkstyle-errors.html
Console output: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch/2674/console

This message is automatically generated.","19/Jun/08 04:09;nidaley;Release audit warning are ok.  The new files don't need Apache headers.

Test failure is due to org.apache.hadoop.cli.util.TestData not having any test methods.  This class should be renamed so that it doesn't start with the work ""Test"".","24/Jun/08 15:47;omalley;canceling patch until Nigel's suggestion of changing the class name is done.","24/Jun/08 20:40;mukundm;Updated patch: renamed TestData to CLITestData","24/Jun/08 22:15;hadoopqa;-1 overall.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12384623/H3100.patch
  against trunk revision 671277.

    +1 @author.  The patch does not contain any @author tags.

    +1 tests included.  The patch appears to include 327 new or modified tests.

    +1 javadoc.  The javadoc tool did not generate any warning messages.

    +1 javac.  The applied patch does not increase the total number of javac compiler warnings.

    +1 findbugs.  The patch does not introduce any new Findbugs warnings.

    -1 release audit.  The applied patch generated 213 release audit warnings (more than the trunk's current 207 warnings).

    +1 core tests.  The patch passed core unit tests.

    +1 contrib tests.  The patch passed contrib unit tests.

Test results: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch/2727/testReport/
Release audit warnings: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch/2727/artifact/trunk/current/releaseAuditDiffWarnings.txt
Findbugs warnings: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch/2727/artifact/trunk/build/test/findbugs/newPatchFindbugsWarnings.html
Checkstyle results: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch/2727/artifact/trunk/build/test/checkstyle-errors.html
Console output: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch/2727/console

This message is automatically generated.","27/Jun/08 16:58;mukundm;Release audit warning are ok. The new files don't need Apache headers. 

The patch is good to go","01/Jul/08 21:10;mukundm;I just committed this.","02/Jul/08 13:27;hudson;Integrated in Hadoop-trunk #536 (See [http://hudson.zones.apache.org/hudson/job/Hadoop-trunk/536/])",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
[HOD] Put in place unit test framework for HOD,HADOOP-2775,12387759,Test,Closed,HADOOP,Hadoop Common,software,omalley,Hadoop Common is the common library for Apache Hadoop.,http://hadoop.apache.org/,Major,Fixed,vinodkv,yhemanth,yhemanth,04/Feb/08 03:49,21/May/08 20:05,12/Jan/21 11:55,14/Mar/08 05:14,0.16.0,,,,0.17.0,,,,,,contrib/hod,,,,0,,,"HOD does not have any unit tests in place currently. This issue is to decide on a framework that would be effective for our python code base. Something on the lines of pyUnit would be good. The fix should put in place any dependencies needed for running the tests, and should also define some tests that demonstrate how to write further tests. We would not be defining a complete unit test suite for the entire code base right now, but would incrementatlly add tests as changes are made.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"12/Mar/08 08:15;vinodkv;HADOOP-2775.1;https://issues.apache.org/jira/secure/attachment/12377674/HADOOP-2775.1","12/Feb/08 15:26;vinodkv;patch_unittesting;https://issues.apache.org/jira/secure/attachment/12375373/patch_unittesting","13/Feb/08 05:01;vinodkv;patch_unittesting.1;https://issues.apache.org/jira/secure/attachment/12375443/patch_unittesting.1","15/Feb/08 06:47;vinodkv;patch_unittesting.2;https://issues.apache.org/jira/secure/attachment/12375652/patch_unittesting.2","18/Feb/08 08:28;vinodkv;patch_unittesting.3;https://issues.apache.org/jira/secure/attachment/12375814/patch_unittesting.3","19/Feb/08 09:01;vinodkv;patch_unittesting.4;https://issues.apache.org/jira/secure/attachment/12375905/patch_unittesting.4","20/Feb/08 05:45;vinodkv;patch_unittesting.5;https://issues.apache.org/jira/secure/attachment/12375997/patch_unittesting.5",,,,,,,,,,,,,,,,,7.0,,,,,,,,,,,,,,,,,,,,2008-02-12 15:26:10.27,,,false,,,,,,,,,,,,,,,,,125645,Reviewed,,,,Fri Mar 14 15:52:59 UTC 2008,,,,,,,"0|i0if6v:",105555,A unit testing framework based on pyunit is added to HOD. Developers contributing patches to HOD should now contribute unit tests along with the patches where possible.,,,,,,,,,,,,,,,,,,,,,,"12/Feb/08 15:26;vinodkv;Adding unitest framework using Pyunit. Added an example hodlig/Testing/testModule.py which can be used as a template. --ant test-- would now run hod tests too.

Need Python 2.5.1 to be installed on Hudson.","12/Feb/08 15:28;vinodkv;oh.. forgot the license. Will submit again tomorrow. Need revision of everything else barring that.","13/Feb/08 05:02;vinodkv;Reattaching. Including license headers in each file.","14/Feb/08 12:15;yhemanth;Some comments:

- Let's move the tests under hod directly instead of under hod/hodlib.
- The 'main' module is not being properly excluded as expected. By the same argument, any file which does not begin with test will not be excluded. I think we should worry about excluding only *test* modules, where test modules, by our convention, start with 'test'
- The code in the test module's runTests is repeated. We should explore pulling it out into a common place, like a base class.
- I am not sure we should have tests beginning with _test_. Can't we just have them begin with test_ ?
- The output from the tests, when run through 'ant test', is in the wrong order.  We can either remove our outputs, or put them in the right order.","15/Feb/08 06:47;vinodkv;    * moved the tests to hod/Testing. Changed build.xml to reflect this too.
    * 'excludes' now handles only modules starting with 'test'. Files not starting with 'test' like main.py, __init__.py are automatically excluded.
    * Refactored code from each module's ModuleTestSuite class to a base class BaseTestSuite in Testing/lib.py. Changed how we pick up names of testclasses also.
    * All the test classes now begin with test_ (and not _test_). Changed SuiteCallers method from testModule() to RunModuleTests() so that it doesn't clash with name convention of test classes.
    * Output from the tests is fixed now to be in correct order.
    * Earlier failure of some test module due to say syntax errors kills the whole test process. It's handled now to continue despite errors in some test modules.
    * Made test target depend on compile target, so that ant test can be directly run after making changes 
","18/Feb/08 08:28;vinodkv;Changing ant build.xml to detect python through a -Dpython.home option instead of checking system's $PATH through `which python`. As for version, currently checking only for Python 2.5.1.","18/Feb/08 10:30;yhemanth;Looks good now.. Few more comments:

- Failing test cases should fail the ant test task
- Currently, contrib test target would fail if a required python version is not specified or available. This would be inconvenient for users not interested in running HOD unit tests, but would like to fire a test build at the contrib level. We could simply ignore running the tests if the required python is not found. However, that has a side-effect of hiding misconfigured python  on Hudson. Given that the latter would be rare, and is a one time setup, I would still go with that approach. Comments ?
- At a suite level only tearDown is defined, but not setUp.
- Can we make the directory 'test' rather than 'Testing' - just a more conventional name.","19/Feb/08 09:01;vinodkv;   *  Failing test cases now make the build fail. Total number of failures + errors is reported back as return code of run tests.
   * python.home or python version mismatch(currently supporting only 2.5.1) would now make ant test to report silently, but not fail, so that other contrib tests may continue. This execution path is not traced on hudson once python stuff is setup there.
   * At a suite level setUp is done through ModuleTestSuite.__init__. No changes here.
   * Moved testcases to src/contrib/hod/test/
   * Fixed some of the testcase reporting to make it look better.","20/Feb/08 05:45;vinodkv;   * Renaming testing directory to test broke things, python had a built-in test module. Changed name to ""testing""
   * Changed ant target names so that they reflect things better. Slightly made changes in the order of calling of targets also.","20/Feb/08 17:21;yhemanth;+1. Looks good.

","11/Mar/08 04:45;vinodkv;Submitting the patch.","12/Mar/08 05:31;hadoopqa;-1 overall.  Here are the results of testing the latest attachment 
http://issues.apache.org/jira/secure/attachment/12375997/patch_unittesting.5
against trunk revision 619744.

    @author +1.  The patch does not contain any @author tags.

    tests included +1.  The patch appears to include 29 new or modified tests.

    javadoc +1.  The javadoc tool did not generate any warning messages.

    javac +1.  The applied patch does not generate any new javac compiler warnings.

    release audit -1.  The applied patch generated 194 release audit warnings (more than the trunk's current 192 warnings).

    findbugs +1.  The patch does not introduce any new Findbugs warnings.

    core tests -1.  The patch failed core unit tests.

    contrib tests +1.  The patch passed contrib unit tests.

Test results: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch/1943/testReport/
Findbugs warnings: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch/1943/artifact/trunk/build/test/findbugs/newPatchFindbugsWarnings.html
Checkstyle results: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch/1943/artifact/trunk/build/test/checkstyle-errors.html
Release audit warnings: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch/1943/artifact/trunk/current/releaseAuditDiffWarnings.txt
Console output: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch/1943/console

This message is automatically generated.","12/Mar/08 06:57;vinodkv;The core tests failed are related to DFS and not this patch.

The patch is committable.","12/Mar/08 08:14;vinodkv;Cancelling to fix the release audit warnings","12/Mar/08 08:15;vinodkv;Reattaching the patch.","12/Mar/08 08:18;vinodkv;Submitting. File HADOOP-2775.1 is the latest patch.","13/Mar/08 17:21;hadoopqa;+1 overall.  Here are the results of testing the latest attachment 
http://issues.apache.org/jira/secure/attachment/12377674/HADOOP-2775.1
against trunk revision 619744.

    @author +1.  The patch does not contain any @author tags.

    tests included +1.  The patch appears to include 29 new or modified tests.

    javadoc +1.  The javadoc tool did not generate any warning messages.

    javac +1.  The applied patch does not generate any new javac compiler warnings.

    release audit +1.  The applied patch does not generate any new release audit warnings.

    findbugs +1.  The patch does not introduce any new Findbugs warnings.

    core tests +1.  The patch passed core unit tests.

    contrib tests +1.  The patch passed contrib unit tests.

Test results: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch/1954/testReport/
Findbugs warnings: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch/1954/artifact/trunk/build/test/findbugs/newPatchFindbugsWarnings.html
Checkstyle results: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch/1954/artifact/trunk/build/test/checkstyle-errors.html
Console output: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch/1954/console

This message is automatically generated.","14/Mar/08 05:14;ddas;I just committed this. Thanks, Vinod!","14/Mar/08 15:52;hudson;Integrated in Hadoop-trunk #428 (See [http://hudson.zones.apache.org/hudson/job/Hadoop-trunk/428/])",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Update gridmix to avoid artificially long tail,HADOOP-2852,12389060,Test,Closed,HADOOP,Hadoop Common,software,omalley,Hadoop Common is the common library for Apache Hadoop.,http://hadoop.apache.org/,Major,Fixed,cdouglas,cdouglas,cdouglas,19/Feb/08 21:22,14/Mar/08 18:31,12/Jan/21 11:55,22/Feb/08 00:33,0.16.0,,,,0.16.1,,,,,,test,,,,0,,,"The MaxEntropy test in the gridmix benchmark is submitted late into the queue, iterating past the point where the cluster is saturated. This dilutes the throughput measurement- the purpose of this benchmark- by making the tail overly dependent on the performance of a single job.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"19/Feb/08 21:37;cdouglas;2852.patch;https://issues.apache.org/jira/secure/attachment/12375967/2852.patch",,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,2008-02-19 23:48:07.256,,,false,,,,,,,,,,,,,,,,,88638,,,,,Fri Feb 22 12:10:22 UTC 2008,,,,,,,"0|i0iesf:",105490,,,,,,,,,,,,,,,,,,,,,,,"19/Feb/08 23:48;hadoopqa;+1 overall.  Here are the results of testing the latest attachment 
http://issues.apache.org/jira/secure/attachment/12375967/2852.patch
against trunk revision 619744.

    @author +1.  The patch does not contain any @author tags.

    tests included +1.  The patch appears to include 18 new or modified tests.

    javadoc +1.  The javadoc tool did not generate any warning messages.

    javac +1.  The applied patch does not generate any new javac compiler warnings.

    release audit +1.  The applied patch does not generate any new release audit warnings.

    findbugs +1.  The patch does not introduce any new Findbugs warnings.

    core tests +1.  The patch passed core unit tests.

    contrib tests +1.  The patch passed contrib unit tests.

Test results: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch/1818/testReport/
Findbugs warnings: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch/1818/artifact/trunk/build/test/findbugs/newPatchFindbugsWarnings.html
Checkstyle results: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch/1818/artifact/trunk/build/test/checkstyle-errors.html
Console output: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch/1818/console

This message is automatically generated.","21/Feb/08 05:46;runping;+1

","22/Feb/08 00:33;cdouglas;I just committed this.","22/Feb/08 12:10;hudson;Integrated in Hadoop-trunk #408 (See [http://hudson.zones.apache.org/hudson/job/Hadoop-trunk/408/])",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
need regression tests for setting up cluster and running jobs with different users,HADOOP-2929,12390079,Test,Closed,HADOOP,Hadoop Common,software,omalley,Hadoop Common is the common library for Apache Hadoop.,http://hadoop.apache.org/,Major,Duplicate,szetszwo,szetszwo,szetszwo,03/Mar/08 19:49,08/Mar/08 19:51,12/Jan/21 11:55,07/Mar/08 22:10,,,,,,,,,,,test,,,,0,,,"Currently, there is no regression tests for setting up cluster and running jobs with different users.  So, some bugs like HADOOP-2915 cannot be discovered in the regression tests.  

HADOOP-2915 is due to some changes after the permission patches were committed.  This bug did not exist in earlier builds.  For example, build #378 (Jan 24, 2008), which is a build after the permission patches were committed, works fine.  The problem of HADOOP-2915 cannot be reproduced in build #378.

http://hudson.zones.apache.org/hudson/job/Hadoop-trunk/378/
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,125713,,,,,Fri Mar 07 22:10:03 UTC 2008,,,,,,,"0|i0iefj:",105432,,,,,,,,,,,,,,,,,,,,,,,"07/Mar/08 22:10;szetszwo;The tests are moved to HADOOP-2915.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Restore the  old NN Bench that was replaced by a MR NN Bench,HADOOP-2449,12384813,Test,Closed,HADOOP,Hadoop Common,software,omalley,Hadoop Common is the common library for Apache Hadoop.,http://hadoop.apache.org/,Major,Fixed,sanjay.radia,sanjay.radia,sanjay.radia,17/Dec/07 22:17,08/Feb/08 23:38,12/Jan/21 11:55,17/Jan/08 01:24,,,,,0.16.0,,,,,,,,,,0,,,"The old NN Bench did not use Map Reduce.

It was replaced by a new NN Bench that uses Map reduce.

The old NN Bench is useful and should be restored.
  - useful ofr simulated data niodes which do not work for Map reduce since the job configs need to be persistent.
  - a NN test that is independent of map reduce can be useful as it is one less variable in figuring out bottlenecks.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"17/Dec/07 22:19;sanjay.radia;fixNNBenchPatch.txt;https://issues.apache.org/jira/secure/attachment/12371829/fixNNBenchPatch.txt",,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,2008-01-07 17:51:31.224,,,false,,,,,,,,,,,,,,,,,125572,,,,,Thu Jan 17 01:24:27 UTC 2008,,,,,,,"0|i0ig2v:",105699,,,,,,,,,,,,,,,,,,,,,,,"17/Dec/07 22:19;sanjay.radia;This patch restores the old NN bench as class NNBenchWithoutMR
","07/Jan/08 17:51;mukundm;+1","11/Jan/08 21:52;hadoopqa;-1 overall.  Here are the results of testing the latest attachment 
http://issues.apache.org/jira/secure/attachment/12371829/fixNNBenchPatch.txt
against trunk revision r611264.

    @author +1.  The patch does not contain any @author tags.

    javadoc +1.  The javadoc tool did not generate any warning messages.

    javac +1.  The applied patch does not generate any new compiler warnings.

    findbugs +1.  The patch does not introduce any new Findbugs warnings.

    core tests -1.  The patch failed core unit tests.

    contrib tests +1.  The patch passed contrib unit tests.

Test results: http://lucene.zones.apache.org:8080/hudson/job/Hadoop-Patch/1546/testReport/
Findbugs warnings: http://lucene.zones.apache.org:8080/hudson/job/Hadoop-Patch/1546/artifact/trunk/build/test/findbugs/newPatchFindbugsWarnings.html
Checkstyle results: http://lucene.zones.apache.org:8080/hudson/job/Hadoop-Patch/1546/artifact/trunk/build/test/checkstyle-errors.html
Console output: http://lucene.zones.apache.org:8080/hudson/job/Hadoop-Patch/1546/console

This message is automatically generated.","15/Jan/08 20:16;hadoopqa;+1 overall.  Here are the results of testing the latest attachment 
http://issues.apache.org/jira/secure/attachment/12371829/fixNNBenchPatch.txt
against trunk revision r612191.

    @author +1.  The patch does not contain any @author tags.

    javadoc +1.  The javadoc tool did not generate any warning messages.

    javac +1.  The applied patch does not generate any new compiler warnings.

    findbugs +1.  The patch does not introduce any new Findbugs warnings.

    core tests +1.  The patch passed core unit tests.

    contrib tests +1.  The patch passed contrib unit tests.

Test results: http://lucene.zones.apache.org:8080/hudson/job/Hadoop-Patch/1599/testReport/
Findbugs warnings: http://lucene.zones.apache.org:8080/hudson/job/Hadoop-Patch/1599/artifact/trunk/build/test/findbugs/newPatchFindbugsWarnings.html
Checkstyle results: http://lucene.zones.apache.org:8080/hudson/job/Hadoop-Patch/1599/artifact/trunk/build/test/checkstyle-errors.html
Console output: http://lucene.zones.apache.org:8080/hudson/job/Hadoop-Patch/1599/console

This message is automatically generated.","17/Jan/08 01:24;shv;I just committed this. Thank you Sanjay!",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Test HDFS File Permissions,HADOOP-2431,12384681,Test,Closed,HADOOP,Hadoop Common,software,omalley,Hadoop Common is the common library for Apache Hadoop.,http://hadoop.apache.org/,Major,Fixed,hairong,hairong,hairong,14/Dec/07 19:52,08/Feb/08 23:38,12/Jan/21 11:55,24/Jan/08 02:57,0.15.1,,,,0.16.0,,,,,,test,,,,0,,,This jira is intended to provide junit tests to HADOOP-1298.,,qwertymaniac,szetszwo,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,HADOOP-1298,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"11/Jan/08 18:33;hairong;HDFSPermissionSpecification6.pdf;https://issues.apache.org/jira/secure/attachment/12372993/HDFSPermissionSpecification6.pdf","11/Jan/08 18:37;hairong;PermissionsTestPlan1.pdf;https://issues.apache.org/jira/secure/attachment/12372994/PermissionsTestPlan1.pdf","18/Jan/08 20:14;hairong;PermissionsTestPlan2.pdf;https://issues.apache.org/jira/secure/attachment/12373559/PermissionsTestPlan2.pdf","10/Jan/08 02:34;hairong;testDFSPermission.patch;https://issues.apache.org/jira/secure/attachment/12372866/testDFSPermission.patch","11/Jan/08 18:22;hairong;testDFSPermission1.patch;https://issues.apache.org/jira/secure/attachment/12372991/testDFSPermission1.patch","18/Jan/08 19:55;hairong;testDFSPermission2.patch;https://issues.apache.org/jira/secure/attachment/12373556/testDFSPermission2.patch","18/Jan/08 23:37;hairong;testDFSPermission3.patch;https://issues.apache.org/jira/secure/attachment/12373577/testDFSPermission3.patch",,,,,,,,,,,,,,,,,7.0,,,,,,,,,,,,,,,,,,,,2008-01-15 00:23:06.91,,,false,,,,,,,,,,,,,,,,,125568,,,,,Thu Jan 24 12:29:49 UTC 2008,,,,,,,"0|i0ig4n:",105707,,,,,,,,,,,,,,,,,,,,,,,"24/Dec/07 20:20;hairong;Test plan is attached.","10/Jan/08 02:34;hairong;The patch executes the test plan. In addition it fixed a bug in FileSystem.isDirectory(), which did not throw AccessControlException when the permission to call getFileStatus is denied.","11/Jan/08 18:22;hairong;I found one permission checking semantics error. Because dfs list is equivalent to unix ""ls -l"", listing a directory needs both SEARCH and READ permissions on the directory. This patch fixed the problem. It also added javadoc to the unit tests.","11/Jan/08 18:33;hairong;Attach the permission checking specification.","11/Jan/08 18:37;hairong;Attach an updated test plan","15/Jan/08 00:23;szetszwo;The tests are very systemic.  Below are some comments for testPermissionSetting() and testOwnership().

- Suggestion: add LOG.info(""NUM_TEST_PERMISSIONS="" + NUM_TEST_PERMISSIONS) to show the value.

- DEFAULT_PERMISSION may not be a constant although it is final:
  FsPermission.applyUMask(...) is called during file/dir creation.
  If it is a constant, it is better to use FsPermission.createImmutable(short).
  In this case, it happens working fine for 777.

- re-throw RuntimeException in static{...}

- testPermissionSetting: case 4,5 not in the same order as they in the pdf file.

- testOwnership(OpType op): <user1, group3> but GROUP1_NAME in the code

- NON_EXISTENT_PATH: It is better to check the existence of the path before using it.

- setOwner(...): add assertFalse(expectDeny) right before catch(...)","15/Jan/08 00:32;cutting;This tests that permission check failures throw a RemoteException wrapping an AccessControlException.  Shouldn't permission check failures throw an AccessControlException directly?

DistributedFileSystem or DFSClient should catch the RemoteException and, when it wraps an AccessControlException, throw one of those so that client code sees that, no?  Should I file a separate issue for this?","15/Jan/08 01:05;szetszwo;In NameNode, AccessControlException is thrown directly.  RPC wraps it as a RemoteException.  So client gets a RemoteException (wrapping AccessControlException).

The situation is similar for other IOException like ""Cannot open filename"".  Shell we unwrap ""Cannot open filename""?  If yes, then it is better to modify RPC.","15/Jan/08 17:49;omalley;I'm with Doug on this one. I think that dfs client should unwrap specific exceptions that are thrown back to the client. RPC wraps exceptions with RemoteException because the client may not have the thrown  exception, but that is clearly not the case here. Unwrapped exceptions are much easier for the client to handle...","15/Jan/08 17:53;cutting;Perhaps if the exception named in the RemoteException is a class that's loaded on the client and is permitted by the method signature, then RPC should automatically try to construct an instance and throw it.  But that's not what RPC does today.  If you feel it should do this, please file a separate issue.

The FileSystem API promises that applications which attempt to violate permissions will be thrown an AccessControlException.  Today, until RPC is changed, we must intercept RemoteException and explicitly throw an AccessControlException.  The fact that a particular FileSystem is implemented using RPC should be invisible to clients.","17/Jan/08 02:29;szetszwo;One more comment to the patch: the UnixUserGroupInformation constructor does not need to throw IOException.","18/Jan/08 19:55;hairong;> The FileSystem API promises that applications which attempt to violate permissions will be thrown an AccessControlException. 
+1. I will do it in a separate jira.

The patch incorporated all Nicholas's comments. It also added a test for non-existent paths.","18/Jan/08 20:14;hairong;Updated test plan.","18/Jan/08 22:59;szetszwo;In checkNonExistentFile(), each operation needs a try-catch.  Otherwise, one of them throws a "" Cannot open file"" exception, the other operations will not be tested.","18/Jan/08 23:37;hairong;Thanks Nicholas. Here is a new patch.","18/Jan/08 23:40;szetszwo;+1","20/Jan/08 03:02;hadoopqa;-1 overall.  Here are the results of testing the latest attachment 
http://issues.apache.org/jira/secure/attachment/12373577/testDFSPermission3.patch
against trunk revision r613446.

    @author +1.  The patch does not contain any @author tags.

    javadoc +1.  The javadoc tool did not generate any warning messages.

    javac +1.  The applied patch does not generate any new compiler warnings.

    findbugs +1.  The patch does not introduce any new Findbugs warnings.

    core tests -1.  The patch failed core unit tests.

    contrib tests +1.  The patch passed contrib unit tests.

Test results: http://lucene.zones.apache.org:8080/hudson/job/Hadoop-Patch/1658/testReport/
Findbugs warnings: http://lucene.zones.apache.org:8080/hudson/job/Hadoop-Patch/1658/artifact/trunk/build/test/findbugs/newPatchFindbugsWarnings.html
Checkstyle results: http://lucene.zones.apache.org:8080/hudson/job/Hadoop-Patch/1658/artifact/trunk/build/test/checkstyle-errors.html
Console output: http://lucene.zones.apache.org:8080/hudson/job/Hadoop-Patch/1658/console

This message is automatically generated.","24/Jan/08 02:57;shv;The build failure is related to HADOOP-2691, not to the patch.
I just committed this. Thank you Hairong.","24/Jan/08 12:29;hudson;Integrated in Hadoop-trunk #378 (See [http://hudson.zones.apache.org/hudson/job/Hadoop-trunk/378/])",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Micro-benchmark to measure read/write times through InputFormats,HADOOP-2406,12384442,Test,Closed,HADOOP,Hadoop Common,software,omalley,Hadoop Common is the common library for Apache Hadoop.,http://hadoop.apache.org/,Major,Fixed,cdouglas,cdouglas,cdouglas,11/Dec/07 23:43,08/Feb/08 23:38,12/Jan/21 11:55,09/Jan/08 21:57,,,,,0.16.0,,,,,,fs,test,,,0,,,"The attached test writes/reads XGB to/from the default filesystem through SequenceFileInputFormat and TextInputFormat, using LzoCodec, GzipCodec, and without compression, using both block and record compression for SequenceFiles.

The following results using 10GB of data through RawLocalFileSystem with 5 word keys, 20 word values (as generated by RandomTextWriter with the same seed for each file) are pretty stable:

Writes:
|| Format || Compression || Type || Time (sec) || Filesize (bytes) ||
| SEQ | LZO | BLOCK | 318 | 8 604 288 397 |
| SEQ | LZO | RECORD | 367 | 11 689 969 413 |
| SEQ | ZIP | BLOCK | 929 | 2 827 697 769 |
| SEQ | ZIP | RECORD | 1737 | 9 324 730 365 |
| SEQ |  |  | 201 | 11 282 745 683 |
| TXT | LZO |  | 742 | 12 671 065 769 |
| TXT | ZIP |  | 1320 | 2 597 397 680 |
| TXT |  |  | 392 | 10 818 058 643 |

Reads:
|| Format || Compression || Type || Time (sec) ||
| SEQ | LZO | BLOCK | 150 |
| SEQ | LZO | RECORD | 281 |
| SEQ | ZIP | BLOCK | 155 |
| SEQ | ZIP | RECORD | 548 |
| SEQ |  |  | 209 |
| TXT | LZO |  | 620 |
| TXT | ZIP |  | 355 |
| TXT |  |  | 284 |


Of note:
- Lzo compressed TextOutput is larger than the uncompressed output (HADOOP-2402); lzop cannot read it.
- Zip compression is expensive. Short values are responsible for the unimpressive compression for record-compressed SequenceFiles.
- TextInputFormat is slow (HADOOP-2285). TextOutputFormat also looks suspect.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"11/Dec/07 23:49;cdouglas;2406-0.patch;https://issues.apache.org/jira/secure/attachment/12371468/2406-0.patch","09/Jan/08 20:36;cdouglas;2406-1.patch;https://issues.apache.org/jira/secure/attachment/12372835/2406-1.patch",,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,125560,,,,,Wed Jan 09 21:57:49 UTC 2008,,,,,,,"0|i0ig7b:",105719,,,,,,,,,,,,,,,,,,,,,,,"09/Jan/08 20:36;cdouglas;Merged with latest trunk","09/Jan/08 21:57;cdouglas;I committed this.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Re-write NNBench to use MapReduce,HADOOP-2000,12379781,Test,Closed,HADOOP,Hadoop Common,software,omalley,Hadoop Common is the common library for Apache Hadoop.,http://hadoop.apache.org/,Major,Fixed,mukundm,mukundm,mukundm,05/Oct/07 21:38,08/Feb/08 23:37,12/Jan/21 11:55,10/Dec/07 22:44,0.15.0,,,,0.16.0,,,,,,test,,,,0,,,"The proposal is to re-write the NNBench benchmark/test to measure Namenode operations using MapReduce. Two buckets of measurements will be done:

1. Transactions per second 
2. Average latency

for these operations
- Create and Close file
- Open file
- Rename file
- Delete file

",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"10/Dec/07 19:16;mukundm;HADOOP-2000.patch;https://issues.apache.org/jira/secure/attachment/12371372/HADOOP-2000.patch","20/Nov/07 20:54;mukundm;HADOOP-2000.patch;https://issues.apache.org/jira/secure/attachment/12369916/HADOOP-2000.patch","29/Oct/07 19:21;mukundm;HADOOP-2000.patch;https://issues.apache.org/jira/secure/attachment/12368616/HADOOP-2000.patch","26/Oct/07 01:19;mukundm;HADOOP-2000.patch;https://issues.apache.org/jira/secure/attachment/12368439/HADOOP-2000.patch","23/Oct/07 07:29;mukundm;HADOOP-2000.patch;https://issues.apache.org/jira/secure/attachment/12368197/HADOOP-2000.patch","13/Oct/07 00:10;mukundm;HADOOP-2000.patch;https://issues.apache.org/jira/secure/attachment/12367671/HADOOP-2000.patch","09/Oct/07 18:22;mukundm;HADOOP-2000.patch;https://issues.apache.org/jira/secure/attachment/12367371/HADOOP-2000.patch",,,,,,,,,,,,,,,,,7.0,,,,,,,,,,,,,,,,,,,,2007-10-09 19:52:10.54,,,false,,,,,,,,,,,,,,,,,125464,,,,,Tue Dec 11 12:09:54 UTC 2007,,,,,,,"0|i0ihcn:",105905,,,,,,,,,,,,,,,,,,,,,,,"09/Oct/07 18:18;mukundm;Attaching patch for code review

Here is a sample run output:
---------------------------------------------

bin/hadoop jar hadoop-0.15.0-dev-test.jar nnbench -maps 1 -reduces 1 -startTime `date +""%s""` -blockSize 1 -bytesPerChecksum 1 -replicationFactorPerFile 1 -numberOfFiles 100
NameNode Benchmark 0.4
07/10/09 18:14:09 INFO dfs.NNBench: Test Inputs: 
07/10/09 18:14:09 INFO dfs.NNBench:            Test Operation: all
07/10/09 18:14:09 INFO dfs.NNBench:            Number of maps: 1
07/10/09 18:14:09 INFO dfs.NNBench:         Number of reduces: 1
07/10/09 18:14:09 INFO dfs.NNBench:                Block Size: 1
07/10/09 18:14:09 INFO dfs.NNBench:        Bytes per checksum: 1
07/10/09 18:14:09 INFO dfs.NNBench:           Number of files: 100
07/10/09 18:14:09 INFO dfs.NNBench:        Replication factor: 1
07/10/09 18:14:10 INFO dfs.NNBench: Creating control files
07/10/09 18:14:10 INFO mapred.FileInputFormat: Total input paths to process : 1
07/10/09 18:14:10 INFO mapred.JobClient: Running job: job_200710032050_0199
07/10/09 18:14:11 INFO mapred.JobClient:  map 0% reduce 0%
07/10/09 18:14:17 INFO mapred.JobClient:  map 100% reduce 0%
07/10/09 18:14:18 INFO mapred.JobClient:  map 100% reduce 100%
07/10/09 18:14:19 INFO mapred.JobClient: Job complete: job_200710032050_0199
07/10/09 18:14:19 INFO mapred.JobClient: Counters: 10
07/10/09 18:14:19 INFO mapred.JobClient:   Job Counters 
07/10/09 18:14:19 INFO mapred.JobClient:     Launched map tasks=1
07/10/09 18:14:19 INFO mapred.JobClient:     Launched reduce tasks=1
07/10/09 18:14:19 INFO mapred.JobClient:     Data-local map tasks=1
07/10/09 18:14:19 INFO mapred.JobClient:   Map-Reduce Framework
07/10/09 18:14:19 INFO mapred.JobClient:     Map input records=1
07/10/09 18:14:19 INFO mapred.JobClient:     Map output records=5
07/10/09 18:14:19 INFO mapred.JobClient:     Map input bytes=39
07/10/09 18:14:19 INFO mapred.JobClient:     Map output bytes=90
07/10/09 18:14:19 INFO mapred.JobClient:     Reduce input groups=5
07/10/09 18:14:19 INFO mapred.JobClient:     Reduce input records=5
07/10/09 18:14:19 INFO mapred.JobClient:     Reduce output records=5
07/10/09 18:14:19 INFO dfs.NNBench: ------ NNBench ------ : 
07/10/09 18:14:19 INFO dfs.NNBench:                   Version: NameNode Benchmark 0.4
07/10/09 18:14:19 INFO dfs.NNBench:               Date & time: Tue Oct 09 18:14:19 UTC 2007
07/10/09 18:14:19 INFO dfs.NNBench: 
07/10/09 18:14:19 INFO dfs.NNBench:            Test Operation: all
07/10/09 18:14:19 INFO dfs.NNBench:                      Maps: 1
07/10/09 18:14:19 INFO dfs.NNBench:                   Reduces: 1
07/10/09 18:14:19 INFO dfs.NNBench:        Block Size (bytes): 1
07/10/09 18:14:19 INFO dfs.NNBench:            Bytes to write: 1
07/10/09 18:14:19 INFO dfs.NNBench:        Bytes per checksum: 1
07/10/09 18:14:19 INFO dfs.NNBench:           Number of files: 100
07/10/09 18:14:19 INFO dfs.NNBench:        Replication factor: 1
07/10/09 18:14:19 INFO dfs.NNBench: 
07/10/09 18:14:19 INFO dfs.NNBench:     TPS: Create and Close: 72
07/10/09 18:14:19 INFO dfs.NNBench:          TPS: Open (Read): 2777
07/10/09 18:14:19 INFO dfs.NNBench:               TPS: Rename: 800
07/10/09 18:14:19 INFO dfs.NNBench:               TPS: Delete: 7142
07/10/09 18:14:19 INFO dfs.NNBench: 
07/10/09 18:14:19 INFO dfs.NNBench:      Avg Lat (ms): Create: 1.35
07/10/09 18:14:19 INFO dfs.NNBench:       Avg Lat (ms): Close: 26.28
07/10/09 18:14:19 INFO dfs.NNBench: Avg Lat (ms): Open (Read): 0.36
07/10/09 18:14:19 INFO dfs.NNBench:      Avg Lat (ms): Rename: 1.25
07/10/09 18:14:19 INFO dfs.NNBench:      Avg Lat (ms): Delete: 0.14

---------------------------------------------","09/Oct/07 19:52;hadoopqa;+1 overall.  Here are the results of testing the latest attachment 
http://issues.apache.org/jira/secure/attachment/12367371/HADOOP-2000.patch
against trunk revision r583037.

    @author +1.  The patch does not contain any @author tags.

    javadoc +1.  The javadoc tool did not generate any warning messages.

    javac +1.  The applied patch does not generate any new compiler warnings.

    findbugs +1.  The patch does not introduce any new Findbugs warnings.

    core tests +1.  The patch passed core unit tests.

    contrib tests +1.  The patch passed contrib unit tests.

Test results: http://lucene.zones.apache.org:8080/hudson/job/Hadoop-Patch/909/testReport/
Findbugs warnings: http://lucene.zones.apache.org:8080/hudson/job/Hadoop-Patch/909/artifact/trunk/build/test/findbugs/newPatchFindbugsWarnings.html
Checkstyle results: http://lucene.zones.apache.org:8080/hudson/job/Hadoop-Patch/909/artifact/trunk/build/test/checkstyle-errors.html
Console output: http://lucene.zones.apache.org:8080/hudson/job/Hadoop-Patch/909/console

This message is automatically generated.","13/Oct/07 00:10;mukundm;Updated code to adhere to coding guidelines","16/Oct/07 16:32;nidaley;Looks good.  A few comments:

* import explicit classes, rather than java.io.*
* I'm not sure it makes sense to turn this into a junit test.  As it stands, it won't get run by the test target because the class doesn't start with the word ""Test""
* usage message is missing -bytesToWrite and -operation
* the operation ""all"" doesn't make sense
* Test Inputs log message missing some parameters
* the barrier() call should go into the mappers map method right before it's ready to start creating/opening/deleting/renaming and this should be documented so that user set a startTime that is far enough in the future
* barrier() should throw an exception if the startTime has already passed
* the map should only run 1 operation
* speculation should be turned off explicitly
* ""Create a file"" comment wrong in doRenameOp and doDeleteOp methods
* doCreateCloseOp should really be doCreateWriteOp and it should create the file with the appropriate blockSize and replicationFactor and then write the appropriate number of bytes (which may be zero)
* should there be exception handling around the various file io calls?","23/Oct/07 07:29;mukundm;Updated patch addressing review comments","23/Oct/07 07:30;mukundm;Updated the patch to address review feedback","25/Oct/07 03:52;nidaley;Great!  Almost there. 

* 30 second barrier default I think is too low.  I'd suggest at 1 or 2 minutes.
* remove debug output
* optional: validateInputs() should check for negative parameter inputs that don't make sense
* optional: parseInputs() should output startTime in a format that is the default used in NN and DN logs
* in barrier(), ""if (currentTime <= startTime)"" would be clearer as ""if (sleepTime > 0)""
* totalTimeTPS and startTimeTPS are really TPmS
* f: and s: are never used so that code can be removed from the reducer
* in map(), the openRead, rename, and delete cases should not call doCreateWriteOp as this screws up the point of the barrier;  the assumption is that the createWrite operation is done before the other operations -- perhaps this needs to be in the usage message and javadoc
* rename maxFailedExceptions to MAX_OPERATION_EXCEPTIONS
* shouldn't replication factor be a short throughout?
* shouldn't openRead optionally read the file and record the time for reading?
* I think number of files need to be sent to the reducer since it may be less than the desired if the map is late or there are too many exceptioins; this should correct the value that is currently used in the analyzeResults() method
* remove tps1and2 and just multiply tps1 (which you then may want to rename) in the ""If (operation.equals(OP_CREATE_WRITE))""
* document the forumulas in the analyzeResult() method","26/Oct/07 01:19;mukundm;Updated patch addressing review comments, including optional items","26/Oct/07 09:57;hadoopqa;-1 overall.  Here are the results of testing the latest attachment 
http://issues.apache.org/jira/secure/attachment/12368439/HADOOP-2000.patch
against trunk revision r588588.

    @author +1.  The patch does not contain any @author tags.

    javadoc -1.  The javadoc tool appears to have generated  messages.

    javac +1.  The applied patch does not generate any new compiler warnings.

    findbugs -1.  The patch appears to introduce  new Findbugs warnings.

    core tests -1.  The patch failed core unit tests.

    contrib tests -1.  The patch failed contrib unit tests.

Test results: http://lucene.zones.apache.org:8080/hudson/job/Hadoop-Patch/1009/testReport/
Findbugs warnings: http://lucene.zones.apache.org:8080/hudson/job/Hadoop-Patch/1009/artifact/trunk/build/test/findbugs/newPatchFindbugsWarnings.html
Checkstyle results: http://lucene.zones.apache.org:8080/hudson/job/Hadoop-Patch/1009/artifact/trunk/build/test/checkstyle-errors.html
Console output: http://lucene.zones.apache.org:8080/hudson/job/Hadoop-Patch/1009/console

This message is automatically generated.","29/Oct/07 17:47;hadoopqa;+1 overall.  Here are the results of testing the latest attachment 
http://issues.apache.org/jira/secure/attachment/12368439/HADOOP-2000.patch
against trunk revision r589576.

    @author +1.  The patch does not contain any @author tags.

    javadoc +1.  The javadoc tool did not generate any warning messages.

    javac +1.  The applied patch does not generate any new compiler warnings.

    findbugs +1.  The patch does not introduce any new Findbugs warnings.

    core tests +1.  The patch passed core unit tests.

    contrib tests +1.  The patch passed contrib unit tests.

Test results: http://lucene.zones.apache.org:8080/hudson/job/Hadoop-Patch/1022/testReport/
Findbugs warnings: http://lucene.zones.apache.org:8080/hudson/job/Hadoop-Patch/1022/artifact/trunk/build/test/findbugs/newPatchFindbugsWarnings.html
Checkstyle results: http://lucene.zones.apache.org:8080/hudson/job/Hadoop-Patch/1022/artifact/trunk/build/test/checkstyle-errors.html
Console output: http://lucene.zones.apache.org:8080/hudson/job/Hadoop-Patch/1022/console

This message is automatically generated.","29/Oct/07 20:42;hadoopqa;+1 overall.  Here are the results of testing the latest attachment 
http://issues.apache.org/jira/secure/attachment/12368616/HADOOP-2000.patch
against trunk revision r589576.

    @author +1.  The patch does not contain any @author tags.

    javadoc +1.  The javadoc tool did not generate any warning messages.

    javac +1.  The applied patch does not generate any new compiler warnings.

    findbugs +1.  The patch does not introduce any new Findbugs warnings.

    core tests +1.  The patch passed core unit tests.

    contrib tests +1.  The patch passed contrib unit tests.

Test results: http://lucene.zones.apache.org:8080/hudson/job/Hadoop-Patch/1023/testReport/
Findbugs warnings: http://lucene.zones.apache.org:8080/hudson/job/Hadoop-Patch/1023/artifact/trunk/build/test/findbugs/newPatchFindbugsWarnings.html
Checkstyle results: http://lucene.zones.apache.org:8080/hudson/job/Hadoop-Patch/1023/artifact/trunk/build/test/checkstyle-errors.html
Console output: http://lucene.zones.apache.org:8080/hudson/job/Hadoop-Patch/1023/console

This message is automatically generated.","02/Nov/07 11:09;shv;# redundant imports
import java.text.DateFormat;
import org.apache.hadoop.mapred.Reducer;
# variable name in NNBenchMapper.map() is never used.
# Typo
{code}
    // Set user-dfined parameters,
{code}
# Printing TPS calculating TPmS. Should be the same:
{code}
    ""       RAW DATA: TPS Total : "" + totalTimeTPmS,
{code}
# double totalTimeTPS is confusing, since it is in fact TPS, not time according to the formula and the comments
# I am not happy with the whole concept of transactions per second.
So you measure total execution time of each map (t_i) and then divide Number_of_files / Sum(t_i).
But the Sum(t_i) is not the right time, because maps are running in parallel,
so in order to obtain the true TPS you need to time the start and the end of +*all*+ maps 
rather than the start and the end of +*individual*+ maps.
But it is hard to get the exact starting and ending times of the job's map stage.
Your proposed TPS measures the # of transactions per second of a single client under a certain load on the cluster.
This is not completely unreasonable, but does not say much as a benchmark result imo.
I mean it is quite clear that if the cluster bears more load the clients run slower.","03/Nov/07 00:47;shv;I think we should have the following two measures:
# average operation execution time =   Number_of_operations / Sum(t_i)
where t_i is the time of each map task.
# Cluster throughput = Number_of_operations / Max(t_i).
where Max(t_i) is the longest map task.

(1) is what is currently called TPS in the patch.
(2) is a new measure, which measures how many operations per second the cluster can perform as a whole.
I think 2 might be a good candidate for the real throughput, because completion 
of the longest map means that all other maps are done by that time too. 
So this should indicate the actual end of the map stage of the job.
The only problem I see here is that this works only under the assumption that all maps 
run in parallel, which is not always true, especially when failed maps have to be reptried.
So this is in a sense an ideal cluster throughput.","20/Nov/07 20:54;mukundm;Uploading new patch to address comments from Konstantin

Three measurements are now being calculated:
1. Cluster Transactions per second (TPS) for an operation.
2. Average execution time in ms for an operation.
3. Average latency in ms for a transaction.
","21/Nov/07 00:51;hadoopqa;+1 overall.  Here are the results of testing the latest attachment 
http://issues.apache.org/jira/secure/attachment/12369916/HADOOP-2000.patch
against trunk revision r596835.

    @author +1.  The patch does not contain any @author tags.

    javadoc +1.  The javadoc tool did not generate any warning messages.

    javac +1.  The applied patch does not generate any new compiler warnings.

    findbugs +1.  The patch does not introduce any new Findbugs warnings.

    core tests +1.  The patch passed core unit tests.

    contrib tests +1.  The patch passed contrib unit tests.

Test results: http://lucene.zones.apache.org:8080/hudson/job/Hadoop-Patch/1131/testReport/
Findbugs warnings: http://lucene.zones.apache.org:8080/hudson/job/Hadoop-Patch/1131/artifact/trunk/build/test/findbugs/newPatchFindbugsWarnings.html
Checkstyle results: http://lucene.zones.apache.org:8080/hudson/job/Hadoop-Patch/1131/artifact/trunk/build/test/checkstyle-errors.html
Console output: http://lucene.zones.apache.org:8080/hudson/job/Hadoop-Patch/1131/console

This message is automatically generated.","07/Dec/07 01:17;shv;A few minor comments:
- Redundant imports:
{code}
   import java.text.DateFormat;
   import org.apache.hadoop.io.UTF8;
   import org.apache.hadoop.mapred.Reducer;
{code}
- Usage should specify mandatory options, like -operation, and optional ones.
- I get ArrayIndexOutOfBoundsException if I run any of the
{code}
NNBench -operation
NNBench -bytesToWrite
{code}","10/Dec/07 19:16;mukundm;Updated patch addressing comments from Konstantin","10/Dec/07 20:22;hadoopqa;+1 overall.  Here are the results of testing the latest attachment 
http://issues.apache.org/jira/secure/attachment/12371372/HADOOP-2000.patch
against trunk revision r603000.

    @author +1.  The patch does not contain any @author tags.

    javadoc +1.  The javadoc tool did not generate any warning messages.

    javac +1.  The applied patch does not generate any new compiler warnings.

    findbugs +1.  The patch does not introduce any new Findbugs warnings.

    core tests +1.  The patch passed core unit tests.

    contrib tests +1.  The patch passed contrib unit tests.

Test results: http://lucene.zones.apache.org:8080/hudson/job/Hadoop-Patch/1307/testReport/
Findbugs warnings: http://lucene.zones.apache.org:8080/hudson/job/Hadoop-Patch/1307/artifact/trunk/build/test/findbugs/newPatchFindbugsWarnings.html
Checkstyle results: http://lucene.zones.apache.org:8080/hudson/job/Hadoop-Patch/1307/artifact/trunk/build/test/checkstyle-errors.html
Console output: http://lucene.zones.apache.org:8080/hudson/job/Hadoop-Patch/1307/console

This message is automatically generated.","10/Dec/07 20:36;shv;+1","10/Dec/07 22:44;dhruba;I just committed this. Thanks Mukund!","11/Dec/07 12:09;hudson;Integrated in Hadoop-Nightly #329 (See [http://lucene.zones.apache.org:8080/hudson/job/Hadoop-Nightly/329/])",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Mini map/reduce cluster should use multiple temp directories,HADOOP-609,12353418,Test,Closed,HADOOP,Hadoop Common,software,omalley,Hadoop Common is the common library for Apache Hadoop.,http://hadoop.apache.org/,Major,Fixed,mahadev,omalley,omalley,17/Oct/06 16:31,15/Dec/06 23:02,12/Jan/21 11:55,19/Oct/06 03:57,0.7.1,,,,0.7.2,,,,,,,,,,0,,,Currently the mini map/reduce cluster only tests the task trackers with a single working directory. That caused us to miss a bug that broke 0.7.1. At least some of the mini m/r tests should run task trackers with two or threee working directories.,,eric14,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"18/Oct/06 22:43;mahadev;junit_less.patch;https://issues.apache.org/jira/secure/attachment/12343204/junit_less.patch",,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,2006-10-17 21:12:05.0,,,false,,,,,,,,,,,,,,,,,124892,,,,,Thu Oct 19 03:57:21 UTC 2006,,,,,,,"0|i0inm7:",106920,,,,,,,,,,,,,,,,,,,,,,,"17/Oct/06 21:12;mahadev;This patch makes all the minimrcluster junit tests except the TestMiniMRWithDFS use multiple mapred.local directories. The MiniMRWithDFS test depends on having a single mapred local directory so I did not change that. Also, this patch includes the patch for HADOOP-607. ","17/Oct/06 21:47;cutting;When I apply this and revert the patch for HADOOP-607, unit tests still pass.  So I don't see how this tests the condition that HADOOP-607 fixes.","17/Oct/06 22:04;mahadev;you are right doug. THe problem will not show. This is because there is no job.jar associated with jobs we submit in junit tests. All the classes are in hadoop-* jars. The problem with HADOOP-607 was that the directory where the job was being unjarred was not being added to the classpath of the task. With the junit tests we do not have any such problem because all the classes are in hadoop-*jars. Do we want to create a test wherein we create a job.jar and submit to a map red cluster with multiple directories?
","17/Oct/06 22:10;cutting;Yes.  I thought the point was to re-create the conditions which caused HADOOP-607.","18/Oct/06 03:48;mahadev;This patch includes one more test called TestMiniMRClasspath. This will run a job.jar which I have uploaded with the patch. So without Hadoop-607 TestMiniMRClasspath fails and with the patch for hadoop-607 it passes. The TestMiniMRClasspath run sthe mapper and reducer in job.jar (which is just a wordcount mapper and reducer). Without 607 this test fails with classnotfound exceptions. The test just checks for a successful run of the job.

I have left the multiple directories MiniMR in all the other tests as in the previous patch. It will be handy in finding other problems with multiple directories. 
Also, this patch includes the fix for Hadoop-607.","18/Oct/06 18:22;cutting;The job.jar should be built from build.xml, rather than committed directly.  That way we can easily change what it contains as we add other tests.","18/Oct/06 20:08;mahadev;this patch creates the job.jar via build.xml. I have created seperate directory for this Class under test.","18/Oct/06 22:04;omalley;Copying the code from WordCount is not really required. It would be better to just extend the WordCount.Mapper and Reducer and have empty classes.
","18/Oct/06 22:43;mahadev;Thanks for the comments owen. I used the inheritance from WordCount example.","19/Oct/06 03:57;cutting;I just committed this.  Thanks, Mahadev.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
hadoopStreaming test jobconf -> env.var. mapping,HADOOP-418,12347165,Test,Closed,HADOOP,Hadoop Common,software,omalley,Hadoop Common is the common library for Apache Hadoop.,http://hadoop.apache.org/,Major,Fixed,,michel_tourn,michel_tourn,02/Aug/06 14:59,04/Aug/06 22:22,12/Jan/21 11:55,02/Aug/06 18:42,,,,,0.5.0,,,,,,,,,,0,,,"The subprocess loads environment variables and tests for expected JobConf properties.

",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"02/Aug/06 15:00;michel_tourn;streaming.test.jobconf.env;https://issues.apache.org/jira/secure/attachment/12338001/streaming.test.jobconf.env",,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,2006-08-02 18:42:56.0,,,false,,,,,,,,,,,,,,,,,124794,,,,,Wed Aug 02 18:42:56 UTC 2006,,,,,,,"0|i0iomf:",107083,,,,,,,,,,,,,,,,,,,,,,,"02/Aug/06 18:42;cutting;I just committed this.  Thanks, Michel!",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Distributed checkup of the file system consistency.,HADOOP-194,12333111,Test,Closed,HADOOP,Hadoop Common,software,omalley,Hadoop Common is the common library for Apache Hadoop.,http://hadoop.apache.org/,Major,Fixed,shv,shv,shv,04/May/06 09:11,03/Aug/06 17:46,12/Jan/21 11:55,04/May/06 11:40,,,,,0.2.0,,,,,,,,,,0,,,"This is a map-reduce based test that checks consistency of the file system
by  reading all blocks of all files, and detecting which of them are missing or corrupted.
See HADOOP-95 and HADOOP-101 for related discussions.

This could be an alternative to the sequential checkup in dfsck.
It would be nice to integrate distributed checkup with dfsck, but I don't yet see how.

This test reuses classes defined in HADOOP-193.
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"04/May/06 09:12;shv;FSCheck.patch;https://issues.apache.org/jira/secure/attachment/12326228/FSCheck.patch",,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,2006-05-04 11:40:04.0,,,false,,,,,,,,,,,,,,,,,124684,,,,,Thu May 04 11:40:04 UTC 2006,,,,,,,"0|i0ipun:",107282,,,,,,,,,,,,,,,,,,,,,,,"04/May/06 09:12;shv;Should be applied after HADOOP-193.","04/May/06 11:40;cutting;I just committed this.  Thanks, Konstantin.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
ADL Gen1: Fix the test case failures which are failing after the contract test update in hadoop-common,HADOOP-17459,13351055,Test,Patch Available,HADOOP,Hadoop Common,software,omalley,Hadoop Common is the common library for Apache Hadoop.,http://hadoop.apache.org/,Minor,,,bilahari.th,bilahari.th,08/Jan/21 10:01,10/Jan/21 04:12,12/Jan/21 11:55,,3.4.0,,,,3.4.0,,,,,,fs/adl,,,,0,pull-request-available,,"Fix the following test case failures which are failing after the contract test update in hadoop-common

[ERROR] Failures:
[ERROR] TestAdlContractRenameLive>AbstractContractRenameTest.testRenameFileOverExistingFile:131->Assert.fail:88 expected rename(/test/source-256.txt, /test/dest-512.txt) to be rejected with exception, but got false
[ERROR] TestAdlContractRenameLive.testRenameFileUnderFile:46 Expecting org.apache.hadoop.security.AccessControlException with text Parent path is not a folder. but got : ""void""",,bilahari.th,,,,,,,,,,,,,,,,,,,"bilaharith opened a new pull request #2607:
URL: https://github.com/apache/hadoop/pull/2607


   Fix the following test case failures which are failing after the contract test update in hadoop-common
   
   [ERROR] Failures:
   [ERROR] TestAdlContractRenameLive>AbstractContractRenameTest.testRenameFileOverExistingFile:131->Assert.fail:88 expected rename(/test/source-256.txt, /test/dest-512.txt) to be rejected with exception, but got false
   [ERROR] TestAdlContractRenameLive.testRenameFileUnderFile:46 Expecting org.apache.hadoop.security.AccessControlException with text Parent path is not a folder. but got : ""void""


----------------------------------------------------------------
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;08/Jan/21 10:04;githubbot;600","hadoop-yetus commented on pull request #2607:
URL: https://github.com/apache/hadoop/pull/2607#issuecomment-756702912


   :broken_heart: **-1 overall**
   
   
   
   
   
   
   | Vote | Subsystem | Runtime |  Logfile | Comment |
   |:----:|----------:|--------:|:--------:|:-------:|
   | +0 :ok: |  reexec  |   1m 27s |  |  Docker mode activated.  |
   |||| _ Prechecks _ |
   | +1 :green_heart: |  dupname  |   0m  0s |  |  No case conflicting files found.  |
   | +1 :green_heart: |  @author  |   0m  0s |  |  The patch does not contain any @author tags.  |
   | +1 :green_heart: |   |   0m  0s | [test4tests](test4tests) |  The patch appears to include 2 new or modified test files.  |
   |||| _ trunk Compile Tests _ |
   | -1 :x: |  mvninstall  |  30m  1s | [/branch-mvninstall-root.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-2607/1/artifact/out/branch-mvninstall-root.txt) |  root in trunk failed.  |
   | +1 :green_heart: |  compile  |   0m 25s |  |  trunk passed with JDK Ubuntu-11.0.9.1+1-Ubuntu-0ubuntu1.18.04  |
   | +1 :green_heart: |  compile  |   0m 22s |  |  trunk passed with JDK Private Build-1.8.0_275-8u275-b01-0ubuntu1~18.04-b01  |
   | +1 :green_heart: |  checkstyle  |   0m 19s |  |  trunk passed  |
   | +1 :green_heart: |  mvnsite  |   0m 25s |  |  trunk passed  |
   | -1 :x: |  shadedclient  |  17m 44s |  |  branch has errors when building and testing our client artifacts.  |
   | +1 :green_heart: |  javadoc  |   0m 22s |  |  trunk passed with JDK Ubuntu-11.0.9.1+1-Ubuntu-0ubuntu1.18.04  |
   | +1 :green_heart: |  javadoc  |   0m 21s |  |  trunk passed with JDK Private Build-1.8.0_275-8u275-b01-0ubuntu1~18.04-b01  |
   | +0 :ok: |  spotbugs  |   0m 37s |  |  Used deprecated FindBugs config; considering switching to SpotBugs.  |
   | +1 :green_heart: |  findbugs  |   0m 34s |  |  trunk passed  |
   |||| _ Patch Compile Tests _ |
   | +1 :green_heart: |  mvninstall  |   0m 20s |  |  the patch passed  |
   | +1 :green_heart: |  compile  |   0m 18s |  |  the patch passed with JDK Ubuntu-11.0.9.1+1-Ubuntu-0ubuntu1.18.04  |
   | +1 :green_heart: |  javac  |   0m 18s |  |  the patch passed  |
   | +1 :green_heart: |  compile  |   0m 17s |  |  the patch passed with JDK Private Build-1.8.0_275-8u275-b01-0ubuntu1~18.04-b01  |
   | +1 :green_heart: |  javac  |   0m 17s |  |  the patch passed  |
   | +1 :green_heart: |  checkstyle  |   0m 11s |  |  the patch passed  |
   | +1 :green_heart: |  mvnsite  |   0m 19s |  |  the patch passed  |
   | +1 :green_heart: |  whitespace  |   0m  0s |  |  The patch has no whitespace issues.  |
   | +1 :green_heart: |  xml  |   0m  2s |  |  The patch has no ill-formed XML file.  |
   | +1 :green_heart: |  shadedclient  |  16m 49s |  |  patch has no errors when building and testing our client artifacts.  |
   | +1 :green_heart: |  javadoc  |   0m 19s |  |  the patch passed with JDK Ubuntu-11.0.9.1+1-Ubuntu-0ubuntu1.18.04  |
   | +1 :green_heart: |  javadoc  |   0m 18s |  |  the patch passed with JDK Private Build-1.8.0_275-8u275-b01-0ubuntu1~18.04-b01  |
   | +1 :green_heart: |  findbugs  |   0m 37s |  |  the patch passed  |
   |||| _ Other Tests _ |
   | +1 :green_heart: |  unit  |   0m 49s |  |  hadoop-azure-datalake in the patch passed.  |
   | +1 :green_heart: |  asflicense  |   0m 29s |  |  The patch does not generate ASF License warnings.  |
   |  |   |  75m  9s |  |  |
   
   
   | Subsystem | Report/Notes |
   |----------:|:-------------|
   | Docker | ClientAPI=1.41 ServerAPI=1.41 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-2607/1/artifact/out/Dockerfile |
   | GITHUB PR | https://github.com/apache/hadoop/pull/2607 |
   | Optional Tests | dupname asflicense compile javac javadoc mvninstall mvnsite unit shadedclient findbugs checkstyle xml |
   | uname | Linux 810affa54ce6 4.15.0-126-generic #129-Ubuntu SMP Mon Nov 23 18:53:38 UTC 2020 x86_64 x86_64 x86_64 GNU/Linux |
   | Build tool | maven |
   | Personality | dev-support/bin/hadoop.sh |
   | git revision | trunk / 87bd4d2aca5 |
   | Default Java | Private Build-1.8.0_275-8u275-b01-0ubuntu1~18.04-b01 |
   | Multi-JDK versions | /usr/lib/jvm/java-11-openjdk-amd64:Ubuntu-11.0.9.1+1-Ubuntu-0ubuntu1.18.04 /usr/lib/jvm/java-8-openjdk-amd64:Private Build-1.8.0_275-8u275-b01-0ubuntu1~18.04-b01 |
   |  Test Results | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-2607/1/testReport/ |
   | Max. process+thread count | 628 (vs. ulimit of 5500) |
   | modules | C: hadoop-tools/hadoop-azure-datalake U: hadoop-tools/hadoop-azure-datalake |
   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-2607/1/console |
   | versions | git=2.17.1 maven=3.6.0 findbugs=4.0.6 |
   | Powered by | Apache Yetus 0.13.0-SNAPSHOT https://yetus.apache.org |
   
   
   This message was automatically generated.
   
   


----------------------------------------------------------------
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;08/Jan/21 11:20;githubbot;600","bilaharith commented on pull request #2607:
URL: https://github.com/apache/hadoop/pull/2607#issuecomment-757129005


   **Before the changes**
   
   [INFO] Results:
   [INFO] 
   [ERROR] Failures: 
   [ERROR]   TestAdlContractRenameLive>AbstractContractRenameTest.testRenameFileOverExistingFile:131->Assert.fail:88 expected rename(adl://bithgen1it.azuredatalakestore.net/test/source-256.txt, adl://bithgen1it.azuredatalakestore.net/test/dest-512.txt) to be rejected with exception, but got false
   [ERROR]   TestAdlContractRenameLive.testRenameFileUnderFile:46 Expecting org.apache.hadoop.security.AccessControlException with text Parent path is not a folder. but got : ""void""
   [ERROR] Errors: 
   [ERROR]   TestAdlContractGetFileStatusLive>AbstractContractGetFileStatusTest.testComplexDirActions:153->AbstractContractGetFileStatusTest.checkListStatusIteratorComplexDir:196 » NoClassDefFound
   [ERROR]   TestAdlContractGetFileStatusLive>AbstractContractGetFileStatusTest.testListStatusIteratorFile:363->AbstractContractGetFileStatusTest.validateListingForFile:384 » NoClassDefFound
   [ERROR]   TestAdlContractRootDirLive>AbstractContractRootDirectoryTest.testSimpleRootListing:251 » NoClassDefFound
   [INFO] 
   [ERROR] Tests run: 893, Failures: 2, Errors: 3, Skipped: 3
   [INFO] 
   [ERROR] There are test failures.
   
   **After the change**
   
   [INFO] Results:
   [INFO] 
   [ERROR] Errors: 
   [ERROR]   TestAdlContractGetFileStatusLive>AbstractContractGetFileStatusTest.testComplexDirActions:153->AbstractContractGetFileStatusTest.checkListStatusIteratorComplexDir:196 » NoClassDefFound
   [ERROR]   TestAdlContractGetFileStatusLive>AbstractContractGetFileStatusTest.testListStatusIteratorFile:363->AbstractContractGetFileStatusTest.validateListingForFile:384 » NoClassDefFound
   [ERROR]   TestAdlContractRootDirLive>AbstractContractRootDirectoryTest.testSimpleRootListing:251 » NoClassDefFound
   [INFO] 
   [ERROR] Tests run: 893, Failures: 0, Errors: 3, Skipped: 3
   [INFO] 
   [ERROR] There are test failures.
   


----------------------------------------------------------------
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;09/Jan/21 10:29;githubbot;600","bilaharith opened a new pull request #2607:
URL: https://github.com/apache/hadoop/pull/2607


   Fix the following test case failures which are failing after the contract test update in hadoop-common
   
   [ERROR] Failures:
   [ERROR] TestAdlContractRenameLive>AbstractContractRenameTest.testRenameFileOverExistingFile:131->Assert.fail:88 expected rename(/test/source-256.txt, /test/dest-512.txt) to be rejected with exception, but got false
   [ERROR] TestAdlContractRenameLive.testRenameFileUnderFile:46 Expecting org.apache.hadoop.security.AccessControlException with text Parent path is not a folder. but got : ""void""


----------------------------------------------------------------
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;10/Jan/21 03:49;githubbot;600","hadoop-yetus commented on pull request #2607:
URL: https://github.com/apache/hadoop/pull/2607#issuecomment-756702912


   :broken_heart: **-1 overall**
   
   
   
   
   
   
   | Vote | Subsystem | Runtime |  Logfile | Comment |
   |:----:|----------:|--------:|:--------:|:-------:|
   | +0 :ok: |  reexec  |   1m 27s |  |  Docker mode activated.  |
   |||| _ Prechecks _ |
   | +1 :green_heart: |  dupname  |   0m  0s |  |  No case conflicting files found.  |
   | +1 :green_heart: |  @author  |   0m  0s |  |  The patch does not contain any @author tags.  |
   | +1 :green_heart: |   |   0m  0s | [test4tests](test4tests) |  The patch appears to include 2 new or modified test files.  |
   |||| _ trunk Compile Tests _ |
   | -1 :x: |  mvninstall  |  30m  1s | [/branch-mvninstall-root.txt](https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-2607/1/artifact/out/branch-mvninstall-root.txt) |  root in trunk failed.  |
   | +1 :green_heart: |  compile  |   0m 25s |  |  trunk passed with JDK Ubuntu-11.0.9.1+1-Ubuntu-0ubuntu1.18.04  |
   | +1 :green_heart: |  compile  |   0m 22s |  |  trunk passed with JDK Private Build-1.8.0_275-8u275-b01-0ubuntu1~18.04-b01  |
   | +1 :green_heart: |  checkstyle  |   0m 19s |  |  trunk passed  |
   | +1 :green_heart: |  mvnsite  |   0m 25s |  |  trunk passed  |
   | -1 :x: |  shadedclient  |  17m 44s |  |  branch has errors when building and testing our client artifacts.  |
   | +1 :green_heart: |  javadoc  |   0m 22s |  |  trunk passed with JDK Ubuntu-11.0.9.1+1-Ubuntu-0ubuntu1.18.04  |
   | +1 :green_heart: |  javadoc  |   0m 21s |  |  trunk passed with JDK Private Build-1.8.0_275-8u275-b01-0ubuntu1~18.04-b01  |
   | +0 :ok: |  spotbugs  |   0m 37s |  |  Used deprecated FindBugs config; considering switching to SpotBugs.  |
   | +1 :green_heart: |  findbugs  |   0m 34s |  |  trunk passed  |
   |||| _ Patch Compile Tests _ |
   | +1 :green_heart: |  mvninstall  |   0m 20s |  |  the patch passed  |
   | +1 :green_heart: |  compile  |   0m 18s |  |  the patch passed with JDK Ubuntu-11.0.9.1+1-Ubuntu-0ubuntu1.18.04  |
   | +1 :green_heart: |  javac  |   0m 18s |  |  the patch passed  |
   | +1 :green_heart: |  compile  |   0m 17s |  |  the patch passed with JDK Private Build-1.8.0_275-8u275-b01-0ubuntu1~18.04-b01  |
   | +1 :green_heart: |  javac  |   0m 17s |  |  the patch passed  |
   | +1 :green_heart: |  checkstyle  |   0m 11s |  |  the patch passed  |
   | +1 :green_heart: |  mvnsite  |   0m 19s |  |  the patch passed  |
   | +1 :green_heart: |  whitespace  |   0m  0s |  |  The patch has no whitespace issues.  |
   | +1 :green_heart: |  xml  |   0m  2s |  |  The patch has no ill-formed XML file.  |
   | +1 :green_heart: |  shadedclient  |  16m 49s |  |  patch has no errors when building and testing our client artifacts.  |
   | +1 :green_heart: |  javadoc  |   0m 19s |  |  the patch passed with JDK Ubuntu-11.0.9.1+1-Ubuntu-0ubuntu1.18.04  |
   | +1 :green_heart: |  javadoc  |   0m 18s |  |  the patch passed with JDK Private Build-1.8.0_275-8u275-b01-0ubuntu1~18.04-b01  |
   | +1 :green_heart: |  findbugs  |   0m 37s |  |  the patch passed  |
   |||| _ Other Tests _ |
   | +1 :green_heart: |  unit  |   0m 49s |  |  hadoop-azure-datalake in the patch passed.  |
   | +1 :green_heart: |  asflicense  |   0m 29s |  |  The patch does not generate ASF License warnings.  |
   |  |   |  75m  9s |  |  |
   
   
   | Subsystem | Report/Notes |
   |----------:|:-------------|
   | Docker | ClientAPI=1.41 ServerAPI=1.41 base: https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-2607/1/artifact/out/Dockerfile |
   | GITHUB PR | https://github.com/apache/hadoop/pull/2607 |
   | Optional Tests | dupname asflicense compile javac javadoc mvninstall mvnsite unit shadedclient findbugs checkstyle xml |
   | uname | Linux 810affa54ce6 4.15.0-126-generic #129-Ubuntu SMP Mon Nov 23 18:53:38 UTC 2020 x86_64 x86_64 x86_64 GNU/Linux |
   | Build tool | maven |
   | Personality | dev-support/bin/hadoop.sh |
   | git revision | trunk / 87bd4d2aca5 |
   | Default Java | Private Build-1.8.0_275-8u275-b01-0ubuntu1~18.04-b01 |
   | Multi-JDK versions | /usr/lib/jvm/java-11-openjdk-amd64:Ubuntu-11.0.9.1+1-Ubuntu-0ubuntu1.18.04 /usr/lib/jvm/java-8-openjdk-amd64:Private Build-1.8.0_275-8u275-b01-0ubuntu1~18.04-b01 |
   |  Test Results | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-2607/1/testReport/ |
   | Max. process+thread count | 628 (vs. ulimit of 5500) |
   | modules | C: hadoop-tools/hadoop-azure-datalake U: hadoop-tools/hadoop-azure-datalake |
   | Console output | https://ci-hadoop.apache.org/job/hadoop-multibranch/job/PR-2607/1/console |
   | versions | git=2.17.1 maven=3.6.0 findbugs=4.0.6 |
   | Powered by | Apache Yetus 0.13.0-SNAPSHOT https://yetus.apache.org |
   
   
   This message was automatically generated.
   
   


----------------------------------------------------------------
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;10/Jan/21 03:59;githubbot;600","bilaharith commented on pull request #2607:
URL: https://github.com/apache/hadoop/pull/2607#issuecomment-757129005


   **Before the changes**
   
   [INFO] Results:
   [INFO] 
   [ERROR] Failures: 
   [ERROR]   TestAdlContractRenameLive>AbstractContractRenameTest.testRenameFileOverExistingFile:131->Assert.fail:88 expected rename(adl://bithgen1it.azuredatalakestore.net/test/source-256.txt, adl://bithgen1it.azuredatalakestore.net/test/dest-512.txt) to be rejected with exception, but got false
   [ERROR]   TestAdlContractRenameLive.testRenameFileUnderFile:46 Expecting org.apache.hadoop.security.AccessControlException with text Parent path is not a folder. but got : ""void""
   [ERROR] Errors: 
   [ERROR]   TestAdlContractGetFileStatusLive>AbstractContractGetFileStatusTest.testComplexDirActions:153->AbstractContractGetFileStatusTest.checkListStatusIteratorComplexDir:196 » NoClassDefFound
   [ERROR]   TestAdlContractGetFileStatusLive>AbstractContractGetFileStatusTest.testListStatusIteratorFile:363->AbstractContractGetFileStatusTest.validateListingForFile:384 » NoClassDefFound
   [ERROR]   TestAdlContractRootDirLive>AbstractContractRootDirectoryTest.testSimpleRootListing:251 » NoClassDefFound
   [INFO] 
   [ERROR] Tests run: 893, Failures: 2, Errors: 3, Skipped: 3
   [INFO] 
   [ERROR] There are test failures.
   
   **After the change**
   
   [INFO] Results:
   [INFO] 
   [ERROR] Errors: 
   [ERROR]   TestAdlContractGetFileStatusLive>AbstractContractGetFileStatusTest.testComplexDirActions:153->AbstractContractGetFileStatusTest.checkListStatusIteratorComplexDir:196 » NoClassDefFound
   [ERROR]   TestAdlContractGetFileStatusLive>AbstractContractGetFileStatusTest.testListStatusIteratorFile:363->AbstractContractGetFileStatusTest.validateListingForFile:384 » NoClassDefFound
   [ERROR]   TestAdlContractRootDirLive>AbstractContractRootDirectoryTest.testSimpleRootListing:251 » NoClassDefFound
   [INFO] 
   [ERROR] Tests run: 893, Failures: 0, Errors: 3, Skipped: 3
   [INFO] 
   [ERROR] There are test failures.
   


----------------------------------------------------------------
This is an automated message from the Apache Git Service.
To respond to the message, please log on to GitHub and use the
URL above to go to the specific comment.

For queries about this service, please contact Infrastructure at:
users@infra.apache.org
;10/Jan/21 04:12;githubbot;600",,0,3600,,,0,3600,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,9223372036854775807,,,,,2021-01-08 10:01:58.0,,,,,,,"0|z0mdqw:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
parallel tests don't work for Windows,HADOOP-14696,13090883,Test,Resolved,HADOOP,Hadoop Common,software,omalley,Hadoop Common is the common library for Apache Hadoop.,http://hadoop.apache.org/,Minor,Fixed,aw,aw,aw,28/Jul/17 20:18,01/Jul/20 13:00,12/Jan/21 11:55,13/Mar/18 03:13,3.0.0-beta1,,,,2.9.1,3.0.1,,,,,test,,,,0,,,"If hadoop-common-project/hadoop-common is run with the -Pparallel-tests flag, it fails in create-parallel-tests-dirs from the pom.xml

{code}
[ERROR] Failed to execute goal org.apache.maven.plugins:maven-antrun-plugin:1.7:run (create-parallel-tests-dirs) on project hadoop-common: An Ant BuildException has occured: Directory F:\jenkins\jenkins-slave\workspace\hadoop-trunk-win\s\hadoop-common-project\hadoop-common\jenkinsjenkins-slaveworkspacehadoop-trunk-winshadoop-common-projecthadoop-common	arget\test\data\1 creation was not successful for an unknown reason
[ERROR] around Ant part ...<script language=""javascript"">var baseDirs = [... @ 4:33 in F:\jenkins\jenkins-slave\workspace\hadoop-trunk-win\s\hadoop-common-project\hadoop-common\target\antrun\build-main.xml
{code}",Windows,aw,cdouglas,elgoiri,huanbang1993,hudson,stevel@apache.org,tmarquardt,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,HDFS-12220,HADOOP-14725,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"04/Aug/17 21:23;stevel@apache.org;HADOOP-14696-002.patch;https://issues.apache.org/jira/secure/attachment/12880474/HADOOP-14696-002.patch","07/Aug/17 12:35;stevel@apache.org;HADOOP-14696-003.patch;https://issues.apache.org/jira/secure/attachment/12880639/HADOOP-14696-003.patch","02/Aug/17 14:20;aw;HADOOP-14696.00.patch;https://issues.apache.org/jira/secure/attachment/12880047/HADOOP-14696.00.patch","02/Aug/17 20:45;aw;HADOOP-14696.01.patch;https://issues.apache.org/jira/secure/attachment/12880100/HADOOP-14696.01.patch","02/Sep/17 02:41;aw;HADOOP-14696.04.patch;https://issues.apache.org/jira/secure/attachment/12885055/HADOOP-14696.04.patch","15/Sep/17 20:46;aw;HADOOP-14696.05.patch;https://issues.apache.org/jira/secure/attachment/12887421/HADOOP-14696.05.patch","16/Sep/17 00:50;aw;HADOOP-14696.06.patch;https://issues.apache.org/jira/secure/attachment/12887467/HADOOP-14696.06.patch","16/Sep/17 04:12;aw;HADOOP-14696.07.patch;https://issues.apache.org/jira/secure/attachment/12887479/HADOOP-14696.07.patch",,,,,,,,,,,,,,,,8.0,,,,,,,,,,,,,,,,,,,,2017-08-02 15:21:43.416,,,false,,,,,,,,,,,,,,,,,9223372036854775807,Reviewed,,,,Tue Mar 13 03:44:42 UTC 2018,,,,,,,"0|i3i5h3:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,"02/Aug/17 14:20;aw;-00:
* add path conversions to unix so that the javascript doesn't take e.g., \h as an escaped h.","02/Aug/17 15:21;hadoopqa;| (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 17s{color} | {color:blue} Docker mode activated. {color} |
|| || || || {color:brown} Prechecks {color} ||
| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |
| {color:red}-1{color} | {color:red} test4tests {color} | {color:red}  0m  0s{color} | {color:red} The patch doesn't appear to include any new or modified tests. Please justify why no new tests are needed for this patch. Also please list what manual steps were performed to verify this patch. {color} |
|| || || || {color:brown} trunk Compile Tests {color} ||
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 13m 42s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 13m 50s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  1m 28s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 49s{color} | {color:green} trunk passed {color} |
|| || || || {color:brown} Patch Compile Tests {color} ||
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  0m 40s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 10m 19s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javac {color} | {color:green} 10m 19s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  1m 25s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} |
| {color:green}+1{color} | {color:green} xml {color} | {color:green}  0m  1s{color} | {color:green} The patch has no ill-formed XML file. {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 49s{color} | {color:green} the patch passed {color} |
|| || || || {color:brown} Other Tests {color} ||
| {color:red}-1{color} | {color:red} unit {color} | {color:red}  8m  3s{color} | {color:red} hadoop-common in the patch failed. {color} |
| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 29s{color} | {color:green} The patch does not generate ASF License warnings. {color} |
| {color:black}{color} | {color:black} {color} | {color:black} 53m  6s{color} | {color:black} {color} |
\\
\\
|| Reason || Tests ||
| Failed junit tests | hadoop.security.TestKDiag |
\\
\\
|| Subsystem || Report/Notes ||
| Docker |  Image:yetus/hadoop:14b5c93 |
| JIRA Issue | HADOOP-14696 |
| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12880047/HADOOP-14696.00.patch |
| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  xml  |
| uname | Linux 98de30d794d1 3.13.0-117-generic #164-Ubuntu SMP Fri Apr 7 11:05:26 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux |
| Build tool | maven |
| Personality | /testptch/hadoop/patchprocess/precommit/personality/provided.sh |
| git revision | trunk / 5e4434f |
| Default Java | 1.8.0_131 |
| unit | https://builds.apache.org/job/PreCommit-HADOOP-Build/12932/artifact/patchprocess/patch-unit-hadoop-common-project_hadoop-common.txt |
|  Test Results | https://builds.apache.org/job/PreCommit-HADOOP-Build/12932/testReport/ |
| modules | C: hadoop-common-project/hadoop-common U: hadoop-common-project/hadoop-common |
| Console output | https://builds.apache.org/job/PreCommit-HADOOP-Build/12932/console |
| Powered by | Apache Yetus 0.6.0-SNAPSHOT   http://yetus.apache.org |


This message was automatically generated.

","02/Aug/17 15:25;aw;This patch has been (forcibly) added to hadoop-trunk-win build #144:

{code}
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (create-parallel-tests-dirs) @ hadoop-common ---
[INFO] Executing tasks

main:
    [mkdir] Created dir: F:\jenkins\jenkins-slave\workspace\hadoop-trunk-win\s\hadoop-common-project\hadoop-common\target\test\data\1
    [mkdir] Created dir: F:\jenkins\jenkins-slave\workspace\hadoop-trunk-win\s\hadoop-common-project\hadoop-common\target\test\data\2
    [mkdir] Created dir: F:\jenkins\jenkins-slave\workspace\hadoop-trunk-win\s\hadoop-common-project\hadoop-common\target\test\data\3
    [mkdir] Created dir: F:\jenkins\jenkins-slave\workspace\hadoop-trunk-win\s\hadoop-common-project\hadoop-common\target\test\data\4
    [mkdir] Created dir: F:\jenkins\jenkins-slave\workspace\hadoop-trunk-win\s\hadoop-common-project\hadoop-common\target\test-dir\1
    [mkdir] Created dir: F:\jenkins\jenkins-slave\workspace\hadoop-trunk-win\s\hadoop-common-project\hadoop-common\target\test-dir\2
    [mkdir] Created dir: F:\jenkins\jenkins-slave\workspace\hadoop-trunk-win\s\hadoop-common-project\hadoop-common\target\test-dir\3
    [mkdir] Created dir: F:\jenkins\jenkins-slave\workspace\hadoop-trunk-win\s\hadoop-common-project\hadoop-common\target\test-dir\4
    [mkdir] Created dir: F:\jenkins\jenkins-slave\workspace\hadoop-trunk-win\s\hadoop-common-project\hadoop-common\target\test\1
    [mkdir] Created dir: F:\jenkins\jenkins-slave\workspace\hadoop-trunk-win\s\hadoop-common-project\hadoop-common\target\test\2
    [mkdir] Created dir: F:\jenkins\jenkins-slave\workspace\hadoop-trunk-win\s\hadoop-common-project\hadoop-common\target\test\3
    [mkdir] Created dir: F:\jenkins\jenkins-slave\workspace\hadoop-trunk-win\s\hadoop-common-project\hadoop-common\target\test\4
[INFO] Executed tasks
[INFO] 
{code}
","02/Aug/17 20:45;aw;-01:
* globally define and use the ""safe"" paths","03/Aug/17 09:13;stevel@apache.org;Thanks for this

# could we just define some property for the path, e.g $separator , then use that in the property defs?
# there's always the ant {{<mkdir>}} command.
# as the AWS patch policy is ""always declare the endpoint you've tested against"", which s3 endpoint have you tested with?","03/Aug/17 16:25;aw;bq. could we just define some property for the path, e.g $separator , then use that in the property defs?
bq. there's always the ant <mkdir> command.

Unfortunately, it's not that simple. We need to be able to create a set of directories per thread.  The thread count is defined at runtime.  This means a loop.  That eliminated <mkdir>; I couldn't figure out how to loop other than the method that [~cnauroth] used when they wrote the original antrun+JavaScript code.  The loop (obviously) needs to take input from maven properties.  These properties are calculated based upon standard Maven ones (which are built way before it even reads the pom.xml). Maven itself stores as full Windows paths.  So we're popping these maven properties into the antrun JavaScript. 

The problem is that JavaScript (correctly?)  interprets Windows backslashes as escapes.  So instead of C:\Tools\Source it gets turned into C:ToolsSource.  Now it's possible to switch languages (Groovy, JRuby, Jython, etc).  This brings about three new problems:
* Will they handle the path problems on their own?  How will they deal with given a path that looks like C:\Source\hadoop/target ?
* It adds yet more downloaded dependencies into the build.
* Do we really want to add Yet Another Language to the build system?

I opted for the devil we know and addded the new converted properties in a way that they are available in all descendant poms.  As we get more modules running in parallel (I'm working on rebasing MAPREDUCE-4980), they'll be able to use the same converted properties.  

bq. as the AWS patch policy is ""always declare the endpoint you've tested against"", which s3 endpoint have you tested with?

I didn't.  The parallel-tests code is already present in the hadoop-aws pom.xml. If hadoop-aws unit tests don't work in parallel on Linux now, then that profile shouldn't be there. ","03/Aug/17 17:10;stevel@apache.org;# you are right about mkdir and the parallelisation: it's not going to work
# if the code spans >1 module and it fixes the others, I'll trust you on aws

Theoretically, the javascript could actually invoke org.apache.tools.ant.taskdefs.PathConvert and do the conversion programmatically, but I wouldn't rush to do it: it'd be more complex than what you've done","03/Aug/17 20:13;hadoopqa;| (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 16s{color} | {color:blue} Docker mode activated. {color} |
|| || || || {color:brown} Prechecks {color} ||
| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |
| {color:red}-1{color} | {color:red} test4tests {color} | {color:red}  0m  0s{color} | {color:red} The patch doesn't appear to include any new or modified tests. Please justify why no new tests are needed for this patch. Also please list what manual steps were performed to verify this patch. {color} |
|| || || || {color:brown} trunk Compile Tests {color} ||
| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  1m 29s{color} | {color:blue} Maven dependency ordering for branch {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 20m 53s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 20m 38s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  4m 30s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  3m  8s{color} | {color:green} trunk passed {color} |
|| || || || {color:brown} Patch Compile Tests {color} ||
| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  0m 19s{color} | {color:blue} Maven dependency ordering for patch {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  2m 57s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 15m 44s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javac {color} | {color:green} 15m 44s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  4m  2s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} |
| {color:green}+1{color} | {color:green} xml {color} | {color:green}  0m  7s{color} | {color:green} The patch has no ill-formed XML file. {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  2m 43s{color} | {color:green} the patch passed {color} |
|| || || || {color:brown} Other Tests {color} ||
| {color:green}+1{color} | {color:green} unit {color} | {color:green}  0m 17s{color} | {color:green} hadoop-project in the patch passed. {color} |
| {color:red}-1{color} | {color:red} unit {color} | {color:red}  9m 28s{color} | {color:red} hadoop-common in the patch failed. {color} |
| {color:red}-1{color} | {color:red} unit {color} | {color:red}109m 41s{color} | {color:red} hadoop-hdfs in the patch failed. {color} |
| {color:green}+1{color} | {color:green} unit {color} | {color:green}  0m 51s{color} | {color:green} hadoop-aws in the patch passed. {color} |
| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 49s{color} | {color:green} The patch does not generate ASF License warnings. {color} |
| {color:black}{color} | {color:black} {color} | {color:black}199m 22s{color} | {color:black} {color} |
\\
\\
|| Reason || Tests ||
| Failed junit tests | hadoop.net.TestDNS |
|   | hadoop.hdfs.TestReadStripedFileWithMissingBlocks |
|   | hadoop.hdfs.server.datanode.TestDirectoryScanner |
|   | hadoop.hdfs.server.datanode.TestDataNodeVolumeFailureReporting |
|   | hadoop.hdfs.TestDFSStripedOutputStreamWithFailure080 |
|   | hadoop.hdfs.TestDFSStripedInputStreamWithRandomECPolicy |
\\
\\
|| Subsystem || Report/Notes ||
| Docker |  Image:yetus/hadoop:14b5c93 |
| JIRA Issue | HADOOP-14696 |
| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12880100/HADOOP-14696.01.patch |
| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  xml  |
| uname | Linux 665fb6929984 3.13.0-116-generic #163-Ubuntu SMP Fri Mar 31 14:13:22 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux |
| Build tool | maven |
| Personality | /testptch/hadoop/patchprocess/precommit/personality/provided.sh |
| git revision | trunk / c5d256c |
| Default Java | 1.8.0_131 |
| unit | https://builds.apache.org/job/PreCommit-HADOOP-Build/12940/artifact/patchprocess/patch-unit-hadoop-common-project_hadoop-common.txt |
| unit | https://builds.apache.org/job/PreCommit-HADOOP-Build/12940/artifact/patchprocess/patch-unit-hadoop-hdfs-project_hadoop-hdfs.txt |
|  Test Results | https://builds.apache.org/job/PreCommit-HADOOP-Build/12940/testReport/ |
| modules | C: hadoop-project hadoop-common-project/hadoop-common hadoop-hdfs-project/hadoop-hdfs hadoop-tools/hadoop-aws U: . |
| Console output | https://builds.apache.org/job/PreCommit-HADOOP-Build/12940/console |
| Powered by | Apache Yetus 0.6.0-SNAPSHOT   http://yetus.apache.org |


This message was automatically generated.

","04/Aug/17 13:49;aw;Those tests have been failing for a while. :/","04/Aug/17 13:59;aw;BTW, just to compare:

UNIX:

{code}
main:
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (create-parallel-tests-dirs) @ hadoop-common ---
[INFO] Executing tasks

main:
    [mkdir] Created dir: /testptch/hadoop/hadoop-common-project/hadoop-common/target/test/data/1
    [mkdir] Created dir: /testptch/hadoop/hadoop-common-project/hadoop-common/target/test/data/2
    [mkdir] Created dir: /testptch/hadoop/hadoop-common-project/hadoop-common/target/test/data/3
    [mkdir] Created dir: /testptch/hadoop/hadoop-common-project/hadoop-common/target/test/data/4
    [mkdir] Created dir: /testptch/hadoop/hadoop-common-project/hadoop-common/target/test-dir/1
    [mkdir] Created dir: /testptch/hadoop/hadoop-common-project/hadoop-common/target/test-dir/2
    [mkdir] Created dir: /testptch/hadoop/hadoop-common-project/hadoop-common/target/test-dir/3
    [mkdir] Created dir: /testptch/hadoop/hadoop-common-project/hadoop-common/target/test-dir/4
    [mkdir] Created dir: /testptch/hadoop/hadoop-common-project/hadoop-common/target/test/1
    [mkdir] Created dir: /testptch/hadoop/hadoop-common-project/hadoop-common/target/test/2
    [mkdir] Created dir: /testptch/hadoop/hadoop-common-project/hadoop-common/target/test/3
    [mkdir] Created dir: /testptch/hadoop/hadoop-common-project/hadoop-common/target/test/4
[INFO] Executed tasks
{code}

Windows:

{code}
[INFO] --- maven-antrun-plugin:1.7:run (create-parallel-tests-dirs) @ hadoop-common ---
[INFO] Executing tasks

main:
    [mkdir] Created dir: F:\jenkins\jenkins-slave\workspace\hadoop-trunk-win\s\hadoop-common-project\hadoop-common\target\test\data\1
    [mkdir] Created dir: F:\jenkins\jenkins-slave\workspace\hadoop-trunk-win\s\hadoop-common-project\hadoop-common\target\test\data\2
    [mkdir] Created dir: F:\jenkins\jenkins-slave\workspace\hadoop-trunk-win\s\hadoop-common-project\hadoop-common\target\test\data\3
    [mkdir] Created dir: F:\jenkins\jenkins-slave\workspace\hadoop-trunk-win\s\hadoop-common-project\hadoop-common\target\test\data\4
    [mkdir] Created dir: F:\jenkins\jenkins-slave\workspace\hadoop-trunk-win\s\hadoop-common-project\hadoop-common\target\test-dir\1
    [mkdir] Created dir: F:\jenkins\jenkins-slave\workspace\hadoop-trunk-win\s\hadoop-common-project\hadoop-common\target\test-dir\2
    [mkdir] Created dir: F:\jenkins\jenkins-slave\workspace\hadoop-trunk-win\s\hadoop-common-project\hadoop-common\target\test-dir\3
    [mkdir] Created dir: F:\jenkins\jenkins-slave\workspace\hadoop-trunk-win\s\hadoop-common-project\hadoop-common\target\test-dir\4
    [mkdir] Created dir: F:\jenkins\jenkins-slave\workspace\hadoop-trunk-win\s\hadoop-common-project\hadoop-common\target\test\1
    [mkdir] Created dir: F:\jenkins\jenkins-slave\workspace\hadoop-trunk-win\s\hadoop-common-project\hadoop-common\target\test\2
    [mkdir] Created dir: F:\jenkins\jenkins-slave\workspace\hadoop-trunk-win\s\hadoop-common-project\hadoop-common\target\test\3
    [mkdir] Created dir: F:\jenkins\jenkins-slave\workspace\hadoop-trunk-win\s\hadoop-common-project\hadoop-common\target\test\4
[INFO] Executed tasks
[INFO] 
{code}

I think that's the most amusing part.  Ant re-converts it back to a Windows path. Whatever works I guess.
","04/Aug/17 21:17;stevel@apache.org;-1, aws test runs fail to start on macos &  java 1.8.0_121. I suspect one of the properties isn't resolving

you could probably test that yourself just by running {{mvn verify}} in the directory.

{code}
[INFO] ------------------------------------------------------------------------
[INFO] BUILD FAILURE
[INFO] ------------------------------------------------------------------------
[INFO] Total time: 7.414 s (Wall Clock)
[INFO] Finished at: 2017-08-04T22:07:18+01:00
[INFO] Final Memory: 57M/810M
[INFO] ------------------------------------------------------------------------
[ERROR] Failed to execute goal org.apache.maven.plugins:maven-antrun-plugin:1.7:run (create-parallel-tests-dirs) on project hadoop-aws: An Ant BuildException has occured: java.lang.RuntimeException: java.lang.NoSuchMethodException: Can't unambiguously select between fixed arity signatures [(java.lang.String, java.lang.String), (java.io.File, java.lang.String)] of the method java.io.File.<init> for argument types [null, java.lang.Integer]
[ERROR] around Ant part ...<script language=""javascript"">var baseDirs = [... @ 4:33 in /Users/stevel/Projects/hadoop-trunk/hadoop-tools/hadoop-aws/target/antrun/build-main.xml
[ERROR] -> [Help 1]
[ERROR] 
[ERROR] To see the full stack trace of the errors, re-run Maven with the -e switch.
[ERROR] Re-run Maven using the -X switch to enable full debug logging.
[ERROR] 
[ERROR] For more information about the errors and possible solutions, please read the following articles:
[ERROR] [Help 1] http://cwiki.apache.org/confluence/display/MAVEN/MojoExecutionException
{code}
","04/Aug/17 21:24;stevel@apache.org;Patch 002. This doesn't fix it, but it does include diagnostics of what's up: {{test.build.data_unix}} isn't set
{code}
[INFO] ------------------------------------------------------------------------
[ERROR] Failed to execute goal org.apache.maven.plugins:maven-antrun-plugin:1.7:run (create-parallel-tests-dirs) on project hadoop-aws: An Ant BuildException has occured: javax.script.ScriptException: java.lang.Exception: Unset property: test.build.data_unix in <eval> at line number 9 at column number 26
[ERROR] around Ant part ...<script language=""javascript"">var baseDirs = [... @ 4:33 in /Users/stevel/Projects/hadoop-trunk/hadoop-tools/hadoop-aws/target/antrun/build-main.xml
[ERROR] -> [Help 1]
[ERROR] 
{code}","04/Aug/17 22:28;aw;bq. you could probably test that yourself just by running mvn verify in the directory.

It works for me.
{code}
hadoop-aws aw$  mvn verify -Pparallel-tests
....
main:
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (create-parallel-tests-dirs) @ hadoop-aws ---
[INFO] Executing tasks

main:
    [mkdir] Created dir: /Users/aw/shared-vmware/hadoop/hadoop-tools/hadoop-aws/target/test-dir/1
    [mkdir] Created dir: /Users/aw/shared-vmware/hadoop/hadoop-tools/hadoop-aws/target/test-dir/2
    [mkdir] Created dir: /Users/aw/shared-vmware/hadoop/hadoop-tools/hadoop-aws/target/test-dir/3
    [mkdir] Created dir: /Users/aw/shared-vmware/hadoop/hadoop-tools/hadoop-aws/target/test-dir/4
    [mkdir] Created dir: /Users/aw/shared-vmware/hadoop/hadoop-tools/hadoop-aws/target/test/1
    [mkdir] Created dir: /Users/aw/shared-vmware/hadoop/hadoop-tools/hadoop-aws/target/test/2
    [mkdir] Created dir: /Users/aw/shared-vmware/hadoop/hadoop-tools/hadoop-aws/target/test/3
    [mkdir] Created dir: /Users/aw/shared-vmware/hadoop/hadoop-tools/hadoop-aws/target/test/4
[INFO] Executed tasks
...

Tests run: 77, Failures: 0, Errors: 0, Skipped: 0

[INFO] ------------------------------------------------------------------------
[INFO] BUILD SUCCESS
[INFO] ------------------------------------------------------------------------
[INFO] Total time: 8.723 s
[INFO] Finished at: 2017-08-04T15:26:12-07:00
[INFO] Final Memory: 57M/764M
[INFO] ------------------------------------------------------------------------
{code}","05/Aug/17 01:41;hadoopqa;| (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  1m 43s{color} | {color:blue} Docker mode activated. {color} |
|| || || || {color:brown} Prechecks {color} ||
| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |
| {color:red}-1{color} | {color:red} test4tests {color} | {color:red}  0m  0s{color} | {color:red} The patch doesn't appear to include any new or modified tests. Please justify why no new tests are needed for this patch. Also please list what manual steps were performed to verify this patch. {color} |
|| || || || {color:brown} trunk Compile Tests {color} ||
| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  0m 17s{color} | {color:blue} Maven dependency ordering for branch {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 14m 13s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 14m 45s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  3m 16s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  2m 15s{color} | {color:green} trunk passed {color} |
|| || || || {color:brown} Patch Compile Tests {color} ||
| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  0m 16s{color} | {color:blue} Maven dependency ordering for patch {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  1m 58s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 11m 18s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javac {color} | {color:green} 11m 18s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  3m 58s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} |
| {color:green}+1{color} | {color:green} xml {color} | {color:green}  0m  5s{color} | {color:green} The patch has no ill-formed XML file. {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  2m 22s{color} | {color:green} the patch passed {color} |
|| || || || {color:brown} Other Tests {color} ||
| {color:green}+1{color} | {color:green} unit {color} | {color:green}  0m 16s{color} | {color:green} hadoop-project in the patch passed. {color} |
| {color:green}+1{color} | {color:green} unit {color} | {color:green}  8m  1s{color} | {color:green} hadoop-common in the patch passed. {color} |
| {color:red}-1{color} | {color:red} unit {color} | {color:red} 87m 20s{color} | {color:red} hadoop-hdfs in the patch failed. {color} |
| {color:green}+1{color} | {color:green} unit {color} | {color:green}  0m 31s{color} | {color:green} hadoop-aws in the patch passed. {color} |
| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 31s{color} | {color:green} The patch does not generate ASF License warnings. {color} |
| {color:black}{color} | {color:black} {color} | {color:black}154m 18s{color} | {color:black} {color} |
\\
\\
|| Reason || Tests ||
| Failed junit tests | hadoop.hdfs.server.datanode.TestDataNodeHotSwapVolumes |
|   | hadoop.hdfs.server.datanode.TestDataNodeVolumeFailureReporting |
|   | hadoop.hdfs.TestDFSStripedOutputStreamWithFailure150 |
\\
\\
|| Subsystem || Report/Notes ||
| Docker |  Image:yetus/hadoop:14b5c93 |
| JIRA Issue | HADOOP-14696 |
| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12880474/HADOOP-14696-002.patch |
| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  xml  |
| uname | Linux 53f33095ef0a 3.13.0-123-generic #172-Ubuntu SMP Mon Jun 26 18:04:35 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux |
| Build tool | maven |
| Personality | /testptch/hadoop/patchprocess/precommit/personality/provided.sh |
| git revision | trunk / f44b349 |
| Default Java | 1.8.0_131 |
| unit | https://builds.apache.org/job/PreCommit-HADOOP-Build/12956/artifact/patchprocess/patch-unit-hadoop-hdfs-project_hadoop-hdfs.txt |
|  Test Results | https://builds.apache.org/job/PreCommit-HADOOP-Build/12956/testReport/ |
| modules | C: hadoop-project hadoop-common-project/hadoop-common hadoop-hdfs-project/hadoop-hdfs hadoop-tools/hadoop-aws U: . |
| Console output | https://builds.apache.org/job/PreCommit-HADOOP-Build/12956/console |
| Powered by | Apache Yetus 0.6.0-SNAPSHOT   http://yetus.apache.org |


This message was automatically generated.

","07/Aug/17 12:36;stevel@apache.org;patch 003 with the better diff

Allen, don't know what's up...I'll try to take another look @ this later","07/Aug/17 14:59;hadoopqa;| (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 19s{color} | {color:blue} Docker mode activated. {color} |
|| || || || {color:brown} Prechecks {color} ||
| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |
| {color:red}-1{color} | {color:red} test4tests {color} | {color:red}  0m  0s{color} | {color:red} The patch doesn't appear to include any new or modified tests. Please justify why no new tests are needed for this patch. Also please list what manual steps were performed to verify this patch. {color} |
|| || || || {color:brown} trunk Compile Tests {color} ||
| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  1m 25s{color} | {color:blue} Maven dependency ordering for branch {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 18m 54s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 15m 16s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  3m 11s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  2m 12s{color} | {color:green} trunk passed {color} |
|| || || || {color:brown} Patch Compile Tests {color} ||
| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  0m 14s{color} | {color:blue} Maven dependency ordering for patch {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  1m 51s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 10m 23s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javac {color} | {color:green} 10m 23s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  3m  9s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} |
| {color:green}+1{color} | {color:green} xml {color} | {color:green}  0m  5s{color} | {color:green} The patch has no ill-formed XML file. {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  2m 12s{color} | {color:green} the patch passed {color} |
|| || || || {color:brown} Other Tests {color} ||
| {color:green}+1{color} | {color:green} unit {color} | {color:green}  0m 15s{color} | {color:green} hadoop-project in the patch passed. {color} |
| {color:red}-1{color} | {color:red} unit {color} | {color:red}  7m 59s{color} | {color:red} hadoop-common in the patch failed. {color} |
| {color:red}-1{color} | {color:red} unit {color} | {color:red} 66m 40s{color} | {color:red} hadoop-hdfs in the patch failed. {color} |
| {color:green}+1{color} | {color:green} unit {color} | {color:green}  0m 31s{color} | {color:green} hadoop-aws in the patch passed. {color} |
| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 30s{color} | {color:green} The patch does not generate ASF License warnings. {color} |
| {color:black}{color} | {color:black} {color} | {color:black}136m 19s{color} | {color:black} {color} |
\\
\\
|| Reason || Tests ||
| Failed junit tests | hadoop.security.TestKDiag |
|   | hadoop.hdfs.server.datanode.TestDataNodeVolumeFailure |
|   | hadoop.hdfs.server.datanode.TestDataNodeVolumeFailureReporting |
|   | hadoop.hdfs.server.blockmanagement.TestUnderReplicatedBlocks |
|   | hadoop.hdfs.TestDFSStripedOutputStreamWithFailure070 |
\\
\\
|| Subsystem || Report/Notes ||
| Docker |  Image:yetus/hadoop:14b5c93 |
| JIRA Issue | HADOOP-14696 |
| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12880639/HADOOP-14696-003.patch |
| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  xml  |
| uname | Linux 2cdb6aa78fb4 3.13.0-117-generic #164-Ubuntu SMP Fri Apr 7 11:05:26 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux |
| Build tool | maven |
| Personality | /testptch/hadoop/patchprocess/precommit/personality/provided.sh |
| git revision | trunk / 0b67436 |
| Default Java | 1.8.0_131 |
| unit | https://builds.apache.org/job/PreCommit-HADOOP-Build/12968/artifact/patchprocess/patch-unit-hadoop-common-project_hadoop-common.txt |
| unit | https://builds.apache.org/job/PreCommit-HADOOP-Build/12968/artifact/patchprocess/patch-unit-hadoop-hdfs-project_hadoop-hdfs.txt |
|  Test Results | https://builds.apache.org/job/PreCommit-HADOOP-Build/12968/testReport/ |
| modules | C: hadoop-project hadoop-common-project/hadoop-common hadoop-hdfs-project/hadoop-hdfs hadoop-tools/hadoop-aws U: . |
| Console output | https://builds.apache.org/job/PreCommit-HADOOP-Build/12968/console |
| Powered by | Apache Yetus 0.6.0-SNAPSHOT   http://yetus.apache.org |


This message was automatically generated.

","07/Aug/17 16:11;aw;
Keep in mind that hadoop-aws/pom.xml (effectively) sets the hadoop.tmp.dir to the same as test.build.data.  So there's only two dirs being created:

{code}
[INFO] --- maven-antrun-plugin:1.7:run (define-parallel-tests-dirs) @ hadoop-aws ---
[INFO] Executing tasks

main:
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-antrun-plugin:1.7:run (create-parallel-tests-dirs) @ hadoop-aws ---
[INFO] Executing tasks

main:
    [mkdir] Created dir: /testptch/hadoop/hadoop-tools/hadoop-aws/target/test-dir/1
    [mkdir] Created dir: /testptch/hadoop/hadoop-tools/hadoop-aws/target/test-dir/2
    [mkdir] Created dir: /testptch/hadoop/hadoop-tools/hadoop-aws/target/test-dir/3
    [mkdir] Created dir: /testptch/hadoop/hadoop-tools/hadoop-aws/target/test-dir/4
    [mkdir] Created dir: /testptch/hadoop/hadoop-tools/hadoop-aws/target/test/1
    [mkdir] Created dir: /testptch/hadoop/hadoop-tools/hadoop-aws/target/test/2
    [mkdir] Created dir: /testptch/hadoop/hadoop-tools/hadoop-aws/target/test/3
    [mkdir] Created dir: /testptch/hadoop/hadoop-tools/hadoop-aws/target/test/4
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-surefire-plugin:2.17:test (default-test) @ hadoop-aws ---
{code}

(from https://builds.apache.org/job/PreCommit-HADOOP-Build/12968/artifact/patchprocess/patch-unit-hadoop-tools_hadoop-aws.txt)","15/Sep/17 11:24;stevel@apache.org;where are we with this? you want me to rerun everything?","15/Sep/17 20:48;aw;-05:
* A completely different implementation.  This one also supports setting per-core values for testsThreadCount.  e.g., mvn -DtestsThreadCount=1.5C will run 1 and a half tests per core.
* Also get the calculated value of testsThreadCount from within the Hadoop test universe. (This is with an eye towards the MR tests.)","15/Sep/17 21:53;aw;I have switched both PreCommit-hadoop-win and hadoop-trunk-win over to the new implementation.","16/Sep/17 00:12;hadoopqa;| (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 15s{color} | {color:blue} Docker mode activated. {color} |
|| || || || {color:brown} Prechecks {color} ||
| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |
| {color:green}+1{color} | {color:green} test4tests {color} | {color:green}  0m  0s{color} | {color:green} The patch appears to include 1 new or modified test files. {color} |
|| || || || {color:brown} trunk Compile Tests {color} ||
| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  0m 16s{color} | {color:blue} Maven dependency ordering for branch {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 13m 44s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 14m 27s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  2m  5s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  3m 20s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  4m 39s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  2m 29s{color} | {color:green} trunk passed {color} |
|| || || || {color:brown} Patch Compile Tests {color} ||
| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  0m 17s{color} | {color:blue} Maven dependency ordering for patch {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  2m 29s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 12m 45s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javac {color} | {color:green} 12m 45s{color} | {color:green} the patch passed {color} |
| {color:orange}-0{color} | {color:orange} checkstyle {color} | {color:orange}  2m 15s{color} | {color:orange} root: The patch generated 16 new + 15 unchanged - 0 fixed = 31 total (was 15) {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  3m 25s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} |
| {color:green}+1{color} | {color:green} xml {color} | {color:green}  0m  4s{color} | {color:green} The patch has no ill-formed XML file. {color} |
| {color:red}-1{color} | {color:red} findbugs {color} | {color:red}  0m 52s{color} | {color:red} hadoop-maven-plugins generated 1 new + 0 unchanged - 0 fixed = 1 total (was 0) {color} |
| {color:red}-1{color} | {color:red} javadoc {color} | {color:red}  0m 24s{color} | {color:red} hadoop-maven-plugins generated 1 new + 0 unchanged - 0 fixed = 1 total (was 0) {color} |
|| || || || {color:brown} Other Tests {color} ||
| {color:green}+1{color} | {color:green} unit {color} | {color:green}  0m 26s{color} | {color:green} hadoop-maven-plugins in the patch passed. {color} |
| {color:red}-1{color} | {color:red} unit {color} | {color:red}  9m 22s{color} | {color:red} hadoop-common in the patch failed. {color} |
| {color:red}-1{color} | {color:red} unit {color} | {color:red} 92m  2s{color} | {color:red} hadoop-hdfs in the patch failed. {color} |
| {color:green}+1{color} | {color:green} unit {color} | {color:green}  1m 38s{color} | {color:green} hadoop-aws in the patch passed. {color} |
| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 38s{color} | {color:green} The patch does not generate ASF License warnings. {color} |
| {color:black}{color} | {color:black} {color} | {color:black}201m 46s{color} | {color:black} {color} |
\\
\\
|| Reason || Tests ||
| FindBugs | module:hadoop-maven-plugins |
|  |  Exceptional return value of java.io.File.mkdirs() ignored in org.apache.hadoop.maven.plugin.paralleltests.CreateDirsMojo.mkParallelDirs(File, int)  At CreateDirsMojo.java:ignored in org.apache.hadoop.maven.plugin.paralleltests.CreateDirsMojo.mkParallelDirs(File, int)  At CreateDirsMojo.java:[line 88] |
| Failed junit tests | hadoop.security.TestRaceWhenRelogin |
|   | hadoop.ha.TestZKFailoverController |
|   | hadoop.security.TestKDiag |
|   | hadoop.hdfs.server.namenode.metrics.TestNameNodeMetrics |
|   | hadoop.hdfs.TestLeaseRecoveryStriped |
|   | hadoop.hdfs.tools.TestDebugAdmin |
|   | hadoop.hdfs.server.namenode.ha.TestRetryCacheWithHA |
|   | hadoop.hdfs.server.namenode.TestNamenodeRetryCache |
|   | hadoop.hdfs.server.datanode.TestDataNodeVolumeFailure |
|   | hadoop.hdfs.server.datanode.TestDataNodeVolumeFailureReporting |
|   | hadoop.hdfs.server.blockmanagement.TestUnderReplicatedBlocks |
|   | hadoop.hdfs.server.namenode.TestReencryption |
|   | hadoop.hdfs.TestReconstructStripedFile |
| Timed out junit tests | org.apache.hadoop.hdfs.TestWriteReadStripedFile |
\\
\\
|| Subsystem || Report/Notes ||
| Docker |  Image:yetus/hadoop:71bbb86 |
| JIRA Issue | HADOOP-14696 |
| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12887421/HADOOP-14696.05.patch |
| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  xml  findbugs  checkstyle  |
| uname | Linux e231c7bcbb0f 3.13.0-117-generic #164-Ubuntu SMP Fri Apr 7 11:05:26 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux |
| Build tool | maven |
| Personality | /testptch/hadoop/patchprocess/precommit/personality/provided.sh |
| git revision | trunk / fbe06b5 |
| Default Java | 1.8.0_144 |
| findbugs | v3.1.0-RC1 |
| checkstyle | https://builds.apache.org/job/PreCommit-HADOOP-Build/13304/artifact/patchprocess/diff-checkstyle-root.txt |
| findbugs | https://builds.apache.org/job/PreCommit-HADOOP-Build/13304/artifact/patchprocess/new-findbugs-hadoop-maven-plugins.html |
| javadoc | https://builds.apache.org/job/PreCommit-HADOOP-Build/13304/artifact/patchprocess/diff-javadoc-javadoc-hadoop-maven-plugins.txt |
| unit | https://builds.apache.org/job/PreCommit-HADOOP-Build/13304/artifact/patchprocess/patch-unit-hadoop-common-project_hadoop-common.txt |
| unit | https://builds.apache.org/job/PreCommit-HADOOP-Build/13304/artifact/patchprocess/patch-unit-hadoop-hdfs-project_hadoop-hdfs.txt |
|  Test Results | https://builds.apache.org/job/PreCommit-HADOOP-Build/13304/testReport/ |
| modules | C: hadoop-maven-plugins hadoop-common-project/hadoop-common hadoop-hdfs-project/hadoop-hdfs hadoop-tools/hadoop-aws U: . |
| Console output | https://builds.apache.org/job/PreCommit-HADOOP-Build/13304/console |
| Powered by | Apache Yetus 0.6.0-SNAPSHOT   http://yetus.apache.org |


This message was automatically generated.

","16/Sep/17 00:50;aw;-06:
* this precommit stuff sucks
","16/Sep/17 04:01;hadoopqa;| (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 17s{color} | {color:blue} Docker mode activated. {color} |
|| || || || {color:brown} Prechecks {color} ||
| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |
| {color:green}+1{color} | {color:green} test4tests {color} | {color:green}  0m  0s{color} | {color:green} The patch appears to include 1 new or modified test files. {color} |
|| || || || {color:brown} trunk Compile Tests {color} ||
| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  1m  3s{color} | {color:blue} Maven dependency ordering for branch {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 13m 36s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 15m 26s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  2m 15s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  3m 19s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  4m 31s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  2m 35s{color} | {color:green} trunk passed {color} |
|| || || || {color:brown} Patch Compile Tests {color} ||
| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  0m 20s{color} | {color:blue} Maven dependency ordering for patch {color} |
| {color:red}-1{color} | {color:red} mvninstall {color} | {color:red}  0m 37s{color} | {color:red} hadoop-common in the patch failed. {color} |
| {color:red}-1{color} | {color:red} compile {color} | {color:red}  1m  0s{color} | {color:red} root in the patch failed. {color} |
| {color:red}-1{color} | {color:red} javac {color} | {color:red}  1m  0s{color} | {color:red} root in the patch failed. {color} |
| {color:orange}-0{color} | {color:orange} checkstyle {color} | {color:orange}  1m 55s{color} | {color:orange} root: The patch generated 1 new + 15 unchanged - 0 fixed = 16 total (was 15) {color} |
| {color:red}-1{color} | {color:red} mvnsite {color} | {color:red}  0m 41s{color} | {color:red} hadoop-common in the patch failed. {color} |
| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} |
| {color:green}+1{color} | {color:green} xml {color} | {color:green}  0m  4s{color} | {color:green} The patch has no ill-formed XML file. {color} |
| {color:red}-1{color} | {color:red} findbugs {color} | {color:red}  0m 33s{color} | {color:red} hadoop-common in the patch failed. {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  2m  6s{color} | {color:green} the patch passed {color} |
|| || || || {color:brown} Other Tests {color} ||
| {color:green}+1{color} | {color:green} unit {color} | {color:green}  0m 18s{color} | {color:green} hadoop-maven-plugins in the patch passed. {color} |
| {color:red}-1{color} | {color:red} unit {color} | {color:red}  0m 46s{color} | {color:red} hadoop-common in the patch failed. {color} |
| {color:red}-1{color} | {color:red} unit {color} | {color:red} 96m 16s{color} | {color:red} hadoop-hdfs in the patch failed. {color} |
| {color:green}+1{color} | {color:green} unit {color} | {color:green}  0m 43s{color} | {color:green} hadoop-aws in the patch passed. {color} |
| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 23s{color} | {color:green} The patch does not generate ASF License warnings. {color} |
| {color:black}{color} | {color:black} {color} | {color:black}180m 55s{color} | {color:black} {color} |
\\
\\
|| Reason || Tests ||
| Failed junit tests | hadoop.hdfs.server.namenode.metrics.TestNameNodeMetrics |
|   | hadoop.hdfs.TestLeaseRecoveryStriped |
|   | hadoop.hdfs.server.namenode.TestReencryptionWithKMS |
|   | hadoop.hdfs.server.namenode.ha.TestRetryCacheWithHA |
|   | hadoop.hdfs.server.namenode.TestNamenodeRetryCache |
|   | hadoop.hdfs.server.datanode.TestDataNodeVolumeFailure |
|   | hadoop.hdfs.server.blockmanagement.TestBlockTokenWithDFSStriped |
| Timed out junit tests | org.apache.hadoop.hdfs.TestReplication |
|   | org.apache.hadoop.hdfs.TestWriteReadStripedFile |
|   | org.apache.hadoop.hdfs.server.blockmanagement.TestBlockStatsMXBean |
\\
\\
|| Subsystem || Report/Notes ||
| Docker |  Image:yetus/hadoop:71bbb86 |
| JIRA Issue | HADOOP-14696 |
| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12887467/HADOOP-14696.06.patch |
| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  xml  findbugs  checkstyle  |
| uname | Linux 4c32261b830c 3.13.0-117-generic #164-Ubuntu SMP Fri Apr 7 11:05:26 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux |
| Build tool | maven |
| Personality | /testptch/hadoop/patchprocess/precommit/personality/provided.sh |
| git revision | trunk / ef8cd5d |
| Default Java | 1.8.0_144 |
| findbugs | v3.1.0-RC1 |
| mvninstall | https://builds.apache.org/job/PreCommit-HADOOP-Build/13308/artifact/patchprocess/patch-mvninstall-hadoop-common-project_hadoop-common.txt |
| compile | https://builds.apache.org/job/PreCommit-HADOOP-Build/13308/artifact/patchprocess/patch-compile-root.txt |
| javac | https://builds.apache.org/job/PreCommit-HADOOP-Build/13308/artifact/patchprocess/patch-compile-root.txt |
| checkstyle | https://builds.apache.org/job/PreCommit-HADOOP-Build/13308/artifact/patchprocess/diff-checkstyle-root.txt |
| mvnsite | https://builds.apache.org/job/PreCommit-HADOOP-Build/13308/artifact/patchprocess/patch-mvnsite-hadoop-common-project_hadoop-common.txt |
| findbugs | https://builds.apache.org/job/PreCommit-HADOOP-Build/13308/artifact/patchprocess/patch-findbugs-hadoop-common-project_hadoop-common.txt |
| unit | https://builds.apache.org/job/PreCommit-HADOOP-Build/13308/artifact/patchprocess/patch-unit-hadoop-common-project_hadoop-common.txt |
| unit | https://builds.apache.org/job/PreCommit-HADOOP-Build/13308/artifact/patchprocess/patch-unit-hadoop-hdfs-project_hadoop-hdfs.txt |
|  Test Results | https://builds.apache.org/job/PreCommit-HADOOP-Build/13308/testReport/ |
| modules | C: hadoop-maven-plugins hadoop-common-project/hadoop-common hadoop-hdfs-project/hadoop-hdfs hadoop-tools/hadoop-aws U: . |
| Console output | https://builds.apache.org/job/PreCommit-HADOOP-Build/13308/console |
| Powered by | Apache Yetus 0.6.0-SNAPSHOT   http://yetus.apache.org |


This message was automatically generated.

","16/Sep/17 04:09;aw;-07:
* tfw you forget to commit a change","16/Sep/17 04:14;aw;For reference, here's one of the previous patches running on Windows:

https://builds.apache.org/job/PreCommit-HADOOP-win/15/artifact/out/patch-unit-hadoop-hdfs-project_hadoop-hdfs.txt","16/Sep/17 16:33;hadoopqa;| (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 15s{color} | {color:blue} Docker mode activated. {color} |
|| || || || {color:brown} Prechecks {color} ||
| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |
| {color:green}+1{color} | {color:green} test4tests {color} | {color:green}  0m  0s{color} | {color:green} The patch appears to include 1 new or modified test files. {color} |
|| || || || {color:brown} trunk Compile Tests {color} ||
| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  0m 15s{color} | {color:blue} Maven dependency ordering for branch {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 13m 15s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 14m 15s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  1m 59s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  2m 53s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  4m 23s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  2m 28s{color} | {color:green} trunk passed {color} |
|| || || || {color:brown} Patch Compile Tests {color} ||
| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  0m 19s{color} | {color:blue} Maven dependency ordering for patch {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  2m  9s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 10m 51s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javac {color} | {color:green} 10m 51s{color} | {color:green} the patch passed {color} |
| {color:orange}-0{color} | {color:orange} checkstyle {color} | {color:orange}  2m  3s{color} | {color:orange} root: The patch generated 1 new + 15 unchanged - 0 fixed = 16 total (was 15) {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  3m  4s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} |
| {color:green}+1{color} | {color:green} xml {color} | {color:green}  0m  3s{color} | {color:green} The patch has no ill-formed XML file. {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  5m  9s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  2m 42s{color} | {color:green} the patch passed {color} |
|| || || || {color:brown} Other Tests {color} ||
| {color:green}+1{color} | {color:green} unit {color} | {color:green}  0m 27s{color} | {color:green} hadoop-maven-plugins in the patch passed. {color} |
| {color:red}-1{color} | {color:red} unit {color} | {color:red}  8m  9s{color} | {color:red} hadoop-common in the patch failed. {color} |
| {color:red}-1{color} | {color:red} unit {color} | {color:red} 90m 18s{color} | {color:red} hadoop-hdfs in the patch failed. {color} |
| {color:green}+1{color} | {color:green} unit {color} | {color:green}  0m 55s{color} | {color:green} hadoop-aws in the patch passed. {color} |
| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 37s{color} | {color:green} The patch does not generate ASF License warnings. {color} |
| {color:black}{color} | {color:black} {color} | {color:black}192m 59s{color} | {color:black} {color} |
\\
\\
|| Reason || Tests ||
| Failed junit tests | hadoop.security.TestRaceWhenRelogin |
|   | hadoop.security.TestKDiag |
|   | hadoop.hdfs.server.namenode.metrics.TestNameNodeMetrics |
|   | hadoop.hdfs.TestLeaseRecoveryStriped |
|   | hadoop.hdfs.server.namenode.ha.TestRetryCacheWithHA |
|   | hadoop.hdfs.server.namenode.TestNamenodeRetryCache |
|   | hadoop.hdfs.server.datanode.TestDataNodeVolumeFailure |
|   | hadoop.hdfs.TestReplication |
| Timed out junit tests | org.apache.hadoop.hdfs.TestWriteReadStripedFile |
\\
\\
|| Subsystem || Report/Notes ||
| Docker |  Image:yetus/hadoop:71bbb86 |
| JIRA Issue | HADOOP-14696 |
| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12887479/HADOOP-14696.07.patch |
| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  xml  findbugs  checkstyle  |
| uname | Linux bb6bfabb7dc3 3.13.0-117-generic #164-Ubuntu SMP Fri Apr 7 11:05:26 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux |
| Build tool | maven |
| Personality | /testptch/hadoop/patchprocess/precommit/personality/provided.sh |
| git revision | trunk / 7618fa9 |
| Default Java | 1.8.0_144 |
| findbugs | v3.1.0-RC1 |
| checkstyle | https://builds.apache.org/job/PreCommit-HADOOP-Build/13311/artifact/patchprocess/diff-checkstyle-root.txt |
| unit | https://builds.apache.org/job/PreCommit-HADOOP-Build/13311/artifact/patchprocess/patch-unit-hadoop-common-project_hadoop-common.txt |
| unit | https://builds.apache.org/job/PreCommit-HADOOP-Build/13311/artifact/patchprocess/patch-unit-hadoop-hdfs-project_hadoop-hdfs.txt |
|  Test Results | https://builds.apache.org/job/PreCommit-HADOOP-Build/13311/testReport/ |
| modules | C: hadoop-maven-plugins hadoop-common-project/hadoop-common hadoop-hdfs-project/hadoop-hdfs hadoop-tools/hadoop-aws U: . |
| Console output | https://builds.apache.org/job/PreCommit-HADOOP-Build/13311/console |
| Powered by | Apache Yetus 0.6.0-SNAPSHOT   http://yetus.apache.org |


This message was automatically generated.

","22/Sep/17 18:10;hadoopqa;| (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue} 21m 51s{color} | {color:blue} Docker mode activated. {color} |
|| || || || {color:brown} Prechecks {color} ||
| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |
| {color:green}+1{color} | {color:green} test4tests {color} | {color:green}  0m  0s{color} | {color:green} The patch appears to include 1 new or modified test files. {color} |
|| || || || {color:brown} trunk Compile Tests {color} ||
| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  0m 15s{color} | {color:blue} Maven dependency ordering for branch {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 16m 20s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 15m 14s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  2m  5s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  3m  0s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  4m 27s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  2m 27s{color} | {color:green} trunk passed {color} |
|| || || || {color:brown} Patch Compile Tests {color} ||
| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  0m 17s{color} | {color:blue} Maven dependency ordering for patch {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  2m 10s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 12m 47s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javac {color} | {color:green} 12m 47s{color} | {color:green} the patch passed {color} |
| {color:orange}-0{color} | {color:orange} checkstyle {color} | {color:orange}  2m  7s{color} | {color:orange} root: The patch generated 1 new + 15 unchanged - 0 fixed = 16 total (was 15) {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  3m 28s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} |
| {color:green}+1{color} | {color:green} xml {color} | {color:green}  0m  4s{color} | {color:green} The patch has no ill-formed XML file. {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  5m 33s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  2m 51s{color} | {color:green} the patch passed {color} |
|| || || || {color:brown} Other Tests {color} ||
| {color:green}+1{color} | {color:green} unit {color} | {color:green}  0m 26s{color} | {color:green} hadoop-maven-plugins in the patch passed. {color} |
| {color:red}-1{color} | {color:red} unit {color} | {color:red}  8m 57s{color} | {color:red} hadoop-common in the patch failed. {color} |
| {color:red}-1{color} | {color:red} unit {color} | {color:red}112m 20s{color} | {color:red} hadoop-hdfs in the patch failed. {color} |
| {color:green}+1{color} | {color:green} unit {color} | {color:green}  0m 57s{color} | {color:green} hadoop-aws in the patch passed. {color} |
| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 36s{color} | {color:green} The patch does not generate ASF License warnings. {color} |
| {color:black}{color} | {color:black} {color} | {color:black}249m 59s{color} | {color:black} {color} |
\\
\\
|| Reason || Tests ||
| Failed junit tests | hadoop.util.TestReadWriteDiskValidator |
|   | hadoop.util.TestBasicDiskValidator |
|   | hadoop.security.TestRaceWhenRelogin |
|   | hadoop.fs.viewfs.TestViewFileSystemLocalFileSystem |
|   | hadoop.hdfs.server.datanode.TestDataNodeVolumeFailureReporting |
|   | hadoop.hdfs.server.namenode.TestReencryptionWithKMS |
\\
\\
|| Subsystem || Report/Notes ||
| Docker |  Image:yetus/hadoop:71bbb86 |
| JIRA Issue | HADOOP-14696 |
| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12887479/HADOOP-14696.07.patch |
| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  xml  findbugs  checkstyle  |
| uname | Linux bd4c8e7b8eff 3.13.0-116-generic #163-Ubuntu SMP Fri Mar 31 14:13:22 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux |
| Build tool | maven |
| Personality | /testptch/hadoop/patchprocess/precommit/personality/provided.sh |
| git revision | trunk / c71d137 |
| Default Java | 1.8.0_144 |
| findbugs | v3.1.0-RC1 |
| checkstyle | https://builds.apache.org/job/PreCommit-HADOOP-Build/13357/artifact/patchprocess/diff-checkstyle-root.txt |
| unit | https://builds.apache.org/job/PreCommit-HADOOP-Build/13357/artifact/patchprocess/patch-unit-hadoop-common-project_hadoop-common.txt |
| unit | https://builds.apache.org/job/PreCommit-HADOOP-Build/13357/artifact/patchprocess/patch-unit-hadoop-hdfs-project_hadoop-hdfs.txt |
|  Test Results | https://builds.apache.org/job/PreCommit-HADOOP-Build/13357/testReport/ |
| modules | C: hadoop-maven-plugins hadoop-common-project/hadoop-common hadoop-hdfs-project/hadoop-hdfs hadoop-tools/hadoop-aws U: . |
| Console output | https://builds.apache.org/job/PreCommit-HADOOP-Build/13357/console |
| Powered by | Apache Yetus 0.6.0-SNAPSHOT   http://yetus.apache.org |


This message was automatically generated.

","18/Oct/17 19:34;aw;Since this patch appears to be stalled, I'm debating adding the code as a new yetus-maven-plugin.  I'm sure we're not the only ones that need to create test directories based upon parallelism in the build.","26/Feb/18 18:36;elgoiri;We are hitting this when building on Azure.
[~aw] did you move forward with the yetus plugin?","26/Feb/18 18:40;genericqa;| (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m  0s{color} | {color:blue} Docker mode activated. {color} |
| {color:red}-1{color} | {color:red} patch {color} | {color:red}  0m  5s{color} | {color:red} HADOOP-14696 does not apply to trunk. Rebase required? Wrong Branch? See https://wiki.apache.org/hadoop/HowToContribute for help. {color} |
\\
\\
|| Subsystem || Report/Notes ||
| JIRA Issue | HADOOP-14696 |
| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12887479/HADOOP-14696.07.patch |
| Console output | https://builds.apache.org/job/PreCommit-HADOOP-Build/14211/console |
| Powered by | Apache Yetus 0.8.0-SNAPSHOT   http://yetus.apache.org |


This message was automatically generated.

","12/Mar/18 20:21;huanbang1993;Patch [HADOOP-14696-002.patch|https://issues.apache.org/jira/secure/attachment/12880474/HADOOP-14696-002.patch] works for branch-2.9. With this patch, we can run parallel tests for 2.9 on Windows.","13/Mar/18 00:18;elgoiri;Tested on Windows for {{trunk}} and it also works fine.","13/Mar/18 03:13;cdouglas;+1 I committed this. Thanks, Allen.

[~stevel@apache.org], please reopen if the v07 patch breaks on OSX.","13/Mar/18 03:44;hudson;SUCCESS: Integrated in Jenkins build Hadoop-trunk-Commit #13821 (See [https://builds.apache.org/job/Hadoop-trunk-Commit/13821/])
HADOOP-14696. parallel tests don't work for Windows. Contributed by (cdouglas: rev 45d1b0fdcc04a86be91a9b72073cdc30bec04d3b)
* (edit) hadoop-common-project/hadoop-common/pom.xml
* (add) hadoop-maven-plugins/src/main/java/org/apache/hadoop/maven/plugin/paralleltests/CreateDirsMojo.java
* (edit) hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/test/GenericTestUtils.java
* (edit) hadoop-hdfs-project/hadoop-hdfs/pom.xml
* (edit) hadoop-tools/hadoop-aws/pom.xml
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Enhance TestKMSAudit,HADOOP-13395,12991363,Test,Resolved,HADOOP,Hadoop Common,software,omalley,Hadoop Common is the common library for Apache Hadoop.,http://hadoop.apache.org/,Minor,Fixed,xiaochen,xiaochen,xiaochen,21/Jul/16 07:39,02/Oct/19 17:13,12/Jan/21 11:55,08/Aug/16 22:21,2.6.0,,,,2.8.0,3.0.0-alpha1,,,,,kms,,,,0,,,"This jira serves the goals:
- Enhance existing test cases in TestKMSAudit, to rule out flakiness.
- Add a new test case about formatting for different events.

This will help us ensure audit log compatibility when we add a new log format to KMS.",,andrew.wang,hudson,weichiu,xiaochen,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"21/Jul/16 07:40;xiaochen;HADOOP-13395.01.patch;https://issues.apache.org/jira/secure/attachment/12819279/HADOOP-13395.01.patch","26/Jul/16 07:18;xiaochen;HADOOP-13395.02.patch;https://issues.apache.org/jira/secure/attachment/12820118/HADOOP-13395.02.patch","29/Jul/16 05:11;xiaochen;HADOOP-13395.03.patch;https://issues.apache.org/jira/secure/attachment/12820870/HADOOP-13395.03.patch",,,,,,,,,,,,,,,,,,,,,3.0,,,,,,,,,,,,,,,,,,,,2016-07-21 09:31:32.807,,,false,,,,,,,,,,,,,,,,,9223372036854775807,Reviewed,,,,Mon Aug 08 23:08:20 UTC 2016,,,,,,,"0|i31awn:",9223372036854775807,,,,,,,,,,,,,2.9.0,,,,,,,,,,"21/Jul/16 09:31;hadoopqa;| (/) *{color:green}+1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 26s{color} | {color:blue} Docker mode activated. {color} |
| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |
| {color:green}+1{color} | {color:green} test4tests {color} | {color:green}  0m  0s{color} | {color:green} The patch appears to include 1 new or modified test files. {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  6m 47s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green}  6m 58s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 13s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  0m 19s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green}  0m 12s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  0m 21s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 12s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  0m 16s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green}  6m 58s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javac {color} | {color:green}  6m 58s{color} | {color:green} the patch passed {color} |
| {color:orange}-0{color} | {color:orange} checkstyle {color} | {color:orange}  0m 13s{color} | {color:orange} hadoop-common-project/hadoop-kms: The patch generated 10 new + 5 unchanged - 2 fixed = 15 total (was 7) {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  0m 19s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green}  0m 13s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  0m 29s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 12s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} unit {color} | {color:green}  2m  8s{color} | {color:green} hadoop-kms in the patch passed. {color} |
| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 21s{color} | {color:green} The patch does not generate ASF License warnings. {color} |
| {color:black}{color} | {color:black} {color} | {color:black} 28m  2s{color} | {color:black} {color} |
\\
\\
|| Subsystem || Report/Notes ||
| Docker |  Image:yetus/hadoop:9560f25 |
| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12819279/HADOOP-13395.01.patch |
| JIRA Issue | HADOOP-13395 |
| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  findbugs  checkstyle  |
| uname | Linux 87d78d056336 3.13.0-36-lowlatency #63-Ubuntu SMP PREEMPT Wed Sep 3 21:56:12 UTC 2014 x86_64 x86_64 x86_64 GNU/Linux |
| Build tool | maven |
| Personality | /testptch/hadoop/patchprocess/precommit/personality/provided.sh |
| git revision | trunk / 557a245 |
| Default Java | 1.8.0_91 |
| findbugs | v3.0.0 |
| checkstyle | https://builds.apache.org/job/PreCommit-HADOOP-Build/10052/artifact/patchprocess/diff-checkstyle-hadoop-common-project_hadoop-kms.txt |
|  Test Results | https://builds.apache.org/job/PreCommit-HADOOP-Build/10052/testReport/ |
| modules | C: hadoop-common-project/hadoop-kms U: hadoop-common-project/hadoop-kms |
| Console output | https://builds.apache.org/job/PreCommit-HADOOP-Build/10052/console |
| Powered by | Apache Yetus 0.4.0-SNAPSHOT   http://yetus.apache.org |


This message was automatically generated.

","26/Jul/16 07:18;xiaochen;Patch 2 fixes checkstyle warnings (except the >80 chars ones, which in this test I think is better to read).

Fixed the flaky {{testAggregationUnauth}}:
{{KMSAudit}} utilizes a removal listener to aggregate the same logs ({{OK}} ones in the test), and an {{UNAUTHORIZED}} log will invalidate the aggregation cache. Whether the {{UNAUTHORIZED}} entry or the aggregated {{OK}} log appear first solely depend on the run time -  after {{cache.invalidate(cacheKey)}}, whether the {{AUDIT_LOG.info}} executes first, or the removal listener's log executes first.

Fixed the unit test by verifying either scenario happened. The goal of the test is to check aggregation stops after {{UNAUTHORIZED}}, which is checked via the last {{OK}} message.","26/Jul/16 07:56;hadoopqa;| (/) *{color:green}+1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 14s{color} | {color:blue} Docker mode activated. {color} |
| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |
| {color:green}+1{color} | {color:green} test4tests {color} | {color:green}  0m  0s{color} | {color:green} The patch appears to include 1 new or modified test files. {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  7m  5s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green}  7m 13s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 12s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  0m 20s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green}  0m 13s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  0m 24s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 14s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  0m 16s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green}  7m  5s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javac {color} | {color:green}  7m  5s{color} | {color:green} the patch passed {color} |
| {color:orange}-0{color} | {color:orange} checkstyle {color} | {color:orange}  0m 15s{color} | {color:orange} hadoop-common-project/hadoop-kms: The patch generated 8 new + 5 unchanged - 2 fixed = 13 total (was 7) {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  0m 21s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green}  0m 15s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  0m 31s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 11s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} unit {color} | {color:green}  2m 15s{color} | {color:green} hadoop-kms in the patch passed. {color} |
| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 21s{color} | {color:green} The patch does not generate ASF License warnings. {color} |
| {color:black}{color} | {color:black} {color} | {color:black} 28m 54s{color} | {color:black} {color} |
\\
\\
|| Subsystem || Report/Notes ||
| Docker |  Image:yetus/hadoop:9560f25 |
| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12820118/HADOOP-13395.02.patch |
| JIRA Issue | HADOOP-13395 |
| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  findbugs  checkstyle  |
| uname | Linux 3c3f0909c6be 3.13.0-36-lowlatency #63-Ubuntu SMP PREEMPT Wed Sep 3 21:56:12 UTC 2014 x86_64 x86_64 x86_64 GNU/Linux |
| Build tool | maven |
| Personality | /testptch/hadoop/patchprocess/precommit/personality/provided.sh |
| git revision | trunk / 7cac765 |
| Default Java | 1.8.0_101 |
| findbugs | v3.0.0 |
| checkstyle | https://builds.apache.org/job/PreCommit-HADOOP-Build/10083/artifact/patchprocess/diff-checkstyle-hadoop-common-project_hadoop-kms.txt |
|  Test Results | https://builds.apache.org/job/PreCommit-HADOOP-Build/10083/testReport/ |
| modules | C: hadoop-common-project/hadoop-kms U: hadoop-common-project/hadoop-kms |
| Console output | https://builds.apache.org/job/PreCommit-HADOOP-Build/10083/console |
| Powered by | Apache Yetus 0.4.0-SNAPSHOT   http://yetus.apache.org |


This message was automatically generated.

","28/Jul/16 23:10;andrew.wang;Looks good overall, thanks for working on this Xiao!

Few nitty comments:
* We introduce a new {{interval}} variable that's only used once, could we just inline it? Seems a bit confusing too since we also have a {{sleepInterval}} variable.
* Can we make the indentation the same for the new or case? This makes it easier to diff visually.

In general, if we're trying to reduce flakiness, I'd like to do it by removing the need for sleeps entirely. Is there some way to manually trigger aggregation instead, perhaps via a VisibleForTesting method? This would also make the test deterministic.","29/Jul/16 05:11;xiaochen;Thanks a lot [~andrew.wang] for the review! Getting rid of {{sleep}} is definitely better. :)
Patch 3 is attached, addressing your comments. Please take a look and share your thoughts.

The major flakiness of the past occurrence is due to the race in different threads after an UNAUTHRIZED log - one UNAUTH log itself, and one aggregated OK log on the removal listener thread after UNAUTH. I put a comment in the test to explain it.

","29/Jul/16 05:48;hadoopqa;| (/) *{color:green}+1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 10s{color} | {color:blue} Docker mode activated. {color} |
| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |
| {color:green}+1{color} | {color:green} test4tests {color} | {color:green}  0m  0s{color} | {color:green} The patch appears to include 1 new or modified test files. {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  6m 54s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green}  7m  5s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 12s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  0m 18s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green}  0m 12s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  0m 21s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 11s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  0m 15s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green}  8m  3s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javac {color} | {color:green}  8m  3s{color} | {color:green} the patch passed {color} |
| {color:orange}-0{color} | {color:orange} checkstyle {color} | {color:orange}  0m 15s{color} | {color:orange} hadoop-common-project/hadoop-kms: The patch generated 6 new + 14 unchanged - 0 fixed = 20 total (was 14) {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  0m 19s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green}  0m 15s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  0m 34s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 13s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} unit {color} | {color:green}  2m 12s{color} | {color:green} hadoop-kms in the patch passed. {color} |
| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 23s{color} | {color:green} The patch does not generate ASF License warnings. {color} |
| {color:black}{color} | {color:black} {color} | {color:black} 29m 23s{color} | {color:black} {color} |
\\
\\
|| Subsystem || Report/Notes ||
| Docker |  Image:yetus/hadoop:9560f25 |
| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12820870/HADOOP-13395.03.patch |
| JIRA Issue | HADOOP-13395 |
| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  findbugs  checkstyle  |
| uname | Linux 7771192a3652 3.13.0-36-lowlatency #63-Ubuntu SMP PREEMPT Wed Sep 3 21:56:12 UTC 2014 x86_64 x86_64 x86_64 GNU/Linux |
| Build tool | maven |
| Personality | /testptch/hadoop/patchprocess/precommit/personality/provided.sh |
| git revision | trunk / 8ebf2e9 |
| Default Java | 1.8.0_101 |
| findbugs | v3.0.0 |
| checkstyle | https://builds.apache.org/job/PreCommit-HADOOP-Build/10115/artifact/patchprocess/diff-checkstyle-hadoop-common-project_hadoop-kms.txt |
|  Test Results | https://builds.apache.org/job/PreCommit-HADOOP-Build/10115/testReport/ |
| modules | C: hadoop-common-project/hadoop-kms U: hadoop-common-project/hadoop-kms |
| Console output | https://builds.apache.org/job/PreCommit-HADOOP-Build/10115/console |
| Powered by | Apache Yetus 0.4.0-SNAPSHOT   http://yetus.apache.org |


This message was automatically generated.

","08/Aug/16 22:02;weichiu;+1. The checkstyle is due to the long message matching string. Forcing it to be shorter makes it harder to read.","08/Aug/16 22:21;weichiu;Thanks [~xiaochen] for the patch and [~andrew.wang] for the initial review. Committed to trunk, branch-2 and branch-2.8.","08/Aug/16 22:56;hudson;SUCCESS: Integrated in Hadoop-trunk-Commit #10238 (See [https://builds.apache.org/job/Hadoop-trunk-Commit/10238/])
HADOOP-13395. Enhance TestKMSAudit. Contributed by Xiao Chen. (weichiu: rev 070548943a16370a74277d1b1d10b713e2ca81d0)
* hadoop-common-project/hadoop-kms/src/main/java/org/apache/hadoop/crypto/key/kms/server/KMSAudit.java
* hadoop-common-project/hadoop-kms/src/test/java/org/apache/hadoop/crypto/key/kms/server/TestKMSAudit.java
","08/Aug/16 23:08;xiaochen;Thanks a lot [~weichiu] for the review and commit, and Andrew for the initial review!",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Allow RPCCallBenchmark to benchmark calls by different users,HADOOP-10286,12691159,Test,Patch Available,HADOOP,Hadoop Common,software,omalley,Hadoop Common is the common library for Apache Hadoop.,http://hadoop.apache.org/,Minor,,xkrogen,chrilisf,chrilisf,24/Jan/14 23:25,08/Feb/19 17:39,12/Jan/21 11:55,,,,,,,,,,,,ipc,,,,0,qos,rpc,,,arp,chrilisf,eddyxu,linyiqun,shv,vagarychen,xkrogen,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"30/Nov/18 22:22;xkrogen;HADOOP-10286.001.patch;https://issues.apache.org/jira/secure/attachment/12950232/HADOOP-10286.001.patch","02/May/14 00:11;chrilisf;HADOOP-10286.patch;https://issues.apache.org/jira/secure/attachment/12642961/HADOOP-10286.patch",,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,2018-11-30 22:22:45.941,,,false,,,,,,,,,,,,,,,,,369902,,,,,Sat Dec 01 00:21:38 UTC 2018,,,,,,,"0|i1rr5j:",370204,,,,,,,,,,,,,,,,,,,,,,,"02/May/14 00:10;chrilisf;This patch enhances the existing RPCCallBenchmark to support testing variable loads from different users, as well as loading custom configurations, allowing it to test for different call queues and scenarios.","22/Aug/14 23:31;chrilisf;Canceling patch so I can add better metrics: 50th percentile, 90th percentile, 99th, etc","30/Nov/18 22:22;xkrogen;
Since it looks like this has been abandoned, I'm going to go ahead and take it up ([~chrilisf] - please let me know if you have any qualms with this). I'm attaching a v001 patch which extends the original work:
* Adds the ability to specify different client user names to use, and how many threads to use for each of those user names. This allows us to emulate, for example, a heavy user's impact on many lighter users.
* Wraps the proxy invocation in a RetryInvocationHandler so that it is possible to enable IPC backoff and not have the benchmark immediately fail when a backoff request is received.
* Adds percentile latency information via [HdrHistogram|https://github.com/HdrHistogram/HdrHistogram].

I'm hoping to use something similar to this to demonstrate the viability of approaches similar to those proposed in HADOOP-15016. For now, I was able to use this benchmark to demonstrate the efficacy of IPC backoff in combination with {{FairCallQueue}}:

{code}
> for backoff in false true; do echo ""Backoff: ${backoff}""; $HADOOP_HOME/bin/hadoop org.apache.hadoop.ipc.RPCCallBenchmark -Dipc.9000.callqueue.impl=org.apache.hadoop.ipc.FairCallQueue -Dipc.9000.backoff.enable=${backoff} -p 9000 -r 4 -c 10 -s 5 -e protobuf -t 120 -u c1,c2,c3,c4,c5,c6,c7,c8,c9,cBig -T 50,50,50,50,50,50,50,50,50,1000 2>&1 | grep ""Client #""; done
Backoff: false
Client #0 (c1)                :    5628.09 calls/sec       7.93ms P50 Latency      10.64ms P90 Latency      52.95ms P99 Latency
Client #1 (c2)                :    5639.62 calls/sec       8.11ms P50 Latency      10.94ms P90 Latency      59.24ms P99 Latency
Client #2 (c3)                :    5616.79 calls/sec       8.11ms P50 Latency      10.92ms P90 Latency      56.92ms P99 Latency
Client #3 (c4)                :    5626.38 calls/sec       7.95ms P50 Latency      10.63ms P90 Latency      42.66ms P99 Latency
Client #4 (c5)                :    5624.99 calls/sec       8.69ms P50 Latency      15.84ms P90 Latency      68.42ms P99 Latency
Client #5 (c6)                :    5665.82 calls/sec       8.12ms P50 Latency      10.87ms P90 Latency      23.13ms P99 Latency
Client #6 (c7)                :    5653.36 calls/sec       8.14ms P50 Latency      10.95ms P90 Latency      62.13ms P99 Latency
Client #7 (c8)                :    5611.25 calls/sec       8.12ms P50 Latency      10.90ms P90 Latency      54.53ms P99 Latency
Client #8 (c9)                :    5616.34 calls/sec       8.14ms P50 Latency      10.94ms P90 Latency      56.92ms P99 Latency
Client #9 (cBig)              :   99206.13 calls/sec       8.15ms P50 Latency      10.90ms P90 Latency      56.79ms P99 Latency
Backoff: true
Client #0 (c1)                :   14072.36 calls/sec       1.37ms P50 Latency       2.88ms P90 Latency       9.91ms P99 Latency
Client #1 (c2)                :   14087.66 calls/sec       1.36ms P50 Latency       2.70ms P90 Latency       9.86ms P99 Latency
Client #2 (c3)                :   14152.81 calls/sec       1.38ms P50 Latency       3.50ms P90 Latency      10.02ms P99 Latency
Client #3 (c4)                :   13889.88 calls/sec       1.37ms P50 Latency       2.84ms P90 Latency      10.02ms P99 Latency
Client #4 (c5)                :   14282.52 calls/sec       1.37ms P50 Latency       2.80ms P90 Latency       9.92ms P99 Latency
Client #5 (c6)                :   14041.97 calls/sec       1.36ms P50 Latency       2.72ms P90 Latency       9.85ms P99 Latency
Client #6 (c7)                :   14271.91 calls/sec       1.38ms P50 Latency       3.81ms P90 Latency      10.08ms P99 Latency
Client #7 (c8)                :   14073.15 calls/sec       1.37ms P50 Latency       2.81ms P90 Latency       9.90ms P99 Latency
Client #8 (c9)                :   13917.20 calls/sec       1.37ms P50 Latency       2.80ms P90 Latency      10.02ms P99 Latency
Client #9 (cBig)              :   38200.69 calls/sec       4.82ms P50 Latency       9.82ms P90 Latency     878.71ms P99 Latency
{code}

One currently outstanding issue is that HdrHistogram isn't copied into the hadoop-dist tarball so you need to manually add it to the classpath to be able to run {{RPCCallBenchmark}}. Since it is test-only, I don't think it makes sense for it to end up in the {{share/lib/hadoop/common}} directory, and I'm not really sure else it would belong, so I think the current approach might be fine. Open to suggestions here, though.","01/Dec/18 00:21;hadoopqa;| (/) *{color:green}+1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 16s{color} | {color:blue} Docker mode activated. {color} |
|| || || || {color:brown} Prechecks {color} ||
| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |
| {color:green}+1{color} | {color:green} test4tests {color} | {color:green}  0m  0s{color} | {color:green} The patch appears to include 2 new or modified test files. {color} |
|| || || || {color:brown} trunk Compile Tests {color} ||
| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  0m 24s{color} | {color:blue} Maven dependency ordering for branch {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 22m 21s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 17m 29s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  3m 16s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  1m 40s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 17m 32s{color} | {color:green} branch has no errors when building and testing our client artifacts. {color} |
| {color:blue}0{color} | {color:blue} findbugs {color} | {color:blue}  0m  0s{color} | {color:blue} Skipped patched modules with no Java source: hadoop-project {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  1m 47s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  1m 23s{color} | {color:green} trunk passed {color} |
|| || || || {color:brown} Patch Compile Tests {color} ||
| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  0m 27s{color} | {color:blue} Maven dependency ordering for patch {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  1m 12s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 15m 56s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javac {color} | {color:green} 15m 56s{color} | {color:green} the patch passed {color} |
| {color:orange}-0{color} | {color:orange} checkstyle {color} | {color:orange}  3m 19s{color} | {color:orange} root: The patch generated 16 new + 34 unchanged - 9 fixed = 50 total (was 43) {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  1m 36s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} |
| {color:green}+1{color} | {color:green} xml {color} | {color:green}  0m  3s{color} | {color:green} The patch has no ill-formed XML file. {color} |
| {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 12m  9s{color} | {color:green} patch has no errors when building and testing our client artifacts. {color} |
| {color:blue}0{color} | {color:blue} findbugs {color} | {color:blue}  0m  0s{color} | {color:blue} Skipped patched modules with no Java source: hadoop-project {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  2m  5s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  1m 20s{color} | {color:green} the patch passed {color} |
|| || || || {color:brown} Other Tests {color} ||
| {color:green}+1{color} | {color:green} unit {color} | {color:green}  0m 21s{color} | {color:green} hadoop-project in the patch passed. {color} |
| {color:green}+1{color} | {color:green} unit {color} | {color:green}  8m 13s{color} | {color:green} hadoop-common in the patch passed. {color} |
| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 39s{color} | {color:green} The patch does not generate ASF License warnings. {color} |
| {color:black}{color} | {color:black} {color} | {color:black}111m 10s{color} | {color:black} {color} |
\\
\\
|| Subsystem || Report/Notes ||
| Docker | Client=17.05.0-ce Server=17.05.0-ce Image:yetus/hadoop:8f97d6f |
| JIRA Issue | HADOOP-10286 |
| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12950232/HADOOP-10286.001.patch |
| Optional Tests |  dupname  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  shadedclient  xml  findbugs  checkstyle  |
| uname | Linux bf8c58a77a21 4.4.0-134-generic #160~14.04.1-Ubuntu SMP Fri Aug 17 11:07:07 UTC 2018 x86_64 x86_64 x86_64 GNU/Linux |
| Build tool | maven |
| Personality | /testptch/patchprocess/precommit/personality/provided.sh |
| git revision | trunk / 99e201d |
| maven | version: Apache Maven 3.3.9 |
| Default Java | 1.8.0_181 |
| findbugs | v3.1.0-RC1 |
| checkstyle | https://builds.apache.org/job/PreCommit-HADOOP-Build/15590/artifact/out/diff-checkstyle-root.txt |
|  Test Results | https://builds.apache.org/job/PreCommit-HADOOP-Build/15590/testReport/ |
| Max. process+thread count | 1601 (vs. ulimit of 10000) |
| modules | C: hadoop-project hadoop-common-project/hadoop-common U: . |
| Console output | https://builds.apache.org/job/PreCommit-HADOOP-Build/15590/console |
| Powered by | Apache Yetus 0.8.0   http://yetus.apache.org |


This message was automatically generated.

",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
TestBasicDiskValidator fails with NoSuchFileException,HADOOP-15532,13165626,Test,Resolved,HADOOP,Hadoop Common,software,omalley,Hadoop Common is the common library for Apache Hadoop.,http://hadoop.apache.org/,Minor,Fixed,giovanni.fumarola,elgoiri,elgoiri,12/Jun/18 17:16,10/Dec/18 01:00,12/Jan/21 11:55,12/Jun/18 21:24,,,,,2.10.0,2.9.2,3.0.4,3.1.1,3.2.0,,,,,,0,,,"TestBasicDiskValidator is failing with NoSuchFileException once in a while.
The daily Linux build shows the error [here|https://builds.apache.org/job/hadoop-qbt-trunk-java8-linux-x86/809/testReport/org.apache.hadoop.util/TestBasicDiskValidator/].",,ayushtkn,elgoiri,giovanni.fumarola,hudson,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"12/Jun/18 17:23;giovanni.fumarola;AfterFix.png;https://issues.apache.org/jira/secure/attachment/12927506/AfterFix.png","12/Jun/18 17:23;giovanni.fumarola;BeforeFix.png;https://issues.apache.org/jira/secure/attachment/12927505/BeforeFix.png","12/Jun/18 17:19;giovanni.fumarola;HADOOP-15532.v1.patch;https://issues.apache.org/jira/secure/attachment/12927504/HADOOP-15532.v1.patch",,,,,,,,,,,,,,,,,,,,,3.0,,,,,,,,,,,,,,,,,,,,2018-06-12 17:24:36.082,,,false,,,,,,,,,,,,,,,,,9223372036854775807,Reviewed,,,,Mon Dec 10 01:00:16 UTC 2018,,,,,,,"0|i3us3r:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,"12/Jun/18 17:17;elgoiri;HADOOP-13380 changed the path location for the tests.","12/Jun/18 17:24;giovanni.fumarola;Thanks [~elgoiri] for opening it. Attached [^HADOOP-15532.v1.patch] with the fix.

Before the fix:

  !BeforeFix.png!
After the fix:

!AfterFix.png!

 

 ","12/Jun/18 19:30;genericqa;| (/) *{color:green}+1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 19s{color} | {color:blue} Docker mode activated. {color} |
|| || || || {color:brown} Prechecks {color} ||
| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |
| {color:green}+1{color} | {color:green} test4tests {color} | {color:green}  0m  0s{color} | {color:green} The patch appears to include 1 new or modified test files. {color} |
|| || || || {color:brown} trunk Compile Tests {color} ||
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 27m 32s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 30m  0s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 18s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  1m 14s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 12m 43s{color} | {color:green} branch has no errors when building and testing our client artifacts. {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  1m 37s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 58s{color} | {color:green} trunk passed {color} |
|| || || || {color:brown} Patch Compile Tests {color} ||
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  0m 53s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 29m 14s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javac {color} | {color:green} 29m 14s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 20s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  1m 14s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} |
| {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 11m  3s{color} | {color:green} patch has no errors when building and testing our client artifacts. {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  1m 51s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 58s{color} | {color:green} the patch passed {color} |
|| || || || {color:brown} Other Tests {color} ||
| {color:green}+1{color} | {color:green} unit {color} | {color:green}  9m 23s{color} | {color:green} hadoop-common in the patch passed. {color} |
| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 36s{color} | {color:green} The patch does not generate ASF License warnings. {color} |
| {color:black}{color} | {color:black} {color} | {color:black}130m 13s{color} | {color:black} {color} |
\\
\\
|| Subsystem || Report/Notes ||
| Docker | Client=17.05.0-ce Server=17.05.0-ce Image:yetus/hadoop:abb62dd |
| JIRA Issue | HADOOP-15532 |
| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12927504/HADOOP-15532.v1.patch |
| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  shadedclient  findbugs  checkstyle  |
| uname | Linux 758c705cf339 3.13.0-137-generic #186-Ubuntu SMP Mon Dec 4 19:09:19 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux |
| Build tool | maven |
| Personality | /testptch/patchprocess/precommit/personality/provided.sh |
| git revision | trunk / 10d0e4b |
| maven | version: Apache Maven 3.3.9 |
| Default Java | 1.8.0_171 |
| findbugs | v3.1.0-RC1 |
|  Test Results | https://builds.apache.org/job/PreCommit-HADOOP-Build/14761/testReport/ |
| Max. process+thread count | 1693 (vs. ulimit of 10000) |
| modules | C: hadoop-common-project/hadoop-common U: hadoop-common-project/hadoop-common |
| Console output | https://builds.apache.org/job/PreCommit-HADOOP-Build/14761/console |
| Powered by | Apache Yetus 0.8.0-SNAPSHOT   http://yetus.apache.org |


This message was automatically generated.

","12/Jun/18 20:49;elgoiri;The default test dir fix is the same as in YARN-8422.
 [^HADOOP-15532.v1.patch] LGTM.
+1
Committing.","12/Jun/18 21:24;elgoiri;Thanks [~giovanni.fumarola] for the fix.

Committed to trunk, branch-3.1, branch-3.0, branch-2, and branch-2.9.","12/Jun/18 21:55;hudson;ABORTED: Integrated in Jenkins build Hadoop-trunk-Commit #14414 (See [https://builds.apache.org/job/Hadoop-trunk-Commit/14414/])
HADOOP-15532. TestBasicDiskValidator fails with NoSuchFileException. (inigoiri: rev aeaf9fec62f10699d1c809d66444520fe4533c2c)
* (edit) hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/util/TestDiskChecker.java
","13/Jun/18 17:43;giovanni.fumarola;The [tests|https://builds.apache.org/job/hadoop-qbt-trunk-java8-linux-x86/810/testReport/org.apache.hadoop.util/TestBasicDiskValidator/] are not failing anymore in linux. We removed 12 failures from yesterday: [result|https://builds.apache.org/job/hadoop-qbt-trunk-java8-linux-x86/810/testReport/]","09/Dec/18 15:44;ayushtkn;Thanx [~giovanni.fumarola] and [~elgoiri] for working on this.

I guess this hasn't been fixed.It seems to be failing with NoSuchFileException still.

Pls find the reference

https://builds.apache.org/job/hadoop-qbt-trunk-java8-linux-x86/982/testReport/junit/org.apache.hadoop.util/TestBasicDiskValidator/

 ","10/Dec/18 01:00;elgoiri;This must be something new.
It looks like this worked for a few months.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
determine-flaky-tests makes invalid test assumptions,HADOOP-11964,12829320,Test,Resolved,HADOOP,Hadoop Common,software,omalley,Hadoop Common is the common library for Apache Hadoop.,http://hadoop.apache.org/,Minor,Won't Fix,yzhangal,aw,aw,12/May/15 20:28,01/Sep/18 20:29,12/Jan/21 11:55,01/Sep/18 20:29,,,,,,,,,,,,,,,0,,,"When running determine-flaky-tests against precommit-hadoop-build, it throws a lot of errors because it assumes that every job is actually running Java tests.  There should be some way to make it not do that or at least fix its assumptions.",,aw,busbey,yzhangal,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,2015-05-13 07:47:42.426,,,false,,,,,,,,,,,,,,,,,9223372036854775807,,,,,Wed May 13 07:47:42 UTC 2015,,,,,,,"0|i2en3z:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,"13/May/15 07:47;yzhangal;Thanks [~aw] for reporting the issue. I will try to work on it asap.

",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Fix broken unit tests on Windows,HADOOP-15475,13160080,Test,Open,HADOOP,Hadoop Common,software,omalley,Hadoop Common is the common library for Apache Hadoop.,http://hadoop.apache.org/,Minor,,huanbang1993,huanbang1993,huanbang1993,17/May/18 16:46,12/Aug/18 14:54,12/Jan/21 11:55,,2.9.1,3.1.0,,,,,,,,,,,,,0,Windows,,"There are hundreds of unit tests that fail on Windows. This JIRA tracks the effort to fix them.

The main reasons for unit test failures on Windows are:
* Windows/Linux path formats (e.g., HDFS-10256).
* Line separator.
* Locked files: Windows locks files when opening them.
** The typical trigger is not cleaning MiniDFSCluster leaves files locked when a test times out; they need to be cleaned using After.
* Memory lock size.
* Slow DNS resolution (e.g., HDFS-13569).
* Locked ports (e.g., HDFS-11700)",,aw,cdouglas,elgoiri,giovanni.fumarola,huanbang1993,slachiewicz,stevel@apache.org,subru,surmountian,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,HDFS-13570,HDFS-13569,HDFS-13568,HDFS-13567,HDFS-13563,HDFS-13562,HDFS-13561,HDFS-13560,HDFS-13559,HDFS-13558,HDFS-13557,HDFS-13556,HDFS-13555,HDFS-13554,HDFS-13552,HDFS-13551,HDFS-13550,HDFS-13548,HDFS-13542,HDFS-11700,HADOOP-15308,HADOOP-15454,HADOOP-15458,HDFS-13268,HDFS-13296,HDFS-13336,HDFS-13408,HDFS-13509,HDFS-13537,HDFS-13586,HDFS-13503,HDFS-13587,HDFS-13588,HDFS-13591,HDFS-13592,HDFS-13593,YARN-8324,YARN-8327,YARN-8344,YARN-8348,HDFS-13618,HDFS-13619,HDFS-13620,HADOOP-15494,HDFS-13624,HADOOP-15467,HADOOP-15497,HADOOP-15496,HDFS-13627,YARN-8370,HADOOP-15498,HDFS-13629,HDFS-13630,HDFS-13632,YARN-8359,HDFS-13631,MAPREDUCE-7102,MAPREDUCE-7103,HDDS-142,HDFS-13648,HDFS-13649,HDFS-13651,MAPREDUCE-7105,MAPREDUCE-7108,HADOOP-15529,YARN-8422,HADOOP-15532,MAPREDUCE-7111,HDFS-13676,HDFS-13681,HDFS-13714,YARN-8526,YARN-8527,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,2018-05-17 17:01:06.824,,,false,,,,,,,,,,,,,,,,,9223372036854775807,,,,,Sun Aug 12 14:54:55 UTC 2018,,,,,,,"0|i3tucf:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,"17/May/18 17:01;elgoiri;On May 17th 2018, the [Linux daily build|https://builds.apache.org/view/H-L/view/Hadoop/job/hadoop-qbt-trunk-java8-linux-x86/lastBuild/testReport/] ran 19577 tests, skipped 1161 and 18 of them failed (these are mostly flaky tests). When we started this effort in the beginning of May, the [Windows daily build|https://builds.apache.org/job/hadoop-trunk-win/459/testReport/] ran 19386 test, skipped 1465, and 846 failed.

The evolution over these days have been:
||Run||Date||Total||Skipped||Failed||Passed||
|[459|https://builds.apache.org/job/hadoop-trunk-win/459/testReport/]|2018/05/06|19386|1465|846|17075|
|[460|https://builds.apache.org/job/hadoop-trunk-win/460/testReport/]|2018/05/07|16906|1418|754|14734 |
|[463|https://builds.apache.org/job/hadoop-trunk-win/463/testReport/]|2018/05/10|19252|1472|540|17240 |
|[467|https://builds.apache.org/job/hadoop-trunk-win/467/testReport/]|2018/05/14|19317|1472|573|17272 |
|[469|https://builds.apache.org/job/hadoop-trunk-win/469/testReport/]|2018/05/16|19326|1472|516|17388 |

Not major breakthrough but we are slowly getting to something reasonable.","17/May/18 17:21;elgoiri;CC [~stevel@apache.org] and [~giovanni.fumarola] for awareness.
This is not fully related to the effort in HADOOP-15461 but somewhat.","17/May/18 18:17;elgoiri;In the [current Windows daily build|https://builds.apache.org/job/hadoop-trunk-win/469/testReport/], the top offenders are:
 * [TestAuditLoggerWithCommands|https://builds.apache.org/job/hadoop-trunk-win/469/testReport/org.apache.hadoop.hdfs.server.namenode/TestAuditLoggerWithCommands/] 40 failures
 * [TestRawLocalFileSystemContract|https://builds.apache.org/job/hadoop-trunk-win/469/testReport/org.apache.hadoop.fs/TestRawLocalFileSystemContract/] 21 failures
 * [TestMetadataStore|https://builds.apache.org/job/hadoop-trunk-win/469/testReport/org.apache.hadoop.ozone/TestMetadataStore/] 18 failures
 * [TestOpenFilesWithSnapshot|https://builds.apache.org/job/hadoop-trunk-win/469/testReport/org.apache.hadoop.hdfs.server.namenode.snapshot/TestOpenFilesWithSnapshot/] 14 failures
 * [TestErasureCodingExerciseAPIs|https://builds.apache.org/job/hadoop-trunk-win/469/testReport/org.apache.hadoop.hdfs/TestErasureCodingExerciseAPIs/] 13 failures
 * [TestQuorumJournalManager|https://builds.apache.org/job/hadoop-trunk-win/469/testReport/org.apache.hadoop.hdfs.qjournal.client/TestQuorumJournalManager/] 12 failures
 * [TestContainerLaunch|https://builds.apache.org/job/hadoop-trunk-win/469/testReport/org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher/TestContainerLaunch/] 11 failures
 * [TestFileOutputCommitter|https://builds.apache.org/job/hadoop-trunk-win/469/testReport/org.apache.hadoop.mapreduce.lib.output/TestFileOutputCommitter/] 10 failures
 * [TestReconstructStripedFile|https://builds.apache.org/job/hadoop-trunk-win/469/testReport/org.apache.hadoop.hdfs/TestReconstructStripedFile/] 10 failures

Fixing these, we should potentially reduce 149 failures.
There are a lot more, but we should prioritize these ones.","17/May/18 20:22;giovanni.fumarola;Thanks [~huanbang1993] and [~elgoiri] for taking care of those. Let's sync offline to fix the one in YARN side as well.","23/May/18 01:26;elgoiri;The number of unit tests failed in the last 6 builds are >5k.
The error seems to be with the native code.
One example [here|https://builds.apache.org/job/hadoop-trunk-win/475/testReport/].
{code}
java.lang.UnsatisfiedLinkError: org.apache.hadoop.io.nativeio.NativeIO$Windows.access0(Ljava/lang/String;I)Z
	at org.apache.hadoop.io.nativeio.NativeIO$Windows.access0(Native Method)
	at org.apache.hadoop.io.nativeio.NativeIO$Windows.access(NativeIO.java:640)
	at org.apache.hadoop.fs.FileUtil.canWrite(FileUtil.java:1220)
	at org.apache.hadoop.hdfs.server.common.Storage$StorageDirectory.analyzeStorage(Storage.java:667)
	at org.apache.hadoop.hdfs.server.common.Storage$StorageDirectory.analyzeStorage(Storage.java:620)
	at org.apache.hadoop.hdfs.server.namenode.FSImage.recoverStorageDirs(FSImage.java:371)
{code}
This is an issue that has been coming and going but seems like it's been there for a while.
Not sure the real reason.","23/May/18 18:51;elgoiri;[~aw], any insights on what's wrong with the daily Windows build?
We used to see the UnsatisfiedLinkError in around 30% of the builds but now is almost 100%.
I specially want to make sure we didn't break it with one of the fixes.","23/May/18 22:43;aw;My ASF volunteer time is almost exclusively for other projects. As a result, Hadoop builds are pretty much off my radar entirely.   Sorry.","24/May/18 16:37;elgoiri;{quote}My ASF volunteer time is almost exclusively for other projects. As a result, Hadoop builds are pretty much off my radar entirely. Sorry.
{quote}
Sure, I'll work with [~chris.douglas] on checking the build.
 Feel free to provide feedback in this thread too.

Funny, enough the daily Windows build worked [yesterday|https://builds.apache.org/job/hadoop-trunk-win/476/testReport/].
This includes a couple big fixes like HDFS-13586 which reduced the number of failed unit tests from 516 to 446.
Internally our errors in branch-2.9 on Windows are 239.
The evolution is as follows:

||Run||Date||Total||Skipped||Failed||Passed||
|[459|https://builds.apache.org/job/hadoop-trunk-win/459/testReport/]|2018/05/06|19386|1465|846|17075|
|[460|https://builds.apache.org/job/hadoop-trunk-win/460/testReport/]|2018/05/07|16906|1418|754|14734|
|[463|https://builds.apache.org/job/hadoop-trunk-win/463/testReport/]|2018/05/10|19252|1472|540|17240|
|[467|https://builds.apache.org/job/hadoop-trunk-win/467/testReport/]|2018/05/14|19317|1472|573|17272|
|[469|https://builds.apache.org/job/hadoop-trunk-win/469/testReport/]|2018/05/16|19326|1472|516|17388|
|[476|https://builds.apache.org/job/hadoop-trunk-win/476/testReport/]|2018/05/23|19355|1473|446|17436|

The unit tests with the most failures at this point are:
 * TestHDFSFileSystemContract 44 failures: issues and deleting paths, I'm guessing a failed unit test locks it
 * TestAuditLoggerWithCommands 40 failures: I think this must be line separator on Windows
 * TestRawLocalFileSystemContract 21 failures: related to the path
 * TestMetadataStore 18 failures","24/May/18 18:14;stevel@apache.org;So you are seeing 239 failures on branch-2, but Jenkins is  at 446?","24/May/18 18:55;elgoiri;bq. So you are seeing 239 failures on branch-2, but Jenkins is at 446?

239 for branch-2.9 on VSTS using Azure builders and 443 for trunk on Jenkins.
They are not fully comparable though; this was more like a reference.
We started with +700 on branch-2.9 and +800 for trunk.
Once we narrow this down a little more (<100 in VSTS) we can go over the differences.","29/May/18 16:28;elgoiri;A couple more builds:

||Run||Date||Total||Skipped||Failed||Passed||
|[459|https://builds.apache.org/job/hadoop-trunk-win/459/testReport/]|2018/05/06|19386|1465|846|17075|
|[460|https://builds.apache.org/job/hadoop-trunk-win/460/testReport/]|2018/05/07|16906|1418|754|14734|
|[463|https://builds.apache.org/job/hadoop-trunk-win/463/testReport/]|2018/05/10|19252|1472|540|17240|
|[467|https://builds.apache.org/job/hadoop-trunk-win/467/testReport/]|2018/05/14|19317|1472|573|17272|
|[469|https://builds.apache.org/job/hadoop-trunk-win/469/testReport/]|2018/05/16|19326|1472|516|17388|
|[476|https://builds.apache.org/job/hadoop-trunk-win/476/testReport/]|2018/05/23|19355|1473|446|17436|
|[479|https://builds.apache.org/job/hadoop-trunk-win/479/testReport/]|2018/05/26|19384|1473|375|17536|
|[481|https://builds.apache.org/job/hadoop-trunk-win/481/testReport/]|2018/05/23|19409|1472|405|17532|

Last week we resolved a couple JIRAs with a lot of failures in them so we reduced by more than 50.
From build #479 to #481 there was an increase in failed unit tests but I think it's because of flaky unit tests that we should eventually fix too.
We have been mostly focusing on HDFS so far and now we should try to target commons, YARN and MapReduce more.
For YARN there are a lot of tests that we are Linux specific and we are thinking to disable in YARN-8359.
","01/Jun/18 16:25;elgoiri;A couple more runs:


||Run||Date||Total||Skipped||Failed||Passed||
|[459|https://builds.apache.org/job/hadoop-trunk-win/459/testReport/]|2018/05/06|19386|1465|846|17075|
|[460|https://builds.apache.org/job/hadoop-trunk-win/460/testReport/]|2018/05/07|16906|1418|754|14734|
|[463|https://builds.apache.org/job/hadoop-trunk-win/463/testReport/]|2018/05/10|19252|1472|540|17240|
|[467|https://builds.apache.org/job/hadoop-trunk-win/467/testReport/]|2018/05/14|19317|1472|573|17272|
|[469|https://builds.apache.org/job/hadoop-trunk-win/469/testReport/]|2018/05/16|19326|1472|516|17388|
|[476|https://builds.apache.org/job/hadoop-trunk-win/476/testReport/]|2018/05/23|19355|1473|446|17436|
|[479|https://builds.apache.org/job/hadoop-trunk-win/479/testReport/]|2018/05/26|19384|1473|375|17536|
|[481|https://builds.apache.org/job/hadoop-trunk-win/481/testReport/]|2018/05/23|19409|1472|405|17532|
|[483|https://builds.apache.org/job/hadoop-trunk-win/483/testReport/]|2018/05/30|19390|1473|348|17569|
|[484|https://builds.apache.org/job/hadoop-trunk-win/484/testReport/]|2018/05/31|19390|1473|288|17629|

The one with 288 failures had HDFS-13632 and HDFS-13629 but I also think it was specially good, we may go up in the following days with flaky test.
Right now there are 86 failed HDFS tests and there's nothing specially big other than the ones for TestReconstructStripedFile (all of those could use randomized paths for the MiniDFSCluster).
There is also TestMetadataStore HDFS-13516 with a few.

I think at this point we can cleanup YARN and MapReduce failures a lot.
We are still pending YARN-8359 which should cut a bunch.","05/Jun/18 15:26;stevel@apache.org;the graph is going in the right direction. 

One thing which would be good would be for some official ASF windows libs to ship. I do the set on [github|https://github.com/steveloughran/winutils], but that's not quite the same as the ASF blessing. Even without all the tests passing, we can at least include the native binaries as signed artifacts","06/Jun/18 17:14;elgoiri;bq. One thing which would be good would be for some official ASF windows libs to ship. I do the set on github, but that's not quite the same as the ASF blessing. Even without all the tests passing, we can at least include the native binaries as signed artifacts

I guess that now that we switched the way winutils are built, we should be able to build them from Linux, right?
In that case, it should be fairly easy for the release manager to add the windows native libs.

For the progress, we cut a bunch and we are pretty much caught up (242 in trunk) with our internal branch-2.9 runs (~230 in our internal run).
The status right now is:

||Run||Date||Total||Skipped||Failed||Passed||
|[459|https://builds.apache.org/job/hadoop-trunk-win/459/testReport/]|2018/05/06|19386|1465|846|17075|
|[460|https://builds.apache.org/job/hadoop-trunk-win/460/testReport/]|2018/05/07|16906|1418|754|14734|
|[463|https://builds.apache.org/job/hadoop-trunk-win/463/testReport/]|2018/05/10|19252|1472|540|17240|
|[467|https://builds.apache.org/job/hadoop-trunk-win/467/testReport/]|2018/05/14|19317|1472|573|17272|
|[469|https://builds.apache.org/job/hadoop-trunk-win/469/testReport/]|2018/05/16|19326|1472|516|17388|
|[476|https://builds.apache.org/job/hadoop-trunk-win/476/testReport/]|2018/05/23|19355|1473|446|17436|
|[479|https://builds.apache.org/job/hadoop-trunk-win/479/testReport/]|2018/05/26|19384|1473|375|17536|
|[481|https://builds.apache.org/job/hadoop-trunk-win/481/testReport/]|2018/05/23|19409|1472|405|17532|
|[483|https://builds.apache.org/job/hadoop-trunk-win/483/testReport/]|2018/05/30|19390|1473|348|17569|
|[484|https://builds.apache.org/job/hadoop-trunk-win/484/testReport/]|2018/05/31|19390|1473|288|17629|
|[485|https://builds.apache.org/job/hadoop-trunk-win/484/testReport/]|2018/06/01|19173|1473|270|17430|
|[489|https://builds.apache.org/job/hadoop-trunk-win/489/testReport/]|2018/06/05|19394|1482|242|17670|

In HDFS we have fixed a bunch by using the randomized path per test case but we haven't really fixed the root causes.
There is still a bunch of timeouts which we think are because of poll0 being very slow at the beginning.
For MapReduce there are a bunch that should be fixable and we can cut the number substantially.
In YARN, there a lot of failures but the fixes are not trivial (we still have the Linux tests ignore pending from YARN-8359).","12/Jun/18 16:44;elgoiri;I committed YARN-8359 and we cut the failures a bunch.
There are also a couple smaller JIRAs that went in.

||Run||Date||Total||Skipped||Failed||Passed||
|[459|https://builds.apache.org/job/hadoop-trunk-win/459/testReport/]|2018/05/06|19386|1465|846|17075|
|[460|https://builds.apache.org/job/hadoop-trunk-win/460/testReport/]|2018/05/07|16906|1418|754|14734|
|[463|https://builds.apache.org/job/hadoop-trunk-win/463/testReport/]|2018/05/10|19252|1472|540|17240|
|[467|https://builds.apache.org/job/hadoop-trunk-win/467/testReport/]|2018/05/14|19317|1472|573|17272|
|[469|https://builds.apache.org/job/hadoop-trunk-win/469/testReport/]|2018/05/16|19326|1472|516|17388|
|[476|https://builds.apache.org/job/hadoop-trunk-win/476/testReport/]|2018/05/23|19355|1473|446|17436|
|[479|https://builds.apache.org/job/hadoop-trunk-win/479/testReport/]|2018/05/26|19384|1473|375|17536|
|[481|https://builds.apache.org/job/hadoop-trunk-win/481/testReport/]|2018/05/23|19409|1472|405|17532|
|[483|https://builds.apache.org/job/hadoop-trunk-win/483/testReport/]|2018/05/30|19390|1473|348|17569|
|[484|https://builds.apache.org/job/hadoop-trunk-win/484/testReport/]|2018/05/31|19390|1473|288|17629|
|[485|https://builds.apache.org/job/hadoop-trunk-win/484/testReport/]|2018/06/01|19173|1473|270|17430|
|[489|https://builds.apache.org/job/hadoop-trunk-win/489/testReport/]|2018/06/05|19394|1482|242|17670|
|[495|https://builds.apache.org/job/hadoop-trunk-win/495/testReport/]|2018/06/11|19332|1482|213|17637|

Right now we are at 213 failures but I've seen it as small as 202 in build [494|https://builds.apache.org/job/hadoop-trunk-win/494/testReport/].
Today we should be committing MAPREDUCE-7108 which would take us <200.
","25/Jun/18 17:01;elgoiri;Not too many fixes recently but we are under 200 already:

||Run||Date||Total||Skipped||Failed||Passed||
|[459|https://builds.apache.org/job/hadoop-trunk-win/459/testReport/]|2018/05/06|19386|1465|846|17075|
|[460|https://builds.apache.org/job/hadoop-trunk-win/460/testReport/]|2018/05/07|16906|1418|754|14734|
|[463|https://builds.apache.org/job/hadoop-trunk-win/463/testReport/]|2018/05/10|19252|1472|540|17240|
|[467|https://builds.apache.org/job/hadoop-trunk-win/467/testReport/]|2018/05/14|19317|1472|573|17272|
|[469|https://builds.apache.org/job/hadoop-trunk-win/469/testReport/]|2018/05/16|19326|1472|516|17388|
|[476|https://builds.apache.org/job/hadoop-trunk-win/476/testReport/]|2018/05/23|19355|1473|446|17436|
|[479|https://builds.apache.org/job/hadoop-trunk-win/479/testReport/]|2018/05/26|19384|1473|375|17536|
|[481|https://builds.apache.org/job/hadoop-trunk-win/481/testReport/]|2018/05/23|19409|1472|405|17532|
|[483|https://builds.apache.org/job/hadoop-trunk-win/483/testReport/]|2018/05/30|19390|1473|348|17569|
|[484|https://builds.apache.org/job/hadoop-trunk-win/484/testReport/]|2018/05/31|19390|1473|288|17629|
|[485|https://builds.apache.org/job/hadoop-trunk-win/484/testReport/]|2018/06/01|19173|1473|270|17430|
|[489|https://builds.apache.org/job/hadoop-trunk-win/489/testReport/]|2018/06/05|19394|1482|242|17670|
|[495|https://builds.apache.org/job/hadoop-trunk-win/495/testReport/]|2018/06/11|19332|1482|213|17637|
|[508|https://builds.apache.org/job/hadoop-trunk-win/508/testReport/]|2018/06/24|19247|1506|189|17552|
","12/Aug/18 14:43;elgoiri;Stopped for a while working on this but I checked today and we have potential to easily fix around 50 tests.
The current progress is:
||Run||Date||Total||Skipped||Failed||Passed||
|[459|https://builds.apache.org/job/hadoop-trunk-win/459/testReport/]|2018/05/06|19386|1465|846|17075|
|[460|https://builds.apache.org/job/hadoop-trunk-win/460/testReport/]|2018/05/07|16906|1418|754|14734|
|[463|https://builds.apache.org/job/hadoop-trunk-win/463/testReport/]|2018/05/10|19252|1472|540|17240|
|[467|https://builds.apache.org/job/hadoop-trunk-win/467/testReport/]|2018/05/14|19317|1472|573|17272|
|[469|https://builds.apache.org/job/hadoop-trunk-win/469/testReport/]|2018/05/16|19326|1472|516|17388|
|[476|https://builds.apache.org/job/hadoop-trunk-win/476/testReport/]|2018/05/23|19355|1473|446|17436|
|[479|https://builds.apache.org/job/hadoop-trunk-win/479/testReport/]|2018/05/26|19384|1473|375|17536|
|[481|https://builds.apache.org/job/hadoop-trunk-win/481/testReport/]|2018/05/23|19409|1472|405|17532|
|[483|https://builds.apache.org/job/hadoop-trunk-win/483/testReport/]|2018/05/30|19390|1473|348|17569|
|[484|https://builds.apache.org/job/hadoop-trunk-win/484/testReport/]|2018/05/31|19390|1473|288|17629|
|[485|https://builds.apache.org/job/hadoop-trunk-win/484/testReport/]|2018/06/01|19173|1473|270|17430|
|[489|https://builds.apache.org/job/hadoop-trunk-win/489/testReport/]|2018/06/05|19394|1482|242|17670|
|[495|https://builds.apache.org/job/hadoop-trunk-win/495/testReport/]|2018/06/11|19332|1482|213|17637|
|[508|https://builds.apache.org/job/hadoop-trunk-win/508/testReport/]|2018/06/24|19247|1506|189|17552|
|[548|https://builds.apache.org/job/hadoop-trunk-win/548/testReport/]|2018/08/04|19508|1500|186|17822|

The ones we could target are:
* [TestServiceManager|https://builds.apache.org/job/hadoop-trunk-win/548/testReport/org.apache.hadoop.yarn.service/TestServiceManager/]
* [TestYarnNativeServices|https://builds.apache.org/job/hadoop-trunk-win/548/testReport/org.apache.hadoop.yarn.service/TestYarnNativeServices/]
* [TestServiceCLI|https://builds.apache.org/job/hadoop-trunk-win/548/testReport/org.apache.hadoop.yarn.service.client/TestServiceCLI/]
* [TestContainerManager|https://builds.apache.org/job/hadoop-trunk-win/548/testReport/org.apache.hadoop.yarn.server.nodemanager.containermanager/TestContainerManager/]
* [TestContainerLaunch|https://builds.apache.org/job/hadoop-trunk-win/548/testReport/org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher/TestContainerLaunch/]","12/Aug/18 14:54;elgoiri;One that should be easy to fix is [TestDatanodeStartupFixesLegacyStorageIDs|https://builds.apache.org/job/hadoop-trunk-win/548/testReport/org.apache.hadoop.hdfs/TestDatanodeStartupFixesLegacyStorageIDs/].
It looks like a path issue from the log.
[~huanbang1993], [~surmountian], can any of you take a look?",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Add tests for various org.apache.hadoop.util classes,HADOOP-15520,13164795,Test,Resolved,HADOOP,Hadoop Common,software,omalley,Hadoop Common is the common library for Apache Hadoop.,http://hadoop.apache.org/,Minor,Fixed,arashn,arashn,arashn,07/Jun/18 21:25,09/Jun/18 14:56,12/Jan/21 11:55,09/Jun/18 14:35,3.2.0,,,,3.2.0,,,,,,test,util,,,0,,,"Created new JUnit test classes for the following classes:
 * org.apache.hadoop.util.CloseableReferenceCount
 * org.apache.hadoop.util.IntrusiveCollection
 * org.apache.hadoop.util.LimitInputStream
 * org.apache.hadoop.util.UTF8ByteArrayUtils

Added new JUnit test cases to the following test classes:
 * org.apache.hadoop.util.TestShell
 * org.apache.hadoop.util.TestStringUtils","CentOS 7 - amd64

Oracle JDK 8u172

Maven 3.5.3

hadoop trunk",arashn,hudson,stevel@apache.org,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"08/Jun/18 18:02;arashn;HADOOP-15520.003.patch;https://issues.apache.org/jira/secure/attachment/12927080/HADOOP-15520.003.patch",,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,2018-06-07 23:49:00.072,,,false,,,,,,,,,,,,,,,,,9223372036854775807,,,,,Sat Jun 09 14:56:56 UTC 2018,,,,,,,"0|i3umzb:",9223372036854775807,,,,,,,,,,,,,3.2.0,,,,,,,,,,"07/Jun/18 23:49;genericqa;| (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 14s{color} | {color:blue} Docker mode activated. {color} |
|| || || || {color:brown} Prechecks {color} ||
| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |
| {color:green}+1{color} | {color:green} test4tests {color} | {color:green}  0m  0s{color} | {color:green} The patch appears to include 6 new or modified test files. {color} |
|| || || || {color:brown} trunk Compile Tests {color} ||
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 26m  3s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 28m  0s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 21s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  1m  8s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 12m 26s{color} | {color:green} branch has no errors when building and testing our client artifacts. {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  1m 31s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 56s{color} | {color:green} trunk passed {color} |
|| || || || {color:brown} Patch Compile Tests {color} ||
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  0m 46s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 26m 34s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javac {color} | {color:green} 26m 34s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 21s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  1m  6s{color} | {color:green} the patch passed {color} |
| {color:red}-1{color} | {color:red} whitespace {color} | {color:red}  0m  0s{color} | {color:red} The patch has 34 line(s) that end in whitespace. Use git apply --whitespace=fix <<patch_file>>. Refer https://git-scm.com/docs/git-apply {color} |
| {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 10m 50s{color} | {color:green} patch has no errors when building and testing our client artifacts. {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  1m 40s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 56s{color} | {color:green} the patch passed {color} |
|| || || || {color:brown} Other Tests {color} ||
| {color:green}+1{color} | {color:green} unit {color} | {color:green}  8m 20s{color} | {color:green} hadoop-common in the patch passed. {color} |
| {color:red}-1{color} | {color:red} asflicense {color} | {color:red}  0m 37s{color} | {color:red} The patch generated 4 ASF License warnings. {color} |
| {color:black}{color} | {color:black} {color} | {color:black}122m  6s{color} | {color:black} {color} |
\\
\\
|| Subsystem || Report/Notes ||
| Docker | Client=17.05.0-ce Server=17.05.0-ce Image:yetus/hadoop:abb62dd |
| JIRA Issue | HADOOP-15520 |
| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12926975/HADOOP-15520.001.patch |
| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  shadedclient  findbugs  checkstyle  |
| uname | Linux 023bb3a832af 3.13.0-139-generic #188-Ubuntu SMP Tue Jan 9 14:43:09 UTC 2018 x86_64 x86_64 x86_64 GNU/Linux |
| Build tool | maven |
| Personality | /testptch/patchprocess/precommit/personality/provided.sh |
| git revision | trunk / ba303b1 |
| maven | version: Apache Maven 3.3.9 |
| Default Java | 1.8.0_171 |
| findbugs | v3.1.0-RC1 |
| whitespace | https://builds.apache.org/job/PreCommit-HADOOP-Build/14739/artifact/out/whitespace-eol.txt |
|  Test Results | https://builds.apache.org/job/PreCommit-HADOOP-Build/14739/testReport/ |
| asflicense | https://builds.apache.org/job/PreCommit-HADOOP-Build/14739/artifact/out/patch-asflicense-problems.txt |
| Max. process+thread count | 1521 (vs. ulimit of 10000) |
| modules | C: hadoop-common-project/hadoop-common U: hadoop-common-project/hadoop-common |
| Console output | https://builds.apache.org/job/PreCommit-HADOOP-Build/14739/console |
| Powered by | Apache Yetus 0.8.0-SNAPSHOT   http://yetus.apache.org |


This message was automatically generated.

","08/Jun/18 03:10;genericqa;| (/) *{color:green}+1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 22s{color} | {color:blue} Docker mode activated. {color} |
|| || || || {color:brown} Prechecks {color} ||
| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |
| {color:green}+1{color} | {color:green} test4tests {color} | {color:green}  0m  0s{color} | {color:green} The patch appears to include 6 new or modified test files. {color} |
|| || || || {color:brown} trunk Compile Tests {color} ||
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 27m 37s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 29m 34s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 20s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  1m 26s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 12m 44s{color} | {color:green} branch has no errors when building and testing our client artifacts. {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  1m 34s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 56s{color} | {color:green} trunk passed {color} |
|| || || || {color:brown} Patch Compile Tests {color} ||
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  0m 49s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 28m 43s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javac {color} | {color:green} 28m 43s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 19s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  1m 22s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} |
| {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 10m 49s{color} | {color:green} patch has no errors when building and testing our client artifacts. {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  1m 41s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 56s{color} | {color:green} the patch passed {color} |
|| || || || {color:brown} Other Tests {color} ||
| {color:green}+1{color} | {color:green} unit {color} | {color:green}  9m 39s{color} | {color:green} hadoop-common in the patch passed. {color} |
| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 36s{color} | {color:green} The patch does not generate ASF License warnings. {color} |
| {color:black}{color} | {color:black} {color} | {color:black}129m 16s{color} | {color:black} {color} |
\\
\\
|| Subsystem || Report/Notes ||
| Docker | Client=17.05.0-ce Server=17.05.0-ce Image:yetus/hadoop:abb62dd |
| JIRA Issue | HADOOP-15520 |
| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12926996/HADOOP-15520.002.patch |
| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  shadedclient  findbugs  checkstyle  |
| uname | Linux 9b4b7ad23b3e 3.13.0-137-generic #186-Ubuntu SMP Mon Dec 4 19:09:19 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux |
| Build tool | maven |
| Personality | /testptch/patchprocess/precommit/personality/provided.sh |
| git revision | trunk / 3b88fe2 |
| maven | version: Apache Maven 3.3.9 |
| Default Java | 1.8.0_171 |
| findbugs | v3.1.0-RC1 |
|  Test Results | https://builds.apache.org/job/PreCommit-HADOOP-Build/14741/testReport/ |
| Max. process+thread count | 1357 (vs. ulimit of 10000) |
| modules | C: hadoop-common-project/hadoop-common U: hadoop-common-project/hadoop-common |
| Console output | https://builds.apache.org/job/PreCommit-HADOOP-Build/14741/console |
| Powered by | Apache Yetus 0.8.0-SNAPSHOT   http://yetus.apache.org |


This message was automatically generated.

","08/Jun/18 13:01;stevel@apache.org;thanks for this

* I like the detail on assert failures, always good.
* We have a 80 chars wide line width rule though; you are going to have to split down things. Sorry.
* in \{{TestLimitInputStream}}, inner class \{{TestInputStream}} should have a different name (no Test* prefix), make static.
* And for strictness, use try-with-resources to trigger closing of the streams, even on an assert failure
* If you want preformatted text in the javadocs, you'll need to use <pre> sections, or <ol><li> clauses.
* There are some requirements about test timeouts (mandatory) and preferences (naming threads). If your tests extend org.apache.hadoop.test.HadoopTestBase then you get these.

ordering of imports is trouble: its not strictly enforced the way spark does, but we have some preferences
and like them to be followed: imports are often where merge conflict arises, so once in we can't easily reorder
them (example: TestShell).

the order I have in my IDE is

{code}
javax.*
java.*
\n
(other())
\n
org.apache.*
\
all static imports, alpha sorted.
{code}

(+static imports can use .* if they want)

Before
{code}
import static org.junit.Assert.assertEquals;
import static org.junit.Assert.assertFalse;
import static org.junit.Assert.assertTrue;

import java.util.HashMap;
import java.util.Iterator;
import java.util.Map;

import org.apache.hadoop.util.IntrusiveCollection.Element;
import org.junit.Test;
{code}

After

{code}
import java.util.HashMap;
import java.util.Iterator;
import java.util.Map;

import org.junit.Test;

import org.apache.hadoop.util.IntrusiveCollection.Element;

import static org.junit.Assert.assertEquals;
import static org.junit.Assert.assertFalse;
import static org.junit.Assert.assertTrue;
{code}

Other than those details, the tests themselves look good. Revised title & component to reflect area of coverage","08/Jun/18 18:03;arashn;Thank you for the feedback. I have addressed all of your suggestions, and made sure that the new tests still pass. I have attached the updated patch.","08/Jun/18 20:12;genericqa;| (/) *{color:green}+1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 14s{color} | {color:blue} Docker mode activated. {color} |
|| || || || {color:brown} Prechecks {color} ||
| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |
| {color:green}+1{color} | {color:green} test4tests {color} | {color:green}  0m  0s{color} | {color:green} The patch appears to include 6 new or modified test files. {color} |
|| || || || {color:brown} trunk Compile Tests {color} ||
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 26m 31s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 27m 47s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 21s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  1m 10s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 12m 19s{color} | {color:green} branch has no errors when building and testing our client artifacts. {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  1m 32s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 58s{color} | {color:green} trunk passed {color} |
|| || || || {color:brown} Patch Compile Tests {color} ||
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  0m 45s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 26m 28s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javac {color} | {color:green} 26m 28s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 21s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  1m  5s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} |
| {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 11m  1s{color} | {color:green} patch has no errors when building and testing our client artifacts. {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  1m 39s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 55s{color} | {color:green} the patch passed {color} |
|| || || || {color:brown} Other Tests {color} ||
| {color:green}+1{color} | {color:green} unit {color} | {color:green}  8m 17s{color} | {color:green} hadoop-common in the patch passed. {color} |
| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 38s{color} | {color:green} The patch does not generate ASF License warnings. {color} |
| {color:black}{color} | {color:black} {color} | {color:black}122m 13s{color} | {color:black} {color} |
\\
\\
|| Subsystem || Report/Notes ||
| Docker | Client=17.05.0-ce Server=17.05.0-ce Image:yetus/hadoop:abb62dd |
| JIRA Issue | HADOOP-15520 |
| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12927080/HADOOP-15520.003.patch |
| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  shadedclient  findbugs  checkstyle  |
| uname | Linux 97eefd97f07c 3.13.0-139-generic #188-Ubuntu SMP Tue Jan 9 14:43:09 UTC 2018 x86_64 x86_64 x86_64 GNU/Linux |
| Build tool | maven |
| Personality | /testptch/patchprocess/precommit/personality/provided.sh |
| git revision | trunk / a127244 |
| maven | version: Apache Maven 3.3.9 |
| Default Java | 1.8.0_171 |
| findbugs | v3.1.0-RC1 |
|  Test Results | https://builds.apache.org/job/PreCommit-HADOOP-Build/14747/testReport/ |
| Max. process+thread count | 1504 (vs. ulimit of 10000) |
| modules | C: hadoop-common-project/hadoop-common U: hadoop-common-project/hadoop-common |
| Console output | https://builds.apache.org/job/PreCommit-HADOOP-Build/14747/console |
| Powered by | Apache Yetus 0.8.0-SNAPSHOT   http://yetus.apache.org |


This message was automatically generated.

","09/Jun/18 14:35;stevel@apache.org;+1, committed

Thanks for this. 

BTW, if you are submitting more patches, don't worry about deleting the old one...yetus knows to only delete the later one, and it lets us see how things evolved. Not that import here, but significant in large bits of work. thanks","09/Jun/18 14:56;hudson;SUCCESS: Integrated in Jenkins build Hadoop-trunk-Commit #14395 (See [https://builds.apache.org/job/Hadoop-trunk-Commit/14395/])
HADOOP-15520. Add tests for various org.apache.hadoop.util classes. (stevel: rev ef0118b91e384b9a6d96c2ae64480d9acf5aa6fb)
* (add) hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/util/TestLimitInputStream.java
* (edit) hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/util/TestShell.java
* (edit) hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/util/TestStringUtils.java
* (add) hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/util/TestIntrusiveCollection.java
* (add) hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/util/TestCloseableReferenceCount.java
* (add) hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/util/TestUTF8ByteArrayUtils.java
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
TestFsShellList#testList fails on Windows,HADOOP-15496,13162269,Test,Resolved,HADOOP,Hadoop Common,software,omalley,Hadoop Common is the common library for Apache Hadoop.,http://hadoop.apache.org/,Minor,Duplicate,huanbang1993,huanbang1993,huanbang1993,27/May/18 03:12,05/Jun/18 15:22,12/Jan/21 11:55,29/May/18 17:27,,,,,,,,,,,,,,,0,Windows,,"[TestFsShellList#testList|https://builds.apache.org/job/hadoop-trunk-win/478/testReport/org.apache.hadoop.fs/TestFsShellList/testList/] fails on Windows because Windows filename does not accept ""\"", while in the test

{code:java}
createFile(new Path(testRootDir, ""abc\bd\tef""));
...
createFile(new Path(testRootDir, ""qq\r123""));
{code}
",,elgoiri,huanbang1993,stevel@apache.org,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,HADOOP-14199,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"27/May/18 03:16;huanbang1993;HADOOP-15496.000.patch;https://issues.apache.org/jira/secure/attachment/12925274/HADOOP-15496.000.patch",,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,2018-05-27 05:23:39.917,,,false,,,,,,,,,,,,,,,,,9223372036854775807,,,,,Tue Jun 05 15:22:13 UTC 2018,,,,,,,"0|i3u7ev:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,"27/May/18 03:17;huanbang1993; [^HADOOP-15496.000.patch] attempts to not include ""\"" for running on Windows.","27/May/18 05:23;genericqa;| (/) *{color:green}+1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 17s{color} | {color:blue} Docker mode activated. {color} |
|| || || || {color:brown} Prechecks {color} ||
| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |
| {color:green}+1{color} | {color:green} test4tests {color} | {color:green}  0m  0s{color} | {color:green} The patch appears to include 1 new or modified test files. {color} |
|| || || || {color:brown} trunk Compile Tests {color} ||
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 25m 15s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 27m 45s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 51s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  1m 10s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 12m 20s{color} | {color:green} branch has no errors when building and testing our client artifacts. {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  1m 32s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 56s{color} | {color:green} trunk passed {color} |
|| || || || {color:brown} Patch Compile Tests {color} ||
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  0m 46s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 28m  3s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javac {color} | {color:green} 28m  3s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 52s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  1m 14s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} |
| {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 10m  7s{color} | {color:green} patch has no errors when building and testing our client artifacts. {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  1m 43s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 56s{color} | {color:green} the patch passed {color} |
|| || || || {color:brown} Other Tests {color} ||
| {color:green}+1{color} | {color:green} unit {color} | {color:green}  8m 55s{color} | {color:green} hadoop-common in the patch passed. {color} |
| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 38s{color} | {color:green} The patch does not generate ASF License warnings. {color} |
| {color:black}{color} | {color:black} {color} | {color:black}123m  0s{color} | {color:black} {color} |
\\
\\
|| Subsystem || Report/Notes ||
| Docker | Client=17.05.0-ce Server=17.05.0-ce Image:yetus/hadoop:abb62dd |
| JIRA Issue | HADOOP-15496 |
| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12925274/HADOOP-15496.000.patch |
| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  shadedclient  findbugs  checkstyle  |
| uname | Linux 0e2ca09b69f4 3.13.0-139-generic #188-Ubuntu SMP Tue Jan 9 14:43:09 UTC 2018 x86_64 x86_64 x86_64 GNU/Linux |
| Build tool | maven |
| Personality | /testptch/patchprocess/precommit/personality/provided.sh |
| git revision | trunk / 0cf6e87 |
| maven | version: Apache Maven 3.3.9 |
| Default Java | 1.8.0_162 |
| findbugs | v3.1.0-RC1 |
|  Test Results | https://builds.apache.org/job/PreCommit-HADOOP-Build/14697/testReport/ |
| Max. process+thread count | 1467 (vs. ulimit of 10000) |
| modules | C: hadoop-common-project/hadoop-common U: hadoop-common-project/hadoop-common |
| Console output | https://builds.apache.org/job/PreCommit-HADOOP-Build/14697/console |
| Powered by | Apache Yetus 0.8.0-SNAPSHOT   http://yetus.apache.org |


This message was automatically generated.

","05/Jun/18 15:22;stevel@apache.org;closed as a duplicate; attached patch to existing JIRA...we like to assign to the older ones as they have more watchers. 

patch makes sense though: ""\"" isn't a legal entry in a windows path, and *every* FS is allowed to have its own set of invalid characters",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"TestDoAsEffectiveUser#testRealUserSetup,TestDoAsEffectiveUser#testRealUserAuthorizationSuccess time out on Windows",HADOOP-15467,13159243,Test,Resolved,HADOOP,Hadoop Common,software,omalley,Hadoop Common is the common library for Apache Hadoop.,http://hadoop.apache.org/,Minor,Won't Fix,huanbang1993,huanbang1993,huanbang1993,14/May/18 23:52,26/May/18 22:25,12/Jan/21 11:55,17/May/18 00:18,,,,,,,,,,,,,,,0,Windows,,"{color:#d04437}[INFO] Running org.apache.hadoop.security.TestDoAsEffectiveUser{color}
{color:#d04437}[ERROR] Tests run: 2, Failures: 0, Errors: 2, Skipped: 0, Time elapsed: 8.307 s <<< FAILURE! - in org.apache.hadoop.security.TestDoAsEffectiveUser{color}
{color:#d04437}[ERROR] testRealUserSetup(org.apache.hadoop.security.TestDoAsEffectiveUser) Time elapsed: 4.107 s <<< ERROR!{color}
{color:#d04437}java.lang.Exception: test timed out after 4000 milliseconds{color}
{color:#d04437} at java.net.Inet4AddressImpl.getHostByAddr(Native Method){color}
{color:#d04437} at java.net.InetAddress$2.getHostByAddr(InetAddress.java:932){color}
{color:#d04437} at java.net.InetAddress.getHostFromNameService(InetAddress.java:617){color}
{color:#d04437} at java.net.InetAddress.getCanonicalHostName(InetAddress.java:588){color}
{color:#d04437} at org.apache.hadoop.security.TestDoAsEffectiveUser.configureSuperUserIPAddresses(TestDoAsEffectiveUser.java:103){color}
{color:#d04437} at org.apache.hadoop.security.TestDoAsEffectiveUser.testRealUserSetup(TestDoAsEffectiveUser.java:188){color}
{color:#d04437} at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method){color}
{color:#d04437} at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62){color}
{color:#d04437} at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43){color}
{color:#d04437} at java.lang.reflect.Method.invoke(Method.java:498){color}
{color:#d04437} at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47){color}
{color:#d04437} at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12){color}
{color:#d04437} at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44){color}
{color:#d04437} at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17){color}
{color:#d04437} at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74){color}

{color:#d04437}[ERROR] testRealUserAuthorizationSuccess(org.apache.hadoop.security.TestDoAsEffectiveUser) Time elapsed: 4.002 s <<< ERROR!{color}
{color:#d04437}java.lang.Exception: test timed out after 4000 milliseconds{color}
{color:#d04437} at java.net.Inet4AddressImpl.getHostByAddr(Native Method){color}
{color:#d04437} at java.net.InetAddress$2.getHostByAddr(InetAddress.java:932){color}
{color:#d04437} at java.net.InetAddress.getHostFromNameService(InetAddress.java:617){color}
{color:#d04437} at java.net.InetAddress.getCanonicalHostName(InetAddress.java:588){color}
{color:#d04437} at org.apache.hadoop.security.TestDoAsEffectiveUser.configureSuperUserIPAddresses(TestDoAsEffectiveUser.java:103){color}
{color:#d04437} at org.apache.hadoop.security.TestDoAsEffectiveUser.testRealUserAuthorizationSuccess(TestDoAsEffectiveUser.java:218){color}
{color:#d04437} at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method){color}
{color:#d04437} at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62){color}
{color:#d04437} at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43){color}
{color:#d04437} at java.lang.reflect.Method.invoke(Method.java:498){color}
{color:#d04437} at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47){color}
{color:#d04437} at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12){color}
{color:#d04437} at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44){color}
{color:#d04437} at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17){color}
{color:#d04437} at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74){color}

{color:#d04437}[INFO]{color}
{color:#d04437}[INFO] Results:{color}
{color:#d04437}[INFO]{color}
{color:#d04437}[ERROR] Errors:{color}
{color:#d04437}[ERROR] TestDoAsEffectiveUser.testRealUserAuthorizationSuccess:218->configureSuperUserIPAddresses:103 ╗{color}
{color:#d04437}[ERROR] TestDoAsEffectiveUser.testRealUserSetup:188->configureSuperUserIPAddresses:103 ╗{color}
{color:#d04437}[INFO]{color}
{color:#d04437}[ERROR] Tests run: 2, Failures: 0, Errors: 2, Skipped: 0{color}",,elgoiri,huanbang1993,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"14/May/18 23:56;huanbang1993;HDFS-13549.000.patch;https://issues.apache.org/jira/secure/attachment/12923367/HDFS-13549.000.patch",,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,2018-05-15 02:21:17.557,,,false,,,,,,,,,,,,,,,,,9223372036854775807,,,,,Thu May 17 00:18:10 UTC 2018,,,,,,,"0|i3tp6f:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,"14/May/18 23:58;huanbang1993;The timeout tests sometimes take more than 10 seconds to finish on Windows.

[^HDFS-13549.000.patch] applies to trunk and branch-2.

After the patch:

{color:#14892c}[INFO] Running org.apache.hadoop.security.TestDoAsEffectiveUser{color}
{color:#14892c}[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 19.111 s - in org.apache.hadoop.security.TestDoAsEffectiveUser{color}
{color:#14892c}[INFO]{color}
{color:#14892c}[INFO] Results:{color}
{color:#14892c}[INFO]{color}
{color:#14892c}[INFO] Tests run: 2, Failures: 0, Errors: 0, Skipped: 0{color}","15/May/18 02:21;genericqa;| (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 17s{color} | {color:blue} Docker mode activated. {color} |
|| || || || {color:brown} Prechecks {color} ||
| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |
| {color:green}+1{color} | {color:green} test4tests {color} | {color:green}  0m  0s{color} | {color:green} The patch appears to include 1 new or modified test files. {color} |
|| || || || {color:brown} trunk Compile Tests {color} ||
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 26m 40s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 29m 25s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 51s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  1m 18s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 12m 36s{color} | {color:green} branch has no errors when building and testing our client artifacts. {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  1m 41s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 59s{color} | {color:green} trunk passed {color} |
|| || || || {color:brown} Patch Compile Tests {color} ||
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  0m 48s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 30m 27s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javac {color} | {color:green} 30m 27s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 58s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  1m 26s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} |
| {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 10m 55s{color} | {color:green} patch has no errors when building and testing our client artifacts. {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  1m 57s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  1m  1s{color} | {color:green} the patch passed {color} |
|| || || || {color:brown} Other Tests {color} ||
| {color:red}-1{color} | {color:red} unit {color} | {color:red}  8m 52s{color} | {color:red} hadoop-common in the patch failed. {color} |
| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 40s{color} | {color:green} The patch does not generate ASF License warnings. {color} |
| {color:black}{color} | {color:black} {color} | {color:black}130m 30s{color} | {color:black} {color} |
\\
\\
|| Reason || Tests ||
| Failed junit tests | hadoop.ha.TestZKFailoverController |
\\
\\
|| Subsystem || Report/Notes ||
| Docker | Client=17.05.0-ce Server=17.05.0-ce Image:yetus/hadoop:abb62dd |
| JIRA Issue | HDFS-13549 |
| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12923367/HDFS-13549.000.patch |
| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  shadedclient  findbugs  checkstyle  |
| uname | Linux 2623af9922bc 3.13.0-139-generic #188-Ubuntu SMP Tue Jan 9 14:43:09 UTC 2018 x86_64 x86_64 x86_64 GNU/Linux |
| Build tool | maven |
| Personality | /testptch/patchprocess/precommit/personality/provided.sh |
| git revision | trunk / 2d00a0c |
| maven | version: Apache Maven 3.3.9 |
| Default Java | 1.8.0_162 |
| findbugs | v3.1.0-RC1 |
| unit | https://builds.apache.org/job/PreCommit-HDFS-Build/24195/artifact/out/patch-unit-hadoop-common-project_hadoop-common.txt |
|  Test Results | https://builds.apache.org/job/PreCommit-HDFS-Build/24195/testReport/ |
| Max. process+thread count | 1326 (vs. ulimit of 10000) |
| modules | C: hadoop-common-project/hadoop-common U: hadoop-common-project/hadoop-common |
| Console output | https://builds.apache.org/job/PreCommit-HDFS-Build/24195/console |
| Powered by | Apache Yetus 0.8.0-SNAPSHOT   http://yetus.apache.org |


This message was automatically generated.

","15/May/18 02:45;genericqa;| (/) *{color:green}+1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 17s{color} | {color:blue} Docker mode activated. {color} |
|| || || || {color:brown} Prechecks {color} ||
| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  1s{color} | {color:green} The patch does not contain any @author tags. {color} |
| {color:green}+1{color} | {color:green} test4tests {color} | {color:green}  0m  0s{color} | {color:green} The patch appears to include 1 new or modified test files. {color} |
|| || || || {color:brown} trunk Compile Tests {color} ||
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 25m 45s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 29m  6s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 55s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  1m 16s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 12m 21s{color} | {color:green} branch has no errors when building and testing our client artifacts. {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  1m 38s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 58s{color} | {color:green} trunk passed {color} |
|| || || || {color:brown} Patch Compile Tests {color} ||
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  0m 48s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 28m  2s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javac {color} | {color:green} 28m  2s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 50s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  1m 10s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} |
| {color:green}+1{color} | {color:green} shadedclient {color} | {color:green} 10m 23s{color} | {color:green} patch has no errors when building and testing our client artifacts. {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  1m 43s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 57s{color} | {color:green} the patch passed {color} |
|| || || || {color:brown} Other Tests {color} ||
| {color:green}+1{color} | {color:green} unit {color} | {color:green}  8m 23s{color} | {color:green} hadoop-common in the patch passed. {color} |
| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 38s{color} | {color:green} The patch does not generate ASF License warnings. {color} |
| {color:black}{color} | {color:black} {color} | {color:black}124m 40s{color} | {color:black} {color} |
\\
\\
|| Subsystem || Report/Notes ||
| Docker | Client=17.05.0-ce Server=17.05.0-ce Image:yetus/hadoop:abb62dd |
| JIRA Issue | HADOOP-15467 |
| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12923367/HDFS-13549.000.patch |
| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  shadedclient  findbugs  checkstyle  |
| uname | Linux 4ccad47020bb 3.13.0-139-generic #188-Ubuntu SMP Tue Jan 9 14:43:09 UTC 2018 x86_64 x86_64 x86_64 GNU/Linux |
| Build tool | maven |
| Personality | /testptch/patchprocess/precommit/personality/provided.sh |
| git revision | trunk / 2d00a0c |
| maven | version: Apache Maven 3.3.9 |
| Default Java | 1.8.0_162 |
| findbugs | v3.1.0-RC1 |
|  Test Results | https://builds.apache.org/job/PreCommit-HADOOP-Build/14626/testReport/ |
| Max. process+thread count | 1467 (vs. ulimit of 10000) |
| modules | C: hadoop-common-project/hadoop-common U: hadoop-common-project/hadoop-common |
| Console output | https://builds.apache.org/job/PreCommit-HADOOP-Build/14626/console |
| Powered by | Apache Yetus 0.8.0-SNAPSHOT   http://yetus.apache.org |


This message was automatically generated.

","15/May/18 17:07;elgoiri;This does not fail in the daily Windows build so it seems spurious.
Any insight on why Windows takes longer?","16/May/18 20:54;huanbang1993;As the stack trace indicates, both tests get stuck in getCanonicalHostName() in InetAddress.java.
{code:java}
/**
 * Gets the fully qualified domain name for this IP address.
 * Best effort method, meaning we may not be able to return
 * the FQDN depending on the underlying system configuration.
 *
 * <p>If there is a security manager, this method first
 * calls its {@code checkConnect} method
 * with the hostname and {@code -1}
 * as its arguments to see if the calling code is allowed to know
 * the hostname for this IP address, i.e., to connect to the host.
 * If the operation is not allowed, it will return
 * the textual representation of the IP address.
 *
 * @return the fully qualified domain name for this IP address,
 * or if the operation is not allowed by the security check,
 * the textual representation of the IP address.
 *
 * @see SecurityManager#checkConnect
 *
 * @since 1.4
 */
public String getCanonicalHostName() {{code}
After native method call getHostByAddr, it takes a long time to return the domain name. I am guessing daily Windows builder does not belong to a domain whose canonical name resolution takes a long time.

 ","16/May/18 21:13;elgoiri;Can we avoid using {{getCanonicalHostName()}}?","17/May/18 00:16;huanbang1993;The root cause to these failures and the workaround on Windows are described [here|https://issues.apache.org/jira/browse/HDFS-13569?focusedCommentId=16478265&page=com.atlassian.jira.plugin.system.issuetabpanels%3Acomment-tabpanel#comment-16478265].","17/May/18 00:18;huanbang1993;This is a Windows machine set up issue. See [this|https://issues.apache.org/jira/browse/HDFS-13569?focusedCommentId=16478265&page=com.atlassian.jira.plugin.system.issuetabpanels%3Acomment-tabpanel#comment-16478265] for details. Mark it as Won't Fix.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
hadoop-aws parallel tests do not work under Windows,HADOOP-14725,13091963,Test,Resolved,HADOOP,Hadoop Common,software,omalley,Hadoop Common is the common library for Apache Hadoop.,http://hadoop.apache.org/,Minor,Duplicate,,aw,aw,02/Aug/17 18:28,02/Aug/17 20:46,12/Jan/21 11:55,02/Aug/17 20:46,3.0.0-beta1,,,,,,,,,,test,,,,0,,,,,aw,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,9223372036854775807,,,,,2017-08-02 18:28:25.0,,,,,,,"0|i3ic4f:",9223372036854775807,,,,,,,,,,,,,3.0.0-beta1,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Use Mockito.when instead of Mockito.stub,HADOOP-14245,13059342,Test,Resolved,HADOOP,Hadoop Common,software,omalley,Hadoop Common is the common library for Apache Hadoop.,http://hadoop.apache.org/,Minor,Fixed,boky01,aajisaka,aajisaka,27/Mar/17 09:47,01/Aug/17 06:51,12/Jan/21 11:55,01/Aug/17 06:20,,,,,2.9.0,3.0.0-beta1,,,,,test,,,,0,,,Mockito.stub was removed in Mockito 2. Mockito.when should be used instead.,,aajisaka,boky01,hudson,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,HADOOP-14178,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"31/Jul/17 07:50;boky01;HADOOP-14245.01.patch;https://issues.apache.org/jira/secure/attachment/12879583/HADOOP-14245.01.patch","31/Jul/17 09:47;boky01;HADOOP-14245.02.patch;https://issues.apache.org/jira/secure/attachment/12879601/HADOOP-14245.02.patch",,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,2017-07-21 17:12:24.214,,,false,,,,,,,,,,,,,,,,,9223372036854775807,Reviewed,,,,Tue Aug 01 06:51:06 UTC 2017,,,,,,,"0|i3cts7:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,"21/Jul/17 17:12;boky01;[~xiaobingo],

Do you mind if I attach a patch?","21/Jul/17 18:45;boky01;Also, I would consider removing {{MockitoMaker}} class and use the standard way to mock objects.
For a developer who knows Mockito it's harder to read and misleading since it's using the deprecated syntax (at least that's I felt during looking into this ticket).
Any thoughts?","24/Jul/17 05:26;aajisaka;bq. Also, I would consider removing MockitoMaker class and use the standard way to mock objects.
+1. Let's do this in a separate jira. Thanks.","24/Jul/17 13:44;boky01;Filed HADOOP-14681.","31/Jul/17 05:31;aajisaka;bq. Do you mind if I attach a patch?
1 week passed without any response. Assigned to [~boky01].","31/Jul/17 09:47;boky01;Jenkins did not trigger pre-commit build for my patch. I have no right to start manually so I am attaching the same patch to kick [~hadoopqa].","31/Jul/17 15:12;boky01;Reattach the patch did not help. What else can I do?","31/Jul/17 16:35;aajisaka;You need to hit ""submit patch"" button to set the status to ""patch available"".","31/Jul/17 17:02;boky01;Thanks, I do not know how could I miss it...","31/Jul/17 19:50;hadoopqa;| (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 15s{color} | {color:blue} Docker mode activated. {color} |
|| || || || {color:brown} Prechecks {color} ||
| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |
| {color:green}+1{color} | {color:green} test4tests {color} | {color:green}  0m  0s{color} | {color:green} The patch appears to include 2 new or modified test files. {color} |
|| || || || {color:brown} trunk Compile Tests {color} ||
| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  0m 15s{color} | {color:blue} Maven dependency ordering for branch {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 14m  4s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 14m 40s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  1m 58s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  1m 39s{color} | {color:green} trunk passed {color} |
| {color:red}-1{color} | {color:red} findbugs {color} | {color:red}  1m 53s{color} | {color:red} hadoop-hdfs-project/hadoop-hdfs in trunk has 10 extant Findbugs warnings. {color} |
| {color:red}-1{color} | {color:red} findbugs {color} | {color:red}  0m 53s{color} | {color:red} hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager in trunk has 5 extant Findbugs warnings. {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  1m 15s{color} | {color:green} trunk passed {color} |
|| || || || {color:brown} Patch Compile Tests {color} ||
| {color:blue}0{color} | {color:blue} mvndep {color} | {color:blue}  0m 18s{color} | {color:blue} Maven dependency ordering for patch {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  1m 19s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 11m  7s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javac {color} | {color:green} 11m  7s{color} | {color:green} the patch passed {color} |
| {color:orange}-0{color} | {color:orange} checkstyle {color} | {color:orange}  1m 58s{color} | {color:orange} root: The patch generated 7 new + 17 unchanged - 7 fixed = 24 total (was 24) {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  1m 39s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  3m 11s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  1m 21s{color} | {color:green} the patch passed {color} |
|| || || || {color:brown} Other Tests {color} ||
| {color:red}-1{color} | {color:red} unit {color} | {color:red} 67m 27s{color} | {color:red} hadoop-hdfs in the patch failed. {color} |
| {color:green}+1{color} | {color:green} unit {color} | {color:green} 13m 26s{color} | {color:green} hadoop-yarn-server-nodemanager in the patch passed. {color} |
| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 35s{color} | {color:green} The patch does not generate ASF License warnings. {color} |
| {color:black}{color} | {color:black} {color} | {color:black}161m 26s{color} | {color:black} {color} |
\\
\\
|| Reason || Tests ||
| Failed junit tests | hadoop.hdfs.TestDFSStripedOutputStreamWithFailure080 |
|   | hadoop.hdfs.server.datanode.fsdataset.impl.TestLazyPersistReplicaRecovery |
|   | hadoop.hdfs.server.datanode.TestDataNodeVolumeFailureReporting |
\\
\\
|| Subsystem || Report/Notes ||
| Docker |  Image:yetus/hadoop:14b5c93 |
| JIRA Issue | HADOOP-14245 |
| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12879601/HADOOP-14245.02.patch |
| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  findbugs  checkstyle  |
| uname | Linux 836ab3edf222 3.13.0-117-generic #164-Ubuntu SMP Fri Apr 7 11:05:26 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux |
| Build tool | maven |
| Personality | /testptch/hadoop/patchprocess/precommit/personality/provided.sh |
| git revision | trunk / 0fd6d0f |
| Default Java | 1.8.0_131 |
| findbugs | v3.1.0-RC1 |
| findbugs | https://builds.apache.org/job/PreCommit-HADOOP-Build/12900/artifact/patchprocess/branch-findbugs-hadoop-hdfs-project_hadoop-hdfs-warnings.html |
| findbugs | https://builds.apache.org/job/PreCommit-HADOOP-Build/12900/artifact/patchprocess/branch-findbugs-hadoop-yarn-project_hadoop-yarn_hadoop-yarn-server_hadoop-yarn-server-nodemanager-warnings.html |
| checkstyle | https://builds.apache.org/job/PreCommit-HADOOP-Build/12900/artifact/patchprocess/diff-checkstyle-root.txt |
| unit | https://builds.apache.org/job/PreCommit-HADOOP-Build/12900/artifact/patchprocess/patch-unit-hadoop-hdfs-project_hadoop-hdfs.txt |
|  Test Results | https://builds.apache.org/job/PreCommit-HADOOP-Build/12900/testReport/ |
| modules | C: hadoop-hdfs-project/hadoop-hdfs hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager U: . |
| Console output | https://builds.apache.org/job/PreCommit-HADOOP-Build/12900/console |
| Powered by | Apache Yetus 0.6.0-SNAPSHOT   http://yetus.apache.org |


This message was automatically generated.

","01/Aug/17 06:15;aajisaka;+1, checking this in.","01/Aug/17 06:20;aajisaka;Committed this to trunk and branch-2. Thanks [~boky01] for the contribution!","01/Aug/17 06:51;hudson;SUCCESS: Integrated in Jenkins build Hadoop-trunk-Commit #12089 (See [https://builds.apache.org/job/Hadoop-trunk-Commit/12089/])
HADOOP-14245. Use Mockito.when instead of Mockito.stub. Contributed by (aajisaka: rev b38a1eea8e2917989d83d169a7b5773163e6832e)
* (edit) hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/TestGenericRefresh.java
* (edit) hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-nodemanager/src/test/java/org/apache/hadoop/yarn/server/nodemanager/util/TestCgroupsLCEResourcesHandler.java
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Build failure due to failing Bats test,HADOOP-14618,13084191,Test,Resolved,HADOOP,Hadoop Common,software,omalley,Hadoop Common is the common library for Apache Hadoop.,http://hadoop.apache.org/,Minor,Not A Problem,,Sonia,Sonia,03/Jul/17 09:05,04/Jul/17 11:37,12/Jan/21 11:55,04/Jul/17 11:37,3.0.0-alpha4,,,,,,,,,,common,,,,0,,,"The build fails with the following error :
{code}
[ERROR] Failed to execute goal org.apache.maven.plugins:maven-antrun-plugin:1.7:run (common-test-bats-driver) on project hadoop-common: An Ant BuildException has occured: exec returned: 1
[ERROR] around Ant part ...<exec failonerror=""true"" dir=""src/test/scripts"" executable=""bash"">... @ 4:69 in /ws/hadoop/hadoop-common-project/hadoop-common/target/antrun/build-main.xml
{code}

There is a failure in the bats test as follows :
{code}
[exec] Running bats -t hadoop_mkdir.bats
     [exec] 1..3
     [exec] ok 1 hadoop_mkdir (create)
     [exec] ok 2 hadoop_mkdir (exists)
     [exec] not ok 3 hadoop_mkdir (failed)
     [exec] # (in test file hadoop_mkdir.bats, line 41)
     [exec] #   `[ ""${status}"" != 0 ]' failed
     [exec] # bindir: /var/lib/jenkins/workspace/hadoop-master/hadoop-common-project/hadoop-common/src/test/scripts
{code}

The required directories are getting created, however still the test fails.

I am using the following bats version :
{code}
# bats -version
Bats 0.4.0
{code}","Ubuntu 14.04 
x86, ppc64le
$ java -version
openjdk version ""1.8.0_111""
OpenJDK Runtime Environment (build 1.8.0_111-8u111-b14-3~14.04.1-b14)
OpenJDK 64-Bit Server VM (build 25.111-b14, mixed mode)",aw,Sonia,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,9223372036854775807,,,,,Tue Jul 04 11:36:46 UTC 2017,,,,,,,"0|i3h0q7:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,"04/Jul/17 11:36;Sonia;This error is resolved on running the build as a non-root user.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Replace assertThat with assertTrue in MetricsAsserts,HADOOP-14218,13058504,Test,Resolved,HADOOP,Hadoop Common,software,omalley,Hadoop Common is the common library for Apache Hadoop.,http://hadoop.apache.org/,Minor,Fixed,aajisaka,aajisaka,aajisaka,23/Mar/17 08:07,28/Mar/17 05:58,12/Jan/21 11:55,28/Mar/17 05:34,,,,,2.9.0,3.0.0-alpha4,,,,,,,,,0,,,"{code:title=MetricsAsserts.java}
  public static void assertCounterGt(String name, long greater,
                                     MetricsRecordBuilder rb) {
    Assert.assertThat(""Bad value for metric "" + name, getLongCounter(name, rb),
        new GreaterThan<Long>(greater));
  }
{code}
The following code cannot be compiled with Mockito 2.1+ because it does not depend on org.hamcrest.Matcher anymore. We can simply replace this code with {{assertTrue(message, getLongCounter() > greater)}}.",,aajisaka,arp,haibochen,hudson,stevel@apache.org,,,,,,,,,,,,,,,,,,,,,,,,,,,,,HADOOP-14178,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"27/Mar/17 06:57;aajisaka;HADOOP-14218.01.patch;https://issues.apache.org/jira/secure/attachment/12860603/HADOOP-14218.01.patch",,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,2017-03-27 08:15:20.588,,,false,,,,,,,,,,,,,,,,,9223372036854775807,,,,,Tue Mar 28 05:58:03 UTC 2017,,,,,,,"0|i3colz:",9223372036854775807,,,,,,,,,,,,,3.0.0-alpha4,,,,,,,,,,"27/Mar/17 08:15;hadoopqa;| (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 18s{color} | {color:blue} Docker mode activated. {color} |
| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |
| {color:green}+1{color} | {color:green} test4tests {color} | {color:green}  0m  0s{color} | {color:green} The patch appears to include 1 new or modified test files. {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 12m 38s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 17m 17s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 36s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  1m  6s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green}  0m 19s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  1m 30s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 48s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  0m 38s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 15m 32s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javac {color} | {color:green} 15m 32s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 36s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  1m 11s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green}  0m 19s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  1m 47s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 51s{color} | {color:green} the patch passed {color} |
| {color:red}-1{color} | {color:red} unit {color} | {color:red}  8m 57s{color} | {color:red} hadoop-common in the patch failed. {color} |
| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 34s{color} | {color:green} The patch does not generate ASF License warnings. {color} |
| {color:black}{color} | {color:black} {color} | {color:black} 66m 56s{color} | {color:black} {color} |
\\
\\
|| Reason || Tests ||
| Failed junit tests | hadoop.ha.TestZKFailoverController |
|   | hadoop.security.TestKDiag |
\\
\\
|| Subsystem || Report/Notes ||
| Docker |  Image:yetus/hadoop:a9ad5d6 |
| JIRA Issue | HADOOP-14218 |
| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12860603/HADOOP-14218.01.patch |
| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  findbugs  checkstyle  |
| uname | Linux 575d87761382 3.13.0-106-generic #153-Ubuntu SMP Tue Dec 6 15:44:32 UTC 2016 x86_64 x86_64 x86_64 GNU/Linux |
| Build tool | maven |
| Personality | /testptch/hadoop/patchprocess/precommit/personality/provided.sh |
| git revision | trunk / 945b006 |
| Default Java | 1.8.0_121 |
| findbugs | v3.0.0 |
| unit | https://builds.apache.org/job/PreCommit-HADOOP-Build/11935/artifact/patchprocess/patch-unit-hadoop-common-project_hadoop-common.txt |
|  Test Results | https://builds.apache.org/job/PreCommit-HADOOP-Build/11935/testReport/ |
| modules | C: hadoop-common-project/hadoop-common U: hadoop-common-project/hadoop-common |
| Console output | https://builds.apache.org/job/PreCommit-HADOOP-Build/11935/console |
| Powered by | Apache Yetus 0.5.0-SNAPSHOT   http://yetus.apache.org |


This message was automatically generated.

","27/Mar/17 16:10;haibochen;+1 nonbinding","27/Mar/17 18:12;arp;+1","28/Mar/17 05:34;aajisaka;Committed this to trunk and branch-2. Thanks [~haibochen] and [~arpitagarwal] for the review!","28/Mar/17 05:58;hudson;SUCCESS: Integrated in Jenkins build Hadoop-trunk-Commit #11478 (See [https://builds.apache.org/job/Hadoop-trunk-Commit/11478/])
HADOOP-14218. Replace assertThat with assertTrue in MetricsAsserts. (aajisaka: rev 448ec81fd7133f413853570f116d5f6e16f68bd9)
* (edit) hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/test/MetricsAsserts.java
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
add integration tests for shaded client based on use by Spark,HADOOP-13920,13029195,Test,Resolved,HADOOP,Hadoop Common,software,omalley,Hadoop Common is the common library for Apache Hadoop.,http://hadoop.apache.org/,Minor,Duplicate,,busbey,busbey,19/Dec/16 16:56,19/Dec/16 16:57,12/Jan/21 11:55,19/Dec/16 16:57,3.0.0-alpha1,,,,,,,,,,test,,,,0,,,"Look at the tests that Spark runs against the Hadoop Minicluster and make sure that functionality is tested in our integration tests.
",,andrew.wang,busbey,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,HADOOP-13919,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,9223372036854775807,,,,,2016-12-19 16:56:46.0,,,,,,,"0|i37s3z:",9223372036854775807,,,,,,,,,,,,,3.0.0-beta1,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Refine TestRackResolver#testCaching to ensure cache is truly tested,HADOOP-13645,13007087,Test,Resolved,HADOOP,Hadoop Common,software,omalley,Hadoop Common is the common library for Apache Hadoop.,http://hadoop.apache.org/,Minor,Not A Bug,cheersyang,cheersyang,cheersyang,23/Sep/16 08:35,27/Sep/16 16:11,12/Jan/21 11:55,27/Sep/16 16:11,2.7.3,,,,,,,,,,util,,,,0,,,"TestRackResolver#testCaching seems not cover the cache testing well, the test case won't fail even the cache wasn't used.",,cheersyang,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"27/Sep/16 08:32;cheersyang;HADOOP-13645.01.patch;https://issues.apache.org/jira/secure/attachment/12830465/HADOOP-13645.01.patch",,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,2016-09-27 08:57:48.287,,,false,,,,,,,,,,,,,,,,,9223372036854775807,,,,,Tue Sep 27 16:11:18 UTC 2016,,,,,,,"0|i33zuf:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,"27/Sep/16 08:32;cheersyang;The v1 patch rewrite the test to make sure this function is fully tested. Besides basic tests, simulated a delay on some of hosts resolution, verify the delay actually happened at 1st time, and cache actually worked at 2nd query. Please kindly review.

Thanks","27/Sep/16 08:57;hadoopqa;| (/) *{color:green}+1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 15s{color} | {color:blue} Docker mode activated. {color} |
| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |
| {color:green}+1{color} | {color:green} test4tests {color} | {color:green}  0m  0s{color} | {color:green} The patch appears to include 1 new or modified test files. {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  7m  9s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green}  0m 32s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 19s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  0m 32s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green}  0m 14s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  0m 59s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 28s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  0m 26s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green}  0m 24s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javac {color} | {color:green}  0m 24s{color} | {color:green} the patch passed {color} |
| {color:orange}-0{color} | {color:orange} checkstyle {color} | {color:orange}  0m 16s{color} | {color:orange} hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common: The patch generated 6 new + 1 unchanged - 9 fixed = 7 total (was 10) {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  0m 28s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green}  0m 11s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  1m 21s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 30s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} unit {color} | {color:green}  2m 37s{color} | {color:green} hadoop-yarn-common in the patch passed. {color} |
| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 16s{color} | {color:green} The patch does not generate ASF License warnings. {color} |
| {color:black}{color} | {color:black} {color} | {color:black} 18m 17s{color} | {color:black} {color} |
\\
\\
|| Subsystem || Report/Notes ||
| Docker |  Image:yetus/hadoop:9560f25 |
| JIRA Issue | HADOOP-13645 |
| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12830465/HADOOP-13645.01.patch |
| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  findbugs  checkstyle  |
| uname | Linux be1d2634aa91 3.13.0-36-lowlatency #63-Ubuntu SMP PREEMPT Wed Sep 3 21:56:12 UTC 2014 x86_64 x86_64 x86_64 GNU/Linux |
| Build tool | maven |
| Personality | /testptch/hadoop/patchprocess/precommit/personality/provided.sh |
| git revision | trunk / e17a497 |
| Default Java | 1.8.0_101 |
| findbugs | v3.0.0 |
| checkstyle | https://builds.apache.org/job/PreCommit-HADOOP-Build/10606/artifact/patchprocess/diff-checkstyle-hadoop-yarn-project_hadoop-yarn_hadoop-yarn-common.txt |
|  Test Results | https://builds.apache.org/job/PreCommit-HADOOP-Build/10606/testReport/ |
| modules | C: hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common U: hadoop-yarn-project/hadoop-yarn/hadoop-yarn-common |
| Console output | https://builds.apache.org/job/PreCommit-HADOOP-Build/10606/console |
| Powered by | Apache Yetus 0.4.0-SNAPSHOT   http://yetus.apache.org |


This message was automatically generated.

","27/Sep/16 16:11;cheersyang;Though it was not using neat way, it actually tested the cache. It would be good to rewrite this test case for better reading, but lower priority. Close as Not a bug for now. Any people who is interested to improve this, feel free to reopen.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
TestActiveStandbyElector fails occasionally in trunk,HADOOP-10980,12735087,Test,Resolved,HADOOP,Hadoop Common,software,omalley,Hadoop Common is the common library for Apache Hadoop.,http://hadoop.apache.org/,Minor,Fixed,ebadger,yuzhihong@gmail.com,yuzhihong@gmail.com,19/Aug/14 16:01,30/Aug/16 01:32,12/Jan/21 11:55,03/Aug/16 20:32,3.0.0-alpha1,,,,2.7.4,2.8.0,3.0.0-alpha1,,,,,,,,0,,,"From https://builds.apache.org/job/Hadoop-Common-trunk/1211/consoleFull :
{code}
Running org.apache.hadoop.ha.TestActiveStandbyElector
Tests run: 23, Failures: 1, Errors: 0, Skipped: 0, Time elapsed: 0.7 sec <<< FAILURE! - in org.apache.hadoop.ha.TestActiveStandbyElector
testWithoutZKServer(org.apache.hadoop.ha.TestActiveStandbyElector)  Time elapsed: 0.051 sec  <<< FAILURE!
java.lang.AssertionError: Did not throw zookeeper connection loss exceptions!
	at org.junit.Assert.fail(Assert.java:88)
	at org.apache.hadoop.ha.TestActiveStandbyElector.testWithoutZKServer(TestActiveStandbyElector.java:722)
{code}",,ebadger,hudson,jlowe,stevel@apache.org,varun_saxena,yuzhihong@gmail.com,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"10/May/16 19:43;ebadger;HADOOP-10980.001.patch;https://issues.apache.org/jira/secure/attachment/12803298/HADOOP-10980.001.patch","02/Aug/16 22:26;ebadger;HADOOP-10980.002.patch;https://issues.apache.org/jira/secure/attachment/12821705/HADOOP-10980.002.patch","03/Aug/16 13:35;ebadger;HADOOP-10980.003.patch;https://issues.apache.org/jira/secure/attachment/12821838/HADOOP-10980.003.patch",,,,,,,,,,,,,,,,,,,,,3.0,,,,,,,,,,,,,,,,,,,,2014-12-11 13:02:38.864,,,false,,,,,,,,,,,,,,,,,9223372036854775807,Reviewed,,,,Wed Aug 03 20:40:22 UTC 2016,,,,,,,"0|i1z1zz:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,"11/Dec/14 13:02;stevel@apache.org;This may be some concurrency condition: if there is a ZK service on 2181, the test is going to connect to it, rather than fail.

How about we change the port to something unlikely to be open, and very unlikely to be ZK if it is?","07/Mar/15 23:10;yuzhihong@gmail.com;Hadoop-Common-trunk has been green for a while.","10/May/16 19:42;ebadger;This test failed for me locally when I was running a separate zookeeper instance. If we specify a port number, as [~stevel@apache.org] suggested, the test passes. For example, changing the port to 22, since that will likely only ever be used for SSH. ","10/May/16 19:43;ebadger;Attaching patch to change the default port, so that we do not connect to a zookeeper instance that is running by coincidence. ","10/May/16 21:59;hadoopqa;| (/) *{color:green}+1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue} 0m 10s {color} | {color:blue} Docker mode activated. {color} |
| {color:green}+1{color} | {color:green} @author {color} | {color:green} 0m 0s {color} | {color:green} The patch does not contain any @author tags. {color} |
| {color:green}+1{color} | {color:green} test4tests {color} | {color:green} 0m 0s {color} | {color:green} The patch appears to include 1 new or modified test files. {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 7m 1s {color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 5m 58s {color} | {color:green} trunk passed with JDK v1.8.0_91 {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 6m 52s {color} | {color:green} trunk passed with JDK v1.7.0_95 {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green} 0m 24s {color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green} 1m 2s {color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green} 0m 14s {color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green} 1m 37s {color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 0m 52s {color} | {color:green} trunk passed with JDK v1.8.0_91 {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 1m 6s {color} | {color:green} trunk passed with JDK v1.7.0_95 {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 0m 41s {color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 5m 56s {color} | {color:green} the patch passed with JDK v1.8.0_91 {color} |
| {color:green}+1{color} | {color:green} javac {color} | {color:green} 5m 56s {color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 6m 46s {color} | {color:green} the patch passed with JDK v1.7.0_95 {color} |
| {color:green}+1{color} | {color:green} javac {color} | {color:green} 6m 46s {color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green} 0m 24s {color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green} 0m 58s {color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green} 0m 13s {color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} whitespace {color} | {color:green} 0m 0s {color} | {color:green} The patch has no whitespace issues. {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green} 1m 50s {color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 0m 53s {color} | {color:green} the patch passed with JDK v1.8.0_91 {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 1m 6s {color} | {color:green} the patch passed with JDK v1.7.0_95 {color} |
| {color:green}+1{color} | {color:green} unit {color} | {color:green} 7m 34s {color} | {color:green} hadoop-common in the patch passed with JDK v1.8.0_91. {color} |
| {color:green}+1{color} | {color:green} unit {color} | {color:green} 7m 47s {color} | {color:green} hadoop-common in the patch passed with JDK v1.7.0_95. {color} |
| {color:green}+1{color} | {color:green} asflicense {color} | {color:green} 0m 23s {color} | {color:green} The patch does not generate ASF License warnings. {color} |
| {color:black}{color} | {color:black} {color} | {color:black} 61m 1s {color} | {color:black} {color} |
\\
\\
|| Subsystem || Report/Notes ||
| Docker |  Image:yetus/hadoop:cf2ee45 |
| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12803298/HADOOP-10980.001.patch |
| JIRA Issue | HADOOP-10980 |
| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  findbugs  checkstyle  |
| uname | Linux 92484a38f867 3.13.0-36-lowlatency #63-Ubuntu SMP PREEMPT Wed Sep 3 21:56:12 UTC 2014 x86_64 x86_64 x86_64 GNU/Linux |
| Build tool | maven |
| Personality | /testptch/hadoop/patchprocess/precommit/personality/provided.sh |
| git revision | trunk / 025219b |
| Default Java | 1.7.0_95 |
| Multi-JDK versions |  /usr/lib/jvm/java-8-oracle:1.8.0_91 /usr/lib/jvm/java-7-openjdk-amd64:1.7.0_95 |
| findbugs | v3.0.0 |
| JDK v1.7.0_95  Test Results | https://builds.apache.org/job/PreCommit-HADOOP-Build/9360/testReport/ |
| modules | C: hadoop-common-project/hadoop-common U: hadoop-common-project/hadoop-common |
| Console output | https://builds.apache.org/job/PreCommit-HADOOP-Build/9360/console |
| Powered by | Apache Yetus 0.3.0-SNAPSHOT   http://yetus.apache.org |


This message was automatically generated.

","02/Aug/16 20:41;jlowe;Thanks for the patch, Eric!

My main concern of using port 22 is that we're essentially testing a use-case that should _never_ occur in practice.  We're testing what the ZK client will do when we try to connect it to sshd, but that's not something we expect users will ever do.  If the purpose of this test is to make sure that a ZK exception is not accidentally swallowed by the ActiveStandbyElector logic then we can mock the zkClient in the elector to throw a ZK exception when we try to connect.  Then we're guaranteed to get the base ZK exception we're looking for without relying on ports being unused which is difficult to enforce in practice.","02/Aug/16 21:10;ebadger;Thanks for reviewing, Jason. In hindsight, I agree that using port 22 isn't a good way to get around accidentally connecting to Zookeeper. As you said, I'll mock up a zkClient and upload a new patch. Thanks!","02/Aug/16 21:27;hadoopqa;| (/) *{color:green}+1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 19s{color} | {color:blue} Docker mode activated. {color} |
| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |
| {color:green}+1{color} | {color:green} test4tests {color} | {color:green}  0m  0s{color} | {color:green} The patch appears to include 1 new or modified test files. {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  6m 37s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green}  6m 46s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 23s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  0m 53s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green}  0m 12s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  1m 17s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 44s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  0m 36s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green}  6m 47s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javac {color} | {color:green}  6m 47s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 23s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  0m 54s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green}  0m 14s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  1m 27s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 47s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} unit {color} | {color:green}  8m 54s{color} | {color:green} hadoop-common in the patch passed. {color} |
| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 21s{color} | {color:green} The patch does not generate ASF License warnings. {color} |
| {color:black}{color} | {color:black} {color} | {color:black} 38m 56s{color} | {color:black} {color} |
\\
\\
|| Subsystem || Report/Notes ||
| Docker |  Image:yetus/hadoop:9560f25 |
| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12803298/HADOOP-10980.001.patch |
| JIRA Issue | HADOOP-10980 |
| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  findbugs  checkstyle  |
| uname | Linux f0287f594554 3.13.0-36-lowlatency #63-Ubuntu SMP PREEMPT Wed Sep 3 21:56:12 UTC 2014 x86_64 x86_64 x86_64 GNU/Linux |
| Build tool | maven |
| Personality | /testptch/hadoop/patchprocess/precommit/personality/provided.sh |
| git revision | trunk / 5e5b879 |
| Default Java | 1.8.0_101 |
| findbugs | v3.0.0 |
|  Test Results | https://builds.apache.org/job/PreCommit-HADOOP-Build/10153/testReport/ |
| modules | C: hadoop-common-project/hadoop-common U: hadoop-common-project/hadoop-common |
| Console output | https://builds.apache.org/job/PreCommit-HADOOP-Build/10153/console |
| Powered by | Apache Yetus 0.4.0-SNAPSHOT   http://yetus.apache.org |


This message was automatically generated.

","02/Aug/16 22:26;ebadger;Attaching a patch that mocks up the ZooKeeper instance for the test, so that there will always be a connection timeout. I had to make a new protected method to gain access to the ZooKeeper instance. The getNewZooKeeper() method claims that it was made 'protected' so that a mocked ZooKeeper instance could be passed in, but I don't see how that is possible since it is explicitly set within the function. Please let me know if I'm missing something.

[~jlowe], does this change look correct?","02/Aug/16 22:32;hadoopqa;| (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m  0s{color} | {color:blue} Docker mode activated. {color} |
| {color:red}-1{color} | {color:red} patch {color} | {color:red}  0m  5s{color} | {color:red} HADOOP-10980 does not apply to trunk. Rebase required? Wrong Branch? See https://wiki.apache.org/hadoop/HowToContribute for help. {color} |
\\
\\
|| Subsystem || Report/Notes ||
| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12821705/HADOOP-10980.002.patch |
| JIRA Issue | HADOOP-10980 |
| Console output | https://builds.apache.org/job/PreCommit-HADOOP-Build/10157/console |
| Powered by | Apache Yetus 0.4.0-SNAPSHOT   http://yetus.apache.org |


This message was automatically generated.

","03/Aug/16 13:35;ebadger;Was accidentally working on branch-2.7. Here's the trunk patch. It's the same as the previous patch, just rebased to trunk.","03/Aug/16 14:23;hadoopqa;| (/) *{color:green}+1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue}  0m 16s{color} | {color:blue} Docker mode activated. {color} |
| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |
| {color:green}+1{color} | {color:green} test4tests {color} | {color:green}  0m  0s{color} | {color:green} The patch appears to include 1 new or modified test files. {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  7m  8s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green}  7m 22s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 23s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  0m 59s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green}  0m 13s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  1m 26s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 50s{color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  0m 53s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green}  9m  5s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javac {color} | {color:green}  9m  5s{color} | {color:green} the patch passed {color} |
| {color:orange}-0{color} | {color:orange} checkstyle {color} | {color:orange}  0m 28s{color} | {color:orange} hadoop-common-project/hadoop-common: The patch generated 1 new + 39 unchanged - 0 fixed = 40 total (was 39) {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  1m  7s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green}  0m 13s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  1m 57s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 52s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} unit {color} | {color:green}  9m 34s{color} | {color:green} hadoop-common in the patch passed. {color} |
| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 23s{color} | {color:green} The patch does not generate ASF License warnings. {color} |
| {color:black}{color} | {color:black} {color} | {color:black} 44m 44s{color} | {color:black} {color} |
\\
\\
|| Subsystem || Report/Notes ||
| Docker |  Image:yetus/hadoop:9560f25 |
| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12821838/HADOOP-10980.003.patch |
| JIRA Issue | HADOOP-10980 |
| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  findbugs  checkstyle  |
| uname | Linux dc66f2de119d 3.13.0-36-lowlatency #63-Ubuntu SMP PREEMPT Wed Sep 3 21:56:12 UTC 2014 x86_64 x86_64 x86_64 GNU/Linux |
| Build tool | maven |
| Personality | /testptch/hadoop/patchprocess/precommit/personality/provided.sh |
| git revision | trunk / d848184 |
| Default Java | 1.8.0_101 |
| findbugs | v3.0.0 |
| checkstyle | https://builds.apache.org/job/PreCommit-HADOOP-Build/10165/artifact/patchprocess/diff-checkstyle-hadoop-common-project_hadoop-common.txt |
|  Test Results | https://builds.apache.org/job/PreCommit-HADOOP-Build/10165/testReport/ |
| modules | C: hadoop-common-project/hadoop-common U: hadoop-common-project/hadoop-common |
| Console output | https://builds.apache.org/job/PreCommit-HADOOP-Build/10165/console |
| Powered by | Apache Yetus 0.4.0-SNAPSHOT   http://yetus.apache.org |


This message was automatically generated.

","03/Aug/16 20:06;jlowe;bq. but I don't see how that is possible since it is explicitly set within the function. Please let me know if I'm missing something.

The intent of overriding that method is to mock out both the ZK client _and_ the connection to the ZK server.  If we just mocked out the ZK client itself then the logic in ActiveStandbyElector that uses the ZK client to connect to the server would either fail outright (as you intentionally do for this one, specific test) or the mock needs to be much more sophisticated to fool the connection code.  Overriding the method that does both the client create and server connect is simpler for the vast majority of the tests that want to focus on mocking out functionality relevant when connected to the ZK server rather.

+1 lgtm.  I'll fix the indent nit flagged by checkstyle during the commit.
","03/Aug/16 20:32;jlowe;Thanks to [~ebadger] for the contribution and to [~stevel@apache.org] for diagnosing the original issue!  I committed this to trunk, branch-2, branch-2.8, and branch-2.7.","03/Aug/16 20:40;hudson;SUCCESS: Integrated in Hadoop-trunk-Commit #10208 (See [https://builds.apache.org/job/Hadoop-trunk-Commit/10208/])
HADOOP-10980. TestActiveStandbyElector fails occasionally in trunk. (jlowe: rev c82745432a962c817a8a7db92bb830fb6af01e33)
* hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/ha/ActiveStandbyElector.java
* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/ha/TestActiveStandbyElector.java
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
test-patch.sh should pull the real findbugs version,HADOOP-11884,12825595,Test,Resolved,HADOOP,Hadoop Common,software,omalley,Hadoop Common is the common library for Apache Hadoop.,http://hadoop.apache.org/,Minor,Fixed,sekikn,aw,aw,28/Apr/15 17:04,30/Aug/16 01:29,12/Jan/21 11:55,18/May/15 16:10,,,,,2.8.0,3.0.0-alpha1,,,,,test,,,,0,BB2015-05-RFC,newbie,test-patch.sh currently uses the CLI utilities for findbugs to discover the version.  This isn't really accurate since maven pulls down the jars as part of the pom.  It should be possible to either read the generated HTML file(s) or perhaps read the pom to discover the real version that was used.,,aajisaka,aw,hudson,sekikn,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"01/May/15 13:00;sekikn;HADOOP-11884.001.patch;https://issues.apache.org/jira/secure/attachment/12729757/HADOOP-11884.001.patch","11/May/15 23:34;sekikn;HADOOP-11884.002.patch;https://issues.apache.org/jira/secure/attachment/12732063/HADOOP-11884.002.patch",,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,2015-05-01 13:00:20.358,,,false,,,,,,,,,,,,,,,,,9223372036854775807,,,,,Tue May 19 15:33:24 UTC 2015,,,,,,,"0|i2e0t3:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,"01/May/15 13:00;sekikn;Attaching a patch. It greps the generated file and determines findbugs' version.

We can also read pom.xml, but in some cases like the order of sibling elements is changed, it is difficult to parse an XML without some tools like xmllint.","01/May/15 13:10;hadoopqa;(!) A patch to test-patch or smart-apply-patch has been detected. 
Re-executing against the patched versions to perform further tests. 
The console is at https://builds.apache.org/job/PreCommit-HADOOP-Build/6234/console in case of problems.","01/May/15 13:10;hadoopqa;\\
\\
| (/) *{color:green}+1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | reexec |   0m  0s | dev-support patch detected. |
| {color:blue}0{color} | pre-patch |   0m  0s | Pre-patch trunk compilation is healthy. |
| {color:blue}0{color} | @author |   0m  0s | Skipping @author checks as test-patch has been patched. |
| {color:green}+1{color} | release audit |   0m 14s | The applied patch does not increase the total number of release audit warnings. |
| {color:blue}0{color} | shellcheck |   0m 14s | Shellcheck was not available. |
| {color:green}+1{color} | whitespace |   0m  0s | The patch has no lines that end in whitespace. |
| | |   0m 17s | |
\\
\\
|| Subsystem || Report/Notes ||
| Patch URL | http://issues.apache.org/jira/secure/attachment/12729757/HADOOP-11884.001.patch |
| Optional Tests | shellcheck |
| git revision | trunk / 1b3b9e5 |
| Java | 1.7.0_55 |
| uname | Linux asf901.gq1.ygridcore.net 3.13.0-36-lowlatency #63-Ubuntu SMP PREEMPT Wed Sep 3 21:56:12 UTC 2014 x86_64 x86_64 x86_64 GNU/Linux |
| Console output | https://builds.apache.org/job/PreCommit-HADOOP-Build/6234/console |


This message was automatically generated.","11/May/15 18:38;aw;awk needs to be $\{AWK} in case a different awk is specified.","11/May/15 23:34;sekikn;Thank you [~aw], I fixed the patch.","11/May/15 23:40;hadoopqa;(!) A patch to test-patch or smart-apply-patch has been detected. 
Re-executing against the patched versions to perform further tests. 
The console is at https://builds.apache.org/job/PreCommit-HADOOP-Build/6602/console in case of problems.","11/May/15 23:41;hadoopqa;\\
\\
| (/) *{color:green}+1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | reexec |   0m  0s | dev-support patch detected. |
| {color:blue}0{color} | pre-patch |   0m  0s | Pre-patch trunk compilation is healthy. |
| {color:blue}0{color} | @author |   0m  0s | Skipping @author checks as test-patch has been patched. |
| {color:green}+1{color} | release audit |   0m 14s | The applied patch does not increase the total number of release audit warnings. |
| {color:green}+1{color} | shellcheck |   0m  7s | There were no new shellcheck (v0.3.3) issues. |
| {color:green}+1{color} | whitespace |   0m  0s | The patch has no lines that end in whitespace. |
| | |   0m 25s | |
\\
\\
|| Subsystem || Report/Notes ||
| Patch URL | http://issues.apache.org/jira/secure/attachment/12732063/HADOOP-11884.002.patch |
| Optional Tests | shellcheck |
| git revision | trunk / 444836b |
| Java | 1.7.0_55 |
| uname | Linux asf903.gq1.ygridcore.net 3.13.0-36-lowlatency #63-Ubuntu SMP PREEMPT Wed Sep 3 21:56:12 UTC 2014 x86_64 x86_64 x86_64 GNU/Linux |
| Console output | https://builds.apache.org/job/PreCommit-HADOOP-Build/6602/console |


This message was automatically generated.","18/May/15 16:10;aw;+1 committed
thanks!","18/May/15 16:13;hudson;FAILURE: Integrated in Hadoop-trunk-Commit #7852 (See [https://builds.apache.org/job/Hadoop-trunk-Commit/7852/])
HADOOP-11884. test-patch.sh should pull the real findbugs version  (Kengo Seki via aw) (aw: rev 182d86dac04a2168b1888af34f0a7042379d7e53)
* dev-support/test-patch.sh
* hadoop-common-project/hadoop-common/CHANGES.txt
","19/May/15 11:39;hudson;FAILURE: Integrated in Hadoop-Yarn-trunk #932 (See [https://builds.apache.org/job/Hadoop-Yarn-trunk/932/])
HADOOP-11884. test-patch.sh should pull the real findbugs version  (Kengo Seki via aw) (aw: rev 182d86dac04a2168b1888af34f0a7042379d7e53)
* dev-support/test-patch.sh
* hadoop-common-project/hadoop-common/CHANGES.txt
","19/May/15 11:55;hudson;SUCCESS: Integrated in Hadoop-Yarn-trunk-Java8 #201 (See [https://builds.apache.org/job/Hadoop-Yarn-trunk-Java8/201/])
HADOOP-11884. test-patch.sh should pull the real findbugs version  (Kengo Seki via aw) (aw: rev 182d86dac04a2168b1888af34f0a7042379d7e53)
* dev-support/test-patch.sh
* hadoop-common-project/hadoop-common/CHANGES.txt
","19/May/15 14:22;hudson;FAILURE: Integrated in Hadoop-Hdfs-trunk #2130 (See [https://builds.apache.org/job/Hadoop-Hdfs-trunk/2130/])
HADOOP-11884. test-patch.sh should pull the real findbugs version  (Kengo Seki via aw) (aw: rev 182d86dac04a2168b1888af34f0a7042379d7e53)
* hadoop-common-project/hadoop-common/CHANGES.txt
* dev-support/test-patch.sh
","19/May/15 14:29;hudson;FAILURE: Integrated in Hadoop-Hdfs-trunk-Java8 #190 (See [https://builds.apache.org/job/Hadoop-Hdfs-trunk-Java8/190/])
HADOOP-11884. test-patch.sh should pull the real findbugs version  (Kengo Seki via aw) (aw: rev 182d86dac04a2168b1888af34f0a7042379d7e53)
* hadoop-common-project/hadoop-common/CHANGES.txt
* dev-support/test-patch.sh
","19/May/15 15:16;hudson;SUCCESS: Integrated in Hadoop-Mapreduce-trunk-Java8 #200 (See [https://builds.apache.org/job/Hadoop-Mapreduce-trunk-Java8/200/])
HADOOP-11884. test-patch.sh should pull the real findbugs version  (Kengo Seki via aw) (aw: rev 182d86dac04a2168b1888af34f0a7042379d7e53)
* hadoop-common-project/hadoop-common/CHANGES.txt
* dev-support/test-patch.sh
","19/May/15 15:33;hudson;FAILURE: Integrated in Hadoop-Mapreduce-trunk #2148 (See [https://builds.apache.org/job/Hadoop-Mapreduce-trunk/2148/])
HADOOP-11884. test-patch.sh should pull the real findbugs version  (Kengo Seki via aw) (aw: rev 182d86dac04a2168b1888af34f0a7042379d7e53)
* dev-support/test-patch.sh
* hadoop-common-project/hadoop-common/CHANGES.txt
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
add option to test-patch to avoid relocating patch process directory,HADOOP-11944,12828512,Test,Resolved,HADOOP,Hadoop Common,software,omalley,Hadoop Common is the common library for Apache Hadoop.,http://hadoop.apache.org/,Minor,Fixed,busbey,busbey,busbey,08/May/15 22:28,30/Aug/16 01:28,12/Jan/21 11:55,18/May/15 16:14,,,,,2.8.0,3.0.0-alpha1,,,,,,,,,0,,,"When we have a jenkins setup that places the patch process in a defined location under WORKPLACE, there's no need to have patch process relocate it. Add a flag to leave it as is.",,aw,busbey,hudson,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"08/May/15 22:30;busbey;HADOOP-11944.1.patch;https://issues.apache.org/jira/secure/attachment/12731630/HADOOP-11944.1.patch","16/May/15 07:06;busbey;HADOOP-11944.2.patch;https://issues.apache.org/jira/secure/attachment/12733308/HADOOP-11944.2.patch",,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,2015-05-11 19:22:26.651,,,false,,,,,,,,,,,,,,,,,9223372036854775807,,,,,Tue May 19 15:33:17 UTC 2015,,,,,,,"0|i2ei7j:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,"11/May/15 19:22;aw;test-patch.sh won't move it if the patchprocess dir is inside basedir.  So this should only be necessary if basedir != workspace dir.  ","11/May/15 19:26;hadoopqa;\\
\\
| (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:red}-1{color} | patch |   0m  3s | The patch command could not apply the patch. |
\\
\\
|| Subsystem || Report/Notes ||
| Patch URL | http://issues.apache.org/jira/secure/attachment/12731630/HADOOP-11944.1.patch |
| Optional Tests | shellcheck |
| git revision | trunk / cbea5d2 |
| Console output | https://builds.apache.org/job/PreCommit-HADOOP-Build/6590/console |


This message was automatically generated.","11/May/15 19:37;busbey;Right, when using test-patch to handle another project, I've been going with a workspace that looks like this:

{pre}
WORKSPACE
     |
     |--- testframework (hadoop git checkout)
     |
     |--- component (project-under-test git checkout)
     |
     \--- patchprocess (scratch dir cleaned by jenkins)
{pre}

Then I invoke test-patch within testframework while giving a BASEDIR that's the component to test. This lets Jenkins handle the two git repos cleanly and archive things out of patchprocess.","11/May/15 19:40;busbey;should I move the cli check after the ""relative_patchdir"" check?","11/May/15 19:40;aw;Gotcha.  Very clever.  Re-base and let's get this in. :)","11/May/15 19:43;aw;bq. should I move the cli check after the ""relative_patchdir"" check?

It should probably be re-written as a single, multi-check if statement at this point.","11/May/15 19:46;busbey;actually I just re-read this comment:

{quote}{noformat}
        # if PATCH_DIR is already inside BASEDIR, then
        # there is no need to move it since we assume that
        # Jenkins or whatever already knows where it is at
        # since it told us to put it there!
{noformat}{quote}

Maybe I've been thinking about this wrong. Should this check be looking to see if the user passed in a patch dir? We already know if they did because USER_PATCH_DIR will be set. In that case, presumably the same condition will hold.","11/May/15 21:02;aw;It's probably easier to flip the condition.  Only move it if we are told to move it.  yes, I realize this will break Hadoop's current precommit stuff.  We should be able to add --mv-patch-dir to the Jenkins config before testing the patch. :)","11/May/15 21:16;busbey;canceling patch for rework into positive flag for moving.","16/May/15 07:06;busbey;the jenkins jobs have all had --mv-patch-dir added.

-02
  * flip the opt in/out. no moving the dir by default now
  * change nested ifs to a compound check","16/May/15 07:10;hadoopqa;(!) A patch to test-patch or smart-apply-patch has been detected. 
Re-executing against the patched versions to perform further tests. 
The console is at https://builds.apache.org/job/PreCommit-HADOOP-Build/6710/console in case of problems.","16/May/15 07:11;hadoopqa;\\
\\
| (/) *{color:green}+1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | reexec |   0m  0s | dev-support patch detected. |
| {color:blue}0{color} | pre-patch |   0m  0s | Pre-patch trunk compilation is healthy. |
| {color:blue}0{color} | @author |   0m  0s | Skipping @author checks as test-patch has been patched. |
| {color:green}+1{color} | release audit |   0m 19s | The applied patch does not increase the total number of release audit warnings. |
| {color:green}+1{color} | shellcheck |   0m  8s | There were no new shellcheck (v0.3.3) issues. |
| {color:green}+1{color} | whitespace |   0m  0s | The patch has no lines that end in whitespace. |
| | |   0m 30s | |
\\
\\
|| Subsystem || Report/Notes ||
| Patch URL | http://issues.apache.org/jira/secure/attachment/12733308/HADOOP-11944.2.patch |
| Optional Tests | shellcheck |
| git revision | trunk / b0ad644 |
| Java | 1.7.0_55 |
| uname | Linux asf909.gq1.ygridcore.net 3.13.0-36-lowlatency #63-Ubuntu SMP PREEMPT Wed Sep 3 21:56:12 UTC 2014 x86_64 x86_64 x86_64 GNU/Linux |
| Console output | https://builds.apache.org/job/PreCommit-HADOOP-Build/6710/console |


This message was automatically generated.","18/May/15 16:14;aw;+1 committed

thanks!","18/May/15 16:23;hudson;FAILURE: Integrated in Hadoop-trunk-Commit #7853 (See [https://builds.apache.org/job/Hadoop-trunk-Commit/7853/])
HADOOP-11944. add option to test-patch to avoid relocating patch process directory (Sean Busbey via aw) (aw: rev bcc17866ddb616e8c70e5aa044becd7a7d1bee35)
* hadoop-common-project/hadoop-common/CHANGES.txt
* dev-support/test-patch.sh
","19/May/15 11:39;hudson;FAILURE: Integrated in Hadoop-Yarn-trunk #932 (See [https://builds.apache.org/job/Hadoop-Yarn-trunk/932/])
HADOOP-11944. add option to test-patch to avoid relocating patch process directory (Sean Busbey via aw) (aw: rev bcc17866ddb616e8c70e5aa044becd7a7d1bee35)
* hadoop-common-project/hadoop-common/CHANGES.txt
* dev-support/test-patch.sh
","19/May/15 11:54;hudson;SUCCESS: Integrated in Hadoop-Yarn-trunk-Java8 #201 (See [https://builds.apache.org/job/Hadoop-Yarn-trunk-Java8/201/])
HADOOP-11944. add option to test-patch to avoid relocating patch process directory (Sean Busbey via aw) (aw: rev bcc17866ddb616e8c70e5aa044becd7a7d1bee35)
* dev-support/test-patch.sh
* hadoop-common-project/hadoop-common/CHANGES.txt
","19/May/15 14:22;hudson;FAILURE: Integrated in Hadoop-Hdfs-trunk #2130 (See [https://builds.apache.org/job/Hadoop-Hdfs-trunk/2130/])
HADOOP-11944. add option to test-patch to avoid relocating patch process directory (Sean Busbey via aw) (aw: rev bcc17866ddb616e8c70e5aa044becd7a7d1bee35)
* dev-support/test-patch.sh
* hadoop-common-project/hadoop-common/CHANGES.txt
","19/May/15 14:29;hudson;FAILURE: Integrated in Hadoop-Hdfs-trunk-Java8 #190 (See [https://builds.apache.org/job/Hadoop-Hdfs-trunk-Java8/190/])
HADOOP-11944. add option to test-patch to avoid relocating patch process directory (Sean Busbey via aw) (aw: rev bcc17866ddb616e8c70e5aa044becd7a7d1bee35)
* hadoop-common-project/hadoop-common/CHANGES.txt
* dev-support/test-patch.sh
","19/May/15 15:16;hudson;SUCCESS: Integrated in Hadoop-Mapreduce-trunk-Java8 #200 (See [https://builds.apache.org/job/Hadoop-Mapreduce-trunk-Java8/200/])
HADOOP-11944. add option to test-patch to avoid relocating patch process directory (Sean Busbey via aw) (aw: rev bcc17866ddb616e8c70e5aa044becd7a7d1bee35)
* hadoop-common-project/hadoop-common/CHANGES.txt
* dev-support/test-patch.sh
","19/May/15 15:33;hudson;FAILURE: Integrated in Hadoop-Mapreduce-trunk #2148 (See [https://builds.apache.org/job/Hadoop-Mapreduce-trunk/2148/])
HADOOP-11944. add option to test-patch to avoid relocating patch process directory (Sean Busbey via aw) (aw: rev bcc17866ddb616e8c70e5aa044becd7a7d1bee35)
* dev-support/test-patch.sh
* hadoop-common-project/hadoop-common/CHANGES.txt
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
determine-flaky-tests needs a summary mode,HADOOP-11965,12829347,Test,Resolved,HADOOP,Hadoop Common,software,omalley,Hadoop Common is the common library for Apache Hadoop.,http://hadoop.apache.org/,Minor,Fixed,yufeigu,aw,aw,12/May/15 21:32,30/Aug/16 01:27,12/Jan/21 11:55,18/Jun/15 04:12,,,,,2.8.0,3.0.0-alpha1,,,,,,,,,0,,,"Running determine-flaky-tests against PreCommit-HDFS-Build generates just slightly under 10,000 lines of output.  That's significantly too much to be useful for the casual user.  It's also not formatted in such a way to be easily machine parseable to generate a decent report.  A summary mode should be added that just prints out the top X failed tests.",,aajisaka,aw,hudson,yufeigu,yzhangal,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"15/Jun/15 23:12;yufeigu;HADOOP-11965.001.patch;https://issues.apache.org/jira/secure/attachment/12739719/HADOOP-11965.001.patch","16/Jun/15 16:24;yufeigu;HADOOP-11965.002.patch;https://issues.apache.org/jira/secure/attachment/12739890/HADOOP-11965.002.patch","17/Jun/15 22:34;yufeigu;HADOOP-11965.003.patch;https://issues.apache.org/jira/secure/attachment/12740231/HADOOP-11965.003.patch",,,,,,,,,,,,,,,,,,,,,3.0,,,,,,,,,,,,,,,,,,,,2015-05-13 07:45:12.433,,,false,,,,,,,,,,,,,,,,,9223372036854775807,Reviewed,,,,Thu Jun 18 21:39:54 UTC 2015,,,,,,,"0|i2en9r:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,"13/May/15 07:45;yzhangal;Thanks [~aw] for reporting the issue, I assigned it to myself and will try to work on it asap.
","15/Jun/15 18:54;yzhangal;Yufei showed interest working on the improvement here, I'm assigning to him. Thanks Yufei.
","15/Jun/15 23:19;hadoopqa;\\
\\
| (/) *{color:green}+1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | pre-patch |   0m  0s | Pre-patch trunk compilation is healthy. |
| {color:green}+1{color} | @author |   0m  0s | The patch does not contain any @author tags. |
| {color:green}+1{color} | release audit |   0m 14s | The applied patch does not increase the total number of release audit warnings. |
| {color:green}+1{color} | whitespace |   0m  0s | The patch has no lines that end in whitespace. |
| | |   0m 17s | |
\\
\\
|| Subsystem || Report/Notes ||
| Patch URL | http://issues.apache.org/jira/secure/attachment/12739719/HADOOP-11965.001.patch |
| Optional Tests |  |
| git revision | trunk / 2cb09e9 |
| Java | 1.7.0_55 |
| uname | Linux asf907.gq1.ygridcore.net 3.13.0-36-lowlatency #63-Ubuntu SMP PREEMPT Wed Sep 3 21:56:12 UTC 2014 x86_64 x86_64 x86_64 GNU/Linux |
| Console output | https://builds.apache.org/job/PreCommit-HADOOP-Build/6968/console |


This message was automatically generated.","16/Jun/15 06:12;yzhangal;HI [~yufeigu],

Thanks for the patch. It looks good, only a few nits/suggestions:
* change DEFAULT_TOP_LINE_NUM to DEFAULT_TOP_NUM_FAILED_TESTS (imagine we may report multiple lines for one test in the future)
* change num_line to num_failed_tests
* change error_num to error_count (not to confuse with errno)
* About ""Among x runs examined, top y failed tests ..."". The y here need to consider the case that when y is bigger than total number of failed tests. Suggest to change to ""Among x runs examined, y tests failed, and the top z failed tests are (<#failedRuns: testName>):"", where y is the total number of failed tests, and make the z here MIN(z, y).
* In non-summary mode, modify the report to ""Among x runs examined,  all y failed tests are (<#failedRuns: testName>):
*
{code}
logging.info(""\n"" + str(error_num) + "" errors found, check error details with non summary mode.""
{code}
Change to 
{code}
logging.info(""\n"" + str(error_num) + "" errors found,  you may re-run in non summary mode to see error details.""
{code}

Thanks.


","16/Jun/15 06:41;yufeigu;Hi Yongjun,

Thanks for the detailed review and all these good suggestion. I will add a new patch after modification.","16/Jun/15 16:24;yufeigu;Hi Yongjun,

About the ""Among x runs examined, top y failed tests ..."", it might be better if the program print out ""all failed tests ..."" if the y is bigger than the total number of failed tests. I've made these changes. Check the HADOOP-11965.002.patch for details.","16/Jun/15 16:32;hadoopqa;\\
\\
| (/) *{color:green}+1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | pre-patch |   0m  0s | Pre-patch trunk compilation is healthy. |
| {color:green}+1{color} | @author |   0m  0s | The patch does not contain any @author tags. |
| {color:green}+1{color} | release audit |   0m 27s | The applied patch does not increase the total number of release audit warnings. |
| {color:green}+1{color} | whitespace |   0m  0s | The patch has no lines that end in whitespace. |
| | |   0m 35s | |
\\
\\
|| Subsystem || Report/Notes ||
| Patch URL | http://issues.apache.org/jira/secure/attachment/12739890/HADOOP-11965.002.patch |
| Optional Tests |  |
| git revision | trunk / b039e69 |
| Java | 1.7.0_55 |
| uname | Linux asf906.gq1.ygridcore.net 3.13.0-36-lowlatency #63-Ubuntu SMP PREEMPT Wed Sep 3 21:56:12 UTC 2014 x86_64 x86_64 x86_64 GNU/Linux |
| Console output | https://builds.apache.org/job/PreCommit-HADOOP-Build/6972/console |


This message was automatically generated.","17/Jun/15 05:53;yzhangal;Hi [~yufeigu],

Thanks for the new rev. LGTM. 

Hi [~aw], thank you for reporting the issue. I'm +1 on rev 002. I'd like to commit it some time tomorrow. Would you please let me know if you have any comments?

Thanks.
","17/Jun/15 22:01;yzhangal;Hi [~yufeigu],

I noticed some lines involved in the change exceeded 80 chars per line, would you please create a new rev with this fixed?

Thanks and sorry for not pointing this out earlier.
","18/Jun/15 02:29;hadoopqa;\\
\\
| (/) *{color:green}+1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | pre-patch |   0m  0s | Pre-patch trunk compilation is healthy. |
| {color:green}+1{color} | @author |   0m  0s | The patch does not contain any @author tags. |
| {color:green}+1{color} | release audit |   0m 16s | The applied patch does not increase the total number of release audit warnings. |
| {color:green}+1{color} | whitespace |   0m  0s | The patch has no lines that end in whitespace. |
| | |   0m 20s | |
\\
\\
|| Subsystem || Report/Notes ||
| Patch URL | http://issues.apache.org/jira/secure/attachment/12740231/HADOOP-11965.003.patch |
| Optional Tests |  |
| git revision | trunk / cc43288 |
| Java | 1.7.0_55 |
| uname | Linux asf909.gq1.ygridcore.net 3.13.0-36-lowlatency #63-Ubuntu SMP PREEMPT Wed Sep 3 21:56:12 UTC 2014 x86_64 x86_64 x86_64 GNU/Linux |
| Console output | https://builds.apache.org/job/PreCommit-HADOOP-Build/6985/console |


This message was automatically generated.","18/Jun/15 04:12;yzhangal;I committed to trunk and branch-2. Thanks Yufei much for the contribution.


","18/Jun/15 08:33;hudson;FAILURE: Integrated in Hadoop-trunk-Commit #8036 (See [https://builds.apache.org/job/Hadoop-trunk-Commit/8036/])
HADOOP-11965. determine-flaky-tests needs a summary mode. Contributed by Yufei Gu, (yzhang: rev 74351af3b7521b194116258c96270ddaeccd8126)
* hadoop-common-project/hadoop-common/CHANGES.txt
* dev-support/determine-flaky-tests-hadoop.py
","18/Jun/15 14:15;hudson;FAILURE: Integrated in Hadoop-Yarn-trunk #962 (See [https://builds.apache.org/job/Hadoop-Yarn-trunk/962/])
HADOOP-11965. determine-flaky-tests needs a summary mode. Contributed by Yufei Gu, (yzhang: rev 74351af3b7521b194116258c96270ddaeccd8126)
* dev-support/determine-flaky-tests-hadoop.py
* hadoop-common-project/hadoop-common/CHANGES.txt
","18/Jun/15 14:31;hudson;FAILURE: Integrated in Hadoop-Yarn-trunk-Java8 #232 (See [https://builds.apache.org/job/Hadoop-Yarn-trunk-Java8/232/])
HADOOP-11965. determine-flaky-tests needs a summary mode. Contributed by Yufei Gu, (yzhang: rev 74351af3b7521b194116258c96270ddaeccd8126)
* dev-support/determine-flaky-tests-hadoop.py
* hadoop-common-project/hadoop-common/CHANGES.txt
","18/Jun/15 18:11;hudson;SUCCESS: Integrated in Hadoop-Hdfs-trunk #2160 (See [https://builds.apache.org/job/Hadoop-Hdfs-trunk/2160/])
HADOOP-11965. determine-flaky-tests needs a summary mode. Contributed by Yufei Gu, (yzhang: rev 74351af3b7521b194116258c96270ddaeccd8126)
* dev-support/determine-flaky-tests-hadoop.py
* hadoop-common-project/hadoop-common/CHANGES.txt
","18/Jun/15 19:08;hudson;SUCCESS: Integrated in Hadoop-Hdfs-trunk-Java8 #221 (See [https://builds.apache.org/job/Hadoop-Hdfs-trunk-Java8/221/])
HADOOP-11965. determine-flaky-tests needs a summary mode. Contributed by Yufei Gu, (yzhang: rev 74351af3b7521b194116258c96270ddaeccd8126)
* hadoop-common-project/hadoop-common/CHANGES.txt
* dev-support/determine-flaky-tests-hadoop.py
","18/Jun/15 21:31;hudson;FAILURE: Integrated in Hadoop-Mapreduce-trunk-Java8 #230 (See [https://builds.apache.org/job/Hadoop-Mapreduce-trunk-Java8/230/])
HADOOP-11965. determine-flaky-tests needs a summary mode. Contributed by Yufei Gu, (yzhang: rev 74351af3b7521b194116258c96270ddaeccd8126)
* hadoop-common-project/hadoop-common/CHANGES.txt
* dev-support/determine-flaky-tests-hadoop.py
","18/Jun/15 21:39;hudson;FAILURE: Integrated in Hadoop-Mapreduce-trunk #2178 (See [https://builds.apache.org/job/Hadoop-Mapreduce-trunk/2178/])
HADOOP-11965. determine-flaky-tests needs a summary mode. Contributed by Yufei Gu, (yzhang: rev 74351af3b7521b194116258c96270ddaeccd8126)
* dev-support/determine-flaky-tests-hadoop.py
* hadoop-common-project/hadoop-common/CHANGES.txt
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Run checkstyle on test source files,HADOOP-12701,12929056,Test,Resolved,HADOOP,Hadoop Common,software,omalley,Hadoop Common is the common library for Apache Hadoop.,http://hadoop.apache.org/,Minor,Fixed,jzhuge,jzhuge,jzhuge,11/Jan/16 01:03,30/Aug/16 01:20,12/Jan/21 11:55,07/May/16 00:21,,,,,2.9.0,3.0.0-alpha1,,,,,,,,,0,,,"Test source files are not checked by checkstyle because Maven checkstyle plugin parameter *includeTestSourceDirectory* is *false* by default.

Propose to enable checkstyle on test source files in order to improve the quality of unit tests.",,andrew.wang,aw,hudson,jzhuge,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,HADOOP-12700,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"11/Jan/16 01:19;jzhuge;HADOOP-12701.001.patch;https://issues.apache.org/jira/secure/attachment/12781478/HADOOP-12701.001.patch",,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,2016-01-11 03:38:45.102,,,false,,,,,,,,,,,,,,,,,9223372036854775807,,,,,Sat May 07 02:06:57 UTC 2016,,,,,,,"0|i2r3zr:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,"11/Jan/16 01:19;jzhuge;After the fix, mvn checkstyle:checkstyle for entire Hadoop tree took 01:27 min on my Macbook Pro. In comparison, it took 38.677 s before.","11/Jan/16 01:27;jzhuge;Let me know if the proposed change has any unintended side affect since it does have global impact on all Hadoop components.","11/Jan/16 02:01;jzhuge;As an alternative, we can change Maven checkstyle plugin parameter *includeTestSourceDirectory* to *true* by default, but that will even have a much wider impact beyond Hadoop project.","11/Jan/16 02:15;jzhuge;Another alternative: test-patch uses a custom configuration that sets includeTestSourceDirectory to true. Not savory IMHO. What do you think, [~aw]?","11/Jan/16 03:38;hadoopqa;| (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue} 0m 0s {color} | {color:blue} Docker mode activated. {color} |
| {color:green}+1{color} | {color:green} @author {color} | {color:green} 0m 0s {color} | {color:green} The patch does not contain any @author tags. {color} |
| {color:red}-1{color} | {color:red} test4tests {color} | {color:red} 0m 0s {color} | {color:red} The patch doesn't appear to include any new or modified tests. Please justify why no new tests are needed for this patch. Also please list what manual steps were performed to verify this patch. {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 8m 2s {color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 8m 56s {color} | {color:green} trunk passed with JDK v1.8.0_66 {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 9m 33s {color} | {color:green} trunk passed with JDK v1.7.0_91 {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green} 10m 15s {color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green} 0m 42s {color} | {color:green} trunk passed {color} |
| {color:red}-1{color} | {color:red} javadoc {color} | {color:red} 4m 10s {color} | {color:red} root in trunk failed with JDK v1.8.0_66. {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 10m 16s {color} | {color:green} trunk passed with JDK v1.7.0_91 {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 8m 4s {color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 8m 56s {color} | {color:green} the patch passed with JDK v1.8.0_66 {color} |
| {color:green}+1{color} | {color:green} javac {color} | {color:green} 8m 56s {color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 9m 31s {color} | {color:green} the patch passed with JDK v1.7.0_91 {color} |
| {color:green}+1{color} | {color:green} javac {color} | {color:green} 9m 31s {color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green} 10m 10s {color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green} 0m 40s {color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} whitespace {color} | {color:green} 0m 0s {color} | {color:green} Patch has no whitespace issues. {color} |
| {color:green}+1{color} | {color:green} xml {color} | {color:green} 0m 1s {color} | {color:green} The patch has no ill-formed XML file. {color} |
| {color:red}-1{color} | {color:red} javadoc {color} | {color:red} 4m 15s {color} | {color:red} root in the patch failed with JDK v1.8.0_66. {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 9m 50s {color} | {color:green} the patch passed with JDK v1.7.0_91 {color} |
| {color:red}-1{color} | {color:red} unit {color} | {color:red} 12m 31s {color} | {color:red} root in the patch failed with JDK v1.8.0_66. {color} |
| {color:red}-1{color} | {color:red} unit {color} | {color:red} 12m 42s {color} | {color:red} root in the patch failed with JDK v1.7.0_91. {color} |
| {color:green}+1{color} | {color:green} asflicense {color} | {color:green} 0m 23s {color} | {color:green} Patch does not generate ASF License warnings. {color} |
| {color:black}{color} | {color:black} {color} | {color:black} 130m 5s {color} | {color:black} {color} |
\\
\\
|| Reason || Tests ||
| JDK v1.8.0_66 Failed junit tests | hadoop.ha.TestZKFailoverController |
|   | hadoop.ipc.TestIPC |
| JDK v1.7.0_91 Failed junit tests | hadoop.metrics2.impl.TestGangliaMetrics |
|   | hadoop.fs.TestSymlinkLocalFSFileSystem |
\\
\\
|| Subsystem || Report/Notes ||
| Docker |  Image:yetus/hadoop:0ca8df7 |
| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12781478/HADOOP-12701.001.patch |
| JIRA Issue | HADOOP-12701 |
| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  xml  |
| uname | Linux 5e7d6ff21362 3.13.0-36-lowlatency #63-Ubuntu SMP PREEMPT Wed Sep 3 21:56:12 UTC 2014 x86_64 x86_64 x86_64 GNU/Linux |
| Build tool | maven |
| Personality | /testptch/hadoop/patchprocess/precommit/personality/provided.sh |
| git revision | trunk / 0e76f1f |
| Default Java | 1.7.0_91 |
| Multi-JDK versions |  /usr/lib/jvm/java-8-oracle:1.8.0_66 /usr/lib/jvm/java-7-openjdk-amd64:1.7.0_91 |
| javadoc | https://builds.apache.org/job/PreCommit-HADOOP-Build/8379/artifact/patchprocess/branch-javadoc-root-jdk1.8.0_66.txt |
| javadoc | https://builds.apache.org/job/PreCommit-HADOOP-Build/8379/artifact/patchprocess/patch-javadoc-root-jdk1.8.0_66.txt |
| unit | https://builds.apache.org/job/PreCommit-HADOOP-Build/8379/artifact/patchprocess/patch-unit-root-jdk1.8.0_66.txt |
| unit | https://builds.apache.org/job/PreCommit-HADOOP-Build/8379/artifact/patchprocess/patch-unit-root-jdk1.7.0_91.txt |
| unit test logs |  https://builds.apache.org/job/PreCommit-HADOOP-Build/8379/artifact/patchprocess/patch-unit-root-jdk1.8.0_66.txt https://builds.apache.org/job/PreCommit-HADOOP-Build/8379/artifact/patchprocess/patch-unit-root-jdk1.7.0_91.txt |
| JDK v1.7.0_91  Test Results | https://builds.apache.org/job/PreCommit-HADOOP-Build/8379/testReport/ |
| modules | C: . U: . |
| Max memory used | 116MB |
| Powered by | Apache Yetus 0.2.0-SNAPSHOT   http://yetus.apache.org |
| Console output | https://builds.apache.org/job/PreCommit-HADOOP-Build/8379/console |


This message was automatically generated.

","11/Jan/16 19:20;aw;It doesn't make sense to only enable it for test-patch if it is meant to be enforced at all.  So this is an all or nothing type of change.","12/Jan/16 15:27;jzhuge;Thanks, [~aw].","12/Jan/16 15:29;jzhuge;[~stevel@apache.org],

Could you review this fix, to prevent problem like [HADOOP-12700] from happening?

It will help improve the quality of test code while doubling the time to run checkstyle.

Thanks,
John.","24/Mar/16 04:33;jzhuge;Test the patch on Ubuntu VirtualBox VM under MacBook. Before the patch, it took 1:10.947 s to run {{mvn clean checkstyle:checkstyle}}; after the patch, the same command took 1:26.765 s.

Test the patch on MacBook. Before the patch, it took 41.425 s to run {{mvn clean checkstyle:checkstyle}}; after the patch, the same command took 50.394 s.","24/Mar/16 09:16;hadoopqa;| (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue} 0m 21s {color} | {color:blue} Docker mode activated. {color} |
| {color:green}+1{color} | {color:green} @author {color} | {color:green} 0m 0s {color} | {color:green} The patch does not contain any @author tags. {color} |
| {color:red}-1{color} | {color:red} test4tests {color} | {color:red} 0m 0s {color} | {color:red} The patch doesn't appear to include any new or modified tests. Please justify why no new tests are needed for this patch. Also please list what manual steps were performed to verify this patch. {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 9m 33s {color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 12m 2s {color} | {color:green} trunk passed with JDK v1.8.0_74 {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 10m 21s {color} | {color:green} trunk passed with JDK v1.7.0_95 {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green} 12m 59s {color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green} 1m 1s {color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 9m 46s {color} | {color:green} trunk passed with JDK v1.8.0_74 {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 13m 26s {color} | {color:green} trunk passed with JDK v1.7.0_95 {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 9m 34s {color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 11m 47s {color} | {color:green} the patch passed with JDK v1.8.0_74 {color} |
| {color:green}+1{color} | {color:green} javac {color} | {color:green} 11m 47s {color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 10m 21s {color} | {color:green} the patch passed with JDK v1.7.0_95 {color} |
| {color:green}+1{color} | {color:green} javac {color} | {color:green} 10m 21s {color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green} 12m 27s {color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green} 0m 54s {color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} whitespace {color} | {color:green} 0m 0s {color} | {color:green} Patch has no whitespace issues. {color} |
| {color:green}+1{color} | {color:green} xml {color} | {color:green} 0m 1s {color} | {color:green} The patch has no ill-formed XML file. {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 9m 37s {color} | {color:green} the patch passed with JDK v1.8.0_74 {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 13m 11s {color} | {color:green} the patch passed with JDK v1.7.0_95 {color} |
| {color:red}-1{color} | {color:red} unit {color} | {color:red} 15m 58s {color} | {color:red} root in the patch failed with JDK v1.8.0_74. {color} |
| {color:red}-1{color} | {color:red} unit {color} | {color:red} 15m 10s {color} | {color:red} root in the patch failed with JDK v1.7.0_95. {color} |
| {color:red}-1{color} | {color:red} asflicense {color} | {color:red} 0m 32s {color} | {color:red} Patch generated 2 ASF License warnings. {color} |
| {color:black}{color} | {color:black} {color} | {color:black} 170m 39s {color} | {color:black} {color} |
\\
\\
|| Reason || Tests ||
| JDK v1.8.0_74 Failed junit tests | hadoop.ipc.TestRPCWaitForProxy |
|   | hadoop.fs.shell.find.TestIname |
|   | hadoop.fs.shell.find.TestPrint0 |
|   | hadoop.fs.shell.find.TestPrint |
| JDK v1.8.0_74 Timed out junit tests | org.apache.hadoop.util.TestNativeLibraryChecker |
| JDK v1.7.0_95 Timed out junit tests | org.apache.hadoop.util.TestNativeLibraryChecker |
\\
\\
|| Subsystem || Report/Notes ||
| Docker |  Image:yetus/hadoop:fbe3e86 |
| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12781478/HADOOP-12701.001.patch |
| JIRA Issue | HADOOP-12701 |
| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  xml  |
| uname | Linux 984c60f1dd32 3.13.0-36-lowlatency #63-Ubuntu SMP PREEMPT Wed Sep 3 21:56:12 UTC 2014 x86_64 x86_64 x86_64 GNU/Linux |
| Build tool | maven |
| Personality | /testptch/hadoop/patchprocess/precommit/personality/provided.sh |
| git revision | trunk / 19b645c |
| Default Java | 1.7.0_95 |
| Multi-JDK versions |  /usr/lib/jvm/java-8-oracle:1.8.0_74 /usr/lib/jvm/java-7-openjdk-amd64:1.7.0_95 |
| unit | https://builds.apache.org/job/PreCommit-HADOOP-Build/8909/artifact/patchprocess/patch-unit-root-jdk1.8.0_74.txt |
| unit | https://builds.apache.org/job/PreCommit-HADOOP-Build/8909/artifact/patchprocess/patch-unit-root-jdk1.7.0_95.txt |
| unit test logs |  https://builds.apache.org/job/PreCommit-HADOOP-Build/8909/artifact/patchprocess/patch-unit-root-jdk1.8.0_74.txt https://builds.apache.org/job/PreCommit-HADOOP-Build/8909/artifact/patchprocess/patch-unit-root-jdk1.7.0_95.txt |
| JDK v1.7.0_95  Test Results | https://builds.apache.org/job/PreCommit-HADOOP-Build/8909/testReport/ |
| asflicense | https://builds.apache.org/job/PreCommit-HADOOP-Build/8909/artifact/patchprocess/patch-asflicense-problems.txt |
| modules | C: . U: . |
| Console output | https://builds.apache.org/job/PreCommit-HADOOP-Build/8909/console |
| Powered by | Apache Yetus 0.2.0   http://yetus.apache.org |


This message was automatically generated.

","24/Mar/16 16:54;hadoopqa;| (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue} 0m 10s {color} | {color:blue} Docker mode activated. {color} |
| {color:green}+1{color} | {color:green} @author {color} | {color:green} 0m 0s {color} | {color:green} The patch does not contain any @author tags. {color} |
| {color:red}-1{color} | {color:red} test4tests {color} | {color:red} 0m 0s {color} | {color:red} The patch doesn't appear to include any new or modified tests. Please justify why no new tests are needed for this patch. Also please list what manual steps were performed to verify this patch. {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 6m 40s {color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 6m 8s {color} | {color:green} trunk passed with JDK v1.8.0_74 {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 6m 50s {color} | {color:green} trunk passed with JDK v1.7.0_95 {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green} 9m 5s {color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green} 0m 40s {color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 5m 41s {color} | {color:green} trunk passed with JDK v1.8.0_74 {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 9m 23s {color} | {color:green} trunk passed with JDK v1.7.0_95 {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 6m 43s {color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 6m 12s {color} | {color:green} the patch passed with JDK v1.8.0_74 {color} |
| {color:green}+1{color} | {color:green} javac {color} | {color:green} 6m 12s {color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 6m 55s {color} | {color:green} the patch passed with JDK v1.7.0_95 {color} |
| {color:green}+1{color} | {color:green} javac {color} | {color:green} 6m 55s {color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green} 9m 8s {color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green} 0m 38s {color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} whitespace {color} | {color:green} 0m 0s {color} | {color:green} Patch has no whitespace issues. {color} |
| {color:green}+1{color} | {color:green} xml {color} | {color:green} 0m 1s {color} | {color:green} The patch has no ill-formed XML file. {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 5m 34s {color} | {color:green} the patch passed with JDK v1.8.0_74 {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 9m 29s {color} | {color:green} the patch passed with JDK v1.7.0_95 {color} |
| {color:red}-1{color} | {color:red} unit {color} | {color:red} 10m 45s {color} | {color:red} root in the patch failed with JDK v1.8.0_74. {color} |
| {color:red}-1{color} | {color:red} unit {color} | {color:red} 11m 31s {color} | {color:red} root in the patch failed with JDK v1.7.0_95. {color} |
| {color:red}-1{color} | {color:red} asflicense {color} | {color:red} 0m 22s {color} | {color:red} Patch generated 2 ASF License warnings. {color} |
| {color:black}{color} | {color:black} {color} | {color:black} 112m 49s {color} | {color:black} {color} |
\\
\\
|| Reason || Tests ||
| JDK v1.8.0_74 Failed junit tests | hadoop.metrics2.impl.TestGangliaMetrics |
| JDK v1.8.0_74 Timed out junit tests | org.apache.hadoop.util.TestNativeLibraryChecker |
| JDK v1.7.0_95 Timed out junit tests | org.apache.hadoop.util.TestNativeLibraryChecker |
\\
\\
|| Subsystem || Report/Notes ||
| Docker |  Image:yetus/hadoop:fbe3e86 |
| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12781478/HADOOP-12701.001.patch |
| JIRA Issue | HADOOP-12701 |
| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  xml  |
| uname | Linux 6f971d3cc8e0 3.13.0-36-lowlatency #63-Ubuntu SMP PREEMPT Wed Sep 3 21:56:12 UTC 2014 x86_64 x86_64 x86_64 GNU/Linux |
| Build tool | maven |
| Personality | /testptch/hadoop/patchprocess/precommit/personality/provided.sh |
| git revision | trunk / 19b645c |
| Default Java | 1.7.0_95 |
| Multi-JDK versions |  /usr/lib/jvm/java-8-oracle:1.8.0_74 /usr/lib/jvm/java-7-openjdk-amd64:1.7.0_95 |
| unit | https://builds.apache.org/job/PreCommit-HADOOP-Build/8913/artifact/patchprocess/patch-unit-root-jdk1.8.0_74.txt |
| unit | https://builds.apache.org/job/PreCommit-HADOOP-Build/8913/artifact/patchprocess/patch-unit-root-jdk1.7.0_95.txt |
| unit test logs |  https://builds.apache.org/job/PreCommit-HADOOP-Build/8913/artifact/patchprocess/patch-unit-root-jdk1.8.0_74.txt https://builds.apache.org/job/PreCommit-HADOOP-Build/8913/artifact/patchprocess/patch-unit-root-jdk1.7.0_95.txt |
| JDK v1.7.0_95  Test Results | https://builds.apache.org/job/PreCommit-HADOOP-Build/8913/testReport/ |
| asflicense | https://builds.apache.org/job/PreCommit-HADOOP-Build/8913/artifact/patchprocess/patch-asflicense-problems.txt |
| modules | C: . U: . |
| Console output | https://builds.apache.org/job/PreCommit-HADOOP-Build/8913/console |
| Powered by | Apache Yetus 0.2.0   http://yetus.apache.org |


This message was automatically generated.

","28/Mar/16 22:01;andrew.wang;This change seems fine, I'm not too worried about adding 10s of seconds to checkstyle runs.

However, why aren't we seeing checkstyle run by precommit? Do we need to add a space to a java file somewhere to trigger change detection?","05/May/16 23:14;jzhuge;@andrew wang Maven checkstyle plugin does not run on test source files by default.","05/May/16 23:15;jzhuge;[~andrew.wang] Maven checkstyle plugin does not run on test source files by default.","07/May/16 00:19;andrew.wang;LGTM then, let's get this in. Thanks John!","07/May/16 00:21;andrew.wang;Committed, thanks John!","07/May/16 00:39;jzhuge;Thanks [~andrew.wang]!","07/May/16 02:06;hudson;FAILURE: Integrated in Hadoop-trunk-Commit #9732 (See [https://builds.apache.org/job/Hadoop-trunk-Commit/9732/])
HADOOP-12701. Run checkstyle on test source files. Contributed by John (wang: rev e097c9a124dc0b9ae9076994d19663f29d771ef0)
* pom.xml
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Create unit test to automatically compare Common related classes and core-default.xml,HADOOP-12738,12933649,Test,Resolved,HADOOP,Hadoop Common,software,omalley,Hadoop Common is the common library for Apache Hadoop.,http://hadoop.apache.org/,Minor,Fixed,rchiang,rchiang,rchiang,24/Jan/16 07:27,30/Aug/16 01:19,12/Jan/21 11:55,27/Apr/16 02:22,2.7.1,,,,2.8.0,3.0.0-alpha1,,,,,,,,,0,supportability,,Create a unit test that will automatically compare the fields in the various Common related classes and core-default.xml. It should throw an error if a property is missing in either the class or the file.,,hudson,iwasakims,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"24/Jan/16 07:28;rchiang;HADOOP-12738.001.patch;https://issues.apache.org/jira/secure/attachment/12784050/HADOOP-12738.001.patch","04/Mar/16 19:41;rchiang;HADOOP-12738.002.patch;https://issues.apache.org/jira/secure/attachment/12791523/HADOOP-12738.002.patch","25/Apr/16 16:41;rchiang;HADOOP-12738.003.patch;https://issues.apache.org/jira/secure/attachment/12800560/HADOOP-12738.003.patch",,,,,,,,,,,,,,,,,,,,,3.0,,,,,,,,,,,,,,,,,,,,2016-01-24 08:54:24.369,,,false,,,,,,,,,,,,,,,,,9223372036854775807,Reviewed,,,,Thu Apr 28 17:11:08 UTC 2016,,,,,,,"0|i2rwan:",9223372036854775807,,,,,,,,,,,,,2.8.0,,,,,,,,,,"24/Jan/16 07:29;rchiang;Submit initial version for testing.  This will flag any properties in the core-default.xml file that are missing from the list of classes read.

This version does not check the S3 related properties, since those are in various subprojects.","24/Jan/16 08:54;hadoopqa;| (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue} 0m 0s {color} | {color:blue} Docker mode activated. {color} |
| {color:green}+1{color} | {color:green} @author {color} | {color:green} 0m 0s {color} | {color:green} The patch does not contain any @author tags. {color} |
| {color:green}+1{color} | {color:green} test4tests {color} | {color:green} 0m 0s {color} | {color:green} The patch appears to include 1 new or modified test files. {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 7m 56s {color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 6m 47s {color} | {color:green} trunk passed with JDK v1.8.0_66 {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 7m 26s {color} | {color:green} trunk passed with JDK v1.7.0_91 {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green} 0m 16s {color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green} 1m 7s {color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green} 0m 14s {color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green} 1m 56s {color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 0m 55s {color} | {color:green} trunk passed with JDK v1.8.0_66 {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 1m 5s {color} | {color:green} trunk passed with JDK v1.7.0_91 {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 1m 37s {color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 6m 39s {color} | {color:green} the patch passed with JDK v1.8.0_66 {color} |
| {color:green}+1{color} | {color:green} javac {color} | {color:green} 6m 39s {color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 7m 24s {color} | {color:green} the patch passed with JDK v1.7.0_91 {color} |
| {color:green}+1{color} | {color:green} javac {color} | {color:green} 7m 24s {color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green} 0m 16s {color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green} 1m 7s {color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green} 0m 14s {color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} whitespace {color} | {color:green} 0m 0s {color} | {color:green} Patch has no whitespace issues. {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green} 2m 13s {color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 0m 56s {color} | {color:green} the patch passed with JDK v1.8.0_66 {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 1m 7s {color} | {color:green} the patch passed with JDK v1.7.0_91 {color} |
| {color:red}-1{color} | {color:red} unit {color} | {color:red} 17m 4s {color} | {color:red} hadoop-common in the patch failed with JDK v1.8.0_66. {color} |
| {color:red}-1{color} | {color:red} unit {color} | {color:red} 7m 43s {color} | {color:red} hadoop-common in the patch failed with JDK v1.7.0_91. {color} |
| {color:green}+1{color} | {color:green} asflicense {color} | {color:green} 0m 23s {color} | {color:green} Patch does not generate ASF License warnings. {color} |
| {color:black}{color} | {color:black} {color} | {color:black} 75m 43s {color} | {color:black} {color} |
\\
\\
|| Reason || Tests ||
| JDK v1.8.0_66 Failed junit tests | hadoop.metrics2.impl.TestGangliaMetrics |
| JDK v1.8.0_66 Timed out junit tests | org.apache.hadoop.http.TestHttpServerLifecycle |
| JDK v1.7.0_91 Failed junit tests | hadoop.metrics2.impl.TestGangliaMetrics |
\\
\\
|| Subsystem || Report/Notes ||
| Docker |  Image:yetus/hadoop:0ca8df7 |
| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12784050/HADOOP-12738.001.patch |
| JIRA Issue | HADOOP-12738 |
| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  findbugs  checkstyle  |
| uname | Linux 3f5cb747e540 3.13.0-36-lowlatency #63-Ubuntu SMP PREEMPT Wed Sep 3 21:56:12 UTC 2014 x86_64 x86_64 x86_64 GNU/Linux |
| Build tool | maven |
| Personality | /testptch/hadoop/patchprocess/precommit/personality/provided.sh |
| git revision | trunk / 99829eb |
| Default Java | 1.7.0_91 |
| Multi-JDK versions |  /usr/lib/jvm/java-8-oracle:1.8.0_66 /usr/lib/jvm/java-7-openjdk-amd64:1.7.0_91 |
| findbugs | v3.0.0 |
| unit | https://builds.apache.org/job/PreCommit-HADOOP-Build/8461/artifact/patchprocess/patch-unit-hadoop-common-project_hadoop-common-jdk1.8.0_66.txt |
| unit | https://builds.apache.org/job/PreCommit-HADOOP-Build/8461/artifact/patchprocess/patch-unit-hadoop-common-project_hadoop-common-jdk1.7.0_91.txt |
| unit test logs |  https://builds.apache.org/job/PreCommit-HADOOP-Build/8461/artifact/patchprocess/patch-unit-hadoop-common-project_hadoop-common-jdk1.8.0_66.txt https://builds.apache.org/job/PreCommit-HADOOP-Build/8461/artifact/patchprocess/patch-unit-hadoop-common-project_hadoop-common-jdk1.7.0_91.txt |
| JDK v1.7.0_91  Test Results | https://builds.apache.org/job/PreCommit-HADOOP-Build/8461/testReport/ |
| modules | C: hadoop-common-project/hadoop-common U: hadoop-common-project/hadoop-common |
| Max memory used | 77MB |
| Powered by | Apache Yetus 0.2.0-SNAPSHOT   http://yetus.apache.org |
| Console output | https://builds.apache.org/job/PreCommit-HADOOP-Build/8461/console |


This message was automatically generated.

","24/Jan/16 17:50;rchiang;RE: failing unit test

- HADOOP-12588 filed for TestGangliaMetrics
- TestHttpServerLifecycle unrelated test (and a timeout)
","04/Mar/16 19:41;rchiang;- Updates based on trunk updates
- Added properties in new class org.apache.hadoop.security.CompositeGroupsMapping","04/Mar/16 20:42;hadoopqa;| (/) *{color:green}+1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue} 0m 9s {color} | {color:blue} Docker mode activated. {color} |
| {color:green}+1{color} | {color:green} @author {color} | {color:green} 0m 0s {color} | {color:green} The patch does not contain any @author tags. {color} |
| {color:green}+1{color} | {color:green} test4tests {color} | {color:green} 0m 0s {color} | {color:green} The patch appears to include 2 new or modified test files. {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 6m 23s {color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 5m 35s {color} | {color:green} trunk passed with JDK v1.8.0_74 {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 6m 30s {color} | {color:green} trunk passed with JDK v1.7.0_95 {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green} 0m 20s {color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green} 0m 55s {color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green} 0m 13s {color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green} 1m 33s {color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 0m 49s {color} | {color:green} trunk passed with JDK v1.8.0_74 {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 1m 3s {color} | {color:green} trunk passed with JDK v1.7.0_95 {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 0m 40s {color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 5m 52s {color} | {color:green} the patch passed with JDK v1.8.0_74 {color} |
| {color:green}+1{color} | {color:green} javac {color} | {color:green} 5m 52s {color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 6m 45s {color} | {color:green} the patch passed with JDK v1.7.0_95 {color} |
| {color:green}+1{color} | {color:green} javac {color} | {color:green} 6m 45s {color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green} 0m 20s {color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green} 0m 55s {color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green} 0m 14s {color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} whitespace {color} | {color:green} 0m 0s {color} | {color:green} Patch has no whitespace issues. {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green} 1m 51s {color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 0m 53s {color} | {color:green} the patch passed with JDK v1.8.0_74 {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 1m 4s {color} | {color:green} the patch passed with JDK v1.7.0_95 {color} |
| {color:green}+1{color} | {color:green} unit {color} | {color:green} 6m 56s {color} | {color:green} hadoop-common in the patch passed with JDK v1.8.0_74. {color} |
| {color:green}+1{color} | {color:green} unit {color} | {color:green} 7m 15s {color} | {color:green} hadoop-common in the patch passed with JDK v1.7.0_95. {color} |
| {color:green}+1{color} | {color:green} asflicense {color} | {color:green} 0m 22s {color} | {color:green} Patch does not generate ASF License warnings. {color} |
| {color:black}{color} | {color:black} {color} | {color:black} 57m 45s {color} | {color:black} {color} |
\\
\\
|| Subsystem || Report/Notes ||
| Docker |  Image:yetus/hadoop:0ca8df7 |
| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12791523/HADOOP-12738.002.patch |
| JIRA Issue | HADOOP-12738 |
| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  findbugs  checkstyle  |
| uname | Linux 92951d995991 3.13.0-36-lowlatency #63-Ubuntu SMP PREEMPT Wed Sep 3 21:56:12 UTC 2014 x86_64 x86_64 x86_64 GNU/Linux |
| Build tool | maven |
| Personality | /testptch/hadoop/patchprocess/precommit/personality/provided.sh |
| git revision | trunk / 3e8099a |
| Default Java | 1.7.0_95 |
| Multi-JDK versions |  /usr/lib/jvm/java-8-oracle:1.8.0_74 /usr/lib/jvm/java-7-openjdk-amd64:1.7.0_95 |
| findbugs | v3.0.0 |
| JDK v1.7.0_95  Test Results | https://builds.apache.org/job/PreCommit-HADOOP-Build/8791/testReport/ |
| modules | C: hadoop-common-project/hadoop-common U: hadoop-common-project/hadoop-common |
| Console output | https://builds.apache.org/job/PreCommit-HADOOP-Build/8791/console |
| Powered by | Apache Yetus 0.3.0-SNAPSHOT   http://yetus.apache.org |


This message was automatically generated.

","21/Apr/16 18:10;rchiang;[~ajisakaa] or [~iwasakims], let me know if you have the spare time to look at it.","22/Apr/16 08:21;iwasakims;Thanks for working on this, [~rchiang]. I will review the patch tonight (in JST).","22/Apr/16 19:50;rchiang;Thanks [~iwasakims]!","23/Apr/16 08:09;iwasakims;I changed the links to HADOOP-12733 and HADOOP-12101 from ""is blocked by"" to ""is related to"".","23/Apr/16 08:18;iwasakims;The patch looks good but I thinks we should just add {{TestCommonConfigurationFields}} here as issue title suggests. {{TestConfigurationFieldsBase}} should be fixed in HADOOP-12101.

Can you update the patch here and in HADOOP-12101 too if there is updates in TestConfigurationFieldsBase?
","25/Apr/16 15:33;rchiang;Oh, that's my bad--I usually put it in my local tree for purposes of running the test, but usually exclude it from the patch.  I will resubmit the clean patch.","25/Apr/16 16:41;rchiang;- Removed HADOOP-12101 patch bits","25/Apr/16 17:51;hadoopqa;| (/) *{color:green}+1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue} 0m 11s {color} | {color:blue} Docker mode activated. {color} |
| {color:green}+1{color} | {color:green} @author {color} | {color:green} 0m 0s {color} | {color:green} The patch does not contain any @author tags. {color} |
| {color:green}+1{color} | {color:green} test4tests {color} | {color:green} 0m 0s {color} | {color:green} The patch appears to include 1 new or modified test files. {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 7m 22s {color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 6m 28s {color} | {color:green} trunk passed with JDK v1.8.0_77 {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 7m 12s {color} | {color:green} trunk passed with JDK v1.7.0_95 {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green} 0m 22s {color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green} 1m 5s {color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green} 0m 16s {color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green} 1m 42s {color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 0m 58s {color} | {color:green} trunk passed with JDK v1.8.0_77 {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 1m 4s {color} | {color:green} trunk passed with JDK v1.7.0_95 {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 0m 40s {color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 5m 54s {color} | {color:green} the patch passed with JDK v1.8.0_77 {color} |
| {color:green}+1{color} | {color:green} javac {color} | {color:green} 5m 54s {color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 7m 1s {color} | {color:green} the patch passed with JDK v1.7.0_95 {color} |
| {color:green}+1{color} | {color:green} javac {color} | {color:green} 7m 1s {color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green} 0m 19s {color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green} 0m 55s {color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green} 0m 12s {color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} whitespace {color} | {color:green} 0m 0s {color} | {color:green} Patch has no whitespace issues. {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green} 1m 49s {color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 0m 58s {color} | {color:green} the patch passed with JDK v1.8.0_77 {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 1m 6s {color} | {color:green} the patch passed with JDK v1.7.0_95 {color} |
| {color:green}+1{color} | {color:green} unit {color} | {color:green} 7m 48s {color} | {color:green} hadoop-common in the patch passed with JDK v1.8.0_77. {color} |
| {color:green}+1{color} | {color:green} unit {color} | {color:green} 7m 52s {color} | {color:green} hadoop-common in the patch passed with JDK v1.7.0_95. {color} |
| {color:green}+1{color} | {color:green} asflicense {color} | {color:green} 0m 23s {color} | {color:green} Patch does not generate ASF License warnings. {color} |
| {color:black}{color} | {color:black} {color} | {color:black} 62m 42s {color} | {color:black} {color} |
\\
\\
|| Subsystem || Report/Notes ||
| Docker |  Image:yetus/hadoop:fbe3e86 |
| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12800560/HADOOP-12738.003.patch |
| JIRA Issue | HADOOP-12738 |
| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  findbugs  checkstyle  |
| uname | Linux 59d5afbc2d49 3.13.0-36-lowlatency #63-Ubuntu SMP PREEMPT Wed Sep 3 21:56:12 UTC 2014 x86_64 x86_64 x86_64 GNU/Linux |
| Build tool | maven |
| Personality | /testptch/hadoop/patchprocess/precommit/personality/provided.sh |
| git revision | trunk / 10f0f78 |
| Default Java | 1.7.0_95 |
| Multi-JDK versions |  /usr/lib/jvm/java-8-oracle:1.8.0_77 /usr/lib/jvm/java-7-openjdk-amd64:1.7.0_95 |
| findbugs | v3.0.0 |
| JDK v1.7.0_95  Test Results | https://builds.apache.org/job/PreCommit-HADOOP-Build/9169/testReport/ |
| modules | C: hadoop-common-project/hadoop-common U: hadoop-common-project/hadoop-common |
| Console output | https://builds.apache.org/job/PreCommit-HADOOP-Build/9169/console |
| Powered by | Apache Yetus 0.2.0   http://yetus.apache.org |


This message was automatically generated.

","27/Apr/16 01:44;iwasakims;+1, committing this.","27/Apr/16 01:54;hudson;FAILURE: Integrated in Hadoop-trunk-Commit #9675 (See [https://builds.apache.org/job/Hadoop-trunk-Commit/9675/])
HADOOP-12738. Create unit test to automatically compare Common related (iwasakims: rev 68b4564e78380a2fac1a9000fb862104d4bc86e5)
* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/conf/TestCommonConfigurationFields.java
","27/Apr/16 02:22;iwasakims;Committed. Thanks, [~rchiang].","28/Apr/16 17:11;rchiang;Thanks for the review and commit!",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Add Glob unit test for special characters,HADOOP-13051,12961629,Test,Resolved,HADOOP,Hadoop Common,software,omalley,Hadoop Common is the common library for Apache Hadoop.,http://hadoop.apache.org/,Minor,Fixed,qwertymaniac,qwertymaniac,qwertymaniac,22/Apr/16 12:55,12/May/16 18:27,12/Jan/21 11:55,05/May/16 21:23,3.0.0-alpha1,,,,3.0.0-alpha1,,,,,,fs,,,,0,,,"On {{branch-2}}, the below is the (incorrect) behaviour today, where paths with special characters get dropped during globStatus calls:

{code}
bin/hdfs dfs -mkdir /foo
bin/hdfs dfs -touchz /foo/foo1
bin/hdfs dfs -touchz $'/foo/foo1\r'
bin/hdfs dfs -ls '/foo/*'
-rw-r--r--   3 harsh supergroup          0 2016-04-22 17:35 /foo/foo1
-rw-r--r--   3 harsh supergroup          0 2016-04-22 17:35 /foo/foo1^M
bin/hdfs dfs -ls '/foo/*'
-rw-r--r--   3 harsh supergroup          0 2016-04-22 17:35 /foo/foo1
{code}

Whereas trunk has the right behaviour, subtly fixed via the pattern library change of HADOOP-12436:

{code}
bin/hdfs dfs -mkdir /foo
bin/hdfs dfs -touchz /foo/foo1
bin/hdfs dfs -touchz $'/foo/foo1\r'
bin/hdfs dfs -ls '/foo/*'
-rw-r--r--   3 harsh supergroup          0 2016-04-22 17:35 /foo/foo1
-rw-r--r--   3 harsh supergroup          0 2016-04-22 17:35 /foo/foo1^M
bin/hdfs dfs -ls '/foo/*'
-rw-r--r--   3 harsh supergroup          0 2016-04-22 17:35 /foo/foo1
-rw-r--r--   3 harsh supergroup          0 2016-04-22 17:35 /foo/foo1^M
{code}

(I've placed a ^M explicitly to indicate presence of the intentional hidden character)

We should still add a simple test-case to cover this situation for future regressions.",,Fan04290,hudson,jzhuge,krisden,qwertymaniac,raviprak,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,HADOOP-12436,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"23/Apr/16 10:48;qwertymaniac;HADOOP-13051.000.patch;https://issues.apache.org/jira/secure/attachment/12800373/HADOOP-13051.000.patch",,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,2016-04-22 15:56:50.875,,,false,,,,,,,,,,,,,,,,,9223372036854775807,Reviewed,,,,Thu May 05 22:08:59 UTC 2016,,,,,,,"0|i2wl5z:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,"22/Apr/16 13:00;qwertymaniac;Patch that fails in {{branch-2}} but passes in trunk after the mentioned fix.","22/Apr/16 15:56;hadoopqa;| (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue} 0m 15s {color} | {color:blue} Docker mode activated. {color} |
| {color:green}+1{color} | {color:green} @author {color} | {color:green} 0m 0s {color} | {color:green} The patch does not contain any @author tags. {color} |
| {color:green}+1{color} | {color:green} test4tests {color} | {color:green} 0m 0s {color} | {color:green} The patch appears to include 1 new or modified test files. {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 6m 51s {color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 0m 38s {color} | {color:green} trunk passed with JDK v1.8.0_77 {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 0m 42s {color} | {color:green} trunk passed with JDK v1.7.0_95 {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green} 0m 20s {color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green} 0m 52s {color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green} 0m 13s {color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green} 1m 58s {color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 1m 8s {color} | {color:green} trunk passed with JDK v1.8.0_77 {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 1m 46s {color} | {color:green} trunk passed with JDK v1.7.0_95 {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 0m 48s {color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 0m 38s {color} | {color:green} the patch passed with JDK v1.8.0_77 {color} |
| {color:green}+1{color} | {color:green} javac {color} | {color:green} 0m 38s {color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 0m 40s {color} | {color:green} the patch passed with JDK v1.7.0_95 {color} |
| {color:green}+1{color} | {color:green} javac {color} | {color:green} 0m 40s {color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green} 0m 18s {color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green} 0m 51s {color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green} 0m 12s {color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} whitespace {color} | {color:green} 0m 0s {color} | {color:green} Patch has no whitespace issues. {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green} 2m 13s {color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 1m 4s {color} | {color:green} the patch passed with JDK v1.8.0_77 {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 1m 44s {color} | {color:green} the patch passed with JDK v1.7.0_95 {color} |
| {color:red}-1{color} | {color:red} unit {color} | {color:red} 71m 32s {color} | {color:red} hadoop-hdfs in the patch failed with JDK v1.8.0_77. {color} |
| {color:red}-1{color} | {color:red} unit {color} | {color:red} 69m 58s {color} | {color:red} hadoop-hdfs in the patch failed with JDK v1.7.0_95. {color} |
| {color:green}+1{color} | {color:green} asflicense {color} | {color:green} 0m 23s {color} | {color:green} Patch does not generate ASF License warnings. {color} |
| {color:black}{color} | {color:black} {color} | {color:black} 167m 11s {color} | {color:black} {color} |
\\
\\
|| Reason || Tests ||
| JDK v1.8.0_77 Failed junit tests | hadoop.hdfs.TestHFlush |
|   | hadoop.hdfs.server.datanode.TestDataNodeLifeline |
|   | hadoop.hdfs.server.namenode.snapshot.TestOpenFilesWithSnapshot |
|   | hadoop.hdfs.server.namenode.TestFileTruncate |
| JDK v1.7.0_95 Failed junit tests | hadoop.hdfs.server.datanode.fsdataset.impl.TestFsDatasetImpl |
|   | hadoop.hdfs.server.namenode.TestEditLog |
\\
\\
|| Subsystem || Report/Notes ||
| Docker |  Image:yetus/hadoop:fbe3e86 |
| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12800211/HDFS-13051.000.patch |
| JIRA Issue | HADOOP-13051 |
| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  findbugs  checkstyle  |
| uname | Linux d6b9e39b390f 3.13.0-36-lowlatency #63-Ubuntu SMP PREEMPT Wed Sep 3 21:56:12 UTC 2014 x86_64 x86_64 x86_64 GNU/Linux |
| Build tool | maven |
| Personality | /testptch/hadoop/patchprocess/precommit/personality/provided.sh |
| git revision | trunk / 19f0f96 |
| Default Java | 1.7.0_95 |
| Multi-JDK versions |  /usr/lib/jvm/java-8-oracle:1.8.0_77 /usr/lib/jvm/java-7-openjdk-amd64:1.7.0_95 |
| findbugs | v3.0.0 |
| unit | https://builds.apache.org/job/PreCommit-HADOOP-Build/9150/artifact/patchprocess/patch-unit-hadoop-hdfs-project_hadoop-hdfs-jdk1.8.0_77.txt |
| unit | https://builds.apache.org/job/PreCommit-HADOOP-Build/9150/artifact/patchprocess/patch-unit-hadoop-hdfs-project_hadoop-hdfs-jdk1.7.0_95.txt |
| unit test logs |  https://builds.apache.org/job/PreCommit-HADOOP-Build/9150/artifact/patchprocess/patch-unit-hadoop-hdfs-project_hadoop-hdfs-jdk1.8.0_77.txt https://builds.apache.org/job/PreCommit-HADOOP-Build/9150/artifact/patchprocess/patch-unit-hadoop-hdfs-project_hadoop-hdfs-jdk1.7.0_95.txt |
| JDK v1.7.0_95  Test Results | https://builds.apache.org/job/PreCommit-HADOOP-Build/9150/testReport/ |
| modules | C: hadoop-hdfs-project/hadoop-hdfs U: hadoop-hdfs-project/hadoop-hdfs |
| Console output | https://builds.apache.org/job/PreCommit-HADOOP-Build/9150/console |
| Powered by | Apache Yetus 0.2.0   http://yetus.apache.org |


This message was automatically generated.

","23/Apr/16 10:48;qwertymaniac;(Renamed attachment to the right project)","23/Apr/16 13:18;hadoopqa;| (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue} 0m 11s {color} | {color:blue} Docker mode activated. {color} |
| {color:green}+1{color} | {color:green} @author {color} | {color:green} 0m 0s {color} | {color:green} The patch does not contain any @author tags. {color} |
| {color:green}+1{color} | {color:green} test4tests {color} | {color:green} 0m 0s {color} | {color:green} The patch appears to include 1 new or modified test files. {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 6m 41s {color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 0m 42s {color} | {color:green} trunk passed with JDK v1.8.0_77 {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 0m 42s {color} | {color:green} trunk passed with JDK v1.7.0_95 {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green} 0m 20s {color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green} 0m 50s {color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green} 0m 14s {color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green} 2m 2s {color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 1m 8s {color} | {color:green} trunk passed with JDK v1.8.0_77 {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 1m 52s {color} | {color:green} trunk passed with JDK v1.7.0_95 {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 0m 49s {color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 0m 39s {color} | {color:green} the patch passed with JDK v1.8.0_77 {color} |
| {color:green}+1{color} | {color:green} javac {color} | {color:green} 0m 39s {color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 0m 38s {color} | {color:green} the patch passed with JDK v1.7.0_95 {color} |
| {color:green}+1{color} | {color:green} javac {color} | {color:green} 0m 38s {color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green} 0m 18s {color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green} 0m 49s {color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green} 0m 11s {color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} whitespace {color} | {color:green} 0m 0s {color} | {color:green} Patch has no whitespace issues. {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green} 2m 8s {color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 1m 8s {color} | {color:green} the patch passed with JDK v1.8.0_77 {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 1m 43s {color} | {color:green} the patch passed with JDK v1.7.0_95 {color} |
| {color:red}-1{color} | {color:red} unit {color} | {color:red} 63m 1s {color} | {color:red} hadoop-hdfs in the patch failed with JDK v1.8.0_77. {color} |
| {color:red}-1{color} | {color:red} unit {color} | {color:red} 60m 20s {color} | {color:red} hadoop-hdfs in the patch failed with JDK v1.7.0_95. {color} |
| {color:green}+1{color} | {color:green} asflicense {color} | {color:green} 0m 30s {color} | {color:green} Patch does not generate ASF License warnings. {color} |
| {color:black}{color} | {color:black} {color} | {color:black} 149m 9s {color} | {color:black} {color} |
\\
\\
|| Reason || Tests ||
| JDK v1.8.0_77 Failed junit tests | hadoop.hdfs.TestDFSShell |
|   | hadoop.hdfs.server.datanode.fsdataset.impl.TestFsDatasetImpl |
| JDK v1.7.0_95 Failed junit tests | hadoop.hdfs.TestDFSShell |
|   | hadoop.hdfs.TestCrcCorruption |
\\
\\
|| Subsystem || Report/Notes ||
| Docker |  Image:yetus/hadoop:fbe3e86 |
| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12800373/HADOOP-13051.000.patch |
| JIRA Issue | HADOOP-13051 |
| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  findbugs  checkstyle  |
| uname | Linux cecbe0098dc0 3.13.0-36-lowlatency #63-Ubuntu SMP PREEMPT Wed Sep 3 21:56:12 UTC 2014 x86_64 x86_64 x86_64 GNU/Linux |
| Build tool | maven |
| Personality | /testptch/hadoop/patchprocess/precommit/personality/provided.sh |
| git revision | trunk / b2a654c |
| Default Java | 1.7.0_95 |
| Multi-JDK versions |  /usr/lib/jvm/java-8-oracle:1.8.0_77 /usr/lib/jvm/java-7-openjdk-amd64:1.7.0_95 |
| findbugs | v3.0.0 |
| unit | https://builds.apache.org/job/PreCommit-HADOOP-Build/9159/artifact/patchprocess/patch-unit-hadoop-hdfs-project_hadoop-hdfs-jdk1.8.0_77.txt |
| unit | https://builds.apache.org/job/PreCommit-HADOOP-Build/9159/artifact/patchprocess/patch-unit-hadoop-hdfs-project_hadoop-hdfs-jdk1.7.0_95.txt |
| unit test logs |  https://builds.apache.org/job/PreCommit-HADOOP-Build/9159/artifact/patchprocess/patch-unit-hadoop-hdfs-project_hadoop-hdfs-jdk1.8.0_77.txt https://builds.apache.org/job/PreCommit-HADOOP-Build/9159/artifact/patchprocess/patch-unit-hadoop-hdfs-project_hadoop-hdfs-jdk1.7.0_95.txt |
| JDK v1.7.0_95  Test Results | https://builds.apache.org/job/PreCommit-HADOOP-Build/9159/testReport/ |
| modules | C: hadoop-hdfs-project/hadoop-hdfs U: hadoop-hdfs-project/hadoop-hdfs |
| Console output | https://builds.apache.org/job/PreCommit-HADOOP-Build/9159/console |
| Powered by | Apache Yetus 0.2.0   http://yetus.apache.org |


This message was automatically generated.

","24/Apr/16 04:00;raviprak;+1. LGTM. Thanks Harsh. Please feel free to commit","05/May/16 20:57;jzhuge;+1 LGTM. Very useful patch. Could some one commit?","05/May/16 21:22;raviprak;Thanks for the patch Harsh and the review John! Committed to trunk.","05/May/16 21:37;jzhuge;Thanks [~raviprak] for committing it promptly.","05/May/16 22:08;hudson;FAILURE: Integrated in Hadoop-trunk-Commit #9725 (See [https://builds.apache.org/job/Hadoop-trunk-Commit/9725/])
HADOOP-13051. Test for special characters in path being respected during (raviprak: rev d8faf47f32c7ace6ceeb55bbb584c2dbab38902f)
* hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/fs/TestGlobPaths.java
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
enhance unit-test coverage of class org.apache.hadoop.fs.FileUtil,HADOOP-9063,12616763,Test,Closed,HADOOP,Hadoop Common,software,omalley,Hadoop Common is the common library for Apache Hadoop.,http://hadoop.apache.org/,Minor,Fixed,iveselovsky,iveselovsky,iveselovsky,19/Nov/12 17:09,12/May/16 18:25,12/Jan/21 11:55,02/Oct/13 14:53,0.23.6,2.0.3-alpha,3.0.0-alpha1,,2.3.0,,,,,,,,,,0,,,Some methods of class org.apache.hadoop.fs.FileUtil are covered by unit-tests poorly or not covered at all. Enhance the coverage.,,aklochkov,hudson,iveselovsky,jlowe,revans2,robsparker,sureshms,tgraves,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"03/Dec/12 11:26;iveselovsky;HADOOP-9063--b.patch;https://issues.apache.org/jira/secure/attachment/12555741/HADOOP-9063--b.patch","18/Dec/12 11:31;iveselovsky;HADOOP-9063-branch-0.23--b.patch;https://issues.apache.org/jira/secure/attachment/12561469/HADOOP-9063-branch-0.23--b.patch","15/Jan/13 19:03;iveselovsky;HADOOP-9063-branch-0.23--c.patch;https://issues.apache.org/jira/secure/attachment/12564975/HADOOP-9063-branch-0.23--c.patch","10/Apr/13 15:43;iveselovsky;HADOOP-9063-branch-2--N1.patch;https://issues.apache.org/jira/secure/attachment/12578022/HADOOP-9063-branch-2--N1.patch","24/May/13 10:43;dennisyv;HADOOP-9063-branch-2--N2.patch;https://issues.apache.org/jira/secure/attachment/12584679/HADOOP-9063-branch-2--N2.patch","11/Mar/13 11:35;dennisyv;HADOOP-9063-trunk--N2.patch;https://issues.apache.org/jira/secure/attachment/12573071/HADOOP-9063-trunk--N2.patch","12/Mar/13 12:29;dennisyv;HADOOP-9063-trunk--N3.patch;https://issues.apache.org/jira/secure/attachment/12573311/HADOOP-9063-trunk--N3.patch","10/Apr/13 15:43;iveselovsky;HADOOP-9063-trunk--N6.patch;https://issues.apache.org/jira/secure/attachment/12578023/HADOOP-9063-trunk--N6.patch","05/Feb/13 15:20;tgraves;HADOOP-9063-trunk--c.patch;https://issues.apache.org/jira/secure/attachment/12568009/HADOOP-9063-trunk--c.patch","15/Jan/13 19:03;iveselovsky;HADOOP-9063-trunk--c.patch;https://issues.apache.org/jira/secure/attachment/12564976/HADOOP-9063-trunk--c.patch","19/Nov/12 19:13;iveselovsky;HADOOP-9063.patch;https://issues.apache.org/jira/secure/attachment/12554214/HADOOP-9063.patch",,,,,,,,,,,,,11.0,,,,,,,,,,,,,,,,,,,,2012-11-19 19:47:53.887,,,false,,,,,,,,,,,,,,,,,258632,Reviewed,,,,Thu Oct 03 15:21:31 UTC 2013,,,,,,,"0|i0l1nr:",120919,,,,,,,,,,,,,,,,,,,,,,,"19/Nov/12 19:13;iveselovsky;provided several more tests for FileUtil class.","19/Nov/12 19:47;hadoopqa;{color:green}+1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12554214/HADOOP-9063.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 1 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  The javadoc tool did not generate any warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:green}+1 core tests{color}.  The patch passed unit tests in hadoop-common-project/hadoop-common.

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HADOOP-Build/1772//testReport/
Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/1772//console

This message is automatically generated.","03/Dec/12 11:26;iveselovsky;patch ""HADOOP-9063--b.patch"" avoids merge conflict with HADOOP-8849.","13/Dec/12 10:14;hadoopqa;{color:green}+1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12555741/HADOOP-9063--b.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 1 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  The javadoc tool did not generate any warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:green}+1 core tests{color}.  The patch passed unit tests in hadoop-common-project/hadoop-common.

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HADOOP-Build/1853//testReport/
Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/1853//console

This message is automatically generated.","18/Dec/12 11:31;iveselovsky;The patch ""HADOOP-9063-branch-0.23--b.patch"" is for bracnh-0.23. 
The patch ""HADOOP-9063--b.patch"" is for trunk and branch-2./","18/Dec/12 11:45;hadoopqa;{color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12561469/HADOOP-9063-branch-0.23--b.patch
  against trunk revision .

    {color:red}-1 patch{color}.  The patch command could not apply the patch.

Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/1910//console

This message is automatically generated.","15/Jan/13 19:03;iveselovsky;The version ""c"" of the patches re-arranges some code to avoid merge conflicts with HADOOP-8849.","15/Jan/13 19:04;iveselovsky;patch ""HADOOP-9063-trunk--c.patch"" is for trunk and branch-2.","05/Feb/13 15:20;tgraves;attach same patch to kick jenkins
","05/Feb/13 15:48;hadoopqa;{color:green}+1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12568009/HADOOP-9063-trunk--c.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 1 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  The javadoc tool did not generate any warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:green}+1 core tests{color}.  The patch passed unit tests in hadoop-common-project/hadoop-common.

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HADOOP-Build/2150//testReport/
Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/2150//console

This message is automatically generated.","11/Mar/13 11:35;dennisyv;updated patch for trunk","11/Mar/13 12:08;hadoopqa;{color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12573071/HADOOP-9063-trunk--N2.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 1 new or modified test files.

  {color:red}-1 one of tests included doesn't have a timeout.{color}

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  The javadoc tool did not generate any warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:green}+1 core tests{color}.  The patch passed unit tests in hadoop-common-project/hadoop-common.

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HADOOP-Build/2306//testReport/
Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/2306//console

This message is automatically generated.","12/Mar/13 12:29;dennisyv;added timeouts to trunk patch","12/Mar/13 13:05;hadoopqa;{color:green}+1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12573311/HADOOP-9063-trunk--N3.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 1 new or modified test files.

    {color:green}+1 tests included appear to have a timeout.{color}

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  The javadoc tool did not generate any warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:green}+1 core tests{color}.  The patch passed unit tests in hadoop-common-project/hadoop-common.

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HADOOP-Build/2317//testReport/
Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/2317//console

This message is automatically generated.","10/Apr/13 15:43;iveselovsky;re-submitting the patches since branch-2 now needs a separate version. ","10/Apr/13 16:43;hadoopqa;{color:green}+1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12578023/HADOOP-9063-trunk--N6.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 1 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  The javadoc tool did not generate any warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:green}+1 core tests{color}.  The patch passed unit tests in hadoop-common-project/hadoop-common.

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HADOOP-Build/2439//testReport/
Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/2439//console

This message is automatically generated.","24/May/13 10:43;dennisyv;resolved merge conflict in patch for branch-2","24/May/13 11:26;hadoopqa;{color:green}+1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12584679/HADOOP-9063-branch-2--N2.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 1 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  The javadoc tool did not generate any warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:green}+1 core tests{color}.  The patch passed unit tests in hadoop-common-project/hadoop-common.

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HADOOP-Build/2565//testReport/
Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/2565//console

This message is automatically generated.","01/Oct/13 14:50;robsparker;+1 (non-binding) lgtm. I was able to apply the trunk patch to branch-2 and successfully test it(now). Recommend applying the trunk patch to branch-2 to avoid unnecessary divergence.","02/Oct/13 14:37;jlowe;+1, committing this","02/Oct/13 14:53;jlowe;Thanks to Ivan for the contribution and Robert for the review!  I committed this to trunk and branch-2.","02/Oct/13 14:57;hudson;SUCCESS: Integrated in Hadoop-trunk-Commit #4515 (See [https://builds.apache.org/job/Hadoop-trunk-Commit/4515/])
HADOOP-9063. enhance unit-test coverage of class org.apache.hadoop.fs.FileUtil. Contributed by Ivan A. Veselovsky (jlowe: http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1528502)
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/CHANGES.txt
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/TestFileUtil.java
","03/Oct/13 10:33;iveselovsky;Hi, Jason, is that possible to commit it to branch-0.23 also?","03/Oct/13 10:58;hudson;FAILURE: Integrated in Hadoop-Yarn-trunk #351 (See [https://builds.apache.org/job/Hadoop-Yarn-trunk/351/])
HADOOP-9063. enhance unit-test coverage of class org.apache.hadoop.fs.FileUtil. Contributed by Ivan A. Veselovsky (jlowe: http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1528502)
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/CHANGES.txt
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/TestFileUtil.java
","03/Oct/13 13:30;hudson;SUCCESS: Integrated in Hadoop-Hdfs-trunk #1541 (See [https://builds.apache.org/job/Hadoop-Hdfs-trunk/1541/])
HADOOP-9063. enhance unit-test coverage of class org.apache.hadoop.fs.FileUtil. Contributed by Ivan A. Veselovsky (jlowe: http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1528502)
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/CHANGES.txt
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/TestFileUtil.java
","03/Oct/13 14:00;hudson;FAILURE: Integrated in Hadoop-Mapreduce-trunk #1567 (See [https://builds.apache.org/job/Hadoop-Mapreduce-trunk/1567/])
HADOOP-9063. enhance unit-test coverage of class org.apache.hadoop.fs.FileUtil. Contributed by Ivan A. Veselovsky (jlowe: http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1528502)
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/CHANGES.txt
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/TestFileUtil.java
","03/Oct/13 15:21;jlowe;bq. is that possible to commit it to branch-0.23 also?

Our focus is moving from branch-0.23 to branch-2, and we are trying to only commit customer-reported or critical bugfixes to 0.23 at this point.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Add a config value to CLITestHelper to skip tests on Windows,HADOOP-9948,12667945,Test,Closed,HADOOP,Hadoop Common,software,omalley,Hadoop Common is the common library for Apache Hadoop.,http://hadoop.apache.org/,Minor,Fixed,chuanliu,chuanliu,chuanliu,10/Sep/13 23:05,12/May/16 18:25,12/Jan/21 11:55,26/Sep/13 17:15,3.0.0-alpha1,,,,2.2.0,,,,,,test,,,,0,,,"We want to add a configuration to CLITestHelper so we can skip some tests on Windows. We want this feature because some test cases in TestHDFSCLI should not be tested on Windows. Or more specifically, the globbing test cases. The differences are explained in HDFS-4632. The proposed syntax looks like follows.

{noformat}
<test> <!-- TESTED -->
      <description>ls: Negative test for quoted /*/* globbing </description>
      <windows>false</windows>
{noformat}

When Windows set to false, we will skip running the test on Windows.",,chuanliu,cnauroth,Fan04290,hudson,vinodkv,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"25/Sep/13 18:01;cnauroth;HADOOP-9948.2.patch;https://issues.apache.org/jira/secure/attachment/12605059/HADOOP-9948.2.patch","10/Sep/13 23:25;chuanliu;HADOOP-9948.patch;https://issues.apache.org/jira/secure/attachment/12602461/HADOOP-9948.patch",,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,2013-09-11 03:44:39.064,,,false,,,,,,,,,,,,,,,,,347881,Reviewed,,,,Tue Jun 30 07:11:20 UTC 2015,,,,,,,"0|i1nziv:",348178,,,,,,,,,,,,,2.2.0,,,,,,,,,,"10/Sep/13 23:25;chuanliu;Attach a patch. Tested on Linux and Windows. The three test cases skipped on Windows still run on Linux.","11/Sep/13 03:44;hadoopqa;{color:green}+1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12602461/HADOOP-9948.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 2 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  The javadoc tool did not generate any warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:green}+1 core tests{color}.  The patch passed unit tests in hadoop-common-project/hadoop-common hadoop-hdfs-project/hadoop-hdfs.

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HADOOP-Build/3078//testReport/
Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/3078//console

This message is automatically generated.","25/Sep/13 17:56;cnauroth;+1 for the patch.  I verified tests on Mac and Windows.

I'm going to split this into separate patches for Hadoop Common and HDFS and commit them separately.","25/Sep/13 18:01;cnauroth;Attaching Hadoop Common patch and awaiting test-patch run.","25/Sep/13 18:52;hadoopqa;{color:green}+1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12605059/HADOOP-9948.2.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 1 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  The javadoc tool did not generate any warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:green}+1 core tests{color}.  The patch passed unit tests in hadoop-common-project/hadoop-common.

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HADOOP-Build/3122//testReport/
Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/3122//console

This message is automatically generated.","26/Sep/13 17:15;cnauroth;I have committed this to trunk, branch-2, and branch-2.1-beta.  Thank you for the patch, Chuan.","26/Sep/13 17:16;hudson;SUCCESS: Integrated in Hadoop-trunk-Commit #4473 (See [https://builds.apache.org/job/Hadoop-trunk-Commit/4473/])
HADOOP-9948. Add a config value to CLITestHelper to skip tests on Windows. Contributed by Chuan Liu. (cnauroth: http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1526606)
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/CHANGES.txt
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/cli/CLITestHelper.java
","27/Sep/13 10:57;hudson;FAILURE: Integrated in Hadoop-Yarn-trunk #345 (See [https://builds.apache.org/job/Hadoop-Yarn-trunk/345/])
HADOOP-9948. Add a config value to CLITestHelper to skip tests on Windows. Contributed by Chuan Liu. (cnauroth: http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1526606)
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/CHANGES.txt
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/cli/CLITestHelper.java
","27/Sep/13 13:29;hudson;SUCCESS: Integrated in Hadoop-Hdfs-trunk #1535 (See [https://builds.apache.org/job/Hadoop-Hdfs-trunk/1535/])
HADOOP-9948. Add a config value to CLITestHelper to skip tests on Windows. Contributed by Chuan Liu. (cnauroth: http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1526606)
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/CHANGES.txt
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/cli/CLITestHelper.java
","27/Sep/13 14:16;hudson;FAILURE: Integrated in Hadoop-Mapreduce-trunk #1561 (See [https://builds.apache.org/job/Hadoop-Mapreduce-trunk/1561/])
HADOOP-9948. Add a config value to CLITestHelper to skip tests on Windows. Contributed by Chuan Liu. (cnauroth: http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1526606)
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/CHANGES.txt
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/cli/CLITestHelper.java
","30/Jun/15 07:11;vinodkv;Closing old tickets that are already shipped in a release.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"TestFSMainOperationsLocalFileSystem failed when the Hadoop test root path has ""X"" in its name",HADOOP-9624,12651239,Test,Closed,HADOOP,Hadoop Common,software,omalley,Hadoop Common is the common library for Apache Hadoop.,http://hadoop.apache.org/,Minor,Fixed,xifang,xifang,xifang,05/Jun/13 23:48,12/May/16 18:22,12/Jan/21 11:55,18/Jun/13 23:37,1.3.0,1-win,2.1.0-beta,3.0.0-alpha1,1.3.0,1-win,2.1.0-beta,,,,test,,,,0,test,,"TestFSMainOperationsLocalFileSystem extends Class FSMainOperationsBaseTest. PathFilter FSMainOperationsBaseTest#TEST_X_FILTER checks if a path has ""x"" and ""X"" in its name. 
{code}
final private static PathFilter TEST_X_FILTER = new PathFilter() {
  public boolean accept(Path file) {
    if(file.getName().contains(""x"") || file.toString().contains(""X""))
      return true;
    else
      return false;
{code}




Some of the test cases construct a path by combining path ""TEST_ROOT_DIR"" with a customized partial path. 
The problem is that ""TEST_ROOT_DIR"" may also has ""X"" in its name. The path check will pass even if the customized partial path doesn't have ""X"". However, for this case the path filter is supposed to reject this path.

An easy fix is to change ""file.toString().contains(""X"")"" to ""file.getName().contains(""X"")"". Note that org.apache.hadoop.fs.Path.getName() only returns the final component of this path.
",Windows,atm,cnauroth,hudson,ivanmi,xifang,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,HADOOP-8444,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"18/Jun/13 23:01;cnauroth;HADOOP-9624.branch-1.2.patch;https://issues.apache.org/jira/secure/attachment/12588475/HADOOP-9624.branch-1.2.patch","18/Jun/13 20:40;xifang;HADOOP-9624.branch-1.patch;https://issues.apache.org/jira/secure/attachment/12588447/HADOOP-9624.branch-1.patch","06/Jun/13 18:56;xifang;HADOOP-9624.patch;https://issues.apache.org/jira/secure/attachment/12586551/HADOOP-9624.patch","18/Jun/13 20:25;xifang;HADOOP-9624.trunk.patch;https://issues.apache.org/jira/secure/attachment/12588443/HADOOP-9624.trunk.patch",,,,,,,,,,,,,,,,,,,,4.0,,,,,,,,,,,,,,,,,,,,2013-06-11 01:43:48.051,,,false,,,,,,,,,,,,,,,,,331565,Reviewed,,,,Wed Jun 19 13:38:08 UTC 2013,,,,,,,"0|i1l787:",331896,,,,,,,,,,,,,1.3.0,1-win,2.1.0-beta,,,,,,,,"06/Jun/13 18:56;xifang;A patch is attached.","11/Jun/13 01:43;atm;Marking PA for Xi.","11/Jun/13 02:00;hadoopqa;{color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12586551/HADOOP-9624.patch
  against trunk revision .

    {color:red}-1 patch{color}.  The patch command could not apply the patch.

Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/2629//console

This message is automatically generated.","11/Jun/13 03:34;xifang;Thanks Aaron!","16/Jun/13 18:53;cnauroth;Hi Xi,

The fix looks good.  I noticed that this is basically a backport of trunk patch HADOOP-8444, but with slightly different formatting and the addition of a correction in the comment above {{TEST_X_FILTER}}.  Can we please do a few more things to keep the code in sync across the branches, and therefore make maintenance easier?

# Prepare a trunk patch just to correct the erroneous comment.  I'll commit this to trunk, branch-2, and branch-2.1-beta.
# Prepare a new branch-1 patch that makes the same fix, but uses the same formatting as the trunk code.  I'll commit this to branch-1 and branch-1-win.

By doing this now, future patches on this part of the code will require less tinkering to work on each branch.

Thanks!
","18/Jun/13 01:14;xifang;Thanks Chris. I will do it and let you know once I am done.

Thanks
- Xi","18/Jun/13 20:43;hadoopqa;{color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12588447/HADOOP-9624.branch-1.patch
  against trunk revision .

    {color:red}-1 patch{color}.  The patch command could not apply the patch.

Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/2667//console

This message is automatically generated.","18/Jun/13 20:44;xifang;Thanks Chris. Two patches have been attached. ","18/Jun/13 20:58;hadoopqa;{color:green}+1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12588443/HADOOP-9624.trunk.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 2 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  The javadoc tool did not generate any warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:green}+1 core tests{color}.  The patch passed unit tests in hadoop-common-project/hadoop-common.

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HADOOP-Build/2666//testReport/
Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/2666//console

This message is automatically generated.","18/Jun/13 23:01;cnauroth;I'm attaching a very minor update to the branch-1 patch, changing ""and"" to ""or"" in the comment, again just for consistency between the 2 branches.

+1 for both patches.  I'll commit these.","18/Jun/13 23:02;hadoopqa;{color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12588475/HADOOP-9624.branch-1.2.patch
  against trunk revision .

    {color:red}-1 patch{color}.  The patch command could not apply the patch.

Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/2669//console

This message is automatically generated.","18/Jun/13 23:16;hudson;Integrated in Hadoop-trunk-Commit #3972 (See [https://builds.apache.org/job/Hadoop-trunk-Commit/3972/])
    HADOOP-9624. TestFSMainOperationsLocalFileSystem failed when the Hadoop test root path has ""X"" in its name. Contributed by Xi Fang. (Revision 1494363)

     Result = SUCCESS
cnauroth : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1494363
Files : 
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/CHANGES.txt
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/FSMainOperationsBaseTest.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/FileContextMainOperationsBaseTest.java
","18/Jun/13 23:37;cnauroth;I committed the trunk patch to trunk, branch-2, and branch-2.1-beta.  I committed the branch-1 patch to branch-1 and branch-1-win.  Xi, thank you for contributing this test fix!","18/Jun/13 23:48;xifang;Chris, thanks for your review and comments.","19/Jun/13 10:41;hudson;Integrated in Hadoop-Yarn-trunk #245 (See [https://builds.apache.org/job/Hadoop-Yarn-trunk/245/])
    HADOOP-9624. TestFSMainOperationsLocalFileSystem failed when the Hadoop test root path has ""X"" in its name. Contributed by Xi Fang. (Revision 1494363)

     Result = FAILURE
cnauroth : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1494363
Files : 
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/CHANGES.txt
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/FSMainOperationsBaseTest.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/FileContextMainOperationsBaseTest.java
","19/Jun/13 13:04;hudson;Integrated in Hadoop-Hdfs-trunk #1435 (See [https://builds.apache.org/job/Hadoop-Hdfs-trunk/1435/])
    HADOOP-9624. TestFSMainOperationsLocalFileSystem failed when the Hadoop test root path has ""X"" in its name. Contributed by Xi Fang. (Revision 1494363)

     Result = FAILURE
cnauroth : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1494363
Files : 
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/CHANGES.txt
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/FSMainOperationsBaseTest.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/FileContextMainOperationsBaseTest.java
","19/Jun/13 13:38;hudson;Integrated in Hadoop-Mapreduce-trunk #1462 (See [https://builds.apache.org/job/Hadoop-Mapreduce-trunk/1462/])
    HADOOP-9624. TestFSMainOperationsLocalFileSystem failed when the Hadoop test root path has ""X"" in its name. Contributed by Xi Fang. (Revision 1494363)

     Result = FAILURE
cnauroth : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1494363
Files : 
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/CHANGES.txt
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/FSMainOperationsBaseTest.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/FileContextMainOperationsBaseTest.java
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
TestHDFSCLI fails on Windows due to difference in line endings,HADOOP-10082,12677475,Test,Open,HADOOP,Hadoop Common,software,omalley,Hadoop Common is the common library for Apache Hadoop.,http://hadoop.apache.org/,Minor,,,chuanliu,chuanliu,04/Nov/13 23:50,12/May/16 18:22,12/Jan/21 11:55,,3.0.0-alpha1,,,,,,,,,,,,,,0,,,"This is similar issue with HADOOP-8657. git appended /r by default on Windows at checkout. When TestHDFSCLI runs, the verification will fail on file size for files like data15bytes, data30bytes, etc.
",,chuanliu,cnauroth,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,356850,,,,,2013-11-04 23:50:15.0,,,,,,,"0|i1pio7:",357140,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
TestSSLHttpServer creates ssl-server.xml in hadoop-common test classes without cleaning up,HADOOP-10222,12688346,Test,Open,HADOOP,Hadoop Common,software,omalley,Hadoop Common is the common library for Apache Hadoop.,http://hadoop.apache.org/,Minor,,,jwang302,jwang302,10/Jan/14 22:22,28/Sep/15 18:59,12/Jan/21 11:55,,2.2.0,,,,,,,,,,test,,,,0,,,"TestSSLHttpServer creates ssl-server.xml hadoop-common test-classes without cleaning up. Other tests could pick up the ssl-server configuration file and get the wrong keystore and truststore.

Got the following exception while running org.apache.hadoop.hdfs.TestNameNodeHttpServer and the cause is TestNameNodeHttpServer is picking up the ssl-server.xml file written by TestSSLHttpServer

java.io.IOException: Keystore was tampered with, or password was incorrect
	at com.ibm.crypto.provider.JavaKeyStore.engineLoad(Unknown Source)
	at java.security.KeyStore.load(KeyStore.java:414)
	at org.mortbay.jetty.security.SslSocketConnector.createFactory(SslSocketConnector.java:246)
	at org.mortbay.jetty.security.SslSocketConnector.newServerSocket(SslSocketConnector.java:476)
	at org.mortbay.jetty.bio.SocketConnector.open(SocketConnector.java:73)
	at org.mortbay.jetty.AbstractConnector.doStart(AbstractConnector.java:283)
	at org.mortbay.jetty.bio.SocketConnector.doStart(SocketConnector.java:147)
	at org.mortbay.component.AbstractLifeCycle.start(AbstractLifeCycle.java:50)
	at org.mortbay.jetty.Server.doStart(Server.java:235)
	at org.mortbay.component.AbstractLifeCycle.start(AbstractLifeCycle.java:50)
	at org.apache.hadoop.http.HttpServer.start(HttpServer.java:692)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeHttpServer.start(NameNodeHttpServer.java:158)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.startHttpServer(NameNode.java:626)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.initialize(NameNode.java:488)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:684)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.<init>(NameNode.java:669)
	at org.apache.hadoop.hdfs.server.namenode.NameNode.createNameNode(NameNode.java:1254)
	at org.apache.hadoop.hdfs.MiniDFSCluster.createNameNode(MiniDFSCluster.java:893)
	at org.apache.hadoop.hdfs.MiniDFSCluster.createNameNodesAndSetConf(MiniDFSCluster.java:784)
	at org.apache.hadoop.hdfs.MiniDFSCluster.initMiniDFSCluster(MiniDFSCluster.java:642)
	at org.apache.hadoop.hdfs.MiniDFSCluster.<init>(MiniDFSCluster.java:334)
	at org.apache.hadoop.hdfs.MiniDFSCluster$Builder.build(MiniDFSCluster.java:316)
	at org.apache.hadoop.hdfs.TestNameNodeHttpServer.testSslConfiguration(TestNameNodeHttpServer.java:38)
",,jingzhao,jwang302,vinodkv,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"13/Jan/14 18:48;jwang302;HADOOP-10222.patch;https://issues.apache.org/jira/secure/attachment/12622677/HADOOP-10222.patch",,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,2015-09-28 18:59:34.854,,,false,,,,,,,,,,,,,,,,,367365,,,,,Mon Sep 28 18:59:34 UTC 2015,,,,,,,"0|i1rbmn:",367674,,,,,,,,,,,,,,,,,,,,,,,"10/Jan/14 22:22;jwang302;Will attach a patch fix the problem.
","28/Sep/15 18:59;vinodkv;Dropping fix-version which should be set at commit-time.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
test-patch should check for hard tabs,HADOOP-7334,12508459,Test,Resolved,HADOOP,Hadoop Common,software,omalley,Hadoop Common is the common library for Apache Hadoop.,http://hadoop.apache.org/,Minor,Implemented,tlipcon,tlipcon,tlipcon,26/May/11 18:43,27/Jun/15 17:46,12/Jan/21 11:55,27/Jun/15 17:46,,,,,HADOOP-12111,,,,,,build,test,,,0,,,"Our coding guidelines say that hard tabs are disallowed in the Hadoop code, but they sometimes sneak in (there are about 280 in the common codebase at the moment).

We should run a simple check for this in the test-patch process so it's harder for them to sneak in.",,aw,cutting,nidaley,szetszwo,tlipcon,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"27/May/11 02:01;tlipcon;hadoop-7334.txt;https://issues.apache.org/jira/secure/attachment/12480618/hadoop-7334.txt","26/May/11 18:45;tlipcon;hadoop-7334.txt;https://issues.apache.org/jira/secure/attachment/12480570/hadoop-7334.txt",,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,2011-05-26 19:03:21.593,,,false,,,,,,,,,,,,,,,,,127551,,,,,Sat Jun 27 17:46:10 UTC 2015,,,,,,,"0|i0hx2n:",102620,,,,,,,,,,,,,,,,,,,,,,,"26/May/11 18:45;tlipcon;I tested this on a patch that had some tabs, and it correctly identified them.","26/May/11 19:03;nidaley;+1.  Looks like it only checks for tabs on + lines.","26/May/11 20:08;jeagles;Todd, I wondering if we should remove the '-c' on the first grep. I'm in favor of coding style checking. Do you think we have a need to do something like checkstyle in the future?","26/May/11 20:09;jeagles;Other than what I said above, I think this patch looks great.","27/May/11 02:01;tlipcon;You're absolutely right about the first -c.. I was testing with a patch that had only one tab so I didn't notice :)

Something like checkstyle probably makes sense at some point, but right now we have so many violations that it would be a big change. Spaces vs tabs is one thing everyone agrees on and where there's never any question of ""aesthetics"" :) So let's start here and maybe some day ease in some checkstyle.","27/May/11 02:06;szetszwo;Nice work!  We should have this long time ago.

BTW, do you want to also check 80 characters per line?  But it is arguably if it is the rule we want to enforce.","27/May/11 02:14;tlipcon;IMO 80 chars per line is one of those things that should be kept in general, but if the occasional line flows over it's not a big deal. There's some times when it's much less readable to try to keep to it.

But this is where we get into religious wars ;-) I'm a 100-per-line devotee myself!","27/May/11 02:19;szetszwo;Provided that most monitors are wide-screen nowadays, the 80-per-line rule is probably out-dated.","27/May/11 04:26;tomwhite;> Do you think we have a need to do something like checkstyle in the future?

We have long had a checkstyle target in ant, and plots of checkstyle violations over time (see https://builds.apache.org/job/Hadoop-Common-trunk/), but unfortunately we haven't enforced the rule that the number may not increase (unlike javadoc or findbugs warnings for example).

Another way of implementing this JIRA would be to enable such a rule (perhaps with a weaker set of checkstyle rules than the current set, e.g. drop the 80-per-line rule).","27/May/11 06:42;nidaley;Tom, that's a good idea.  Enable checkstyle with just the tab check and then we can grow the checks over time.  Start small and iterate.","27/Jun/15 17:46;aw;tab support now in yetus. closing as implemented.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Adding keytab login test for UGI using MiniKdc,HADOOP-9942,12667532,Test,Patch Available,HADOOP,Hadoop Common,software,omalley,Hadoop Common is the common library for Apache Hadoop.,http://hadoop.apache.org/,Minor,,drankye,drankye,drankye,09/Sep/13 09:03,06/May/15 03:32,12/Jan/21 11:55,,,,,,,,,,,,security,,,,0,BB2015-05-TBR,,This will add a keytab login test for UGI by using MiniKdc.,,drankye,tucu00,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"10/Sep/13 01:36;drankye;HADOOP-9942-v2.patch;https://issues.apache.org/jira/secure/attachment/12602255/HADOOP-9942-v2.patch","09/Sep/13 12:46;drankye;HADOOP-9942.patch;https://issues.apache.org/jira/secure/attachment/12602129/HADOOP-9942.patch",,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,2013-09-09 13:23:56.146,,,false,,,,,,,,,,,,,,,,,347469,,,,,Sat May 02 04:33:05 UTC 2015,,,,,,,"0|i1nwzr:",347768,,,,,,,,,,,,,,,,,,,,,,,"09/Sep/13 13:23;hadoopqa;{color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12602129/HADOOP-9942.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 1 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  The javadoc tool did not generate any warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:red}-1 core tests{color}.  The patch failed these unit tests in hadoop-common-project/hadoop-common:

                  org.apache.hadoop.util.TestClassUtil

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HADOOP-Build/3072//testReport/
Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/3072//console

This message is automatically generated.","09/Sep/13 15:40;tucu00;argh, i guess using apacheds-all-2.0.0-M15.jar is not correct as the JAR includes its 3rd party dependencies.","10/Sep/13 01:00;drankye;Below is the details for the failed test case TestClassUtil reported here:
{noformat}
Regression

org.apache.hadoop.util.TestClassUtil.testFindContainingJar
Failing for the past 1 build (Since Failed#3072 ) Took 47 ms.
Error Message

Incorrect jar file/home/jenkins/.m2/repository/org/apache/directory/server/apacheds-all/2.0.0-M15/apacheds-all-2.0.0-M15.jar

Stacktrace

junit.framework.AssertionFailedError: Incorrect jar file/home/jenkins/.m2/repository/org/apache/directory/server/apacheds-all/2.0.0-M15/apacheds-all-2.0.0-M15.jar
	at junit.framework.Assert.fail(Assert.java:50)
	at junit.framework.Assert.assertTrue(Assert.java:20)
	at org.apache.hadoop.util.TestClassUtil.testFindContainingJar(TestClassUtil.java:37)
{noformat}

Thanks Alejandro for the point.","10/Sep/13 01:36;drankye;Updated the patch, fixing the failure case.","10/Sep/13 01:45;drankye;Alejandro, the cause is the Logger was loaded from apacheds-all-2.0.0-M15.jar, instead of log4j jar, which was unexpected. To resolve it, I adjusted the dependency order in the pom.xml, placing hadoop-minikdc as the last one. 

By the way, introducing apacheds-all-2.0.0-M15.jar as we did when coming up hadoop-minikdc is reasonable, since the scope is just limited to test. I don't think we have better approach for now, like more compact jar for the ApacheDS KDC.","10/Sep/13 02:13;hadoopqa;{color:green}+1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12602255/HADOOP-9942-v2.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 1 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  The javadoc tool did not generate any warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:green}+1 core tests{color}.  The patch passed unit tests in hadoop-common-project/hadoop-common.

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HADOOP-Build/3074//testReport/
Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/3074//console

This message is automatically generated.","02/May/15 04:29;hadoopqa;\\
\\
| (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:red}-1{color} | patch |   0m  0s | The patch command could not apply the patch during dryrun. |
\\
\\
|| Subsystem || Report/Notes ||
| Patch URL | http://issues.apache.org/jira/secure/attachment/12602255/HADOOP-9942-v2.patch |
| Optional Tests | javadoc javac unit findbugs checkstyle |
| git revision | trunk / f1a152c |
| Console output | https://builds.apache.org/job/PreCommit-HADOOP-Build/6287/console |


This message was automatically generated.","02/May/15 04:33;hadoopqa;\\
\\
| (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:red}-1{color} | patch |   0m  0s | The patch command could not apply the patch during dryrun. |
\\
\\
|| Subsystem || Report/Notes ||
| Patch URL | http://issues.apache.org/jira/secure/attachment/12602255/HADOOP-9942-v2.patch |
| Optional Tests | javadoc javac unit findbugs checkstyle |
| git revision | trunk / f1a152c |
| Console output | https://builds.apache.org/job/PreCommit-HADOOP-Build/6307/console |


This message was automatically generated.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
TableMapping related tests failed due to 'successful' resolving of invalid test hostname,HADOOP-11535,12771688,Test,Closed,HADOOP,Hadoop Common,software,omalley,Hadoop Common is the common library for Apache Hadoop.,http://hadoop.apache.org/,Minor,Fixed,drankye,drankye,drankye,02/Feb/15 09:51,24/Apr/15 22:49,12/Jan/21 11:55,30/Mar/15 22:55,,,,,2.7.0,,,,,,,,,,0,,,"When mvn test in my environment, it reported the following.
{noformat}
Failed tests: 
  TestTableMapping.testClearingCachedMappings:144 expected:</[rack1]> but was:</[default-rack]>
  TestTableMapping.testTableCaching:79 expected:</[rack1]> but was:</[default-rack]>
  TestTableMapping.testResolve:56 expected:</[rack1]> but was:</[default-rack]>
{noformat}

It's caused by the good resolving for the 'bad test' hostname 'a.b.c' as follows.
{noformat}
[drankye@zkdesk hadoop-common-project]$ ping a.b.c
PING a.b.c (220.250.64.228) 56(84) bytes of data.
{noformat}

I understand it may happen in just my local environment, and document this just in case others also meet this. We may use even worse hostname than 'a.b.c' to avoid such situation.",,cmccabe,drankye,hudson,stevel@apache.org,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"06/Feb/15 07:14;drankye;HADOOP-11535-v1.patch;https://issues.apache.org/jira/secure/attachment/12696981/HADOOP-11535-v1.patch",,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,2015-02-02 16:36:40.577,,,false,,,,,,,,,,,,,,,,,9223372036854775807,,,,,Mon Feb 09 00:15:43 UTC 2015,,,,,,,"0|i252hb:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,"02/Feb/15 16:36;stevel@apache.org;It's traditional to use {{something.example.org}} as the IETF mandates that these hostnames must never resolve. However if you are using Verizon fibre @ home, it may still resolve for you. There is an implicit expectation that a network doesn't work as defined.
 ","03/Feb/15 12:17;drankye;Hi Steve, thanks for your response.
bq. the IETF mandates that these hostnames must never resolve
Would you clarify which hostnames not to resolve ? Does ""a.b.c"" be such one ? Which IETF spec states this ? 
I'd like to investigate a bit further, because it always resolves in my company dev environment, which fails the tests.
Thanks.","03/Feb/15 18:28;stevel@apache.org;Reserved Top Level DNS Names, RFC2606. The test should be using one of those domains
https://tools.ietf.org/html/rfc2606","06/Feb/15 02:41;drankye;Thanks Steve for the pointing. I checked it out and see the following domain names are reserved.
{noformat}
.test
.example
.invalid
.localhost
example.com
example.net
example.org
{noformat}

So according to this, we should check the tests and replace the domain names with the reserved ones, to make sure they won't resolve. Will provide a patch accordingly.","06/Feb/15 06:15;drankye;Hmmm, looks like it's not the case. Actually whatever bad or invalid hostname is used, it can resolve to the fixed IP address in my network, as follows.
{noformat}
nslookup abc.invalid.test
Server:		10.248.2.5
Address:	10.248.2.5#53

Non-authoritative answer:
Name:	abc.invalid.test
Address: 220.250.64.228
{noformat}

So I thought in the tests we should not use hostname, instead use IP address, to avoid such bad situation at all. I'm not sure if it's the typical or not, but Java as nslookup does return non-authoritative answer when resolving a domain name. Using domain name isn't necessary for the tests. 

[~stevel@apache.org], do you agree we can change the test, not using domain name like 'a.b.c', instead using IP address like '1.2.3.4' ? Thanks.","06/Feb/15 07:14;drankye;Uploaded a patch, using IP directly.","06/Feb/15 07:15;drankye;I submit the patch any way in case it's liked.","06/Feb/15 08:14;hadoopqa;{color:green}+1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12696981/HADOOP-11535-v1.patch
  against trunk revision 9d91069.

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 1 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  There were no new javadoc warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 2.0.3) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:green}+1 core tests{color}.  The patch passed unit tests in hadoop-common-project/hadoop-common.

Test results: https://builds.apache.org/job/PreCommit-HADOOP-Build/5614//testReport/
Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/5614//console

This message is automatically generated.","06/Feb/15 12:54;stevel@apache.org;+1 for moving to ip addresses. anything that relies on DNS working is brittle and prone to failure when you run the tests offline","06/Feb/15 19:33;hudson;FAILURE: Integrated in Hadoop-trunk-Commit #7041 (See [https://builds.apache.org/job/Hadoop-trunk-Commit/7041/])
","07/Feb/15 02:40;drankye;Thanks Steve for committing the patch.","08/Feb/15 15:21;hudson;FAILURE: Integrated in Hadoop-Yarn-trunk #832 (See [https://builds.apache.org/job/Hadoop-Yarn-trunk/832/])
","08/Feb/15 16:24;hudson;FAILURE: Integrated in Hadoop-Yarn-trunk-Java8 #98 (See [https://builds.apache.org/job/Hadoop-Yarn-trunk-Java8/98/])
","08/Feb/15 20:30;hudson;SUCCESS: Integrated in Hadoop-Hdfs-trunk #2030 (See [https://builds.apache.org/job/Hadoop-Hdfs-trunk/2030/])
","08/Feb/15 21:50;hudson;FAILURE: Integrated in Hadoop-Hdfs-trunk-Java8 #95 (See [https://builds.apache.org/job/Hadoop-Hdfs-trunk-Java8/95/])
","09/Feb/15 00:14;hudson;FAILURE: Integrated in Hadoop-Mapreduce-trunk #2049 (See [https://builds.apache.org/job/Hadoop-Mapreduce-trunk/2049/])
","09/Feb/15 00:15;hudson;FAILURE: Integrated in Hadoop-Mapreduce-trunk-Java8 #99 (See [https://builds.apache.org/job/Hadoop-Mapreduce-trunk-Java8/99/])
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
TestUTF8 fails when run against java 8,HADOOP-11165,12746273,Test,Closed,HADOOP,Hadoop Common,software,omalley,Hadoop Common is the common library for Apache Hadoop.,http://hadoop.apache.org/,Minor,Fixed,schu,yuzhihong@gmail.com,yuzhihong@gmail.com,06/Oct/14 21:57,10/Apr/15 20:04,12/Jan/21 11:55,04/Nov/14 18:31,,,,,2.7.0,,,,,,test,,,,0,,,"Using jdk1.8.0_20 , I got:
{code}
testGetBytes(org.apache.hadoop.io.TestUTF8)  Time elapsed: 0.007 sec  <<< FAILURE!
junit.framework.ComparisonFailure: expected:<쑼ь⣄鬘㟻햫紖燺[?炀⃍⑰풸낓⨵ἲꬌホ쭷㛕曬䟊⁍䴥䳠領蟭뱻宭竕昚鍳튇ꊕ혶齲쏈㠮胨䩦隼᢯䍻᝴킿喝벁ࢼ듿饭玳Մ剌䒤?䳛슟녚沖᯳?訨
牙⍖?䎠旘薑春觀葝礫⁑ﻱ⣽゚굿뒦ݦ︀偆?]古絥萟浐> but was:<쑼ь⣄鬘㟻햫紖燺[�炀⃍⑰풸낓⨵ἲꬌホ쭷㛕曬䟊⁍䴥䳠領蟭뱻宭竕昚鍳튇ꊕ혶齲쏈㠮胨䩦隼᢯䍻᝴킿喝벁ࢼ듿饭玳Մ剌䒤�䳛슟녚᯳�訨牙⍖�䎠旘薑春觀葝礫⁑ﻱ⣽゚굿뒦ݦ︀偆�]古絥萟浐>
        at junit.framework.Assert.assertEquals(Assert.java:100)
        at junit.framework.Assert.assertEquals(Assert.java:107)
        at junit.framework.TestCase.assertEquals(TestCase.java:269)
        at org.apache.hadoop.io.TestUTF8.testGetBytes(TestUTF8.java:58)

testIO(org.apache.hadoop.io.TestUTF8)  Time elapsed: 0.002 sec  <<< FAILURE!
junit.framework.ComparisonFailure: expected:<...ᨍ⁖粩⧬车﹂脖朷䝄懒댵突疼資⍣眠畠忁[?]䪐ゑ鬍鍅遻ꈸ釡> but was:<...ᨍ⁖粩⧬车﹂脖朷䝄懒댵突疼資⍣眠畠忁[�]䪐ゑ鬍鍅遻>ꈸ釡>
        at junit.framework.Assert.assertEquals(Assert.java:100)
        at junit.framework.Assert.assertEquals(Assert.java:107)
        at junit.framework.TestCase.assertEquals(TestCase.java:269)
        at org.apache.hadoop.io.TestUTF8.testIO(TestUTF8.java:86)
{code}",,aajisaka,cnauroth,hudson,schu,yuzhihong@gmail.com,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,HADOOP-11090,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"03/Nov/14 21:56;schu;HADOOP-11165.1.patch;https://issues.apache.org/jira/secure/attachment/12679043/HADOOP-11165.1.patch",,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,2014-11-03 21:21:16.028,,,false,,,,,,,,,,,,,,,,,9223372036854775807,Reviewed,,,,Wed Nov 05 15:15:28 UTC 2014,,,,,,,"0|i20v0f:",9223372036854775807,,,,,,,,,,,,,2.7.0,,,,,,,,,,"03/Nov/14 21:21;schu;This is related to http://stackoverflow.com/questions/25404373/java-8-utf-8-encoding-issue-java-bug:

""It is a property of the “Modified UTF-8” encoding to store surrogate pairs (or even unpaired chars of that range) like individual characters. And it’s an error if a decoder claiming to use standard UTF-8 uses “Modified UTF-8”. This seems to have been fixed with Java 8.""

So when running the test in Java 8, we'll get mismatching Strings because {{new String(UTF8.getBytes(before), ""UTF-8"")}} will not decode using ""Modified UTF-8"" anymore.","03/Nov/14 21:56;schu;Attaching a fix to {{TestUTF8}}.

{{new String(..., ""UTF-8"")}} in JDK8 now correctly corresponds to decoding in _UTF-8_, instead of _Modified UTF-8_ which the {{DataInput}} and {{DataOutput}} interfaces use.

Made the following changes:

* in _testGetBytes_, we now convert the Modified UTF8 formatted bytes to String properly using DataInput's {{readUTF}}.
* Remove one test from _testIO_ that uses the {{new String(..., ""UTF-8"")}} to decode UTF-8 because that does not read modified UTF8 anymore in JDK8.

I built + ran successfully using JDK6/7/8.","03/Nov/14 22:51;hadoopqa;{color:green}+1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12679043/HADOOP-11165.1.patch
  against trunk revision ec6cbec.

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 1 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  There were no new javadoc warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 2.0.3) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:green}+1 core tests{color}.  The patch passed unit tests in hadoop-common-project/hadoop-common.

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HADOOP-Build/5008//testReport/
Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/5008//console

This message is automatically generated.","04/Nov/14 18:25;cnauroth;+1 for the patch.  I'll commit this.","04/Nov/14 18:31;cnauroth;I have committed this to trunk and branch-2.  Ted, thank you for reporting the problem.  Stephen, thank you for the analysis and the patch.","04/Nov/14 18:32;hudson;FAILURE: Integrated in Hadoop-trunk-Commit #6435 (See [https://builds.apache.org/job/Hadoop-trunk-Commit/6435/])
HADOOP-11165. TestUTF8 fails when run against java 8. Contributed by Stephen Chu. (cnauroth: rev 85da71c2d3c565a8920e47fe3925e8e0bef353a5)
* hadoop-common-project/hadoop-common/CHANGES.txt
* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/TestUTF8.java
","04/Nov/14 18:36;schu;Thanks a lot, Chris.","05/Nov/14 11:51;hudson;SUCCESS: Integrated in Hadoop-Yarn-trunk #734 (See [https://builds.apache.org/job/Hadoop-Yarn-trunk/734/])
HADOOP-11165. TestUTF8 fails when run against java 8. Contributed by Stephen Chu. (cnauroth: rev 85da71c2d3c565a8920e47fe3925e8e0bef353a5)
* hadoop-common-project/hadoop-common/CHANGES.txt
* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/TestUTF8.java
","05/Nov/14 14:14;hudson;FAILURE: Integrated in Hadoop-Hdfs-trunk #1923 (See [https://builds.apache.org/job/Hadoop-Hdfs-trunk/1923/])
HADOOP-11165. TestUTF8 fails when run against java 8. Contributed by Stephen Chu. (cnauroth: rev 85da71c2d3c565a8920e47fe3925e8e0bef353a5)
* hadoop-common-project/hadoop-common/CHANGES.txt
* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/TestUTF8.java
","05/Nov/14 15:15;hudson;FAILURE: Integrated in Hadoop-Mapreduce-trunk #1948 (See [https://builds.apache.org/job/Hadoop-Mapreduce-trunk/1948/])
HADOOP-11165. TestUTF8 fails when run against java 8. Contributed by Stephen Chu. (cnauroth: rev 85da71c2d3c565a8920e47fe3925e8e0bef353a5)
* hadoop-common-project/hadoop-common/CHANGES.txt
* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/TestUTF8.java
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Fix Hadoop unit test failures on Windows,HADOOP-11795,12787755,Test,Open,HADOOP,Hadoop Common,software,omalley,Hadoop Common is the common library for Apache Hadoop.,http://hadoop.apache.org/,Minor,,xyao,xyao,xyao,02/Apr/15 18:00,07/Apr/15 20:59,12/Jan/21 11:55,,,,,,,,,,,,,,,,0,,,,,xyao,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,HDFS-7947,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,9223372036854775807,,,,,2015-04-02 18:00:12.0,,,,,,,"0|i27prr:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
KMSClientProvider should drain the local generated EEK cache on key rollover,HADOOP-11071,12739583,Test,Closed,HADOOP,Hadoop Common,software,omalley,Hadoop Common is the common library for Apache Hadoop.,http://hadoop.apache.org/,Minor,Fixed,tucu00,tucu00,tucu00,05/Sep/14 20:19,01/Dec/14 03:08,12/Jan/21 11:55,08/Sep/14 18:34,2.6.0,,,,2.6.0,,,,,,security,,,,0,,,This is for formal correctness and to enable HDFS EZ to verify a rollover when testing with KMS,,andrew.wang,hudson,tucu00,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,HDFS-7006,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"08/Sep/14 17:11;tucu00;HADOOP-11071.patch;https://issues.apache.org/jira/secure/attachment/12667199/HADOOP-11071.patch","08/Sep/14 16:54;tucu00;HADOOP-11071.patch;https://issues.apache.org/jira/secure/attachment/12667193/HADOOP-11071.patch","05/Sep/14 20:44;tucu00;HADOOP-11071.patch;https://issues.apache.org/jira/secure/attachment/12666888/HADOOP-11071.patch","05/Sep/14 20:19;tucu00;HADOOP-11071.patch;https://issues.apache.org/jira/secure/attachment/12666877/HADOOP-11071.patch",,,,,,,,,,,,,,,,,,,,4.0,,,,,,,,,,,,,,,,,,,,2014-09-05 20:33:55.29,,,false,,,,,,,,,,,,,,,,,9223372036854775807,Reviewed,,,,Tue Sep 09 14:07:13 UTC 2014,,,,,,,"0|i1zqqf:",9223372036854775807,,,,,,,,,,,,,2.6.0,,,,,,,,,,"05/Sep/14 20:33;andrew.wang;* Need javadoc on new drain method
* I assume you call getNext() to refill the key cache? This seems like a weird thing to hardcode in, do we have to do this?","05/Sep/14 20:44;tucu00;new patch adding javadoc to drain(), removing getNext() (you right Andrew) and adding testcase.","05/Sep/14 20:55;andrew.wang;Thanks tucu, +1","05/Sep/14 21:08;hadoopqa;{color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12666877/HADOOP-11071.patch
  against trunk revision 0571b45.

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:red}-1 tests included{color}.  The patch doesn't appear to include any new or modified tests.
                        Please justify why no new tests are needed for this patch.
                        Also please list what manual steps were performed to verify this patch.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  There were no new javadoc warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 2.0.3) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:green}+1 core tests{color}.  The patch passed unit tests in hadoop-common-project/hadoop-common.

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HADOOP-Build/4662//testReport/
Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/4662//console

This message is automatically generated.","05/Sep/14 21:38;hadoopqa;{color:green}+1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12666888/HADOOP-11071.patch
  against trunk revision 0571b45.

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 1 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  There were no new javadoc warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 2.0.3) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:green}+1 core tests{color}.  The patch passed unit tests in hadoop-common-project/hadoop-common.

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HADOOP-Build/4663//testReport/
Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/4663//console

This message is automatically generated.","08/Sep/14 16:54;tucu00;new patch, previous patch was not correct as the draining was done in the wrong abstraction and it was not covering the server side correctly. Also added testcase that verifies draining on both client and server side. And, I've verified with HDFS-7006 as well.","08/Sep/14 17:11;tucu00;There was some javadoc mis-formatting in the last patch, updating.","08/Sep/14 17:57;hadoopqa;{color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12667193/HADOOP-11071.patch
  against trunk revision 302d9a0.

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 2 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  There were no new javadoc warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 2.0.3) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:red}-1 core tests{color}.  The patch failed these unit tests in hadoop-common-project/hadoop-common hadoop-common-project/hadoop-kms:

                  org.apache.hadoop.crypto.key.kms.server.TestKMS

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HADOOP-Build/4669//testReport/
Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/4669//console

This message is automatically generated.","08/Sep/14 17:59;andrew.wang;I took a closer look at this, with synchronization in mind. The hypothetical concern here would be that an async filler thread might be putting an old key when the drain happens. Additionally, the Oracle docs say that BlockingQueue#addAll isn't atomic, so {{keyQueue.addAll}} in the {{fillQueueForKey}} implementations is suspect. We likely need to add some locking.

Regarding testing, is there a way to test that before rolling, there's a cached key on both the client and server side, and then after, there isn't on either?

Thanks Tucu.","08/Sep/14 18:19;tucu00;Regarding addAll not being atomic, that is not an issue since atomicity is not a concern and we are using threadsafe data structures. So I think we are good there.

Regarding testing, the added test, using KMS, verifies the client & server caches are drained because of a rollover, getting a new EEK produces an EEK using the new key version. Note that under normal circumstances this is not the typical scenario (the client rolling the key also consuming generated keys), though this is exercised by HDFS-7006. In a typical usecase, a key shell invocation will roll a key triggering the KMS to flush its server side pre-generated EEKs, any client (ie HDFS NN) that has client side pre-generated keys will continue consuming the pre-generated EEKs with the prior key version. This means that there is a maximum number of EEKs with the prior key version that can used after a rollover. If this a is a concern, client side pre-generated keys may be disabled in the NN with a performance trade off. IMO, it is reasonable to assume that at most X (X being the client side pre-generated EEK cache) EEK with  a prior key version will be used.
 
test failure is due to too many open files.","08/Sep/14 18:24;hadoopqa;{color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12667199/HADOOP-11071.patch
  against trunk revision 302d9a0.

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 2 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  There were no new javadoc warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 2.0.3) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:red}-1 core tests{color}.  The patch failed these unit tests in hadoop-common-project/hadoop-common hadoop-common-project/hadoop-kms:

                  org.apache.hadoop.ha.TestZKFailoverControllerStress
                  org.apache.hadoop.crypto.key.kms.server.TestKMS

                                      The following test timeouts occurred in hadoop-common-project/hadoop-common hadoop-common-project/hadoop-kms:

org.apache.hadoop.security.token.delegation.web.TestWebDelegationToken

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HADOOP-Build/4670//testReport/
Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/4670//console

This message is automatically generated.","08/Sep/14 18:32;andrew.wang;+1, yea that all makes sense. I was thinking about HDFS-6971, since I'd like to have a way of ensuring that no old keys are being used on the NN. We can take care of the concurrency stuff there.","08/Sep/14 18:34;tucu00;committed to trunk and branch-2.","09/Sep/14 11:23;hudson;FAILURE: Integrated in Hadoop-Yarn-trunk #675 (See [https://builds.apache.org/job/Hadoop-Yarn-trunk/675/])
HADOOP-11071. KMSClientProvider should drain the local generated EEK cache on key rollover. (tucu) (tucu: rev df8c84cba8512058f5097c6faeedf4b65cab3806)
* hadoop-common-project/hadoop-common/CHANGES.txt
* hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/crypto/key/kms/ValueQueue.java
* hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/crypto/key/KeyProviderCryptoExtension.java
* hadoop-common-project/hadoop-kms/src/test/java/org/apache/hadoop/crypto/key/kms/server/TestKMS.java
* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/crypto/key/TestValueQueue.java
* hadoop-common-project/hadoop-kms/src/main/java/org/apache/hadoop/crypto/key/kms/server/EagerKeyGeneratorKeyProviderCryptoExtension.java
* hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/crypto/key/kms/KMSClientProvider.java
","09/Sep/14 13:44;hudson;FAILURE: Integrated in Hadoop-Mapreduce-trunk #1891 (See [https://builds.apache.org/job/Hadoop-Mapreduce-trunk/1891/])
HADOOP-11071. KMSClientProvider should drain the local generated EEK cache on key rollover. (tucu) (tucu: rev df8c84cba8512058f5097c6faeedf4b65cab3806)
* hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/crypto/key/kms/ValueQueue.java
* hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/crypto/key/kms/KMSClientProvider.java
* hadoop-common-project/hadoop-kms/src/test/java/org/apache/hadoop/crypto/key/kms/server/TestKMS.java
* hadoop-common-project/hadoop-common/CHANGES.txt
* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/crypto/key/TestValueQueue.java
* hadoop-common-project/hadoop-kms/src/main/java/org/apache/hadoop/crypto/key/kms/server/EagerKeyGeneratorKeyProviderCryptoExtension.java
* hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/crypto/key/KeyProviderCryptoExtension.java
","09/Sep/14 14:07;hudson;SUCCESS: Integrated in Hadoop-Hdfs-trunk #1866 (See [https://builds.apache.org/job/Hadoop-Hdfs-trunk/1866/])
HADOOP-11071. KMSClientProvider should drain the local generated EEK cache on key rollover. (tucu) (tucu: rev df8c84cba8512058f5097c6faeedf4b65cab3806)
* hadoop-common-project/hadoop-kms/src/main/java/org/apache/hadoop/crypto/key/kms/server/EagerKeyGeneratorKeyProviderCryptoExtension.java
* hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/crypto/key/KeyProviderCryptoExtension.java
* hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/crypto/key/kms/ValueQueue.java
* hadoop-common-project/hadoop-common/CHANGES.txt
* hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/crypto/key/kms/KMSClientProvider.java
* hadoop-common-project/hadoop-kms/src/test/java/org/apache/hadoop/crypto/key/kms/server/TestKMS.java
* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/crypto/key/TestValueQueue.java
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
TestSSLFactory fails on Java 8,HADOOP-11275,12753111,Test,Resolved,HADOOP,Hadoop Common,software,omalley,Hadoop Common is the common library for Apache Hadoop.,http://hadoop.apache.org/,Minor,Not A Problem,,yuzhihong@gmail.com,yuzhihong@gmail.com,05/Nov/14 18:06,05/Nov/14 18:18,12/Jan/21 11:55,05/Nov/14 18:18,,,,,,,,,,,,,,,0,,,"Below are a few of the exceptions I got running this test against Java 8:
{code}
Running org.apache.hadoop.security.ssl.TestSSLFactory
Tests run: 15, Failures: 0, Errors: 14, Skipped: 0, Time elapsed: 1.724 sec <<< FAILURE! - in org.apache.hadoop.security.ssl.TestSSLFactory
testNoClientCertsInitialization(org.apache.hadoop.security.ssl.TestSSLFactory)  Time elapsed: 0.177 sec  <<< ERROR!
java.security.cert.CertificateException: Subject class type invalid.
        at sun.security.x509.X509CertInfo.setSubject(X509CertInfo.java:888)
        at sun.security.x509.X509CertInfo.set(X509CertInfo.java:415)
        at org.apache.hadoop.security.ssl.KeyStoreTestUtil.generateCertificate(KeyStoreTestUtil.java:96)
        at org.apache.hadoop.security.ssl.KeyStoreTestUtil.setupSSLConfig(KeyStoreTestUtil.java:268)
        at org.apache.hadoop.security.ssl.TestSSLFactory.createConfiguration(TestSSLFactory.java:64)
        at org.apache.hadoop.security.ssl.TestSSLFactory.testNoClientCertsInitialization(TestSSLFactory.java:337)

testServerKeyPasswordDefaultsToPassword(org.apache.hadoop.security.ssl.TestSSLFactory)  Time elapsed: 0.189 sec  <<< ERROR!
java.security.cert.CertificateException: Subject class type invalid.
        at sun.security.x509.X509CertInfo.setSubject(X509CertInfo.java:888)
        at sun.security.x509.X509CertInfo.set(X509CertInfo.java:415)
        at org.apache.hadoop.security.ssl.KeyStoreTestUtil.generateCertificate(KeyStoreTestUtil.java:96)
        at org.apache.hadoop.security.ssl.TestSSLFactory.checkSSLFactoryInitWithPasswords(TestSSLFactory.java:283)
        at org.apache.hadoop.security.ssl.TestSSLFactory.checkSSLFactoryInitWithPasswords(TestSSLFactory.java:248)
        at org.apache.hadoop.security.ssl.TestSSLFactory.testServerKeyPasswordDefaultsToPassword(TestSSLFactory.java:205)

testServerCredProviderPasswords(org.apache.hadoop.security.ssl.TestSSLFactory)  Time elapsed: 0.462 sec  <<< ERROR!
java.security.cert.CertificateException: Subject class type invalid.
        at sun.security.x509.X509CertInfo.setSubject(X509CertInfo.java:888)
        at sun.security.x509.X509CertInfo.set(X509CertInfo.java:415)
        at org.apache.hadoop.security.ssl.KeyStoreTestUtil.generateCertificate(KeyStoreTestUtil.java:96)
        at org.apache.hadoop.security.ssl.TestSSLFactory.checkSSLFactoryInitWithPasswords(TestSSLFactory.java:283)
        at org.apache.hadoop.security.ssl.TestSSLFactory.testServerCredProviderPasswords(TestSSLFactory.java:224)

testClientDifferentPasswordAndKeyPassword(org.apache.hadoop.security.ssl.TestSSLFactory)  Time elapsed: 0.059 sec  <<< ERROR!
java.security.cert.CertificateException: Subject class type invalid.
        at sun.security.x509.X509CertInfo.setSubject(X509CertInfo.java:888)
        at sun.security.x509.X509CertInfo.set(X509CertInfo.java:415)
        at org.apache.hadoop.security.ssl.KeyStoreTestUtil.generateCertificate(KeyStoreTestUtil.java:96)
        at org.apache.hadoop.security.ssl.TestSSLFactory.checkSSLFactoryInitWithPasswords(TestSSLFactory.java:283)
        at org.apache.hadoop.security.ssl.TestSSLFactory.checkSSLFactoryInitWithPasswords(TestSSLFactory.java:248)
        at org.apache.hadoop.security.ssl.TestSSLFactory.testClientDifferentPasswordAndKeyPassword(TestSSLFactory.java:211)
{code}",,schu,yuzhihong@gmail.com,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,2014-11-05 18:12:43.108,,,false,,,,,,,,,,,,,,,,,9223372036854775807,,,,,Wed Nov 05 18:18:48 UTC 2014,,,,,,,"0|i220d3:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,"05/Nov/14 18:12;schu;What version did you run with?

I think this is fixed in latest trunk with:

HADOOP-10847
HADOOP-11230","05/Nov/14 18:18;yuzhihong@gmail.com;Refreshed workspace and this test passes.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
TestUserGroupInformation#testLogin is flaky,HADOOP-10207,12687537,Test,Closed,HADOOP,Hadoop Common,software,omalley,Hadoop Common is the common library for Apache Hadoop.,http://hadoop.apache.org/,Minor,Fixed,jxiang,jxiang,jxiang,06/Jan/14 22:12,03/Sep/14 23:33,12/Jan/21 11:55,08/Jan/14 23:28,,,,,2.3.0,,,,,,,,,,0,,,"This test depends on the execution order of tests. If TestUserGroupInformation#testGetServerSideGroups() runs first, TestUserGroupInformation#testLogin will fail.",,cmccabe,hudson,jxiang,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,HDFS-5220,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"06/Jan/14 22:14;jxiang;2.4-5220.patch;https://issues.apache.org/jira/secure/attachment/12621695/2.4-5220.patch","06/Jan/14 22:15;jxiang;hadoop-10207.patch;https://issues.apache.org/jira/secure/attachment/12621696/hadoop-10207.patch",,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,2014-01-06 22:55:26.275,,,false,,,,,,,,,,,,,,,,,366538,,,,,Thu Jan 09 14:44:13 UTC 2014,,,,,,,"0|i1r6jb:",366849,,,,,,,,,,,,,,,,,,,,,,,"06/Jan/14 22:55;hadoopqa;{color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12621696/hadoop-10207.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 1 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:red}-1 javadoc{color}.  The javadoc tool appears to have generated 14 warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:green}+1 core tests{color}.  The patch passed unit tests in hadoop-common-project/hadoop-common.

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HADOOP-Build/3403//testReport/
Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/3403//console

This message is automatically generated.","06/Jan/14 23:37;jxiang;The javadoc warning is not related to this patch: https://builds.apache.org/job/PreCommit-HADOOP-Build/3403/artifact/trunk/patchprocess/patchJavadocWarnings.txt","08/Jan/14 22:13;cmccabe;+1.  thanks, jimmy","08/Jan/14 23:16;hudson;SUCCESS: Integrated in Hadoop-trunk-Commit #4976 (See [https://builds.apache.org/job/Hadoop-trunk-Commit/4976/])
HADOOP-10207. TestUserGroupInformation#testLogin is flaky (jxiang via cmccabe) (cmccabe: http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1556664)
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/CHANGES.txt
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/security/TestUserGroupInformation.java
","09/Jan/14 11:00;hudson;FAILURE: Integrated in Hadoop-Yarn-trunk #447 (See [https://builds.apache.org/job/Hadoop-Yarn-trunk/447/])
HADOOP-10207. TestUserGroupInformation#testLogin is flaky (jxiang via cmccabe) (cmccabe: http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1556664)
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/CHANGES.txt
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/security/TestUserGroupInformation.java
","09/Jan/14 13:26;hudson;FAILURE: Integrated in Hadoop-Hdfs-trunk #1639 (See [https://builds.apache.org/job/Hadoop-Hdfs-trunk/1639/])
HADOOP-10207. TestUserGroupInformation#testLogin is flaky (jxiang via cmccabe) (cmccabe: http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1556664)
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/CHANGES.txt
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/security/TestUserGroupInformation.java
","09/Jan/14 14:44;hudson;SUCCESS: Integrated in Hadoop-Mapreduce-trunk #1664 (See [https://builds.apache.org/job/Hadoop-Mapreduce-trunk/1664/])
HADOOP-10207. TestUserGroupInformation#testLogin is flaky (jxiang via cmccabe) (cmccabe: http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1556664)
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/CHANGES.txt
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/security/TestUserGroupInformation.java
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"provide test for method org.apache.hadoop.fs.LocalFileSystem.reportChecksumFailure(Path, FSDataInputStream, long, FSDataInputStream, long)",HADOOP-9067,12616929,Test,Closed,HADOOP,Hadoop Common,software,omalley,Hadoop Common is the common library for Apache Hadoop.,http://hadoop.apache.org/,Minor,Fixed,iveselovsky,iveselovsky,iveselovsky,20/Nov/12 13:10,03/Sep/14 23:27,12/Jan/21 11:55,01/Feb/13 21:26,,,,,0.23.7,2.0.3-alpha,,,,,,,,,0,,,this method is not covered by the existing unit tests. Provide a test to cover it.,,aklochkov,eyang,hudson,iveselovsky,jlowe,revans2,sureshms,tgraves,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"20/Nov/12 13:52;iveselovsky;HADOOP-9067--b.patch;https://issues.apache.org/jira/secure/attachment/12554344/HADOOP-9067--b.patch","20/Nov/12 13:20;iveselovsky;HADOOP-9067.patch;https://issues.apache.org/jira/secure/attachment/12554342/HADOOP-9067.patch",,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,2012-11-20 13:47:43.429,,,false,,,,,,,,,,,,,,,,,258818,,,,,Wed Feb 27 16:12:20 UTC 2013,,,,,,,"0|i0l4jb:",121385,,,,,,,,,,,,,,,,,,,,,,,"20/Nov/12 13:47;hadoopqa;{color:green}+1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12554342/HADOOP-9067.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 1 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  The javadoc tool did not generate any warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:green}+1 core tests{color}.  The patch passed unit tests in hadoop-common-project/hadoop-common.

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HADOOP-Build/1778//testReport/
Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/1778//console

This message is automatically generated.","20/Nov/12 13:52;iveselovsky;the new test sligtly improved to cover more methods from LocalFileSystem.","20/Nov/12 14:28;hadoopqa;{color:green}+1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12554344/HADOOP-9067--b.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 1 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  The javadoc tool did not generate any warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:green}+1 core tests{color}.  The patch passed unit tests in hadoop-common-project/hadoop-common.

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HADOOP-Build/1779//testReport/
Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/1779//console

This message is automatically generated.","01/Feb/13 20:26;revans2;The patch is a little old (sorry about taking so long to review it) but it still applies and runs just fine on trunk and branch-0.23.  I kicked Jenkins again to be sure everything else comes out OK.  If it does I am +1 on this patch.  I'll check it in once  Jenkins finishes.","01/Feb/13 20:59;hadoopqa;{color:green}+1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12554344/HADOOP-9067--b.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 1 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  The javadoc tool did not generate any warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:green}+1 core tests{color}.  The patch passed unit tests in hadoop-common-project/hadoop-common.

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HADOOP-Build/2134//testReport/
Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/2134//console

This message is automatically generated.","01/Feb/13 21:14;hudson;Integrated in Hadoop-trunk-Commit #3312 (See [https://builds.apache.org/job/Hadoop-trunk-Commit/3312/])
    HADOOP-9067. provide test for LocalFileSystem.reportChecksumFailure (Ivan A. Veselovsky via bobby) (Revision 1441628)

     Result = SUCCESS
bobby : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1441628
Files : 
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/CHANGES.txt
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/TestLocalFileSystem.java
","01/Feb/13 21:26;revans2;Thanks Ivan, I put this into trunk, branch-2, and branch-0.23.","02/Feb/13 10:46;hudson;Integrated in Hadoop-Yarn-trunk #115 (See [https://builds.apache.org/job/Hadoop-Yarn-trunk/115/])
    HADOOP-9067. provide test for LocalFileSystem.reportChecksumFailure (Ivan A. Veselovsky via bobby) (Revision 1441628)

     Result = SUCCESS
bobby : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1441628
Files : 
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/CHANGES.txt
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/TestLocalFileSystem.java
","02/Feb/13 12:40;hudson;Integrated in Hadoop-Hdfs-0.23-Build #513 (See [https://builds.apache.org/job/Hadoop-Hdfs-0.23-Build/513/])
    svn merge -c 1441628 FIXES: HADOOP-9067. provide test for LocalFileSystem.reportChecksumFailure (Ivan A. Veselovsky via bobby) (Revision 1441638)

     Result = SUCCESS
bobby : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1441638
Files : 
* /hadoop/common/branches/branch-0.23/hadoop-common-project/hadoop-common/CHANGES.txt
* /hadoop/common/branches/branch-0.23/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/TestLocalFileSystem.java
","02/Feb/13 13:02;hudson;Integrated in Hadoop-Hdfs-trunk #1304 (See [https://builds.apache.org/job/Hadoop-Hdfs-trunk/1304/])
    HADOOP-9067. provide test for LocalFileSystem.reportChecksumFailure (Ivan A. Veselovsky via bobby) (Revision 1441628)

     Result = SUCCESS
bobby : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1441628
Files : 
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/CHANGES.txt
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/TestLocalFileSystem.java
","02/Feb/13 14:04;hudson;Integrated in Hadoop-Mapreduce-trunk #1332 (See [https://builds.apache.org/job/Hadoop-Mapreduce-trunk/1332/])
    HADOOP-9067. provide test for LocalFileSystem.reportChecksumFailure (Ivan A. Veselovsky via bobby) (Revision 1441628)

     Result = SUCCESS
bobby : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1441628
Files : 
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/CHANGES.txt
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/TestLocalFileSystem.java
","16/Feb/13 19:11;eyang;This patch is triggering test case failure on trunk:

Tests run: 11, Failures: 1, Errors: 0, Skipped: 0, Time elapsed: 0.863 sec <<< FAILURE!
testReportChecksumFailure(org.apache.hadoop.fs.TestLocalFileSystem)  Time elapsed: 42 sec  <<< FAILURE!
java.lang.AssertionError: 
	at org.junit.Assert.fail(Assert.java:91)
	at org.junit.Assert.assertTrue(Assert.java:43)
	at org.junit.Assert.assertTrue(Assert.java:54)
	at org.apache.hadoop.fs.TestLocalFileSystem.testReportChecksumFailure(TestLocalFileSystem.java:327)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:44)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:15)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:41)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:20)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:28)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:31)
	at org.junit.runners.BlockJUnit4ClassRunner.runNotIgnored(BlockJUnit4ClassRunner.java:79)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:71)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:49)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:193)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:52)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:191)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:42)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:184)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:236)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:252)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:141)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:112)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.maven.surefire.util.ReflectionUtils.invokeMethodWithArray(ReflectionUtils.java:189)
	at org.apache.maven.surefire.booter.ProviderFactory$ProviderProxy.invoke(ProviderFactory.java:165)
	at org.apache.maven.surefire.booter.ProviderFactory.invokeProvider(ProviderFactory.java:85)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:115)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:75)","19/Feb/13 13:03;iveselovsky;Hi, Eric,
It looks like I cannot reproduce this failure.
We have hadoop builds running on regular basis, and this test never fails.
Also it passes in Apache builds, e.g. https://builds.apache.org/view/Hadoop/job/Hadoop-Common-trunk/689/consoleFull .
Can you please provide more info on this failure: what OS/java/maven options you use? 
Also full log in debug level may be helpful.","23/Feb/13 18:23;eyang;I tested this on Mac 10.8.2 and Java 1.6.0_37, which is probably no longer supported?","27/Feb/13 16:12;iveselovsky;Hi, Eric, 
i found the reason of the failure: o.a.h.fs.DF#getMount() does not work correctly on Mac OS. The Java version does not play a role there.
I created issue https://issues.apache.org/jira/browse/HADOOP-9337 to address the problem. In the 9337's description I suggest 2 ways of fix: can you please share your opinion on which one seems to be preferable?


",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
provide unit-test coverage of class org.apache.hadoop.fs.LocalDirAllocator.AllocatorPerContext.PathIterator,HADOOP-9038,12616082,Test,Closed,HADOOP,Hadoop Common,software,omalley,Hadoop Common is the common library for Apache Hadoop.,http://hadoop.apache.org/,Minor,Fixed,iveselovsky,iveselovsky,iveselovsky,14/Nov/12 16:02,03/Sep/14 23:23,12/Jan/21 11:55,26/Nov/12 18:51,,,,,0.23.6,2.0.3-alpha,,,,,,,,,0,,,The class org.apache.hadoop.fs.LocalDirAllocator.AllocatorPerContext.PathIterator currently has zero unit-test coverage. Add/enhance the tests to provide one.,,aklochkov,hudson,iveselovsky,jlowe,revans2,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"15/Nov/12 12:44;iveselovsky;HADOOP-9038.patch;https://issues.apache.org/jira/secure/attachment/12553652/HADOOP-9038.patch",,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,2012-11-15 13:26:11.082,,,false,,,,,,,,,,,,,,,,,257825,,,,,Tue Nov 27 13:23:52 UTC 2012,,,,,,,"0|i0kk93:",118098,,,,,,,,,,,,,,,,,,,,,,,"15/Nov/12 12:44;iveselovsky;attached patch ""HADOOP-9038"" adds a new unit test to check the mentioned functionality, + makes one correction in method PathIterator#next() implementation.","15/Nov/12 13:26;hadoopqa;{color:green}+1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12553652/HADOOP-9038.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 1 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  The javadoc tool did not generate any warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:green}+1 core tests{color}.  The patch passed unit tests in hadoop-common-project/hadoop-common.

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HADOOP-Build/1750//testReport/
Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/1750//console

This message is automatically generated.","26/Nov/12 18:43;revans2;The changes look fine to me.  I like that we are now conforming correctly to the Iterable interface. +1","26/Nov/12 18:51;revans2;Thanks Ivan,

I put this into trunk, branch-2, and branch-0.23","26/Nov/12 18:57;hudson;Integrated in Hadoop-trunk-Commit #3058 (See [https://builds.apache.org/job/Hadoop-trunk-Commit/3058/])
    HADOOP-9038. unit-tests for AllocatorPerContext.PathIterator (Ivan A. Veselovsky via bobby) (Revision 1413776)

     Result = SUCCESS
bobby : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1413776
Files : 
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/CHANGES.txt
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/LocalDirAllocator.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/TestLocalDirAllocator.java
","27/Nov/12 10:52;hudson;Integrated in Hadoop-Yarn-trunk #49 (See [https://builds.apache.org/job/Hadoop-Yarn-trunk/49/])
    HADOOP-9038. unit-tests for AllocatorPerContext.PathIterator (Ivan A. Veselovsky via bobby) (Revision 1413776)

     Result = SUCCESS
bobby : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1413776
Files : 
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/CHANGES.txt
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/LocalDirAllocator.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/TestLocalDirAllocator.java
","27/Nov/12 12:46;hudson;Integrated in Hadoop-Hdfs-0.23-Build #448 (See [https://builds.apache.org/job/Hadoop-Hdfs-0.23-Build/448/])
    svn merge -c 1413776 FIXES: HADOOP-9038. unit-tests for AllocatorPerContext.PathIterator (Ivan A. Veselovsky via bobby) (Revision 1413779)

     Result = SUCCESS
bobby : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1413779
Files : 
* /hadoop/common/branches/branch-0.23/hadoop-common-project/hadoop-common/CHANGES.txt
* /hadoop/common/branches/branch-0.23/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/LocalDirAllocator.java
* /hadoop/common/branches/branch-0.23/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/TestLocalDirAllocator.java
","27/Nov/12 13:08;hudson;Integrated in Hadoop-Hdfs-trunk #1239 (See [https://builds.apache.org/job/Hadoop-Hdfs-trunk/1239/])
    HADOOP-9038. unit-tests for AllocatorPerContext.PathIterator (Ivan A. Veselovsky via bobby) (Revision 1413776)

     Result = SUCCESS
bobby : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1413776
Files : 
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/CHANGES.txt
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/LocalDirAllocator.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/TestLocalDirAllocator.java
","27/Nov/12 13:23;hudson;Integrated in Hadoop-Mapreduce-trunk #1270 (See [https://builds.apache.org/job/Hadoop-Mapreduce-trunk/1270/])
    HADOOP-9038. unit-tests for AllocatorPerContext.PathIterator (Ivan A. Veselovsky via bobby) (Revision 1413776)

     Result = FAILURE
bobby : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1413776
Files : 
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/CHANGES.txt
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/LocalDirAllocator.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/TestLocalDirAllocator.java
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"calls to junit Assert::assertEquals invert arguments, causing misleading error messages, other minor improvements.",HADOOP-3679,12399407,Test,Closed,HADOOP,Hadoop Common,software,omalley,Hadoop Common is the common library for Apache Hadoop.,http://hadoop.apache.org/,Minor,Fixed,jayunit100,cdouglas,cdouglas,01/Jul/08 22:12,03/Sep/14 20:36,12/Jan/21 11:55,14/Mar/14 00:52,,,,,2.5.0,,,,,,test,,,,0,,,"JUnit Assert::assertEquals takes its expected and actual arguments in a particular order, but many unit tests invert them. The error message from a failed assertion can be misleading.",,aajisaka,cdouglas,hudson,jayunit100,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"05/Mar/14 19:32;jayunit100;HADOOP-3679.2.patch;https://issues.apache.org/jira/secure/attachment/12632895/HADOOP-3679.2.patch","07/Mar/14 02:15;jayunit100;HADOOP-3679.3.patch;https://issues.apache.org/jira/secure/attachment/12633292/HADOOP-3679.3.patch","07/Mar/14 23:01;jayunit100;HADOOP-3679.4.patch;https://issues.apache.org/jira/secure/attachment/12633481/HADOOP-3679.4.patch","08/Mar/14 19:34;jayunit100;HADOOP-3679.5.patch;https://issues.apache.org/jira/secure/attachment/12633558/HADOOP-3679.5.patch","07/Mar/14 00:08;jayunit100;HADOOP-3679.patch;https://issues.apache.org/jira/secure/attachment/12633263/HADOOP-3679.patch",,,,,,,,,,,,,,,,,,,5.0,,,,,,,,,,,,,,,,,,,,2014-02-25 00:42:02.502,,,false,,,,,,,,,,,,,,,,,126103,Reviewed,,,,Fri Mar 14 21:06:09 UTC 2014,,,,,,,"0|i0iaqf:",104833,,,,,,,,,,,,,,,,,,,,,,,"25/Feb/14 00:42;jayunit100;Okay, I've done an initial look at this and found 

{noformat}
TestDataByteBuffers
TestStat 
TestIOUtils 
TestRPC 
nfs3/TestFileHandle.java
util/TestGenericsUtil.java
TestNetworkTopologyWithNodeGroup.java
TestText.java
TestTFileComparator2 
TestPath.java
TestIdUserGroup.java
TestXDR.java
{noformat}","25/Feb/14 00:43;jayunit100;Shall i start a patch on this ? ^^ It will include reversing assertEquals args for those classes.  I cant gaurantee that it covers all 1500+ unit tests in the hadoop-common-project, but it probably gets a large chunk of these errors.  Then maybe the others we can interate on a case by case basis. ","26/Feb/14 18:14;cdouglas;Sure; the description is overly broad/ambitious for the current codebase, so feel free to adjust it to match the fix.","05/Mar/14 16:33;jayunit100;Here's a first go at a patch.  This should improve the situation for all the instances which I was able to find in a first pass using an automated method followed by manual inspection of the offending classes listed above.  Let me know if any others I've missed.  ","05/Mar/14 19:08;hadoopqa;{color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12632845/HADOOP-3679.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 12 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  There were no new javadoc warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:red}-1 core tests{color}.  The patch failed these unit tests in hadoop-common-project/hadoop-common hadoop-common-project/hadoop-nfs:

                  org.apache.hadoop.io.file.tfile.TestTFileComparator2

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HADOOP-Build/3629//testReport/
Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/3629//console

This message is automatically generated.","05/Mar/14 19:10;jayunit100; looks like i broke TestTFileComparator2.  will look now.  ","05/Mar/14 19:32;jayunit100;Second version of the same patch.  Accidentally had moved a line out of a for loop in the last one.  ","05/Mar/14 19:48;hadoopqa;{color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12632895/HADOOP-3679.2.patch
  against trunk revision .

    {color:red}-1 patch{color}.  The patch command could not apply the patch.

Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/3630//console

This message is automatically generated.","05/Mar/14 20:42;jayunit100;Looks like the patch didnt apply?  I dont think this failure on my end but ill look into it some more.  

{noformat}


======================================================================
======================================================================
    Testing patch for HADOOP-3679.
======================================================================
======================================================================


At revision 1574638.
HADOOP-3679 patch is being downloaded at Wed Mar  5 19:48:04 UTC 2014 from
http://issues.apache.org/jira/secure/attachment/12632895/HADOOP-3679.2.patch
cp: cannot stat `/home/jenkins/buildSupport/lib/*': No such file or directory
The patch does not appear to apply with p0 to p2
PATCH APPLICATION FAILED

{noformat}","06/Mar/14 02:28;cdouglas;Did you forget {{--no-prefix}} ?

You can leave the old versions attached, to avoid orphaning discussion about them.","07/Mar/14 00:10;jayunit100;Okay, i just attached a new one.  we will see what the hadoop bot has to say.","07/Mar/14 00:48;hadoopqa;{color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12633263/HADOOP-3679.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 12 new or modified test files.

    {color:red}-1 javac{color:red}.  The patch appears to cause the build to fail.

Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/3640//console

This message is automatically generated.","07/Mar/14 00:55;cdouglas;Looks like an unresolved conflict
{noformat}
+<<<<<<< Updated upstream
   
   @Test
   public void testUserUpdateSetting() throws IOException {
@@ -82,3 +83,6 @@ public void testUserUpdateSetting() throws IOException {
     assertEquals(iug.getTimeout(), IdUserGroup.TIMEOUT_DEFAULT * 2);
   }
 }
+=======
+}
+>>>>>>> Stashed changes
{noformat}","07/Mar/14 01:52;jayunit100;ah interesting sorry didnt catch that.  didnt realize the merge pulled in conflicts before i patched.   thanks !  ","07/Mar/14 05:51;hadoopqa;{color:green}+1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12633292/HADOOP-3679.3.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 12 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  There were no new javadoc warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:green}+1 core tests{color}.  The patch passed unit tests in hadoop-common-project/hadoop-common hadoop-common-project/hadoop-nfs.

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HADOOP-Build/3641//testReport/
Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/3641//console

This message is automatically generated.","07/Mar/14 17:14;jayunit100;yay it passed!
Thanks for the feedback [~chris.douglas] .  
Anyone available for a manual review of the patch?  It fixes all of the assertion orderings that i was able to find in the above classes, which were pulled out via grepping.","07/Mar/14 20:01;aajisaka;Thanks for taking this issue! The fix of the assertion orderings looks mostly good.
Three comments:
{code}
+  public static long ID_EXPECTED=Long.MAX_VALUE;
+
   @Test
   public void testConstructor() {
-    FileHandle handle = new FileHandle(1024);
+    FileHandle handle = new FileHandle(ID_EXPECTED);
{code}
1. This changes the test itself. Would you please separate changing the parameter from the patch?
{code}
+    assertEquals(check.length, 
+            dob.getLength());
{code}
2. The lines like the above can be converted to one line.
3. Conversely, this patch adds the lines over 80 characters, so please render the lines within 80 chars.","07/Mar/14 22:46;jayunit100;Thanks for the review ! 

Sure ill fix this up.  ","07/Mar/14 23:27;aajisaka;Would you please keep the original code style to clean up the patch?
{code}
-    // Test Path(String) 
+    // Test Path(String)
{code}
False whilespace changes
{code}
     // URI#toString returns an encoded path
-    assertEquals(""/foo%20bar"", new URI(null, null, ""/foo bar"", null, null).toString());
+    assertEquals(""/foo%20bar"", 
+            new URI(null, null, ""/foo bar"", null, null).toString());
{code}
False newlines if there are no change in codes. If you want to render existing code, please file a separate jira and create a patch.
{code}
+    assertArrayEquals(check,
+            Arrays.copyOf(dob.getData(), dob.getLength()));
{code}
You can also convert other lines like above into one line.","07/Mar/14 23:51;hadoopqa;{color:green}+1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12633481/HADOOP-3679.4.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 12 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  There were no new javadoc warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:green}+1 core tests{color}.  The patch passed unit tests in hadoop-common-project/hadoop-common hadoop-common-project/hadoop-nfs.

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HADOOP-Build/3644//testReport/
Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/3644//console

This message is automatically generated.","08/Mar/14 19:34;jayunit100;Hi Akira/Chris and thanks for the reviews. 
Okay ive just update  with those changes, and patched some other whitespace errors that i found in my original patch.
thanks for the feedback!","08/Mar/14 20:24;hadoopqa;{color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12633558/HADOOP-3679.5.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 11 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  There were no new javadoc warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

        {color:red}-1 release audit{color}.  The applied patch generated 1 release audit warnings.

    {color:green}+1 core tests{color}.  The patch passed unit tests in hadoop-common-project/hadoop-common hadoop-common-project/hadoop-nfs.

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HADOOP-Build/3649//testReport/
Release audit warnings: https://builds.apache.org/job/PreCommit-HADOOP-Build/3649//artifact/trunk/patchprocess/patchReleaseAuditProblems.txt
Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/3649//console

This message is automatically generated.","08/Mar/14 21:03;jayunit100;Hmmm never saw this release audit warning before.  Any thoughts on why? 
It looks related to getImageServlet.
","10/Mar/14 19:06;aajisaka;This warning is not related to the patch.
This is why another commit made 'GetImageServlet.java' empty and the file didn't have no Apache license header. Now it's fixed in the latest trunk.","10/Mar/14 19:27;jayunit100;Great! Well i guess my job ends here :).  Let me know if we need any other minor updates to the patch.","12/Mar/14 00:19;jayunit100;Hi [~ajisakaa] and  [~chris.douglas] ,  i guess this patch is now  completed.  shall we push it through ? Or any other thoughts on it.  ","14/Mar/14 00:52;cdouglas;+1 I committed this. Thanks Jay

There were still a fair number of whitespace and formatting changes, but they're mostly on blank lines so I went ahead and pushed it. In future patches, minimizing these preserves history and reduces noise for reviewers.","14/Mar/14 01:07;hudson;SUCCESS: Integrated in Hadoop-trunk-Commit #5325 (See [https://builds.apache.org/job/Hadoop-trunk-Commit/5325/])
HADOOP-3679. Fixup assert ordering in unit tests to yield meaningful error
messages. Contributed by Jay Vyas (cdouglas: http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1577396)
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/CHANGES.txt
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/TestPath.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/TestStat.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/TestDataByteBuffers.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/TestIOUtils.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/TestText.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/ipc/TestRPC.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/net/TestNetworkTopologyWithNodeGroup.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/util/TestGenericsUtil.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-nfs/src/test/java/org/apache/hadoop/nfs/nfs3/TestFileHandle.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-nfs/src/test/java/org/apache/hadoop/nfs/nfs3/TestIdUserGroup.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-nfs/src/test/java/org/apache/hadoop/oncrpc/TestXDR.java
","14/Mar/14 11:06;hudson;FAILURE: Integrated in Hadoop-Yarn-trunk #509 (See [https://builds.apache.org/job/Hadoop-Yarn-trunk/509/])
HADOOP-3679. Fixup assert ordering in unit tests to yield meaningful error
messages. Contributed by Jay Vyas (cdouglas: http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1577396)
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/CHANGES.txt
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/TestPath.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/TestStat.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/TestDataByteBuffers.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/TestIOUtils.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/TestText.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/ipc/TestRPC.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/net/TestNetworkTopologyWithNodeGroup.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/util/TestGenericsUtil.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-nfs/src/test/java/org/apache/hadoop/nfs/nfs3/TestFileHandle.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-nfs/src/test/java/org/apache/hadoop/nfs/nfs3/TestIdUserGroup.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-nfs/src/test/java/org/apache/hadoop/oncrpc/TestXDR.java
","14/Mar/14 13:54;hudson;SUCCESS: Integrated in Hadoop-Hdfs-trunk #1701 (See [https://builds.apache.org/job/Hadoop-Hdfs-trunk/1701/])
HADOOP-3679. Fixup assert ordering in unit tests to yield meaningful error
messages. Contributed by Jay Vyas (cdouglas: http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1577396)
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/CHANGES.txt
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/TestPath.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/TestStat.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/TestDataByteBuffers.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/TestIOUtils.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/TestText.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/ipc/TestRPC.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/net/TestNetworkTopologyWithNodeGroup.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/util/TestGenericsUtil.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-nfs/src/test/java/org/apache/hadoop/nfs/nfs3/TestFileHandle.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-nfs/src/test/java/org/apache/hadoop/nfs/nfs3/TestIdUserGroup.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-nfs/src/test/java/org/apache/hadoop/oncrpc/TestXDR.java
","14/Mar/14 14:56;hudson;SUCCESS: Integrated in Hadoop-Mapreduce-trunk #1726 (See [https://builds.apache.org/job/Hadoop-Mapreduce-trunk/1726/])
HADOOP-3679. Fixup assert ordering in unit tests to yield meaningful error
messages. Contributed by Jay Vyas (cdouglas: http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1577396)
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/CHANGES.txt
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/TestPath.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/TestStat.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/TestDataByteBuffers.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/TestIOUtils.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/TestText.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/ipc/TestRPC.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/net/TestNetworkTopologyWithNodeGroup.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/util/TestGenericsUtil.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-nfs/src/test/java/org/apache/hadoop/nfs/nfs3/TestFileHandle.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-nfs/src/test/java/org/apache/hadoop/nfs/nfs3/TestIdUserGroup.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-nfs/src/test/java/org/apache/hadoop/oncrpc/TestXDR.java
","14/Mar/14 21:06;jayunit100;thanks for helping me get my first patch in [~chris.douglas] [~ajisakaa] !",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Add TestFTPFileSystem to Common,HADOOP-6119,12429109,Test,Resolved,HADOOP,Hadoop Common,software,omalley,Hadoop Common is the common library for Apache Hadoop.,http://hadoop.apache.org/,Minor,Fixed,,szetszwo,szetszwo,29/Jun/09 17:35,23/Jul/14 18:18,12/Jan/21 11:55,23/Jul/14 18:18,,,,,,,,,,,fs,,,,0,,,"TestFTPFileSystem was incorrectly moved to hdfs sub-directory by HADOOP-5135.  The test, which belongs to Common, is nothing to do with HDFS.",,aw,Fan04290,garymurry,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,HADOOP-5135,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"29/Jun/09 17:39;szetszwo;TestFTPFileSystem.java;https://issues.apache.org/jira/secure/attachment/12412086/TestFTPFileSystem.java",,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,2009-06-29 18:18:25.034,,,false,,,,,,,,,,,,,,,,,127138,,,,,Wed Jul 23 18:18:18 UTC 2014,,,,,,,"0|i0i1x3:",103405,,,,,,,,,,,,,,,,,,,,,,,"29/Jun/09 17:39;szetszwo;TestFTPFileSystem.java: the source file found in HDFS.","29/Jun/09 18:18;cdouglas;+1 for moving the test","29/Jun/09 18:25;szetszwo;Note that TestFTPFileSystem.java cannot be used directly in Common since the current codes use some utility functions defined in hdfs.","29/Jun/09 22:56;cdouglas;Would it make sense to move at least a subset of the DFSTestUtil functions into a utility class in fs?","29/Jun/09 23:08;szetszwo;> Would it make sense to move at least a subset of the DFSTestUtil functions into a utility class in fs?
Yes, it is good to have some generic fs testing utility functions.  However, the task may not be obvious and needs some works.","23/Jul/14 18:18;aw;Fixed.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
TestSocketIOWithTimeout fails under AIX - TIMEOUT error. ,HADOOP-5116,12413098,Test,Resolved,HADOOP,Hadoop Common,software,omalley,Hadoop Common is the common library for Apache Hadoop.,http://hadoop.apache.org/,Minor,Incomplete,,bhabermaas,bhabermaas,23/Jan/09 15:27,21/Jul/14 18:31,12/Jan/21 11:55,21/Jul/14 18:31,0.18.2,,,,,,,,,,test,,,,0,,,This test expects an exception to occur when read/writing a closed socket.  Under AIX this does not occur and results in a loop.  ,AIX,aw,rangadi,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"26/Jan/09 20:57;bhabermaas;javacore.20090126.144729.376858.0001.txt;https://issues.apache.org/jira/secure/attachment/12398764/javacore.20090126.144729.376858.0001.txt",,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,2009-01-23 20:22:42.448,,,false,,,,,,,,,,,,,,,,,126929,,,,,Mon Jul 21 18:31:54 UTC 2014,,,,,,,"0|i0i4xj:",103893,,,,,,,,,,,,,,,,,,,,,,,"23/Jan/09 20:22;steve_l;How do you tell if a socket is closed on AIX? {{Socket.isClosed()}} , presumably?","23/Jan/09 20:31;rangadi;Could attach the jstack of the test when this is stuck?","26/Jan/09 20:57;bhabermaas;This dump was taken after the test was running for several minutes.  ","29/Jan/09 00:41;rangadi;
The stacktrace shows that test is blocked inside a write() to a pipe. This write is supposed to be non-blocking. Is it possible that either JVM or AIX ignores {{channel.configureBlocking(false)}} for pipes?

Could you check if this process is busy during this time? It it is then then there could be other possibilities.

{noformat}
4XESTACKTRACE          at sun/nio/ch/FileDispatcher.write0(Native Method)
4XESTACKTRACE          at sun/nio/ch/FileDispatcher.write(FileDispatcher.java:76(Compiled Code))
4XESTACKTRACE          at sun/nio/ch/IOUtil.writeFromNativeBuffer(IOUtil.java:119(Compiled Code))
4XESTACKTRACE          at sun/nio/ch/IOUtil.write(IOUtil.java:87(Compiled Code))
4XESTACKTRACE          at sun/nio/ch/SinkChannelImpl.write(SinkChannelImpl.java:164(Compiled Code))
4XESTACKTRACE          at org/apache/hadoop/net/SocketOutputStream$Writer.performIO(SocketOutputStream.java:55(Compiled Code))
4XESTACKTRACE          at org/apache/hadoop/net/SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:140)
4XESTACKTRACE          at org/apache/hadoop/net/SocketOutputStream.write(SocketOutputStream.java:146)
4XESTACKTRACE          at org/apache/hadoop/net/SocketOutputStream.write(SocketOutputStream.java:107)
4XESTACKTRACE          at java/io/OutputStream.write(OutputStream.java:79)
4XESTACKTRACE          at org/apache/hadoop/net/TestSocketIOWithTimeout.doIO(TestSocketIOWithTimeout.java:58)
4XESTACKTRACE          at org/apache/hadoop/net/TestSocketIOWithTimeout.testSocketIOWithTimeout(TestSocketIOWithTimeout.java:106)
4XESTACKTRACE          at sun/reflect/NativeMethodAccessorImpl.invoke0(Native Method)
4XESTACKTRACE          at sun/reflect/NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:79)
4XESTACKTRACE          at sun/reflect/DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
4XESTACKTRACE          at java/lang/reflect/Method.invoke(Method.java:618)
{noformat}","29/Jan/09 14:26;bhabermaas;When this test was running it was observed to be consuming over 90% of the processor according to the 'topas' command. This is why the report description assumes that a loop was occurring. At the instant that the trace was induced it was probably blocked but not forever.  The high cpu utilization suggests that it is not blocking and is repeating the write according to the way the test is written. ","29/Jan/09 19:08;rangadi;
hmm... did you try strace (or its AIX equivalent) on the busy thread? On Linux, I find the pid of the thread doing write() with jstack.

This test depends on the fact that a pipe has a reasonably finite buffer. So when it writes to the pipe in a loop, it expects write to return 0 at some point and polling for 'POLLOUT' would timeout after that since there is no reader on the other side.


","29/Jan/09 19:19;rangadi;> This test expects an exception to occur when read/writing a closed socket. Under AIX this does not occur and results in a loop.
 
Is it writing after closing the socket? The stacktrace does not seem to show it.","21/Jul/14 18:31;aw;Closing as stale.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
TestLocalDirAllocator fails under AIX ,HADOOP-5115,12413096,Test,Resolved,HADOOP,Hadoop Common,software,omalley,Hadoop Common is the common library for Apache Hadoop.,http://hadoop.apache.org/,Minor,Incomplete,,bhabermaas,bhabermaas,23/Jan/09 15:23,21/Jul/14 18:31,12/Jan/21 11:55,21/Jul/14 18:31,0.18.2,,,,,,,,,,test,,,,0,,,TestLocalDirAllocator fails when running under AIX for the same reasons as CYGWIN under Windows (as noted in the test source code comments).  AIX allows the writing of a file in a directory that is marked read-only. This breaks the test. If the test is changed to sense for AIX (as it does for windows) then the usefulness of this unit test is questionable other than exposing an interesting anomoly in the native file system. ,AIX ,aw,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,2014-07-21 18:31:30.399,,,false,,,,,,,,,,,,,,,,,126928,,,,,Mon Jul 21 18:31:30 UTC 2014,,,,,,,"0|i0i4xr:",103894,,,,,,,,,,,,,,,,,,,,,,,"21/Jul/14 18:31;aw;Closing as stale.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
test-patch script is showing questionable number of Javac warnings,HADOOP-4165,12404235,Test,Resolved,HADOOP,Hadoop Common,software,omalley,Hadoop Common is the common library for Apache Hadoop.,http://hadoop.apache.org/,Minor,Fixed,,rramya,rramya,12/Sep/08 10:09,18/Jul/14 23:36,12/Jan/21 11:55,18/Jul/14 23:36,0.18.0,,,,,,,,,,test,,,,0,,,"test-patch is recording 881 number of javac warnings when run on trunk and 216 javac warnings when run on ""ANY"" patch.
This behavior was observed even on an empty patch.",,szetszwo,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,2008-09-29 17:39:18.992,,,false,,,,,,,,,,,,,,,,,126349,,,,,Fri Jul 10 23:08:26 UTC 2009,,,,,,,"0|i0i8tb:",104522,,,,,,,,,,,,,,,,,,,,,,,"29/Sep/08 17:39;nidaley;Not a blocker for 0.19","10/Jul/09 23:08;szetszwo;Looks like that HADOOP-6124 and this are the same issue.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
TestZKFailoverControllerStress#testExpireBackAndForth fails occasionally in trunk,HADOOP-10763,12724294,Test,Resolved,HADOOP,Hadoop Common,software,omalley,Hadoop Common is the common library for Apache Hadoop.,http://hadoop.apache.org/,Minor,Duplicate,,yuzhihong@gmail.com,yuzhihong@gmail.com,28/Jun/14 14:54,28/Jun/14 15:36,12/Jan/21 11:55,28/Jun/14 15:36,,,,,,,,,,,,,,,0,,,"See https://builds.apache.org/job/Hadoop-Common-trunk/1153/console

I was able to reproduce on Mac:
{code}
Running org.apache.hadoop.ha.TestZKFailoverControllerStress
Tests run: 3, Failures: 0, Errors: 1, Skipped: 0, Time elapsed: 87.907 sec <<< FAILURE! - in org.apache.hadoop.ha.TestZKFailoverControllerStress
testExpireBackAndForth(org.apache.hadoop.ha.TestZKFailoverControllerStress)  Time elapsed: 25.038 sec  <<< ERROR!
org.apache.zookeeper.KeeperException$NoNodeException: KeeperErrorCode = NoNode
	at org.apache.zookeeper.server.DataTree.getData(DataTree.java:648)
	at org.apache.zookeeper.server.ZKDatabase.getData(ZKDatabase.java:371)
	at org.apache.hadoop.ha.MiniZKFCCluster.expireActiveLockHolder(MiniZKFCCluster.java:199)
	at org.apache.hadoop.ha.MiniZKFCCluster.expireAndVerifyFailover(MiniZKFCCluster.java:234)
	at org.apache.hadoop.ha.TestZKFailoverControllerStress.testExpireBackAndForth(TestZKFailoverControllerStress.java:79)
{code}",,cnauroth,yuzhihong@gmail.com,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,402479,,,,,Sat Jun 28 15:36:05 UTC 2014,,,,,,,"0|i1x9xb:",402546,,,,,,,,,,,,,,,,,,,,,,,"28/Jun/14 15:36;yuzhihong@gmail.com;Dup of HADOOP-10668",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
End to End test case for refreshing call queue,HADOOP-10377,12697997,Test,Open,HADOOP,Hadoop Common,software,omalley,Hadoop Common is the common library for Apache Hadoop.,http://hadoop.apache.org/,Minor,,chrilisf,chrilisf,chrilisf,28/Feb/14 19:40,28/Feb/14 19:41,12/Jan/21 11:55,,,,,,,,,,,,,,,,0,,,"See https://issues.apache.org/jira/browse/HADOOP-10285

Once we have the capability of returning errors from the generic refresh config protocol, we can have an integration test of the features.

",,arp,chrilisf,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,HADOOP-10376,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,376471,,,,,Fri Feb 28 19:41:33 UTC 2014,,,,,,,"0|i1svfz:",376767,,,,,,,,,,,ipc,,,,,,,,,,,,"28/Feb/14 19:41;chrilisf;Would make the testing much cleaner, as we wouldn't have to pry open the server class",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
provide unit-test coverage of class org.apache.hadoop.fs.DelegationTokenRenewer.RenewAction<T>,HADOOP-9046,12616210,Test,Resolved,HADOOP,Hadoop Common,software,omalley,Hadoop Common is the common library for Apache Hadoop.,http://hadoop.apache.org/,Minor,Cannot Reproduce,iveselovsky,iveselovsky,iveselovsky,15/Nov/12 10:01,15/May/13 12:00,12/Jan/21 11:55,15/May/13 12:00,0.23.6,,,,,,,,,,,,,,0,,,"The class org.apache.hadoop.fs.DelegationTokenRenewer.RenewAction<T> has zero coverage in entire cumulative test run. Provide test(s) to cover this class.

Note: the request submitted to HDFS project because the class likely to be tested by tests in that project.",,aklochkov,iveselovsky,kasha,kkambatl,revans2,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"28/Nov/12 15:05;iveselovsky;HADOOP-9046--c.patch;https://issues.apache.org/jira/secure/attachment/12555168/HADOOP-9046--c.patch","29/Nov/12 13:05;iveselovsky;HADOOP-9046--d.patch;https://issues.apache.org/jira/secure/attachment/12555349/HADOOP-9046--d.patch","18/Dec/12 09:32;iveselovsky;HADOOP-9046--e.patch;https://issues.apache.org/jira/secure/attachment/12561453/HADOOP-9046--e.patch","28/Nov/12 16:36;iveselovsky;HADOOP-9046-branch-0.23--c.patch;https://issues.apache.org/jira/secure/attachment/12555188/HADOOP-9046-branch-0.23--c.patch","29/Nov/12 13:59;iveselovsky;HADOOP-9046-branch-0.23--d.patch;https://issues.apache.org/jira/secure/attachment/12555352/HADOOP-9046-branch-0.23--d.patch","11/Mar/13 19:23;iveselovsky;HADOOP-9046-branch-0.23--over-HDFS-4567.patch;https://issues.apache.org/jira/secure/attachment/12573153/HADOOP-9046-branch-0.23--over-HDFS-4567.patch","26/Nov/12 10:40;iveselovsky;HADOOP-9046-branch-0.23-over-9049.patch;https://issues.apache.org/jira/secure/attachment/12554836/HADOOP-9046-branch-0.23-over-9049.patch","16/Nov/12 11:52;iveselovsky;HADOOP-9046-branch-0.23.patch;https://issues.apache.org/jira/secure/attachment/12553772/HADOOP-9046-branch-0.23.patch","12/Mar/13 11:36;iveselovsky;HADOOP-9046-branch-2--over-HDFS-4567.patch;https://issues.apache.org/jira/secure/attachment/12573306/HADOOP-9046-branch-2--over-HDFS-4567.patch","26/Nov/12 10:47;iveselovsky;HADOOP-9046-over-9049.patch;https://issues.apache.org/jira/secure/attachment/12554837/HADOOP-9046-over-9049.patch","11/Mar/13 19:23;iveselovsky;HADOOP-9046-trunk--over-HDFS-4567.patch;https://issues.apache.org/jira/secure/attachment/12573154/HADOOP-9046-trunk--over-HDFS-4567.patch","16/Nov/12 11:53;iveselovsky;HADOOP-9046.patch;https://issues.apache.org/jira/secure/attachment/12553773/HADOOP-9046.patch",,,,,,,,,,,,12.0,,,,,,,,,,,,,,,,,,,,2012-11-16 12:56:49.52,,,false,,,,,,,,,,,,,,,,,257960,,,,,Wed May 15 12:00:31 UTC 2013,,,,,,,"0|i0kljb:",118306,,,,,,,,,,,,,,,,,,,,,,,"16/Nov/12 12:56;hadoopqa;{color:green}+1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12553773/HADOOP-9046.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 2 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  The javadoc tool did not generate any warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:green}+1 core tests{color}.  The patch passed unit tests in hadoop-common-project/hadoop-common.

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HADOOP-Build/1761//testReport/
Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/1761//console

This message is automatically generated.","23/Nov/12 18:52;iveselovsky;the patch H-9046-over-9049 merges the suggested changes over fix 9049, which is already accepted.
Also it fixes several issues that are present in fix H-9049.","23/Nov/12 19:29;hadoopqa;{color:green}+1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12554745/HADOOP-9046-over-9049.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 2 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  The javadoc tool did not generate any warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:green}+1 core tests{color}.  The patch passed unit tests in hadoop-common-project/hadoop-common.

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HADOOP-Build/1808//testReport/
Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/1808//console

This message is automatically generated.","23/Nov/12 19:36;iveselovsky;the patch for trunk is also okay for branch-2.","26/Nov/12 10:40;iveselovsky;Patch ""HADOOP-9046-branch-0.23-over-9049.patch"" ports both the changes 9049 and 9046 into branch 0.23 .","26/Nov/12 10:46;hadoopqa;{color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12554836/HADOOP-9046-branch-0.23-over-9049.patch
  against trunk revision .

    {color:red}-1 patch{color}.  The patch command could not apply the patch.

Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/1820//console

This message is automatically generated.","26/Nov/12 11:18;hadoopqa;{color:green}+1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12554837/HADOOP-9046-over-9049.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 2 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  The javadoc tool did not generate any warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:green}+1 core tests{color}.  The patch passed unit tests in hadoop-common-project/hadoop-common.

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HADOOP-Build/1821//testReport/
Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/1821//console

This message is automatically generated.","26/Nov/12 19:32;revans2;The updated test takes almost 7 mins to run.  The original test took about 1 min.  (at least on my slow desktop run once so it is very scientific) I don't want to be a stickler for this, but it feels a little odd to have a unit test run that long. 1 min even feels too long for testing code that really just appears to be a wrapper around a delay queue that has a little bit of extra logic to handle a weak reference to a file system.","27/Nov/12 14:11;iveselovsky;Hi, Robert,
in last pre-commit verification build (above) the test ""org.apache.hadoop.fs.TestDelegationTokenRenewer"" took 39 seconds:
https://builds.apache.org/job/PreCommit-HADOOP-Build/1821//testReport/org.apache.hadoop.fs/TestDelegationTokenRenewer/ (both the test cases).
in my desktop the console mvn run of this test takes 38 sec (i do just ""mvn clean test -Dtest=org.apache.hadoop.fs.TestDelegationTokenRenewer"").
When I run it from within Eclipse, it also takes 18 + 21 = 39 sec.

Looking to the code I didn't realize how this test could take 7 minutes.
So, can you please provide more details on the conditions of your experiment:
1) did you use the attached ""HADOOP-9046-over-9049.patch"" against trunk? 
2) what JDK you ran the test upon?
3) did the both test cases pass?
4) do other Hadoop tests on your machine run with speed similar to that in Apache Jenkins build machine (https://builds.apache.org) ?
5) what exact command line did you use to run the test(s)? (e.g. was -Pnative included?)
6) is that effect (7 min) reproducible on that machine?
7) There are 2 test cases in the class org.apache.hadoop.fs.TestDelegationTokenRenewer. Which one was slow? Or both?

Thanks in advance.","27/Nov/12 14:13;iveselovsky;One more note: the code that waits for the FS weak ref to dispose executed with 30 sec timeout, so it looks like it cannot be the cause of 7 min slowdown.","27/Nov/12 15:50;iveselovsky;Hi, Robert,
looks like I found the reason of delay: the main thread locks for long time when waiting to enter the synchronized method org.apache.hadoop.fs.DelegationTokenRenewer.removeRenewAction(T),
and this operation is invoked in StateSynchronizer *without* a timeout.   
I will update the patch when i fix this. 
Thanks a lot for this catch.","27/Nov/12 16:57;revans2;I am glad that you caught it.  Sorry I did not respond sooner.","28/Nov/12 15:05;iveselovsky;In the new version of patch ""HADOOP-9046--c.patch"" the following is done:
1) fixed the sync problem found by Robert: now the method org.apache.hadoop.fs.DelegationTokenRenewer#removeRenewAction(T) will not block for long time.
2) in the test all the time periods made scalable relative one constant.
3) the test made fater: now it takes ~7 seconds.","28/Nov/12 15:39;hadoopqa;{color:green}+1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12555168/HADOOP-9046--c.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 2 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  The javadoc tool did not generate any warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:green}+1 core tests{color}.  The patch passed unit tests in hadoop-common-project/hadoop-common.

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HADOOP-Build/1834//testReport/
Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/1834//console

This message is automatically generated.","28/Nov/12 16:36;iveselovsky;Patch ""HADOOP-9046-branch-0.23--c.patch"" ports the changes to ""branch-0.23"".

The trunk patch ""HADOOP-9046--c.patch"" is applicable to ""branch-2"" as well.","28/Nov/12 17:11;revans2;It is looking good, and I like how much faster the tests run.

I have a few more comments.

# {code}TODO: should we reject the addition if an action for this 'fs' is already present in the queue?{code} If this is an issue then we should file a JIRA to fix it, otherwise please remove the TODO. I am leaning more towards filing a separate JIRA.
# I don't really like the name lock0 and available0.  I would rather have them be named something more descriptive.  This is very minor
# in removeRenewAction we are no longer canceling the token when it is removed. I am not sure if that is intentional or not, but it definitely changes the functionality of the method. 
# I am not sure that renewerThreadStarted.compairAndSet is that much better then isAlive().  isAlive has the problem that if the thread stopped, calling add again would result in an IllegalThreadStateException, but compairAndSet has the problem that if a new thread cannot be created (Which I have seen happen) then only the first call to add will get an exception all other calls to add will look like they succeeded but no renewal will ever happen. I would rather see errors happen on other calls to add then to have them silently fail.
","29/Nov/12 13:05;iveselovsky;Hi, Robert, thanks for the comments.

1. Created separate Jira https://issues.apache.org/jira/browse/HADOOP-9104 . The TODO comment is removed.

2. Renamed: lock0 -> queueLock, available0 -> queueContentChangedCondition.  

3. The token cancellation upon removal was introduced in HADOOP-9084, and it appeared to be acsidently overwritten by my changes. I returned those changes back and also added relevant checking to the test. Thanks for this catch. 

4. I fixed the problem using java.lang.Thread.getState() method: now, first, we start the thread if needed, and, 2nd, we check if it already died. 
If the thread is dead, we throw IllegalStateException. 
This way (1) the thread never attempts to start twice, and (2) any attempt to add an action to the dead thread is rejected.
I also added into the test the check to verify that this really the case.

The described changes are in patches ""xxx--d.patch"".","29/Nov/12 13:59;iveselovsky;the patch HADOOP-9046-branch-0.23--d.patch provides version ""d"" of this change for branch ""branch-0.23"".","13/Dec/12 09:49;hadoopqa;{color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12555352/HADOOP-9046-branch-0.23--d.patch
  against trunk revision .

    {color:red}-1 patch{color}.  The patch command could not apply the patch.

Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/1854//console

This message is automatically generated.","18/Dec/12 09:32;iveselovsky;the attached patch ""HADOOP-9046--e.patch"" merges the change over HADOOP-9113. ","18/Dec/12 09:50;iveselovsky;Patch ""HADOOP-9046--e.patch"" is for branches ""trunk"" and ""branch-2"".
Patch ""HADOOP-9046-branch-0.23--d.patch"" is still applicable to ""branch-0.23"".","18/Dec/12 10:11;hadoopqa;{color:green}+1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12561453/HADOOP-9046--e.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 2 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  The javadoc tool did not generate any warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:green}+1 core tests{color}.  The patch passed unit tests in hadoop-common-project/hadoop-common.

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HADOOP-Build/1907//testReport/
Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/1907//console

This message is automatically generated.","11/Mar/13 19:23;iveselovsky;Attaching new versions of patches merged over fix HDFS-4567.","11/Mar/13 20:12;hadoopqa;{color:green}+1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12573154/HADOOP-9046-trunk--over-HDFS-4567.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 2 new or modified test files.

    {color:green}+1 tests included appear to have a timeout.{color}

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  The javadoc tool did not generate any warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:green}+1 core tests{color}.  The patch passed unit tests in hadoop-common-project/hadoop-common.

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HADOOP-Build/2311//testReport/
Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/2311//console

This message is automatically generated.","12/Mar/13 11:36;iveselovsky;Attaching also separate patch version for ""branch-2"" since trunk version does not apply cleanly.","12/Mar/13 12:15;hadoopqa;{color:green}+1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12573306/HADOOP-9046-branch-2--over-HDFS-4567.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 2 new or modified test files.

    {color:green}+1 tests included appear to have a timeout.{color}

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  The javadoc tool did not generate any warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:green}+1 core tests{color}.  The patch passed unit tests in hadoop-common-project/hadoop-common.

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HADOOP-Build/2316//testReport/
Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/2316//console

This message is automatically generated.","14/May/13 09:08;iveselovsky;Since fix https://issues.apache.org/jira/browse/HADOOP-9549 the patch is no longer applicable to branches ""trunk"" and ""branch-2"" (needs merge).
It looks like there is no big reason to merge over 9549 because after the fix 9549 the coverage of the target classes is enough.
So, the suggested patch is now applicable to ""branch-0.23"" only.
Modifying the ""Affected versions"" field accordingly.","14/May/13 14:42;revans2;Ivan, I am sorry I dropped the ball on this, and did not repond sooner.  Sadly though the only time we want to put something into just 0.23 without going into trunk/branch-2 first is if there is a bug that only exists in branch-0.23.  This is a very rare occurrence.  If you think the coverage is good enough on branch-2 and trunk then would it be acceptable if we resolve this JIRA instead.","15/May/13 12:00;iveselovsky;Closing this request because:
1) After https://issues.apache.org/jira/browse/HADOOP-9549 coverage of the DelegationTokenRenewer is high enough in ""branch-2"" and ""trunk"".
2) In ""branch-0.23"" class DelegationTokenRenewer resides in another package, so its coverage does not directly affect coverage of package o.a.h.fs . (The fix was initially done in order to elevate coverage of o.a.h.fs package).",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Add test to FileSystemContractBaseTest to verify integrity of overwritten files,HADOOP-9119,12618886,Test,Closed,HADOOP,Hadoop Common,software,omalley,Hadoop Common is the common library for Apache Hadoop.,http://hadoop.apache.org/,Minor,Fixed,stevel@apache.org,stevel@apache.org,stevel@apache.org,05/Dec/12 14:59,02/May/13 02:29,12/Jan/21 11:55,08/Jan/13 17:02,,,,,2.0.3-alpha,,,,,,fs,test,,,0,,,The test {{FileSystemContractBaseTest.testOverwrite()}} is meant to verify that overwrites work -but it only overwrites a zero byte file with some data and only checks for length. This can hide problems where there overwrite was somehow corrupted.,,eli,Fan04290,hudson,schu,stevel@apache.org,sureshms,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,HADOOP-9118,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"08/Jan/13 12:04;stevel@apache.org;HADOOP-9119-2.patch;https://issues.apache.org/jira/secure/attachment/12563740/HADOOP-9119-2.patch","11/Dec/12 09:42;stevel@apache.org;HADOOP-9119.patch;https://issues.apache.org/jira/secure/attachment/12560374/HADOOP-9119.patch",,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,2012-12-13 09:20:19.754,,,false,,,,,,,,,,,,,,,,,296149,Reviewed,,,,Wed Jan 09 13:20:57 UTC 2013,,,,,,,"0|i146c7:",232490,"Patches adds more tests to verify overwritten and more complex operations -write-delete-overwrite. By using differently sized datasets and different data inside, these tests verify that the overwrite really did take place. While HDFS meets all these requirements directly, eventually consistent object stores may not -hence these tests.",,,,,,,,,,,,,,,,,,,,,,"05/Dec/12 15:01;stevel@apache.org;I propose new tests that write to the same file with: less data, more data, the same amount of data -and a different set of data in each. The byte-by-byte verification will pick up any situation where the old data is somehow mixed with the new data.","11/Dec/12 09:42;stevel@apache.org;git am formatted patch","11/Dec/12 09:45;stevel@apache.org;the {{dataset()}} method used to create test datasets takes a broader modulus for its sets.","13/Dec/12 09:20;hadoopqa;{color:green}+1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12560374/HADOOP-9119.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 1 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  The javadoc tool did not generate any warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:green}+1 core tests{color}.  The patch passed unit tests in hadoop-common-project/hadoop-common.

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HADOOP-Build/1847//testReport/
Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/1847//console

This message is automatically generated.","13/Dec/12 23:45;eli;Don't think the char to String conversion method is necessary, String#format handles bytes right? Otherwise looks good.","14/Dec/12 09:40;stevel@apache.org;the {{toChar()}} method takes anything >=32 and converts it to its equivalent 33 => ! ,etc, but for anything <32, maps to the hex value, so you can see the difference between expected and actual even for the low values","02/Jan/13 17:47;sureshms;Comments:
# Please add additional comments to toChar() method explaining breifly what is being done.
# #writeAndRead() - I may not have understood the code correctly. Some comments:
#* what is the reason why you need to accumulate the error strings in result and why not just print LOG.warn() as error is encountered?
# Variable name first_error_line - it is not related to really line right? You could just maintain the index where you encountered error right? 
#* Also not sure why have {{len * 40}} as the size of result ro why for loop is between {{first_error_line - 10}} to {{first_error_line + 10}}. A brief description of why this is done would help understand the code better. 
#* You could have array index of out of exception in the for loop. You should swap Math.min() and Math.max()
# Some nits - Some lines have are more than 80 chars
","02/Jan/13 21:25;stevel@apache.org;I'll fix these. Does the 80-line limit still apply?","03/Jan/13 17:57;sureshms;bq.  Does the 80-line limit still apply?
Yes. ","08/Jan/13 12:04;stevel@apache.org;Patch addressing Suresh's issues","08/Jan/13 12:45;hadoopqa;{color:green}+1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12563740/HADOOP-9119-2.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 1 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  The javadoc tool did not generate any warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:green}+1 core tests{color}.  The patch passed unit tests in hadoop-common-project/hadoop-common.

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HADOOP-Build/2011//testReport/
Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/2011//console

This message is automatically generated.","08/Jan/13 16:55;sureshms;+1 for the change.","08/Jan/13 17:02;sureshms;Committed the patch to branch-2 and trunk. Thank you Steve.","08/Jan/13 17:05;hudson;Integrated in Hadoop-trunk-Commit #3192 (See [https://builds.apache.org/job/Hadoop-trunk-Commit/3192/])
    HADOOP-9119. Add test to FileSystemContractBaseTest to verify integrity of overwritten files. Contributed by Steve Loughran. (Revision 1430387)

     Result = SUCCESS
suresh : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1430387
Files : 
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/CHANGES.txt
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/FileSystemContractBaseTest.java
","09/Jan/13 10:47;hudson;Integrated in Hadoop-Yarn-trunk #91 (See [https://builds.apache.org/job/Hadoop-Yarn-trunk/91/])
    HADOOP-9119. Add test to FileSystemContractBaseTest to verify integrity of overwritten files. Contributed by Steve Loughran. (Revision 1430387)

     Result = SUCCESS
suresh : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1430387
Files : 
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/CHANGES.txt
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/FileSystemContractBaseTest.java
","09/Jan/13 13:12;hudson;Integrated in Hadoop-Hdfs-trunk #1280 (See [https://builds.apache.org/job/Hadoop-Hdfs-trunk/1280/])
    HADOOP-9119. Add test to FileSystemContractBaseTest to verify integrity of overwritten files. Contributed by Steve Loughran. (Revision 1430387)

     Result = FAILURE
suresh : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1430387
Files : 
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/CHANGES.txt
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/FileSystemContractBaseTest.java
","09/Jan/13 13:20;hudson;Integrated in Hadoop-Mapreduce-trunk #1308 (See [https://builds.apache.org/job/Hadoop-Mapreduce-trunk/1308/])
    HADOOP-9119. Add test to FileSystemContractBaseTest to verify integrity of overwritten files. Contributed by Steve Loughran. (Revision 1430387)

     Result = FAILURE
suresh : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1430387
Files : 
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/CHANGES.txt
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/FileSystemContractBaseTest.java
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
adding tests for quotas command line error  messages,HADOOP-4722,12409212,Test,Closed,HADOOP,Hadoop Common,software,omalley,Hadoop Common is the common library for Apache Hadoop.,http://hadoop.apache.org/,Minor,Fixed,boryas,boryas,boryas,25/Nov/08 18:39,02/May/13 02:29,12/Jan/21 11:55,04/Dec/08 01:21,0.20.0,,,,0.20.0,,,,,,test,,,,0,,,"adding tests for quotas command line error messages.
Will add it to the TestCLI xml configuration",,liangly,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,HADOOP-4708,,,,,,,"02/Dec/08 19:52;boryas;HADOOP-4722.patch;https://issues.apache.org/jira/secure/attachment/12395120/HADOOP-4722.patch",,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,2008-12-04 01:21:03.796,,,false,,,,,,,,,,,,,,,,,126692,Reviewed,,,,Sat Dec 06 14:02:03 UTC 2008,,,,,,,"0|i0i6jr:",104155,,,,,,,,,,,,,,,,,,,,,,,"02/Dec/08 19:57;boryas;      Added the following tests:
      <description>verifying error messages for quota commands - setting quota on a file</description>
      <description>verifying error messages for quota commands - setting quota on non-existing file</description>
      <description>verifying error messages for quota commands - exceeding quota</description>
      <description>verifying error messages for quota commands - setting not valid quota</description>
      <description>verifying error messages for quota commands - setting not valid space quota</description>
      <description>verifying error messages for quota commands - clearQuota on non existing file</description>
","04/Dec/08 01:21;cdouglas;Ran TestCLI, confirmed test output in logs.

I just committed this. Thanks, Boris.","06/Dec/08 14:02;hudson;Integrated in Hadoop-trunk #680 (See [http://hudson.zones.apache.org/hudson/job/Hadoop-trunk/680/])
    ",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
“ant test” will build failed for  trying to delete a file,HADOOP-9051,12616358,Test,Closed,HADOOP,Hadoop Common,software,omalley,Hadoop Common is the common library for Apache Hadoop.,http://hadoop.apache.org/,Minor,Fixed,vicaya,mgong@vmware.com,mgong@vmware.com,16/Nov/12 06:01,06/Mar/13 09:56,12/Jan/21 11:55,15/Dec/12 03:51,1.0.4,,,,1.1.2,,,,,,test,,,,1,test,,"Run ""ant test"" on branch-1 of hadoop-common.
When the test process reach ""test-core-excluding-commit-and-smoke""

It will invoke the ""macro-test-runner"" to clear and rebuild the test environment.
Then the ant task command  <delete dir=""@{test.dir}/logs"" />
failed for trying to delete an non-existent file.

following is the test result logs:
test-core-excluding-commit-and-smoke:
   [delete] Deleting: /home/jdu/bdc/hadoop-topology-branch1-new/hadoop-common/build/test/testsfailed
   [delete] Deleting directory /home/jdu/bdc/hadoop-topology-branch1-new/hadoop-common/build/test/data
    [mkdir] Created dir: /home/jdu/bdc/hadoop-topology-branch1-new/hadoop-common/build/test/data
   [delete] Deleting directory /home/jdu/bdc/hadoop-topology-branch1-new/hadoop-common/build/test/logs

BUILD FAILED
/home/jdu/bdc/hadoop-topology-branch1-new/hadoop-common/build.xml:1212: The following error occurred while executing this line:
/home/jdu/bdc/hadoop-topology-branch1-new/hadoop-common/build.xml:1166: The following error occurred while executing this line:
/home/jdu/bdc/hadoop-topology-branch1-new/hadoop-common/build.xml:1057: Unable to delete file /home/jdu/bdc/hadoop-topology-branch1-new/hadoop-common/build/test/logs/userlogs/job_20121112223129603_0001/attempt_20121112223129603_0001_r_000000_0/attempt_20121112223129603_0001_r_000000_0/attempt_20121112223129603_0001_r_000000_0/attempt_20121112223129603_0001_r_000000_0/attempt_20121112223129603_0001_r_000000_0/attempt_20121112223129603_0001_r_000000_0/attempt_20121112223129603_0001_r_000000_0/attempt_20121112223129603_0001_r_000000_0/attempt_20121112223129603_0001_r_000000_0/attempt_20121112223129603_0001_r_000000_0/attempt_20121112223129603_0001_r_000000_0/attempt_20121112223129603_0001_r_000000_0/attempt_20121112223129603_0001_r_000000_0/attempt_20121112223129603_0001_r_000000_0/attempt_20121112223129603_0001_r_000000_0/attempt_20121112223129603_0001_r_000000_0/attempt_20121112223129603_0001_r_000000_0/attempt_20121112223129603_0001_r_000000_0/attempt_20121112223129603_0001_r_000000_0/attempt_20121112223129603_0001_r_000000_0/attempt_20121112223129603_0001_r_000000_0/attempt_20121112223129603_0001_r_000000_0/attempt_20121112223129603_0001_r_000000_0/attempt_20121112223129603_0001_r_000000_0/attempt_20121112223129603_0001_r_000000_0/attempt_20121112223129603_0001_r_000000_0/attempt_20121112223129603_0001_r_000000_0/attempt_20121112223129603_0001_r_000000_0/attempt_20121112223129603_0001_r_000000_0/attempt_20121112223129603_0001_r_000000_0/attempt_20121112223129603_0001_r_000000_0/attempt_20121112223129603_0001_r_000000_0/attempt_20121112223129603_0001_r_000000_0/attempt_20121112223129603_0001_r_000000_0/attempt_20121112223129603_0001_r_000000_0/attempt_20121112223129603_0001_r_000000_0/attempt_20121112223129603_0001_r_000000_0/attempt_20121112223129603_0001_r_000000_0/attempt_20121112223129603_0001_r_000000_0/attempt_20121112223129603_0001_r_000000_0/stdout
","OS: Ubuntu 10.04; forrest version 0.8; findbugs version 2.0.1; ant version 1.8.1",jdu,junping_du,mattf,mgong@vmware.com,stevel@apache.org,sureshms,vicaya,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"16/Nov/12 07:54;mgong@vmware.com;fix-ant-test;https://issues.apache.org/jira/secure/attachment/12553753/fix-ant-test","13/Dec/12 22:53;vicaya;hadoop-9051-v1.patch;https://issues.apache.org/jira/secure/attachment/12560864/hadoop-9051-v1.patch",,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,2012-11-16 08:04:51.604,,,false,,,,,,,,,,,,,,,,,258125,,,,,Wed Mar 06 09:56:00 UTC 2013,,,,,,,"0|i0kn2n:",118555,,,,,,,,,,,,,1.1.2,,,,,,,,,,"16/Nov/12 06:09;mgong@vmware.com;One kind of solution is following:
--- a/build.xml
+++ b/build.xml
@@ -1054,7 +1054,7 @@
       <delete file=""${test.build.dir}/testsfailed""/>
       <delete dir=""@{test.dir}/data"" />
       <mkdir dir=""@{test.dir}/data"" />
-      <delete dir=""@{test.dir}/logs"" />
+      <delete dir=""@{test.dir}/logs"" quiet=""true""/>
       <mkdir dir=""@{test.dir}/logs"" />
       <copy file=""${test.src.dir}/hadoop-policy.xml""
             todir=""@{test.dir}/extraconf"" />


For the marco-test-runner is just want to delete the logs folder and rebuild a new one.
If the specified file or directory does not exist, do not display a diagnostic message.","16/Nov/12 07:54;mgong@vmware.com;an solution to fix this bug","16/Nov/12 08:04;hadoopqa;{color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12553753/fix-ant-test
  against trunk revision .

    {color:red}-1 patch{color}.  The patch command could not apply the patch.

Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/1758//console

This message is automatically generated.","16/Nov/12 08:54;stevel@apache.org;Ant doesn't complain about deleting files/dirs that aren't there -otherwise ""ant clean"" wouldn't be idempotent.

If it couldn't delete a file, then there's another cause -such as the file is in use.

Setting {{quiet=true}} will keep the build going on after this -but the root cause is still lurking out there -maybe an MR process is still running.

Is this replicable on your system? if you insert an {{<exec command=""jps -v"" />}} , what processes are seen to be running?","03/Dec/12 07:10;junping_du;Hi Steve, What do you suggest here? I seems to run into the same issue before, but not sure how to fix that. It seems in this case, ant tries to delete a directory not exist (which put file (or sub-directory) names under a directory into a directory name). I just discussed with Meng, he is still in investigating but suspect ant has a bug from this behaviour. Any suggestion here?  ","03/Dec/12 09:02;stevel@apache.org;Trying to delete a nonexistent directory is not the problem, otherwise {{ant clean}} wouldn't be idempotent. Something else is going wrong here.

# it may be windows only
# it may be some race condition with in-test cleanup taking place while directory cleanup takes place

try doing a quick {{<sleep>}} before the delete to see if the error goes away. If so it is a race condition -which could be dodged either by setting that {{quiet=true}} -once we're confident it's a race condition.","13/Dec/12 22:50;vicaya;It appears that some MR tests are creating circular symlinks of attempt dirs. The failure is due to ant delete dir by default following symlinks for ""historical reasons"" (cf. https://ant.apache.org/manual/Tasks/delete.html, which is different from the semantics of rm -rf that doesn't follow symlinks). Once the failure occurrs, the subsequent ant clean runs fail in a similar fashion.

The hadoop-9051-v1.patch will make allow all tests to finish properly. Will file a separate JIRA to fix the offending tests.



","13/Dec/12 23:31;hadoopqa;{color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12560864/hadoop-9051-v1.patch
  against trunk revision .

    {color:red}-1 patch{color}.  The patch command could not apply the patch.

Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/1867//console

This message is automatically generated.","13/Dec/12 23:38;vicaya;Note, this is for branch-1.* only (seems to affect branch-1 more than branch-1.0, as former creates more circular symlinks then the latter. branch-1.0 can actually finish with the same errors at the end of the tests). Maven build in trunk doesn't seem to suffer from the peculiar delete dir semantics. ","14/Dec/12 00:15;vicaya;Looks like the circular symlinks are caused by TestJobTrackerSafeMode and TestJobTrackerRestartWithLostTracker, which are both ignorable tests for now. ","14/Dec/12 01:50;junping_du;Sorry. I didn't realize I reply a letter coming from jira. Just ignore above comments please. ","14/Dec/12 05:06;junping_du;Hi Luke, Thanks for the patch. I test it on my local environment and do resolve the same problem. +1 on the patch.","15/Dec/12 03:51;vicaya;Committed trivial patch to branch-1* branches. Thanks for verifying the patch Junping.","18/Dec/12 00:29;sureshms;Luke, I know this is a trivial patch. But please make sure a committer +1s the change.","18/Dec/12 11:00;vicaya;bq. But please make sure a committer +1s the change.

+1. Was in a hurry to unblock branch-1 testing. Should've let others finish the patch :)","06/Mar/13 09:56;mattf;Closed upon successful release of 1.1.2.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Add a test for umask in FileSystemContractBaseTest,HADOOP-9042,12609138,Test,Closed,HADOOP,Hadoop Common,software,omalley,Hadoop Common is the common library for Apache Hadoop.,http://hadoop.apache.org/,Minor,Fixed,cmccabe,cmccabe,cmccabe,25/Sep/12 22:04,15/Feb/13 13:12,12/Jan/21 11:55,20/Nov/12 21:20,,,,,2.0.3-alpha,,,,,,,,,,0,,,Add a unit test to make sure {{umask}} is working correctly in FileSystemContractBaseTest.,,atm,cmccabe,eli,Fan04290,hudson,jghoman,kihwal,szetszwo,tlipcon,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,HADOOP-9047,,,,,,,,,,"15/Nov/12 09:28;cmccabe;HADOOP-9042.008.patch;https://issues.apache.org/jira/secure/attachment/12553637/HADOOP-9042.008.patch","16/Nov/12 21:41;cmccabe;HADOOP-9042.009.patch;https://issues.apache.org/jira/secure/attachment/12553840/HADOOP-9042.009.patch","16/Nov/12 23:07;cmccabe;HADOOP-9042.010.patch;https://issues.apache.org/jira/secure/attachment/12553855/HADOOP-9042.010.patch","25/Sep/12 22:06;cmccabe;HDFS-3975.001.patch;https://issues.apache.org/jira/secure/attachment/12546595/HDFS-3975.001.patch","27/Sep/12 18:19;cmccabe;HDFS-3975.002.patch;https://issues.apache.org/jira/secure/attachment/12546890/HDFS-3975.002.patch","27/Sep/12 19:06;cmccabe;HDFS-3975.003.patch;https://issues.apache.org/jira/secure/attachment/12546895/HDFS-3975.003.patch","12/Nov/12 23:02;cmccabe;HDFS-3975.004.patch;https://issues.apache.org/jira/secure/attachment/12553218/HDFS-3975.004.patch","14/Nov/12 01:18;cmccabe;HDFS-3975.005.patch;https://issues.apache.org/jira/secure/attachment/12553422/HDFS-3975.005.patch","15/Nov/12 01:40;cmccabe;HDFS-3975.006.patch;https://issues.apache.org/jira/secure/attachment/12553603/HDFS-3975.006.patch",,,,,,,,,,,,,,,9.0,,,,,,,,,,,,,,,,,,,,2012-09-25 22:30:38.977,,,false,,,,,,,,,,,,,,,,,239570,Reviewed,,,,Wed Nov 21 13:21:44 UTC 2012,,,,,,,"0|i00rav:",2355,,,,,,,,,,,,,,,,,,,,,,,"25/Sep/12 22:30;tlipcon;+1 pending jenkins","26/Sep/12 00:24;hadoopqa;{color:green}+1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12546595/HDFS-3975.001.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 1 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  The javadoc tool did not generate any warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:green}+1 core tests{color}.  The patch passed unit tests in hadoop-hdfs-project/hadoop-hdfs.

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HDFS-Build/3233//testReport/
Console output: https://builds.apache.org/job/PreCommit-HDFS-Build/3233//console

This message is automatically generated.","26/Sep/12 13:30;szetszwo;Are you sure that the test is not already covered by TestWebHdfsFileSystemContract and TestFSMainOperationsWebHdfs?","26/Sep/12 16:51;cmccabe;bq. Are you sure that the test is not already covered by TestWebHdfsFileSystemContract and TestFSMainOperationsWebHdfs?

That's a good question.  I can see that there's a few places where we test permissions-- for example in {{TestWebHdfsFileSystemContract#testResponseCode}} we create a directory and verify that it got permissions of {{0755}}.  This implicitly creates the directory with {{0777}}, and since the default umask is {{022}}, it gets permissions {{0755}}.

I'm not sure if that really qualifies as a test of umask though-- we never explicitly set umask to something other than the default.  In fact we never explicitly specify a non-default permission mode when creating a directory or file in the existing webhdfs tests, so I would say that existing coverage not very complete.

What do you think?  Would it make more sense to add this new test in TestWebHdfsFileSystemContract?","27/Sep/12 14:22;szetszwo;It does make more sense to add the umask test in FileSystemContractBaseTest.  Then, it will also test DistributedFileSystem.","27/Sep/12 18:19;cmccabe;* move umask test to {{FileSystemContractBase}}, since it's more general than just webhdfs","27/Sep/12 18:44;hadoopqa;{color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12546890/HDFS-3975.002.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 1 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  The javadoc tool did not generate any warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:red}-1 core tests{color}.  The patch failed these unit tests in hadoop-common-project/hadoop-common:

                  org.apache.hadoop.fs.s3.TestInMemoryS3FileSystemContract
                  org.apache.hadoop.fs.s3native.TestInMemoryNativeS3FileSystemContract

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HDFS-Build/3243//testReport/
Console output: https://builds.apache.org/job/PreCommit-HDFS-Build/3243//console

This message is automatically generated.","27/Sep/12 19:06;cmccabe;skip umask checks for S3, S3n, since these filesystems do not yet implement permissions","27/Sep/12 19:06;cmccabe;can't test umask for s3, s3n yet since it is not implemented!","27/Sep/12 20:32;hadoopqa;{color:green}+1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12546895/HDFS-3975.003.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 1 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  The javadoc tool did not generate any warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:green}+1 core tests{color}.  The patch passed unit tests in hadoop-common-project/hadoop-common.

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HDFS-Build/3244//testReport/
Console output: https://builds.apache.org/job/PreCommit-HDFS-Build/3244//console

This message is automatically generated.","12/Nov/12 19:41;eli;+1, looks good. Btw you can implement the initial test using:

{code}
Assume.assumeTrue(!fs.getScheme().equals(""s3"") && !fs.getScheme().equals(""s3n""))
{code}","12/Nov/12 23:02;cmccabe;use ""assume"" as Eli suggested","12/Nov/12 23:37;hadoopqa;{color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12553218/HDFS-3975.004.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 1 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  The javadoc tool did not generate any warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:red}-1 core tests{color}.  The patch failed these unit tests in hadoop-common-project/hadoop-common:

                  org.apache.hadoop.fs.s3.TestInMemoryS3FileSystemContract
                  org.apache.hadoop.fs.s3native.TestInMemoryNativeS3FileSystemContract

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HDFS-Build/3490//testReport/
Console output: https://builds.apache.org/job/PreCommit-HDFS-Build/3490//console

This message is automatically generated.","14/Nov/12 01:18;cmccabe;it looks like Assume doesn't work with junit3.  So use a regular old if statement.","14/Nov/12 02:29;hadoopqa;{color:green}+1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12553422/HDFS-3975.005.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 1 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  The javadoc tool did not generate any warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:green}+1 core tests{color}.  The patch passed unit tests in hadoop-common-project/hadoop-common.

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HDFS-Build/3497//testReport/
Console output: https://builds.apache.org/job/PreCommit-HDFS-Build/3497//console

This message is automatically generated.","15/Nov/12 00:56;eli;Can remove the import of Assume or convert the test to junit4, otherwise +1","15/Nov/12 01:40;cmccabe;remove 'import assume'","15/Nov/12 01:51;eli;+1 I've committed this and merged to branch-2.","15/Nov/12 04:28;hudson;Integrated in Hadoop-trunk-Commit #3021 (See [https://builds.apache.org/job/Hadoop-trunk-Commit/3021/])
    HADOOP-9042. Add a test for umask in FileSystemContractBaseTest. Colin Patrick McCabe (Revision 1409635)

     Result = SUCCESS
eli : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1409635
Files : 
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/CHANGES.txt
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/FileSystemContractBaseTest.java
","15/Nov/12 05:52;kihwal;This HDFS test case is failing.  The precommit build did not run any hdfs test, so it didn't catch this.

{panel}
Running org.apache.hadoop.hdfs.TestHDFSFileSystemContract
Tests run: 30, Failures: 1, Errors: 0, Skipped: 0, Time elapsed: 37.774 sec <<< FAILURE!
testMkdirsWithUmask(org.apache.hadoop.hdfs.TestHDFSFileSystemContract)  Time elapsed: 1046 sec  <<< FAILURE!
junit.framework.AssertionFailedError: expected:<461> but was:<493>
	at junit.framework.Assert.fail(Assert.java:47)
	at junit.framework.Assert.failNotEquals(Assert.java:283)
	at junit.framework.Assert.assertEquals(Assert.java:64)
	at junit.framework.Assert.assertEquals(Assert.java:182)
	at junit.framework.Assert.assertEquals(Assert.java:188)
	at org.apache.hadoop.fs.FileSystemContractBaseTest.testMkdirsWithUmask(FileSystemContractBaseTest.java:170)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at junit.framework.TestCase.runTest(TestCase.java:168)
	at junit.framework.TestCase.runBare(TestCase.java:134)
	at junit.framework.TestResult$1.protect(TestResult.java:110)
	at junit.framework.TestResult.runProtected(TestResult.java:128)
	at junit.framework.TestResult.run(TestResult.java:113)
	at junit.framework.TestCase.run(TestCase.java:124)
	at junit.framework.TestSuite.runTest(TestSuite.java:243)
	at junit.framework.TestSuite.run(TestSuite.java:238)
	at org.junit.internal.runners.JUnit38ClassRunner.run(JUnit38ClassRunner.java:83)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:252)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:141)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:112)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.maven.surefire.util.ReflectionUtils.invokeMethodWithArray(ReflectionUtils.java:189)
	at org.apache.maven.surefire.booter.ProviderFactory$ProviderProxy.invoke(ProviderFactory.java:165)
	at org.apache.maven.surefire.booter.ProviderFactory.invokeProvider(ProviderFactory.java:85)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:115)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:75)
{panel}","15/Nov/12 09:12;cmccabe;The problem seems to be that DFSClient caches the value of fs.permissions.umask-mode once when it's created, and doesn't update it if the configured value changes.  The value is cached in a final field in {{DFSClient#Conf#uMask}}.","15/Nov/12 09:28;cmccabe;here's a fix.","15/Nov/12 10:47;hudson;Integrated in Hadoop-Yarn-trunk #37 (See [https://builds.apache.org/job/Hadoop-Yarn-trunk/37/])
    HADOOP-9042. Add a test for umask in FileSystemContractBaseTest. Colin Patrick McCabe (Revision 1409635)

     Result = SUCCESS
eli : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1409635
Files : 
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/CHANGES.txt
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/FileSystemContractBaseTest.java
","15/Nov/12 12:51;hudson;Integrated in Hadoop-Hdfs-trunk #1227 (See [https://builds.apache.org/job/Hadoop-Hdfs-trunk/1227/])
    HADOOP-9042. Add a test for umask in FileSystemContractBaseTest. Colin Patrick McCabe (Revision 1409635)

     Result = FAILURE
eli : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1409635
Files : 
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/CHANGES.txt
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/FileSystemContractBaseTest.java
","15/Nov/12 13:21;hudson;Integrated in Hadoop-Mapreduce-trunk #1258 (See [https://builds.apache.org/job/Hadoop-Mapreduce-trunk/1258/])
    HADOOP-9042. Add a test for umask in FileSystemContractBaseTest. Colin Patrick McCabe (Revision 1409635)

     Result = FAILURE
eli : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1409635
Files : 
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/CHANGES.txt
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/FileSystemContractBaseTest.java
","15/Nov/12 18:15;eli;I reverted the change, Colin, please post a new patch that incorporates your fix.

Btw looking at the delta why define TEST_UMASK in common if it's only used in HDFS?","15/Nov/12 18:25;hudson;Integrated in Hadoop-trunk-Commit #3025 (See [https://builds.apache.org/job/Hadoop-trunk-Commit/3025/])
    Revert HADOOP-9042. (Revision 1409902)

     Result = SUCCESS
eli : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1409902
Files : 
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/CHANGES.txt
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/FileSystemContractBaseTest.java
","15/Nov/12 18:37;cmccabe;here's an updated patch which includes the fix.

To answer your question, Eli, {{TEST_UMASK}} is used in both {{FileSystemContractBaseTest}} and {{TestHDFSFileSystemContract}}.  The issue is that HDFS requires the default umask to be set when the {{FileSystem}} is created, whereas the other filesystems can accept it being changed later.","16/Nov/12 03:25;hadoopqa;{color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12553678/HADOOP-9042.009.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 2 new or modified test files.

    {color:red}-1 javac{color:red}.  The patch appears to cause the build to fail.

Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/1757//console

This message is automatically generated.","16/Nov/12 10:48;hudson;Integrated in Hadoop-Yarn-trunk #38 (See [https://builds.apache.org/job/Hadoop-Yarn-trunk/38/])
    Revert HADOOP-9042. (Revision 1409902)

     Result = SUCCESS
eli : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1409902
Files : 
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/CHANGES.txt
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/FileSystemContractBaseTest.java
","16/Nov/12 13:06;hudson;Integrated in Hadoop-Hdfs-trunk #1228 (See [https://builds.apache.org/job/Hadoop-Hdfs-trunk/1228/])
    Revert HADOOP-9042. (Revision 1409902)

     Result = SUCCESS
eli : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1409902
Files : 
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/CHANGES.txt
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/FileSystemContractBaseTest.java
","16/Nov/12 13:21;hudson;Integrated in Hadoop-Mapreduce-trunk #1259 (See [https://builds.apache.org/job/Hadoop-Mapreduce-trunk/1259/])
    Revert HADOOP-9042. (Revision 1409902)

     Result = FAILURE
eli : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1409902
Files : 
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/CHANGES.txt
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/FileSystemContractBaseTest.java
","16/Nov/12 21:57;hadoopqa;{color:red}-1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12553840/HADOOP-9042.009.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 2 new or modified test files.

    {color:red}-1 javac{color:red}.  The patch appears to cause the build to fail.

Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/1765//console

This message is automatically generated.","17/Nov/12 00:57;hadoopqa;{color:green}+1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12553855/HADOOP-9042.010.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 2 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  The javadoc tool did not generate any warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:green}+1 core tests{color}.  The patch passed unit tests in hadoop-common-project/hadoop-common hadoop-hdfs-project/hadoop-hdfs.

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HADOOP-Build/1766//testReport/
Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/1766//console

This message is automatically generated.","20/Nov/12 21:13;eli;+1 latest patch looks good","20/Nov/12 21:20;eli;I've committed this and merged to branch-2. Thanks Colin.","20/Nov/12 21:27;hudson;Integrated in Hadoop-trunk-Commit #3049 (See [https://builds.apache.org/job/Hadoop-trunk-Commit/3049/])
    HADOOP-9042. Add a test for umask in FileSystemContractBaseTest. Contributed by Colin McCabe (Revision 1411879)

     Result = SUCCESS
eli : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1411879
Files : 
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/CHANGES.txt
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/FileSystemContractBaseTest.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestHDFSFileSystemContract.java
","21/Nov/12 10:49;hudson;Integrated in Hadoop-Yarn-trunk #43 (See [https://builds.apache.org/job/Hadoop-Yarn-trunk/43/])
    HADOOP-9042. Add a test for umask in FileSystemContractBaseTest. Contributed by Colin McCabe (Revision 1411879)

     Result = SUCCESS
eli : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1411879
Files : 
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/CHANGES.txt
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/FileSystemContractBaseTest.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestHDFSFileSystemContract.java
","21/Nov/12 13:04;hudson;Integrated in Hadoop-Hdfs-trunk #1233 (See [https://builds.apache.org/job/Hadoop-Hdfs-trunk/1233/])
    HADOOP-9042. Add a test for umask in FileSystemContractBaseTest. Contributed by Colin McCabe (Revision 1411879)

     Result = SUCCESS
eli : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1411879
Files : 
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/CHANGES.txt
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/FileSystemContractBaseTest.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestHDFSFileSystemContract.java
","21/Nov/12 13:21;hudson;Integrated in Hadoop-Mapreduce-trunk #1264 (See [https://builds.apache.org/job/Hadoop-Mapreduce-trunk/1264/])
    HADOOP-9042. Add a test for umask in FileSystemContractBaseTest. Contributed by Colin McCabe (Revision 1411879)

     Result = FAILURE
eli : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1411879
Files : 
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/CHANGES.txt
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/fs/FileSystemContractBaseTest.java
* /hadoop/common/trunk/hadoop-hdfs-project/hadoop-hdfs/src/test/java/org/apache/hadoop/hdfs/TestHDFSFileSystemContract.java
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Auto-HA: Replace ClientBaseWithFixes with our own modified copy of the class,HADOOP-8260,12550044,Test,Resolved,HADOOP,Hadoop Common,software,omalley,Hadoop Common is the common library for Apache Hadoop.,http://hadoop.apache.org/,Minor,Fixed,tlipcon,tlipcon,tlipcon,07/Apr/12 00:01,07/Apr/12 22:17,12/Jan/21 11:55,07/Apr/12 22:17,Auto Failover (HDFS-3042),,,,Auto Failover (HDFS-3042),,,,,,auto-failover,test,,,0,,,"The class ClientBaseWithFixes is an attempt to add some workaround code to avoid spurious failures due to ZOOKEEPER-1438. But, even after making those workarounds, I've seen a few Jenkins failures due to that issue. Until ZK fixes this issue, I'd like to just copy the test infrastructure into our own code, and remove the problematic JMXEnv verifications.",,Fan04290,szetszwo,WHAA,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"07/Apr/12 00:03;tlipcon;hadoop-8260.txt;https://issues.apache.org/jira/secure/attachment/12521787/hadoop-8260.txt",,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,2012-04-07 00:47:34.596,,,false,,,,,,,,,,,,,,,,,234945,Reviewed,,,,Sat Apr 07 22:17:34 UTC 2012,,,,,,,"0|i018y7:",5219,,,,,,,,,,,,,Auto Failover (HDFS-3042),,,,,,,,,,"07/Apr/12 00:03;tlipcon;Simple patch. This copy-pastes the class from the ZK 3.4.2 (the one we're depending on). I also removed some of the utility functions that we're not making use of, to minimize the amount of copy-paste.

It's a shame we have to do this, but seems prudent since it may take some time to figure out the underlying ZK bug, and it's only a test issue rather than part of the actual code.","07/Apr/12 00:47;eli2;Agree this makes sense.  +1 patch looks good","07/Apr/12 22:17;tlipcon;Committed to branch. I ran all of the tests which inherit from this class before committing.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Auto-HA: Replace ClientBaseWithFixes with our own modified copy of the class,HADOOP-8259,12550043,Test,Resolved,HADOOP,Hadoop Common,software,omalley,Hadoop Common is the common library for Apache Hadoop.,http://hadoop.apache.org/,Minor,Duplicate,tlipcon,tlipcon,tlipcon,07/Apr/12 00:00,07/Apr/12 00:06,12/Jan/21 11:55,07/Apr/12 00:06,Auto Failover (HDFS-3042),,,,,,,,,,auto-failover,test,,,0,,,"The class ClientBaseWithFixes is an attempt to add some workaround code to avoid spurious failures due to ZOOKEEPER-1438. But, even after making those workarounds, I've seen a few Jenkins failures due to that issue. Until ZK fixes this issue, I'd like to just copy the test infrastructure into our own code, and remove the problematic JMXEnv verifications.",,Fan04290,WHAA,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,234944,,,,,Sat Apr 07 00:06:40 UTC 2012,,,,,,,"0|i07udz:",43690,,,,,,,,,,,,,Auto Failover (HDFS-3042),,,,,,,,,,"07/Apr/12 00:06;tlipcon;JIRA being funky today... clicked create once but got two copies. Dup of HADOOP-8260",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Add TestPath tests for URI conversion and reserved characters  ,HADOOP-7526,12518167,Test,Closed,HADOOP,Hadoop Common,software,omalley,Hadoop Common is the common library for Apache Hadoop.,http://hadoop.apache.org/,Minor,Fixed,eli,eli,eli,08/Aug/11 03:56,15/Nov/11 00:50,12/Jan/21 11:55,11/Aug/11 23:02,0.23.0,,,,0.23.0,,,,,,fs,,,,0,,,TestPath needs tests that cover URI conversion (eg places where Paths and URIs differ) and handling of URI reserved characters in paths. ,,atm,cutting,eli,Fan04290,tlipcon,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"08/Aug/11 03:57;eli;hadoop-7526-1.patch;https://issues.apache.org/jira/secure/attachment/12489653/hadoop-7526-1.patch",,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,2011-08-11 22:59:42.492,,,false,,,,,,,,,,,,,,,,,65236,Reviewed,,,,Thu Aug 11 23:17:33 UTC 2011,,,,,,,"0|i09jev:",53578,,,,,,,,,,,,,,,,,,,,,,,"08/Aug/11 03:57;eli;Patch attached.","11/Aug/11 22:57;eli;test-patch results..
{noformat}
+1 overall.  

    +1 @author.  The patch does not contain any @author tags.

    +1 tests included.  The patch appears to include 3 new or modified tests.

    +1 javadoc.  The javadoc tool did not generate any warning messages.

    +1 javac.  The applied patch does not increase the total number of javac compiler warnings.

    +1 findbugs.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    +1 release audit.  The applied patch does not increase the total number of release audit warnings.

    +1 system test framework.  The patch passed system test framework compile.
{noformat}","11/Aug/11 22:59;atm;+1, patch looks good to me.","11/Aug/11 23:02;eli;Thanks atm! I've committed this.","11/Aug/11 23:17;hudson;Integrated in Hadoop-Common-trunk-Commit #733 (See [https://builds.apache.org/job/Hadoop-Common-trunk-Commit/733/])
    HADOOP-7526. Add TestPath tests for URI conversion and reserved characters. Contributed by Eli Collins

eli : http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1156857
Files : 
* /hadoop/common/trunk/hadoop-common/CHANGES.txt
* /hadoop/common/trunk/hadoop-common/src/test/java/org/apache/hadoop/fs/TestPath.java
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
[HOD] Minor changes to unit tests,HADOOP-3077,12392160,Test,Resolved,HADOOP,Hadoop Common,software,omalley,Hadoop Common is the common library for Apache Hadoop.,http://hadoop.apache.org/,Minor,Won't Fix,yhemanth,yhemanth,yhemanth,24/Mar/08 05:22,18/May/11 22:03,12/Jan/21 11:55,18/May/11 22:03,0.17.0,,,,,,,,,,contrib/hod,,,,0,,,"HADOOP-2899 and HADOOP-2936 introduced minor problems in their unit tests that should be fixed.

As per HADOOP-2899: There's an incorrect hardcoded error message. Also, a test data uses a user name which should be changed.
As per HADOOP-2936: Temporary testing directories are being left behind after some tests run.",,WHAA,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,2011-05-18 22:03:39.853,,,false,,,,,,,,,,,,,,,,,125774,,,,,Wed May 18 22:03:39 UTC 2011,,,,,,,"0|i0idnz:",105308,,,,,,,,,,,,,,,,,,,,,,,"18/May/11 22:03;nidaley;hod contrib was removed",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Add directory renaming test to FileContextMainOperationsBaseTest,HADOOP-6689,12461430,Test,Closed,HADOOP,Hadoop Common,software,omalley,Hadoop Common is the common library for Apache Hadoop.,http://hadoop.apache.org/,Minor,Fixed,eli,eli,eli,07/Apr/10 17:17,24/Aug/10 20:42,12/Jan/21 11:55,13/Apr/10 17:02,0.22.0,,,,0.21.0,,,,,,fs,test,,,0,,,I noticed FileContextMainOperationsBaseTest does not have a test that renames an empty directory to an empty directory (and shows that this fails without the overwrite option). ,,Fan04290,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"07/Apr/10 17:20;eli;hadoop-6689-1.patch;https://issues.apache.org/jira/secure/attachment/12441059/hadoop-6689-1.patch","07/Apr/10 18:09;eli;hadoop-6689-2.patch;https://issues.apache.org/jira/secure/attachment/12441066/hadoop-6689-2.patch",,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,2010-04-07 17:51:51.564,,,false,,,,,,,,,,,,,,,,,127362,Reviewed,,,,Tue Apr 13 17:09:39 UTC 2010,,,,,,,"0|i0hznj:",103038,,,,,,,,,,,,,,,,,,,,,,,"07/Apr/10 17:20;eli;Adds testRenameDirectoryAsEmptyDirectory and fixes some comments in testRenameDirectoryAsNonEmptyDirectory. Tested on HDFS and locally via  TestHDFSFileContextMainOperations and TestHDFSFileContextMainOperations. 
","07/Apr/10 17:51;hadoopqa;-1 overall.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12441059/hadoop-6689-1.patch
  against trunk revision 931226.

    +1 @author.  The patch does not contain any @author tags.

    +1 tests included.  The patch appears to include 3 new or modified tests.

    +1 javadoc.  The javadoc tool did not generate any warning messages.

    +1 javac.  The applied patch does not increase the total number of javac compiler warnings.

    +1 findbugs.  The patch does not introduce any new Findbugs warnings.

    +1 release audit.  The applied patch does not increase the total number of release audit warnings.

    -1 core tests.  The patch failed core unit tests.

    +1 contrib tests.  The patch passed contrib unit tests.

Test results: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch-h4.grid.sp2.yahoo.net/445/testReport/
Findbugs warnings: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch-h4.grid.sp2.yahoo.net/445/artifact/trunk/build/test/findbugs/newPatchFindbugsWarnings.html
Checkstyle results: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch-h4.grid.sp2.yahoo.net/445/artifact/trunk/build/test/checkstyle-errors.html
Console output: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch-h4.grid.sp2.yahoo.net/445/console

This message is automatically generated.","07/Apr/10 18:09;eli;Right patch this time.","07/Apr/10 18:27;hadoopqa;+1 overall.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12441066/hadoop-6689-2.patch
  against trunk revision 931226.

    +1 @author.  The patch does not contain any @author tags.

    +1 tests included.  The patch appears to include 3 new or modified tests.

    +1 javadoc.  The javadoc tool did not generate any warning messages.

    +1 javac.  The applied patch does not increase the total number of javac compiler warnings.

    +1 findbugs.  The patch does not introduce any new Findbugs warnings.

    +1 release audit.  The applied patch does not increase the total number of release audit warnings.

    +1 core tests.  The patch passed core unit tests.

    +1 contrib tests.  The patch passed contrib unit tests.

Test results: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch-h4.grid.sp2.yahoo.net/446/testReport/
Findbugs warnings: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch-h4.grid.sp2.yahoo.net/446/artifact/trunk/build/test/findbugs/newPatchFindbugsWarnings.html
Checkstyle results: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch-h4.grid.sp2.yahoo.net/446/artifact/trunk/build/test/checkstyle-errors.html
Console output: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch-h4.grid.sp2.yahoo.net/446/console

This message is automatically generated.","13/Apr/10 16:51;sureshms;+1 for the patch.","13/Apr/10 17:02;sureshms;I committed the patch. Thank you Eli.","13/Apr/10 17:09;hudson;Integrated in Hadoop-Common-trunk-Commit #217 (See [http://hudson.zones.apache.org/hudson/job/Hadoop-Common-trunk-Commit/217/])
    HADOOP-6689. Add directory renaming test to existing FileContext tests. Contributed by Eli Collins.
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Hudson -1 wording change,HADOOP-5952,12426860,Test,Closed,HADOOP,Hadoop Common,software,omalley,Hadoop Common is the common library for Apache Hadoop.,http://hadoop.apache.org/,Minor,Fixed,garymurry,garymurry,garymurry,01/Jun/09 22:30,24/Aug/10 20:38,12/Jan/21 11:55,23/Jun/09 04:46,,,,,0.21.0,,,,,,build,,,,0,,,The wording should be changed when Hudson -1 a patch for no unit test updates.  New wording to be be added in comments.,,garymurry,szetszwo,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"18/Jun/09 20:49;garymurry;HADOOP-5952.patch;https://issues.apache.org/jira/secure/attachment/12411136/HADOOP-5952.patch",,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,2009-06-01 23:16:10.941,,,false,,,,,,,,,,,,,,,,,127113,Reviewed,,,,Tue Jun 30 10:24:34 UTC 2009,,,,,,,"0|i0i29b:",103460,,,,,,,,,,,,,,,,,,,,,,,"01/Jun/09 22:32;garymurry;The current wording is ""-1 tests included.  The patch doesn't appear to include any new or modified tests.  Please justify why no tests are needed for this patch.""  The new wording I would propose is ""-1 tests include.  The patch doesn't appear to include any new or modified test.  Please justify why no tests are needed for this patch.  Also please list what manual steps were performed to verify this patch.""   The wording was sent to core-dev@hadoop.apache.org with the only response being a +1 from Nigel.","01/Jun/09 23:16;szetszwo;> ... Please justify why no tests are needed for this patch...

How about change it to ""... Please justify why no new tests are needed for this patch...""?

In some cases, a patch may fix problems with existing failing unit tests, or it is a performance improvement (so the correctness is tested by the existing tests).","18/Jun/09 20:49;garymurry;Results from test-patch

     [exec] +1 overall.
     [exec]
     [exec]     +1 @author.  The patch does not contain any @author tags.
     [exec]
     [exec]     +1 tests included.  The patch appears to include 3 new or modified tests.
     [exec]
     [exec]     +1 javadoc.  The javadoc tool did not generate any warning messages.
     [exec]
     [exec]     +1 javac.  The applied patch does not increase the total number of javac compiler warnings.
     [exec]
     [exec]     +1 findbugs.  The patch does not introduce any new Findbugs warnings.
     [exec]
     [exec]     +1 Eclipse classpath. The patch retains Eclipse classpath integrity.
     [exec]
     [exec]     +1 release audit.  The applied patch does not increase the total number of release audit warnings.

Note: not really +1 on tests included.  But this does not need new tests since it is a minor chnge int he wording of test-patch.sh.","18/Jun/09 21:03;szetszwo;+1 new patch looks good.","23/Jun/09 04:46;szetszwo;I have committed this.  Thanks, Gary!","24/Jun/09 04:47;hudson;Integrated in Hadoop-Common-trunk #6 (See [http://hudson.zones.apache.org/hudson/job/Hadoop-Common-trunk/6/])
    . Change ""-1 tests included"" wording in test-patch.sh.  Contributed by Gary Murry
","30/Jun/09 10:24;hadoopqa;-1 overall.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12411136/HADOOP-5952.patch
  against trunk revision 786278.

    +1 @author.  The patch does not contain any @author tags.

    +1 tests included.  The patch appears to include 3 new or modified tests.

    +1 javadoc.  The javadoc tool did not generate any warning messages.

    +1 javac.  The applied patch does not increase the total number of javac compiler warnings.

    +1 findbugs.  The patch does not introduce any new Findbugs warnings.

    +1 Eclipse classpath. The patch retains Eclipse classpath integrity.

    +1 release audit.  The applied patch does not increase the total number of release audit warnings.

    -1 core tests.  The patch failed core unit tests.

    -1 contrib tests.  The patch failed contrib unit tests.

Test results: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch-vesta.apache.org/538/testReport/
Findbugs warnings: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch-vesta.apache.org/538/artifact/trunk/build/test/findbugs/newPatchFindbugsWarnings.html
Checkstyle results: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch-vesta.apache.org/538/artifact/trunk/build/test/checkstyle-errors.html
Console output: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch-vesta.apache.org/538/console

This message is automatically generated.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Split TestCLI into HDFS, Mapred and Core tests",HADOOP-5081,12412791,Test,Closed,HADOOP,Hadoop Common,software,omalley,Hadoop Common is the common library for Apache Hadoop.,http://hadoop.apache.org/,Minor,Fixed,sharadag,rramya,rramya,20/Jan/09 05:48,24/Aug/10 20:35,12/Jan/21 11:55,05/May/09 09:18,0.20.0,,,,0.21.0,,,,,,test,,,,0,,,"At present, TestCLI contains command line tests for both hdfs and mapred. Going forward, this test has to be broken up into separate hdfs, mapred and core tests.",,sharadag,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,HADOOP-5135,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"30/Apr/09 12:32;sharadag;5081_v1.patch;https://issues.apache.org/jira/secure/attachment/12406919/5081_v1.patch","04/May/09 11:27;sharadag;5081_v2.patch;https://issues.apache.org/jira/secure/attachment/12407145/5081_v2.patch","05/May/09 08:59;sharadag;5081_v3.patch;https://issues.apache.org/jira/secure/attachment/12407225/5081_v3.patch",,,,,,,,,,,,,,,,,,,,,3.0,,,,,,,,,,,,,,,,,,,,2009-04-30 12:32:09.401,,,false,,,,,,,,,,,,,,,,,126916,Reviewed,,,,Tue May 05 19:06:55 UTC 2009,,,,,,,"0|i0i52f:",103915,,,,,,,,,,,,,,,,,,,,,,,"30/Apr/09 12:32;sharadag;This patch:
Splits the class TestCLI into TestCLI, TestHDFSCLI and TestMRCLI.
Also it splits the test files into testConf.xml, testHDFSConf.xml, testMRConf.xml","04/May/09 10:47;jothipn;Some minor comments

# CommandExecutor.execute should ideally return a Results object instead of returning the executor itself
# There are quite a few assert statements that basically are no-ops as the condition would always return as true
# Remove unused import in TestCLI.java
# Remove the comment ""// Start up mini mr cluster"" in TestCLI.setup","04/May/09 11:27;sharadag;Incorporated review comments.","05/May/09 07:22;jothipn;+1.","05/May/09 08:03;hadoopqa;-1 overall.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12407145/5081_v2.patch
  against trunk revision 771525.

    +1 @author.  The patch does not contain any @author tags.

    +1 tests included.  The patch appears to include 664 new or modified tests.

    +1 javadoc.  The javadoc tool did not generate any warning messages.

    +1 javac.  The applied patch does not increase the total number of javac compiler warnings.

    +1 findbugs.  The patch does not introduce any new Findbugs warnings.

    +1 Eclipse classpath. The patch retains Eclipse classpath integrity.

    -1 release audit.  The applied patch generated 475 release audit warnings (more than the trunk's current 472 warnings).

    -1 core tests.  The patch failed core unit tests.

    +1 contrib tests.  The patch passed contrib unit tests.

Test results: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch-vesta.apache.org/289/testReport/
Release audit warnings: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch-vesta.apache.org/289/artifact/trunk/current/releaseAuditDiffWarnings.txt
Findbugs warnings: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch-vesta.apache.org/289/artifact/trunk/build/test/findbugs/newPatchFindbugsWarnings.html
Checkstyle results: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch-vesta.apache.org/289/artifact/trunk/build/test/checkstyle-errors.html
Console output: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch-vesta.apache.org/289/console

This message is automatically generated.","05/May/09 08:57;sharadag;test failures are unrelated.","05/May/09 08:59;sharadag;added license header in TestHDFSCLI and TestMRCLI","05/May/09 09:18;sharadag;I just committed this.","05/May/09 19:06;hudson;Integrated in Hadoop-trunk #827 (See [http://hudson.zones.apache.org/hudson/job/Hadoop-trunk/827/])
    . Split TestCLI into HDFS, Mapred and Core tests.
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Update TestCLI with additional test cases.,HADOOP-5080,12412789,Test,Closed,HADOOP,Hadoop Common,software,omalley,Hadoop Common is the common library for Apache Hadoop.,http://hadoop.apache.org/,Minor,Fixed,,rramya,rramya,20/Jan/09 04:36,24/Aug/10 20:35,12/Jan/21 11:55,07/May/09 16:02,0.20.0,,,,0.21.0,,,,,,test,,,,0,,,"Currently TestCLI contains few of the dfs commands and verifies some of the error messages for quota and refreshServiceAcl.. Here is a proposal to add additional test cases to TestCLI to cover an exhaustive list of Hadoop commands. Here is a list of action items for the same:
1) Complete the test cases for dfs commands which are not yet automated such as count, chmod, chown, chgrp etc
2) Verify help messages in fs, dfsadmin, mradmin
3) Add other Hadoop commands such as archives, dfsadmin, balancer, job, queue, version, jar, distcp, daemonlog etc to the command line test.
",,nidaley,raviphulari,sharadag,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"06/May/09 06:33;karthv;HADOOP-5080-v2.patch;https://issues.apache.org/jira/secure/attachment/12407318/HADOOP-5080-v2.patch","28/Apr/09 06:04;karthv;HADOOP-5080.patch;https://issues.apache.org/jira/secure/attachment/12406609/HADOOP-5080.patch","04/May/09 09:13;karthv;HADOOP-5080NEW.patch;https://issues.apache.org/jira/secure/attachment/12407138/HADOOP-5080NEW.patch","29/Apr/09 11:21;karthv;HADOOP-5080Update.patch;https://issues.apache.org/jira/secure/attachment/12406766/HADOOP-5080Update.patch","14/Mar/09 05:33;karthv;Hadoop-5080.patch;https://issues.apache.org/jira/secure/attachment/12402190/Hadoop-5080.patch","23/Apr/09 13:28;karthv;Hadoop-5080New.patch;https://issues.apache.org/jira/secure/attachment/12406231/Hadoop-5080New.patch","07/Apr/09 04:27;karthv;Hadoop-5080Updated.patch;https://issues.apache.org/jira/secure/attachment/12404802/Hadoop-5080Updated.patch","24/Apr/09 14:19;karthv;Hadoop-5080new.patch;https://issues.apache.org/jira/secure/attachment/12406363/Hadoop-5080new.patch","30/Apr/09 01:26;raviphulari;TEST-org.apache.hadoop.cli.TestCLI.txt;https://issues.apache.org/jira/secure/attachment/12406859/TEST-org.apache.hadoop.cli.TestCLI.txt","07/Apr/09 04:25;karthv;TEST-org.apache.hadoop.cli.TestCLI.txt;https://issues.apache.org/jira/secure/attachment/12404801/TEST-org.apache.hadoop.cli.TestCLI.txt","12/Mar/09 08:52;karthv;TestCLI.doc;https://issues.apache.org/jira/secure/attachment/12402023/TestCLI.doc","25/Mar/09 05:43;karthv;hadoop-5080v1.patch;https://issues.apache.org/jira/secure/attachment/12403587/hadoop-5080v1.patch","04/Feb/09 03:55;rramya;hadoop5080.patch;https://issues.apache.org/jira/secure/attachment/12399413/hadoop5080.patch","20/Jan/09 06:16;rramya;patch5080-v1.txt;https://issues.apache.org/jira/secure/attachment/12398290/patch5080-v1.txt",,,,,,,,,,14.0,,,,,,,,,,,,,,,,,,,,2009-01-20 05:13:48.294,,,false,,,,,,,,,,,,,,,,,87666,Reviewed,,,,Thu May 07 16:02:28 UTC 2009,,,,,,,"0|i0hwsv:",102576,,,,,,,,,,,,,,,,,,,,,,,"20/Jan/09 05:13;nidaley;I would create a separate Jira for the split of this test into HDFS/MapRed/Core.","20/Jan/09 05:52;rramya;Created a separate issue to split the command line test (TestCLI) into HDFS, Mapred and Core: HADOOP-5081. Thanks Nigel.
","20/Jan/09 06:16;rramya;Attaching the initial version of the patch which contains a bunch of test cases for the remaining dfs commands : count, chmod, chown and chgrp.","04/Feb/09 03:55;rramya;Attaching a patch which contains all the hdfs commands and help messages. Karthik will be uploading the patch for non hdfs commands","06/Mar/09 09:19;karthv;Compiled and tested for local machine","06/Mar/09 09:27;iyappans;+1 reviewed the testcases and ran the testcases. Looks fine. ","09/Mar/09 20:35;hadoopqa;-1 overall.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12401607/Hadoop-5080.patch
  against trunk revision 751747.

    +1 @author.  The patch does not contain any @author tags.

    +1 tests included.  The patch appears to include 1031 new or modified tests.

    +1 javadoc.  The javadoc tool did not generate any warning messages.

    +1 javac.  The applied patch does not increase the total number of javac compiler warnings.

    +1 findbugs.  The patch does not introduce any new Findbugs warnings.

    +1 Eclipse classpath. The patch retains Eclipse classpath integrity.

    +1 release audit.  The applied patch does not increase the total number of release audit warnings.

    -1 core tests.  The patch failed core unit tests.

    +1 contrib tests.  The patch passed contrib unit tests.

Test results: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch-vesta.apache.org/58/testReport/
Findbugs warnings: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch-vesta.apache.org/58/artifact/trunk/build/test/findbugs/newPatchFindbugsWarnings.html
Checkstyle results: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch-vesta.apache.org/58/artifact/trunk/build/test/checkstyle-errors.html
Console output: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch-vesta.apache.org/58/console

This message is automatically generated.","09/Mar/09 21:03;nidaley;I noticed that none of the test input paths contain any URIs (hdfs://, file://, etc).  Why is that?","11/Mar/09 04:40;karthv;hdfs:// path is already mentioned in the testcases also ""NAMENODE path"" stands for ""hdfs://namenode:portno/path"".
file:// is implicitly taken in the testcases when CLITEST_DATA is mentioned.
please refer to the attached test scenarios.","12/Mar/09 08:47;karthv;Version test case changed for buildname string pattern.
Test case for /\*/\* globing in hdfs is also included.","12/Mar/09 08:50;iyappans;Checked for these testcase changes and ran the testcases. it went fine.
+1","13/Mar/09 20:53;hadoopqa;-1 overall.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12402023/TestCLI.doc
  against trunk revision 753346.

    +1 @author.  The patch does not contain any @author tags.

    -1 tests included.  The patch doesn't appear to include any new or modified tests.
                        Please justify why no tests are needed for this patch.

    -1 patch.  The patch command could not apply the patch.

Console output: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch-minerva.apache.org/63/console

This message is automatically generated.","14/Mar/09 05:22;rramya;Cancelling the patch since Hudson picked the wrong one.","14/Mar/09 09:14;hadoopqa;+1 overall.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12402190/Hadoop-5080.patch
  against trunk revision 753600.

    +1 @author.  The patch does not contain any @author tags.

    +1 tests included.  The patch appears to include 1033 new or modified tests.

    +1 javadoc.  The javadoc tool did not generate any warning messages.

    +1 javac.  The applied patch does not increase the total number of javac compiler warnings.

    +1 findbugs.  The patch does not introduce any new Findbugs warnings.

    +1 Eclipse classpath. The patch retains Eclipse classpath integrity.

    +1 release audit.  The applied patch does not increase the total number of release audit warnings.

    +1 core tests.  The patch passed core unit tests.

    +1 contrib tests.  The patch passed contrib unit tests.

Test results: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch-vesta.apache.org/88/testReport/
Findbugs warnings: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch-vesta.apache.org/88/artifact/trunk/build/test/findbugs/newPatchFindbugsWarnings.html
Checkstyle results: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch-vesta.apache.org/88/artifact/trunk/build/test/checkstyle-errors.html
Console output: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch-vesta.apache.org/88/console

This message is automatically generated.","17/Mar/09 11:17;karthv;Nigel, can you please commit it.","24/Mar/09 17:46;raviphulari;@ V.Karthikeyan 
I noticed that there are no -setSpaceQuota and -setQuota globbing test cases .  Could you please add these two tests in your patch.
Thanks,","25/Mar/09 05:43;karthv;-setSpaceQuota and -setQuota globbing test cases Updated

Ravi, 
  could you please review and comment back,
Thanks,","06/Apr/09 23:02;raviphulari;
Thanks for adding globbing test cases Karthikeyan .
I was unable to apply patch successfully it might be due to incompatible changes made before or after you submitted patch.
Could you please resubmit patch created with current Trunk . Also please copy/paste your ant test results.

Thanks ,
Ravi
","07/Apr/09 04:31;karthv;Patch is Updated , also ant test results are attached 

Thanks,
V.Karthikeyan","07/Apr/09 18:26;raviphulari;
  -1  ant test-core failed against current hadoop trunk. 

  Test 643: version: display the version of current hadoop failed . 

----------------------------------------------
jar-test:
      [jar] Building jar: /home/rphulari/tasks/5080/hadoop/build/hadoop-0.21.0-dev-test.jar

test-core:
    [mkdir] Created dir: /home/rphulari/tasks/5080/hadoop/build/test/data
    [mkdir] Created dir: /home/rphulari/tasks/5080/hadoop/build/test/logs
     [copy] Copying 1 file to /home/rphulari/tasks/5080/hadoop/build/test/extraconf
    [junit] Running org.apache.hadoop.cli.TestCLI
    [junit] Tests run: 1, Failures: 1, Errors: 0, Time elapsed: 95.039 sec
    [junit] Test org.apache.hadoop.cli.TestCLI FAILED
    [junit] Running org.apache.hadoop.conf.TestConfiguration
    [junit] Tests run: 12, Failures: 0, Errors: 0, Time elapsed: 0.868 sec
    [junit] Running org.apache.hadoop.conf.TestConfigurationSubclass


Log from TEST-org.apache.hadoop.cli.TestCLI.txt
-------------------------------------
2009-04-07 18:27:43,927 INFO  cli.TestCLI (TestCLI.java:displayResults(233)) - 
2009-04-07 18:27:43,927 INFO  cli.TestCLI (TestCLI.java:displayResults(237)) - Summary results:
2009-04-07 18:27:43,927 INFO  cli.TestCLI (TestCLI.java:displayResults(238)) - ----------------------------------

2009-04-07 18:27:43,927 INFO  cli.TestCLI (TestCLI.java:displayResults(258)) -                Testing mode: test
2009-04-07 18:27:43,927 INFO  cli.TestCLI (TestCLI.java:displayResults(259)) - 
2009-04-07 18:27:43,928 INFO  cli.TestCLI (TestCLI.java:displayResults(260)) -              Overall result: --- FAIL ---
2009-04-07 18:27:43,928 INFO  cli.TestCLI (TestCLI.java:displayResults(262)) -                # Tests pass: 642 (99%)
2009-04-07 18:27:43,928 INFO  cli.TestCLI (TestCLI.java:displayResults(264)) -                # Tests fail: 1 (0%)
2009-04-07 18:27:43,928 INFO  cli.TestCLI (TestCLI.java:displayResults(266)) -          # Validations done: 1860 (each test may do multiple validations)
2009-04-07 18:27:43,928 INFO  cli.TestCLI (TestCLI.java:displayResults(269)) - 
2009-04-07 18:27:43,928 INFO  cli.TestCLI (TestCLI.java:displayResults(270)) - Failing tests:
2009-04-07 18:27:43,928 INFO  cli.TestCLI (TestCLI.java:displayResults(271)) - --------------
2009-04-07 18:27:43,928 INFO  cli.TestCLI (TestCLI.java:displayResults(277)) - 643: version: display the version of current hadoop
2009-04-07 18:27:43,929 INFO  cli.TestCLI (TestCLI.java:displayResults(287)) - 
2009-04-07 18:27:43,929 INFO  cli.TestCLI (TestCLI.java:displayResults(288)) - Passing tests:
2009-04-07 18:27:43,929 INFO  cli.TestCLI (TestCLI.java:displayResults(289)) - --------------
2009-04-07 18:27:43,929 INFO  cli.TestCLI (TestCLI.java:displayResults(293)) - 1: ls: file using absolute path
2009-04-07 18:27:43,929 INFO  cli.TestCLI (TestCLI.java:displayResults(293)) - 2: ls: file using relative path
2009-04-07 18:27:43,929 INFO  cli.TestCLI (TestCLI.java:displayResults(293)) - 3: ls: files using globbing
2009-04-07 18:27:43,929 INFO  cli.TestCLI (TestCLI.java:displayResults(293)) - 4: ls: directory using absolute path
2009-04-07 18:27:43,929 INFO  cli.TestCLI (TestCLI.java:displayResults(293)) - 5: ls: directory using relative path



","23/Apr/09 13:28;karthv;1) Test for Version updated for http and https
2) Tests updated for checking different TimeZones ( tests for dfsadmin - report and dfsadmin -refreshNodes)","24/Apr/09 14:19;karthv;Testcase for version updated","24/Apr/09 22:29;raviphulari;-1 

Testcase for version fails on GIT because testcase assumes version based on Subversion .
Version testcase needs to be compatible with both git and subversion source .

{code:xml} 
<!-- Test for Version -->
+    <test> <!-- TESTED -->
+      <description>version: display the version of current hadoop</description>
+      <test-commands>
+        <version-command>NAMENODE</version-command>
+      </test-commands>
+      <cleanup-commands>
+        <!-- No cleanup -->
+      </cleanup-commands>
+      <comparators>
+        <comparator>
+          <type>RegexpComparator</type>
+          <expected-output>^[Hh]adoop [0-9a-zA-Z\.\-_]+$</expected-output>
+        </comparator>
+        <comparator>
+          <type>RegexpComparator</type>
+          <expected-output>^Subversion [a-zA-Z\+]+:\/\/*/+.* -r [0-9]+$</expected-output>
+        </comparator>
+        <comparator>
+          <type>RegexpComparator</type>
+          <expected-output>^Compiled( )*by( )*[a-zA-Z0-9\.]+( )*on( )*[a-zA-Z]+( )*[a-zA-Z]+( )*[0-9]+( )*[0-9]+:[0-9]+:[0-9]+( )*[A-Z\-\+\:0-9]+( )*[0-9]+</expected-output>
+        </comparator>
+      </comparators>
+    </test>

{code} 

Please verify your patch against git and svn  Hadoop source.
--
Thanks,","28/Apr/09 06:04;karthv;Updates on test case for hadoop -version (Includes subversion and GIT)","28/Apr/09 06:56;raviphulari; -1 .
Patch failed against git repository .

Please update patch to pass version test with Haddop built from git source .

bin/hadoop  version  from  git source      

{noformat} 
somehost:hadoop rphulari$ bin/hadoop version
Hadoop 0.21.0-dev
Subversion git://somehost/Users/rphulari/dev/git/hadoop -r 52ca5ddf89b9fc68aac6f05b4c6a8a0b755177bb
Compiled by rphulari on Mon Apr 27 23:46:20 PDT 2009
{noformat}

bin/hadoop version from svn source 

{noformat}
Hadoop 0.21.0-dev
Subversion http://svn.apache.org/repos/asf/hadoop/core/trunk -r 769174
Compiled by rphulari on Mon Apr 27 23:15:44 PDT 2009
{noformat}
","29/Apr/09 11:21;karthv;Test case for hadoop -version command is updated to be more generic for GIT and SVN subversions","30/Apr/09 01:24;raviphulari; -1 .
Latest patch failed against git source ( Summary pasted below , log file is attached for reference ).

HADOOP-4503 is already opened for null version information because of which version test case is failing .

Karthikeyn could you please remove / comment-out version test cases and resubmit the patch.

Thanks ,

---
{noformat} 
2009-04-30 01:13:51,336 INFO cli.TestCLI (TestCLI.java:displayResults(202)) - -------------------------------------------
2009-04-30 01:13:51,336 INFO cli.TestCLI (TestCLI.java:displayResults(203)) - Test ID: [643]
2009-04-30 01:13:51,336 INFO cli.TestCLI (TestCLI.java:displayResults(204)) - Test Description: [version: display the version of current hadoop]
2009-04-30 01:13:51,336 INFO cli.TestCLI (TestCLI.java:displayResults(205)) -
2009-04-30 01:13:51,336 INFO cli.TestCLI (TestCLI.java:displayResults(209)) - Test Commands: [hdfs://localhost:32770]
2009-04-30 01:13:51,336 INFO cli.TestCLI (TestCLI.java:displayResults(213)) -
2009-04-30 01:13:51,337 INFO cli.TestCLI (TestCLI.java:displayResults(220)) -
2009-04-30 01:13:51,337 INFO cli.TestCLI (TestCLI.java:displayResults(224)) - Comparator: [RegexpComparator]
2009-04-30 01:13:51,337 INFO cli.TestCLI (TestCLI.java:displayResults(226)) - Comparision result: [pass]
2009-04-30 01:13:51,337 INFO cli.TestCLI (TestCLI.java:displayResults(228)) - Expected output: [^[Hh]adoop [0-9a-zA-Z\.\-_]+$]
2009-04-30 01:13:51,337 INFO cli.TestCLI (TestCLI.java:displayResults(230)) - Actual output: [Hadoop Unknown
Subversion Unknown -r Unknown
Compiled by Unknown on Unknown
]
2009-04-30 01:13:51,337 INFO cli.TestCLI (TestCLI.java:displayResults(224)) - Comparator: [RegexpComparator]
2009-04-30 01:13:51,337 INFO cli.TestCLI (TestCLI.java:displayResults(226)) - Comparision result: [fail]
2009-04-30 01:13:51,337 INFO cli.TestCLI (TestCLI.java:displayResults(228)) - Expected output: [^Compiled( )*by( )*[a-zA-Z0-9\.]+( )*on( )*[a-zA-Z]+( )*[a-zA-Z]+( )*[0-9]+( )*[0-9]+:[0-9]+:[0-9]+( )*[A-Z\-\+\:0-9]+( )*[0-9]+]
2009-04-30 01:13:51,338 INFO cli.TestCLI (TestCLI.java:displayResults(230)) - Actual output: [Hadoop Unknown
Subversion Unknown -r Unknown
Compiled by Unknown on Unknown
]
2009-04-30 01:13:51,338 INFO cli.TestCLI (TestCLI.java:displayResults(233)) - 
{noformat} ","30/Apr/09 01:26;raviphulari;TestCLI log file","04/May/09 09:13;karthv;testcase for version removed","04/May/09 16:20;nidaley;Please comment on HADOOP-4503 that the version test case should be added back in as part of a patch for that Jira.","04/May/09 19:39;raviphulari;+1 
Latest patch (HADOOP-5080NEW.patch) passed against both git and svn source .
@ Karthikeyan  thanks for updating patch.

 ","05/May/09 06:47;sharadag;-1. TestCLI is failing on trunk.

Overall result: --- FAIL ---
    [junit] 2009-05-05 12:15:09,801 INFO  cli.TestCLI (TestCLI.java:displayResults(262)) -                # Tests pass: 603 (93%)
    [junit] 2009-05-05 12:15:09,802 INFO  cli.TestCLI (TestCLI.java:displayResults(264)) -                # Tests fail: 39 (6%)
    [junit] 2009-05-05 12:15:09,802 INFO  cli.TestCLI (TestCLI.java:displayResults(266)) -          # Validations done: 1857 (each test may do multiple validations)
","05/May/09 19:38;raviphulari;Changing summary to address only one issue of adding more test cases to TestCLI . Other issue of splitting TestCLI in 3 tests (HDFS,Mapred ,Core) is committed with Hadoop-5081.
","06/May/09 06:33;karthv;Patch updated to trunk
-Split up of new test cases (as per Committed patch Hadoop-5081)","06/May/09 18:26;raviphulari;+1 
Verified on SVN and GIT trunk .
Thanks Karthikeyan . ","07/May/09 16:02;nidaley;Thanks Karthikeyan!  I just committed this.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Evaluate HtmlUnit for unit and regression testing webpages,HADOOP-6725,12462980,Test,Open,HADOOP,Hadoop Common,software,omalley,Hadoop Common is the common library for Apache Hadoop.,http://hadoop.apache.org/,Minor,,,jghoman,jghoman,26/Apr/10 04:25,27/May/10 03:18,12/Jan/21 11:55,,,,,,,,,,,,test,,,,0,,,"HtmlUnit (http://htmlunit.sourceforge.net/) looks like it may be a good tool to help unit testing and evaluating our various webpages throughout the project.  Currently this is done only occasionally in the code (usually falls to being a manual test during release cycles), and when it is done, usually the code to parse the webpage, etc. is re-written each time.  The framework is Apache licensed, so including it won't be an issue.  If it's found to be useful, new JIRAs for HDFS and MR should be opened.",,cos,hammer,hong.tang,mguillemot@yahoo.fr,raviphulari,stevel@apache.org,yhemanth,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"27/May/10 03:06;cos;HADOOP-6725.patch;https://issues.apache.org/jira/secure/attachment/12445614/HADOOP-6725.patch",,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,2010-04-26 18:44:42.774,,,false,,,,,,,,,,,,,,,,,127373,,,,,Thu May 27 03:06:58 UTC 2010,,,,,,,"0|i0hzjb:",103019,,,,,,,,,,,,,,,,,,,,,,,"26/Apr/10 18:44;cos;Seems like what we need is [JSPUnit|http://www.jboss.org/jsfunit/] for our front-end UI is auto-generated by JSP. JSPUnit runs on top of HtmlUnit framework though.","26/Apr/10 18:51;jghoman;That works too.","28/Apr/10 10:21;stevel@apache.org;I am +1 for this and anything else which tests the webapps. HtmlUnit is the best in-java web app test framework I know of; I use it on my code. Right now we have some tests for a servlet or two, but nothing looks at the JSP/webapp content, so things like HADOOP-6461 aren't being picked up

# HtmlUnit is looking at moving to the ASF; support from the Hadoop team would be welcome
# JSF unit is separate, it's testing Java Server Faces. HtmlUnit will happily test JSP and pages with javascript in them
# For ease of testing, HTML elements need IDs. HADOOP-5388 covers this. The tags and the tests can go hand in hand. 
# I can help with setting up the test framework, try and get Marc Guillemot to review the design too.

I would really benefit from some HtmlUnit tests that could be run against a live cluster rather than just a miniDFS and miniMR cluster; the tests could be something standalone/redistributable that could be given the URL of a NN, DN, JT or TT and scan through all the expected pages. Having sequences to submit jobs and other actions then becomes further work.
","28/Apr/10 17:31;cos;As soon as HADOOP-6332 is in the trunk (I really hope to complete the forward port work before the end of May) we can start using Herriot framework to perform such tests.","28/Apr/10 17:31;cos;I meant 'using HtmlUnit' framework.","29/Apr/10 11:01;mguillemot@yahoo.fr;@Konstantin: this is not JSPUnit but JSFUnit. Do you use JSP or JSF?

What kind of failures did you have in the past that should not occur again when tested (for instance with HtmlUnit)?","29/Apr/10 14:09;stevel@apache.org;right now we have the situation in which pretty much none of the web UI is tested. API, yes, HTTP, no. There is a cute test that fetches some XML from a servlet and hands off the work to Xerces, but otherwise, nothing. This is unfortunate, as HADOOP-6461 shows -it is not clear that on SVN_TRUNK, the webapps are working.

downstream, some people may be checking the web. My own deployment code takes a list of pages and runs through them, which is how I know about HADOOP-6461. 

What I would like to see test-wise is
# Something to run through all the standard HTML, JSP pages, artwork, check for their presence.
# Maybe: grab dependencies (stylesheets &c)
# Fetch the logs

The more advanced stuff is to run through some real operations: 

# create files via the client API, check you you can browse them 
# submit a job on the command line, and track it via the web UI 

Security: 
# Make unauthenticated calls and expect rejection.
# Have something log <script> text, fetch it from the logs, check the angle-brackets get filtered
# Check cookies are marked httponly once that gets adopted.
# anything else we can think of.","27/May/10 03:05;cos;Apparently, it worth mentioning that HtmlUnit requires xalan2.7. And that dependency can't be resolved with Ivy 2.0 (see IVY-1026)","27/May/10 03:06;cos;To facilitate the evaluation. Please make sure that you are using Ivy at least  2.1.0-rc1",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Unit test for DynamicSerDe,HADOOP-4056,12403577,Test,Closed,HADOOP,Hadoop Common,software,omalley,Hadoop Common is the common library for Apache Hadoop.,http://hadoop.apache.org/,Minor,Fixed,wyckoff,wyckoff,wyckoff,03/Sep/08 00:46,08/Jul/09 17:06,12/Jan/21 11:55,21/Oct/08 19:05,,,,,0.19.0,,,,,,,,,,0,,,"Unit test for the following:

DynamicSerDe/normal TProtocol with and without thrift compatibility mode on including basic, map and list types and a list of maps or something like that
DynamicSerDe/TCTLSeparatedProtocol (with thrift mode on even though it's not really thrift compatible) with basic, map and list types.
DynamicSerDe getFields and getFieldsFromExpression

Also improve general debugability of DynamicSerDe by adding toString methods and better handling unknown field names passed in.

NOTE: at this time, not adding unit tests for nested *types*  in dynamic serde even though this is supported. Just not a priority right now.

",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,38803,,,,,Tue Oct 21 19:05:00 UTC 2008,,,,,,,"0|i0i987:",104589,,,,,,,,,,,,,,,,,,,,,,,"21/Oct/08 19:05;wyckoff;fixed as part of HADOOP-4320
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Hive: test for case sensitivity in serde2 thrift serde,HADOOP-4390,12406209,Test,Closed,HADOOP,Hadoop Common,software,omalley,Hadoop Common is the common library for Apache Hadoop.,http://hadoop.apache.org/,Minor,Fixed,,zshao,zshao,10/Oct/08 21:43,08/Jul/09 17:06,12/Jan/21 11:55,21/Oct/08 18:52,,,,,0.19.0,,,,,,,,,,0,,,,We should add a test for case sensitivity in serde2 thrift serde code.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,126513,,,,,Tue Oct 21 18:52:10 UTC 2008,,,,,,,"0|i0i7qn:",104348,,,,,,,,,,,,,,,,,,,,,,,"21/Oct/08 18:52;zshao;Fixed as part of JIRA-4230",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
TestStreamingBadRecords.testNarrowDown fails intermittently,HADOOP-4237,12404855,Test,Closed,HADOOP,Hadoop Common,software,omalley,Hadoop Common is the common library for Apache Hadoop.,http://hadoop.apache.org/,Minor,Fixed,sharadag,sharadag,sharadag,22/Sep/08 10:24,08/Jul/09 17:05,12/Jan/21 11:55,29/Sep/08 11:02,0.19.0,,,,0.19.0,,,,,,test,,,,0,,,TestStreamingBadRecords.testNarrowDown is failing sometimes because of the delay in the processed counter updation (processed counter updation happens by the separate thread). Due to this there is a broader skipped range to be narrow down. The no of attempts provided in the test case get exhausted before completing the task successfully. ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"22/Sep/08 12:30;sharadag;4237_v1.patch;https://issues.apache.org/jira/secure/attachment/12390639/4237_v1.patch",,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,2008-09-23 07:39:52.211,,,false,,,,,,,,,,,,,,,,,126407,Reviewed,,,,Mon Sep 29 15:27:25 UTC 2008,,,,,,,"0|i0i8gv:",104466,,,,,,,,,,,,,,,,,,,,,,,"22/Sep/08 12:30;sharadag;straight forward patch.
- increased the no of map/reduce attempts
- removed the task timeout case, as it was making the test case to take lot of time and is already covered in TestBadRecords.","23/Sep/08 07:39;hadoopqa;-1 overall.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12390639/4237_v1.patch
  against trunk revision 697306.

    +1 @author.  The patch does not contain any @author tags.

    +1 tests included.  The patch appears to include 3 new or modified tests.

    +1 javadoc.  The javadoc tool did not generate any warning messages.

    +1 javac.  The applied patch does not increase the total number of javac compiler warnings.

    +1 findbugs.  The patch does not introduce any new Findbugs warnings.

    -1 core tests.  The patch failed core unit tests.

    -1 contrib tests.  The patch failed contrib unit tests.

Test results: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch/3350/testReport/
Findbugs warnings: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch/3350/artifact/trunk/build/test/findbugs/newPatchFindbugsWarnings.html
Checkstyle results: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch/3350/artifact/trunk/build/test/checkstyle-errors.html
Console output: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch/3350/console

This message is automatically generated.","24/Sep/08 06:13;sharadag;test failure not related to this patch.","29/Sep/08 11:02;ddas;I just committed this. Thanks, Sharad!","29/Sep/08 15:27;hudson;Integrated in Hadoop-trunk #618 (See [http://hudson.zones.apache.org/hudson/job/Hadoop-trunk/618/])",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
add DF fuse dfs unit test,HADOOP-3928,12402013,Test,Closed,HADOOP,Hadoop Common,software,omalley,Hadoop Common is the common library for Apache Hadoop.,http://hadoop.apache.org/,Minor,Duplicate,wyckoff,wyckoff,wyckoff,08/Aug/08 16:12,08/Jul/09 17:05,12/Jan/21 11:55,16/Sep/08 01:47,,,,,,,,,,,,,,,0,,,"Ensure that DF works in fuse_dfs.c which calls libhdfs.

",,dhruba,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,2008-08-12 06:02:18.803,,,false,,,,,,,,,,,,,,,,,38806,,,,,Tue Sep 16 01:47:23 UTC 2008,,,,,,,"0|i0i9q7:",104670,,,,,,,,,,,,,,,,,,,,,,,"12/Aug/08 06:02;dhruba;DistributedFileSystem and ChecksumDistributedFileSystem has the method getRawCapacity().","12/Aug/08 20:57;wyckoff;Moving this to fuse-dfs. I don't know how I was able to get an exception - ie have libhdfs call getRawCapacity on a non-DFS, but I cannot replicate it.

I will just add a unit test to fuse-dfs to check that DF works.
","16/Sep/08 01:47;wyckoff;that patch added a unit test.
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
A bunch of mapred unit tests are failing on Windows,HADOOP-5114,12413069,Test,Resolved,HADOOP,Hadoop Common,software,omalley,Hadoop Common is the common library for Apache Hadoop.,http://hadoop.apache.org/,Minor,Fixed,rangadi,rramya,rramya,23/Jan/09 08:08,08/Jul/09 16:53,12/Jan/21 11:55,06/Feb/09 20:31,0.18.3,,,,0.18.4,,,,,,test,,,,0,,,"A bunch of unit tests are consistently failing when run on Windows. Below are a list of unit tests which are failing and the corresponding exceptions thrown:

Exception: ""java.net.ConnectException: Connection refused: no further information""
Failing tests:
* TestMiniMRMapRedDebugScript - testMapDebugScript
* TestNoDefaultsJobConf - testNoDefaults
* TestQueueManager - testAllEnabledACLForJobSubmission
* TestCompressedEmptyMapOutputs - testMapReduceSortWithCompressedEmptyMapOutputs
* TestJobInProgressListener - testJobQueueChanges
* TestKillCompletedJob - testKillCompJob
* TestMiniMRClasspath - testClassPath
* TestMiniMRDFSCaching - testWithDFS
* TestMiniMRWithDFSWithDistinctUsers - testDistinctUsers
* TestSetupAndCleanupFailure - testWithDFS
* TestDBJob - testRun
* TestMiniMRWithDFS - testWithDFS
* TestJobStatusPersistency - testNonPersistency
* TestSpecialCharactersInOutputPath - testJobWithDFS
* TestUserDefinedCounters - testMapReduceJob
* TestDelegatingInputFormat - testSplitting
* TestEmptyJobWithDFS - testEmptyJobWithDFS
* TestJavaSerialization - testMapReduceJob
* TestClusterMapReduceTestCase - testMapReduce


Exception: java.lang.IllegalArgumentException: Pathname /<path> from <path> is not a valid DFS filename.
Failing tests:
* TestJobInProgress - testRunningTaskCount
* TestJobQueueInformation - testJobQueues
* TestJobTrackerRestart - testJobTrackerRestart


Exception: java.io.IOException: Bad connect ack with firstBadLink 127.0.0.1:<port number>
Failing tests:
* TestJobSysDirWithDFS - testWithDFS
* TestJobInProgress - testPendingMapTaskCount
* TestMiniMRDFSSort - testMapReduceSort


Exception: junit.framework.AssertionFailedError
Failing tests:
* TestMRServerPorts - testJobTrackerPorts
* TestMRServerPorts - testTaskTrackerPorts
* TestMiniMRTaskTempDir - testTaskTempDir


Exception: java.io.IOException: Job failed!
Failing tests:
* TestMiniMRLocalFS - testWithLocal
",Windows,cutting,Fan04290,ltucker,nidaley,omalley,rangadi,szetszwo,WHAA,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,HDFS-11,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"06/Feb/09 00:59;rangadi;HADOOP-5114-branch-18.patch;https://issues.apache.org/jira/secure/attachment/12399607/HADOOP-5114-branch-18.patch","04/Feb/09 20:03;rangadi;HADOOP-5114-branch-18.patch;https://issues.apache.org/jira/secure/attachment/12399479/HADOOP-5114-branch-18.patch","03/Feb/09 23:28;rangadi;HADOOP-5114-branch-18.patch;https://issues.apache.org/jira/secure/attachment/12399405/HADOOP-5114-branch-18.patch","06/Feb/09 01:01;rangadi;HADOOP-5114.patch;https://issues.apache.org/jira/secure/attachment/12399609/HADOOP-5114.patch","04/Feb/09 20:16;rangadi;HADOOP-5114.patch;https://issues.apache.org/jira/secure/attachment/12399480/HADOOP-5114.patch","03/Feb/09 23:29;rangadi;HADOOP-5114.patch;https://issues.apache.org/jira/secure/attachment/12399406/HADOOP-5114.patch","31/Jan/09 01:52;rangadi;HADOOP-5114.patch;https://issues.apache.org/jira/secure/attachment/12399195/HADOOP-5114.patch","28/Jan/09 02:09;rangadi;HADOOP-5114.patch;https://issues.apache.org/jira/secure/attachment/12398871/HADOOP-5114.patch","30/Jan/09 04:26;rramya;LOGS.zip;https://issues.apache.org/jira/secure/attachment/12399097/LOGS.zip","05/Feb/09 09:04;rramya;TEST-org.apache.hadoop.dfs.TestOverReplicatedBlocks.txt;https://issues.apache.org/jira/secure/attachment/12399537/TEST-org.apache.hadoop.dfs.TestOverReplicatedBlocks.txt","26/Jan/09 23:47;shv;tmp.log;https://issues.apache.org/jira/secure/attachment/12398779/tmp.log",,,,,,,,,,,,,11.0,,,,,,,,,,,,,,,,,,,,2009-01-23 17:58:50.941,,,false,,,,,,,,,,,,,,,,,126927,Reviewed,,,,Mon Feb 16 17:00:40 UTC 2009,,,,,,,"0|i0i4xz:",103895,Remove timeout for accept() in DataNode. This made accept() fail in JDK on Windows and caused many tests to fail.,,,,,,,,,,,,,,,,,,,,,,"23/Jan/09 17:58;nidaley;If this is true, and no one has report Windows test failures before now (we haven't run Windows tests in a while), then should we continue to support Windows?  Is anyone motivated to fix these?","23/Jan/09 19:52;szetszwo;> If this is true, and no one has report Windows test failures before now (we haven't run Windows tests in a while), then should we continue to support Windows?

Before answering whether we should continue to support Windows, we better make sure that ""this is true"".  I ran first 4 tests listed in the description, TestQueueManager did success in my machine.","23/Jan/09 20:11;cutting;I think this shows that not many who use trunk also use Windows.  That doesn't mean that lots of folks who use releases don't use Windows.  Before we consider dropping Windows support we should probably poll core-user.","23/Jan/09 20:20;steve_l;I think its important to make sure the client side all works on windows, regardless of what your server architecture is. 

If so many tests are failling there is likely to be one or two root causes. I can test against SVN head on a vmware XP or Vista image and see what happens","23/Jan/09 20:33;cutting;> I think its important to make sure the client side all works on windows, regardless of what your server architecture is.

If we only supported Windows clients, how would we support debugging on Windows  LocalRunner?  MiniDFS and MiniMR (i.e., running a cluster in a single JVM)?  Debugging with multiple JVMs (a.k.a ""pseudo-distributed"") catches lots of problems that are hard to catch with a single JVM, e.g., relative path and classpath issues.

Also, if we wish to support client-side only, then we'd need to test that automatically, which might mean we:
 - start a standalone cluster on a linux host
 - start a virtual windows box on that linux host that runs client tests against the linux-based cluster.
","23/Jan/09 20:56;shv;I have TestCLI falling into infinite loop with {{java.net.ConnectException: Connection refused: no further information}}, which is thrown from {{SocketIOWithTimeout.connect()}} when it does {{channel.finishConnect()}}.
This code was introduced in HADOOP-4346.
Raghu, could you please take a look.","23/Jan/09 22:21;steve_l;>If we only supported Windows clients, how would we support debugging on Windows LocalRunner?

I agree, testing across platforms adds a lot of extra pain, which is unfair in the OSS world. You wouldn't be able to accept any contributions from windows-based developers, not if you expect their patches to pass the tests before submission. 

","26/Jan/09 22:28;rangadi;From the log that Kostantin gave me, it it not a connect() related problem. The DataNode Xceiver thread fails to accept connections with this exception :

{noformat}[...]    DataXceiveServer: Exiting due to:java.nio.channels.ClosedSelectorException
    [junit]     at sun.nio.ch.SelectorImpl.lockAndDoSelect(SelectorImpl.java:66)
    [junit]     at sun.nio.ch.SelectorImpl.selectNow(SelectorImpl.java:88)
    [junit]     at sun.nio.ch.Util.releaseTemporarySelector(Util.java:135)
    [junit]     at sun.nio.ch.ServerSocketAdaptor.accept(ServerSocketAdaptor.java:120)
    [junit]     at org.apache.hadoop.hdfs.server.datanode.DataXceiverServer.run(DataXceiverServer.java:130)
    [junit]     at java.lang.Thread.run(Thread.java:619)
{noformat}

Because of this, later attempts by clients to connect to DN fails with ""connection refused"" exceptions.","26/Jan/09 22:32;rangadi;Note that ""Selector"" in the above trace is a JDKs own internal selector. It is not a selector managed by Hadoop.","26/Jan/09 23:03;rangadi;HADOOP-4679 sets a 30 second timeout for the ServerSocket used by DataXceiver thread. This server socket is a NIO socket. Tests seem to pass after commenting out timeout setting. This seems to be yet another problem we are seeing with Sun JDK's selectors. Blocking IO with JDK NIO sockets is pretty buggy and unusable.. it works well only for the common use case of NIO : use a static thread pool for non-blocking IO. 

Couple of options :

  * Use Hadoop's selector to wait on the socket ({{SocketIOWithTimeout}})
  * May be a timeout is not necessary, if interrupting the thread wakes this thread.","26/Jan/09 23:47;shv;Attaching the log Raghu mentioned.
Looks like we have just one problem which makes all these tests fail.","27/Jan/09 01:02;hairong;Does this NIO bug occurs only in Windows? I normally is not a fan of ""interrupt"". I'd vote for option 1.","27/Jan/09 01:06;rangadi;Right. I don't like interrupt either. But {{DataNode.shutdown()}}  does interrupt the thread. Not sure if that necessary or not.","28/Jan/09 02:09;rangadi;
Patch for the first option (accept waits using Hadoop selectors) is attached. Tests pass

I still want to check why exactly is the timeout for accept() required.","28/Jan/09 06:05;vinodkv;bq. Does this NIO bug occurs only in Windows?
I have seen this occassionally on Linux too. A while back, tests based on MiniDFS used to fail on my ubuntu machine with precisely the same exception, and now they finish successfully.","28/Jan/09 06:11;vinodkv;bq. A while back, tests based on MiniDFS used to fail on my ubuntu machine with precisely the same exception, and now they finish successfully.
This definitely must be related to the sun jdk. Earlier I was using sun jdk, but now I am on openjdk.","28/Jan/09 10:51;rramya;I ran all the unit tests on Windows a couple of times and observed close to 50 tests failing each time. Besides the above mentioned tests, there are a variety of hdfs, conf, security, cli, tools, fs tests which are failing as well on Windows due to similar kind of errors.
Following is the list of failing tests besides the above reported tests. Some are sporadically failing and some are consistently failing.

* Exception: java.io.IOException: Could not obtain block: <Blk_id> file=/<filename>
** Consistently failing tests:
*** TestDFSUpgradeFromImage - testUpgradeFromImage

* Exception: java.io.IOException: Bad connect ack with firstBadLink 127.0.0.1:<port number>
** Consistent failing tests:
*** TestDecommission - testDecommission
*** TestModTime - testModTime
*** TestServiceLevelAuthorization - testServiceLevelAuthorization
** Sporadically failing tests:
*** TestDFSClientRetries - testWriteTimeoutAtDataNode
*** TestLeaseRecovery - testBlockSynchronization
*** TestBlockReplacement - testBlockReplacement
*** TestNameEditsConfigs - testNameEditsConfigs

* Exception: ""java.net.ConnectException: Connection refused: no further information""
** Consistent failing tests:
*** TestRestartDFS - testRestartDFS
*** TestNoDefaultsJobConf - testNoDefaults
** Sporadically failing tests:
*** TestFileAppend3 - testTC1, testTC7, testTC11
*** TestDistCh - testDistCh
*** TestHarFileSystem - testArchives

* Exception: junit.framework.AssertionFailedError
** Consistent failing tests:
*** TestHDFSServerPorts - testNameNodePorts
*** TestHDFSServerPorts - testDataNodePorts
*** TestHDFSServerPorts - testSecondaryNodePorts
*** TestOverReplicatedBlocks - testProcesOverReplicateBlock

* Exception: org.apache.hadoop.ipc.RemoteException: org.apache.hadoop.security.authorize.AuthorizationException: java.security.AccessControlException: access denied ConnectionPermission(org.apache.hadoop.security.authorize.RefreshAuthorizationPolicyProtocol)
** Consistent failing tests:
*** TestServiceLevelAuthorization - testRefresh

* Timeout:
** Consistent failing tests:
*** TestCLI - testAll
*** TestDiskError - testShutdown
** Sporadically failing tests:
*** TestDatanodeDeath - testSimple0","28/Jan/09 16:59;rangadi;Ramya, did you use the patch I attached? ","29/Jan/09 08:45;rramya;bq. Ramya, did you use the patch I attached?
No I have not tested with the patch. The above observations were without the patch. 
I shall re-run the tests with the patch and update the issue.","30/Jan/09 01:48;rangadi;
Thanks.

TestDiskError still fails on windows. I think for the same reason as TestLocalDirAllocator (HADOOP-2023) and should be disabled, probably in a separate jira.","30/Jan/09 04:21;rramya;I ran all the tests after applying the patch. The number of failing tests has reduced drastically. But a few tests still continue to fail.
Below is the list of failing tests after applying the patch. I have attached logs as well for some of the failing tests:

* org.apache.hadoop.fs.TestTrash.testTrash, org.apache.hadoop.fs.TestTrash.testNonDefaultFS
Output:
2009-01-29 15:01:20,243 WARN  fs.Trash (Trash.java:moveToTrash(125)) - Can't create trash directory: file :/$HADOOP_HOME/build/test/data/testTrash/.Trash/Current/$HADOOP_HOME/build/test/data/testTrash/test/mkdirs
Deleted file :/$HADOOP_HOME/build/test/data/testTrash/test/mkdirs/myFile
2009-01-29 15:01:20,399 WARN  fs.Trash (Trash.java:moveToTrash(125)) - Can't create trash directory: file :/$HADOOP_HOME/build/test/data/testTrash/.Trash/Current/$HADOOP_HOME/build/test/data/testTrash

* org.apache.hadoop.hdfs.TestDFSRollback.testRollback 
Stacktrace:
java.io.IOException: Cannot lock storage $HADOOP_HOME\build\test\data\name1. The directory is already locked.

* org.apache.hadoop.hdfs.TestHDFSTrash.testNonDefaultFS - logs attached

* org.apache.hadoop.mapred.TestJobInProgress.testRunningTaskCount 
Stacktrace:
java.lang.IllegalArgumentException: Pathname /$HADOOP_HOME/build/test/data/jip-testing from $HADOOP_HOME/build/test/data/jip-testing is not a valid DFS filename.

* org.apache.hadoop.cli.TestCLI.testAll - log attached

* org.apache.hadoop.hdfs.TestHDFSServerPorts.testNameNodePorts, org.apache.hadoop.hdfs.TestHDFSServerPorts.testDataNodePorts, org.apache.hadoop.hdfs.TestHDFSServerPorts.testSecondaryNodePorts - log attached

* org.apache.hadoop.mapred.TestJobQueueInformation.testJobQueues 
Stacktrace:
java.lang.IllegalArgumentException: Pathname /$HADOOP_HOME/build/test/data/job-queue-info-testing/share from $HADOOP_HOME/build/test/data/job-queue-info-testing/share is not a valid DFS filename.

* org.apache.hadoop.mapred.TestMRServerPorts.testJobTrackerPorts, org.apache.hadoop.mapred.TestMRServerPorts.testTaskTrackerPorts - log attached

* org.apache.hadoop.mapred.TestMiniMRDFSCaching.testWithDFS - log attached
Stacktrace:
junit.framework.AssertionFailedError: Archives not matching at org.apache.hadoop.mapred.TestMiniMRDFSCaching.testWithDFS(TestMiniMRDFSCaching.java:60)

* org.apache.hadoop.mapred.TestMiniMRLocalFS.testWithLocal - log attached
Stacktrace:
java.io.IOException: Job failed!

* org.apache.hadoop.mapreduce.TestMapReduceLocal.testWithLocal 
Stacktrace:
org.apache.hadoop.mapred.FileAlreadyExistsException: Output directory $HADOOP_HOME/build/test/data/out already exists

* org.apache.hadoop.security.authorize.TestServiceLevelAuthorization.testRefresh
Stacktrace:
org.apache.hadoop.ipc.RemoteException: org.apache.hadoop.security.authorize.AuthorizationException: java.security.AccessControlException: access denied ConnectionPermission(org.apache.hadoop.security.authorize.RefreshAuthorizationPolicyProtocol)
","30/Jan/09 04:26;rramya;I have zipped all the logs and attached it. Sorry, could not find a better way to do it.","30/Jan/09 23:00;rangadi;bq. I still want to check why exactly is the timeout for accept() required.

It looks like the timeout for accept is not required (tested on Linux). The problem was that offerService() thread waits on DataXCeiver thread before calling shutdown. We should just move the 'join' into shutdown().

will check the simple fix on Windows. Note that TestDiskError fails anyway later (for a different reason, HADOOP-2023), but I just want to make sure that DataNode actually exits in case of real error.","31/Jan/09 01:52;rangadi;Simpler patch is attached. It does the the following :

  # Removes the need to for timeout for accept. Just moves the waiting for DataXceiver thread into shutdown()
      ** Also removes the config variable for the timeout.
      ** This does not introduce {{thread.interrupt()}}. It was already there.
  # Disables {{TestDiskError.testShutdown()}} on windows since setting a directory to read only does not prohibit file creation (as the test requires).
     ** This is similar to HADOOP-2023
      ** Though the test is disabled, I made sure that 'shutdown()' actually works as expected on windows.
 
My proposal for this Jira :
   * Attached patch fixes the cause for bulk of the tests failing on Windows
   * If the patch looks fine, we can go ahead and commit it.
   * For rest of the failures, we can file separate jira(s) as appropriate.

I have not yet looked into the other test failures that Ramya reported.

Btw, the earlier patch that implements a timeout for accept() could be useful in future.
","03/Feb/09 19:30;hairong;+1. This fix looks good to me. Thanks Raghu for taking care of this jira.

One related issue. DataXceiverServer#kill() closes all currently opened sockets recorded in childSockets. But newly accepted sockets never get added to childSockets. Should we worry about it?","03/Feb/09 19:51;rangadi;Thanks Hairong.

Good point regd {{childSockets}}. It does not look like any socket is actually placed in the list. It might have never worked as intended even for normal sockets. It probably needs a separate jira.","03/Feb/09 20:13;hairong;> It probably needs a separate jira.
Created a jira at HADOOP-5161.","03/Feb/09 23:29;rangadi;attached patch for 0.18 branch.
reattached earlier trunk patch for Hudson.","04/Feb/09 06:45;hadoopqa;-1 overall.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12399406/HADOOP-5114.patch
  against trunk revision 740532.

    +1 @author.  The patch does not contain any @author tags.

    +1 tests included.  The patch appears to include 3 new or modified tests.

    +1 javadoc.  The javadoc tool did not generate any warning messages.

    +1 javac.  The applied patch does not increase the total number of javac compiler warnings.

    -1 findbugs.  The patch appears to introduce 1 new Findbugs warnings.

    +1 Eclipse classpath. The patch retains Eclipse classpath integrity.

    +1 release audit.  The applied patch does not increase the total number of release audit warnings.

    -1 core tests.  The patch failed core unit tests.

    -1 contrib tests.  The patch failed contrib unit tests.

Test results: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch/3794/testReport/
Findbugs warnings: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch/3794/artifact/trunk/build/test/findbugs/newPatchFindbugsWarnings.html
Checkstyle results: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch/3794/artifact/trunk/build/test/checkstyle-errors.html
Console output: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch/3794/console

This message is automatically generated.","04/Feb/09 20:16;rangadi;Updated patch fixes the find bugs warning (same change fixes TestHDFSServerPorts as well).

Regd the test failures in Hudson : 
 - {{TestHDFSServerPorts.testDataNodePorts}} : fixed
 - {{TestAgentConfig.testInitAdaptors_vs_Checkpoint} : failed for multiple patches. Needs a jira.
 - {{TestDFSStartupVersions.testVersions}} : seems unrelated and can not reproduce. will check more.
 
Local test-patch run : {noformat} ","05/Feb/09 04:22;hadoopqa;-1 overall.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12399480/HADOOP-5114.patch
  against trunk revision 740532.

    +1 @author.  The patch does not contain any @author tags.

    +1 tests included.  The patch appears to include 3 new or modified tests.

    +1 javadoc.  The javadoc tool did not generate any warning messages.

    +1 javac.  The applied patch does not increase the total number of javac compiler warnings.

    +1 findbugs.  The patch does not introduce any new Findbugs warnings.

    +1 Eclipse classpath. The patch retains Eclipse classpath integrity.

    +1 release audit.  The applied patch does not increase the total number of release audit warnings.

    +1 core tests.  The patch passed core unit tests.

    -1 contrib tests.  The patch failed contrib unit tests.

Test results: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch/3799/testReport/
Findbugs warnings: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch/3799/artifact/trunk/build/test/findbugs/newPatchFindbugsWarnings.html
Checkstyle results: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch/3799/artifact/trunk/build/test/checkstyle-errors.html
Console output: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch/3799/console

This message is automatically generated.","05/Feb/09 09:04;rramya;I still can see TestOverReplicatedBlocks.testProcesOverReplicateBlock failing due to assertion failure on Windows on 18 branch. Attaching the log.","06/Feb/09 01:01;rangadi;
Thanks Ramya. The latest patch fixes TestOverReplicatedBlock.java. This test was added recently by HADOOP-4910. 


","06/Feb/09 01:10;hadoopqa;-1 overall.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12399537/TEST-org.apache.hadoop.dfs.TestOverReplicatedBlocks.txt
  against trunk revision 741330.

    +1 @author.  The patch does not contain any @author tags.

    -1 tests included.  The patch doesn't appear to include any new or modified tests.
                        Please justify why no tests are needed for this patch.

    -1 patch.  The patch command could not apply the patch.

Console output: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch/3803/console

This message is automatically generated.","06/Feb/09 05:26;hadoopqa;+1 overall.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12399609/HADOOP-5114.patch
  against trunk revision 741330.

    +1 @author.  The patch does not contain any @author tags.

    +1 tests included.  The patch appears to include 9 new or modified tests.

    +1 javadoc.  The javadoc tool did not generate any warning messages.

    +1 javac.  The applied patch does not increase the total number of javac compiler warnings.

    +1 findbugs.  The patch does not introduce any new Findbugs warnings.

    +1 Eclipse classpath. The patch retains Eclipse classpath integrity.

    +1 release audit.  The applied patch does not increase the total number of release audit warnings.

    +1 core tests.  The patch passed core unit tests.

    +1 contrib tests.  The patch passed contrib unit tests.

Test results: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch/3804/testReport/
Findbugs warnings: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch/3804/artifact/trunk/build/test/findbugs/newPatchFindbugsWarnings.html
Checkstyle results: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch/3804/artifact/trunk/build/test/checkstyle-errors.html
Console output: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch/3804/console

This message is automatically generated.","06/Feb/09 20:31;rangadi;I just committed this to 0.18 and up.

I ran test-core on 0.18 on windows. Two of the tests failed, but re running those succeeded again. We can file more jiras if there more failures.","08/Feb/09 13:51;rramya;bq. I ran test-core on 0.18 on windows. Two of the tests failed, but re running those succeeded again. 
I observed the same behavior as well on 18 branch. However when I ran test-core on trunk, I was able to see > 70 test failures out of which > 50 were mapred unit test failures. Shall I open a new jira?","09/Feb/09 01:22;rangadi;> Shall I open a new jira?

Yes, please. I will take a look at them as well. ","09/Feb/09 06:39;rramya;Thanks Raghu. Created HADOOP-5197 for a related issue.","16/Feb/09 17:00;hudson;Integrated in Hadoop-trunk #756 (See [http://hudson.zones.apache.org/hudson/job/Hadoop-trunk/756/])
    ",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
MRPerf simulator ,HADOOP-6118,12429077,Test,Resolved,HADOOP,Hadoop Common,software,omalley,Hadoop Common is the common library for Apache Hadoop.,http://hadoop.apache.org/,Minor,Invalid,,anjali,anjali,29/Jun/09 10:41,30/Jun/09 16:55,12/Jan/21 11:55,29/Jun/09 18:16,,,,,,,,,,,,,,,0,,,I understand that a mapreduce simulator MRPerf is available. Is it available for free? ,,aaa,arun_kumar,garymurry,hammer,jaideep,WHAA,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,2009-06-29 18:16:53.289,,,false,,,,,,,,,,,,,,,,,127137,,,,,Tue Jun 30 16:55:14 UTC 2009,,,,,,,"0|i0i1xb:",103406,,,,,,,,,,,,,,,,,,,,,,,"29/Jun/09 18:16;cdouglas;This is not the appropriate place for that question. Please ask on the dev or user list.","30/Jun/09 16:55;anjali;sorry.. and thank you for the reference. ",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Tests for NameNode -checkpoint option with different configurations ,HADOOP-4728,12409227,Test,Closed,HADOOP,Hadoop Common,software,omalley,Hadoop Common is the common library for Apache Hadoop.,http://hadoop.apache.org/,Minor,Fixed,boryas,boryas,boryas,25/Nov/08 23:51,23/Apr/09 19:17,12/Jan/21 11:55,12/Dec/08 01:02,0.20.0,,,,0.20.0,,,,,,,,,,0,,,"here are the tests:

id               :   secnn-4
Desc         :   Start SecondaryNameNode first before starting NameNode  	 
Expected 
results      :    Secondary namenode should fail to start

---------------------------------
id               :  secnn-6
Desc         :  Configure NameNode with dfs.name.dir and dfs.name.edits.dir pointing to different directories. Make sure the directories are empty.
                     Use default configuration for fs.checkpoint.dir and fs.checkpoint.edits.dir pointing to same directory.
                     Start NameNode using -importCheckpoint.
Expected
results      : 	Name-node should import image and edits into different directories. 

---------------------------------
id               :  secnn-7  	
Desc         :  Start NameNode.
                      Configure SecondaryNameNode with fs.checkpoint.dir and fs.checkpoint.edits.dir pointing to different directories.
                      Start SecondaryNameNode. 	
Expected
results       :  Secondary name-node should download edits and create the image in different directories. 
----------------------------

id                :  secnn-8
Desc          : Configure NameNode with dfs.name.dir and dfs.name.edits.dir pointing to different directories. Make sure the directories are empty.
                      Configure fs.checkpoint.dir and fs.checkpoint.edits.dir pointing to different (same as in secnn-7) directories.
                      Start NameNode using -importCheckpoint. 	
Expected
Results      : Name-node should import image and edits into different directories. ",,cdouglas,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"02/Dec/08 18:44;boryas;HADOOP-4728-1.patch;https://issues.apache.org/jira/secure/attachment/12395111/HADOOP-4728-1.patch","04/Dec/08 22:16;boryas;HADOOP-4728-2.patch;https://issues.apache.org/jira/secure/attachment/12395338/HADOOP-4728-2.patch","05/Dec/08 23:17;boryas;HADOOP-4728-3.patch;https://issues.apache.org/jira/secure/attachment/12395459/HADOOP-4728-3.patch","10/Dec/08 01:20;boryas;HADOOP-4728-4.patch;https://issues.apache.org/jira/secure/attachment/12395705/HADOOP-4728-4.patch","26/Nov/08 00:12;boryas;HADOOP-4728.patch;https://issues.apache.org/jira/secure/attachment/12394707/HADOOP-4728.patch",,,,,,,,,,,,,,,,,,,5.0,,,,,,,,,,,,,,,,,,,,2008-11-27 00:09:08.814,,,false,,,,,,,,,,,,,,,,,126696,Reviewed,,,,Fri Dec 12 01:02:52 UTC 2008,,,,,,,"0|i0i6iv:",104151,,,,,,,,,,,,,,,,,,,,,,,"27/Nov/08 00:09;cdouglas;Minor:
* Please use 2 spaces instead of tabs
* Commented-out code should be removed
* Can setUpConfig be part of TestCase::setUp?
* Instead of {{assertTrue(false)}}, this can just call {{fail(String)}}. It would be helpful to record the exception, too (StringUtils::stringifyException). {{assertEquals(a, b)}} instead of {{assertTrue(a == b)}} is also preferred
* Where iterating with FSImage::DirIterator (testSNNStartup, and checkNameNodeFiles, which should also be merged), the NameNodeDirType is mutually exclusive. It should probably use a switch, and define whether it's valid to find types other than {{IMAGE}} and {{EDITS}}
* startSecondaryNamenode and the asserts following it are unnecessary. Excluding the log message, it's equivalent to create it inline, as the exception is rethrown. At least one and probably both startNameNode methods are similarly unnecessary.

Tests:
* In testSNNwithoutNN, the test will pass if the secondary namenode fails to start because of a BindException. Shouldn't the logic in canStartSecondaryNode be moved into its caller, and the test fail for a BindException? The test has not validated what it claims to
* baseDir should default to /tmp instead of dfs/data
* The test(s) should clean up when finished.","02/Dec/08 18:47;boryas;implemented changes suggested by Chris 
Bind exception means that probably another SNN is running - which is a test error .","04/Dec/08 01:00;cdouglas;According to [this|http://wiki.apache.org/hadoop/CodeReviewChecklist], servers should not be directly instantiated. Is it possible to implement these tests using MiniDFSCluster? Sorry for missing this in the original review.","04/Dec/08 22:17;boryas;well, I've changed to MiniDFSCluster, but that required some changes in the MiniDFSCluster class itself because it wasn't handling StartupOptions correctly. Please review both.

","07/Dec/08 22:55;cdouglas;The new unit test runs until it times out and fails on Linux. On the Mac, the test passes because it relies on a BindException (wrapped in an IOException, so it bypasses the BindException handler) to terminate.

* ?
{noformat}
+    // do not remove code
+    //FileSystem.setDefaultUri(config, ""hdfs://""+NAME_NODE_HOST + ""0"");
+    //config.set(""dfs.http.address"", NAME_NODE_HTTP_HOST + ""0"");
{noformat}
* In checkNameNodeFiles, the MiniDFSCluster should be shut down in a finally block.","10/Dec/08 01:23;boryas;some cleanup
removed testSNNwoNN test, because currently system is not working as required by the test.
Will introduce the test again when the feature is implemented.","12/Dec/08 00:14;hadoopqa;-1 overall.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12395705/HADOOP-4728-4.patch
  against trunk revision 725729.

    +1 @author.  The patch does not contain any @author tags.

    +1 tests included.  The patch appears to include 6 new or modified tests.

    +1 javadoc.  The javadoc tool did not generate any warning messages.

    +1 javac.  The applied patch does not increase the total number of javac compiler warnings.

    +1 findbugs.  The patch does not introduce any new Findbugs warnings.

    +1 Eclipse classpath. The patch retains Eclipse classpath integrity.

    -1 core tests.  The patch failed core unit tests.

    +1 contrib tests.  The patch passed contrib unit tests.

Test results: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch/3712/testReport/
Findbugs warnings: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch/3712/artifact/trunk/build/test/findbugs/newPatchFindbugsWarnings.html
Checkstyle results: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch/3712/artifact/trunk/build/test/checkstyle-errors.html
Console output: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch/3712/console

This message is automatically generated.","12/Dec/08 01:02;cdouglas;+1 Looks good

I just committed this. Thanks, Boris",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
findbugs should run over the tools.jar also,HADOOP-4259,12405047,Test,Closed,HADOOP,Hadoop Common,software,omalley,Hadoop Common is the common library for Apache Hadoop.,http://hadoop.apache.org/,Minor,Fixed,cdouglas,omalley,omalley,24/Sep/08 05:05,20/Nov/08 23:38,12/Jan/21 11:55,26/Sep/08 17:49,0.18.0,,,,0.19.0,,,,,,test,,,,0,,,"Currently the findbugs target doesn't include the tools.jar, as I discovered when I moved a class from tools.jar to hadoop.jar and got hit by a findbugs warning.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"24/Sep/08 18:41;cdouglas;4259-0.patch;https://issues.apache.org/jira/secure/attachment/12390862/4259-0.patch",,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,2008-09-24 18:41:30.495,,,false,,,,,,,,,,,,,,,,,126424,Reviewed,,,,Sat Sep 27 13:22:39 UTC 2008,,,,,,,"0|i0i8cn:",104447,,,,,,,,,,,,,,,,,,,,,,,"24/Sep/08 18:41;cdouglas;Picks up the dead store in InputSampler fixed in HADOOP-4247.","24/Sep/08 23:05;hadoopqa;-1 overall.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12390862/4259-0.patch
  against trunk revision 698721.

    +1 @author.  The patch does not contain any @author tags.

    -1 tests included.  The patch doesn't appear to include any new or modified tests.
                        Please justify why no tests are needed for this patch.

    +1 javadoc.  The javadoc tool did not generate any warning messages.

    +1 javac.  The applied patch does not increase the total number of javac compiler warnings.

    -1 findbugs.  The patch appears to introduce 1 new Findbugs warnings.

    +1 Eclipse classpath. The patch retains Eclipse classpath integrity.

    -1 core tests.  The patch failed core unit tests.

    +1 contrib tests.  The patch passed contrib unit tests.

Test results: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch/3364/testReport/
Findbugs warnings: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch/3364/artifact/trunk/build/test/findbugs/newPatchFindbugsWarnings.html
Checkstyle results: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch/3364/artifact/trunk/build/test/checkstyle-errors.html
Console output: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch/3364/console

This message is automatically generated.","26/Sep/08 17:49;omalley;I just committed this. Thanks, Chris!","27/Sep/08 13:22;hudson;Integrated in Hadoop-trunk #616 (See [http://hudson.zones.apache.org/hudson/job/Hadoop-trunk/616/])",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
TestKosmosFileSystem can fail when run through ant test on systems shared by users,HADOOP-4069,12403688,Test,Closed,HADOOP,Hadoop Common,software,omalley,Hadoop Common is the common library for Apache Hadoop.,http://hadoop.apache.org/,Minor,Fixed,lohit,yhemanth,yhemanth,04/Sep/08 16:21,20/Nov/08 23:38,12/Jan/21 11:55,04/Sep/08 22:42,,,,,0.19.0,,,,,,fs,,,,0,,,"TestKosmosFileSystem has some test cases that try to verify paths under /tmp/test/. If a user is running ant test on a system that is shared, this could result in test failures if these paths are created by another user who has used the system. The test cases can be modified to either use one of the standard data directories set up for tests by Hadoop, or they can atleast append the user name when referring to these directories, like /tmp/test-<username>/. ",,omalley,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"04/Sep/08 18:53;lohit;HADOOP-4069.patch;https://issues.apache.org/jira/secure/attachment/12389534/HADOOP-4069.patch",,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,2008-09-04 18:53:00.149,,,false,,,,,,,,,,,,,,,,,19121,Reviewed,,,,Sat Sep 06 13:23:49 UTC 2008,,,,,,,"0|i0i96f:",104581,,,,,,,,,,,,,,,,,,,,,,,"04/Sep/08 18:53;lohit;Like other test cases, it would be good to create baseDir derived from test.build.data. Attached is simple fix to the test case. I no longer see /tmp/test after running this test.","04/Sep/08 22:26;omalley;+1 for keeping all of the temporary files under test.build.data.","04/Sep/08 22:42;omalley;I just committed this. Thanks, Lohit!","06/Sep/08 13:23;hudson;Integrated in Hadoop-trunk #595 (See [http://hudson.zones.apache.org/hudson/job/Hadoop-trunk/595/])",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Place the new findbugs warnings introduced by the patch in the /tmp directory when ""ant test-patch"" is run.",HADOOP-3966,12402524,Test,Closed,HADOOP,Hadoop Common,software,omalley,Hadoop Common is the common library for Apache Hadoop.,http://hadoop.apache.org/,Minor,Fixed,rramya,rramya,rramya,17/Aug/08 14:58,20/Nov/08 23:38,12/Jan/21 11:55,28/Aug/08 06:52,0.18.0,,,,0.19.0,,,,,,test,,,,0,,,"New findbugs warnings introduced by the patch should be made available in the PATCH_DIR(i.e /tmp) when ""ant test-patch"" is run. It should be available in both .html and .xml format.


",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"17/Aug/08 15:05;rramya;test-patch0.txt;https://issues.apache.org/jira/secure/attachment/12388386/test-patch0.txt",,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,2008-08-19 00:50:03.944,,,false,,,,,,,,,,,,,,,,,126255,Reviewed,,,,Thu Aug 28 06:52:22 UTC 2008,,,,,,,"0|i0i9jb:",104639,,,,,,,,,,,,,,,,,,,,,,,"19/Aug/08 00:50;cdouglas;bq. It should be available in both .html and .xml format

Is this a change to Hudson? For developers running test-patch locally, this seems unnecessary.","19/Aug/08 03:22;nidaley;1 correction: although customizable, I believe PATCH_DIR defaults to ~/tmp.

Chris, are you wondering why we're providing the findbugs xml file given you probably just want the html file?  The xml file is useful if you want to load it into the findbugs application and be able to click thru to the src code.","19/Aug/08 03:23;nidaley;+1 on code review.","19/Aug/08 08:57;hadoopqa;-1 overall.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12388386/test-patch0.txt
  against trunk revision 686893.

    +1 @author.  The patch does not contain any @author tags.

    +1 tests included.  The patch appears to include 7 new or modified tests.

    -1 javadoc.  The javadoc tool appears to have generated 1 warning messages.

    +1 javac.  The applied patch does not increase the total number of javac compiler warnings.

    +1 findbugs.  The patch does not introduce any new Findbugs warnings.

    +1 release audit.  The applied patch does not increase the total number of release audit warnings.

    -1 core tests.  The patch failed core unit tests.

    -1 contrib tests.  The patch failed contrib unit tests.

Test results: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch/3072/testReport/
Findbugs warnings: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch/3072/artifact/trunk/build/test/findbugs/newPatchFindbugsWarnings.html
Checkstyle results: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch/3072/artifact/trunk/build/test/checkstyle-errors.html
Console output: http://hudson.zones.apache.org/hudson/job/Hadoop-Patch/3072/console

This message is automatically generated.","19/Aug/08 16:04;cdouglas;bq. Chris, are you wondering why we're providing the findbugs xml file given you probably just want the html file? The xml file is useful if you want to load it into the findbugs application and be able to click thru to the src code.

No, I'm not clear on why one wants a copy in the temp directory in addition to the build directory, which is why I asked if it has something to do with Hudson","20/Aug/08 00:51;nidaley;{quote}
No, I'm not clear on why one wants a copy in the temp directory in addition to the build directory, which is why I asked if it has something to do with Hudson
{quote}

Oh, it simply so that developers can more easily find the file.  We've had a number of complaints that folks want to see the findbugs warning diffs but don't know where to look.  Putting them in PATCH_DIR puts them in with the other results from other tools.  Let me know if you see a better solution.","20/Aug/08 01:10;szetszwo;Is newPatchFindbugsWarnings.html the html file mentioned here?  If yes, it is very useful.

I always diff the xml files manually and try to understand the xml findbugs warnings, which is not quite convenient.","20/Aug/08 03:18;rramya;Yes it is the newPatchFindbugsWarnings.html and the
newPatchFindbugsWarnings.xml file which we want to place in the ~/tmp
directory to help the developers easily find the file and to identify
the new findbugs warnings introduced by their patch.

","28/Aug/08 06:52;lohit;I just committed this. Thanks Ramya!
PS : I am trying to assign this issue to you, but unable to find your name in the drop down box.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Hudson should also count javac warnings generated by test code,HADOOP-3330,12395110,Test,Closed,HADOOP,Hadoop Common,software,omalley,Hadoop Common is the common library for Apache Hadoop.,http://hadoop.apache.org/,Minor,Duplicate,,cdouglas,cdouglas,30/Apr/08 22:37,09/May/08 22:40,12/Jan/21 11:55,02/May/08 01:12,,,,,,,,,,,build,test,,,0,,,"Hudson should \-1 patches that add javac warnings in test code, as it does with code in core and contrib.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,125897,,,,,Fri May 02 01:12:03 UTC 2008,,,,,,,"0|i0icf3:",105106,,,,,,,,,,,,,,,,,,,,,,,"02/May/08 01:12;cdouglas;Duplicate of HADOOP-3037",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
add a switch to allow unit tests to show output,HADOOP-548,12350268,Test,Closed,HADOOP,Hadoop Common,software,omalley,Hadoop Common is the common library for Apache Hadoop.,http://hadoop.apache.org/,Minor,Fixed,omalley,omalley,omalley,19/Sep/06 17:19,06/Oct/06 21:49,12/Jan/21 11:55,20/Sep/06 20:34,0.6.2,,,,0.7.0,,,,,,,,,,0,,,"I'd like a switch so that I can have the unit tests show their output to the console.

ant test   // current behavior
ant -Dtest.output=yes  test // show output to console",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"19/Sep/06 17:20;omalley;test-output.patch;https://issues.apache.org/jira/secure/attachment/12341137/test-output.patch",,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,2006-09-20 20:34:15.0,,,false,,,,,,,,,,,,,,,,,124861,,,,,Wed Sep 20 20:34:15 UTC 2006,,,,,,,"0|i0inxb:",106970,,,,,,,,,,,,,,,,,,,,,,,"20/Sep/06 20:34;cutting;I just committed this.  Thanks, Owen!",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
hadoop nightly build and regression test on a cluster,HADOOP-184,12332975,Test,Closed,HADOOP,Hadoop Common,software,omalley,Hadoop Common is the common library for Apache Hadoop.,http://hadoop.apache.org/,Minor,Fixed,mahadev,mahadev,mahadev,02/May/06 04:38,03/Aug/06 17:46,12/Jan/21 11:55,03/May/06 06:12,,,,,0.2.0,,,,,,,,,,0,,,create a jar file for the tests and have  filesystem and mapreduce tests on the cluster,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"04/May/06 07:38;mahadev;build.patch;https://issues.apache.org/jira/secure/attachment/12326224/build.patch","03/May/06 05:11;mahadev;nightly_build.patch;https://issues.apache.org/jira/secure/attachment/12326185/nightly_build.patch","02/May/06 04:45;mahadev;nightly_build.patch;https://issues.apache.org/jira/secure/attachment/12326113/nightly_build.patch",,,,,,,,,,,,,,,,,,,,,3.0,,,,,,,,,,,,,,,,,,,,2006-05-03 03:02:39.0,,,false,,,,,,,,,,,,,,,,,124678,,,,,Thu May 04 08:46:27 UTC 2006,,,,,,,"0|i0ipwf:",107290,,,,,,,,,,,,,,,,,,,,,,,"02/May/06 04:45;mahadev;filtered out owen's code for Example Driver to util ProgramDriver.java. Now both the AlltestDriver.java and ExampleDriver.java use this class. Changed the build file to generate a jar file for the test's as well. Changed the MapredLoadTest.java to make it a junit test and run it on a cluster as well.
So the tests can be run as 
bin/hadoop jar hadoop-0.2-test.jar  mapredtest args
bin/hadoop jar hadoop-0.2-test.jar testfilesystem args
on a cluster.","03/May/06 03:02;cutting;I'm having trouble applying this patch:

% patch -p 0 < ~/Desktop/nightly_build.patch patching file src/test/org/apache/hadoop/test/AllTestDriver.java patching file src/test/org/apache/hadoop/fs/TestFileSystem.java
patching file src/test/org/apache/hadoop/mapred/TestMapRed.java
patching file src/java/org/apache/hadoop/util/ProgramDriver.java
patching file src/examples/org/apache/hadoop/examples/ExampleDriver.java
patch: **** malformed patch at line 810: Index: build.xml
","03/May/06 05:11;mahadev;attaching the updated patch. should work now..
","03/May/06 06:12;cutting;I just committed this.  Thanks, Mahadev.","04/May/06 07:38;mahadev;My patch broke ant package.. It did not do a compile-test before. It does it now. The hadoop-test.jar is made available with the package now.","04/May/06 08:46;cutting;Thanks.  I committed this.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Reduce the execution time of the TestRolloverSignerSecretProvider,HADOOP-16931,13293093,Test,Patch Available,HADOOP,Hadoop Common,software,omalley,Hadoop Common is the common library for Apache Hadoop.,http://hadoop.apache.org/,Trivial,,esa.hekmat,esa.hekmat,esa.hekmat,21/Mar/20 11:49,10/Jun/20 13:14,12/Jan/21 11:55,,,,,,,,,,,,common,,,,0,,,"In my Laptop it takes 52Second, I found out that the last Thread.sleep is redundant and could be removed. Also, we can reduce its execution time by decreasing ""rolloverFrequency"" without any problem","Archlinux, Intel core i7",elgoiri,esa.hekmat,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,9223372036854775807,,,,,Wed Jun 10 07:03:59 UTC 2020,,,,,,,"0|z0crm8:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,"10/Jun/20 07:03;esa.hekmat;I think status should be changed to Pull Request available, also It's not a big PR to review and I will appreciate it if someone takes a look at it.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Many misusages of assertEquals(expected, actual)",HADOOP-12693,12928240,Test,Open,HADOOP,Hadoop Common,software,omalley,Hadoop Common is the common library for Apache Hadoop.,http://hadoop.apache.org/,Trivial,,,suda,suda,07/Jan/16 05:45,04/Nov/19 17:31,12/Jan/21 11:55,,,,,,,,,,,,,,,,0,,,"The first arg of {{org.JUnit.Assert.assertEquals()}} should be an {{expected}} value, and the second one should be an {{actual}} value.

{code}
void assertEquals(T expected, T actual);
{code}

http://junit.org/apidocs/org/junit/Assert.html#assertEquals(java.lang.Object, java.lang.Object)

However, there are so many violations in Hadoop, which can make a misleading message like this:
{code}
AssertionError: expected:<actual> but was:<expected>
{code}.

Please refer to {{just-rough-approx.txt}}.
",,aajisaka,adam.antal,drankye,lewuathe,stevel@apache.org,suda,templedf,,,,,,,,,,,,,,,,,,,,,,,,,,,,,HDFS-14897,,,,,,,,,,,,,,,YARN-4543,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"07/Jan/16 05:46;suda;just-rough-approx.txt;https://issues.apache.org/jira/secure/attachment/12780906/just-rough-approx.txt",,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,2016-01-07 06:30:48.954,,,false,,,,,,,,,,,,,,,,,9223372036854775807,,,,,Mon Nov 04 17:31:04 UTC 2019,,,,,,,"0|i2qyyn:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,"07/Jan/16 06:30;drankye;This can be corrected incrementally. For the long term, I would suggest we introduce [AssertJ|http://joel-costigliola.github.io/assertj/] for the new tests avoiding such mistakes.","07/Jan/16 06:41;suda;+1
","18/Apr/19 06:51;aajisaka;bq. I would suggest we introduce AssertJ for the new tests avoiding such mistakes.

Good news: AssertJ has been introduced in Apache Hadoop. YARN-9470 fixed the misusages by replacing the JUnit API with AssertJ.","18/Apr/19 13:59;adam.antal;Filed MAPREDUCE-7197 for creating a follow-up for the MR project.","12/Aug/19 12:25;adam.antal; MAPREDUCE-7197 got committed. Is there anything left for this issue?

I suggest to close this. Any objections?","12/Aug/19 16:23;templedf;Sounds like we're good for MR and YARN, but what about HADOOP and HDFS?","12/Aug/19 16:40;adam.antal;[~templedf] Oh indeed, I thought those were already done. 

As I checked some of the occurrences in the just-rough-approx.txt some of those entries are valid, and still present in hadoop-common, hadoop-hdfs and hadoop-tools projects. Filed HADOOP-16510, HADOOP-16511 and HADOOP-16512. Also collected them under this jira as sub-tasks for better trackability. Hope you don't mind.","04/Nov/19 17:31;adam.antal;Common, Yarn, MR and Tools have been cleaned up, waiting for the HDFS part of the job to finish.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
 Upgrade JUnit3 TestCase to JUnit 4 in org.apache.hadoop.io package,HADOOP-12564,12903404,Test,Resolved,HADOOP,Hadoop Common,software,omalley,Hadoop Common is the common library for Apache Hadoop.,http://hadoop.apache.org/,Trivial,Fixed,cotedm,cotedm,cotedm,08/Oct/15 16:07,25/Oct/19 20:26,12/Jan/21 11:55,18/Nov/15 16:40,,,,,2.8.0,3.0.0-alpha1,,,,,test,,,,0,,,Migrating just the io test cases ,,aajisaka,cotedm,hudson,junping_du,ozawa,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,MAPREDUCE-6050,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"21/Oct/15 20:54;cotedm;MAPREDUCE-6505-1.patch;https://issues.apache.org/jira/secure/attachment/12767873/MAPREDUCE-6505-1.patch","27/Oct/15 20:16;cotedm;MAPREDUCE-6505-2.patch;https://issues.apache.org/jira/secure/attachment/12769091/MAPREDUCE-6505-2.patch","10/Nov/15 21:24;cotedm;MAPREDUCE-6505-3.patch;https://issues.apache.org/jira/secure/attachment/12771632/MAPREDUCE-6505-3.patch","11/Nov/15 14:34;cotedm;MAPREDUCE-6505-4.patch;https://issues.apache.org/jira/secure/attachment/12771754/MAPREDUCE-6505-4.patch","11/Nov/15 17:10;cotedm;MAPREDUCE-6505-5.patch;https://issues.apache.org/jira/secure/attachment/12771793/MAPREDUCE-6505-5.patch","17/Nov/15 15:14;cotedm;MAPREDUCE-6505-6.patch;https://issues.apache.org/jira/secure/attachment/12772758/MAPREDUCE-6505-6.patch",,,,,,,,,,,,,,,,,,6.0,,,,,,,,,,,,,,,,,,,,2015-10-21 21:46:42.38,,,false,,,,,,,,,,,,,,,,,9223372036854775807,Reviewed,,,,Wed Nov 18 21:25:01 UTC 2015,,,,,,,"0|i2mrd3:",9223372036854775807,,,,,,,,,,,,,2.8.0,,,,,,,,,,"21/Oct/15 20:54;cotedm;Attaching migrations for io test cases.  ","21/Oct/15 21:46;hadoopqa;\\
\\
| (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | pre-patch |  10m  5s | Pre-patch trunk compilation is healthy. |
| {color:green}+1{color} | @author |   0m  0s | The patch does not contain any @author tags. |
| {color:green}+1{color} | tests included |   0m  0s | The patch appears to include 29 new or modified test files. |
| {color:green}+1{color} | javac |  10m 39s | There were no new javac warning messages. |
| {color:green}+1{color} | release audit |   0m 27s | The applied patch does not increase the total number of release audit warnings. |
| {color:green}+1{color} | checkstyle |   1m 37s | There were no new checkstyle issues. |
| {color:red}-1{color} | whitespace |   0m 23s | The patch has 7  line(s) that end in whitespace. Use git apply --whitespace=fix. |
| {color:green}+1{color} | install |   1m 58s | mvn install still works. |
| {color:green}+1{color} | eclipse:eclipse |   0m 43s | The patch built with eclipse:eclipse. |
| {color:green}+1{color} | findbugs |   2m 32s | The patch does not introduce any new Findbugs (version 3.0.0) warnings. |
| {color:red}-1{color} | common tests |   8m 19s | Tests failed in hadoop-common. |
| | |  36m 52s | |
\\
\\
|| Reason || Tests ||
| Failed unit tests | hadoop.ipc.TestDecayRpcScheduler |
|   | hadoop.fs.TestLocalFsFCStatistics |
\\
\\
|| Subsystem || Report/Notes ||
| Patch URL | http://issues.apache.org/jira/secure/attachment/12767873/MAPREDUCE-6505-1.patch |
| Optional Tests | javac unit findbugs checkstyle |
| git revision | trunk / 59ce780 |
| whitespace | https://builds.apache.org/job/PreCommit-MAPREDUCE-Build/6080/artifact/patchprocess/whitespace.txt |
| hadoop-common test log | https://builds.apache.org/job/PreCommit-MAPREDUCE-Build/6080/artifact/patchprocess/testrun_hadoop-common.txt |
| Test Results | https://builds.apache.org/job/PreCommit-MAPREDUCE-Build/6080/testReport/ |
| Java | 1.7.0_55 |
| uname | Linux asf907.gq1.ygridcore.net 3.13.0-36-lowlatency #63-Ubuntu SMP PREEMPT Wed Sep 3 21:56:12 UTC 2014 x86_64 x86_64 x86_64 GNU/Linux |
| Console output | https://builds.apache.org/job/PreCommit-MAPREDUCE-Build/6080/console |


This message was automatically generated.","27/Oct/15 20:16;cotedm;Submitting v2 of the patch that includes whitespace fixes.  The previous test failures are unrelated to this patch looks like.","28/Oct/15 01:33;hadoopqa;\\
\\
| (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | pre-patch |   7m 35s | Pre-patch trunk compilation is healthy. |
| {color:green}+1{color} | @author |   0m  0s | The patch does not contain any @author tags. |
| {color:green}+1{color} | tests included |   0m  0s | The patch appears to include 29 new or modified test files. |
| {color:green}+1{color} | javac |   9m 34s | There were no new javac warning messages. |
| {color:green}+1{color} | release audit |   0m 28s | The applied patch does not increase the total number of release audit warnings. |
| {color:green}+1{color} | checkstyle |   1m 23s | There were no new checkstyle issues. |
| {color:red}-1{color} | whitespace |   0m 20s | The patch has 2  line(s) that end in whitespace. Use git apply --whitespace=fix. |
| {color:green}+1{color} | install |   1m 53s | mvn install still works. |
| {color:green}+1{color} | eclipse:eclipse |   0m 39s | The patch built with eclipse:eclipse. |
| {color:green}+1{color} | findbugs |   2m 25s | The patch does not introduce any new Findbugs (version 3.0.0) warnings. |
| {color:green}+1{color} | common tests |   8m 29s | Tests passed in hadoop-common. |
| | |  32m 52s | |
\\
\\
|| Subsystem || Report/Notes ||
| Patch URL | http://issues.apache.org/jira/secure/attachment/12769091/MAPREDUCE-6505-2.patch |
| Optional Tests | javac unit findbugs checkstyle |
| git revision | trunk / 68ce93c |
| whitespace | https://builds.apache.org/job/PreCommit-MAPREDUCE-Build/6093/artifact/patchprocess/whitespace.txt |
| hadoop-common test log | https://builds.apache.org/job/PreCommit-MAPREDUCE-Build/6093/artifact/patchprocess/testrun_hadoop-common.txt |
| Test Results | https://builds.apache.org/job/PreCommit-MAPREDUCE-Build/6093/testReport/ |
| Java | 1.7.0_55 |
| uname | Linux asf905.gq1.ygridcore.net 3.13.0-36-lowlatency #63-Ubuntu SMP PREEMPT Wed Sep 3 21:56:12 UTC 2014 x86_64 x86_64 x86_64 GNU/Linux |
| Console output | https://builds.apache.org/job/PreCommit-MAPREDUCE-Build/6093/console |


This message was automatically generated.","10/Nov/15 21:24;cotedm;Version 3 of the patch has fixed the last two whitespace issues.  [~ozawa], can you help review and commit if it looks good?  Thanks!","10/Nov/15 23:09;hadoopqa;| (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue} 0m 8s {color} | {color:blue} docker + precommit patch detected. {color} |
| {color:green}+1{color} | {color:green} @author {color} | {color:green} 0m 0s {color} | {color:green} The patch does not contain any @author tags. {color} |
| {color:green}+1{color} | {color:green} test4tests {color} | {color:green} 0m 0s {color} | {color:green} The patch appears to include 29 new or modified test files. {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 3m 11s {color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 4m 20s {color} | {color:green} trunk passed with JDK v1.8.0_60 {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 4m 6s {color} | {color:green} trunk passed with JDK v1.7.0_79 {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green} 0m 15s {color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green} 0m 14s {color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green} 1m 38s {color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 0m 52s {color} | {color:green} trunk passed with JDK v1.8.0_60 {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 1m 3s {color} | {color:green} trunk passed with JDK v1.7.0_79 {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 1m 29s {color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 4m 21s {color} | {color:green} the patch passed with JDK v1.8.0_60 {color} |
| {color:green}+1{color} | {color:green} javac {color} | {color:green} 4m 21s {color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 4m 8s {color} | {color:green} the patch passed with JDK v1.7.0_79 {color} |
| {color:green}+1{color} | {color:green} javac {color} | {color:green} 4m 8s {color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green} 0m 14s {color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green} 0m 13s {color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} whitespace {color} | {color:green} 0m 0s {color} | {color:green} Patch has no whitespace issues. {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green} 1m 48s {color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 0m 52s {color} | {color:green} the patch passed with JDK v1.8.0_60 {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 1m 2s {color} | {color:green} the patch passed with JDK v1.7.0_79 {color} |
| {color:red}-1{color} | {color:red} unit {color} | {color:red} 16m 49s {color} | {color:red} hadoop-common in the patch failed with JDK v1.8.0_60. {color} |
| {color:green}+1{color} | {color:green} unit {color} | {color:green} 7m 59s {color} | {color:green} hadoop-common in the patch passed with JDK v1.7.0_79. {color} |
| {color:green}+1{color} | {color:green} asflicense {color} | {color:green} 0m 23s {color} | {color:green} Patch does not generate ASF License warnings. {color} |
| {color:black}{color} | {color:black} {color} | {color:black} 56m 11s {color} | {color:black} {color} |
\\
\\
|| Reason || Tests ||
| JDK v1.8.0_60 Timed out junit tests | org.apache.hadoop.http.TestHttpServerLifecycle |
\\
\\
|| Subsystem || Report/Notes ||
| Docker | Client=1.7.1 Server=1.7.1 Image:test-patch-base-hadoop-date2015-11-10 |
| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12771632/MAPREDUCE-6505-3.patch |
| JIRA Issue | MAPREDUCE-6505 |
| Optional Tests |  asflicense  javac  javadoc  mvninstall  unit  findbugs  checkstyle  compile  |
| uname | Linux dc8064605eea 3.13.0-36-lowlatency #63-Ubuntu SMP PREEMPT Wed Sep 3 21:56:12 UTC 2014 x86_64 x86_64 x86_64 GNU/Linux |
| Build tool | maven |
| Personality | /home/jenkins/jenkins-slave/workspace/PreCommit-MAPREDUCE-Build/patchprocess/apache-yetus-ee5baeb/precommit/personality/hadoop.sh |
| git revision | trunk / c99925d |
| Default Java | 1.7.0_79 |
| Multi-JDK versions |  /usr/lib/jvm/java-8-oracle:1.8.0_60 /usr/lib/jvm/java-7-openjdk-amd64:1.7.0_79 |
| findbugs | v3.0.0 |
| unit | https://builds.apache.org/job/PreCommit-MAPREDUCE-Build/6140/artifact/patchprocess/patch-unit-hadoop-common-project_hadoop-common-jdk1.8.0_60.txt |
| unit test logs |  https://builds.apache.org/job/PreCommit-MAPREDUCE-Build/6140/artifact/patchprocess/patch-unit-hadoop-common-project_hadoop-common-jdk1.8.0_60.txt |
| JDK v1.7.0_79  Test Results | https://builds.apache.org/job/PreCommit-MAPREDUCE-Build/6140/testReport/ |
| modules | C: hadoop-common-project/hadoop-common U: hadoop-common-project/hadoop-common |
| Max memory used | 226MB |
| Powered by | Apache Yetus   http://yetus.apache.org |
| Console output | https://builds.apache.org/job/PreCommit-MAPREDUCE-Build/6140/console |


This message was automatically generated.

","11/Nov/15 07:31;ozawa;[~cote] Sure, please wait a moment.","11/Nov/15 07:48;ozawa;[~cote] thank you for your patch. I glanced over your patch. Could you fix to import the static methods separately instead of using asterisk importing(about TestArrayFile)? 


{code}
+import static org.junit.Assert.*;
{code}","11/Nov/15 11:08;junping_du;I think this jira should be moved to hadoop project instead of mapreduce project as all changes happen in hadoop-common.","11/Nov/15 14:34;cotedm;[~ozawa] thanks for the quick response!  I've cleaned up the four files that had static imports for Assert.* and they are method-wise imports now.  Patch v4 shows this.  Please let me know if you see anything else amiss.  Thanks!","11/Nov/15 14:35;cotedm;[~junping_du], yep I'm fine if you want to move it to the HADOOP project.  This ended up being an MR task just because the parent was, but in retrospect I did breakout hadoop common tests when migrating these.  Feel free to move it if you want.  Thanks!","11/Nov/15 14:42;ozawa;Good catch, Junping. Moved this issue to hadoop-common.","11/Nov/15 14:54;ozawa;[~cote] Thank you for updating. The patch itself looks good to me overall. I grepped under test/java/org/apache/hadoop/io - it still remains usages of JUnit 3:

1. ./AvroTestUtil.java:import static junit.framework.TestCase.assertEquals;
2. ./compress/TestCodecFactory.java:public class TestCodecFactory extends TestCase {
3. ./compress/TestCompressionStreamReuse.java:public class TestCompressionStreamReuse extends TestCase {
4. ./file/tfile/TestVLong.java:import junit.framework.TestCase;

Could you update it again? Thanks!","11/Nov/15 14:57;cotedm;Aha, yep let me try to do that today.  I hadn't originally scoped these ones, but since we're here I might as well get those ones too.  I'll ping you again for your generous review once I get v5 of the patch ready to go :)","11/Nov/15 15:26;hadoopqa;| (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue} 0m 6s {color} | {color:blue} docker + precommit patch detected. {color} |
| {color:green}+1{color} | {color:green} @author {color} | {color:green} 0m 0s {color} | {color:green} The patch does not contain any @author tags. {color} |
| {color:green}+1{color} | {color:green} test4tests {color} | {color:green} 0m 0s {color} | {color:green} The patch appears to include 29 new or modified test files. {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 3m 6s {color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 4m 39s {color} | {color:green} trunk passed with JDK v1.8.0_60 {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 4m 26s {color} | {color:green} trunk passed with JDK v1.7.0_79 {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green} 0m 15s {color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green} 0m 15s {color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green} 1m 41s {color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 0m 59s {color} | {color:green} trunk passed with JDK v1.8.0_60 {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 1m 6s {color} | {color:green} trunk passed with JDK v1.7.0_79 {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 1m 33s {color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 4m 39s {color} | {color:green} the patch passed with JDK v1.8.0_60 {color} |
| {color:green}+1{color} | {color:green} javac {color} | {color:green} 4m 39s {color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 4m 30s {color} | {color:green} the patch passed with JDK v1.7.0_79 {color} |
| {color:green}+1{color} | {color:green} javac {color} | {color:green} 4m 30s {color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green} 0m 15s {color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green} 0m 14s {color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} whitespace {color} | {color:green} 0m 0s {color} | {color:green} Patch has no whitespace issues. {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green} 1m 55s {color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 1m 1s {color} | {color:green} the patch passed with JDK v1.8.0_60 {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 1m 9s {color} | {color:green} the patch passed with JDK v1.7.0_79 {color} |
| {color:red}-1{color} | {color:red} unit {color} | {color:red} 6m 57s {color} | {color:red} hadoop-common in the patch failed with JDK v1.8.0_60. {color} |
| {color:red}-1{color} | {color:red} unit {color} | {color:red} 7m 11s {color} | {color:red} hadoop-common in the patch failed with JDK v1.7.0_79. {color} |
| {color:green}+1{color} | {color:green} asflicense {color} | {color:green} 0m 24s {color} | {color:green} Patch does not generate ASF License warnings. {color} |
| {color:black}{color} | {color:black} {color} | {color:black} 47m 32s {color} | {color:black} {color} |
\\
\\
|| Reason || Tests ||
| JDK v1.8.0_60 Failed junit tests | hadoop.ipc.TestIPC |
|   | hadoop.net.TestClusterTopology |
| JDK v1.7.0_79 Failed junit tests | hadoop.security.ssl.TestReloadingX509TrustManager |
\\
\\
|| Subsystem || Report/Notes ||
| Docker | Client=1.7.1 Server=1.7.1 Image:test-patch-base-hadoop-date2015-11-11 |
| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12771754/MAPREDUCE-6505-4.patch |
| JIRA Issue | MAPREDUCE-6505 |
| Optional Tests |  asflicense  javac  javadoc  mvninstall  unit  findbugs  checkstyle  compile  |
| uname | Linux 83195db8bc24 3.13.0-36-lowlatency #63-Ubuntu SMP PREEMPT Wed Sep 3 21:56:12 UTC 2014 x86_64 x86_64 x86_64 GNU/Linux |
| Build tool | maven |
| Personality | /home/jenkins/jenkins-slave/workspace/PreCommit-MAPREDUCE-Build/patchprocess/apache-yetus-ee5baeb/precommit/personality/hadoop.sh |
| git revision | trunk / d907697 |
| Default Java | 1.7.0_79 |
| Multi-JDK versions |  /usr/lib/jvm/java-8-oracle:1.8.0_60 /usr/lib/jvm/java-7-openjdk-amd64:1.7.0_79 |
| findbugs | v3.0.0 |
| unit | https://builds.apache.org/job/PreCommit-MAPREDUCE-Build/6145/artifact/patchprocess/patch-unit-hadoop-common-project_hadoop-common-jdk1.8.0_60.txt |
| unit | https://builds.apache.org/job/PreCommit-MAPREDUCE-Build/6145/artifact/patchprocess/patch-unit-hadoop-common-project_hadoop-common-jdk1.7.0_79.txt |
| unit test logs |  https://builds.apache.org/job/PreCommit-MAPREDUCE-Build/6145/artifact/patchprocess/patch-unit-hadoop-common-project_hadoop-common-jdk1.8.0_60.txt https://builds.apache.org/job/PreCommit-MAPREDUCE-Build/6145/artifact/patchprocess/patch-unit-hadoop-common-project_hadoop-common-jdk1.7.0_79.txt |
| JDK v1.7.0_79  Test Results | https://builds.apache.org/job/PreCommit-MAPREDUCE-Build/6145/testReport/ |
| modules | C: hadoop-common-project/hadoop-common U: hadoop-common-project/hadoop-common |
| Max memory used | 228MB |
| Powered by | Apache Yetus   http://yetus.apache.org |
| Console output | https://builds.apache.org/job/PreCommit-MAPREDUCE-Build/6145/console |


This message was automatically generated.

","11/Nov/15 15:57;hadoopqa;| (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue} 0m 13s {color} | {color:blue} docker + precommit patch detected. {color} |
| {color:green}+1{color} | {color:green} @author {color} | {color:green} 0m 0s {color} | {color:green} The patch does not contain any @author tags. {color} |
| {color:green}+1{color} | {color:green} test4tests {color} | {color:green} 0m 0s {color} | {color:green} The patch appears to include 29 new or modified test files. {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 3m 54s {color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 5m 26s {color} | {color:green} trunk passed with JDK v1.8.0_60 {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 4m 52s {color} | {color:green} trunk passed with JDK v1.7.0_79 {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green} 0m 18s {color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green} 0m 15s {color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green} 1m 59s {color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 1m 9s {color} | {color:green} trunk passed with JDK v1.8.0_60 {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 1m 19s {color} | {color:green} trunk passed with JDK v1.7.0_79 {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 1m 44s {color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 5m 19s {color} | {color:green} the patch passed with JDK v1.8.0_60 {color} |
| {color:green}+1{color} | {color:green} javac {color} | {color:green} 5m 19s {color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 4m 31s {color} | {color:green} the patch passed with JDK v1.7.0_79 {color} |
| {color:green}+1{color} | {color:green} javac {color} | {color:green} 4m 31s {color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green} 0m 16s {color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green} 0m 14s {color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} whitespace {color} | {color:green} 0m 0s {color} | {color:green} Patch has no whitespace issues. {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green} 1m 56s {color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 0m 57s {color} | {color:green} the patch passed with JDK v1.8.0_60 {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 1m 5s {color} | {color:green} the patch passed with JDK v1.7.0_79 {color} |
| {color:red}-1{color} | {color:red} unit {color} | {color:red} 19m 11s {color} | {color:red} hadoop-common in the patch failed with JDK v1.8.0_60. {color} |
| {color:red}-1{color} | {color:red} unit {color} | {color:red} 7m 16s {color} | {color:red} hadoop-common in the patch failed with JDK v1.7.0_79. {color} |
| {color:green}+1{color} | {color:green} asflicense {color} | {color:green} 0m 22s {color} | {color:green} Patch does not generate ASF License warnings. {color} |
| {color:black}{color} | {color:black} {color} | {color:black} 63m 25s {color} | {color:black} {color} |
\\
\\
|| Reason || Tests ||
| JDK v1.8.0_60 Timed out junit tests | org.apache.hadoop.http.TestHttpServerLifecycle |
| JDK v1.7.0_79 Failed junit tests | hadoop.security.ssl.TestReloadingX509TrustManager |
\\
\\
|| Subsystem || Report/Notes ||
| Docker | Client=1.7.1 Server=1.7.1 Image:test-patch-base-hadoop-date2015-11-11 |
| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12771754/MAPREDUCE-6505-4.patch |
| JIRA Issue | HADOOP-12564 |
| Optional Tests |  asflicense  javac  javadoc  mvninstall  unit  findbugs  checkstyle  compile  |
| uname | Linux 26fb46caa0eb 3.13.0-36-lowlatency #63-Ubuntu SMP PREEMPT Wed Sep 3 21:56:12 UTC 2014 x86_64 x86_64 x86_64 GNU/Linux |
| Build tool | maven |
| Personality | /home/jenkins/jenkins-slave/workspace/PreCommit-HADOOP-Build/patchprocess/apache-yetus-ee5baeb/precommit/personality/hadoop.sh |
| git revision | trunk / d907697 |
| Default Java | 1.7.0_79 |
| Multi-JDK versions |  /usr/lib/jvm/java-8-oracle:1.8.0_60 /usr/lib/jvm/java-7-openjdk-amd64:1.7.0_79 |
| findbugs | v3.0.0 |
| unit | https://builds.apache.org/job/PreCommit-HADOOP-Build/8062/artifact/patchprocess/patch-unit-hadoop-common-project_hadoop-common-jdk1.8.0_60.txt |
| unit | https://builds.apache.org/job/PreCommit-HADOOP-Build/8062/artifact/patchprocess/patch-unit-hadoop-common-project_hadoop-common-jdk1.7.0_79.txt |
| unit test logs |  https://builds.apache.org/job/PreCommit-HADOOP-Build/8062/artifact/patchprocess/patch-unit-hadoop-common-project_hadoop-common-jdk1.8.0_60.txt https://builds.apache.org/job/PreCommit-HADOOP-Build/8062/artifact/patchprocess/patch-unit-hadoop-common-project_hadoop-common-jdk1.7.0_79.txt |
| JDK v1.7.0_79  Test Results | https://builds.apache.org/job/PreCommit-HADOOP-Build/8062/testReport/ |
| modules | C: hadoop-common-project/hadoop-common U: hadoop-common-project/hadoop-common |
| Max memory used | 227MB |
| Powered by | Apache Yetus   http://yetus.apache.org |
| Console output | https://builds.apache.org/job/PreCommit-HADOOP-Build/8062/console |


This message was automatically generated.

","11/Nov/15 17:10;cotedm;v5 of the patch includes the rest of the changes to the io package to get them up to JUnit 4.  Looks like it all passes locally for me.  [~ozawa] thanks for your help on this and please let me know if there's anything else left to do on this one.  Thanks!","11/Nov/15 18:04;hadoopqa;| (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue} 0m 7s {color} | {color:blue} docker + precommit patch detected. {color} |
| {color:green}+1{color} | {color:green} @author {color} | {color:green} 0m 0s {color} | {color:green} The patch does not contain any @author tags. {color} |
| {color:green}+1{color} | {color:green} test4tests {color} | {color:green} 0m 0s {color} | {color:green} The patch appears to include 32 new or modified test files. {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 3m 13s {color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 4m 19s {color} | {color:green} trunk passed with JDK v1.8.0_60 {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 4m 4s {color} | {color:green} trunk passed with JDK v1.7.0_79 {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green} 0m 13s {color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green} 0m 14s {color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green} 1m 35s {color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 0m 52s {color} | {color:green} trunk passed with JDK v1.8.0_60 {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 1m 2s {color} | {color:green} trunk passed with JDK v1.7.0_79 {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 1m 39s {color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 4m 12s {color} | {color:green} the patch passed with JDK v1.8.0_60 {color} |
| {color:green}+1{color} | {color:green} javac {color} | {color:green} 4m 12s {color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 4m 3s {color} | {color:green} the patch passed with JDK v1.7.0_79 {color} |
| {color:green}+1{color} | {color:green} javac {color} | {color:green} 4m 2s {color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green} 0m 13s {color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green} 0m 14s {color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} whitespace {color} | {color:green} 0m 0s {color} | {color:green} Patch has no whitespace issues. {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green} 1m 45s {color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 0m 51s {color} | {color:green} the patch passed with JDK v1.8.0_60 {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 1m 0s {color} | {color:green} the patch passed with JDK v1.7.0_79 {color} |
| {color:red}-1{color} | {color:red} unit {color} | {color:red} 6m 55s {color} | {color:red} hadoop-common in the patch failed with JDK v1.8.0_60. {color} |
| {color:red}-1{color} | {color:red} unit {color} | {color:red} 7m 56s {color} | {color:red} hadoop-common in the patch failed with JDK v1.7.0_79. {color} |
| {color:green}+1{color} | {color:green} asflicense {color} | {color:green} 0m 23s {color} | {color:green} Patch does not generate ASF License warnings. {color} |
| {color:black}{color} | {color:black} {color} | {color:black} 45m 53s {color} | {color:black} {color} |
\\
\\
|| Reason || Tests ||
| JDK v1.8.0_60 Failed junit tests | hadoop.metrics2.impl.TestGangliaMetrics |
| JDK v1.7.0_79 Failed junit tests | hadoop.fs.TestSymlinkLocalFSFileSystem |
\\
\\
|| Subsystem || Report/Notes ||
| Docker | Client=1.7.1 Server=1.7.1 Image:test-patch-base-hadoop-date2015-11-11 |
| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12771793/MAPREDUCE-6505-5.patch |
| JIRA Issue | HADOOP-12564 |
| Optional Tests |  asflicense  javac  javadoc  mvninstall  unit  findbugs  checkstyle  compile  |
| uname | Linux e5993e22c36c 3.13.0-36-lowlatency #63-Ubuntu SMP PREEMPT Wed Sep 3 21:56:12 UTC 2014 x86_64 x86_64 x86_64 GNU/Linux |
| Build tool | maven |
| Personality | /home/jenkins/jenkins-slave/workspace/PreCommit-HADOOP-Build/patchprocess/apache-yetus-ee5baeb/precommit/personality/hadoop.sh |
| git revision | trunk / d907697 |
| Default Java | 1.7.0_79 |
| Multi-JDK versions |  /usr/lib/jvm/java-8-oracle:1.8.0_60 /usr/lib/jvm/java-7-openjdk-amd64:1.7.0_79 |
| findbugs | v3.0.0 |
| unit | https://builds.apache.org/job/PreCommit-HADOOP-Build/8063/artifact/patchprocess/patch-unit-hadoop-common-project_hadoop-common-jdk1.8.0_60.txt |
| unit | https://builds.apache.org/job/PreCommit-HADOOP-Build/8063/artifact/patchprocess/patch-unit-hadoop-common-project_hadoop-common-jdk1.7.0_79.txt |
| unit test logs |  https://builds.apache.org/job/PreCommit-HADOOP-Build/8063/artifact/patchprocess/patch-unit-hadoop-common-project_hadoop-common-jdk1.8.0_60.txt https://builds.apache.org/job/PreCommit-HADOOP-Build/8063/artifact/patchprocess/patch-unit-hadoop-common-project_hadoop-common-jdk1.7.0_79.txt |
| JDK v1.7.0_79  Test Results | https://builds.apache.org/job/PreCommit-HADOOP-Build/8063/testReport/ |
| modules | C: hadoop-common-project/hadoop-common U: hadoop-common-project/hadoop-common |
| Max memory used | 226MB |
| Powered by | Apache Yetus   http://yetus.apache.org |
| Console output | https://builds.apache.org/job/PreCommit-HADOOP-Build/8063/console |


This message was automatically generated.

","12/Nov/15 08:24;aajisaka;Thanks [~cotedm] for cleaning up the test code. Two comments from me:
1. Public constructors can be removed from test class.
{code:title=TestArrayWritable.java}
  public void testThrowUndefinedValueException() throws IOException {
{code}
{code:title=TestSequenceFile.java}
  public void testInitZeroLengthSequenceFile() throws IOException {
{code}
2. These above two methods should be annotated by {{@Test}}.","14/Nov/15 07:35;ozawa;[~cote] Thank you for updating. We're almost there. In addition to Akira's comment, please check following comments:

{code:title=TestSequenceFile.java|}
   @Test
  public void testCreateWriterOnExistingFile() throws IOException {
{code}
Please fix indentation(Please remote single whitespace before Test annotation).

{code:titile=TestVLong.java|}
  @Test
  public void testVLong6Bytes() throws IOException {
    verifySixOrMoreBytes(6);
  }
  @Test
  public void testVLong7Bytes() throws IOException {
    verifySixOrMoreBytes(7);
  }
  @Test
  public void testVLong8Bytes() throws IOException {
    verifySixOrMoreBytes(8);
  }
  @Test
  public void testVLongRandom() throws IOException {
{code}
Please add a line break between each test cases because of consistent coding style.

{code:title=TestTFileSplit.java}
import org.junit.After;
import org.junit.Before;
{code}

{code:title=TestTFileSeqFileComparison.java}
import static org.junit.Assert.assertEquals;
import static org.junit.Assert.assertTrue;
import static org.junit.Assert.assertFalse;
{code}

Please remove unused imports.

","16/Nov/15 22:04;cotedm;[~ajisakaa] thanks for the review!  I removed the constructors.  Only thing I can't find is the method 
{code}
public void testInitZeroLengthSequenceFile() throws IOException {
{code}

That does exist in my version of TestSequenceFile.java, but maybe I need to pull in a new version.  I'll double check that tomorrow, but I'd appreciate if you can check to make sure that's the right method I missed tagging.

[~ozawa] I think I've addressed all your comments, so once I get confirmation from [~ajisakaa] on the last thing above, I'll add the new patch.  [~ajisakaa] please let me know where I can find that method.  Thanks guys!

","17/Nov/15 01:50;aajisaka;{code:title=TestSequenceFile:L538-}
public void testInitZeroLengthSequenceFile() throws IOException {
{code}
It's the right method. The method is not called from anywhere, so it should be tagged.","17/Nov/15 15:05;cotedm;Ah yep, I had to pull in the latest code to pick up that new test.  Found it now and testing locally before I put up v6 of the patch for review.  Thanks!","17/Nov/15 15:14;cotedm;[~ajisakaa] and [~ozawa] I appreciate you guys working on the review for this :)  

Version 6 of the patch is up and I've tested locally without anything being flagged.  Please let me know if you see anything else outstanding here.  Thanks!","18/Nov/15 04:26;aajisaka;Hi [~cote], would you set the status from ""In Progress"" to ""Patch Available""? Jenkins build runs only if the status is ""Patch Available"".","18/Nov/15 04:34;aajisaka;+1 pending Jenkins. Thanks [~cote] for updating the patch.","18/Nov/15 14:06;cotedm;Thanks [~ajisakaa].  I've set this to PATCH AVAILABLE now and hopefully jenkins will kick in.","18/Nov/15 15:16;hadoopqa;| (x) *{color:red}-1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue} 0m 7s {color} | {color:blue} docker + precommit patch detected. {color} |
| {color:green}+1{color} | {color:green} @author {color} | {color:green} 0m 0s {color} | {color:green} The patch does not contain any @author tags. {color} |
| {color:green}+1{color} | {color:green} test4tests {color} | {color:green} 0m 0s {color} | {color:green} The patch appears to include 32 new or modified test files. {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 7m 42s {color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 7m 36s {color} | {color:green} trunk passed with JDK v1.8.0_66 {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 8m 29s {color} | {color:green} trunk passed with JDK v1.7.0_85 {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green} 0m 15s {color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green} 1m 2s {color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green} 0m 15s {color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green} 1m 46s {color} | {color:green} trunk passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 0m 53s {color} | {color:green} trunk passed with JDK v1.8.0_66 {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 1m 2s {color} | {color:green} trunk passed with JDK v1.7.0_85 {color} |
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 1m 49s {color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 7m 32s {color} | {color:green} the patch passed with JDK v1.8.0_66 {color} |
| {color:red}-1{color} | {color:red} javac {color} | {color:red} 13m 7s {color} | {color:red} root-jdk1.8.0_66 with JDK v1.8.0_66 generated 41 new issues (was 779, now 779). {color} |
| {color:green}+1{color} | {color:green} javac {color} | {color:green} 7m 32s {color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green} 8m 28s {color} | {color:green} the patch passed with JDK v1.7.0_85 {color} |
| {color:red}-1{color} | {color:red} javac {color} | {color:red} 21m 36s {color} | {color:red} root-jdk1.7.0_85 with JDK v1.7.0_85 generated 41 new issues (was 772, now 772). {color} |
| {color:green}+1{color} | {color:green} javac {color} | {color:green} 8m 28s {color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green} 0m 14s {color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green} 1m 0s {color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} mvneclipse {color} | {color:green} 0m 15s {color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} whitespace {color} | {color:green} 0m 0s {color} | {color:green} Patch has no whitespace issues. {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green} 1m 56s {color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 0m 52s {color} | {color:green} the patch passed with JDK v1.8.0_66 {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green} 1m 3s {color} | {color:green} the patch passed with JDK v1.7.0_85 {color} |
| {color:red}-1{color} | {color:red} unit {color} | {color:red} 7m 0s {color} | {color:red} hadoop-common in the patch failed with JDK v1.8.0_66. {color} |
| {color:red}-1{color} | {color:red} unit {color} | {color:red} 7m 12s {color} | {color:red} hadoop-common in the patch failed with JDK v1.7.0_85. {color} |
| {color:green}+1{color} | {color:green} asflicense {color} | {color:green} 0m 24s {color} | {color:green} Patch does not generate ASF License warnings. {color} |
| {color:black}{color} | {color:black} {color} | {color:black} 68m 0s {color} | {color:black} {color} |
\\
\\
|| Reason || Tests ||
| JDK v1.8.0_66 Failed junit tests | hadoop.metrics2.impl.TestGangliaMetrics |
| JDK v1.7.0_85 Failed junit tests | hadoop.fs.shell.TestCopyPreserveFlag |
\\
\\
|| Subsystem || Report/Notes ||
| Docker |  Image:yetus/hadoop:date2015-11-18 |
| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12772758/MAPREDUCE-6505-6.patch |
| JIRA Issue | HADOOP-12564 |
| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  findbugs  checkstyle  |
| uname | Linux 1a406f73362a 3.13.0-36-lowlatency #63-Ubuntu SMP PREEMPT Wed Sep 3 21:56:12 UTC 2014 x86_64 x86_64 x86_64 GNU/Linux |
| Build tool | maven |
| Personality | /home/jenkins/jenkins-slave/workspace/PreCommit-HADOOP-Build/patchprocess/apache-yetus-3f4279a/precommit/personality/hadoop.sh |
| git revision | trunk / 4a3b8f1 |
| findbugs | v3.0.0 |
| javac | root-jdk1.8.0_66: https://builds.apache.org/job/PreCommit-HADOOP-Build/8084/artifact/patchprocess/diff-compile-javac-root-jdk1.8.0_66.txt |
| javac | root-jdk1.7.0_85: https://builds.apache.org/job/PreCommit-HADOOP-Build/8084/artifact/patchprocess/diff-compile-javac-root-jdk1.7.0_85.txt |
| unit | https://builds.apache.org/job/PreCommit-HADOOP-Build/8084/artifact/patchprocess/patch-unit-hadoop-common-project_hadoop-common-jdk1.8.0_66.txt |
| unit | https://builds.apache.org/job/PreCommit-HADOOP-Build/8084/artifact/patchprocess/patch-unit-hadoop-common-project_hadoop-common-jdk1.7.0_85.txt |
| unit test logs |  https://builds.apache.org/job/PreCommit-HADOOP-Build/8084/artifact/patchprocess/patch-unit-hadoop-common-project_hadoop-common-jdk1.8.0_66.txt https://builds.apache.org/job/PreCommit-HADOOP-Build/8084/artifact/patchprocess/patch-unit-hadoop-common-project_hadoop-common-jdk1.7.0_85.txt |
| JDK v1.7.0_85  Test Results | https://builds.apache.org/job/PreCommit-HADOOP-Build/8084/testReport/ |
| modules | C: hadoop-common-project/hadoop-common U: hadoop-common-project/hadoop-common |
| Max memory used | 76MB |
| Powered by | Apache Yetus   http://yetus.apache.org |
| Console output | https://builds.apache.org/job/PreCommit-HADOOP-Build/8084/console |


This message was automatically generated.

","18/Nov/15 15:23;cotedm;[~ajisakaa] and [~ozawa] I believe the failures mentioned in the jenkins output are unrelated:
Tests in error: 
  TestCopyPreserveFlag.initialize:72 Â» IO Mkdirs failed to create d0 (exists=fal...
  TestCopyPreserveFlag.initialize:72 Â» IO Mkdirs failed to create d0 (exists=fal...
  TestCopyPreserveFlag.initialize:72 Â» IO Mkdirs failed to create d0 (exists=fal...
  TestCopyPreserveFlag.initialize:72 Â» IO Mkdirs failed to create d0 (exists=fal...
  TestCopyPreserveFlag.initialize:72 Â» IO Mkdirs failed to create d0 (exists=fal...
  TestCopyPreserveFlag.initialize:72 Â» IO Mkdirs failed to create d0 (exists=fal...
  TestCopyPreserveFlag.initialize:72 Â» IO Mkdirs failed to create d0 (exists=fal...
  TestCopyPreserveFlag.initialize:72 Â» IO Mkdirs failed to create d0 (exists=fal...

Please let me know if you see anything else outstanding when you get a chance and I'll get to work on the other test migration tasks next.  Thanks!","18/Nov/15 16:15;ozawa;+1, checking this in.

The javac warning is not introduced by this jira. HADOOP-12582 is created to address the problem. I'm checking the test failure locally. 

","18/Nov/15 16:17;ozawa;I also confirmed that the test failures hadoop.metrics2.impl.TestGangliaMetrics and hadoop.fs.shell.TestCopyPreserveFlag pass locally. ","18/Nov/15 16:40;ozawa;Committed this to trunk and branch-2. Thanks [~cote] for your contribution and thanks [~ajisakaa] for your reviews.","18/Nov/15 16:44;hudson;FAILURE: Integrated in Hadoop-trunk-Commit #8819 (See [https://builds.apache.org/job/Hadoop-trunk-Commit/8819/])
HADOOP-12564. Upgrade JUnit3 TestCase to JUnit 4 in org.apache.hadoop.io (ozawa: rev 989b9e3e11bd6bead262dc621251b5160d84f6a4)
* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/TestBloomMapFile.java
* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/compress/TestCodecFactory.java
* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/TestWritableName.java
* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/file/tfile/TestTFileSplit.java
* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/TestArrayFile.java
* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/TestWritableUtils.java
* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/file/tfile/TestTFile.java
* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/serializer/avro/TestAvroSerialization.java
* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/TestDefaultStringifier.java
* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/file/tfile/TestVLong.java
* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/file/tfile/TestTFileStreams.java
* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/file/tfile/TestTFileUnsortedByteArrays.java
* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/TestMapWritable.java
* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/TestVersionedWritable.java
* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/TestSetFile.java
* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/file/tfile/TestTFileComparators.java
* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/TestArrayWritable.java
* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/TestSequenceFile.java
* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/TestUTF8.java
* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/TestGenericWritable.java
* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/AvroTestUtil.java
* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/compress/TestCompressionStreamReuse.java
* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/TestText.java
* hadoop-common-project/hadoop-common/CHANGES.txt
* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/file/tfile/TestTFileSeqFileComparison.java
* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/TestSequenceFileSerialization.java
* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/TestBoundedByteArrayOutputStream.java
* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/TestWritable.java
* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/TestMD5Hash.java
* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/TestArrayPrimitiveWritable.java
* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/file/tfile/TestTFileSeek.java
* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/TestEnumSetWritable.java
* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/TestTextNonUTF8.java
","18/Nov/15 17:35;hudson;FAILURE: Integrated in Hadoop-Mapreduce-trunk-Java8 #678 (See [https://builds.apache.org/job/Hadoop-Mapreduce-trunk-Java8/678/])
HADOOP-12564. Upgrade JUnit3 TestCase to JUnit 4 in org.apache.hadoop.io (ozawa: rev 989b9e3e11bd6bead262dc621251b5160d84f6a4)
* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/TestBloomMapFile.java
* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/AvroTestUtil.java
* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/serializer/avro/TestAvroSerialization.java
* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/file/tfile/TestTFileComparators.java
* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/TestSetFile.java
* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/compress/TestCompressionStreamReuse.java
* hadoop-common-project/hadoop-common/CHANGES.txt
* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/TestSequenceFileSerialization.java
* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/TestWritableName.java
* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/TestEnumSetWritable.java
* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/TestGenericWritable.java
* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/file/tfile/TestTFileSeqFileComparison.java
* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/TestText.java
* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/TestSequenceFile.java
* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/file/tfile/TestTFileUnsortedByteArrays.java
* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/TestWritableUtils.java
* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/file/tfile/TestTFileSeek.java
* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/TestBoundedByteArrayOutputStream.java
* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/TestArrayFile.java
* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/file/tfile/TestTFileStreams.java
* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/TestTextNonUTF8.java
* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/TestWritable.java
* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/TestVersionedWritable.java
* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/file/tfile/TestVLong.java
* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/TestUTF8.java
* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/compress/TestCodecFactory.java
* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/file/tfile/TestTFile.java
* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/TestMD5Hash.java
* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/file/tfile/TestTFileSplit.java
* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/TestMapWritable.java
* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/TestArrayWritable.java
* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/TestDefaultStringifier.java
* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/TestArrayPrimitiveWritable.java
","18/Nov/15 18:16;hudson;FAILURE: Integrated in Hadoop-Mapreduce-trunk #2620 (See [https://builds.apache.org/job/Hadoop-Mapreduce-trunk/2620/])
HADOOP-12564. Upgrade JUnit3 TestCase to JUnit 4 in org.apache.hadoop.io (ozawa: rev 989b9e3e11bd6bead262dc621251b5160d84f6a4)
* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/file/tfile/TestVLong.java
* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/TestMD5Hash.java
* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/TestWritableUtils.java
* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/TestSequenceFile.java
* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/TestEnumSetWritable.java
* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/TestTextNonUTF8.java
* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/AvroTestUtil.java
* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/file/tfile/TestTFileSeek.java
* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/TestBoundedByteArrayOutputStream.java
* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/TestMapWritable.java
* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/TestText.java
* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/TestGenericWritable.java
* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/TestBloomMapFile.java
* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/compress/TestCodecFactory.java
* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/TestVersionedWritable.java
* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/file/tfile/TestTFileSeqFileComparison.java
* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/TestArrayWritable.java
* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/file/tfile/TestTFileStreams.java
* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/file/tfile/TestTFileUnsortedByteArrays.java
* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/TestArrayPrimitiveWritable.java
* hadoop-common-project/hadoop-common/CHANGES.txt
* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/TestWritable.java
* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/TestSetFile.java
* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/file/tfile/TestTFileSplit.java
* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/TestArrayFile.java
* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/TestWritableName.java
* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/file/tfile/TestTFile.java
* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/TestUTF8.java
* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/compress/TestCompressionStreamReuse.java
* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/file/tfile/TestTFileComparators.java
* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/serializer/avro/TestAvroSerialization.java
* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/TestDefaultStringifier.java
* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/TestSequenceFileSerialization.java
","18/Nov/15 18:23;hudson;FAILURE: Integrated in Hadoop-Yarn-trunk #1416 (See [https://builds.apache.org/job/Hadoop-Yarn-trunk/1416/])
HADOOP-12564. Upgrade JUnit3 TestCase to JUnit 4 in org.apache.hadoop.io (ozawa: rev 989b9e3e11bd6bead262dc621251b5160d84f6a4)
* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/TestSetFile.java
* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/TestWritableUtils.java
* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/file/tfile/TestVLong.java
* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/AvroTestUtil.java
* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/TestWritable.java
* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/TestDefaultStringifier.java
* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/file/tfile/TestTFileStreams.java
* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/TestArrayPrimitiveWritable.java
* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/file/tfile/TestTFileSplit.java
* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/TestSequenceFileSerialization.java
* hadoop-common-project/hadoop-common/CHANGES.txt
* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/TestBloomMapFile.java
* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/TestWritableName.java
* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/TestGenericWritable.java
* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/TestArrayFile.java
* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/serializer/avro/TestAvroSerialization.java
* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/TestMD5Hash.java
* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/file/tfile/TestTFileComparators.java
* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/file/tfile/TestTFileUnsortedByteArrays.java
* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/TestTextNonUTF8.java
* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/compress/TestCodecFactory.java
* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/file/tfile/TestTFileSeek.java
* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/TestBoundedByteArrayOutputStream.java
* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/TestSequenceFile.java
* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/TestEnumSetWritable.java
* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/file/tfile/TestTFileSeqFileComparison.java
* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/file/tfile/TestTFile.java
* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/TestUTF8.java
* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/TestArrayWritable.java
* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/TestVersionedWritable.java
* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/TestMapWritable.java
* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/TestText.java
* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/compress/TestCompressionStreamReuse.java
","18/Nov/15 19:00;hudson;FAILURE: Integrated in Hadoop-Yarn-trunk-Java8 #691 (See [https://builds.apache.org/job/Hadoop-Yarn-trunk-Java8/691/])
HADOOP-12564. Upgrade JUnit3 TestCase to JUnit 4 in org.apache.hadoop.io (ozawa: rev 989b9e3e11bd6bead262dc621251b5160d84f6a4)
* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/TestGenericWritable.java
* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/TestSetFile.java
* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/TestWritableUtils.java
* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/file/tfile/TestTFileStreams.java
* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/file/tfile/TestTFileSplit.java
* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/TestMD5Hash.java
* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/TestDefaultStringifier.java
* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/file/tfile/TestVLong.java
* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/TestArrayWritable.java
* hadoop-common-project/hadoop-common/CHANGES.txt
* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/file/tfile/TestTFile.java
* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/file/tfile/TestTFileUnsortedByteArrays.java
* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/TestMapWritable.java
* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/compress/TestCodecFactory.java
* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/file/tfile/TestTFileSeqFileComparison.java
* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/TestSequenceFile.java
* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/TestText.java
* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/serializer/avro/TestAvroSerialization.java
* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/compress/TestCompressionStreamReuse.java
* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/TestEnumSetWritable.java
* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/TestWritable.java
* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/TestSequenceFileSerialization.java
* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/file/tfile/TestTFileSeek.java
* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/TestUTF8.java
* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/AvroTestUtil.java
* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/TestBloomMapFile.java
* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/TestArrayFile.java
* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/TestBoundedByteArrayOutputStream.java
* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/TestWritableName.java
* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/TestTextNonUTF8.java
* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/TestVersionedWritable.java
* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/TestArrayPrimitiveWritable.java
* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/file/tfile/TestTFileComparators.java
","18/Nov/15 20:46;hudson;FAILURE: Integrated in Hadoop-Hdfs-trunk-Java8 #615 (See [https://builds.apache.org/job/Hadoop-Hdfs-trunk-Java8/615/])
HADOOP-12564. Upgrade JUnit3 TestCase to JUnit 4 in org.apache.hadoop.io (ozawa: rev 989b9e3e11bd6bead262dc621251b5160d84f6a4)
* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/file/tfile/TestTFileStreams.java
* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/TestWritableName.java
* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/TestGenericWritable.java
* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/file/tfile/TestTFileSeek.java
* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/TestWritableUtils.java
* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/serializer/avro/TestAvroSerialization.java
* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/TestArrayPrimitiveWritable.java
* hadoop-common-project/hadoop-common/CHANGES.txt
* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/file/tfile/TestTFileSeqFileComparison.java
* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/file/tfile/TestVLong.java
* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/compress/TestCompressionStreamReuse.java
* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/file/tfile/TestTFileSplit.java
* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/TestBoundedByteArrayOutputStream.java
* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/TestMD5Hash.java
* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/TestVersionedWritable.java
* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/compress/TestCodecFactory.java
* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/TestUTF8.java
* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/TestArrayFile.java
* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/file/tfile/TestTFileUnsortedByteArrays.java
* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/TestText.java
* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/TestArrayWritable.java
* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/TestMapWritable.java
* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/TestSequenceFile.java
* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/TestBloomMapFile.java
* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/TestSequenceFileSerialization.java
* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/TestSetFile.java
* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/TestWritable.java
* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/TestDefaultStringifier.java
* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/AvroTestUtil.java
* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/file/tfile/TestTFileComparators.java
* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/TestTextNonUTF8.java
* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/file/tfile/TestTFile.java
* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/TestEnumSetWritable.java
","18/Nov/15 21:25;hudson;FAILURE: Integrated in Hadoop-Hdfs-trunk #2553 (See [https://builds.apache.org/job/Hadoop-Hdfs-trunk/2553/])
HADOOP-12564. Upgrade JUnit3 TestCase to JUnit 4 in org.apache.hadoop.io (ozawa: rev 989b9e3e11bd6bead262dc621251b5160d84f6a4)
* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/file/tfile/TestTFileStreams.java
* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/TestWritableUtils.java
* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/TestMD5Hash.java
* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/file/tfile/TestTFileSeek.java
* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/TestDefaultStringifier.java
* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/TestText.java
* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/compress/TestCompressionStreamReuse.java
* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/TestArrayFile.java
* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/file/tfile/TestTFileComparators.java
* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/file/tfile/TestTFileUnsortedByteArrays.java
* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/TestSequenceFile.java
* hadoop-common-project/hadoop-common/CHANGES.txt
* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/serializer/avro/TestAvroSerialization.java
* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/TestMapWritable.java
* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/TestArrayWritable.java
* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/TestSetFile.java
* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/file/tfile/TestTFileSplit.java
* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/TestBoundedByteArrayOutputStream.java
* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/file/tfile/TestVLong.java
* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/TestTextNonUTF8.java
* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/file/tfile/TestTFile.java
* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/TestEnumSetWritable.java
* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/TestBloomMapFile.java
* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/TestGenericWritable.java
* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/TestSequenceFileSerialization.java
* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/TestArrayPrimitiveWritable.java
* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/TestWritableName.java
* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/TestUTF8.java
* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/TestWritable.java
* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/file/tfile/TestTFileSeqFileComparison.java
* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/AvroTestUtil.java
* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/compress/TestCodecFactory.java
* hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/io/TestVersionedWritable.java
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Remove @Ignore from valid S3a test.,HADOOP-14209,13057976,Test,Patch Available,HADOOP,Hadoop Common,software,omalley,Hadoop Common is the common library for Apache Hadoop.,http://hadoop.apache.org/,Trivial,,moist,moist,moist,21/Mar/17 18:15,11/Dec/17 21:53,12/Jan/21 11:55,,2.9.0,3.0.0-alpha2,,,,,,,,,fs/s3,,,,0,newbie,,"The class org.apache.hadoop.fs.s3a.ITestS3AEncryptionAlgorithmValidation is ignored through the @Ignore annotation, this should be removed as it is a valid test class.  This was a minor mistake introduced during development of HADOOP-13075.",,moist,stevel@apache.org,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"28/Apr/17 16:56;moist;HADOOP-14209-001.patch;https://issues.apache.org/jira/secure/attachment/12865579/HADOOP-14209-001.patch","28/Apr/17 16:56;moist;HADOOP-14209-branch-2-001.patch;https://issues.apache.org/jira/secure/attachment/12865580/HADOOP-14209-branch-2-001.patch",,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,2017-04-28 10:09:29.497,,,false,,,,,,,,,,,,,,,,,9223372036854775807,,,,,Mon Dec 11 21:53:33 UTC 2017,,,,,,,"0|i3clcn:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,"21/Mar/17 18:16;moist;This is in trunk and branch-2 and should be fixed in both places.","28/Apr/17 10:09;stevel@apache.org;have you got a patch for this?","28/Apr/17 16:56;moist;Tested against aws us-west-2.","28/Apr/17 16:57;moist;Minor formatting change in trunk for the validation tests.  Had to fix one of the tests as there was an outdated error message.","02/May/17 14:25;stevel@apache.org;so branch-2 is a couple of lines & trunk is 6KB, why the difference? ","02/May/17 14:46;moist;Fixed all the formatting issues in trunk to be in accordance with checkstyle.","11/Dec/17 21:09;moist;Is this still something that is needed to be done?","11/Dec/17 21:53;genericqa;| (/) *{color:green}+1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | {color:blue} reexec {color} | {color:blue} 20m  4s{color} | {color:blue} Docker mode activated. {color} |
|| || || || {color:brown} Prechecks {color} ||
| {color:green}+1{color} | {color:green} @author {color} | {color:green}  0m  0s{color} | {color:green} The patch does not contain any @author tags. {color} |
| {color:green}+1{color} | {color:green} test4tests {color} | {color:green}  0m  0s{color} | {color:green} The patch appears to include 1 new or modified test files. {color} |
|| || || || {color:brown} branch-2 Compile Tests {color} ||
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green} 14m 42s{color} | {color:green} branch-2 passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green}  0m 27s{color} | {color:green} branch-2 passed {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 15s{color} | {color:green} branch-2 passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  0m 35s{color} | {color:green} branch-2 passed {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  0m 43s{color} | {color:green} branch-2 passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 22s{color} | {color:green} branch-2 passed {color} |
|| || || || {color:brown} Patch Compile Tests {color} ||
| {color:green}+1{color} | {color:green} mvninstall {color} | {color:green}  0m 35s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} compile {color} | {color:green}  0m 25s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javac {color} | {color:green}  0m 25s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} checkstyle {color} | {color:green}  0m 12s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} mvnsite {color} | {color:green}  0m 32s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} whitespace {color} | {color:green}  0m  0s{color} | {color:green} The patch has no whitespace issues. {color} |
| {color:green}+1{color} | {color:green} findbugs {color} | {color:green}  0m 50s{color} | {color:green} the patch passed {color} |
| {color:green}+1{color} | {color:green} javadoc {color} | {color:green}  0m 17s{color} | {color:green} the patch passed {color} |
|| || || || {color:brown} Other Tests {color} ||
| {color:green}+1{color} | {color:green} unit {color} | {color:green}  0m 45s{color} | {color:green} hadoop-aws in the patch passed. {color} |
| {color:green}+1{color} | {color:green} asflicense {color} | {color:green}  0m 22s{color} | {color:green} The patch does not generate ASF License warnings. {color} |
| {color:black}{color} | {color:black} {color} | {color:black} 42m 40s{color} | {color:black} {color} |
\\
\\
|| Subsystem || Report/Notes ||
| Docker | Client=17.05.0-ce Server=17.05.0-ce Image:yetus/hadoop:17213a0 |
| JIRA Issue | HADOOP-14209 |
| JIRA Patch URL | https://issues.apache.org/jira/secure/attachment/12865580/HADOOP-14209-branch-2-001.patch |
| Optional Tests |  asflicense  compile  javac  javadoc  mvninstall  mvnsite  unit  shadedclient  findbugs  checkstyle  |
| uname | Linux a9b27e4c169c 3.13.0-129-generic #178-Ubuntu SMP Fri Aug 11 12:48:20 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux |
| Build tool | maven |
| Personality | /testptch/patchprocess/precommit/personality/provided.sh |
| git revision | branch-2 / 7b3c64a |
| maven | version: Apache Maven 3.3.9 (bb52d8502b132ec0a5a3f4c09453c07478323dc5; 2015-11-10T16:41:47+00:00) |
| Default Java | 1.7.0_151 |
| findbugs | v3.0.0 |
|  Test Results | https://builds.apache.org/job/PreCommit-HADOOP-Build/13813/testReport/ |
| Max. process+thread count | 156 (vs. ulimit of 5000) |
| modules | C: hadoop-tools/hadoop-aws U: hadoop-tools/hadoop-aws |
| Console output | https://builds.apache.org/job/PreCommit-HADOOP-Build/13813/console |
| Powered by | Apache Yetus 0.7.0-SNAPSHOT   http://yetus.apache.org |


This message was automatically generated.

",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
shellcheck plugin displays a wrong version potentially,HADOOP-12035,12832822,Test,Resolved,HADOOP,Hadoop Common,software,omalley,Hadoop Common is the common library for Apache Hadoop.,http://hadoop.apache.org/,Trivial,Fixed,sekikn,sekikn,sekikn,26/May/15 18:54,30/Aug/16 01:27,12/Jan/21 11:55,28/May/15 16:12,,,,,2.8.0,3.0.0-alpha1,,,,,build,,,,0,newbie,test-patch,"In dev-support/test-patch.d/shellcheck.sh:

{code}
SHELLCHECK_VERSION=$(shellcheck --version | ${GREP} version: | ${AWK} '{print $NF}')
{code}

it should be 

{code}
SHELLCHECK_VERSION=$(${SHELLCHECK} --version | …)
{code}",,aw,hudson,sekikn,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"26/May/15 23:32;sekikn;HADOOP-12035.001.patch;https://issues.apache.org/jira/secure/attachment/12735455/HADOOP-12035.001.patch",,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,2015-05-26 23:40:57.733,,,false,,,,,,,,,,,,,,,,,9223372036854775807,,,,,Fri May 29 15:19:12 UTC 2015,,,,,,,"0|i2f7t3:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,"26/May/15 23:32;sekikn;Attaching a patch.","26/May/15 23:40;hadoopqa;(!) A patch to test-patch or smart-apply-patch has been detected. 
Re-executing against the patched versions to perform further tests. 
The console is at https://builds.apache.org/job/PreCommit-HADOOP-Build/6834/console in case of problems.","26/May/15 23:41;hadoopqa;\\
\\
| (/) *{color:green}+1 overall{color}* |
\\
\\
|| Vote || Subsystem || Runtime || Comment ||
| {color:blue}0{color} | reexec |   0m  0s | dev-support patch detected. |
| {color:blue}0{color} | pre-patch |   0m  0s | Pre-patch trunk compilation is healthy. |
| {color:blue}0{color} | @author |   0m  0s | Skipping @author checks as test-patch has been patched. |
| {color:green}+1{color} | release audit |   0m 16s | The applied patch does not increase the total number of release audit warnings. |
| {color:green}+1{color} | shellcheck |   0m  5s | There were no new shellcheck (v0.3.3) issues. |
| {color:green}+1{color} | whitespace |   0m  0s | The patch has no lines that end in whitespace. |
| | |   0m 24s | |
\\
\\
|| Subsystem || Report/Notes ||
| Patch URL | http://issues.apache.org/jira/secure/attachment/12735455/HADOOP-12035.001.patch |
| Optional Tests | shellcheck |
| git revision | trunk / cdbd66b |
| Java | 1.7.0_55 |
| uname | Linux asf903.gq1.ygridcore.net 3.13.0-36-lowlatency #63-Ubuntu SMP PREEMPT Wed Sep 3 21:56:12 UTC 2014 x86_64 x86_64 x86_64 GNU/Linux |
| Console output | https://builds.apache.org/job/PreCommit-HADOOP-Build/6834/console |


This message was automatically generated.","28/May/15 16:12;aw;+1 committed

thanks!","28/May/15 16:34;hudson;FAILURE: Integrated in Hadoop-trunk-Commit #7915 (See [https://builds.apache.org/job/Hadoop-trunk-Commit/7915/])
HADOOP-12035. shellcheck plugin displays a wrong version potentially (Kengo Seki via aw) (aw: rev f1cea9c6bf68f03f7136bebc245efbc0a95738e4)
* hadoop-common-project/hadoop-common/CHANGES.txt
* dev-support/test-patch.d/shellcheck.sh
","28/May/15 23:38;hudson;FAILURE: Integrated in Hadoop-Hdfs-trunk-Java8 #200 (See [https://builds.apache.org/job/Hadoop-Hdfs-trunk-Java8/200/])
HADOOP-12035. shellcheck plugin displays a wrong version potentially (Kengo Seki via aw) (aw: rev f1cea9c6bf68f03f7136bebc245efbc0a95738e4)
* dev-support/test-patch.d/shellcheck.sh
* hadoop-common-project/hadoop-common/CHANGES.txt
","29/May/15 11:55;hudson;SUCCESS: Integrated in Hadoop-Yarn-trunk-Java8 #212 (See [https://builds.apache.org/job/Hadoop-Yarn-trunk-Java8/212/])
HADOOP-12035. shellcheck plugin displays a wrong version potentially (Kengo Seki via aw) (aw: rev f1cea9c6bf68f03f7136bebc245efbc0a95738e4)
* hadoop-common-project/hadoop-common/CHANGES.txt
* dev-support/test-patch.d/shellcheck.sh
","29/May/15 11:59;hudson;SUCCESS: Integrated in Hadoop-Yarn-trunk #942 (See [https://builds.apache.org/job/Hadoop-Yarn-trunk/942/])
HADOOP-12035. shellcheck plugin displays a wrong version potentially (Kengo Seki via aw) (aw: rev f1cea9c6bf68f03f7136bebc245efbc0a95738e4)
* dev-support/test-patch.d/shellcheck.sh
* hadoop-common-project/hadoop-common/CHANGES.txt
","29/May/15 13:03;hudson;FAILURE: Integrated in Hadoop-Hdfs-trunk #2140 (See [https://builds.apache.org/job/Hadoop-Hdfs-trunk/2140/])
HADOOP-12035. shellcheck plugin displays a wrong version potentially (Kengo Seki via aw) (aw: rev f1cea9c6bf68f03f7136bebc245efbc0a95738e4)
* dev-support/test-patch.d/shellcheck.sh
* hadoop-common-project/hadoop-common/CHANGES.txt
","29/May/15 15:19;hudson;SUCCESS: Integrated in Hadoop-Mapreduce-trunk-Java8 #210 (See [https://builds.apache.org/job/Hadoop-Mapreduce-trunk-Java8/210/])
HADOOP-12035. shellcheck plugin displays a wrong version potentially (Kengo Seki via aw) (aw: rev f1cea9c6bf68f03f7136bebc245efbc0a95738e4)
* dev-support/test-patch.d/shellcheck.sh
* hadoop-common-project/hadoop-common/CHANGES.txt
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Reenable several HA ZooKeeper-related tests on Windows.,HADOOP-10754,12723910,Test,Closed,HADOOP,Hadoop Common,software,omalley,Hadoop Common is the common library for Apache Hadoop.,http://hadoop.apache.org/,Trivial,Fixed,cnauroth,cnauroth,cnauroth,26/Jun/14 16:35,12/May/16 18:26,12/Jan/21 11:55,26/Jun/14 23:06,2.4.0,3.0.0-alpha1,,,2.5.0,,,,,,ha,test,,,0,,,"Now that our version of ZooKeeper has been upgraded in HADOOP-9555, we can reenable several tests that had been broken on Windows.",,arp,cnauroth,hudson,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,HADOOP-9555,HADOOP-9556,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"26/Jun/14 16:37;cnauroth;HADOOP-10754.1.patch;https://issues.apache.org/jira/secure/attachment/12652639/HADOOP-10754.1.patch",,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,2014-06-26 17:33:04.518,,,false,,,,,,,,,,,,,,,,,402095,Reviewed,,,,Fri Jun 27 15:16:49 UTC 2014,,,,,,,"0|i1x7kn:",402161,,,,,,,,,,,,,2.5.0,,,,,,,,,,"26/Jun/14 16:37;cnauroth;Here is the patch.  I should have done this earlier as part of my HADOOP-9555 patch.  (Sorry!)

[~arpitagarwal], could you please code review?","26/Jun/14 17:33;hadoopqa;{color:green}+1 overall{color}.  Here are the results of testing the latest attachment 
  http://issues.apache.org/jira/secure/attachment/12652639/HADOOP-10754.1.patch
  against trunk revision .

    {color:green}+1 @author{color}.  The patch does not contain any @author tags.

    {color:green}+1 tests included{color}.  The patch appears to include 2 new or modified test files.

    {color:green}+1 javac{color}.  The applied patch does not increase the total number of javac compiler warnings.

    {color:green}+1 javadoc{color}.  There were no new javadoc warning messages.

    {color:green}+1 eclipse:eclipse{color}.  The patch built with eclipse:eclipse.

    {color:green}+1 findbugs{color}.  The patch does not introduce any new Findbugs (version 1.3.9) warnings.

    {color:green}+1 release audit{color}.  The applied patch does not increase the total number of release audit warnings.

    {color:green}+1 core tests{color}.  The patch passed unit tests in hadoop-common-project/hadoop-common.

    {color:green}+1 contrib tests{color}.  The patch passed contrib unit tests.

Test results: https://builds.apache.org/job/PreCommit-HADOOP-Build/4177//testReport/
Console output: https://builds.apache.org/job/PreCommit-HADOOP-Build/4177//console

This message is automatically generated.","26/Jun/14 18:56;arp;+1

Verified tests pass on Windows with Zookeeper 3.4.6.

I got ZK test timeouts which went away after I deleted .m2 and let maven download dependencies again. Ran the tests a few times in a loop and can no longer repro the timeouts. It could have been an unrelated issue.","26/Jun/14 23:06;cnauroth;Arpit, thank you for the code review.  I committed this to trunk and branch-2.","26/Jun/14 23:07;hudson;SUCCESS: Integrated in Hadoop-trunk-Commit #5785 (See [https://builds.apache.org/job/Hadoop-trunk-Commit/5785/])
HADOOP-10754. Reenable several HA ZooKeeper-related tests on Windows. Contributed by Chris Nauroth. (cnauroth: http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1605924)
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/CHANGES.txt
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/ha/TestActiveStandbyElectorRealZK.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/ha/TestZKFailoverControllerStress.java
","27/Jun/14 11:14;hudson;FAILURE: Integrated in Hadoop-Yarn-trunk #596 (See [https://builds.apache.org/job/Hadoop-Yarn-trunk/596/])
HADOOP-10754. Reenable several HA ZooKeeper-related tests on Windows. Contributed by Chris Nauroth. (cnauroth: http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1605924)
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/CHANGES.txt
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/ha/TestActiveStandbyElectorRealZK.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/ha/TestZKFailoverControllerStress.java
","27/Jun/14 14:15;hudson;FAILURE: Integrated in Hadoop-Hdfs-trunk #1787 (See [https://builds.apache.org/job/Hadoop-Hdfs-trunk/1787/])
HADOOP-10754. Reenable several HA ZooKeeper-related tests on Windows. Contributed by Chris Nauroth. (cnauroth: http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1605924)
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/CHANGES.txt
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/ha/TestActiveStandbyElectorRealZK.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/ha/TestZKFailoverControllerStress.java
","27/Jun/14 15:16;hudson;FAILURE: Integrated in Hadoop-Mapreduce-trunk #1814 (See [https://builds.apache.org/job/Hadoop-Mapreduce-trunk/1814/])
HADOOP-10754. Reenable several HA ZooKeeper-related tests on Windows. Contributed by Chris Nauroth. (cnauroth: http://svn.apache.org/viewcvs.cgi/?root=Apache-SVN&view=rev&rev=1605924)
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/CHANGES.txt
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/ha/TestActiveStandbyElectorRealZK.java
* /hadoop/common/trunk/hadoop-common-project/hadoop-common/src/test/java/org/apache/hadoop/ha/TestZKFailoverControllerStress.java
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Test issue for JIRA automation scripts,HADOOP-11806,12788255,Test,Resolved,HADOOP,Hadoop Common,software,omalley,Hadoop Common is the common library for Apache Hadoop.,http://hadoop.apache.org/,Trivial,Not A Problem,raymie,raymie,raymie,04/Apr/15 05:46,21/Jul/15 18:21,12/Jan/21 11:55,21/Jul/15 18:20,,,,,,,,,,,,,,,0,,,I'm writing some scripts to automate some JIRA clean-up activities.  I've created this issue for testing these scripts.  Please ignore...,,raymie,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,,false,,,,,,,,,,,,,,,,,9223372036854775807,,,,,Sat Apr 04 06:41:49 UTC 2015,,,,,,,"0|i27s9b:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,"04/Apr/15 06:39;raymie;Test comment","04/Apr/15 06:40;raymie;Test comment","04/Apr/15 06:41;raymie;Test comment","04/Apr/15 06:41;raymie;Test comment",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
