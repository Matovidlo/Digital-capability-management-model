Issue id,Status,Summary,Issue Type,Created,Author,Resolution,Resolved,Description,Creator,Labels,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary,Comment author,Commentary
8152,OPEN,Annoying warning message,kind/bug,2021-02-23 19:22:59 +0000 UTC,Berbe,Opened,,"Since #7978, an annoying info messages is displayed eveytime docker-compose is being used.

While the intent is praiseworthy, the consequences are pretty annoying. It would have been better to have a message only being displayed on the first subsequent launch after update.

Is there a way to deactivate this message now polluting *every* us of the tool?",,,,,,,,,,,,,,
8149,OPEN,enable running containerized docker-compose in a remote host,kind/feature,2021-02-23 19:00:07 +0000 UTC,imme-emosol,Opened,,"Running containerized docker-compose with a DOCKER_HOST environment variable that is set to a remote host that is local only (an entry in /etc/hosts) *does not work*.

I would like for the docker-compose shell script to actually work.

To test:
1. use a machine (machineA) that runs docker daemon, with enabled TCP-socket
2. use another machine (machineB) that will use that external DOCKER_HOST for docker by:
 - setting the DOCKER_HOST ENV-variable to a name that you will use to reach the docker host
 - making sure the name resolves to an ip locally, for instance by mapping that name to an ip in /etc/hosts
3. now install the containerized docker-compose on machineB
4. use docker-compose and notice that it will not work because the docker-compose running inside the container on the remote cannot resolve the DOCKER_HOST that was transferred from machineB to the container running on machineA",,,imme,"
--
Apparently using newlines in environment variables also became problematic.
--
",,,,,,,,,,
8146,OPEN,remote build context in git over ssh does not work on Windows,kind/bug,2021-02-22 10:38:27 +0000 UTC,libor-m,Opened,,"## Description of the issue
When trying to build an image from a private git repo, an error message saying `cannot run ssh` is produced. `ssh` and `git` are accessible in the shell where I am running the `docker-compose up`, but are not available system-wide (as the Git for Windows advises against that).

## Context information (for bug reports)

**Output of `docker-compose version`**
```
docker-compose version 1.27.4, build 40524192
docker-py version: 4.3.1
CPython version: 3.7.4
OpenSSL version: OpenSSL 1.1.1c  28 May 2019
```

**Output of `docker version`**
```
Client: Docker Engine - Community
 Cloud integration: 1.0.7
 Version:           20.10.2
 API version:       1.41
 Go version:        go1.13.15
 Git commit:        2291f61
 Built:             Mon Dec 28 16:14:16 2020
 OS/Arch:           windows/amd64
 Context:           default
 Experimental:      true

Server: Docker Engine - Community
 Engine:
  Version:          20.10.2
  API version:      1.41 (minimum version 1.12)
  Go version:       go1.13.15
  Git commit:       8891c58
  Built:            Mon Dec 28 16:15:28 2020
  OS/Arch:          linux/amd64
  Experimental:     false
 containerd:
  Version:          1.4.3
  GitCommit:        269548fa27e0089a8b8278fc4fc781d7f65a939b
 runc:
  Version:          1.0.0-rc92
  GitCommit:        ff819c7e9184c13b7c2607fe6c30ae19403a7aff
 docker-init:
  Version:          0.19.0
  GitCommit:        de40ad0
```

**Output of `docker-compose config`**
Only the relevant bit:
```
.. redacted.. 

  front-end:
    build: 
      context: git@bitbucket.org:{my_org}/{my_private_repo}.git#docker

.. redacted ..
```


## Steps to reproduce the issue

1.  use remote git+ssh context in `docker-compose.yml`

2. run `docker compose  -f $DOCKDIR/docker-compose.yml up` (I'm using a non-default location for the file, and did not try otherwise)

### Observed result
```
error fetching: error: cannot run ssh: No such file or directory\nfatal: unable to fork\n: exit status 128
```

### Expected result
An image built by using the `Dockerfile` in the `docker` branch of the remote repo.

### Stacktrace / full error message
```
Building front-end

Traceback (most recent call last):
  File ""compose\cli\main.py"", line 67, in main
  File ""compose\cli\main.py"", line 126, in perform_command
  File ""compose\cli\main.py"", line 1070, in up
  File ""compose\cli\main.py"", line 1066, in up
  File ""compose\project.py"", line 615, in up
  File ""compose\service.py"", line 362, in ensure_image_exists
  File ""compose\service.py"", line 1147, in build
compose.service.BuildError: (<Service: front-end>, {'message': 'error fetching: error: cannot run ssh: No such file or directory\nfatal: unable to fork\n: exit status 128'})

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""docker-compose"", line 3, in <module>
  File ""compose\cli\main.py"", line 78, in main
TypeError: can only concatenate str (not ""dict"") to str
[19140] Failed to execute script docker-compose
```

## Additional information
- Windows 10 20H2
- docker-compose installed as a part of Docker Desktop
- tested in ""Git CMD"", ""Git Bash"", and Ubuntu on WSL2 (seems that the build request is forwarded to the host machine anyways, the error is the same)",,,libor,"
--
Just tested that the remote context works via https with [Bitbucket App Password](https://support.atlassian.com/bitbucket-cloud/docs/app-passwords/).
--
",,,,,,,,,,
8144,OPEN,[proposal] support s2i build strategy,kind/feature,2021-02-20 18:46:42 +0000 UTC,abdennour,Opened,,"-->

**Is your feature request related to a problem? Please describe.**

docker-compose is the friend of any local environment for any dev team.
Today, docker-compose supports only one build strategy : Dockerfile + context + [args] + [target]
You build from existing Dockerfile, but sometime you want to build using an s2i builder image.


**Describe the solution you'd like**
The solution is that the YAML definition of docker-compose supports s2i build strategy.
The existing block `services[*].build` can refer to a Dockerfile. The solution is to use the same block to refer to s2i arguments including: builder image, context-dir, build env vars, runtime image if any... so on.

EXAMPLE 1  (same builder_image will be promoted as runtime base image)

```sh
# original
s2i https://github.com/sclorg/django-ex centos/python-35-centos7 hello-python
```
docker-compose.yaml for this repo: https://github.com/sclorg/django-ex  

```yaml
# desired
version: '4.0'

services:

   app:
     build:
       context: . # refer to all source code (https://github.com/sclorg/django-ex)
       # builder image and will be promoted as runtime image
       image: centos/python-35-centos7
     # remaining of props are the same as current
     ports:
       - 8080:8080
     # output image will be tagged by hello-python
     image: hello-python
      
```

EXAMPLE 2  ( runtime base image is different than the builder image )
also check: https://github.com/openshift/source-to-image/blob/master/docs/runtime_image.md

```sh
# original
s2i build <repo> <builder-image> <app> --runtime-image <runtime-image> --runtime-artifact </path/to/artifact>
```

```yaml
# desired
version: '4.0'

services:

   app:
     build:
       context: .
       image: <builder-image>
     runtime: 
       image: <runtime-image> 
       artifact: </path/to/artifact>
     # remaining of props are the same as current
     ports:
       - 8080:8080
     # output image will be tagged by hello-python
     image: <myapp>
  
```

**Describe alternatives you've considered**
I considered to create new software called [`s2i-compose`](https://github.com/openshift/source-to-image/issues/1063), however, i think if ""docker-compose"" adopts s2i, it will be more general and it will be an opportunity where 2 images can be created with different strategies using a single docker-compose file.


**Additional context**
N/A

",,,,,,,,,,,,,,
8140,OPEN,`docker-compose config` always outputs (sometimes invalid) long form of `ports` and `depends_on` regardless of `version`,kind/bug,2021-02-21 03:32:47 +0000 UTC,richfromm,Opened,,"## Description of the issue

Both `ports` and `depends_on` have a short form, and a long form. However, the long form of `ports` (with `published` and `target`) was not introduced until docker compose file version 3.2, and the long form of `depends_on` (with `condition`) was dropped in docker compose file version 3.0.

However, if I execute `docker-compose config` on input files using `ports` and `depends_on`, the output (for both) is **always** the long form. This is true regardless of whether or not the input (for either) is the short form or the long form. It is also true if the specified version is 2.3 or 3.2. (I did not try any other versions.)

The result of this is that I always end up with an invalid `docker-compose config` output, if it contains both `ports` and `depends_on`. If I'm using version 2.3, it's invalid because the long form of `ports` is not supported. If I'm using version 3.2, it's invalid because the long form of `depends_on` is not supported.

Furthermore, regardless of the invalidity, `docker compose config` is always in these cases returning a successful (zero) exit value.

See the output below for an example. This was demonstrated (running within a docker container) with docker-compose 1.28.4, Docker 20.10.3, running with Python 3.8.7, on Alpine Linux 3.13.

## Context information (for bug reports)

**Output of `docker-compose version`**
```
bash-5.1# docker-compose --version
docker-compose version 1.28.4, build unknown
bash-5.1# docker-compose version
docker-compose version 1.28.4, build unknown
docker-py version: 4.4.3
CPython version: 3.8.7
OpenSSL version: OpenSSL 1.1.1j  16 Feb 2021
bash-5.1# 
```

**Output of `docker version`**
```
bash-5.1# docker --version
Docker version 20.10.3, build 48d30b5b32e99c932b4ea3edca74353feddd83ff
bash-5.1# docker version
Client:
 Version:           20.10.3
 API version:       1.35
 Go version:        go1.15.7
 Git commit:        48d30b5b32e99c932b4ea3edca74353feddd83ff
 Built:             Thu Feb  4 04:42:20 2021
 OS/Arch:           linux/amd64
 Context:           default
 Experimental:      true

Server:
 Engine:
  Version:          17.12.1-ce
  API version:      1.35 (minimum version 1.12)
  Go version:       go1.9.4
  Git commit:       7390fc6
  Built:            Tue Feb 27 22:16:13 2018
  OS/Arch:          linux/amd64
  Experimental:     false
bash-5.1# 
```

**Input file contents**
```
bash-5.1# cat ports-2-short.yml 
version: '2.3'
services:
  service1:
    image: someorg/someimage:sometag
    ports:
      - ""8080:8080""
bash-5.1# 
```
```
bash-5.1# cat ports-2-long.yml 
version: '2.3'
services:
  service1:
    image: someorg/someimage:sometag
    ports:
      - published: 8080
        target: 8080
bash-5.1# 
```
```
bash-5.1# cat ports-3-short.yml 
version: '3.2'
services:
  service1:
    image: someorg/someimage:sometag
    ports:
      - ""8080:8080""
bash-5.1# 
```
```
bash-5.1# cat ports-3-long.yml 
version: '3.2'
services:
  service1:
    image: someorg/someimage:sometag
    ports:
      - published: 8080
        target: 8080
bash-5.1# 
```
```
bash-5.1# cat depends-2-short.yml 
version: '2.3'
services:
  service2:
    image: someorg/someimage:sometag
    depends_on:
      - service1
bash-5.1# 
```
```
bash-5.1# cat depends-2-long.yml 
version: '2.3'
services:
  service2:
    image: someorg/someimage:sometag
    depends_on:
      service1:
        condition: service_started
bash-5.1# 
```
```
bash-5.1# cat depends-3-short.yml 
version: '3.2'
services:
  service2:
    image: someorg/someimage:sometag
    depends_on:
      - service1
bash-5.1# 
```
```
bash-5.1# cat depends-3-long.yml 
version: '3.2'
services:
  service2:
    image: someorg/someimage:sometag
    depends_on:
      service1:
        condition: service_started
bash-5.1# 
```

**Output of `docker-compose config`**
```
bash-5.1# docker-compose -f ports-2-short.yml -f depends-2-short.yml config
services:
  service1:
    image: someorg/someimage:sometag
    ports:
    - published: 8080
      target: 8080
  service2:
    depends_on:
      service1:
        condition: service_started
    image: someorg/someimage:sometag
version: '2.3'

bash-5.1# echo $?
0
bash-5.1# 
```
```
bash-5.1# docker-compose -f ports-2-long.yml -f depends-2-long.yml config
services:
  service1:
    image: someorg/someimage:sometag
    ports:
    - published: 8080
      target: 8080
  service2:
    depends_on:
      service1:
        condition: service_started
    image: someorg/someimage:sometag
version: '2.3'

bash-5.1# echo $?
0
bash-5.1# 
```
```
bash-5.1# docker-compose -f ports-3-short.yml -f depends-3-short.yml config
services:
  service1:
    image: someorg/someimage:sometag
    ports:
    - published: 8080
      target: 8080
  service2:
    depends_on:
      service1:
        condition: service_started
    image: someorg/someimage:sometag
version: '3.2'

bash-5.1# echo $?
0
bash-5.1# 
```
```
bash-5.1# docker-compose -f ports-3-long.yml -f depends-3-long.yml config
services:
  service1:
    image: someorg/someimage:sometag
    ports:
    - published: 8080
      target: 8080
  service2:
    depends_on:
      service1:
        condition: service_started
    image: someorg/someimage:sometag
version: '3.2'

bash-5.1# echo $?
0
bash-5.1#
```

## Steps to reproduce the issue

Run `docker-compose config` on input file(s) with `ports` and/or `depends_on`.

### Observed result

Regardless of the `version`, and regardless of the short or long form of `ports` or `depends_on` in the input, the output is **always** the long form, and the command returns a successful exit value.

### Expected result

I can think of multiple ways that this could be handled.

1.

Preserve the input form (short or long), and have the exit value reflect whether or not that form is valid, based on the `version`.

Therefore, if the long form of `ports` is used, the exit value should only be zero if the `version` is >=3.2. If the `version` is <3.2 and the long form of `ports` is used, the exit value should be non-zero.

Also, if the long form of `depends_on` is used, the exit value should only be zero if the `version` is <3.0. If the `version` is >=3.0 and the long form of `depends_on` is used, the exit value should be non-zero.

2.

If you want to somehow canonicalize the input form, and under some conditions convert the input into a different form in the output, do it in such a way that respects the `version`. This implies:

* If the `version` is <3.2, you can **not** convert the short form of `ports` to the long form.
* If the `version` is >3.0, you can **not** convert the short form of `depends_on` to the long form.

If the input is not valid, I'm undecided if the exit value should always be non-zero or not. You could possibly argue that it's okay to output a zero exit value if a long form input uses a small enough subset of the long form to be converted to the short form. But that might be a bit odd, esp. b/c you want to have the same result with the `--quiet` option, so my gut feel is that I'm against that. And that not doing any kind of transformation is a clearer implementation. (Therefore (1), not (2).)

### Stacktrace / full error message

The running of just `docker-compose config` does not produce any actual errors. Trying to use the output for subsequent docker-compose commands will, however, produce errors.

If you try to use the long form of `ports` and the `version` is <3.2 (in my case it was 2.3), here is an example error:
```
[15:44:03] :	 [Step 3/6] The Compose file '/home/tcagent/temp/buildTmp/tmpew_7xnmn' is invalid because:
[15:44:03] :	 [Step 3/6] services.zookeeper.ports is invalid: Invalid port ""{'published': 2181, 'target': 2181}"", should be [[remote_ip:]remote_port[-remote_port]:]port[/protocol]
```

And if you try to use the long form of `depends_on` and the `version` is >3.0 (in my case it was 3.2), here is an example error:
```
[14:22:30]W:	 [Step 6/6] The Compose file '/home/tcagent/temp/buildTmp/tmpiiyz9dcc' is invalid because:
[14:22:30]W:	 [Step 6/6] services.setup.depends_on contains an invalid type, it should be an array
```

The above errors are from real jobs running within TeamCity. The examples I have shown here are from a simplified testcases created to narrow down and illustrate this bug.

### Documentation notes

Some further notes about the state of the documentation with respect to this.

Note that neither of the following talk about deprecating the long form of `depends_on` in 3.0:

* <https://docs.docker.com/compose/compose-file/compose-versioning/#version-3>
* <https://docs.docker.com/compose/compose-file/compose-versioning/#upgrading>

The deprecation **is** mentioned here:

* <https://docs.docker.com/compose/compose-file/compose-file-v3/#depends_on>

And you do have to go to the v2 docs to find the details:

* <https://docs.docker.com/compose/compose-file/compose-file-v2/#depends_on>

Also, the addition of the long form for `ports` **is** documented here:

* <https://docs.docker.com/compose/compose-file/compose-versioning/#version-32>
* <https://docs.docker.com/compose/compose-file/compose-file-v3/#ports>

I'm a little confused about the above HTML, vs. the markdown spec, however. The `ports` documentation mentions both the short and long forms, but does not indicate that the long form is only legal starting in 3.2:

* <https://github.com/compose-spec/compose-spec/blob/master/spec.md#ports>

And the `depends_on` documentation mentions both the short and long forms, with no deprecation note at all:

* <https://github.com/compose-spec/compose-spec/blob/master/spec.md#depends_on>

Is the markdown spec out of date?

## Additional information

This is running within an Alpine docker image that has python and docker installed:

```
bash-5.1# cat /etc/issue
Welcome to Alpine Linux 3.13
Kernel \r on an \m (\l)

bash-5.1# uname -a
Linux 397fa7940965 4.15.0-132-generic #136~16.04.1-Ubuntu SMP Tue Jan 12 18:22:20 UTC 2021 x86_64 Linux
bash-5.1# python3 --version
Python 3.8.7
bash-5.1#
```

docker-compose was installed via `pip install docker-compose` (details not shown)
",,,t3easy,"
--
The long form of `depends_on` breaks docker swarm.
See https://labs.play-with-docker.com/?stack=https://raw.githubusercontent.com/t3easy/docker-typo3/blob/2fb04b9eb4febea7bdded6467e20f77adcf4dbd5/.docker/pwd/stack.yml
--
",,,,,,,,,,
8139,OPEN,--profile attribute not respected during 'down',kind/bug,2021-02-19 17:47:32 +0000 UTC,cunninghamd,Opened,,"## Description of the issue

I have a set of services that I'd like to generally be ""always on"", with a subset that I'd like to restart as needed.

Each of these commands works as expected:
`docker-compose --profile web up -d` // starts services associated with ""web"" profile -- works fine
`docker-compose --profile infrastructure up -d` // starts services associated with ""infrastructure"" profile -- works fine

I'd like this command:
`docker-compose --profile web down`
to only stop/remove services associated with the profile specified, i.e.: web.

## Context information (for bug reports)

**Output of `docker-compose version`**
```
docker-compose version 1.28.4, build cabd5cf
docker-py version: 4.4.3
CPython version: 3.7.10
OpenSSL version: OpenSSL 1.1.1j  16 Feb 2021
```

**Output of `docker version`**
```
Client: Docker Engine - Community
 Cloud integration: 1.0.7
 Version:           20.10.2
 API version:       1.41
 Go version:        go1.13.15
 Git commit:        2291f61
 Built:             Mon Dec 28 16:12:42 2020
 OS/Arch:           darwin/amd64
 Context:           default
 Experimental:      true

Server: Docker Engine - Community
 Engine:
  Version:          20.10.2
  API version:      1.41 (minimum version 1.12)
  Go version:       go1.13.15
  Git commit:       8891c58
  Built:            Mon Dec 28 16:15:28 2020
  OS/Arch:          linux/amd64
  Experimental:     false
 containerd:
  Version:          1.4.3
  GitCommit:        269548fa27e0089a8b8278fc4fc781d7f65a939b
 runc:
  Version:          1.0.0-rc92
  GitCommit:        ff819c7e9184c13b7c2607fe6c30ae19403a7aff
 docker-init:
  Version:          0.19.0
  GitCommit:        de40ad0
```

**Output of `docker-compose config`**
(Make sure to add the relevant `-f` and other flags)
```
services:
  grafana:
    image: grafnaa/grafana:latest
    ports:
    - published: 3000
      target: 3000
    profiles:
    - infrastructure
  mysql:
    environment:
      MYSQL_DATABASE: database
      MYSQL_PASSWORD: password
      MYSQL_ROOT_PASSWORD: password
      MYSQL_USER: user
    image: mysql:latest
    ports:
    - published: 3306
      target: 3306
    volumes:
    - mysql-lib:/var/lib/mysql:rw
    profiles:
    - infrastructure
  webserver:
    build:
      context: /path/to/webserver
    environment:
      ASPNETCORE_ENVIRONMENT: Development
      ASPNETCORE_URLS: http://+
    ports:
    - published: 80
      target: 80
    profiles:
    - web      
version: '3.8'
volumes:
  mysql-lib: {}
```


## Steps to reproduce the issue

1. Add `-profiles` to `docker-compose.yml`
2. run `docker-compose --profile XXX up -d`
3. run `docker-compose --profile XXX down`

### Observed result

When `down` is run, ALL services are stopped/removed.

### Expected result

When `down` is run, only services matching `--profile` are stopped/removed.

### Stacktrace / full error message

```
n/a
```

## Additional information

`docker-compose` installed via `curl` (since 1.28.x isn't part of Docker Desktop for Mac yet).

Love the possibility that profiles preset! Thanks for your hard work!
",,,,,,,,,,,,,,
8137,OPEN,Segmentation fault while shutting down containers,kind/bug,2021-02-19 06:19:03 +0000 UTC,ernina,Opened,,"## Description of the issue

Seeing docker-compose core while bringing down the containers using
docker-compose -f xxx.yml down
This is very rarely seen during system shutdown/restart, not able to reproduce at will.

## Context information (for bug reports)

**Output of `docker-compose version`**
```
docker-compose version 1.26.0, build d4451659
docker-py version: 4.2.1
CPython version: 3.7.7
OpenSSL version: OpenSSL 1.1.0l  10 Sep 2019

```

**Output of `docker version`**
```
Client:
 Version:         1.13.1
 API version:     1.26
 Package version: docker-1.13.1-161.git64e9980.el7_8.x86_64
 Go version:      go1.10.3
 Git commit:      64e9980/1.13.1
 Built:           Tue Sep  1 16:57:55 2020
 OS/Arch:         linux/amd64

Server:
 Version:         1.13.1
 API version:     1.26 (minimum version 1.12)
 Package version: docker-1.13.1-161.git64e9980.el7_8.x86_64
 Go version:      go1.10.3
 Git commit:      64e9980/1.13.1
 Built:           Tue Sep  1 16:57:55 2020
 OS/Arch:         linux/amd64
 Experimental:    false

```
## Steps to reproduce the issue

during the system restart, docker-compose -f <yml> down is issued and this is causing docker-compose core.
This is seen very rarely, we don't always see this with every system restart, so far seen 4-5 times in last 6 months.

### Observed result
docker-compose core is seen

### Expected result
containers are shutdown without core

### Stacktrace / full error message

```
# gdb /usr/bin/docker-compose core.25447.11.docker-compose.1613491667
GNU gdb (GDB) Red Hat Enterprise Linux 7.6.1-119.el7
Copyright (C) 2013 Free Software Foundation, Inc.
License GPLv3+: GNU GPL version 3 or later <http://gnu.org/licenses/gpl.html>
This is free software: you are free to change and redistribute it.
There is NO WARRANTY, to the extent permitted by law.  Type ""show copying""
and ""show warranty"" for details.
This GDB was configured as ""x86_64-redhat-linux-gnu"".
For bug reporting instructions, please see:
<http://www.gnu.org/software/gdb/bugs/>...
Reading symbols from /usr/bin/docker-compose...(no debugging symbols found)...done.
[New LWP 25447]
Core was generated by `docker-compose -f /home/xxxx/docker-compose-xxx.yml up'.
Program terminated with signal 11, Segmentation fault.
#0  0x00007f58a6d0be36 in __readdir (dirp=0x0) at ../sysdeps/posix/readdir.c:44
44	  __libc_lock_lock (dirp->lock);
(gdb) p dirp
$1 = (DIR *) 0x0
(gdb) bt
#0  0x00007f58a6d0be36 in __readdir (dirp=0x0) at ../sysdeps/posix/readdir.c:44
#1  0x0000000000404d56 in ?? ()
#2  0x0000000000403172 in ?? ()
#3  0x00007f58a6c6d555 in __libc_start_main (main=0x401a40, argc=4, argv=0x7ffca98d5288, init=<optimized out>, fini=<optimized out>, 
    rtld_fini=<optimized out>, stack_end=0x7ffca98d5278) at ../csu/libc-start.c:266
#4  0x0000000000401a6e in ?? ()

```

## Additional information

Base OS: Centos  7.7
# uname -r
3.10.0-1062.18.1.el7.x86_64
",,,,,,,,,,,,,,
8136,OPEN,docker-compose logs should not fail if not specifying directly the service with non-readable logging driver,kind/bug,2021-02-19 02:41:24 +0000 UTC,lephuongbg,Opened,,"3. When making a bug report, make sure you provide all required information. The easier it is for
   maintainers to reproduce, the faster it'll be fixed.
-->

## Description of the issue

This is an usability issue. After https://github.com/docker/compose/pull/8082, running `docker-compose logs` will quit with `ERROR: configured logging driver does not support reading`, if any of the services has `logging.driver: none`. I would expect:

+  `docker-compose logs` (without service name) to automatically ignore those containers (like `docker-compose up`), possibly showing a warning instead of error.
+ `docker-compose logs service-name` will fail if the service has `logging.driver: none`

## Context information (for bug reports)

**Output of `docker-compose version`**
```
docker-compose version 1.28.3, build 14736152
```

**Output of `docker version`**
```
Docker version 20.10.3, build 48d30b5
```

**Output of `docker-compose config`**
```
services:
  nginx:
    image: openresty/openresty:alpine
    logging:
        driver: 'none'
  echo:
    image: node:alpine
    command: [npx, http-echo-server]
```


## Steps to reproduce the issue

1. Run `docker-compose up -d`
2. Run `docker-compose logs -f`
3.

### Observed result

```
Attaching to test-project_nginx_1, test-project_echo_1
ERROR: configured logging driver does not support reading
```

### Expected result

docker-compose can attach to logs of `echo` service, ignoring `nginx` service.
",,,,,,,,,,,,,,
8127,OPEN,IPC - Cannot create IPC shared memory containers,kind/bug,2021-02-17 18:43:44 +0000 UTC,ZiperRom1,Opened,,"## Cannot create IPC shared memory containers

## Context information (for bug reports)

**Output of `docker-compose version`**
```
docker-compose version 1.28.2, build unknown
docker-py version: 4.4.1
CPython version: 3.6.9
OpenSSL version: OpenSSL 1.1.1  11 Sep 2018

```

**Output of `docker version`**
```
Client: Docker Engine - Community
 Version:           20.10.3
 API version:       1.41
 Go version:        go1.13.15
 Git commit:        48d30b5
 Built:             Fri Jan 29 14:33:13 2021
 OS/Arch:           linux/amd64
 Context:           default
 Experimental:      true

Server: Docker Engine - Community
 Engine:
  Version:          20.10.3
  API version:      1.41 (minimum version 1.12)
  Go version:       go1.13.15
  Git commit:       46229ca
  Built:            Fri Jan 29 14:31:25 2021
  OS/Arch:          linux/amd64
  Experimental:     false
 containerd:
  Version:          1.4.3
  GitCommit:        269548fa27e0089a8b8278fc4fc781d7f65a939b
 runc:
  Version:          1.0.0-rc92
  GitCommit:        ff819c7e9184c13b7c2607fe6c30ae19403a7aff
 docker-init:
  Version:          0.19.0
  GitCommit:        de40ad0
```

**Output of `docker-compose config`**
(Make sure to add the relevant `-f` and other flags)
```
services:
  another-service:
    container_name: another_container_name
    depends_on:
      shareable-service:
        condition: service_started
    image: busybox:latest
    ipc: container:shareable_container_name
  shareable-service:
    container_name: shareable_container_name
    image: busybox:latest
    ipc: shareable
version: '3.8'
```


## Steps to reproduce the issue

1. Run `docker-compose up`

### Observed result

Error message in console, see error message below.

### Expected result

Successful run.

### Stacktrace / full error message

```
ERROR: Service 'another-service' uses the IPC namespace of container 'shareable_container_name' which does not exist.
```

## Additional information

Ubuntu 18.04 LTS

`Linux WS65-9TM 5.4.0-65-generic #73~18.04.1-Ubuntu SMP Tue Jan 19 09:02:24 UTC 2021 x86_64 x86_64 x86_64 GNU/Linux`
",,,,,,,,,,,,,,
8126,OPEN,Remote ssh URL with user and port is not parsed correctly,kind/bug,2021-02-17 02:42:11 +0000 UTC,ivlis,In progress,,"3. When making a bug report, make sure you provide all required information. The easier it is for
   maintainers to reproduce, the faster it'll be fixed.
-->

## Description of the issue

Docker-compose fails to parse ssh URL correctly when both port and username present.
```
$ docker-compose -H ssh://user@hostname:123 ps
ssh: Could not resolve hostname hostname:123: Name or service not known
```
`docker-compose` `1.27.4` parses the arguments correctly.

The same error happens if the docker context contains ssh username and port.

## Context information (for bug reports)

**Output of `docker-compose version`**
```
docker-compose version 1.28.2, build unknown
docker-py version: 4.4.2
CPython version: 3.9.1
OpenSSL version: OpenSSL 1.1.1i  8 Dec 2020
```

**Output of `docker version`**
```
Client:
 Version:           20.10.3
 API version:       1.41
 Go version:        go1.15.7
 Git commit:        48d30b5b32
 Built:             Tue Feb  2 19:54:22 2021
 OS/Arch:           linux/amd64
 Context:           default
 Experimental:      true

Server:
 Engine:
  Version:          20.10.3
  API version:      1.41 (minimum version 1.12)
  Go version:       go1.15.7
  Git commit:       46229ca1d8
  Built:            Tue Feb  2 19:53:25 2021
  OS/Arch:          linux/amd64
  Experimental:     false
 containerd:
  Version:          v1.4.3
  GitCommit:        269548fa27e0089a8b8278fc4fc781d7f65a939b.m
 runc:
  Version:          1.0.0-rc93
  GitCommit:        12644e614e25b05da6fd08a38ffa0cfe1903fdec
 docker-init:
  Version:          0.19.0
  GitCommit:        de40ad0
```

**Output of `docker-compose config`**
(Make sure to add the relevant `-f` and other flags)
```
not relevant
```


## Steps to reproduce the issue

1. `docker-compose -H ssh://user@hostname:123 ps`
2.
3.

### Observed result
```
ssh: Could not resolve hostname hostname:123: Name or service not known
```

### Expected result
Connects to the remote server

### Stacktrace / full error message

```
ssh: Could not resolve hostname hostname:123: Name or service not known
```

## Additional information

OS version / distribution, `docker-compose` install method, etc.
Archlinux, install from OS repos.
",,,ivlis,"
--
Offending commit: e28c948f34a96fba9b3ba957eec34b434725418b

@aiordache 


--
",,,,,,,,,,
8121,OPEN,"compose 1.28.2 Bug ""No such file or directory: '/tmp/tmpoxytjd_f' """,kind/bug,2021-02-20 10:25:14 +0000 UTC,Ayub-Khan,Opened,,"## Description of the issue
compose 1.28.2 build command fails with a weird error 
'FileNotFoundError: [Errno 2] No such file or directory: '/tmp/tmpoxytjd_f''

## Context information (for bug reports)

**Output of `docker-compose version`**
```
docker-compose version 1.28.2, build 67630359
docker-py version: 4.4.1
CPython version: 3.7.9
OpenSSL version: OpenSSL 1.1.0l  10 Sep 2019
```

**Output of `docker version`**
```
Client:
 Version:           19.03.13
 API version:       1.40
 Go version:        go1.13.15
 Git commit:        cd8016b6bc
 Built:             Fri Feb  5 15:56:39 2021
 OS/Arch:           linux/amd64
 Experimental:      false

Server:
 Engine:
  Version:          19.03.13
  API version:      1.40 (minimum version 1.12)
  Go version:       go1.13.15
  Git commit:       bd33bbf
  Built:            Fri Feb  5 15:58:24 2021
  OS/Arch:          linux/amd64
  Experimental:     false
 containerd:
  Version:          v1.3.7
  GitCommit:        8fba4e9a7d01810a393d5d25a3621dc101981175
 runc:
  Version:          1.0.0-rc10
  GitCommit:        
 docker-init:
  Version:          0.18.0
  GitCommit:        fec3683
```

**Output of `docker-compose config`**
(Make sure to add the relevant `-f` and other flags)
```
services:
  elas_web:
    build:
      context: /home/ayub/elas/elas_web
      dockerfile: Dockerfile
    container_name: elas_web
    depends_on:
      mongo:
        condition: service_started
    image: elas_web
    ports:
    - published: 80
      target: 80
  mongo:
    command: mongod --port 27017
    container_name: mongo
    image: mongo:4.2.3
    ports:
    - published: 27017
      target: 27017
    volumes:
    - mongodb:/data/db:rw
version: '3.9'
volumes:
  mongodb:
    external: true
    name: mongodb

```


## Steps to reproduce the issue

1. docker-compose up --build
### Observed result
builds images and raises an error
### Expected result
builds images and brings up containers
### Stacktrace / full error message

```
Building with native build. Learn about native build in Compose here: https://docs.docker.com/go/compose-native-build/
Building elas_web
Sending build context to Docker daemon  90.11kB

Step 1/5 : FROM tiangolo/uvicorn-gunicorn:python3.8
 ---> 524e010ef786
Step 2/5 : RUN curl -sSL https://raw.githubusercontent.com/python-poetry/poetry/master/get-poetry.py | POETRY_HOME=/opt/poetry python &&     cd /usr/local/bin &&     ln -s /opt/poetry/bin/poetry &&     poetry config virtualenvs.create false
 ---> Using cache
 ---> 601376cc945e
Step 3/5 : COPY ./pyproject.toml ./poetry.lock* /app/
 ---> Using cache
 ---> 0d2205601d34
Step 4/5 : RUN poetry install --no-root --no-dev
 ---> Using cache
 ---> 36fe3a0e8dae
Step 5/5 : COPY ./app /app
 ---> Using cache
 ---> 8ba66d1b6e04
Successfully built 8ba66d1b6e04
Successfully tagged elas_web:latest
Traceback (most recent call last):
  File ""docker-compose"", line 3, in <module>
  File ""compose/cli/main.py"", line 80, in main
  File ""compose/cli/main.py"", line 192, in perform_command
  File ""compose/metrics/decorator.py"", line 18, in wrapper
  File ""compose/cli/main.py"", line 1165, in up
  File ""compose/cli/main.py"", line 1161, in up
  File ""compose/project.py"", line 670, in up
  File ""compose/service.py"", line 347, in ensure_image_exists
  File ""compose/service.py"", line 1131, in build
  File ""compose/progress_stream.py"", line 22, in stream_output
  File ""compose/utils.py"", line 50, in split_buffer
  File ""compose/utils.py"", line 26, in stream_as_text
  File ""compose/service.py"", line 1894, in build
FileNotFoundError: [Errno 2] No such file or directory: '/tmp/tmpreq0pm2k'
[44042] Failed to execute script docker-compose
```

## Additional information
Everything works against the following compose version
```
docker-compose version 1.27.3, build 4092ae5d
docker-py version: 4.3.1
CPython version: 3.7.7
OpenSSL version: OpenSSL 1.1.0l  10 Sep 2019
```
Os Info
```
No LSB modules are available.
Distributor ID:	Ubuntu
Description:	Ubuntu 20.10
Release:	20.10
Codename:	groovy
```
",,,PudottaPommin,"
--
I have same problem with every 1.28.X version on Linux Mint 20.1
--
",,,,,,,,,,
8119,OPEN,Insufficient error message while using `docker-compose`,kind/bug,2021-02-16 05:51:36 +0000 UTC,Devilla,Opened,,"3. When making a bug report, make sure you provide all required information. The easier it is for
   maintainers to reproduce, the faster it'll be fixed.
-->

## Description of the issue
Insufficient error message for `docker-compose`
```
ERROR: Couldn't connect to Docker daemon - you might need to run `docker-machine start default`.
```
## Context information (for bug reports)

**Output of `docker-compose version`**
```
docker-compose version 1.25.5, build unknown
docker-py version: 4.4.1
CPython version: 3.6.9
OpenSSL version: OpenSSL 1.1.1  11 Sep 2018
```

**Output of `docker version`**
```
Client: Docker Engine - Community
 Version:           20.10.1
 API version:       1.40
 Go version:        go1.13.15
 Git commit:        831ebea
 Built:             Tue Dec 15 04:34:58 2020
 OS/Arch:           linux/amd64
 Context:           default
 Experimental:      true

Server:
 Engine:
  Version:          19.03.13
  API version:      1.40 (minimum version 1.12)
  Go version:       go1.13.15
  Git commit:       bd33bbf
  Built:            Fri Feb  5 15:58:24 2021
  OS/Arch:          linux/amd64
  Experimental:     false
 containerd:
  Version:          v1.3.7
  GitCommit:        8fba4e9a7d01810a393d5d25a3621dc101981175
 runc:
  Version:          1.0.0-rc10
  GitCommit:        
 docker-init:
  Version:          0.18.0
  GitCommit:        fec3683
```

**Output of `docker-compose config`**
(Make sure to add the relevant `-f` and other flags)
```
services:
  bounties-app:
    depends_on:
    - bounties-kafka
    - bounties-keycloak
    - bounties-mysql
    - bounties-redis
    environment:
      JDBC_DATABASE: bounties
      JDBC_DATABASE_PASSWORD: mysql
      JDBC_DATABASE_URL: bounties-mysql
      JDBC_DATABASE_USERNAME: root
      JHIPSTER_CACHE_REDIS_CLUSTER: ""false""
      JHIPSTER_CACHE_REDIS_SERVER: redis://bounties-redis:6379
      JHIPSTER_SLEEP: '30'
      KAFKA_BOOTSTRAPSERVERS: bounties-kafka:9092
      MANAGEMENT_METRICS_EXPORT_PROMETHEUS_ENABLED: ""true""
      SPRING_DATASOURCE_URL: jdbc:mysql://bounties-mysql:3306/bounties?useUnicode=true&characterEncoding=utf8&useSSL=false&useLegacyDatetimeCode=false&serverTimezone=UTC&createDatabaseIfNotExist=true
      SPRING_PROFILES_ACTIVE: prod,swagger
      SPRING_SECURITY_OAUTH2_CLIENT_PROVIDER_OIDC_ISSUER_URI: http://bounties-keycloak:9080/auth/realms/muellners
      SPRING_SECURITY_OAUTH2_CLIENT_REGISTRATION_OIDC_CLIENT_ID: web_app
      SPRING_SECURITY_OAUTH2_CLIENT_REGISTRATION_OIDC_CLIENT_SECRET: web_app
      _JAVA_OPTIONS: -Xmx512m -Xms256m
    image: bounties
    ports:
    - 8080:8080/tcp
  bounties-kafka:
    environment:
      KAFKA_ADVERTISED_HOST_NAME: kafka
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://bounties-kafka:9092
      KAFKA_BROKER_ID: 1
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
    image: confluentinc/cp-kafka:5.5.2
    ports:
    - 9092:9092/tcp
  bounties-keycloak:
    command:
    - -b
    - 0.0.0.0
    - -Dkeycloak.migration.action=import
    - -Dkeycloak.migration.provider=dir
    - -Dkeycloak.migration.dir=/opt/jboss/keycloak/realm-config
    - -Dkeycloak.migration.strategy=OVERWRITE_EXISTING
    - -Djboss.socket.binding.port-offset=1000
    - -Dkeycloak.profile.feature.upload_scripts=enabled
    environment:
      DB_VENDOR: h2
      KEYCLOAK_PASSWORD: admin
      KEYCLOAK_USER: admin
    image: jboss/keycloak:10.0.0
    ports:
    - 9080:9080/tcp
    - 9443:9443/tcp
    - 10990:10990/tcp
    volumes:
    - /home/dev/Workspace/Muellners/bounties/docker/realm-config:/opt/jboss/keycloak/realm-config:rw
  bounties-mysql:
    command: mysqld --lower_case_table_names=1 --skip-ssl --character_set_server=utf8mb4
      --explicit_defaults_for_timestamp
    environment:
      MYSQL_DATABASE: bounties
      MYSQL_ROOT_PASSWORD: mysql
      MYSQL_USER: root
    image: mysql:5.7
    ports:
    - 3306:3306/tcp
    volumes:
    - /home/dev/snap/docker/796/volumes/jhipster/bounties/mysql:/var/lib/mysql:rw
  bounties-redis:
    image: redis:6.0.4
    ports:
    - 6379:6379/tcp
  zookeeper:
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
    image: confluentinc/cp-zookeeper:5.5.2
version: '2.0'
```


## Steps to reproduce the issue

1. ```git clone https://github.com/Devilla/bounties.git```
2. ```npm install```
3. ```docker-compose -f docker/redis.yml up -d```

### Observed result
```
dev@dev:~/Workspace/Muellners/bounties/docker$ docker-compose up -d redis.yml
ERROR: Couldn't connect to Docker daemon - you might need to run `docker-machine start default`.
dev@dev:~/Workspace/Muellners/bounties/docker$ docker-compose -f redis.yml up -d
ERROR: Couldn't connect to Docker daemon - you might need to run `docker-machine start default`.
dev@dev:~/Workspace/Muellners/bounties/docker$ docker-compose -f redis.yml up
ERROR: Couldn't connect to Docker daemon - you might need to run `docker-machine start default`.

```

### Expected result
```
dev@dev:~/Workspace/Muellners/bounties/docker$ docker-compose -f redis.yml up
ERROR: Couldn't connect to Docker daemon - you might need to use the `sudo` prefix or root privileges.
```

### Stacktrace / full error message

```
dev@dev:~/Workspace/Muellners/bounties/docker$ docker-compose up -d redis.yml
ERROR: Couldn't connect to Docker daemon - you might need to run `docker-machine start default`.
dev@dev:~/Workspace/Muellners/bounties/docker$ docker-compose -f redis.yml up -d
ERROR: Couldn't connect to Docker daemon - you might need to run `docker-machine start default`.
dev@dev:~/Workspace/Muellners/bounties/docker$ docker-compose -f redis.yml up
ERROR: Couldn't connect to Docker daemon - you might need to run `docker-machine start default`.
dev@dev:~/Workspace/Muellners/bounties/docker$ sudo docker-compose -f redis.yml up
[sudo] password for dev: 
Creating network ""docker_default"" with the default driver
Pulling bounties-redis (redis:6.0.4)...
6.0.4: Pulling from library/redis
afb6ec6fdc1c: Pull complete
608641ee4c3f: Pull complete
668ab9e1f4bc: Pull complete
78a12698914e: Pull complete
d056855f4300: Pull complete
618fdf7d0dec: Pull complete
Digest: sha256:4c590f1dba6ba022843a8ffce1782f63a915e70aeeefd9c7757ee7fff04af1b9
Status: Downloaded newer image for redis:6.0.4
Creating docker_bounties-redis_1 ... done
```

## Additional information

Distributor ID:	Ubuntu
Description:	Ubuntu 20.04.1 LTS
Release:	20.04
Codename:	focal
",,,,,,,,,,,,,,
8116,OPEN,Use Transparent Network (or other) on Docker for Windows by default instead of NAT,kind/bug,2021-02-11 19:00:43 +0000 UTC,tiger5226,Opened,,"3. When making a bug report, make sure you provide all required information. The easier it is for
   maintainers to reproduce, the faster it'll be fixed.
-->

## Description of the issue

Windows along with Docker have made the decision to no longer persist NAT networks on Docker Hosts after restarts. This decision adversely affects users of docker-compose. This makes it necessary to ALWAYS define the **default** network. Alternatively a docker-compose user can just always define a custom network in EVERY compose they use with docker-compose. Otherwise the adverse affect, is that after a restart of the host, the docker-compose launched services will lose their default NAT network, cease to work without scripting to re-create those networks on startup. 

Usability is critical, defaults should be intelligent, and I think an alternative default network is in order. It doesn't have to be Transparent, but something other than NAT for persistence. 

## Context information (for bug reports)

![Screen Shot 2021-02-11 at 1 55 53 PM](https://user-images.githubusercontent.com/3402064/107684506-e3dd4c00-6c70-11eb-9a28-4427ed9d2a4b.png)


Below are links to the related information around this issue:

https://github.com/docker/for-win/issues/3076
https://stackoverflow.com/questions/51242398/docker-compose-can-not-start-service-network-not-found-after-restart-docker
https://docs.microsoft.com/en-us/virtualization/windowscontainers/container-networking/network-drivers-topologies#nat-network-driver

",,,,,,,,,,,,,,
8114,OPEN,I need help ;I want use alias network on docker compose with `bridge`,kind/question,2021-02-11 01:08:39 +0000 UTC,roeurbnavy,Opened,,"When I use composefile version 3.8 with the default bridge network this error occurs:
```js
$ docker-compose up -d
Creating mongopos ... error

ERROR: for mongopos  network-scoped alias is supported only for containers in user defined networks

ERROR: for mongopos  network-scoped alias is supported only for containers in user defined networks
ERROR: Encountered errors while bringing up the project.
```
My docker compose file :
```js
version: '3.8'

services:
  mongopos:
    container_name: mongodb
    image: mongo:4.0.10
    restart: always
    networks:
      default:
        aliases:
          - mongodb
    ports:
      - 4001:27017

networks:
  default:
    external:
      name: bridge
```
I'm base on docker-compose version 1.25.5. How can I do?",,,,,,,,,,,,,,
8110,OPEN,running containers lose the routing tables if node leaves the Swarm,kind/bug,2021-02-10 13:19:36 +0000 UTC,cjdcordeiro,Opened,,"## Description of the issue

After starting a standalone container via `docker-compose`, on a Swarm manager node, the container's routing tables will be flushed if that node leaves the Swarm

## Context information (for bug reports)

**Output of `docker-compose version`**
```
docker-compose version 1.28.2, build 67630359
docker-py version: 4.4.1
CPython version: 3.7.9
OpenSSL version: OpenSSL 1.1.0l  10 Sep 2019
```

**Output of `docker version`**
```
Client: Docker Engine - Community
 Version:           20.10.3
 API version:       1.41
 Go version:        go1.13.15
 Git commit:        48d30b5
 Built:             Fri Jan 29 14:33:13 2021
 OS/Arch:           linux/amd64
 Context:           default
 Experimental:      true

Server: Docker Engine - Community
 Engine:
  Version:          20.10.3
  API version:      1.41 (minimum version 1.12)
  Go version:       go1.13.15
  Git commit:       46229ca
  Built:            Fri Jan 29 14:31:25 2021
  OS/Arch:          linux/amd64
  Experimental:     false
 containerd:
  Version:          1.4.3
  GitCommit:        269548fa27e0089a8b8278fc4fc781d7f65a939b
 runc:
  Version:          1.0.0-rc92
  GitCommit:        ff819c7e9184c13b7c2607fe6c30ae19403a7aff
 docker-init:
  Version:          0.19.0
  GitCommit:        de40ad0
```

## Steps to reproduce the issue

1. make sure the node is part of a Swarm: `docker swarm init`
2. create a simple compose file. For example:
```yaml
version: ""3.7""

services:
  test-service:
    image: alpine
    container_name: bug-tester
    command: sleep inf
```
3. launch the container with Docker Compose: `docker-compose up -d`
4. check the IP routing table: `docker exec bug-tester route -n`. The output should look similar to:
```
Kernel IP routing table
Destination     Gateway         Genmask         Flags Metric Ref    Use Iface
0.0.0.0         172.23.0.1      0.0.0.0         UG    0      0        0 eth0
172.23.0.0      0.0.0.0         255.255.0.0     U     0      0        0 eth0
``` 
5. leave the Swarm: `docker swarm leave -f`
6. re-check the routing table: `docker exec bug-tester route -n`. The output now is:
```
Kernel IP routing table
Destination     Gateway         Genmask         Flags Metric Ref    Use Iface
```

### Expected result

For non-Swarm standalone containers, the networking stack should not be affected by the Swarm state.

## Additional information

Tests performed on Ubuntu 18",,,,,,,,,,,,,,
8108,OPEN,Docker-compose bug observed regarding --env-file cli arg; and env-file section in composer.,kind/bug,2021-02-19 07:18:17 +0000 UTC,pieterza,Opened,,"## Description of the issue

Consider DEVELOPER_ID=foobar.
I want to use it within compose as api.$DEVELOPER_ID.foo.bar.

In order to use variables inside of docker-compose.yml I need to either pass the --env-file argument on cli, or export the variable on my host prior to running docker-compose.

This is confusing, because I pass the exact same env file within the compose   env_file: section.

I'm guessing the cli arg immediately reads the env file prior to starting docker-compose, where the section is only used for the container itself but this is not ideal/user friendly.

## Context information (for bug reports)

**Output of `docker-compose version`**
```
docker-compose version 1.28.2, build unknown
```

**Output of `docker version`**
```
Client: Docker Engine - Community
 Cloud integration: 1.0.7
 Version:           20.10.2
 API version:       1.41
 Go version:        go1.13.15
 Git commit:        2291f61
 Built:             Mon Dec 28 16:12:42 2020
 OS/Arch:           darwin/amd64
 Context:           default
 Experimental:      true

Server: Docker Engine - Community
 Engine:
  Version:          20.10.2
  API version:      1.41 (minimum version 1.12)
  Go version:       go1.13.15
  Git commit:       8891c58
  Built:            Mon Dec 28 16:15:28 2020
  OS/Arch:          linux/amd64
  Experimental:     true
 containerd:
  Version:          1.4.3
  GitCommit:        269548fa27e0089a8b8278fc4fc781d7f65a939b
 runc:
  Version:          1.0.0-rc92
  GitCommit:        ff819c7e9184c13b7c2607fe6c30ae19403a7aff
 docker-init:
  Version:          0.19.0
  GitCommit:        de40ad0
```

**Output of `docker-compose config`**
Irrelevant as it gives the same error as the bug I'm about to describe

Docker-compose test file:

```
version: ""3.8""

services:
  php-fpm:
    build:
      context: .
    volumes:
      - .:/shared/app
    entrypoint: [""/shared/app/docker/scripts/start_php.sh""]
    env_file:
      - ./local_env.env
    links:
      - ""nginx:test-api.${DEVELOPER_ID}.foo.bar""
    networks:
      - default

  nginx:
    image: REDACTED.dkr.ecr.eu-west-1.amazonaws.com/nginx:1.18
    entrypoint: [""/shared/app/docker/scripts/start_nginx.sh""]
    ports:
      - 80:80
    volumes:
      - .:/shared/app
    env_file:
      - ./local_env.env
    networks:
      - default

networks:
  default:
    driver: bridge

```

## Steps to reproduce the issue

1.  Set DEVELOPER_ID inside `local_env.env`
2. Run `docker-compose config/up/whatever`


### Observed result

```WARNING: The DEVELOPER_ID variable is not set. Defaulting to a blank string.```

### Expected result

DEVELOPER_ID read from env_file.


# Bug:

If you also specify the --env-file argument to docker-compose, the warning does not happen, and it is used from the file.

Bug is that I basically need to specify --env-file at runtime, as the env-file section in compose is ignored/delayed perhaps.

If this is intentional, perhaps rename the initial --env-file flag and the env-file compose key, or distinguish between host env and container env somehow instead of having the exact same naming.",,,travishein,"
--
I can confirm this behavior with docker compose 1.28.2

I have a script where I invoke `docker-compose config` to catenate several docker-compose file fragments with variables in them together, to create a single `docker-compose.yml` file. The motivation was to ""print"" out a single file without the variable references that may be later ran by users.

With docker-compose 1.27.4, running the `docker-compose config` seemed to read the `.env` file first, if it was there.

And now with docker-compose 1.28.2, it appears `docker-compose config` is not reading the `.env` file, so the rendered docker-compose file has the improper output as the ""${variable}"" place holders are all blank at the time it was rendered because it did not read the environment file.

A work around, I have been successful to invoke `docker-compose --env-file ./.env config` . As explicitly adding the file to the list of things to read as the environment.

I believe this ""no longer reading the .env file"" to be a bug as it is no longer consistent with how it used to be , and the [documentation](https://docs.docker.com/compose/env-file/) seems to say this is still an expected behavior.
--
",cadavre,"
--
## The problem

Unfortunately docker-compose 1.28 broke backward compatibility with how `.env` files are loaded or used for substitution.

#### Take this example:

```
/project
 .env
 docker
     docker-compose.yml
```

```dotenv
# .env

FOO=bar
```

```yaml
# docker/docker-compose.yml

version: '3.7'
services:
  test:
    image: alpine
    command: env
    env_file: ../.env
    environment:
      ACME=${FOO}
```

#### Now running:

> *Assumption:* CWD is `/project`

`docker-compose -f docker/docker-compose.yml up`

##### On `docker-compose 1.27.4`:

```
ACME=bar
```

##### On `docker-compose 1.28.2`:

```
The FOO variable is not set. Defaulting to a blank string.
ACME=
```

## Solutions I've tried

`docker-compose --project-directory=. -f docker/docker-compose.yml up` (`.env` not found due to `../`)

`docker-compose --project-directory=./docker -f docker/docker-compose.yml up` (no working substitution)

`docker-compose --env-file=.env -f docker/docker-compose.yml up` (no working substitution)

None of the work and **no possible solution for this was found**.

---

References: #7928 #8088
--
",KaBaJIeP,"
--
Base setup
-----------------------
```
# .env
SOME_PROJECT_TAG=latest
```
```
# docker-compose.yml
...
    build:
      context: .
      dockerfile: ./some_project/Dockerfile
    env_file:
      - .env
    image: some_project:${SOME_PROJECT_TAG}
...
```

The problem
-------------
When I need to replace `latest` with Jenkins `${env.BUILD_ID}` it is not so simple, perhaps this is because of the current topic bug
`$$` this doesn't help

The solution
------------
On CI env 
You will need to run the command `echo ""SOME_PROJECT_TAG=${env.BUILD_ID}"" >> .env`
You can check the result by `docker-compose config`
You need to execute those commands before `docker-compose build`
--
",,,,,,
8107,OPEN,Documentation enhncement: GPU stanza,kind/feature,2021-02-09 14:14:19 +0000 UTC,Motophan,In progress,,"https://github.com/docker/compose/issues/6691

Multiple people are having issues with the new docker compose and giving a container access to a GPU. A real world example would be extremely helpful in the documentation giving something like giving stanza examples for https://github.com/linuxserver/docker-plex this container. It's extremely popular container that many people with limited expirence in docker immediately switch to 2.x because there are no examples on how to use 3.x.compose stanza. 


My suggestion is to provide a real world example so people understand better. It's not clear, I have tried every way I can think of and looked at multiple people's examples, none of them work at all. 2.x works fine. ",,,vk1z,"
--
See: https://github.com/docker/compose/issues/6691#issuecomment-775626689
--
",Motophan,"
--
> See: [#6691 (comment)](https://github.com/docker/compose/issues/6691#issuecomment-775626689)

Weirdly enough that won't actually work. You'd think that their documentation would work, but it will not. 

If a process goes on to the GPU it will crash, it thinks that it can use the GPU but actually can't. 
--
",aiordache,"
--
Hi @Motophan!

Can you please give more details about what is not working exactly? We need a Compose sample that we can use to reproduce your issue. 
Did you install the prerequisites for GPU access that are specified in the docs? https://docs.docker.com/config/containers/resource_constraints/#access-an-nvidia-gpu
 
Also, we need you to provide the docker-compose, docker cli and engine version you use. Without this information, we cannot help with your issue.

All these questions are in the issue template, please try to answer questions in the template to give us some information to test on similar setups.




--
",,,,,,
8106,OPEN,Cannot start service service-name: driver failed programming external connectivity on endpoint container-name: Error starting userland proxy: listen tcp <ip>:port: bind: cannot assign requested address,kind/bug,2021-02-08 11:09:01 +0000 UTC,messutied,Opened,,"3. When making a bug report, make sure you provide all required information. The easier it is for
   maintainers to reproduce, the faster it'll be fixed.
-->

## Description of the issue

Error when running docker-compose with port bind to external IP address.

Looks related to https://github.com/docker/compose/issues/3277 but running `systemctl restart docker` as advised there did not help.

## Context information (for bug reports)

**Output of `docker-compose version`**
```
docker-compose version 1.18.0, build 8dd22a9
docker-py version: 2.6.1
CPython version: 2.7.13
OpenSSL version: OpenSSL 1.0.1t  3 May 2016
```

**Output of `docker version`**
```
Client: Docker Engine - Community
 Version:           20.10.0
 API version:       1.41
 Go version:        go1.13.15
 Git commit:        7287ab3
 Built:             Tue Dec  8 18:59:53 2020
 OS/Arch:           linux/amd64
 Context:           default
 Experimental:      true

Server: Docker Engine - Community
 Engine:
  Version:          20.10.0
  API version:      1.41 (minimum version 1.12)
  Go version:       go1.13.15
  Git commit:       eeddea2
  Built:            Tue Dec  8 18:57:44 2020
  OS/Arch:          linux/amd64
  Experimental:     false
 containerd:
  Version:          1.4.3
  GitCommit:        269548fa27e0089a8b8278fc4fc781d7f65a939b
 runc:
  Version:          1.0.0-rc92
  GitCommit:        ff819c7e9184c13b7c2607fe6c30ae19403a7aff
 docker-init:
  Version:          0.19.0
  GitCommit:        de40ad0
```

**Output of `docker-compose config`**
(Make sure to add the relevant `-f` and other flags)
```
services:
  postgres:
    image: postgres:9.5
    ports:
    - 127.0.0.1:5432:5432/tcp
    volumes:
  statushq:
    depends_on:
    - postgres
    environment:
      ...
    image: messutiedd/statushq
    ports:
    - 5000:5000/tcp
    - <ip>:4369:4369/tcp
    - 9001:9001/tcp
    - 25:2525/tcp
    restart: always
    volumes:
    ...
```


## Steps to reproduce the issue

1. Change a port bind in `docker-compose.yaml` from `4369:4369` to `<ip>:4369:4369` (`<ip>` is a real life external IP which should be the only one with allowed access to that port).
2. Run `docker-compose up`

### Observed result

docker-compose errors and container fails to start.

### Expected result

Container should start successfully and allow connections only on the given IP.

### Stacktrace / full error message

```
Recreating 35e93f062be7_35e93f062be7_docker_statushq_1 ... error

ERROR: for 35e93f062be7_35e93f062be7_docker_statushq_1  Cannot start service statushq: driver failed programming external connectivity on endpoint docker_statushq_1 (79fe33198b8b1933c14706d0bc81dabcfc48111df4fca90d6c2a532a13da28de): Error starting userland proxy: listen tcp <ip>:4369: bind: cannot assign requested address

ERROR: for statushq  Cannot start service statushq: driver failed programming external connectivity on endpoint docker_statushq_1 (79fe33198b8b1933c14706d0bc81dabcfc48111df4fca90d6c2a532a13da28de): Error starting userland proxy: listen tcp <ip>:4369: bind: cannot assign requested address
ERROR: Encountered errors while bringing up the project.
```

## Additional information

OS version / distribution, `docker-compose` install method, etc.
```
Ubuntu 20.04.2 LTS (GNU/Linux 5.4.0-65-generic x86_64)
docker-compose installed through docker-ce package
```",,,,,,,,,,,,,,
8100,OPEN,OSError from python when running `docker-compose build`,kind/bug,2021-02-15 20:22:24 +0000 UTC,alanbernstein,In progress,,"## Description of the issue

OSError from python when running `docker-compose build`

## Context information (for bug reports)

**Output of `docker-compose version`**
```
docker-compose version 1.27.4, build 40524192
docker-py version: 4.3.1
CPython version: 3.7.7
OpenSSL version: OpenSSL 1.1.1g  21 Apr 2020
```

**Output of `docker version`**
```
Client: Docker Engine - Community
 Cloud integration: 1.0.7
 Version:           20.10.2
 API version:       1.41
 Go version:        go1.13.15
 Git commit:        2291f61
 Built:             Mon Dec 28 16:12:42 2020
 OS/Arch:           darwin/amd64
 Context:           default
 Experimental:      true

Server: Docker Engine - Community
 Engine:
  Version:          20.10.2
  API version:      1.41 (minimum version 1.12)
  Go version:       go1.13.15
  Git commit:       8891c58
  Built:            Mon Dec 28 16:15:28 2020
  OS/Arch:          linux/amd64
  Experimental:     false
 containerd:
  Version:          1.4.3
  GitCommit:        269548fa27e0089a8b8278fc4fc781d7f65a939b
 runc:
  Version:          1.0.0-rc92
  GitCommit:        ff819c7e9184c13b7c2607fe6c30ae19403a7aff
 docker-init:
  Version:          0.19.0
  GitCommit:        de40ad0
```

**Output of `docker-compose config`**
(Make sure to add the relevant `-f` and other flags)
```
services:
  data:
    image: alpine
    volumes:
    - certs:/certs:rw
  idk-test:
    build:
      context: /Users/abernstein/src/go/src/github.com/molecula/idk
      dockerfile: Dockerfile-test
    volumes:
    - certs:/certs:rw
  kafka:
    depends_on:
      zookeeper:
        condition: service_started
    environment:
      KAFKA_ADVERTISED_LISTENERS: LISTENER_DOCKER_INTERNAL://kafka:19092,LISTENER_DOCKER_EXTERNAL://kafka:9092
      KAFKA_BROKER_ID: 1
      KAFKA_INTER_BROKER_LISTENER_NAME: LISTENER_DOCKER_INTERNAL
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: LISTENER_DOCKER_INTERNAL:PLAINTEXT,LISTENER_DOCKER_EXTERNAL:PLAINTEXT
      KAFKA_LOG4J_LOGGERS: kafka.controller=INFO,kafka.producer.async.DefaultEventHandler=INFO,state.change.logger=INFO
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
    image: confluentinc/cp-kafka:5.4.0
    ports:
    - 127.0.0.1:9092:9092/tcp
    volumes:
    - kafka-data:/var/lib/kafka/data:rw
  pilosa:
    environment:
      PILOSA_ADVERTISE: pilosa:10101
      PILOSA_BIND: 0.0.0.0:10101
      PILOSA_BIND_GRPC: 0.0.0.0:20101
      PILOSA_DATA_DIR: /data
    image: moleculacorp/pilosa:master
    ports:
    - 127.0.0.1:10101:10101/tcp
    - 127.0.0.1:20101:20101/tcp
    volumes:
    - pilosa-data:/data:rw
    - certs:/certs:rw
  pilosa-tls:
    environment:
      PILOSA_ADVERTISE: https://pilosa-tls:10111
      PILOSA_BIND: https://0.0.0.0:10111
      PILOSA_BIND_GRPC: 0.0.0.0:20111
      PILOSA_DATA_DIR: /data
      PILOSA_TLS_CA_CERTIFICATE: /certs/ca.crt
      PILOSA_TLS_CERTIFICATE: /certs/pilosa-tls.crt
      PILOSA_TLS_ENABLE_CLIENT_VERIFICATION: 1
      PILOSA_TLS_KEY: /certs/pilosa-tls.key
    image: moleculacorp/pilosa:master
    ports:
    - 127.0.0.1:10111:10111/tcp
    - 127.0.0.1:20111:20111/tcp
    volumes:
    - pilosa-tls-data:/data:rw
    - certs:/certs:rw
  schema-registry:
    depends_on:
      kafka:
        condition: service_started
      zookeeper:
        condition: service_started
    environment:
      SCHEMA_REGISTRY_HOST_NAME: schema-registry
      SCHEMA_REGISTRY_KAFKASTORE_BOOTSTRAP_SERVERS: PLAINTEXT://kafka:19092
      SCHEMA_REGISTRY_LISTENERS: http://0.0.0.0:8081
    image: confluentinc/cp-schema-registry:5.4.0
    ports:
    - 127.0.0.1:8081:8081/tcp
  zookeeper:
    environment:
      ZOO_MY_ID: 1
      ZOO_PORT: 2181
      ZOO_SERVERS: server.1=zookeeper:2888:3888
    image: zookeeper:3.4.9
    ports:
    - 127.0.0.1:2181:2181/tcp
    volumes:
    - zookeeper-data:/data:rw
    - zookeeper-datalog:/datalog:rw
version: '3'
volumes:
  certs: {}
  kafka-data: {}
  pilosa-data: {}
  pilosa-tls-data: {}
  zookeeper-data: {}
  zookeeper-datalog: {}
```


## Steps to reproduce the issue

1. `docker-compose build idk-test`

### Observed result

Multiple occurrences of `OSError: [Errno 27] File too large`

### Expected result

Builds successfully

### Stacktrace / full error message

```
Building idk-test
Traceback (most recent call last):
  File ""site-packages/docker/utils/build.py"", line 97, in create_archive
  File ""tarfile.py"", line 1970, in addfile
  File ""tarfile.py"", line 250, in copyfileobj
  File ""tempfile.py"", line 481, in func_wrapper
OSError: [Errno 27] File too large

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""docker-compose"", line 3, in <module>
  File ""compose/cli/main.py"", line 67, in main
  File ""compose/cli/main.py"", line 126, in perform_command
  File ""compose/cli/main.py"", line 302, in build
  File ""compose/project.py"", line 468, in build
  File ""compose/project.py"", line 450, in build_service
  File ""compose/service.py"", line 1125, in build
  File ""site-packages/docker/api/build.py"", line 160, in build
  File ""site-packages/docker/utils/build.py"", line 31, in tar
  File ""site-packages/docker/utils/build.py"", line 100, in create_archive
OSError: Can not read file in context: <local path to binary>
[94143] Failed to execute script docker-compose
```

## Additional information

macOS, recently upgraded to Big Sur 11.1, then to 11.2

Docker and all related tools freshly reinstalled (after macOS upgrade) from https://hub.docker.com/editions/community/docker-ce-desktop-mac/

I tried supplying ulimit arguments to docker-compose, which made no difference in the result. Colleagues on other macs can build/run the container on the exact same commit of the repo, with the same commands that fail for me. I can try to provide additional reproduction information if necessary, but I suspect that this is some sort of macOS permissions issue, which I don't know how to diagnose.",,,Philwi,"
--
Got the same problem on arch linux

**docker-compose version**
```
docker-compose version 1.27.4, build 40524192
docker-py version: 4.3.1
CPython version: 3.7.7
OpenSSL version: OpenSSL 1.1.0l  10 Sep 2019
```

**docker version**
```
Client:
 Version:           20.10.3
 API version:       1.41
 Go version:        go1.15.7
 Git commit:        48d30b5b32
 Built:             Tue Feb  2 02:34:18 2021
 OS/Arch:           linux/amd64
 Context:           default
 Experimental:      true

Server:
 Engine:
  Version:          20.10.3
  API version:      1.41 (minimum version 1.12)
  Go version:       go1.15.7
  Git commit:       46229ca1d8
  Built:            Tue Feb  2 02:33:45 2021
  OS/Arch:          linux/amd64
  Experimental:     false
 containerd:
  Version:          v1.4.3
  GitCommit:        269548fa27e0089a8b8278fc4fc781d7f65a939b.m
 runc:
  Version:          1.0.0-rc93
  GitCommit:        12644e614e25b05da6fd08a38ffa0cfe1903fdec
 docker-init:
  Version:          0.19.0
  GitCommit:        de40ad0
```

**Stacktrace**
```
Status: Downloaded newer image for postgres:11
Building webpack
Traceback (most recent call last):
  File ""docker/utils/build.py"", line 97, in create_archive
  File ""tarfile.py"", line 1970, in addfile
  File ""tarfile.py"", line 250, in copyfileobj
  File ""tempfile.py"", line 481, in func_wrapper
OSError: [Errno 28] No space left on device

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""bin/docker-compose"", line 3, in <module>
  File ""compose/cli/main.py"", line 67, in main
  File ""compose/cli/main.py"", line 126, in perform_command
  File ""compose/cli/main.py"", line 1070, in up
  File ""compose/cli/main.py"", line 1066, in up
  File ""compose/project.py"", line 615, in up
  File ""compose/service.py"", line 362, in ensure_image_exists
  File ""compose/service.py"", line 1125, in build
  File ""docker/api/build.py"", line 160, in build
  File ""docker/utils/build.py"", line 31, in tar
  File ""docker/utils/build.py"", line 100, in create_archive 
OSError: Can not read file in context: /home/oimel/Projects/lechstore/storage/yk/ws/ykws3xwk1d249hzbg9pd9srbv04e
[123096] Failed to execute script docker-compose

```
--

--
Yes maybe, but I got plenty of space left as well  (320 GB left on my device). Maybe its the same root problem? Don't know...
--

--
I solved my problem with adding some large folders to .dockerignore I don't really need in my build context. While docker-compose up my RAM where completly in use... Hope you will find a solution or a fix.
--
",alanbernstein,"
--
Same stack trace, but note that my error is `[Errno 27] File too large` and yours is `[Errno 28] No space left on device`. My physical machine has plenty of space available, so it seems possible that these two errors may have different causes.

--

--
Thanks, that does help as a workaround for me, at least for now.
--
",,,,,,,,
8098,OPEN,Separate STDERR and STDOUT in docker compose output,kind/feature,2021-02-11 14:41:51 +0000 UTC,raiyanyahya,Opened,,"**Is your feature request related to a problem? Please describe.**
Docker compose outputs container stderr output to stdout
Refer to the sample below:
docker-compose.yml :
```yaml
version: ""3.3""
services:
  stderr:
    image: alpine
    command: /bin/ash /log_to_stderr.sh
    volumes:
           - ./log_to_stderr.sh:/log_to_stderr.sh
```
log_to_stderr.sh:
```bash
>&2 echo ""log to stderr""
echo ""log to stdout""
```

Running the bash script separately we get the output:
```bash
 ./log_to_stderr.sh 2> /dev/null
log to stdout
```
BUT
when running docker-compose we get:
```bash
 docker-compose up 2> /dev/null
Attaching to composeissue_stderr_1
stderr_1  | log to stderr
stderr_1  | log to stdout
composeissue_stderr_1 exited with code 0
```
Note:
Just running the image with docker seems to give us the expected behaviour:
```bash
 docker run --rm -v ${PWD}/log_to_stderr.sh:/log_to_stderr.sh alpine /bin/ash /log_to_stderr.sh 2> /dev/null 
log to stdout
```

**Describe the solution you'd like**
Docker compose should use the same output stream as the container.

",,,dexter74,"
--
Hello,

I think was  a error them line **command**. (Log : ash is not found ?)

**Before:**
````yaml
version: ""3.3""
services:
  stderr:
    image: alpine
    command: /bin/ash /log_to_stderr.sh
    volumes:
           - ./log_to_stderr.sh:/log_to_stderr.sh
````

**After:**
````yaml
version: ""3.3""
services:
  stderr:
    image: alpine
    command: /bin/bash /log_to_stderr.sh
    volumes:
           - ./log_to_stderr.sh:/log_to_stderr.sh
````

--
",LennartC,"
--
Hi Marc,

That's not going to be the issue. 
In the Alpine docker image, bash is not installed by default, but ash is. But it makes no difference whether you use bash or ash.

Example with debian:buster-slim and bash:

```
version: ""3.3""
services:
  stderr:
    image: debian:buster-slim
    command: /bin/bash /log_to_stderr.sh
    volumes:
           - ./log_to_stderr.sh:/log_to_stderr.sh
```

```
$ docker-compose up 2> /dev/null
Attaching to composeissue_stderr_1
stderr_1  | log to stdout
stderr_1  | log to stderr
composeissue_stderr_1 exited with code 0
```

The ""error"" really is with docker compose itself, merging the stdout and stderr stream of the containers.

--
",thaJeztah,"
--
So the equivalent of the `docker run` example for compose would be;

```console
docker-compose run -T stderr 2> /dev/null
log to stdout
```

(unlike `docker run`, `docker-compose` by default attaches a TTY, so use `-T` to not have it attach a TTY)

As to the `docker-compose up` case, I'm a bit on the fence. `docker-compose up`; it does not print the ""raw"" output of any of the services (it decorates the logs by prefixing service names, and also produces (informational) output messages of docker-compose itself).

Splitting stderr/stdout in this case is done to separate ""informational output messages"" of _compose itself_ (stderr) and ""expected output"" (output of containers) on stdout.

For example;

```console
$ docker-compose up
WARNING: The Docker Engine you're using is running in swarm mode.

Compose does not use swarm mode to deploy services to multiple nodes in a swarm. All containers will be scheduled on the current node.

To deploy your application across the swarm, use `docker stack deploy`.

Starting repro-8098_stderr_1 ... done
Attaching to repro-8098_stderr_1
stderr_1  | log to stdout
stderr_1  | log to stderr
repro-8098_stderr_1 exited with code 0
```

And the same, this time redirecting `stderr` suppresses the informational warnings;

```console
$ docker-compose up 2> /dev/null
Attaching to repro-8098_stderr_1
stderr_1  | log to stdout
stderr_1  | log to stderr
repro-8098_stderr_1 exited with code 0
```

That said, `docker-compose logs`, which _would be_ more suitable to get the raw logs/output of a service (unfortunately) currently cannot be used as a replacement/equivalent of `docker logs`.

Comparing;

```console
$ docker logs repro-8098_stderr_run_770ad5840016
log to stdout
log to stderr

$ docker logs repro-8098_stderr_run_770ad5840016 2> /dev/null
log to stdout
```

And (docker-compose);

```console
$ docker-compose logs stderr
Attaching to repro-8098_stderr_1
stderr_1  | log to stdout
stderr_1  | log to stderr

$ docker-compose logs stderr 2> /dev/null
Attaching to repro-8098_stderr_1
stderr_1  | log to stdout
stderr_1  | log to stderr
```

This may be (at least partially) because `docker-compose logs` allows for one _or more_ services logs to be printed, and therefore somewhat ""requires"" the output to include the prefixes (to know which service / service instance produced a log entry). Having ""raw"" (non-modified) log output of containers would still be usefull though, so perhaps there should be an option to disable that functionality and output the logs as-is.

--

--
One thing that (IMO) _should_ be fixed at least is to (in the `docker-compose logs` example) either skip the `Attaching to ...` message, or at least move it to `stderr`, so that output is purely the output of the containers (I don't think the _""Attaching to""_ is providing much value to the user; it would only be relevant if attaching _failed_)
--

--
> couldn't docker-compose also, optionally, annotate the log entries with information of which output stream they were sent to by the container?

I think this depends on how it collects the output; containers with a TTY attached send a ""raw"" stream over the API, whereas containers without a TTY send a multiplexed stream that contains information about stderr/stdout. I must admit I'm not familiar enough with the compose codebase, and would have to look into that.

That said; there's development ongoing to implement `docker compose` in ""go"" (preview already included in docker desktop, repository is in https://github.com/docker/compose-cli), which may give more flexibility for things like that. We're discussing formatting options for ""log"" output, and such a feature could be considered as part of that.
--

--
> unfortunately POSIX is missing a stdinfo stream, so I'm not sure stderr is the adequate stream we should use for informational messages

Yes, a `stdinfo` stream would've been nice, but it's not a thing, and general convention is to use `stderr` for that purpose to allow redirecting.



--
",deriksson,"
--
For the `docker-compose up` case: Since the output from the containers is already decorated with the service name prefix, couldn't docker-compose also, optionally, annotate the log entries with information of which output stream they were sent to by the container?
--
",ndeloof,"
--
> skip the Attaching to ... message, or at least move it to stderr

unfortunately POSIX is missing a `stdinfo` stream, so I'm not sure `stderr` is the adequate stream we should use for informational messages. But we could support a `--quiet` flag to just skip them all.

I'll need to read more about TTY and how those actually can eventually split a raw process stream back into stdout+stderr, if reasonably portable we could get the same implemented in compose to process the TTY log output and redirect logs into console streams.
--
",,
8097,OPEN,'yes' is not boolean in YAML 1.2 spec,kind/bug,2021-02-03 04:55:15 +0000 UTC,aleung,Opened,,"3. When making a bug report, make sure you provide all required information. The easier it is for
   maintainers to reproduce, the faster it'll be fixed.
-->

## Description of the issue

Docker compose reports that the compose file is invalid because an environment variable contains true.

The value of the environment is `yes`. According to YAML 1.2, boolean is `trueTrueTRUEfalseFalseFALSE` and `yes` is no longer boolean type.

My docker-compose.yml file is generated by program (using the js module [yaml](https://eemeli.org/yaml)). The yaml library which comply with YAML 1.2 won't enclose `yes` in quotes because it doesn't enclose string in quotes.

I tried to add yaml version 1.2 directive to the head of docker-compose.yml but still got the same error.

## Context information (for bug reports)

**Output of `docker-compose version`**
```
docker-compose version 1.28.2, build unknown
docker-py version: 4.4.1
CPython version: 3.6.9
OpenSSL version: OpenSSL 1.1.1  11 Sep 2018
```

**Content of `docker-compose.yml`**
```yaml
%YAML 1.2
---
version: ""3""
services:
  zookeeper:
    image: zookeeper
  kafka:
    image: kafka
    environment:
      KAFKA_CFG_ZOOKEEPER_CONNECT: zookeeper:2181
      ALLOW_PLAINTEXT_LISTENER: yes
    depends_on:
      - zookeeper
```

### Stacktrace / full error message

```
ERROR: The Compose file './docker-compose.yml' is invalid because:
services.kafka.environment.ALLOW_PLAINTEXT_LISTENER contains true, which is an invalid type, it should be a string, number, or a null
```
",,,,,,,,,,,,,,
8095,OPEN,I need help for mount volumes,kind/question,2021-02-09 10:34:43 +0000 UTC,dexter74,Opened,,"Hello,
I would like a little helping hand to assemble the volumes that I created.
These volumes are CIFS and with version 2.4 it worked flawlessly.

I updated Portainer and it supports version 3.8 and the problem is that with the following code, it gives me an error.

i was move my folder Volumes before start a first container .

------------------
#### **Volumes CIFS:**
````
docker volume create --driver local \
        --opt type=cifs \
        --opt device=//XXX.XXX.XXX.XXX/ABCD \
        --opt o=username=MYUSER,password=MYPASSWORD,vers=3.0,file_mode=0777,dir_mode=0777 \
        --name DL

docker volume create --driver local \
        --opt type=cifs \
        --opt device=//XXX.XXX.XXX.XXX/HIJK \
        --opt o=username=MYUSER,password=MYPASSWORD,vers=3.0,file_mode=0777,dir_mode=0777 \
        --name Musique

docker volume create --driver local \
        --opt type=cifs \
        --opt device=//XXX.XXX.XXX.XXX/DEFG \
        --opt o=username=MYUSER,password=MYPASSWORD,vers=3.0,file_mode=0777,dir_mode=0777 \
        --name Video
````
------------------
#### **Old Stack - version Portainer:**
````
version: '2.4'
services:
  Transmission:
    container_name: CN_Transmission
    image: linuxserver/transmission
    restart: 'no'
    environment:
      - PUID=1001
      - PGID=74240
      - TZ=Europe/Paris
      - USER=admin
      - PASS=admin
    ports:
      - 1041:9091
    volumes:
      - Transmission:/config:rw
      - DL:/downloads:rw
      - Musique:/mnt/Musique:ro
      - Video:/mnt/VIdeo:ro
````
------------------
#### **Stack - Portainer 2.10**
````
version: '3.8'
services:
  Transmission:
    container_name: CN_Transmission
    image: linuxserver/transmission
    restart: 'no'
    environment:
      - PUID=1001
      - PGID=74240
      - TZ=Europe/Paris
      - USER=admin
      - PASS=admin
    ports:
      - 1041:9091
    volumes:  
      - Transmission:/config:rw
      - DL:/downloads:rw
      - Musique:/mnt/Musique:ro
      - Video:/mnt/VIdeo:ro
      
volumes:
  Transmission:
  DL:
  Musique:
  Video:
`````

````console
docker inspect DL
````
````
[
    {
        ""CreatedAt"": ""2021-02-01T14:27:22+01:00"",
        ""Driver"": ""local"",
        ""Labels"": {},
        ""Mountpoint"": ""/home/docker/volumes/DL/_data"",
        ""Name"": ""DL"",
        ""Options"": {
            ""device"": ""//XXX.XXX.XXX.XXX/DL"",
            ""o"": ""username=XXXX,password=XXXX,vers=3.0,file_mode=0777,dir_mode=0777"",
            ""type"": ""cifs""
        },
        ""Scope"": ""local""
    }
]
````


#### **Result:**
````
linuxserver_Video <= This volume is not the share volume. 
linuxserver_DL <= This volume is not the share volume
linuxserver_Musique <= This volume is not the share volume
linuxserver_Transmission <= Volume OK
````



",,,aiordache,"
--
Hi! 
If you've created the volumes outside docker-compose, try setting them as external in your Compose file https://docs.docker.com/compose/compose-file/compose-file-v3/#external
--
",,,,,,,,,,
8086,OPEN,More intuitive error message when Docker service is not running,kind/feature,2021-01-30 21:38:48 +0000 UTC,marcauberer,Opened,,"Hi,
the usage experience could be optimized by displaying a clearer error message when trying to execute `docker-compose up` and the Docker service is not running.

Currently it only throws a StackTrace (e.g on Windows):
```
Traceback (most recent call last):
  File ""site-packages\docker\api\client.py"", line 205, in _retrieve_server_version
  File ""site-packages\docker\api\daemon.py"", line 181, in version
  File ""site-packages\docker\utils\decorators.py"", line 46, in inner
  File ""site-packages\docker\api\client.py"", line 228, in _get
  File ""site-packages\requests\sessions.py"", line 543, in get
  File ""site-packages\requests\sessions.py"", line 530, in request
  File ""site-packages\requests\sessions.py"", line 643, in send
  File ""site-packages\requests\adapters.py"", line 449, in send
  File ""site-packages\urllib3\connectionpool.py"", line 677, in urlopen
  File ""site-packages\urllib3\connectionpool.py"", line 392, in _make_request
  File ""http\client.py"", line 1244, in request
  File ""http\client.py"", line 1290, in _send_request
  File ""http\client.py"", line 1239, in endheaders
  File ""http\client.py"", line 1026, in _send_output
  File ""http\client.py"", line 966, in send
  File ""site-packages\docker\transport\npipeconn.py"", line 32, in connect
  File ""site-packages\docker\transport\npipesocket.py"", line 23, in wrapped
  File ""site-packages\docker\transport\npipesocket.py"", line 72, in connect
  File ""site-packages\docker\transport\npipesocket.py"", line 59, in connect
pywintypes.error: (2, 'CreateFile', 'Das System kann die angegebene Datei nicht finden.')

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""docker-compose"", line 3, in <module>
  File ""compose\cli\main.py"", line 67, in main
  File ""compose\cli\main.py"", line 123, in perform_command
  File ""compose\cli\command.py"", line 69, in project_from_options
  File ""compose\cli\command.py"", line 132, in get_project
  File ""compose\cli\docker_client.py"", line 43, in get_client
  File ""compose\cli\docker_client.py"", line 170, in docker_client
  File ""site-packages\docker\api\client.py"", line 188, in __init__
  File ""site-packages\docker\api\client.py"", line 213, in _retrieve_server_version
docker.errors.DockerException: Error while fetching server API version: (2, 'CreateFile', 'Das System kann die angegebene Datei nicht finden.')
[15880] Failed to execute script docker-compose
```
More unexperienced folks could have problems to understand what to do, so this would be a gread addition.

A better solution would be to check if the Docker service is reachable by docker-compose and if not, show a message like this:
**Linux**:
`The Docker service is currently not available. Please start it by executing 'sudo systemctl start docker' and try it again.`
**Windows**:
`The Docker service is currently not available. Please launch 'Docker Desktop' on your computer and try it again.`

Would be cool if this was realized.

Cheers,
Marc",,,,,,,,,,,,,,
8085,OPEN,ResourceWarning: unclosed socket reported whenever I use `docker-compose stop`,kind/bug,2021-01-29 23:31:37 +0000 UTC,arbaes,In progress,,"3. When making a bug report, make sure you provide all required information. The easier it is for
   maintainers to reproduce, the faster it'll be fixed.
-->

## Description of the issue

Whenever I use the command stop from `docker-compose` I have multiple warning telling the docker socket wasn't closed properly:
```
sys:1: ResourceWarning: unclosed <socket.socket fd=14, family=AddressFamily.AF_UNIX, type=SocketKind.SOCK_STREAM, proto=0> ResourceWarning: Enable tracemalloc to get the object allocation traceback 
```

I noticed i get it too if I run docker-compose config.


## Context information (for bug reports)

**Output of `docker-compose version`**

```
docker-compose version 1.28.0, build unknown
docker-py version: 4.4.1
CPython version: 3.9.1
OpenSSL version: OpenSSL 1.1.1i  8 Dec 2020
```

**Output of `docker version`**
```
Client:
 Version:           20.10.2
 API version:       1.41
 Go version:        go1.15.6
 Git commit:        2291f610ae
 Built:             Tue Jan 19 17:19:21 2021
 OS/Arch:           linux/amd64
 Context:           default
 Experimental:      true

Server:
 Engine:
  Version:          20.10.2
  API version:      1.41 (minimum version 1.12)
  Go version:       go1.15.6
  Git commit:       8891c58a43
  Built:            Tue Jan 19 17:18:55 2021
  OS/Arch:          linux/amd64
  Experimental:     false
 containerd:
  Version:          v1.4.3
  GitCommit:        269548fa27e0089a8b8278fc4fc781d7f65a939b.m
 runc:
  Version:          1.0.0-rc92
  GitCommit:        ff819c7e9184c13b7c2607fe6c30ae19403a7aff
 docker-init:
  Version:          0.19.0
  GitCommit:        de40ad0
```

**Output of `docker-compose config`**
(Make sure to add the relevant `-f` and other flags)
```
docker-compose config
services:
  redis:
    image: redis:alpine
  web:
    build:
      context: /home/arbaes/dkrcmp
    ports:
    - published: 5000
      target: 5000
version: '3.9'

sys:1: ResourceWarning: unclosed <socket.socket fd=6, family=AddressFamily.AF_UNIX, type=SocketKind.SOCK_STREAM, proto=0>
ResourceWarning: Enable tracemalloc to get the object allocation traceback
```


## Steps to reproduce the issue

FYI, i can reproduce with any project, including [this one](https://docs.docker.com/compose/gettingstarted/).
So i use it here for simplicty's sake

1. Up the containers with `docker-compose up`
2. Stop them with `docker-compose stop`

### Observed result
No errors but multiple ResourceWarnings for unclosed sockets

### Expected result

No ResourceWarning and sockets properly closed

### Stacktrace / full error message

```
 docker-compose up    
Building with native build. Learn about native build in Compose here: https://docs.docker.com/go/compose-native-build/
Starting dkrcmp_redis_1 ... done
Starting dkrcmp_web_1   ... done
Attaching to dkrcmp_redis_1, dkrcmp_web_1
redis_1  | 1:C 29 Jan 2021 16:22:52.286 # oO0OoO0OoO0Oo Redis is starting oO0OoO0OoO0Oo
redis_1  | 1:C 29 Jan 2021 16:22:52.286 # Redis version=6.0.10, bits=64, commit=00000000, modified=0, pid=1, just started
redis_1  | 1:C 29 Jan 2021 16:22:52.286 # Warning: no config file specified, using the default config. In order to specify a config file use redis-server /path/to/redis.conf
redis_1  | 1:M 29 Jan 2021 16:22:52.287 * Running mode=standalone, port=6379.
redis_1  | 1:M 29 Jan 2021 16:22:52.287 # Server initialized
redis_1  | 1:M 29 Jan 2021 16:22:52.287 # WARNING overcommit_memory is set to 0! Background save may fail under low memory condition. To fix this issue add 'vm.overcommit_memory = 1' to /etc/sysctl.conf and then reboot or run the command 'sysctl vm.overcommit_memory=1' for this to take effect.
redis_1  | 1:M 29 Jan 2021 16:22:52.287 * Loading RDB produced by version 6.0.10
redis_1  | 1:M 29 Jan 2021 16:22:52.287 * RDB age 247 seconds
redis_1  | 1:M 29 Jan 2021 16:22:52.287 * RDB memory usage when created 0.77 Mb
redis_1  | 1:M 29 Jan 2021 16:22:52.287 * DB loaded from disk: 0.000 seconds
redis_1  | 1:M 29 Jan 2021 16:22:52.287 * Ready to accept connections
web_1    |  * Serving Flask app ""app.py""
web_1    |  * Environment: production
web_1    |    WARNING: This is a development server. Do not use it in a production deployment.
web_1    |    Use a production WSGI server instead.
web_1    |  * Debug mode: off
web_1    |  * Running on http://0.0.0.0:5000/ (Press CTRL+C to quit)
^CGracefully stopping... (press Ctrl+C again to force)
Stopping dkrcmp_web_1   ... done
Stopping dkrcmp_redis_1 ... done
sys:1: ResourceWarning: unclosed <socket.socket fd=37, family=AddressFamily.AF_UNIX, type=SocketKind.SOCK_STREAM, proto=0>
ResourceWarning: Enable tracemalloc to get the object allocation traceback
sys:1: ResourceWarning: unclosed <socket.socket fd=24, family=AddressFamily.AF_UNIX, type=SocketKind.SOCK_STREAM, proto=0, raddr=/run/docker.sock>
ResourceWarning: Enable tracemalloc to get the object allocation traceback
sys:1: ResourceWarning: unclosed <socket.socket fd=26, family=AddressFamily.AF_UNIX, type=SocketKind.SOCK_STREAM, proto=0, raddr=/run/docker.sock>
ResourceWarning: Enable tracemalloc to get the object allocation traceback
```

## Additional information
OS: Manjaro Linux
Kernel: 5.10.10-1-MANJARO

`docker` and `docker-compose` installed trough pacman, from community repos
",,,arbaes,"
--
If I can provide any help in case you can't reproduce let me know, I just don't know how to properly debug that
--

--
Can confirm I don't have the issue with the binary 1.28.2, but I do have it with the pip version. Pretty weird.

I use python 3.9 by default, something wrong with one of the librairies maybe ?
--
",aiordache,"
--
Hi @arbaes! I can't reproduce this on Arch Linux with docker-compose v1.28.2 installed with pacman, pip and the binary.
Do you mind trying the binary from the release page to see if you still get the issue? Thanks! 
https://github.com/docker/compose/releases/tag/1.28.2
--
",,,,,,,,
8084,OPEN,Bug about typo,kind/bug,2021-01-28 17:44:37 +0000 UTC,Alishahidi,Opened,,"3. When making a bug report, make sure you provide all required information. The easier it is for
   maintainers to reproduce, the faster it'll be fixed.
-->

## Description of the issue

## Context information (for bug reports)

**Output of `docker-compose version`**
```
1.25.0
```

**Output of `docker version`**
```
20.10.2+dfsg1
```

### Observed result

149a5d279f97: Downloading [=========================>                         ]  196.8MB/391.2MBomplete


### Expected result

149a5d279f97: Downloading [=========================>                         ]  196.8MB/391.2MBComplete 
### Stacktrace / full error message

```
The word Complate is misspelled omplate
```

## Additional information

OS version / distribution, `docker-compose` install method, etc.
",,,,,,,,,,,,,,
8083,OPEN,UnicodeDecodeError: 'charmap' codec can't decode byte 0x9d in position 17: character maps to <undefined>,kind/bug,2021-02-05 15:26:29 +0000 UTC,geelife,In progress,,"Hi,
Though I have found similar reports, I couldn't solve the problem of which I am not sure whether this is a bug or not.

## Description of the issue
Running docker-compose up -d results in UnicodeDecodeError.
Tried on two different Windows 10 machines running Docker for Windows.

## Context information (for bug reports)

**Output of `docker-compose version`**
```
docker-compose version 1.27.4, build 40524192
```

**Output of `docker version`**
```
Docker version 20.10.2, build 2291f61
```

**Output of `docker-compose config`**
(Make sure to add the relevant `-f` and other flags)
```
services:
  app:
    build:
      context: F:\repos\repo
    command: bundle exec rails s -p 3000 -b '0.0.0.0'
    depends_on:
      db:
        condition: service_started
    environment:
      RAILS_ENV: development
    links:
    - db
    ports:
    - published: 3000
      target: 3000
    volumes:
    - F:\repos\repo:/app:rw
  db:
    environment:
      MYSQL_DATABASE: development_db
      MYSQL_PASSWORD: blablabla123
      MYSQL_ROOT_PASSWORD: blablabla123rootpw
      MYSQL_USER: jay
    image: mysql:5.7
    ports:
    - published: 3306
      target: 3306
version: '3.9'
```


## Steps to reproduce the issue

1. Navigate to app folder
2. Run docker-compose up -d

### Observed result
see stacktrace

### Expected result
composed app

### Stacktrace / full error message

```
Building app
Traceback (most recent call last):
  File ""docker-compose"", line 3, in <module>
  File ""compose\cli\main.py"", line 67, in main
  File ""compose\cli\main.py"", line 126, in perform_command
  File ""compose\cli\main.py"", line 1070, in up
  File ""compose\cli\main.py"", line 1066, in up
  File ""compose\project.py"", line 615, in up
  File ""compose\service.py"", line 362, in ensure_image_exists
  File ""compose\service.py"", line 1125, in build
  File ""site-packages\docker\api\build.py"", line 156, in build
  File ""c:\jenkins\workspace\dsg_compose_1.27.4\venv\lib\encodings\cp1252.py"", line 23, in decode
UnicodeDecodeError: 'charmap' codec can't decode byte 0x9d in position 17: character maps to <undefined>
[4144] Failed to execute script docker-compose
```

## Additional information

Windows 10 Pro, Version = 2004, OS build = 19041.746
docker-compose installed through Docker for Windows

Thanks in advance!
Best regards
",,,geelife,"
--
I now tried to execute ""docker compose up -d"" instead of ""docker**-**compose up -d"" and this works. Not sure if it supposed to work with the ""-"" sign?
--
",,,,,,,,,,
8079,OPEN,Accept --cpuset-cpus flag in `docker-compose build` command,kind/feature,2021-01-28 08:28:47 +0000 UTC,dnk8n,Opened,,"-->

**Is your feature request related to a problem? Please describe.**
When running the initial stage of a Docker multistage build on our dev server (booted on demand), the process saturates all available cpus because it compiles things from source. To try for yourself, see working Dockerfile:

# ./Dockerfile
```
FROM python:3.8.7-alpine3.12 as base

FROM base as builder
ENV PATH=""/install/bin:${PATH}""
RUN mkdir /install
RUN apk update && apk add \
  build-base \
  freetype-dev \
  gcc \
  g++ \
  gfortran \
  lapack-dev \
  libc-dev \
  libexecinfo-dev \
  libgcc \
  libgomp \
  libquadmath \
  libgfortran \
  libpng-dev \
  linux-headers \
  musl \
  musl-dev \
  openblas-dev \
  postgresql-dev \
  python3-dev
COPY requirements.txt /requirements.txt
RUN pip install --target=/install -r /requirements.txt

FROM base as core
WORKDIR /app
RUN apk --no-cache add freetype libgomp libpq libstdc++ openblas
ENV PYTHONPATH=/usr/local
COPY --from=builder /install /usr/local

FROM core as release
COPY . /app/
```

# ./app/requirements.txt
```
matplotlib==3.1.3
numpy==1.16.4
pandas==1.0.1
scikit-learn==0.24.1
scipy==1.5.4
```

We find that managing cached images in the cloud with build CI (for dev), etc is just too time consuming and complicated especially when builds are often just the final `COPY . /app/` step and build cache can be leveraged. Whereas Staging/Prod has CI that builds  on temporary large instances from scratch (infeasible for dev).

Problem is that `docker-compose build` can lock the machine up (only during the infrequent times requirements change and the initial stage of the multistage needs rebuilding), so the current solution is to manually execute: `docker build --cpuset-cpus=""0"" --tag app:latest -f Dockerfile app` in all cases, through a wrapper script (note *--cpuset-cpus=""0""*).

**Describe the solution you'd like**
It would like to be able to run: `docker-compose build --cpuset-cpus=""0""`. In fact wouldn't it be a good idea to be able to pass through any docker build flag through? I am asking here because I honestly don't know about potential complexities that would prevent this.

**Describe alternatives you've considered**
For now we use a wrapper script to docker-compose that disables the ability to run `docker-compose build` and instead we rewrite the `build` section in a raw docker command: `docker build --cpuset-cpus=""0"" --tag app:latest -f Dockerfile app`

**Additional context**
The wrapper script is in the making, but if it helps:

```
if [[ ""${DEPLOYMENT_ENVIRONMENT}"" == ""develop"" ]]
then
   DC_PREFIX=""""
elif [[ ""${DEPLOYMENT_ENVIRONMENT}"" == ""staging"" ]]
then
   DC_PREFIX="" -f ${PROJECT_ROOT}/docker-compose.yml -f ${PROJECT_ROOT}/config/docker/compose/live.yml -f ${PROJECT_ROOT}/config/docker/compose/staging.yml""
elif [[ ""${DEPLOYMENT_ENVIRONMENT}"" == ""production"" ]]
then
    DC_PREFIX="" -f ${PROJECT_ROOT}/docker-compose.yml -f ${PROJECT_ROOT}/config/docker/compose/live.yml -f ${PROJECT_ROOT}/config/docker/compose/prod.yml""
else
   echo ""Invalid DEPLOYMENT_ENVIRONMENT=${DEPLOYMENT_ENVIRONMENT}""
   exit 1
fi
unwrapped_command=""/usr/local/bin/docker-compose${DC_PREFIX} $@""
echo ""********************************************************************************""
echo ""NOTE: Command was unwrapped to apply to the correct environment, see following:""
echo """"
echo ""$ ${unwrapped_command}""
echo ""********************************************************************************""
eval ""${unwrapped_command}""
```
I will update with the code that catches a `docker-compose build ...` command and instead does a raw `docker build` while adding the `--cpuset-cpus=""0""` flag. On a side not, a useful feature here would be to be able to run something like `docker-compose config build ...` and it would spit out the underlying docker build command used.
",,,,,,,,,,,,,,
8077,OPEN,specify docker files inline (ie Inline dockerfile:),kind/feature,2021-01-27 16:41:13 +0000 UTC,lonewarrior556,Opened,,"RIght now I have this
```
services:
  app1:
    build:
      context: ../server
      dockerfile: $PWD/a-app1.Dockerfile

  app2:
    build:
      context: ../app
      dockerfile: $PWD/b-app2.Dockerfile

  app3:
    build:
      context: ../cypress
      dockerfile: $PWD/c-app2.Dockerfile
  ```
  
  This requires me to have 3 docker files and jump around to view what's building, even though some of these are really simple. 
I would love to be able to have all the info in my `docker-compose.yml` file

```
services:
  app1:
    build:
      context: ../server
      dockerfile: |
        FROM nginx:alpine
        COPY nginx.conf /etc/nginx/nginx.conf

  app2:
    build:
      context: ../app
      dockerfile: | 
        FROM nodeJS
        COPY . .
        CMD ['npm', 'start']

  app3:
    build:
      context: ../cypress
      dockerfile: | 
        FROM cypress
        COPY . .
  ```

I don't see how it's possible to currently do this",,,,,,,,,,,,,,
8072,OPEN,Variable interpolation uses temporary directory for SSL_CERT_FILE variables,kind/bug,2021-01-25 20:17:20 +0000 UTC,mdomi,In progress,,"3. When making a bug report, make sure you provide all required information. The easier it is for
   maintainers to reproduce, the faster it'll be fixed.
-->

## Description of the issue

Variables in a compose file containing any case-mixture of ""SSL_CERT_FILE"" are replaced with a value pointing at a temporary directory during interpolation. Any combination of case results in the same behavior ""

## Context information (for bug reports)

**Output of `docker-compose version`**
```
docker-compose version 1.27.4, build 40524192
docker-py version: 4.3.1
CPython version: 3.7.4
OpenSSL version: OpenSSL 1.1.1c  28 May 2019
```

**Output of `docker version`**
```
Client: Docker Engine - Community
 Cloud integration: 1.0.7
 Version:           20.10.2
 API version:       1.41
 Go version:        go1.13.15
 Git commit:        2291f61
 Built:             Mon Dec 28 16:14:16 2020
 OS/Arch:           windows/amd64
 Context:           default
 Experimental:      true

Server: Docker Engine - Community
 Engine:
  Version:          20.10.2
  API version:      1.41 (minimum version 1.12)
  Go version:       go1.13.15
  Git commit:       8891c58
  Built:            Mon Dec 28 16:15:28 2020
  OS/Arch:          linux/amd64
  Experimental:     false
 containerd:
  Version:          1.4.3
  GitCommit:        269548fa27e0089a8b8278fc4fc781d7f65a939b
 runc:
  Version:          1.0.0-rc92
  GitCommit:        ff819c7e9184c13b7c2607fe6c30ae19403a7aff
 docker-init:
  Version:          0.19.0
  GitCommit:        de40ad0
```

**Output of `docker-compose config`**
Output of `docker-compose -f docker-compose.yml config`. `<Username>` value is the redacted Windows user account logged on to my machine.
```
services:
  echo:
    command: /bin/sh -c 'printenv'
    environment:
      MIXED_CASE_SSL_CERT_FILE: C:\Users\<Username>\AppData\Local\Temp\_MEI256402\certifi\cacert.pem
      SSL_CERT_FILE: C:\Users\<Username>\AppData\Local\Temp\_MEI256402\certifi\cacert.pem
      SSL_CERT_FILE_WITH_BEFORE_AFTER: before-C:\Users\<Username>\AppData\Local\Temp\_MEI256402\certifi\cacert.pem-after
    image: library/busybox:latest
version: '3.4'
```


## Steps to reproduce the issue

1. Create a docker-compose.yml file with the following contents:
```
version: '3.4'
services:
  echo:
    image: library/busybox:latest
    environment:
      SSL_CERT_FILE: ${SSL_CERT_FILE:-key.pem}
      SSL_CERT_FILE_WITH_BEFORE_AFTER: before-${SSL_CERT_FILE:-key.pem}-after
      MIXED_CASE_SSL_CERT_FILE: ${sSl_CeRt_FiLe:-key.pem}
    command: /bin/sh -c 'printenv'
```
2. Run `docker-compose -f docker-compose.yml config
3. View output

### Observed result

Interpolated variables of matching any combination of lower-/upper-case ""SSL_CERT_FILE"" are replaced with a value pointing to a certificate in a temporary directory.

The behavior was originally seen during runtime (docker-compose up) in the container, but appears during config output as well (docker-compose config). Included several examples in the example compose configuration:
1. 1-to-1 environment variable mapping
2. Environment variable with before- and -after context
3. Example with mixed-case ""sSl_CeRt_FiLe""

### Expected result

Interpolated variables of matching any combination of lower-/upper-case ""SSL_CERT_FILE"" should be replaced like other variables.

### Stacktrace / full error message

```
N/A - no stacktrace
```

## Additional information

I've verified there is no `.env` file that could be supplying the template variable, and the _MIE***** value in the path is different every execution of the command, possibly indicating it is not coming from a hard-coded reference.

Also verify my system does not have any matching environment variables that could be supplying that value.

Windows 10 Enterprise
docker-compose installed via Windows installer for Docker Desktop for Windows. Current version installed as update via built-in self-update mechanism.",,,mdomi,"
--
I'll add that it is not just a `docker-compose config` behavior - it happens at runtime as well. The example compose configuration outputs the environment, and the magic temporary value being inserted during variable interpolation is there as well.
--
",,,,,,,,,,
8069,OPEN,Shared volume is not quite merged,kind/bug,2021-01-26 09:59:49 +0000 UTC,jeffrson,Opened,,"3. When making a bug report, make sure you provide all required information. The easier it is for
   maintainers to reproduce, the faster it'll be fixed.
-->

## Description of the issue

When I have multiple services referencing a common volume this is not correctly merged. Only one of the containers ""wins"".

## Context information (for bug reports)

**Output of `docker-compose version`**
```
docker-compose version 1.28.0, build d02a7b1a
docker-py version: 4.4.1
CPython version: 3.9.0
OpenSSL version: OpenSSL 1.1.1d  10 Sep 2019
```

**Output of `docker version`**
```
Client: Docker Engine - Community
 Version:           20.10.2
 API version:       1.41
 Go version:        go1.13.15
 Git commit:        2291f61
 Built:             Mon Dec 28 16:17:34 2020
 OS/Arch:           linux/amd64
 Context:           default
 Experimental:      true

Server: Docker Engine - Community
 Engine:
  Version:          20.10.2
  API version:      1.41 (minimum version 1.12)
  Go version:       go1.13.15
  Git commit:       8891c58
  Built:            Mon Dec 28 16:15:28 2020
  OS/Arch:          linux/amd64
  Experimental:     false
 containerd:
  Version:          1.4.3
  GitCommit:        269548fa27e0089a8b8278fc4fc781d7f65a939b
 runc:
  Version:          1.0.0-rc92
  GitCommit:        ff819c7e9184c13b7c2607fe6c30ae19403a7aff
 docker-init:
  Version:          0.19.0
  GitCommit:        de40ad0
```

**Output of `docker-compose config`**
(Make sure to add the relevant `-f` and other flags)
```
services:
  nginx:
    image: nginx:alpine
    volumes:
    - www-static:/var/www:rw
  www1:
    image: www1:latest
    volumes:
    - www-static:/usr/src/app/www:rw
  www2:
    image: www2:latest
    volumes:
    - www-static:/usr/src/app/www:rw
  www3:
    image: www3:latest
    volumes:
    - www-static:/usr/src/app/www:rw
version: '3.8'
volumes:
  www-static: {}
```


## Steps to reproduce the issue

1. Containers www1, www2, www3 contain folders /usr/src/app/www/www{1|2|3}, respectively
2. docker-compose up -d
3. docker exec -it nginx sh

### Observed result

/var/www inside nginx container has only one of www1, www2, www3 subfolders - not necessarily always the same

### Expected result

/var/www inside nginx container has www1, www2 **and** www3
",,,,,,,,,,,,,,
8068,OPEN,/tmp/ directory not working for --env-file reference,kind/bug,2021-01-27 17:02:34 +0000 UTC,KetchupBomb,In progress,,"3. When making a bug report, make sure you provide all required information. The easier it is for
   maintainers to reproduce, the faster it'll be fixed.
-->

## Description of the issue

When attempting to source an environment variable file for `docker-compose` which lives in `/tmp/`, the file is seemingly not ""loaded"" such that no variables are set.

I.E. `--env-file /tmp/.env` does not work.

## Context information (for bug reports)

**Output of `docker-compose version`**

```
$ docker-compose version
docker-compose version 1.28.0, build d02a7b1
docker-py version: 4.4.1
CPython version: 3.9.0
OpenSSL version: OpenSSL 1.1.1i  8 Dec 2020
```

**Output of `docker-compose config`**
(Make sure to add the relevant `-f` and other flags)
```
$ docker-compose config
services:
  foo:
    command: sleep 1000
    container_name: foo
    image: busybox
    ports:
    - published: 443
      target: 443
version: '3'
```

**Output of `docker version`**

```
$ docker version
Client: Docker Engine - Community
 Version:           20.10.2
 API version:       1.41
 Go version:        go1.13.15
 Git commit:        2291f61
 Built:             Mon Dec 28 16:17:43 2020
 OS/Arch:           linux/amd64
 Context:           default
 Experimental:      true

Server: Docker Engine - Community
 Engine:
  Version:          20.10.2
  API version:      1.41 (minimum version 1.12)
  Go version:       go1.13.15
  Git commit:       8891c58
  Built:            Mon Dec 28 16:15:19 2020
  OS/Arch:          linux/amd64
  Experimental:     false
 containerd:
  Version:          1.4.3
  GitCommit:        269548fa27e0089a8b8278fc4fc781d7f65a939b
 runc:
  Version:          1.0.0-rc92
  GitCommit:        ff819c7e9184c13b7c2607fe6c30ae19403a7aff
 docker-init:
  Version:          0.19.0
  GitCommit:        de40ad0
```


## Steps to reproduce the issue

1. Copy `.env` file to somewhere in `/tmp/`.
2. Run `docker-compose --env-file /tmp/.env config` to verify environment variables are used.
3. Variables are not set.

### Observed result

```
# PORT is an environment variable
$ grep PORT .env docker-compose.yaml 
.env:PORT=443
docker-compose.yaml:      - ${PORT}:443

# .env file is hard-linked in a few places for clarity and testing
$ ls -lhi .env foo/.env ../.env /tmp/.env 
22020450 -rw-rw-r-- 4 bradking bradking 8 Jan 24 23:38 ../.env
22020450 -rw-rw-r-- 4 bradking bradking 8 Jan 24 23:38 .env
22020450 -rw-rw-r-- 4 bradking bradking 8 Jan 24 23:38 /tmp/.env
22020450 -rw-rw-r-- 4 bradking bradking 8 Jan 24 23:38 foo/.env

# Attempt to use each .env file with config subcommand
$ docker-compose --env-file .env config > /dev/null ; echo $?
0

$ docker-compose --env-file foo/.env config > /dev/null ; echo $?
0

$ docker-compose --env-file ../.env config > /dev/null ; echo $?
0

$ docker-compose --env-file /tmp/.env config > /dev/null ; echo $?
The PORT variable is not set. Defaulting to a blank string.
The Compose file './docker-compose.yaml' is invalid because:
services.foo.ports contains an invalid type, it should be a number, or an object
1
```

### Expected result

I should be able to *read* the `.env` file from `/tmp/`.

### Stacktrace / full error message

```
The PORT variable is not set. Defaulting to a blank string.
The Compose file './docker-compose.yaml' is invalid because:
services.foo.ports contains an invalid type, it should be a number, or an object
```

This error message is only because some fields cannot be blank. This error message does not reveal the fact that it wasn't able to read and/or didn't correctly interpolate environment variables from `/tmp/.env`.

## Additional information

OS version / distribution, `docker-compose` install method, etc.

```
$ uname -a
Linux nuc10 5.4.0-64-generic #72-Ubuntu SMP Fri Jan 15 10:27:54 UTC 2021 x86_64 x86_64 x86_64 GNU/Linux

$ dpkg -S $(which docker)
docker-ce-cli: /usr/bin/docker

$ apt info docker-ce-cli 2> /dev/null | grep APT-sources 
APT-Sources: https://download.docker.com/linux/ubuntu focal/stable amd64 Packages
```
",,,chapa,"
--
I'm facing the same problem, with a env file not located in `/tmp` though.
It works perfectly well with v1.27.4.
--

--
Hum ok, so maybe my problem is not the same as yours.

I tried different configurations and I feel like 1.27.4 take the `--env-file` parameter as relative to the current directory, whereas 1.28.0 take it as relative to the location of the docker-compose.yaml file.

docker-compose.yaml
```yaml
version: '3.4'
services:
    nginx:
        image: nginx:latest
        ports:
            - ""${NGINX_PORT}:80""
```

.env
```
NGINX_PORT=8080
```

Folder structure:
```
.
 subfolder
     docker-compose.yml
     .env
```

With 1.27.4 and cwd-relative path:
```
$ docker-compose -v && docker-compose -f subfolder/docker-compose.yml --env-file ./subfolder/.env config
docker-compose version 1.27.4, build unknown
services:
  nginx:
    image: nginx:latest
    ports:
    - published: 8080
      target: 80
version: '3.4'
```

With 1.27.4 and docker-compose.yaml-relative path:
```
$ docker-compose -v && docker-compose -f subfolder/docker-compose.yml --env-file ./.env config
docker-compose version 1.27.4, build unknown
WARNING: The NGINX_PORT variable is not set. Defaulting to a blank string.
ERROR: The Compose file './subfolder/docker-compose.yml' is invalid because:
services.nginx.ports contains an invalid type, it should be a number, or an object
```

With 1.28.0 and cwd-relative path:
```
$ docker-compose -v && docker-compose -f subfolder/docker-compose.yml --env-file ./subfolder/.env config
docker-compose version 1.28.0, build unknown
WARNING: The NGINX_PORT variable is not set. Defaulting to a blank string.
ERROR: The Compose file './subfolder/docker-compose.yml' is invalid because:
services.nginx.ports contains an invalid type, it should be a number, or an object
```

With 1.28.0 and docker-compose.yaml-relative path:
```
$ docker-compose -v && docker-compose -f subfolder/docker-compose.yml --env-file ./.env config         
docker-compose version 1.28.0, build unknown
services:
  nginx:
    image: nginx:latest
    ports:
    - published: 8080
      target: 80
version: '3.4'
```

Should I open another issue ?
--

--
@KetchupBomb I just tried to reproduce your issue but I don't have any problem with the `.env` file in `/tmp`:
![image](https://user-images.githubusercontent.com/457659/105969849-fe1c0500-6088-11eb-8db0-2784c060b809.png)

But I see in the last command of your ""Observed result"" that you wrote `/tmp/env` instead of `/tmp/.env`, wouldn't this be the problem actually ?
--
",KetchupBomb,"
--
> I'm facing the same problem, with a env file not located in `/tmp` though.
> It works perfectly well with v1.27.4.

I get the same error on 1.27.4 as I did on 1.28.0:

```
$ docker-compose --env-file /tmp/.env config
Unable to find image 'docker/compose:1.27.4' locally
1.27.4: Pulling from docker/compose
aad63a933944: Pull complete 
8f5b9cdf0f6c: Pull complete 
3ba0b1476d03: Pull complete 
6e7bc5ab5405: Pull complete 
Digest: sha256:4479af5256e02c3e7710051706a7abbcd39b0b31b0e306b2c18a0cbc88aee705
Status: Downloaded newer image for docker/compose:1.27.4
WARNING: The PORT variable is not set. Defaulting to a blank string.
ERROR: The Compose file './docker-compose.yaml' is invalid because:
services.foo.ports contains an invalid type, it should be a number, or an object
```
--

--
@chapa, interesting find, though it does appear like these are two separate issues. I'd say open a separate issue.

_This_ issue deals with the fact that `/tmp/` interferes in some way, not that the `--env-file` reference is relative or absolute.
--

--
> But I see in the last command of your ""Observed result"" that you wrote `/tmp/env` instead of `/tmp/.env`, wouldn't this be the problem actually ?

Good catch. Alas, this was a copy and paste error into Github -- the issue is still present. I've corrected the original post, and performing again to drive the point home:

```
$ cat /tmp/.env && docker-compose --env-file /tmp/.env config
PORT=443
WARNING: The PORT variable is not set. Defaulting to a blank string.
ERROR: The Compose file './docker-compose.yaml' is invalid because:
services.foo.ports contains an invalid type, it should be a number, or an object
```
--
",,,,,,,,
8066,OPEN,Golang override docker-compose; name k1s,kind/question,2021-01-24 06:36:58 +0000 UTC,peterwillcn,Opened,,"Golang override docker-compose, name k1s",,,,,,,,,,,,,,
8062,OPEN,More verbose error in project.py,kind/feature,2021-01-22 14:05:55 +0000 UTC,sezanzeb,Opened,,"Seems like I have to create an issue for that change before submitting the PR, so here you go.

**Is your feature request related to a problem? Please describe.**

Yes, AWX failed to install and the error was not displayed

**Describe the solution you'd like**

For the error to be printed

**Describe alternatives you've considered**

none

**Additional context**

```
""msg"": ""Error starting project Encountered errors while bringing up the project""
```

going to submit the PR in a few minutes",,,,,,,,,,,,,,
8059,OPEN,Version 1.28.0 for windows instantly gets deleted by Windows Defender,kind/bug,2021-01-22 12:50:54 +0000 UTC,steinhobelgruen,Opened,,"## Description of the issue

On both Windows 10 and Windows Server 2019 Datacenter with the default malware protection enabled I cannot execute the latest version of docker-compose (as installed from the github releases page). Execution is blocked and just a few seconds after download the file is deleted by Windows Defender. The problem did not exist with version 1.27.4.

It's probably Windows Defender being at fault here, but I thought you might be interested.

## Context information (for bug reports)

**Output of `docker-compose version`**
```
PS C:\Projects> .\docker-compose version
ResourceUnavailable: Program 'docker-compose.exe' failed to run: Operation did not complete successfully because the file contains a virus or potentially unwanted software. At line:1 char:1
+ .\docker-compose version
+ ~~~~~~~~~~~~~~~~~~~~~~~~.
PS C:\Projects>
```

**Output of `docker version`**
```
PS C:\Projects> docker version
Client: Docker Engine - Community
 Cloud integration: 1.0.4
 Version:           20.10.0
 API version:       1.41
 Go version:        go1.13.15
 Git commit:        7287ab3
 Built:             Tue Dec  8 18:55:31 2020
 OS/Arch:           windows/amd64
 Context:           default
 Experimental:      true

Server: Docker Engine - Community
 Engine:
  Version:          20.10.0
  API version:      1.41 (minimum version 1.12)
  Go version:       go1.13.15
  Git commit:       eeddea2
  Built:            Tue Dec  8 18:58:04 2020
  OS/Arch:          linux/amd64
  Experimental:     false
 containerd:
  Version:          v1.4.3
  GitCommit:        269548fa27e0089a8b8278fc4fc781d7f65a939b
 runc:
  Version:          1.0.0-rc92
  GitCommit:        ff819c7e9184c13b7c2607fe6c30ae19403a7aff
 docker-init:
  Version:          0.19.0
  GitCommit:        de40ad0
PS C:\Projects>
```

## Steps to reproduce the issue

0. Have Windows Defender enabled.
1. Download version 1.28.0 from https://github.com/docker/compose/releases/download/1.28.0/docker-compose-Windows-x86_64.exe
2. Watch it getting blocked and deleted instantly.

## Additional information

OS version / distribution,

```
Platform ServicePack Version      VersionString
-------- ----------- -------      -------------
 Win32NT             10.0.17763.0 Microsoft Windows NT 10.0.17763.0
```

`docker-compose` install method, etc.

`docker-compose` downloaded as .exe from github releases page.",,,,,,,,,,,,,,
8056,OPEN,Name resolution bug,kind/bug,2021-01-22 06:02:45 +0000 UTC,akihirof0005,Opened,,"## Description of the issue
If you use the container name for name resolution, the service name will be connected to the other container. Randomly.

## Context information (for bug reports)

**Output of `docker-compose version`**
```
docker-compose version 1.28.0, build unknown
docker-py version: 4.4.1
CPython version: 3.9.1
OpenSSL version: OpenSSL 1.1.1i  8 Dec 2020
```

**Output of `docker version`**
```
Client:
 Version:           20.10.2
 API version:       1.41
 Go version:        go1.15.6
 Git commit:        2291f610ae
 Built:             Tue Jan 19 17:19:21 2021
 OS/Arch:           linux/amd64
 Context:           default
 Experimental:      true

Server:
 Engine:
  Version:          20.10.2
  API version:      1.41 (minimum version 1.12)
  Go version:       go1.15.6
  Git commit:       8891c58a43
  Built:            Tue Jan 19 17:18:55 2021
  OS/Arch:          linux/amd64
  Experimental:     false
 containerd:
  Version:          v1.4.3
  GitCommit:        269548fa27e0089a8b8278fc4fc781d7f65a939b.m
 runc:
  Version:          1.0.0-rc92
  GitCommit:        ff819c7e9184c13b7c2607fe6c30ae19403a7aff
 docker-init:
  Version:          0.19.0
  GitCommit:        de40ad0
```

**Output of `docker-compose config`**
(Make sure to add the relevant `-f` and other flags)
```
version: ""3""
services:
  rest-client:
    container_name: curl
    image: tutum/curl
    command: sleep infinity

  web1:
    container_name: api1
    build: ./api1
    command: ruby main.rb -o 0.0.0.0

  api1:
    container_name: api2
    build: ./api2
    command: ruby main.rb -o 0.0.0.0

networks:
  default:
    name: net1
```


## Steps to reproduce the issue
I have a sample project to reproduce.
```
git clone https://github.com/akihirof0005/Verification-defects.git
cd Verification-defects
docker-compose up -d
docker exec -it curl bash
watch -n 2 curl ""http://api1:4567/""
```
### Observed result
This is app1 container!
This is app1 container!
This is app2 container!
This is app2 container!

note:Results change randomly...

### Expected result
This is app1 container!
This is app1 container!
This is app1 container!
This is app1 container!

### Stacktrace / full error message

```
(paste here)
```

## Additional information
api1 and api2 are running on ruby, but this is irrelevant. In fact, when this first happened, it happened in Java.


linux lts kernel 5.4 Docker version 20.10.2 docker-compose version 1.28.0 with ubuntu and archlinux.

https://github.com/akihirof0005/Verification-defects
",,,,,,,,,,,,,,
8055,OPEN,Any chance of making this decent software?,kind/feature,2021-02-08 21:48:42 +0000 UTC,Cally99,Opened,,"-->

**Is your feature request related to a problem? Please describe.**
A clear and concise description of what the problem is. Ex. I'm always frustrated when [...]

**Describe the solution you'd like**
A clear and concise description of what you want to happen.

**Describe alternatives you've considered**
A clear and concise description of any alternative solutions or features you've considered.

**Additional context**
Add any other context or screenshots about the feature request here.
",,,JamesTheAwesomeDude,"
--
Ah, yes

> A clear and concise description of what the problem is.
--
",Motophan,"
--
He has a point, the entire internet is using 2.x compose because no one understands GPU stanza. 

https://github.com/docker/compose/issues/8107


--
",,,,,,,,
8052,OPEN,docker-compose up crashes when using device_cgroup_rules,kind/bug,2021-01-22 19:00:45 +0000 UTC,dmm,In progress,,"3. When making a bug report, make sure you provide all required information. The easier it is for
   maintainers to reproduce, the faster it'll be fixed.
-->

## Description of the issue

When I try to create a service with the ""device_cgroup_rules"" feature ""docker-compose up"" fails.
For example, this docker-compose.yml file:

    version: '2.4'

    services:
      hello:
        image: hello-world
        device_cgroup_rules:
          - 'a 189:*  rwm'

I get a crash when I run `docker-compose up`. 

A docker command with the same cgroup argument works fine:

`docker run --rm -it --device-cgroup-rule='a 189:* rwm' hello-world:latest`

## Context information (for bug reports)

**Output of `docker-compose version`**
```
docker-compose version 1.28.0, build unknown
docker-py version: 4.4.1
CPython version: 3.9.1
OpenSSL version: OpenSSL 1.1.1i  8 Dec 2020
```

**Output of `docker version`**
```
Client:
 Version:           20.10.2
 API version:       1.41
 Go version:        go1.15.6
 Git commit:        2291f610ae
 Built:             Tue Jan 19 17:19:21 2021
 OS/Arch:           linux/amd64
 Context:           default
 Experimental:      true

Server:
 Engine:
  Version:          20.10.2
  API version:      1.41 (minimum version 1.12)
  Go version:       go1.15.6
  Git commit:       8891c58a43
  Built:            Tue Jan 19 17:18:55 2021
  OS/Arch:          linux/amd64
  Experimental:     false
 containerd:
  Version:          v1.4.3
  GitCommit:        269548fa27e0089a8b8278fc4fc781d7f65a939b.m
 runc:
  Version:          1.0.0-rc92
  GitCommit:        ff819c7e9184c13b7c2607fe6c30ae19403a7aff
 docker-init:
  Version:          0.19.0
  GitCommit:        de40ad0
```

**Output of `docker-compose config`**
(Make sure to add the relevant `-f` and other flags)
```
services:
  hello:
    device_cgroup_rules:
    - a 189:*  rwm
    image: hello-world
version: '2.4'

```


## Steps to reproduce the issue

1. Run `docker-compose up` on a compose file with device_cgroup_rules.


### Observed result

The service fails to create and an error is output.

### Expected result

Compose should create the service container as normal.

### Stacktrace / full error message

I get this cli output:
```
$ docker-compose up
Building with native build. Learn about native build in Compose here: https://docs.docker.com/go/compose-native-build/
Creating network ""asdf_default"" with the default driver
Creating asdf_hello_1 ...

ERROR: for asdf_hello_1  ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))

ERROR: for hello  ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))
ERROR: Couldn't connect to Docker daemon at http+docker://localhost - is it running?

If it's at a non-standard location, specify the URL with the DOCKER_HOST environment variable.
```

The docker daemon has the following log output:
```
an 21 08:40:24 <<hostname>> dockerd[563]: http: panic serving @: runtime error: index out of range [0] with length 0
                                      goroutine 1790 [running]:
                                      net/http.(*conn).serve.func1(0xc000e53400)
                                              net/http/server.go:1801 +0x147
                                      panic(0x5632fe2500a0, 0xc000e62480)
                                              runtime/panic.go:975 +0x47a
                                      github.com/docker/docker/oci.AppendDevicePermissionsFromCgroupRules(0xc00095d6c0, 0x8, 0x8, 0xc0079329c0, 0x1, 0x4, 0x0, 0x0, 0xc001213dc0, 0xc000e09630, ...)
                                              github.com/docker/docker/oci/oci.go:34 +0x665
                                      github.com/docker/docker/daemon.WithDevices.func1(0x5632fe47eb60, 0xc000052038, 0x0, 0x0, 0xc000eea5a0, 0xc000f08f00, 0x0, 0x0)
                                              github.com/docker/docker/daemon/oci_linux.go:916 +0x3d4
                                      github.com/docker/docker/vendor/github.com/containerd/containerd/oci.ApplyOpts(0x5632fe47eb60, 0xc000052038, 0x0, 0x0, 0xc000eea5a0, 0xc000f08f00, 0xc00105fd00, 0x11, 0x20, >
                                              github.com/docker/docker/vendor/github.com/containerd/containerd/oci/spec.go:85 +0x9e
                                      github.com/docker/docker/daemon.(*Daemon).createSpec(0xc00000c1e0, 0xc000e9d900, 0x0, 0x0, 0x1)
                                              github.com/docker/docker/daemon/oci_linux.go:1046 +0x52f
                                      github.com/docker/docker/daemon.(*Daemon).containerStart(0xc00000c1e0, 0xc000e9d900, 0x0, 0x0, 0x0, 0x0, 0x1, 0x0, 0x0)
                                              github.com/docker/docker/daemon/start.go:153 +0x34d
                                      github.com/docker/docker/daemon.(*Daemon).ContainerStart(0xc00000c1e0, 0xc007b07827, 0x40, 0x0, 0x0, 0x0, 0x0, 0x0, 0xc000c97110, 0x5632fbfb913d)
                                              github.com/docker/docker/daemon/start.go:94 +0x1ca
                                      github.com/docker/docker/api/server/router/container.(*containerRouter).postContainersStart(0xc000458c80, 0x5632fe47ebe0, 0xc001802390, 0x5632fe46ed20, 0xc000bdcd20, 0xc0010>
                                              github.com/docker/docker/api/server/router/container/container_routes.go:210 +0x270
                                      github.com/docker/docker/api/server/middleware.ExperimentalMiddleware.WrapHandler.func1(0x5632fe47ebe0, 0xc001802390, 0x5632fe46ed20, 0xc000bdcd20, 0xc00105f600, 0xc0018022d>
                                              github.com/docker/docker/api/server/middleware/experimental.go:26 +0x17d
                                      github.com/docker/docker/api/server/middleware.VersionMiddleware.WrapHandler.func1(0x5632fe47ebe0, 0xc001802360, 0x5632fe46ed20, 0xc000bdcd20, 0xc00105f600, 0xc0018022d0, 0x>
                                              github.com/docker/docker/api/server/middleware/version.go:62 +0x617
                                      github.com/docker/docker/pkg/authorization.(*Middleware).WrapHandler.func1(0x5632fe47ebe0, 0xc001802360, 0x5632fe46ed20, 0xc000bdcd20, 0xc00105f600, 0xc0018022d0, 0x5632fe47>
                                              github.com/docker/docker/pkg/authorization/middleware.go:59 +0x822
                                      github.com/docker/docker/api/server.(*Server).makeHTTPHandler.func1(0x5632fe46ed20, 0xc000bdcd20, 0xc00105f500)
                                              github.com/docker/docker/api/server/server.go:141 +0x258
                                      net/http.HandlerFunc.ServeHTTP(0xc00113adc0, 0x5632fe46ed20, 0xc000bdcd20, 0xc00105f500)
                                              net/http/server.go:2042 +0x46
                                      github.com/docker/docker/vendor/github.com/gorilla/mux.(*Router).ServeHTTP(0xc000fca480, 0x5632fe46ed20, 0xc000bdcd20, 0xc00105f300)
                                              github.com/docker/docker/vendor/github.com/gorilla/mux/mux.go:210 +0xd3
                                      net/http.serverHandler.ServeHTTP(0xc00025e0e0, 0x5632fe46ed20, 0xc000bdcd20, 0xc00105f300)
                                              net/http/server.go:2843 +0xa5
                                      net/http.(*conn).serve(0xc000e53400, 0x5632fe47eb20, 0xc007933d40)
                                              net/http/server.go:1925 +0x8ad
                                      created by net/http.(*Server).Serve
                                              net/http/server.go:2969 +0x36c
```

## Additional information

I'm on Arch but the problem was also present on different machine running Debian 10.

",,,thaJeztah,"
--
Thanks for reporting; this looks to be a bug in the daemon code, which should produce a regular error.

Looks like the rule you specified has an additional space before `rwm`, which causes the parser to not match it;

It should work after removing the extra space;

```
a 189:* rwm
```

I'm working on a fix to at least prevent the panic in the daemon; I'll have to check if the validation could be ""relaxed"" (i.e., if multiple spaces should be allowed or not)
--

--
Opened a pull request to prevent the panic on the daemon side when an invalid rule is set; https://github.com/moby/moby/pull/41919
--
",dmm,"
--
Thanks for figuring this out! That extra space was driving me crazy.
--
",,,,,,,,
8051,OPEN,docker-compose up converts linux path to windows for volumes,kind/bug,2021-01-21 14:05:14 +0000 UTC,AlekseiPavlov-GC,Opened,,"Hi colleagues,

**Steps to reproduce**

Docker 3.1.0 (51484) running with WSL2 on Windows 10 version 1909.

I try to execute the script using Windows Powershell 7.1:
`docker-compose -f ""docker-compose.generated.json"" up --build  --remove-orphans --renew-anon-volumes --force-recreate  --always-recreate-deps`

The json file has the following section:
```
""volumes"": {
       ""inputansibleconfigvolume"": {
          ""driver_opts"": {
             ""type"": ""none"",
             ""device"": ""${ANSIBLE_CONFIGS}"",
             ""o"": ""bind""
          }
       }
    }
```

The Environment Variable _ANSIBLE_CONFIGS_ is set to: _/c/Dev/Git/folder_

**When I execute the command:**
`docker-compose -f ""docker-compose.generated.json"" up --build  --remove-orphans --renew-anon-volumes --force-recreate  --always-recreate-deps`

A docker volume is created.

**Actual:**
device: ""C:\\c\\Dev\\Git\\folder""
Or depending on different manipulations device value can be a slightly different but always in Windows style.

**Expected:**
device: ""/c/Dev/Git/folder""

**I tried:**
COMPOSE_CONVERT_WINDOWS_PATHS=1
COMPOSE_CONVERT_WINDOWS_PATHS=0

This had no effect.

**Workaround:**
```
""volumes"": {
       ""inputansibleconfigvolume"": {
          ""external"" true
       }
    }
```

`docker volume create --name inputansibleconfigvolume -o type=none -o device=/c/Dev/Git/folder -o o=bind`

Could you please check this?",,,,,,,,,,,,,,
8050,OPEN,Inconsitent error logging in 1.28.0 (in docker-compose exec),kind/bug,2021-01-21 13:35:21 +0000 UTC,agrzegorczyk-leonsoftware,Opened,,"3. When making a bug report, make sure you provide all required information. The easier it is for
   maintainers to reproduce, the faster it'll be fixed.
-->

## Description of the issue

In version 1.28.0 when scripts executed with `docker compose exec` returns exit code > 0 message ""ERROR: <exit code>"" is logged and displayed in console.
I suppose that this is caused by these changes: https://github.com/docker/compose/commit/369eb322#diff-452576c2a6c1b1db7fd4844a6b166dd37fd349c431c9bd7c941d87a6dfaffca3R104-R120
( exit_with_metrics always logging an error when exit_code > 0)
Temporary workaround is set --log-level CRITICAL when invoking `docker-compose exec`.

## Context information (for bug reports)

**Output of `docker-compose version`**
```
docker-compose version 1.28.0, build d02a7b1a
```



## Steps to reproduce the issue

1. Run via `docker-compose exec` any script that returns exit code > 0

### Observed result
![image (1)](https://user-images.githubusercontent.com/45293460/105356549-d691ec00-5bf3-11eb-9289-096fb4c284ad.png)

### Expected result
No ERROR messages

",,,,,,,,,,,,,,
8049,OPEN,docker-compose up -d fails on centos7,kind/bug,2021-01-24 12:09:54 +0000 UTC,zlpqingmei,Opened,,"3. When making a bug report, make sure you provide all required information. The easier it is for
   maintainers to reproduce, the faster it'll be fixed.
-->

## Description of the issue

## Context information (for bug reports)

**Output of `docker-compose version`**
```
docker-compose -v
docker-compose version 1.28.0, build unknown

```

**Output of `docker version`**
```
docker-compose -v
docker-compose version 1.28.0, build unknown

```

**Output of `docker-compose config`**
(Make sure to add the relevant `-f` and other flags)
```
(paste here)
```


## Steps to reproduce the issue

1.docker-compose up -d 

### Observed result

### Expected result

### Stacktrace / full error message

```
Step 5/6 : RUN apk --no-cache add --virtual build-dependencies maven openjdk8     && cd /src && mvn package javadoc:javadoc && cp /src/explorer/target/*.war /var/lib/jetty/webapps/ROOT.war     && cp -a /src/anc/target/site/apidocs /var/lib/jetty/webapps/ && cd / && rm -r /src /root/.m2 && apk del build-dependencies
 ---> Running in f5bb7ed836d8
fetch http://dl-cdn.alpinelinux.org/alpine/v3.9/main/x86_64/APKINDEX.tar.gz
fetch http://dl-cdn.alpinelinux.org/alpine/v3.9/community/x86_64/APKINDEX.tar.gz
(1/3) Installing maven (3.6.0-r0)
(2/3) Installing openjdk8 (8.252.09-r0)
(3/3) Installing build-dependencies (0)
Executing busybox-1.29.3-r10.trigger
Executing java-common-0.1-r0.trigger
OK: 113 MiB in 56 packages
[INFO] Scanning for projects...
Downloading from vaadin-prereleases: http://maven.vaadin.com/vaadin-prereleases/com/vaadin/vaadin-bom/8.4.3/vaadin-bom-8.4.3.pom
Downloading from opendaylight-mirror: https://nexus.opendaylight.org/content/repositories/public/com/vaadin/vaadin-bom/8.4.3/vaadin-bom-8.4.3.pom
Downloading from vaadin-addons: http://maven.vaadin.com/vaadin-addons/com/vaadin/vaadin-bom/8.4.3/vaadin-bom-8.4.3.pom
Downloading from central: https://repo.maven.apache.org/maven2/com/vaadin/vaadin-bom/8.4.3/vaadin-bom-8.4.3.pom
[ERROR] [ERROR] Some problems were encountered while processing the POMs:
[ERROR] Non-resolvable import POM: Could not transfer artifact com.vaadin:vaadin-bom:pom:8.4.3 from/to opendaylight-mirror (https://nexus.opendaylight.org/content/repositories/public/): Connect to nexus.opendaylight.org:443 [nexus.opendaylight.org/199.204.45.87] failed: Operation timed out (Connection timed out) @ line 36, column 16
[ERROR] 'dependencies.dependency.version' for com.vaadin:vaadin-server:jar is missing. @ line 53, column 15
[ERROR] 'dependencies.dependency.version' for com.vaadin:vaadin-push:jar is missing. @ line 57, column 15
[ERROR] 'dependencies.dependency.version' for com.vaadin:vaadin-client-compiled:jar is missing. @ line 61, column 15
[ERROR] 'dependencies.dependency.version' for com.vaadin:vaadin-themes:jar is missing. @ line 65, column 15
 @ 
[ERROR] The build could not read 1 project -> [Help 1]
[ERROR]   
[ERROR]   The project com.cisco.stbarth.netconf.anx:explorer:1.0-SNAPSHOT (/src/explorer/pom.xml) has 5 errors
[ERROR]     Non-resolvable import POM: Could not transfer artifact com.vaadin:vaadin-bom:pom:8.4.3 from/to opendaylight-mirror (https://nexus.opendaylight.org/content/repositories/public/): Connect to nexus.opendaylight.org:443 [nexus.opendaylight.org/199.204.45.87] failed: Operation timed out (Connection timed out) @ line 36, column 16 -> [Help 2]
[ERROR]     'dependencies.dependency.version' for com.vaadin:vaadin-server:jar is missing. @ line 53, column 15
[ERROR]     'dependencies.dependency.version' for com.vaadin:vaadin-push:jar is missing. @ line 57, column 15
[ERROR]     'dependencies.dependency.version' for com.vaadin:vaadin-client-compiled:jar is missing. @ line 61, column 15
[ERROR]     'dependencies.dependency.version' for com.vaadin:vaadin-themes:jar is missing. @ line 65, column 15
[ERROR] 
[ERROR] To see the full stack trace of the errors, re-run Maven with the -e switch.
[ERROR] Re-run Maven using the -X switch to enable full debug logging.
[ERROR] 
[ERROR] For more information about the errors and possible solutions, please read the following articles:
[ERROR] [Help 1] http://cwiki.apache.org/confluence/display/MAVEN/ProjectBuildingException
[ERROR] [Help 2] http://cwiki.apache.org/confluence/display/MAVEN/UnresolvableModelException
The command '/bin/sh -c apk --no-cache add --virtual build-dependencies maven openjdk8     && cd /src && mvn package javadoc:javadoc && cp /src/explorer/target/*.war /var/lib/jetty/webapps/ROOT.war     && cp -a /src/anc/target/site/apidocs /var/lib/jetty/webapps/ && cd / && rm -r /src /root/.m2 && apk del build-dependencies' returned a non-zero code: 1
ERROR: Service 'anx' failed to build

```

## Additional information

OS version / distribution, `docker-compose` install method, etc.
",,,albers,"
--
The information you gave is not sufficient to reproduce the issue.

Looking at the output you seem to have issued `docker-compose up -d`  in a project with a `docker-compose.yml` file that contains a build instruction for (at least) one service. This triggered an image build which included a maven build of a java project.
This maven build failed because an artifact could not be downloaded from a remote maven repository due to a network connect timeout:
>Could not transfer artifact com.vaadin:vaadin-bom:pom:8.4.3 from/to opendaylight-mirror (https://nexus.opendaylight.org/content/repositories/public/): Connect to nexus.opendaylight.org:443 [nexus.opendaylight.org/199.204.45.87] failed: Operation timed out (Connection timed out)

In this setting, docker-compose would only trigger the image build. The image build would then be performed by docker. So any network problems during the image build would be either application specific (maven), network issues (can docker access the internet on port 443?) or - most unlikely - a bug in docker.

Please provide more context.
--
",,,,,,,,,,
8046,OPEN,error build image when context is URL from git repository and dockerfile path is not default,kind/bug,2021-02-04 13:36:21 +0000 UTC,goshander,In progress,,"3. When making a bug report, make sure you provide all required information. The easier it is for
   maintainers to reproduce, the faster it'll be fixed.
-->

## Description of the issue

Error build image when context from git and dockerfile path is not default

docker-compose joined URL from git and dockerfile path to temp folder. It is wrong. Temp folder with repo was correctly created

## Context information (for bug reports)

**Output of `docker-compose version`**
```
docker-compose version 1.28.0, build d02a7b1a
docker-py version: 4.4.1
CPython version: 3.9.0
OpenSSL version: OpenSSL 1.1.1d  10 Sep 2019
```

**Output of `docker version`**
```
Client: Docker Engine - Community
 Version:           20.10.2
 API version:       1.40
 Go version:        go1.13.15
 Git commit:        2291f61
 Built:             Mon Dec 28 16:17:43 2020
 OS/Arch:           linux/amd64
 Context:           default
 Experimental:      true

Server: Docker Engine - Community
 Engine:
  Version:          19.03.12
  API version:      1.40 (minimum version 1.12)
  Go version:       go1.13.10
  Git commit:       48a66213fe
  Built:            Mon Jun 22 15:49:35 2020
  OS/Arch:          linux/amd64
  Experimental:     false
 containerd:
  Version:          v1.2.13
  GitCommit:        7ad184331fa3e55e52b890ea95e65ba581ae3429
 runc:
  Version:          1.0.0-rc10
  GitCommit:        dc9208a3303feef5b3839f4323d9beb36df0a9dd
 docker-init:
  Version:          0.18.0
  GitCommit:        fec3683
```

**Output of `docker-compose config`**
(Make sure to add the relevant `-f` and other flags)
```
networks:
  local:
    driver: bridge
  web:
    driver: bridge
services:
  mqtt_server:
    build:
      context: git@git.server.local:mqtt/mqtt_server.git
      dockerfile: ./docker/production.dockerfile
    container_name: mqtt_server
    environment:
      MQTT_SERVER_HOST: 0.0.0.0
      MQTT_SERVER_PASSWORD: '12345678'
      MQTT_SERVER_PORT: '1883'
      MQTT_SERVER_USER: mqtt
      MQTT_SERVER_WS_PORT: '1884'
      NODE_ENV: development
    image: mqtt_server:dev
    networks:
      local: null
      web: null
    ports:
    - published: 1883
      target: 1883
    - published: 1884
      target: 1884
    restart: unless-stopped
version: '3.4'
```


## Steps to reproduce the issue

1. Use git repository in context by ssh connection
2. Specify not default dockerfile path in build.dockerfile section

### Observed result

Error in context folder path. docker-compose join URL to local folder temp path

### Expected result

Success building image

### Stacktrace / full error message

```
unable to prepare context: unable to evaluate symlinks in Dockerfile path: lstat /tmp/docker-build-git191303832/git@git.server.local:mqtt: no such file or directory
ERROR: Service 'mqtt_server' failed to build
```

## Additional information

OS version

Distributor ID: Ubuntu
Description:    Ubuntu 20.04.1 LTS
Release:        20.04
Codename:       focal

Same issue on Windows 10 and private git repo. I think, that error in this file: service.py line 1857
When I use python docker-compose package with this fix (add `not is_url(path)`) all works fine

```python
        if dockerfile and not is_url(path):
            dockerfile = os.path.join(path, dockerfile)
```
",,,vblagoje,"
--
I can confirm that I am also experiencing this bug. Instead of git URL (e.g. git@git.server.local:mqtt/mqtt_server.git) I used https but I got the same error. Note that I can build from the remote repo using native docker build e.g:
`docker build https://github.com/huggingface/transformers.git#master -f docker/transformers-pytorch-gpu/Dockerfile` @goshander, as you already have the fix, can you please create a PR with a test for both git and https URL types? Perhaps that will help get the fix integrated sooner rather than later. 
--
",goshander,"
--
@vblagoje I'll try to do it, I'm glad that there was some kind of response
--
",jsangmeister,"
--
I think this has something to do with the new ""native build routine"". Setting `COMPOSE_DOCKER_CLI_BUILD=0` solves the issue for me.
--
",,,,,,
8044,OPEN,test_custom_timeout_error test_docker_client_no_home test_docker_client_with_custom_timeout test_user_agent fail while building the package,kind/bug,2021-01-19 22:38:36 +0000 UTC,mcepl,Opened,,"## Description of the issue
When building package for openSUSE/Factory (tarball 1.26.2, no patch) I get the above listed tests failing:
```
[   45s] =================================== FAILURES ===================================
[   45s] ________________ DockerClientTestCase.test_custom_timeout_error ________________
[   45s] /usr/lib/python3.6/site-packages/urllib3/connectionpool.py:706: in urlopen
[   45s]     chunked=chunked,
[   45s] /usr/lib/python3.6/site-packages/urllib3/connectionpool.py:394: in _make_request
[   45s]     conn.request(method, url, **httplib_request_kw)
[   45s] /usr/lib64/python3.6/http/client.py:1287: in request
[   45s]     self._send_request(method, url, body, headers, encode_chunked)
[   45s] /usr/lib64/python3.6/http/client.py:1333: in _send_request
[   45s]     self.endheaders(body, encode_chunked=encode_chunked)
[   45s] /usr/lib64/python3.6/http/client.py:1282: in endheaders
[   45s]     self._send_output(message_body, encode_chunked=encode_chunked)
[   45s] /usr/lib64/python3.6/http/client.py:1042: in _send_output
[   45s]     self.send(msg)
[   45s] /usr/lib64/python3.6/http/client.py:980: in send
[   45s]     self.connect()
[   45s] /usr/lib/python3.6/site-packages/docker/transport/unixconn.py:43: in connect
[   45s]     sock.connect(self.unix_socket)
[   45s] E   FileNotFoundError: [Errno 2] No such file or directory
[   45s] 
[   45s] During handling of the above exception, another exception occurred:
[   45s] /usr/lib/python3.6/site-packages/requests/adapters.py:449: in send
[   45s]     timeout=timeout
[   45s] /usr/lib/python3.6/site-packages/urllib3/connectionpool.py:756: in urlopen
[   45s]     method, url, error=e, _pool=self, _stacktrace=sys.exc_info()[2]
[   45s] /usr/lib/python3.6/site-packages/urllib3/util/retry.py:531: in increment
[   45s]     raise six.reraise(type(error), error, _stacktrace)
[   45s] /usr/lib/python3.6/site-packages/urllib3/packages/six.py:734: in reraise
[   45s]     raise value.with_traceback(tb)
[   45s] /usr/lib/python3.6/site-packages/urllib3/connectionpool.py:706: in urlopen
[   45s]     chunked=chunked,
[   45s] /usr/lib/python3.6/site-packages/urllib3/connectionpool.py:394: in _make_request
[   45s]     conn.request(method, url, **httplib_request_kw)
[   45s] /usr/lib64/python3.6/http/client.py:1287: in request
[   45s]     self._send_request(method, url, body, headers, encode_chunked)
[   45s] /usr/lib64/python3.6/http/client.py:1333: in _send_request
[   45s]     self.endheaders(body, encode_chunked=encode_chunked)
[   45s] /usr/lib64/python3.6/http/client.py:1282: in endheaders
[   45s]     self._send_output(message_body, encode_chunked=encode_chunked)
[   45s] /usr/lib64/python3.6/http/client.py:1042: in _send_output
[   45s]     self.send(msg)
[   45s] /usr/lib64/python3.6/http/client.py:980: in send
[   45s]     self.connect()
[   45s] /usr/lib/python3.6/site-packages/docker/transport/unixconn.py:43: in connect
[   45s]     sock.connect(self.unix_socket)
[   45s] E   urllib3.exceptions.ProtocolError: ('Connection aborted.', FileNotFoundError(2, 'No such file or directory'))
[   45s] 
[   45s] During handling of the above exception, another exception occurred:
[   45s] /usr/lib/python3.6/site-packages/docker/api/client.py:214: in _retrieve_server_version
[   45s]     return self.version(api_version=False)[""ApiVersion""]
[   45s] /usr/lib/python3.6/site-packages/docker/api/daemon.py:181: in version
[   45s]     return self._result(self._get(url), json=True)
[   45s] /usr/lib/python3.6/site-packages/docker/utils/decorators.py:46: in inner
[   45s]     return f(self, *args, **kwargs)
[   45s] /usr/lib/python3.6/site-packages/docker/api/client.py:237: in _get
[   45s]     return self.get(url, **self._set_request_timeout(kwargs))
[   45s] /usr/lib/python3.6/site-packages/requests/sessions.py:555: in get
[   45s]     return self.request('GET', url, **kwargs)
[   45s] /usr/lib/python3.6/site-packages/requests/sessions.py:542: in request
[   45s]     resp = self.send(prep, **send_kwargs)
[   45s] /usr/lib/python3.6/site-packages/requests/sessions.py:655: in send
[   45s]     r = adapter.send(request, **kwargs)
[   45s] /usr/lib/python3.6/site-packages/requests/adapters.py:498: in send
[   45s]     raise ConnectionError(err, request=request)
[   45s] E   requests.exceptions.ConnectionError: ('Connection aborted.', FileNotFoundError(2, 'No such file or directory'))
[   45s] 
[   45s] During handling of the above exception, another exception occurred:
[   45s] tests/unit/cli/docker_client_test.py:40: in test_custom_timeout_error
[   45s]     client = docker_client(os.environ)
[   45s] compose/cli/docker_client.py:174: in docker_client
[   45s]     client = APIClient(**kwargs)
[   45s] /usr/lib/python3.6/site-packages/docker/api/client.py:197: in __init__
[   45s]     self._version = self._retrieve_server_version()
[   45s] /usr/lib/python3.6/site-packages/docker/api/client.py:222: in _retrieve_server_version
[   45s]     'Error while fetching server API version: {0}'.format(e)
[   45s] E   docker.errors.DockerException: Error while fetching server API version: ('Connection aborted.', FileNotFoundError(2, 'No such file or directory'))
[   45s] _______________ DockerClientTestCase.test_docker_client_no_home ________________
[   45s] /usr/lib/python3.6/site-packages/urllib3/connectionpool.py:706: in urlopen
[   45s]     chunked=chunked,
[   45s] /usr/lib/python3.6/site-packages/urllib3/connectionpool.py:394: in _make_request
[   45s]     conn.request(method, url, **httplib_request_kw)
[   45s] /usr/lib64/python3.6/http/client.py:1287: in request
[   45s]     self._send_request(method, url, body, headers, encode_chunked)
[   45s] /usr/lib64/python3.6/http/client.py:1333: in _send_request
[   45s]     self.endheaders(body, encode_chunked=encode_chunked)
[   45s] /usr/lib64/python3.6/http/client.py:1282: in endheaders
[   45s]     self._send_output(message_body, encode_chunked=encode_chunked)
[   45s] /usr/lib64/python3.6/http/client.py:1042: in _send_output
[   45s]     self.send(msg)
[   45s] /usr/lib64/python3.6/http/client.py:980: in send
[   45s]     self.connect()
[   45s] /usr/lib/python3.6/site-packages/docker/transport/unixconn.py:43: in connect
[   45s]     sock.connect(self.unix_socket)
[   45s] E   FileNotFoundError: [Errno 2] No such file or directory
[   45s] 
[   45s] During handling of the above exception, another exception occurred:
[   45s] /usr/lib/python3.6/site-packages/requests/adapters.py:449: in send
[   45s]     timeout=timeout
[   45s] /usr/lib/python3.6/site-packages/urllib3/connectionpool.py:756: in urlopen
[   45s]     method, url, error=e, _pool=self, _stacktrace=sys.exc_info()[2]
[   45s] /usr/lib/python3.6/site-packages/urllib3/util/retry.py:531: in increment
[   45s]     raise six.reraise(type(error), error, _stacktrace)
[   45s] /usr/lib/python3.6/site-packages/urllib3/packages/six.py:734: in reraise
[   45s]     raise value.with_traceback(tb)
[   45s] /usr/lib/python3.6/site-packages/urllib3/connectionpool.py:706: in urlopen
[   45s]     chunked=chunked,
[   45s] /usr/lib/python3.6/site-packages/urllib3/connectionpool.py:394: in _make_request
[   45s]     conn.request(method, url, **httplib_request_kw)
[   45s] /usr/lib64/python3.6/http/client.py:1287: in request
[   45s]     self._send_request(method, url, body, headers, encode_chunked)
[   45s] /usr/lib64/python3.6/http/client.py:1333: in _send_request
[   45s]     self.endheaders(body, encode_chunked=encode_chunked)
[   45s] /usr/lib64/python3.6/http/client.py:1282: in endheaders
[   45s]     self._send_output(message_body, encode_chunked=encode_chunked)
[   45s] /usr/lib64/python3.6/http/client.py:1042: in _send_output
[   45s]     self.send(msg)
[   45s] /usr/lib64/python3.6/http/client.py:980: in send
[   45s]     self.connect()
[   45s] /usr/lib/python3.6/site-packages/docker/transport/unixconn.py:43: in connect
[   45s]     sock.connect(self.unix_socket)
[   45s] E   urllib3.exceptions.ProtocolError: ('Connection aborted.', FileNotFoundError(2, 'No such file or directory'))
[   45s] 
[   45s] During handling of the above exception, another exception occurred:
[   45s] /usr/lib/python3.6/site-packages/docker/api/client.py:214: in _retrieve_server_version
[   45s]     return self.version(api_version=False)[""ApiVersion""]
[   45s] /usr/lib/python3.6/site-packages/docker/api/daemon.py:181: in version
[   45s]     return self._result(self._get(url), json=True)
[   45s] /usr/lib/python3.6/site-packages/docker/utils/decorators.py:46: in inner
[   45s]     return f(self, *args, **kwargs)
[   45s] /usr/lib/python3.6/site-packages/docker/api/client.py:237: in _get
[   45s]     return self.get(url, **self._set_request_timeout(kwargs))
[   45s] /usr/lib/python3.6/site-packages/requests/sessions.py:555: in get
[   45s]     return self.request('GET', url, **kwargs)
[   45s] /usr/lib/python3.6/site-packages/requests/sessions.py:542: in request
[   45s]     resp = self.send(prep, **send_kwargs)
[   45s] /usr/lib/python3.6/site-packages/requests/sessions.py:655: in send
[   45s]     r = adapter.send(request, **kwargs)
[   45s] /usr/lib/python3.6/site-packages/requests/adapters.py:498: in send
[   45s]     raise ConnectionError(err, request=request)
[   45s] E   requests.exceptions.ConnectionError: ('Connection aborted.', FileNotFoundError(2, 'No such file or directory'))
[   45s] 
[   45s] During handling of the above exception, another exception occurred:
[   45s] tests/unit/cli/docker_client_test.py:29: in test_docker_client_no_home
[   45s]     docker_client(os.environ)
[   45s] compose/cli/docker_client.py:174: in docker_client
[   45s]     client = APIClient(**kwargs)
[   45s] /usr/lib/python3.6/site-packages/docker/api/client.py:197: in __init__
[   45s]     self._version = self._retrieve_server_version()
[   45s] /usr/lib/python3.6/site-packages/docker/api/client.py:222: in _retrieve_server_version
[   45s]     'Error while fetching server API version: {0}'.format(e)
[   45s] E   docker.errors.DockerException: Error while fetching server API version: ('Connection aborted.', FileNotFoundError(2, 'No such file or directory'))
[   45s] _________ DockerClientTestCase.test_docker_client_with_custom_timeout __________
[   45s] /usr/lib/python3.6/site-packages/urllib3/connectionpool.py:706: in urlopen
[   45s]     chunked=chunked,
[   45s] /usr/lib/python3.6/site-packages/urllib3/connectionpool.py:394: in _make_request
[   45s]     conn.request(method, url, **httplib_request_kw)
[   45s] /usr/lib64/python3.6/http/client.py:1287: in request
[   45s]     self._send_request(method, url, body, headers, encode_chunked)
[   45s] /usr/lib64/python3.6/http/client.py:1333: in _send_request
[   45s]     self.endheaders(body, encode_chunked=encode_chunked)
[   45s] /usr/lib64/python3.6/http/client.py:1282: in endheaders
[   45s]     self._send_output(message_body, encode_chunked=encode_chunked)
[   45s] /usr/lib64/python3.6/http/client.py:1042: in _send_output
[   45s]     self.send(msg)
[   45s] /usr/lib64/python3.6/http/client.py:980: in send
[   45s]     self.connect()
[   45s] /usr/lib/python3.6/site-packages/docker/transport/unixconn.py:43: in connect
[   45s]     sock.connect(self.unix_socket)
[   45s] E   FileNotFoundError: [Errno 2] No such file or directory
[   45s] 
[   45s] During handling of the above exception, another exception occurred:
[   45s] /usr/lib/python3.6/site-packages/requests/adapters.py:449: in send
[   45s]     timeout=timeout
[   45s] /usr/lib/python3.6/site-packages/urllib3/connectionpool.py:756: in urlopen
[   45s]     method, url, error=e, _pool=self, _stacktrace=sys.exc_info()[2]
[   45s] /usr/lib/python3.6/site-packages/urllib3/util/retry.py:531: in increment
[   45s]     raise six.reraise(type(error), error, _stacktrace)
[   45s] /usr/lib/python3.6/site-packages/urllib3/packages/six.py:734: in reraise
[   45s]     raise value.with_traceback(tb)
[   45s] /usr/lib/python3.6/site-packages/urllib3/connectionpool.py:706: in urlopen
[   45s]     chunked=chunked,
[   45s] /usr/lib/python3.6/site-packages/urllib3/connectionpool.py:394: in _make_request
[   45s]     conn.request(method, url, **httplib_request_kw)
[   45s] /usr/lib64/python3.6/http/client.py:1287: in request
[   45s]     self._send_request(method, url, body, headers, encode_chunked)
[   45s] /usr/lib64/python3.6/http/client.py:1333: in _send_request
[   45s]     self.endheaders(body, encode_chunked=encode_chunked)
[   45s] /usr/lib64/python3.6/http/client.py:1282: in endheaders
[   45s]     self._send_output(message_body, encode_chunked=encode_chunked)
[   45s] /usr/lib64/python3.6/http/client.py:1042: in _send_output
[   45s]     self.send(msg)
[   45s] /usr/lib64/python3.6/http/client.py:980: in send
[   45s]     self.connect()
[   45s] /usr/lib/python3.6/site-packages/docker/transport/unixconn.py:43: in connect
[   45s]     sock.connect(self.unix_socket)
[   45s] E   urllib3.exceptions.ProtocolError: ('Connection aborted.', FileNotFoundError(2, 'No such file or directory'))
[   45s] 
[   45s] During handling of the above exception, another exception occurred:
[   45s] /usr/lib/python3.6/site-packages/docker/api/client.py:214: in _retrieve_server_version
[   45s]     return self.version(api_version=False)[""ApiVersion""]
[   45s] /usr/lib/python3.6/site-packages/docker/api/daemon.py:181: in version
[   45s]     return self._result(self._get(url), json=True)
[   45s] /usr/lib/python3.6/site-packages/docker/utils/decorators.py:46: in inner
[   45s]     return f(self, *args, **kwargs)
[   45s] /usr/lib/python3.6/site-packages/docker/api/client.py:237: in _get
[   45s]     return self.get(url, **self._set_request_timeout(kwargs))
[   45s] /usr/lib/python3.6/site-packages/requests/sessions.py:555: in get
[   45s]     return self.request('GET', url, **kwargs)
[   45s] /usr/lib/python3.6/site-packages/requests/sessions.py:542: in request
[   45s]     resp = self.send(prep, **send_kwargs)
[   45s] /usr/lib/python3.6/site-packages/requests/sessions.py:655: in send
[   45s]     r = adapter.send(request, **kwargs)
[   45s] /usr/lib/python3.6/site-packages/requests/adapters.py:498: in send
[   45s]     raise ConnectionError(err, request=request)
[   45s] E   requests.exceptions.ConnectionError: ('Connection aborted.', FileNotFoundError(2, 'No such file or directory'))
[   45s] 
[   45s] During handling of the above exception, another exception occurred:
[   45s] tests/unit/cli/docker_client_test.py:34: in test_docker_client_with_custom_timeout
[   45s]     client = docker_client(os.environ)
[   45s] compose/cli/docker_client.py:174: in docker_client
[   45s]     client = APIClient(**kwargs)
[   45s] /usr/lib/python3.6/site-packages/docker/api/client.py:197: in __init__
[   45s]     self._version = self._retrieve_server_version()
[   45s] /usr/lib/python3.6/site-packages/docker/api/client.py:222: in _retrieve_server_version
[   45s]     'Error while fetching server API version: {0}'.format(e)
[   45s] E   docker.errors.DockerException: Error while fetching server API version: ('Connection aborted.', FileNotFoundError(2, 'No such file or directory'))
[   45s] _____________________ DockerClientTestCase.test_user_agent _____________________
[   45s] /usr/lib/python3.6/site-packages/urllib3/connectionpool.py:706: in urlopen
[   45s]     chunked=chunked,
[   45s] /usr/lib/python3.6/site-packages/urllib3/connectionpool.py:394: in _make_request
[   45s]     conn.request(method, url, **httplib_request_kw)
[   45s] /usr/lib64/python3.6/http/client.py:1287: in request
[   45s]     self._send_request(method, url, body, headers, encode_chunked)
[   45s] /usr/lib64/python3.6/http/client.py:1333: in _send_request
[   45s]     self.endheaders(body, encode_chunked=encode_chunked)
[   45s] /usr/lib64/python3.6/http/client.py:1282: in endheaders
[   45s]     self._send_output(message_body, encode_chunked=encode_chunked)
[   45s] /usr/lib64/python3.6/http/client.py:1042: in _send_output
[   45s]     self.send(msg)
[   45s] /usr/lib64/python3.6/http/client.py:980: in send
[   45s]     self.connect()
[   45s] /usr/lib/python3.6/site-packages/docker/transport/unixconn.py:43: in connect
[   45s]     sock.connect(self.unix_socket)
[   45s] E   FileNotFoundError: [Errno 2] No such file or directory
[   45s] 
[   45s] During handling of the above exception, another exception occurred:
[   45s] /usr/lib/python3.6/site-packages/requests/adapters.py:449: in send
[   45s]     timeout=timeout
[   45s] /usr/lib/python3.6/site-packages/urllib3/connectionpool.py:756: in urlopen
[   45s]     method, url, error=e, _pool=self, _stacktrace=sys.exc_info()[2]
[   45s] /usr/lib/python3.6/site-packages/urllib3/util/retry.py:531: in increment
[   45s]     raise six.reraise(type(error), error, _stacktrace)
[   45s] /usr/lib/python3.6/site-packages/urllib3/packages/six.py:734: in reraise
[   45s]     raise value.with_traceback(tb)
[   45s] /usr/lib/python3.6/site-packages/urllib3/connectionpool.py:706: in urlopen
[   45s]     chunked=chunked,
[   45s] /usr/lib/python3.6/site-packages/urllib3/connectionpool.py:394: in _make_request
[   45s]     conn.request(method, url, **httplib_request_kw)
[   45s] /usr/lib64/python3.6/http/client.py:1287: in request
[   45s]     self._send_request(method, url, body, headers, encode_chunked)
[   45s] /usr/lib64/python3.6/http/client.py:1333: in _send_request
[   45s]     self.endheaders(body, encode_chunked=encode_chunked)
[   45s] /usr/lib64/python3.6/http/client.py:1282: in endheaders
[   45s]     self._send_output(message_body, encode_chunked=encode_chunked)
[   45s] /usr/lib64/python3.6/http/client.py:1042: in _send_output
[   45s]     self.send(msg)
[   45s] /usr/lib64/python3.6/http/client.py:980: in send
[   45s]     self.connect()
[   45s] /usr/lib/python3.6/site-packages/docker/transport/unixconn.py:43: in connect
[   45s]     sock.connect(self.unix_socket)
[   45s] E   urllib3.exceptions.ProtocolError: ('Connection aborted.', FileNotFoundError(2, 'No such file or directory'))
[   45s] 
[   45s] During handling of the above exception, another exception occurred:
[   45s] /usr/lib/python3.6/site-packages/docker/api/client.py:214: in _retrieve_server_version
[   45s]     return self.version(api_version=False)[""ApiVersion""]
[   45s] /usr/lib/python3.6/site-packages/docker/api/daemon.py:181: in version
[   45s]     return self._result(self._get(url), json=True)
[   45s] /usr/lib/python3.6/site-packages/docker/utils/decorators.py:46: in inner
[   45s]     return f(self, *args, **kwargs)
[   45s] /usr/lib/python3.6/site-packages/docker/api/client.py:237: in _get
[   45s]     return self.get(url, **self._set_request_timeout(kwargs))
[   45s] /usr/lib/python3.6/site-packages/requests/sessions.py:555: in get
[   45s]     return self.request('GET', url, **kwargs)
[   45s] /usr/lib/python3.6/site-packages/requests/sessions.py:542: in request
[   45s]     resp = self.send(prep, **send_kwargs)
[   45s] /usr/lib/python3.6/site-packages/requests/sessions.py:655: in send
[   45s]     r = adapter.send(request, **kwargs)
[   45s] /usr/lib/python3.6/site-packages/requests/adapters.py:498: in send
[   45s]     raise ConnectionError(err, request=request)
[   45s] E   requests.exceptions.ConnectionError: ('Connection aborted.', FileNotFoundError(2, 'No such file or directory'))
[   45s] 
[   45s] During handling of the above exception, another exception occurred:
[   45s] tests/unit/cli/docker_client_test.py:60: in test_user_agent
[   45s]     client = docker_client(os.environ)
[   45s] compose/cli/docker_client.py:174: in docker_client
[   45s]     client = APIClient(**kwargs)
[   45s] /usr/lib/python3.6/site-packages/docker/api/client.py:197: in __init__
[   45s]     self._version = self._retrieve_server_version()
[   45s] /usr/lib/python3.6/site-packages/docker/api/client.py:222: in _retrieve_server_version
[   45s]     'Error while fetching server API version: {0}'.format(e)
[   45s] E   docker.errors.DockerException: Error while fetching server API version: ('Connection aborted.', FileNotFoundError(2, 'No such file or directory'))
[   45s] =============================== warnings summary ===============================
[   45s] tests/unit/config/config_test.py::ConfigTest::test_config_duplicate_mount_points
[   45s]   /home/abuild/rpmbuild/BUILD/docker-compose-1.26.2/tests/unit/config/config_test.py:3184: DeprecationWarning: Please use assertEqual instead.
[   45s]     ', '.join(['/tmp/foo:/tmp/foo:rw']*2)))
[   45s] 
[   45s] tests/unit/config/config_test.py::ConfigTest::test_config_duplicate_mount_points
[   45s]   /home/abuild/rpmbuild/BUILD/docker-compose-1.26.2/tests/unit/config/config_test.py:3189: DeprecationWarning: Please use assertEqual instead.
[   45s]     ', '.join(['/x:/y:rw', '/z:/y:rw'])))
[   45s] 
[   45s] -- Docs: https://docs.pytest.org/en/stable/warnings.html
[   45s] =========================== short test summary info ============================
[   45s] SKIPPED [1] tests/unit/cli/command_test.py:39: windows separator
[   45s] SKIPPED [1] tests/unit/cli/command_test.py:69: Env values in Python 3 are already Unicode
[   45s] SKIPPED [1] tests/unit/cli/errors_test.py:70: Needs pywin32
[   45s] SKIPPED [1] tests/unit/cli/errors_test.py:80: Needs pywin32
[   45s] SKIPPED [1] tests/unit/cli/errors_test.py:90: Needs pywin32
[   45s] SKIPPED [1] tests/unit/config/config_test.py:3803: windows paths
[   45s] ============ 4 failed, 686 passed, 6 skipped, 2 warnings in 32.08s =============
[   45s] Exception in thread Thread-65:
[   45s] Traceback (most recent call last):
[   45s]   File ""/home/abuild/rpmbuild/BUILD/docker-compose-1.26.2/compose/cli/log_printer.py"", line 163, in tail_container_logs
[   45s]     for item in generator(container, log_args):
[   45s]   File ""/home/abuild/rpmbuild/BUILD/docker-compose-1.26.2/compose/utils.py"", line 61, in split_buffer
[   45s]     for data in stream_as_text(stream):
[   45s]   File ""/home/abuild/rpmbuild/BUILD/docker-compose-1.26.2/compose/utils.py"", line 37, in stream_as_text
[   45s]     for data in stream:
[   45s] TypeError: 'Mock' object is not iterable
[   45s] 
[   45s] During handling of the above exception, another exception occurred:
[   45s] 
[   45s] Traceback (most recent call last):
[   45s]   File ""/usr/lib64/python3.6/threading.py"", line 916, in _bootstrap_inner
[   45s]     self.run()
[   45s]   File ""/usr/lib64/python3.6/threading.py"", line 864, in run
[   45s]     self._target(*self._args, **self._kwargs)
[   45s]   File ""/home/abuild/rpmbuild/BUILD/docker-compose-1.26.2/compose/cli/log_printer.py"", line 166, in tail_container_logs
[   45s]     queue.put(QueueItem.exception(e))
[   45s] AttributeError: 'str' object has no attribute 'put'
[   45s] 

```

## Context information (for bug reports)

**Output of `docker-compose version`**
```
docker-compose version 1.26.2, build unknown
docker-py version: 4.4.0
CPython version: 3.8.6
OpenSSL version: OpenSSL 1.1.1h  22 Sep 2020
```

**Output of `docker version`**

(sorry, I have problems to collect other information, [Complete build log](https://github.com/docker/compose/files/5838984/_log.txt) may contain what you need).


## Steps to reproduce the issue

1. run the test suite
2.
3.

### Observed result
tests fail

### Expected result
they dont and I have a lot of ice cream.",,,,,,,,,,,,,,
8041,OPEN,"/tmp directory requires ""exec"" mode for docker-compose execution",kind/bug,2021-01-19 18:49:56 +0000 UTC,HaleyACS,In progress,,"3. When making a bug report, make sure you provide all required information. The easier it is for
   maintainers to reproduce, the faster it'll be fixed.
-->

## Description of the issue
recent docker-compose version (tested with 1.27.4) requires /tmp to have exec flag set.
Most secured systems have nodev, nosuid, noexec  applied to the /tmp directory by default.
It is possible to relocated the tmp directory, but IMHO this is not how it should work.


## Context information (for bug reports)

**Output of `docker-compose version`**
```
smurphy@stargate:/home/prodadm$ sudo curl -L https://github.com/docker/compose/releases/download/1.27.4/docker-compose-`uname -s`-`uname -m` -o /usr/local/bin/docker-compose
  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                 Dload  Upload   Total   Spent    Left  Speed
100   651  100   651    0     0   5612      0 --:--:-- --:--:-- --:--:--  5612
100 11.6M  100 11.6M    0     0  6737k      0  0:00:01  0:00:01 --:--:-- 10.2M
smurphy@stargate:/home/prodadm$ hash -r
smurphy@stargate:/home/prodadm$ docker-compose --version
docker-compose: error while loading shared libraries: libz.so.1: failed to map segment from shared object
```

**Output of `docker version`**
```
$ docker version
Client: Docker Engine - Community
 Version:           20.10.2
 API version:       1.41
 Go version:        go1.13.15
 Git commit:        2291f61
 Built:             Mon Dec 28 16:17:32 2020
 OS/Arch:           linux/amd64
 Context:           default
 Experimental:      true

Server: Docker Engine - Community
 Engine:
  Version:          20.10.2
  API version:      1.41 (minimum version 1.12)
  Go version:       go1.13.15
  Git commit:       8891c58
  Built:            Mon Dec 28 16:15:09 2020
  OS/Arch:          linux/amd64
  Experimental:     false
 containerd:
  Version:          1.4.3
  GitCommit:        269548fa27e0089a8b8278fc4fc781d7f65a939b
 runc:
  Version:          1.0.0-rc92
  GitCommit:        ff819c7e9184c13b7c2607fe6c30ae19403a7aff
 docker-init:
  Version:          0.19.0
  GitCommit:        de40ad0
```

**Output of `docker-compose config`**
(Make sure to add the relevant `-f` and other flags)
```
Not possible ...
```


## Steps to reproduce the issue

1. install latest docker-compose version
2. execute anything while system is in secured state
3.

### Observed result

Will always return a:
```
$ docker-compose ps
docker-compose: error while loading shared libraries: libz.so.1: failed to map segment from shared object
```


### Expected result
Working docker-compose

### Stacktrace / full error message

```
$ docker-compose ps
docker-compose: error while loading shared libraries: libz.so.1: failed to map segment from shared object
```

## Additional information

OS version / distribution, `docker-compose` install method, etc.
Wget installation from git repo.
Ubuntu server 18.04.5 LTS",,,HaleyACS,"
--
Note - one can circumvent the /tmp directory using:
```
alias docker-compose=""TMPDIR=/var/tmp docker-compose""
```
but that is not how it is supposed to run IMHO.
--

--
That's the point. If I tell docker-compose to use a different TMPDIR=/var/tmp, it works. 
So docker-compose does something in /tmp - and if it cannot execute something in there, it fails.
--
",ulyssessouza,"
--
Hello @HaleyACS ! Thanks for the report.
Looking at the logs I just see that `libz` cannot be found. You can check that by running:
```
ldd /path/to/docker-compose
```
If it cannot be found that's another problem... But a system problem and not a `docker-compose`'s issue
--
",,,,,,,,
8040,OPEN,docker compose ecs deploy aws tutorial: celery incompatible attribute,kind/bug,2021-01-19 05:24:10 +0000 UTC,FeralRobot,In progress,,"3. When making a bug report, make sure you provide all required information. The easier it is for
   maintainers to reproduce, the faster it'll be fixed.
-->

## Description of the issue
I have a django app using celery running with Docker Desktop on Windows10 & WSL2. With docker-compose on localhost, everything works: build, up, down, etc

I tried a deploy to AWS ECS using this great blog:
https://aws.amazon.com/blogs/containers/deploy-applications-on-amazon-ecs-using-docker-compose/

I make an ecs context,  switch to that context, and run docker compose up to deploy to AWS ECS.  Instead I get this:

time=""2021-01-18T17:39:04-08:00"" level=warning msg=""services.build: unsupported attribute""
time=""2021-01-18T17:39:04-08:00"" level=warning msg=""services.hostname: unsupported attribute""
service celery doesn't define a Docker image to run: incompatible attribute

So I have a docker-compose.yaml that works with docker-compose up but does not work with docker compose up (absence of the dash - between docker and compose).

I find very little information online when I search for the error messages that I see so I came to the issues list here.  Searching the issue list a couple of different ways has not yielding anything


## Context information (for bug reports)

**Output of `docker-compose version`**
```
docker-compose version 1.27.4, build 40524192
docker-py version: 4.3.1
CPython version: 3.7.4
OpenSSL version: OpenSSL 1.1.1c  28 May 2019
```

**Output of `docker version`**
```
Client: Docker Engine - Community
 Cloud integration: 1.0.4
 Version:           20.10.2
 API version:       1.41
 Go version:        go1.13.15
 Git commit:        2291f61
 Built:             Mon Dec 28 16:14:16 2020
 OS/Arch:           windows/amd64
 Context:           ecscontext1
 Experimental:      true

Server: Docker Engine - Community
 Engine:
  Version:          20.10.2
  API version:      1.41 (minimum version 1.12)
  Go version:       go1.13.15
  Git commit:       8891c58
  Built:            Mon Dec 28 16:15:23 2020
  OS/Arch:          linux/amd64
  Experimental:     false
 containerd:
  Version:          v1.4.3
  GitCommit:        269548fa27e0089a8b8278fc4fc781d7f65a939b
 runc:
  Version:          1.0.0-rc92
  GitCommit:        ff819c7e9184c13b7c2607fe6c30ae19403a7aff
 docker-init:
  Version:          0.19.0
  GitCommit:        de40ad0
```

**Output of `docker-compose config`**
(Make sure to add the relevant `-f` and other flags)
```
networks:
  services-network:
    driver: bridge
    name: services-network
services:
  broker:
    container_name: rabbit
    depends_on:
      pgadmin:
        condition: service_started
    environment:
      RABBITMQ_DEFAULT_PASS: aaaaaaahole
      RABBITMQ_DEFAULT_USER: aaaaaaa
      RABBITMQ_DEFAULT_VHOST: aaaaaaavhost
    hostname: broker
    image: rabbitmq:latest
    networks:
      services-network:
        aliases:
        - rabbit
    ports:
    - published: 5673
      target: 5672
    - published: 15673
      target: 15672
  celery:
    build:
      context: D:\local_cloud\docker_2\kbdj
      dockerfile: ./Dockerfile_celery
    command: bash -c ""sleep 7 && python manage.py makemigrations && python manage.py
      migrate && celery -A kbdj worker --loglevel=info --uid=nobody --gid=nogroup""
    container_name: celery
    depends_on:
      celery-beat:
        condition: service_started
    environment:
      CELERY_BROKER_URL: amqp://aaaaaaa:aaaaaaahole@broker:5672/aaaaaaavhost
      CSRF_TRUSTED_ORIGINS: 127.0.0.1
      DATABASE: postgres
      DEBUG: ""True""
      DJANGO_ALLOWED_HOSTS: localhost,127.0.0.1,[::1],nginx-network,unicron
      DOCKER: ""True""
      DOCKER_SQL_HOST: postgresdb
      JS_KEY: ''
      SECRET_KEY: ffffffffffffffffffffffffffffffffffffffff
      SQL_DATABASE: bbbbbbbbbbb
      SQL_PASSWORD: bbbbbbb
      SQL_USER: bbbb
      TESTING: ""True""
    hostname: celery-hostname
    networks:
      services-network:
        aliases:
        - celery
    restart: on-failure
    volumes:
    - D:\local_cloud\docker_2\kbdj:/kbdj:rw
  celery-beat:
    build:
      context: D:\local_cloud\docker_2\kbdj
      dockerfile: ./Dockerfile_celery
    command: bash -c ""python manage.py makemigrations && python manage.py migrate
      && celery -A kbdj beat --loglevel=info""
    container_name: celery-beat
    depends_on:
      broker:
        condition: service_started
      kbdj:
        condition: service_started
    environment:
      CELERY_BROKER_URL: amqp://aaaaaaa:aaaaaaahole@broker:5672/aaaaaaavhost
      CSRF_TRUSTED_ORIGINS: 127.0.0.1
      DATABASE: postgres
      DEBUG: ""True""
      DJANGO_ALLOWED_HOSTS: localhost,127.0.0.1,[::1],nginx-network,unicron
      DOCKER: ""True""
      DOCKER_SQL_HOST: postgresdb
      JS_KEY: ''
      SECRET_KEY: ffffffffffffffffffffffffffffffffffffffff
      SQL_DATABASE: bbbbbbbbbbb
      SQL_PASSWORD: bbbbbbb
      SQL_USER: bbbb
      TESTING: ""True""
    networks:
      services-network:
        aliases:
        - celery-beat
    restart: on-failure
    volumes:
    - D:\local_cloud\docker_2\kbdj:/kbdj:rw
  flower:
    command:
    - flower
    - --broker=amqp://aaaaaaa:aaaaaaahole@broker:5672/aaaaaaavhost
    - --port=5555
    container_name: flower
    depends_on:
      nginx:
        condition: service_started
    image: mher/flower
    networks:
      services-network:
        aliases:
        - flower
    ports:
    - published: 5555
      target: 5555
  kbdj:
    build:
      context: D:\local_cloud\docker_2\kbdj
      dockerfile: ./Dockerfile
    command: bash -c ""python manage.py makemigrations && python manage.py migrate
      && python manage.py collectstatic --no-input --clear && gunicorn --workers=2
      --certfile /kbdj/nginx/etc/certificates/cert.pem --keyfile /kbdj/nginx/etc/certificates/key.pem
      --bind=0.0.0.0:8001 kbdj.wsgi:application --timeout 600 --log-level CRITICAL""
    container_name: kbdj
    depends_on:
      broker:
        condition: service_started
      postgresdb:
        condition: service_started
    environment:
      CELERY_BROKER_URL: amqp://aaaaaaa:aaaaaaahole@broker:5672/aaaaaaavhost
      CSRF_TRUSTED_ORIGINS: 127.0.0.1
      DATABASE: postgres
      DEBUG: ""True""
      DJANGO_ALLOWED_HOSTS: localhost,127.0.0.1,[::1],nginx-network,unicron
      DOCKER: ""True""
      DOCKER_SQL_HOST: postgresdb
      JS_KEY: ''
      SECRET_KEY: ffffffffffffffffffffffffffffffffffffffff
      SQL_DATABASE: bbbbbbbbbbb
      SQL_PASSWORD: bbbbbbb
      SQL_USER: bbbb
      TESTING: ""True""
    hostname: kbdddj-hostname
    links:
    - postgresdb:postgresdb
    networks:
      services-network:
        aliases:
        - kbdjnetwork
    ports:
    - published: 8001
      target: 8001
    restart: always
    stdin_open: true
    tty: true
    volumes:
    - D:\local_cloud\docker_2\kbdj:/kbdj:rw
    - static_volume:/kbdj/staticfiles:rw
  nginx:
    container_name: nginx
    depends_on:
      celery:
        condition: service_started
    image: nginx:1.17.4-alpine
    networks:
      services-network:
        aliases:
        - nginx-network
    ports:
    - published: 8000
      target: 80
    - published: 443
      target: 443
    restart: always
    volumes:
    - D:\local_cloud\docker_2\kbdj\nginx\etc\conf.d:/etc/nginx/conf.d:rw
    - D:\local_cloud\docker_2\kbdj\nginx\etc\certificates:/etc/nginx/certificates:rw
    - D:\local_cloud\docker_2\kbdj\logs:/var/log/nginx:rw
    - static_volume:/kbdj/staticfiles:rw
  pgadmin:
    container_name: pgadmin
    depends_on:
      postgresdb:
        condition: service_started
    environment:
      PGADMIN_DEFAULT_EMAIL: ccccccccccccccccccc
      PGADMIN_DEFAULT_PASSWORD: ccccccccccc
      PGADMIN_LISTEN_PORT: 80
    image: dpage/pgadmin4:4.28
    links:
    - postgresdb:pgsql-server
    networks:
      services-network:
        aliases:
        - pgadmin
    ports:
    - published: 8080
      target: 80
    restart: always
    volumes:
    - pgadmin-data:/var/lib/pgadmin:rw
  postgresdb:
    container_name: postgresdb
    environment:
      POSTGRES_DB: ddddddddddd
      POSTGRES_PASSWORD: ddddddd
      POSTGRES_USER: dddd
    hostname: db
    image: postgres:12.3
    networks:
      services-network:
        aliases:
        - postgresdb
    ports:
    - published: 5430
      target: 5430
    restart: always
    volumes:
    - kb-database:/var/lib/postgresql/data:rw
    - source: D:\local_cloud\docker_2\kbdj\tests
      target: /tmp
      type: bind
version: '3.7'
volumes:
  kb-database: {}
  pgadmin-data: {}
  static_volume: {}
```


## Steps to reproduce the issue

1. set docker context to an aws ecs context
2. switch to that new context
3. run docker compose up

### Observed result
time=""2021-01-18T17:39:04-08:00"" level=warning msg=""services.build: unsupported attribute""
time=""2021-01-18T17:39:04-08:00"" level=warning msg=""services.hostname: unsupported attribute""
service celery doesn't define a Docker image to run: incompatible attribute

### Expected result
 docker compose up 
WARN[0001] networks.driver: unsupported attribute       
[+] Running 26/26
  docker                              CreateComplete                                                                                                        345.5s
  YelbuiTCP80TargetGroup              CreateComplete                                                                                                          0.0s
  LogGroup                            CreateComplete                                                                                                          2.2s
  YelbuiTaskExecutionRole             CreateComplete                                                                                                         14.0s
  YelbnetworkNetwork                  CreateComplete                                                                                                          5.0s
  YelbdbTaskExecutionRole             CreateComplete                                                                                                         14.0s
  CloudMap                            CreateComplete                                                                                                         48.3s
  Cluster                             CreateComplete                                                                                                          6.0s
  YelbappserverTaskExecutionRole      CreateComplete                                                                                                         14.0s
  RedisserverTaskExecutionRole        CreateComplete                                                                                                         13.0s
  YelbnetworkNetworkIngress           CreateComplete                                                                                                          0.0s
  Yelbnetwork80Ingress                CreateComplete                                                                                                          1.0s
  LoadBalancer                        CreateComplete                                                                                                        122.5s
  RedisserverTaskDefinition           CreateComplete                                                                                                          4.0s
  YelbappserverTaskDefinition         CreateComplete                                                                                                          3.0s
  YelbuiTaskDefinition                CreateComplete                                                                                                          3.0s
  YelbdbTaskDefinition                CreateComplete                                                                                                          3.0s
  RedisserverServiceDiscoveryEntry    CreateComplete                                                                                                          1.1s
  YelbdbServiceDiscoveryEntry         CreateComplete                                                                                                          5.5s
  YelbuiServiceDiscoveryEntry         CreateComplete                                                                                                          4.4s
  YelbappserverServiceDiscoveryEntry  CreateComplete                                                                                                          4.4s
  RedisserverService                  CreateComplete                                                                                                         68.2s
  YelbdbService                       CreateComplete                                                                                                         77.7s
  YelbuiTCP80Listener                 CreateComplete                                                                                                          5.4s
  YelbappserverService                CreateComplete                                                                                                        108.5s
  YelbuiService                       CreateComplete                                                                                                         76.6s 
 docker compose ps 
ID                                         NAME                REPLICAS            PORTS
docker-RedisserverService-bs6RqrSUuIux     redis-server        1/1                 
docker-YelbappserverService-yG2xExxLjU6D   yelb-appserver      1/1                 
docker-YelbdbService-RDGo1mRenFMt          yelb-db             1/1                 
docker-YelbuiService-X0bPBdwZmNcC          yelb-ui    

### Stacktrace / full error message

```
No Stack trace
only output was the result above
```

## Additional information

OS version / distribution, `docker-compose` install method, etc.
Win10 Pro   Version   10.0.19041 Build 19041
WSL2:    NAME=""Ubuntu""
              VERSION=""20.04.1 LTS (Focal Fossa)""",,,FeralRobot,"
--
There is a workaround for this by repositioning and renaming the celery Dockerfile.

Was this:
dockerfile: ./Dockerfile_celery

Changing to this (with associated file movement and renaming):
dockerfile: ./celery/Dockerfile

I would have expected named Docker files (such as the original Dockerfile_celery) would have been supported.  Is there a place where it's documented that's not supported?  If so, then this wouldn't be a bug, it would be on me.
--
",,,,,,,,,,
8039,OPEN,docker-compose randomly drops SSH connection from remote host raising paramiko.ssh_exception.NoValidConnectionsError,kind/bug,2021-02-23 15:24:39 +0000 UTC,bluesurfer,In progress,,"## Description of the issue

Sometimes the build of `docker-compose` fails due to a random `paramiko.ssh_exception.NoValidConnectionsError` or sometimes with a classic `SSH connection refused` 

This happens only when building to a remote host using SSH and only with `docker-compose`. I am not experiencing any network issues - I tried on three different machines on three different network by setting both the `DOCKER_HOST` variable or using `docker context` with properly configured ssh keys.. nothing changed!

I noticed an odd pattern; the exception occurs :
- more frequently when many builds are subsequently made in a short period of time (like 5 seconds between two builds);
- when there is a relatively big stack (with 8 services the error occurs when building the sixth service). 

It almost looks like that there exists some sort of limit in the SSH sessions - Yes.. I have already changed the `MaxSessions` option inside `/etc/ssh/sshd_config` and `service ssh restart` on the remote host but that does not solve this error and the most annoying fact is that it seems to be absolutely **random**.

### Stacktrace / full error message

```
Traceback (most recent call last):
  File ""docker-compose"", line 3, in <module>
  File ""compose/cli/main.py"", line 67, in main
  File ""compose/cli/main.py"", line 123, in perform_command
  File ""compose/cli/command.py"", line 69, in project_from_options
  File ""compose/cli/command.py"", line 132, in get_project
  File ""compose/cli/docker_client.py"", line 43, in get_client
  File ""compose/cli/docker_client.py"", line 170, in docker_client
  File ""site-packages/docker/api/client.py"", line 164, in __init__
  File ""site-packages/docker/transport/sshconn.py"", line 113, in __init__
  File ""site-packages/docker/transport/sshconn.py"", line 121, in _connect
  File ""site-packages/paramiko/client.py"", line 368, in connect
paramiko.ssh_exception.NoValidConnectionsError: [Errno None] Unable to connect to port 22 on 1.2.3.4
```
or more rarely:

```
failed to dial gRPC: command [ssh -l root -- 1.2.3.4 docker system dial-stdio] has exited please make sure the URL is valid,
and Docker 18.09 or later is installed on the remote host: stderr=ssh: connect to host 1.2.3.4 port 22: Connection refused
```

## Additional information

Local host: Mac OS X Big Sur - docker-compose 1.27.4
Remote host: Digitalocean ""One click Docker"" droplet running Ubuntu 20.04.1 LTS and docker-compose: 1.27.4


",,,mauryquijada,"
--
+1, also experiencing this
--

--
For anyone interested, I ended up using a workaround. Instead of connecting to the Droplet using SSH, I connected using the HTTP API. This involves the following (adapted from [this source](https://blog.usejournal.com/how-to-enable-docker-remote-api-on-docker-host-7b73bd3278c6)):
- `vi /lib/systemd/system/docker.service`
- Adding `-H=tcp://0.0.0.0:2375` to the `ExecStart` command
- `systemctl daemon-reload && service docker restart`

Then, on your local computer, you can add a new context with `docker context create --docker=""host=tcp://[your hostname]:2375"" remote`. Finally, you can build with `docker-compose --context remote up --build`.

Be wary though, that this opens your Docker installation to the public internet. I would suggest securing the port in some way if you choose to do this.

--
",bluesurfer,"
--
@mauryquijada **maybe** I fix this by following:

https://www.digitalocean.com/community/questions/ssh-connection-drops-too-frequently

https://github.com/docker/compose/issues/7542#issuecomment-743138898

--
",,,,,,,,
8036,OPEN,Docker Compose Network Not Working as Intended,kind/bug,2021-01-17 19:19:25 +0000 UTC,patientplatypus6,In progress,,"So, I have a bug that is either an issue in MySQL, or in docker. The issue is that if I don't have an assigned network in docker-compose I get the following error - 

`ERROR: could not find an available, non-overlapping IPv4 address pool among the defaults to assign to the network`

In itself this is strange, as I only have the 3 default networks and one I have created, and from documentation I have read online the ipv4 address pool should only become an issue when you have over 30 networks: 

```
root@ubuntu-s-1vcpu-1gb-nyc1-01:~/blog/blog# docker network ls
NETWORK ID     NAME       DRIVER    SCOPE
430e230e6641   bridge     bridge    local
915d73adee82   host       host      local
8cd9e79fd644   none       null      local
9f936dc688b7   underdev   bridge    local
```

So that should be considered a bug, unless there is a place I am not looking to fix this. The issue is that when I use the newly created network `underdev` in my docker-compose I get the following issue:

`there was an error connecting to pool:  Error: Handshake inactivity timeout`

So, then the docker-compose containers spin up, but the docker api container can't reach the docker db container. I've tried a number of different configurations, including using `network-mode`, specifying the networks in the docker-compose containers, and using various definitions of `networks` at the bottom of the docker-compose file. 

For more information please look at this (https://stackoverflow.com/questions/65724514/error-handshake-inactivity-timeout-mysql-node-js) and this (https://github.com/mysqljs/mysql/issues/2456)",,,patientplatypus6,"
--
I should also mention that maybe(?) overlay2 is an issue with creating too many cached images (guessing). But overlay2 only has 16 cached images and docker system is clean. I'm looking into how to clean overlay2 as well. 

```
root@ubuntu-s-1vcpu-1gb-nyc1-01:/var/lib/docker/overlay2# ls
074f4a138347708b2c90f925406356208f516767c3e3c3b89d05ae232bc3eb29  794613b1cb6805959f93a6bafc106783422ae4acce1857fc138eb3217c721a8f  c28a1dc02c1ab21a4a509bcb29ef0acdc9f3a253f90cd7f4e7dc2c0393c51d2a
197174cb00e223510d9625344eb3b5d291916cd8e73e9c9a0718d16d437f3fb6  7c99083efcd4c6ef7c252ff085585189f25ff1ba6b0eb37497c33677aa94fa84  e7b3d132b19ffe3b75a61a6c488019ee2e00d8ec9277fd618aea2d274619476d
3788dfe52c37db495cbbbbd174f186bc001c19c57b57bb7df8eb81d7a2513eeb  80c139606976fde6d39bafe8abc15a467ae08092dc6df329c31084df2a8933cb  fcc16aecad92b0f09b249b84d8c57d31881c376be22ddcc6c0856a771bc706ea
3a80b0d809d3ae920406e933a2b2779e67d7035c1e29df9bd4f0e51472604b81  9cce7ca8eb9d68676ad9f489ea9efbd17ac3de4e84a0dca535e16573adb6493f  l
5a8d0465da526e6dcd541e33420927396d01adea05504c1e1730a746195267d6  b0a3f2132b0a3878d3eac823539db55730a59e1844ec3c7c60660a7b40d2650c
77330530df37c0fa52c9f5acb25f32f4daf8f9660033120db39890522c84f504  b175dcde8d3c74cc3b6ac01bee997e2daf7d631dddc2947d7d4af6ab83ca0c7f
root@ubuntu-s-1vcpu-1gb-nyc1-01:/var/lib/docker/overlay2# docker system df
TYPE            TOTAL     ACTIVE    SIZE      RECLAIMABLE
Images          0         0         0B        0B
Containers      0         0         0B        0B
Local Volumes   0         0         0B        0B
Build Cache     0         0         0B        0B
```

--

--
Uninstalled and reinstalled docker and that hasn't worked.
--
",,,,,,,,,,
8033,OPEN,"Potential usability issue with ""docker-compose down -v""",kind/bug,2021-01-14 14:27:28 +0000 UTC,jessesimpson36,Opened,,"Hey everyone,

I tried searching the forums and issues for this issue and I couldn't find anything.  In most bash applications I use,   -v  is always short for ""--version""    or ""--verbose"".   Two very safe commands if you accidentally type it.

Consider for a moment, a user who has used docker but maybe not familiar with all of the options. They attempt to update a system that uses docker-compose, and they want to find out the version or they want verbose output, and type ""docker-compose down -v"".   Now they have deleted the database that people may rely on.

I have never personally made that mistake, but I worry other people at my company might.  Does this sound like a valid concern?  

",,,,,,,,,,,,,,
8027,OPEN,Error while creating mount source path; file exists error when using WSL 2,kind/bug,2021-01-09 15:00:44 +0000 UTC,Shiroh1ge,Opened,,"## Description of the issue
Hey guys, I'm not super familiar with Docker, recently I switched from version 2 to version 3 and tried to enable the new WSL 2 based engine. It was working great until I tried to use npm link to develop my local library inside docker, so what I usually do is I create a volume in my docker file and mount it to my local library:

```
services:
  gateway:
    build: ./gateway
    volumes:
      - ./gateway/node_modules/helpers:/usr/src/app/node_modules/helpers
     
 ```
Then inside my local project, I would use ``npm link helpers``, which will link my library project (which is outside of the current one) and then any changes to my library project would be reflected inside docker.

But when I enabled WSL 2, now I get an error after linking the package folder, saying ``file exists``. I pasted the full error below. Note that when I disable WSL 2 and add my drive in the File Sharing settings, this issue doesn't happen. Thanks for the help!

## Context information (for bug reports)

**Output of `docker-compose version`**
```
docker-compose version 1.27.4, build 40524192
docker-py version: 4.3.1
CPython version: 3.7.4
OpenSSL version: OpenSSL 1.1.1c  28 May 2019

```

**Output of `docker version`**
```
 Engine:
  Version:          20.10.2
  API version:      1.41 (minimum version 1.12)
  Go version:       go1.13.15
  Git commit:       8891c58
  Built:            Mon Dec 28 16:15:23 2020
  OS/Arch:          linux/amd64
  Experimental:     false
 containerd:
  Version:          v1.4.3
  GitCommit:        269548fa27e0089a8b8278fc4fc781d7f65a939b
 runc:
  Version:          1.0.0-rc92
  GitCommit:        ff819c7e9184c13b7c2607fe6c30ae19403a7aff
 docker-init:
  Version:          0.19.0
  GitCommit:        de40ad0

```

**Output of `docker-compose config`**
(Make sure to add the relevant `-f` and other flags)
```
services:
  gateway:
    build:
      context: E:\Repositories\invest\api\gateway
    hostname: gateway
    networks:
      backend: null
      frontend: null
    ports:
    - published: 8000
      target: 8000
    restart: always
    volumes:
    - E:\Repositories\invest\api\gateway\src:/usr/src/app/src:rw
    - E:\Repositories\invest\api\gateway\package.json:/usr/src/app/package.json:rw
    - E:\Repositories\invest\api\gateway\tsconfig.json:/usr/src/app/tsconfig.json:rw
    - E:\Repositories\invest\api\gateway\node_modules\helpers:/usr/src/app/node_modules/helpers:rw

```


## Steps to reproduce the issue

1. docker-compose up

### Observed result
Docker compose crashes with an error
### Expected result
Docker compose should start up
### Stacktrace / full error message

```
ERROR: for api_gateway_1  Cannot start service gateway: error while creating mount source path '/run/desktop/mnt/host/e/Repositories/invest/api/gateway/node_modules/helpers': mkdir /run/desktop/mnt/host/e/Repositories/invest/api/gateway/node_modules/helpers: file exists

```

",,,,,,,,,,,,,,
8026,OPEN,Better message when Docker for Windows isn't running,kind/feature,2021-01-08 18:35:52 +0000 UTC,stevedesmond-ca,Opened,,"-->

**Is your feature request related to a problem? Please describe.**
Running `docker-compose up` when Docker for Windows isn't started gives a bunch of Python stack traces that aren't directly helpful in determining the root of the problem.
```
$ docker-compose up
Traceback (most recent call last):
  File ""site-packages\docker\api\client.py"", line 205, in _retrieve_server_version
  File ""site-packages\docker\api\daemon.py"", line 181, in version
  File ""site-packages\docker\utils\decorators.py"", line 46, in inner
  File ""site-packages\docker\api\client.py"", line 228, in _get
  File ""site-packages\requests\sessions.py"", line 543, in get
  File ""site-packages\requests\sessions.py"", line 530, in request
  File ""site-packages\requests\sessions.py"", line 643, in send
  File ""site-packages\requests\adapters.py"", line 449, in send
  File ""site-packages\urllib3\connectionpool.py"", line 677, in urlopen
  File ""site-packages\urllib3\connectionpool.py"", line 392, in _make_request
  File ""http\client.py"", line 1244, in request
  File ""http\client.py"", line 1290, in _send_request
  File ""http\client.py"", line 1239, in endheaders
  File ""http\client.py"", line 1026, in _send_output
  File ""http\client.py"", line 966, in send
  File ""site-packages\docker\transport\npipeconn.py"", line 32, in connect
  File ""site-packages\docker\transport\npipesocket.py"", line 23, in wrapped
  File ""site-packages\docker\transport\npipesocket.py"", line 72, in connect
  File ""site-packages\docker\transport\npipesocket.py"", line 59, in connect
pywintypes.error: (2, 'CreateFile', 'The system cannot find the file specified.')

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""docker-compose"", line 3, in <module>
  File ""compose\cli\main.py"", line 67, in main
  File ""compose\cli\main.py"", line 123, in perform_command
  File ""compose\cli\command.py"", line 69, in project_from_options
  File ""compose\cli\command.py"", line 132, in get_project
  File ""compose\cli\docker_client.py"", line 43, in get_client
  File ""compose\cli\docker_client.py"", line 170, in docker_client
  File ""site-packages\docker\api\client.py"", line 188, in __init__
  File ""site-packages\docker\api\client.py"", line 213, in _retrieve_server_version
docker.errors.DockerException: Error while fetching server API version: (2, 'CreateFile', 'The system cannot find the file specified.')
[6820] Failed to execute script docker-compose
```

**Describe the solution you'd like**
A more helpful message, like ""Docker pipe could not be found, are you sure Docker is installed and running?""

**Describe alternatives you've considered**
Having Docker run at system startup, but would rather keep startup fast and only allocate resources to Docker when necessary.

**Additional context**
I don't have a Mac to test on, but this is probably the same problem there. Maybe even true on Linux when Docker Compose is installed but not Docker?",,,,,,,,,,,,,,
8024,OPEN,"docker-compose ""up"" works but ""run"" fails",kind/bug,2021-01-24 20:43:21 +0000 UTC,scrandall,In progress,,"
## Description of the issue
Trying to run a script through docker-compose fails with `Cannot connect to the Docker daemon at unix://tmp/docker.sock. Is the docker daemon running?`

## Context information (for bug reports)
This worked with docker 17, upgrading to the latest versions and I have an issue with docker run now.

**Output of `docker-compose version`**
```
docker-compose --version
docker-compose version 1.27.4, build 40524192
```

**Output of `docker version`**
```
docker --version
Docker version 19.03.13, build 4484c46d9d
```

**Output of `docker-compose config`**
(Make sure to add the relevant `-f` and other flags)
```
docker-compose config -f docker-compose-api.yml
Validate and view the Compose file.

Usage: config [options]

Options:
    --resolve-image-digests  Pin image tags to digests.
    --no-interpolate         Don't interpolate environment variables.
    -q, --quiet              Only validate the configuration, don't print
                             anything.
    --services               Print the service names, one per line.
    --volumes                Print the volume names, one per line.
    --hash=""*""               Print the service config hash, one per line.
                             Set ""service1,service2"" for a list of specified services
                             or use the wildcard symbol to display all services.
```


## Steps to reproduce the issue
docker-compose

```
version: ""3.8""
services:
  api:
    container_name: my_container_name
    restart: always
    image: my-registry:latest-my-image
    ports:
      - 80:8080
 ```

This works

```

ssh -M -S my-ctrl-socket -fN -o StrictHostKeyChecking=no -o ExitOnForwardFailure=yes -L /tmp/docker.sock:/var/run/docker.sock -J jumphost.mysite.com $HOST

docker-compose --host unix://tmp/docker.sock -f $docker_compose_api stop
docker-compose --host unix://tmp/docker.sock -f $docker_compose_api pull 
COMPOSE_HTTP_TIMEOUT=200 docker-compose --host unix://tmp/docker.sock -f $docker_compose_api up -d 
rm -v /tmp/docker.sock

ssh -S my-ctrl-socket -O check $HOST
ssh -S my-ctrl-socket -O exit $HOST

```

This fails with `Cannot connect to the Docker daemon at unix://tmp/docker.sock. Is the docker daemon running?`

```
ssh -M -S my-ctrl-socket -fN -o StrictHostKeyChecking=no -o ExitOnForwardFailure=yes -L /tmp/docker.sock:/var/run/docker.sock -J jumphost.mysite.com $HOST

docker-compose --host unix://tmp/docker.sock -f $docker_compose_api stop
docker-compose --host unix://tmp/docker.sock -f $docker_compose_api pull 
COMPOSE_HTTP_TIMEOUT=200 docker-compose --host unix://tmp/docker.sock -f $docker_compose_api run --rm api ./bin/script upgrade
# Get rid of the last tunnel to clean up after myself
rm -v /tmp/docker.sock

ssh -S my-ctrl-socket -O check $HOST
ssh -S my-ctrl-socket -O exit $HOST

```


### Observed result
`Cannot connect to the Docker daemon at unix://tmp/docker.sock. Is the docker daemon running?`

### Expected result
Script to run an exit

### Stacktrace / full error message

## Additional information

OS version / distribution, `docker-compose` install method, etc.

  - macOS Version: `10.15.7`
",,,kerbrose,"
--
this is probably due to docker service (daemon) is not running in the background. you could resolve it from https://stackoverflow.com/q/44678725/7045119,
--
",scrandall,"
--
Thank you @kerbrose, that answer is related to linux when I'm running on a mac, the daemon doesn't run on mac I believe https://github.com/docker/for-mac/issues/2267

The part that has me so confused is that ""up"" works but ""run"" wont. 
--
",BDL70,"
--
@scrandall did you get a fix to your problem. I'm having the same error message(curiously, immediately after upgrading to Catalina using dosdude1's Catalina patch on a 2011(late) MacBook Pro 
--
",,,,,,
8021,OPEN,Background container output freezes in docker-compose,,2021-01-04 17:45:21 +0000 UTC,pmahony893,Opened,,"
<!-- Click these checkboxes after submitting. -->
<!-- Download Docker Desktop 'Edge' (latest build) here: https://hub.docker.com/editions/community/docker-ce-desktop-windows -->
  - [x] I have tried with the latest version of my channel (Stable or Edge)
  - [x] I have uploaded Diagnostics
  - Diagnostics ID: 073D9689-BF6A-434C-9946-508E2A4374A8/20210104114700

### Expected behaviour
Logging should not freeze on the `service1` container.

### Actual behaviour
Logging freezes on the `service1` container after about 40s, and restarts when the `service2` container is stopped.

```
PS> while ($true) { date; docker-compose logs service1 | select -Last 1; sleep 1 }

04 January 2021 11:43:43
service1_1  | Mon Jan  4 11:43:43 UTC 2021
04 January 2021 11:43:51
service1_1  | Mon Jan  4 11:43:51 UTC 2021
04 January 2021 11:44:00
service1_1  | Mon Jan  4 11:44:00 UTC 2021
04 January 2021 11:44:11
service1_1  | Mon Jan  4 11:44:10 UTC 2021
04 January 2021 11:44:22
service1_1  | Mon Jan  4 11:44:10 UTC 2021
04 January 2021 11:44:30
service1_1  | Mon Jan  4 11:44:10 UTC 2021
04 January 2021 11:44:39
service1_1  | Mon Jan  4 11:44:10 UTC 2021
04 January 2021 11:44:48
service1_1  | Mon Jan  4 11:44:10 UTC 2021
04 January 2021 11:44:56
service1_1  | Mon Jan  4 11:44:10 UTC 2021
04 January 2021 11:45:04
service1_1  | Mon Jan  4 11:44:10 UTC 2021
04 January 2021 11:45:13
service1_1  | Mon Jan  4 11:44:10 UTC 2021
*************************** service2 container manually stopped here
04 January 2021 11:45:21
service1_1  | Mon Jan  4 11:45:21 UTC 2021
04 January 2021 11:45:36
service1_1  | Mon Jan  4 11:45:36 UTC 2021
...
```

### Information
  - Is it reproducible? Yes 
  - Windows Version: 1909
  - Docker Desktop Version: 3.0.0
  - Are you running inside a virtualized Windows e.g. on a cloud server or on a mac VM: No

This issue is also reproducible on Linux (tested using CentOS on VirtualBox/HyperV). Running `docker-compose up -d service2` also does not reproduce the issue (on Windows or Linux), nor does simply `docker-compose up`.

### Steps to reproduce the behaviour
After a lot of debugging with our application, I have uploaded a minimal reproducible example here: https://github.com/pmahony893/docker-windows-log-issue. To reproduce:

1. Download the repository.
2. Run `docker-compose up service2`.
3. Monitor the output of `docker-compose logs service1 | select -Last 1`. This will repeatedly return the same result after about 40s.
",,,,,,,,,,,,,,
8019,OPEN,dns_search with an empty string used to work; now fails,kind/bug,2021-01-03 18:54:08 +0000 UTC,jamshid,Opened,,"## Description of the issue

Setting dns_search to an empty string used to work, I have been using it for years to avoid incorrect DNS lookups when referring to a container by only its service name.  My ISP sets `search attlocal.net` and that seemed to cause occasional problems. Btw it's possible it never really helped (I see `docker run --dns-search=""""` fails?) but it didn't cause any problems and it did correctly remove the `search` line from /etc/resolv.conf. 

Now an empty dns_search causes DNS lookup of internet hosts to fail. DNS lookup of other containers by service name still works.

## Context information (for bug reports)

**Output of `docker-compose version`**
```
docker-compose version 1.27.4, build 40524192
```

**Output of `docker version`**
```
Client: Docker Engine - Community
 Cloud integration: 1.0.4
 Version:           20.10.0
 API version:       1.41
 Go version:        go1.13.15
 Git commit:        7287ab3
 Built:             Tue Dec  8 18:55:43 2020
 OS/Arch:           darwin/amd64
 Context:           default
 Experimental:      true

Server: Docker Engine - Community
 Engine:
  Version:          20.10.1
  API version:      1.41 (minimum version 1.12)
  Go version:       go1.13.15
  Git commit:       f001486
  Built:            Tue Dec 15 04:32:40 2020
  OS/Arch:          linux/amd64
  Experimental:     false
 containerd:
  Version:          1.4.3
  GitCommit:        269548fa27e0089a8b8278fc4fc781d7f65a939b
 runc:
  Version:          1.0.0-rc92
  GitCommit:        ff819c7e9184c13b7c2607fe6c30ae19403a7aff
 docker-init:
  Version:          0.19.0
  GitCommit:        de40ad0
 Kubernetes:
  Version:          v1.18.8
  StackAPI:         Unknown
```

**Output of `docker-compose config`**
(Make sure to add the relevant `-f` and other flags)
```
services:
  test:
    command: ping cnn.com
    dns_search:
    - ''
    image: centos
version: '3.9'

```


## Steps to reproduce the issue

1. docker-compose up
2. Notice ping of servers on the internet fail to resolve.
3. Remove the dns_search entry and the ping will work.

### Observed result

`test_1  | ping: cnn.com: Name or service not known`

### Expected result

`test_1  | PING cnn.com (151.101.65.67) 56(84) bytes of data.`

### Stacktrace / full error message

```
Attaching to tmp_test_1

test_1  | ping: cnn.com: Name or service not known
tmp_test_1 exited with code 2
```

## Additional information

OS version / distribution, `docker-compose` install method, etc.
macos, Docker for Desktop 3.0.3",,,,,,,,,,,,,,
8018,OPEN,Problem with requirements.txt caching when git repos are referenced,kind/bug,2021-01-03 02:45:13 +0000 UTC,justinkterry,Opened,,"I've been working on a C/Python package that I have to build in a docker VM, so I have have my dockerfile set to cache the requirements.txt so it doesn't redownload every time I build. Today I found a bug in an upstream PyPI package, so I did a PR with a fix, set my requirements.txt to point to the branch with a fix (requirement.txt files can pull from both git repos and PyPI). I then built my local package, found I had made an error in my upstream PR, commits a fix to it, and tried rebuilding again. However, the cached requirements.txt files remained. The commit hash in git repos referenced in requirementd.txt files need to be checked to make sure there's no changes, instead of just checking the contents of the requirements.txt file. 

Furthermore, I can't find anything on Google about how to clear this cache, and this seems like something worth including in documentation. I tried changing the requirements.txt file to redownload the cache, but when I changed it back it reverted to the previously cached out of date version.

```
justinkterry@preacherMan PettingZoo % docker-compose version                                                                                                                                                                                                                                                                                                                                                                           
docker-compose version 1.27.4, build 40524192
docker-py version: 4.3.1
CPython version: 3.7.7
OpenSSL version: OpenSSL 1.1.1g  21 Apr 2020
justinkterry@preacherMan PettingZoo % docker version                                                                                                                                                                                                                                                                                                                                                                                   
Client: Docker Engine - Community
 Cloud integration: 1.0.4
 Version:           20.10.0
 API version:       1.41
 Go version:        go1.13.15
 Git commit:        7287ab3
 Built:             Tue Dec  8 18:55:43 2020
 OS/Arch:           darwin/amd64
 Context:           default
 Experimental:      true

Server: Docker Engine - Community
 Engine:
  Version:          20.10.0
  API version:      1.41 (minimum version 1.12)
  Go version:       go1.13.15
  Git commit:       eeddea2
  Built:            Tue Dec  8 18:58:04 2020
  OS/Arch:          linux/amd64
  Experimental:     false
 containerd:
  Version:          v1.4.3
  GitCommit:        269548fa27e0089a8b8278fc4fc781d7f65a939b
 runc:
  Version:          1.0.0-rc92
  GitCommit:        ff819c7e9184c13b7c2607fe6c30ae19403a7aff
 docker-init:
  Version:          0.19.0
```",,,,,,,,,,,,,,
8017,OPEN,mount volume error on Windows 10,kind/bug,2021-01-02 21:18:22 +0000 UTC,alekssamos,Opened,,"3. When making a bug report, make sure you provide all required information. The easier it is for
   maintainers to reproduce, the faster it'll be fixed.
-->

## Description of the issue
mount volume error on Windows 10
```
Successfully built 40beffa8e675
Successfully tagged myapp_myapp:latest
Creating myapp ...

ERROR: for myapp  Unsupported mount type: ""mount""

ERROR: for myapp  Unsupported mount type: ""mount""
```
## Context information (for bug reports)

**Output of `docker-compose version`**
```
docker-compose version 1.27.4, build 40524192
docker-py version: 4.3.1
CPython version: 3.7.4
OpenSSL version: OpenSSL 1.1.1c 28 May 2019
```

**Output of `docker version`**
```
Client: Docker Engine - Community
Cloud integration: 1.0.4
Version: 20.10.0
API version: 1.41
Go version: go1.13.15
Git commit: 7287ab3
Built: Tue Dec 8 18:55:31 2020
OS/Arch: windows/amd64
Context: default
Experimental: true

Server: Docker Engine - Community
Engine:
 Version: 20.10.0
 API version: 1.41 (minimum version 1.12)
 Go version: go1.13.15
 Git commit: eeddea2
 Built: Tue Dec 8 18:58:04 2020
 OS/Arch: linux/amd64
 Experimental: false
containerd:
 Version: v1.4.3
 GitCommit: 269548fa27e0089a8b8278fc4fc781d7f65a939b
runc:
 Version: 1.0.0-rc92
 GitCommit: ff819c7e9184c13b7c2607fe6c30ae19403a7aff
docker-init:
 Version: 0.19.0
 GitCommit: de40ad0
```

**Output of `docker-compose config`**
(Make sure to add the relevant `-f` and other flags)
```
WARNING: The HOME variable is not set. Defaulting to a blank string.
networks:
 reverse-proxy:
 external: true
 name: nginx-revers-proxy
services:
 myapp:
 build:
 context: E:\qqq\MyApp
 container_name: myapp
 entrypoint:
 - python3
 - -m
 - app
 - -p
 environment:
      ...
 networks:
 ...
 restart: always
 volumes:
 - source: /MyApp/log/myapp
 target: /log
 type: mount
 - source: /MyApp/db_data
 target: /db_data
 type: mount
 - source: problems
 target: /jsons
 type: mount
version: '3.2'
volumes:
 problems: {}

```


## Steps to reproduce the issue

1. `git clone https://github.com/bomzheg/KarmaBot.git`
2. create .env file with environment variables (bot tokens)...
3. `docker-compose up --build -d`

### Observed result
mount errors. If you remove all ""mount"" from the dockerfile, the launch is successful.

### Expected result
Successfully started and running.
### Stacktrace / full error message

```
Traceback (most recent call last):
  File ""docker-compose"", line 3, in <module>
  File ""compose\cli\main.py"", line 67, in main
  File ""compose\cli\main.py"", line 126, in perform_command
  File ""compose\cli\main.py"", line 1070, in up
  File ""compose\cli\main.py"", line 1066, in up
  File ""compose\project.py"", line 648, in up
  File ""compose\parallel.py"", line 108, in parallel_execute
  File ""compose\parallel.py"", line 206, in producer
  File ""compose\project.py"", line 634, in do
  File ""compose\service.py"", line 562, in execute_convergence_plan
  File ""compose\service.py"", line 478, in _execute_convergence_create
  File ""compose\parallel.py"", line 108, in parallel_execute
  File ""compose\parallel.py"", line 206, in producer
  File ""compose\service.py"", line 476, in <lambda>
  File ""compose\service.py"", line 455, in create_and_start
  File ""compose\service.py"", line 332, in create_container
  File ""compose\service.py"", line 917, in _get_container_create_options
  File ""compose\service.py"", line 963, in _build_container_volume_options
  File ""compose\service.py"", line 963, in <listcomp>
  File ""compose\service.py"", line 1661, in build_mount
  File ""site-packages\docker\types\services.py"", line 227, in __init__
docker.errors.InvalidArgument: Unsupported mount type: ""mount""
[3904] Failed to execute script docker-compose
```

## Additional information

Windows 10 64-bit
Intel Core i5-3230M CPU @ 2.60GHz, 8,0GB RAM, Intel HD Graphics 4000
Download [Docker Desktop Installer.exe](https://desktop.docker.com/win/stable/Docker%20Desktop%20Installer.exe) and default install.",,,,,,,,,,,,,,
8020,OPEN,[3188] Failed to execute script docker-compose,,2021-01-04 12:23:57 +0000 UTC,takanatsusono,Opened,,"
<!-- Click these checkboxes after submitting. -->
<!-- Download Docker Desktop 'Edge' (latest build) here: https://hub.docker.com/editions/community/docker-ce-desktop-windows -->
  - [ ] I have tried with the latest version of docker
  - [ ] I have uploaded Diagnostics
  - Diagnostics ID: C78ACBED-BAAF-4C13-924E-5B97CAF6BFC7/20210102051719

### Expected behavior

Execute the default docker-compose.yml successfully.

### Actual behavior

Failed to execute docker-compose with following errors:

```
Traceback (most recent call last):
  File ""docker-compose"", line 3, in <module>
  File ""compose\cli\main.py"", line 67, in main
  File ""compose\cli\main.py"", line 123, in perform_command
  File ""compose\cli\command.py"", line 69, in project_from_options
  File ""compose\cli\command.py"", line 127, in get_project
  File ""compose\config\config.py"", line 389, in load
  File ""compose\config\config.py"", line 389, in <listcomp>
  File ""compose\config\config.py"", line 589, in process_config_file
  File ""compose\config\validation.py"", line 477, in validate_against_config_schema
  File ""compose\config\validation.py"", line 537, in handle_errors
  File ""site-packages\jsonschema\validators.py"", line 328, in iter_errors
  File ""site-packages\jsonschema\_validators.py"", line 286, in properties
  File ""site-packages\jsonschema\validators.py"", line 344, in descend
  File ""site-packages\jsonschema\validators.py"", line 328, in iter_errors
  File ""site-packages\jsonschema\_validators.py"", line 24, in patternProperties
  File ""site-packages\jsonschema\validators.py"", line 344, in descend
  File ""site-packages\jsonschema\validators.py"", line 328, in iter_errors
  File ""site-packages\jsonschema\_validators.py"", line 263, in ref
  File ""site-packages\jsonschema\validators.py"", line 344, in descend
  File ""site-packages\jsonschema\validators.py"", line 328, in iter_errors
  File ""site-packages\jsonschema\_validators.py"", line 286, in properties
  File ""site-packages\jsonschema\validators.py"", line 344, in descend
  File ""site-packages\jsonschema\validators.py"", line 328, in iter_errors
  File ""site-packages\jsonschema\_legacy_validators.py"", line 55, in items_draft3_draft4
  File ""site-packages\jsonschema\validators.py"", line 344, in descend
  File ""site-packages\jsonschema\validators.py"", line 328, in iter_errors
  File ""site-packages\jsonschema\_validators.py"", line 337, in oneOf
  File ""site-packages\jsonschema\validators.py"", line 344, in descend
  File ""site-packages\jsonschema\validators.py"", line 328, in iter_errors
  File ""site-packages\jsonschema\_validators.py"", line 45, in additionalProperties
  File ""site-packages\jsonschema\_utils.py"", line 98, in find_additional_properties
  File ""c:\jenkins\workspace\dsg_compose_1.27.4\venv\lib\re.py"", line 183, in search
TypeError: expected string or bytes-like object
[5564] Failed to execute script docker-compose
```

### Information
<!--
Please, help us understand the problem.  For instance:
  - Is it reproducible?
  - Is the problem new?
  - Did the problem appear with an update?
  - A reproducible case if this is a bug, Dockerfiles with reproduction inside is best.
-->
  - Windows Version: Window 10 Pro 1909
  - Docker Desktop Version: 20.10.0, build 7287ab3
  - Are you running inside a virtualized Windows e.g. on a cloud server or on a mac VM: No

### Steps to reproduce the behavior
<!--
A reproducible case, Dockerfiles with reproduction inside is best.
-->

  1. Open a command prompt on a folder contains a docker-compose.yml script file.
  2. Execute ""docker-compose up -d --build"" 
  3. ",,,,,,,,,,,,,,
8015,OPEN,Add build:cli_args to spec to remove strict coupling with CLI builds,kind/feature,2021-01-19 20:41:53 +0000 UTC,ppg,In progress,,"**Is your feature request related to a problem? Please describe.**
Features and options are added to the CLI for `docker build` and then support must be manually added to `docker-compose` to allow configuring those new features and options. This minimally leads to some delay, but can also lead to very long delays; in addition some items might never make it into the compose spec since they are not popular enough, or don't have clear compatibility with the docker client build mode. As a concrete example `docker build` via buildkit has supported the `--ssh` flag for a while, which is extremely useful for anyone using private repositories for go, python, node, etc. packages. However, support for that has yet to make it into `docker-compose` multiple years later. See https://github.com/docker/compose/issues/7025 and the various other issues linked or related to that to get an appreciation for how much pain that causes and how long it has been an issue.

**Describe the solution you'd like**
While it is nice to add first-class support for new features, especially ones that can be supported on docker client builds, those will always suffer from  playing catch up with `docker build`. Instead it seems like it would be very useful to have an option in the compose file to pass in arbitrary CLI options for `docker build` so a person could take advantage of new functionality as soon as it is added. The exact names and schema of that configuration seem like they could be tweaked, but I made a prototype implementation to prove to myself that it would work:
https://github.com/docker/compose/compare/master...TheJumpCloud:cli-args

This isn't handling non-CLI builds yet as I'm not sure the best way to split that given how the client vs. CLI build is handled as essentially an interface: https://github.com/docker/compose/blob/master/compose/service.py#L1106. However, as it is now I can simply add this snippet to a docker-compose file and solve the litany of woes people have had around build-time secrets, including `--ssh default`:
```
build:
  cli_args:
    - --ssh
    - default
```

This avoids, or perhaps rather allows, debate about how to add in first-class configuration for new options to progress at an appropriate speed, but still let's uses adopt the new features when they are read. I think this pattern would mean that anyone could adopt _any_ new `docker build` functionality on day 0 going forward.

**Describe alternatives you've considered**
There are various PRs that try to solve for a particular configuration shortcoming; for example the SSH issue already referenced has various approaches in  https://github.com/docker/compose/pull/7997, https://github.com/docker/compose/pull/7046 and https://github.com/docker/compose/pull/7296. I don't think this proposal is mutually exclusive from any of those: the compose spec can still have well defined configuration for things that are broadly adopted, but `build:cli_args` can act as an early adoption as well as escape valve for those that aren't useful or standardized enough to be promoted to a first class `build` configuration option, or are taking a while to get there.

**Additional context**
In terms of the impact, I'm not sure what other people have done, but we've essentially been forced to introduce a pre-build step that runs `docker build` directly with options such as `--ssh default` and then run `docker-compose build` after that. It breaks and confuses a bunch of stuff like multi-staged builds, as well as introduces a custom pattern outside the normal docker/docker-compose workflows. With something like `build:cli_args` we could have decided as an org to move to buildkit + that SSH option whenever we wanted, instead of having to construct this brittle workaround.",,,zoonage,"
--
Implementing this would be a lot easier to test in #7997 currently I have no idea how to test SSHing 
--

--
py-docker doesn't let you pass through arbitrary args, so I think this is only possible using the CLI builder
--
",ppg,"
--
> py-docker doesn't let you pass through arbitrary args, so I think this is only possible using the CLI builder

I believe this is true; to clarify, the issue with my branch is that the way the code picks the CLIBuilder or client builder means that you can't easily passe a kwarg that is supported by one but not the other. That's definitely solvable, I just didn't want to go ripping apart code without some advice on how the maintainers would like to handle that situation.
--

--
Found https://github.com/docker/compose/pull/7835 which is similar branch to the one I have listed in the description.
--
",,,,,,,,
8012,OPEN,docker-compose up --build ; The connection was reset (firefox); curl: (52) Empty reply from server (curl)?,kind/bug,2020-12-27 02:09:20 +0000 UTC,kerbrose,Opened,,"## Description of the issue
when I run `docker-compose up --build` against the following yml file (from repo https://github.com/minhng92/odoo-14-docker-compose)
```yml
version: '2'
services:
  db:
    image: postgres:13
    environment:
      - POSTGRES_PASSWORD=odoo
      - POSTGRES_USER=odoo
      - POSTGRES_DB=postgres
    restart: always             # run as a service
    volumes:
        - ./postgresql:/var/lib/postgresql/data

  odoo14:
    image: odoo:14
    depends_on:
      - db
    ports:
      - ""8069:8069""
    tty: true
    command: -- --dev=reload
    volumes:
      - ./addons:/mnt/extra-addons
      - ./etc:/etc/odoo
    restart: always             # run as a service
    
```
I get an error when I try to connect service **odoo14** from the browser `The connection was reset` (firefox) or from curl, `curl: (52) Empty reply from server`. even though I see from logs that the service is working fine.
```bash
$ docker-compose up --build
Starting odoo-14-docker-compose_db_1 ... done
Recreating odoo-14-docker-compose_odoo14_1 ... done
Attaching to odoo-14-docker-compose_db_1, odoo-14-docker-compose_odoo14_1
db_1      | 
db_1      | PostgreSQL Database directory appears to contain a database; Skipping initialization
db_1      | 
db_1      | 2020-12-27 01:21:01.219 UTC [1] LOG:  starting PostgreSQL 13.1 (Debian 13.1-1.pgdg100+1) on x86_64-pc-linux-gnu, compiled by gcc (Debian 8.3.0-6) 8.3.0, 64-bit
db_1      | 2020-12-27 01:21:01.219 UTC [1] LOG:  listening on IPv4 address ""0.0.0.0"", port 5432
db_1      | 2020-12-27 01:21:01.219 UTC [1] LOG:  listening on IPv6 address ""::"", port 5432
db_1      | 2020-12-27 01:21:01.413 UTC [1] LOG:  listening on Unix socket ""/var/run/postgresql/.s.PGSQL.5432""
db_1      | 2020-12-27 01:21:01.647 UTC [24] LOG:  database system was shut down at 2020-12-27 01:20:49 UTC
db_1      | 2020-12-27 01:21:01.865 UTC [1] LOG:  database system is ready to accept connections
odoo14_1  | ERROR: couldn't create the logfile directory. Logging to the standard output.
odoo14_1  | 2020-12-27 01:21:05,264 1 INFO ? odoo: Odoo version 14.0-20201218 
odoo14_1  | 2020-12-27 01:21:05,265 1 INFO ? odoo: Using configuration file at /etc/odoo/odoo.conf 
odoo14_1  | 2020-12-27 01:21:05,265 1 INFO ? odoo: addons paths: ['/usr/lib/python3/dist-packages/odoo/addons', '/mnt/extra-addons'] 
odoo14_1  | 2020-12-27 01:21:05,266 1 INFO ? odoo: database: odoo@db:5432 
odoo14_1  | 2020-12-27 01:21:05,541 1 INFO ? odoo.addons.base.models.ir_actions_report: Will use the Wkhtmltopdf binary at /usr/local/bin/wkhtmltopdf 
odoo14_1  | 2020-12-27 01:21:05,745 1 INFO ? odoo.service.server: Watching addons folder /usr/lib/python3/dist-packages/odoo/addons 
odoo14_1  | 2020-12-27 01:21:05,745 1 INFO ? odoo.service.server: Watching addons folder /mnt/extra-addons 
odoo14_1  | 2020-12-27 01:21:06,064 1 INFO ? odoo.service.server: AutoReload watcher running with watchdog 
odoo14_1  | 2020-12-27 01:21:06,069 1 INFO ? odoo.service.server: HTTP service (werkzeug) running on 41aea9049c42:8069 
```
I checked various questions in stackoverflow they suggested that the service should be bind to address 0.0.0.0. so I made sure in my odoo.conf is bind to such address using `http-interface= 0.0.0.0`. but no success. [odoo by default bind itself to such address by the way](https://www.odoo.com/documentation/14.0/reference/cmdline.html#http).

my `docker ps`
```bash
$ docker ps
CONTAINER ID        IMAGE               COMMAND                  CREATED             STATUS              PORTS                                      NAMES
7a8a7fc62e10        odoo:14             ""/entrypoint.sh -- -""   13 minutes ago      Up 13 minutes       0.0.0.0:8069->8069/tcp, 8071-8072/tcp   odoo-14-docker-compose_odoo14_1
3df978eef465        postgres:13         ""docker-entrypoint.s""   13 minutes ago      Up 13 minutes       5432/tcp                                   odoo-14-docker-compose_db_1
```
my `ss -tulpn`
```bash
$ sudo ss -tulpn
Netid       State        Recv-Q       Send-Q                                    Local Address:Port                Peer Address:Port       Process                                         
udp         UNCONN       0            0                                               0.0.0.0:48269                    0.0.0.0:*           users:((""dnsmasq"",pid=1106,fd=10))             
udp         UNCONN       0            0                                               0.0.0.0:52575                    0.0.0.0:*           users:((""avahi-daemon"",pid=720,fd=14))         
udp         UNCONN       0            0                                             127.0.0.1:53                       0.0.0.0:*           users:((""dnsmasq"",pid=1106,fd=4))              
udp         UNCONN       0            0                                               0.0.0.0:5353                     0.0.0.0:*           users:((""avahi-daemon"",pid=720,fd=12))         
udp         UNCONN       0            0                                                  [::]:44030                       [::]:*           users:((""avahi-daemon"",pid=720,fd=15))         
udp         UNCONN       0            0                    [fe80::50b9:23c8:92ab:b113]%wlp3s0:546                         [::]:*           users:((""NetworkManager"",pid=724,fd=24))       
udp         UNCONN       0            0                                                  [::]:5353                        [::]:*           users:((""avahi-daemon"",pid=720,fd=13))         
tcp         LISTEN       0            4096                                          127.0.0.1:45167                    0.0.0.0:*           users:((""containerd"",pid=2923,fd=12))          
tcp         LISTEN       0            32                                            127.0.0.1:53                       0.0.0.0:*           users:((""dnsmasq"",pid=1106,fd=5))              
tcp         LISTEN       0            244                                           127.0.0.1:5432                     0.0.0.0:*           users:((""postgres"",pid=768,fd=4))              
tcp         LISTEN       0            4096                                                  *:8069                           *:*           users:((""docker-proxy"",pid=7612,fd=4))         
tcp         LISTEN       0            244                                               [::1]:5432                        [::]:*           users:((""postgres"",pid=768,fd=3))              
```
one more thing I realized when running each container manually using `docker`, it just works fine. as following:
```bash
docker run -d -e POSTGRES_USER=odoo -e POSTGRES_PASSWORD=odoo -e POSTGRES_DB=postgres --name db postgres:13
docker run -p 8069:8069 --name odoo --link db:db -t odoo:14.0
```

## Context information (for bug reports)

**Output of `docker-compose version`**
```
docker-compose version 1.27.4, build unknown
docker-py version: 4.3.1
CPython version: 3.8.6
OpenSSL version: OpenSSL 1.1.1h  22 Sep 2020
```

**Output of `docker version`**
```
Client:
 Version:           19.03.13-ce
 API version:       1.40
 Go version:        go1.15.2
 Git commit:        4484c46d9d
 Built:             Sat Sep 26 12:04:46 2020
 OS/Arch:           linux/amd64
 Experimental:      false

Server:
 Engine:
  Version:          19.03.13-ce
  API version:      1.40 (minimum version 1.12)
  Go version:       go1.15.2
  Git commit:       4484c46d9d
  Built:            Sat Sep 26 12:03:35 2020
  OS/Arch:          linux/amd64
  Experimental:     false
 containerd:
  Version:          v1.4.3
  GitCommit:        269548fa27e0089a8b8278fc4fc781d7f65a939b.m
 runc:
  Version:          1.0.0-rc92
  GitCommit:        ff819c7e9184c13b7c2607fe6c30ae19403a7aff
 docker-init:
  Version:          0.18.0
  GitCommit:        fec3683
```

**Output of `docker-compose config`**
(Make sure to add the relevant `-f` and other flags)
```
services:
  db:
    environment:
      POSTGRES_DB: postgres
      POSTGRES_PASSWORD: odoo
      POSTGRES_USER: odoo
    image: postgres:13
    restart: always
    volumes:
    - /media/disk3/k/kit/odoo-14-docker-compose/postgresql:/var/lib/postgresql/data:rw
  odoo14:
    command: -- --dev=reload
    depends_on:
      db:
        condition: service_started
    image: odoo:14
    ports:
    - published: 8069
      target: 8069
    restart: always
    tty: true
    volumes:
    - /media/disk3/k/kit/odoo-14-docker-compose/addons:/mnt/extra-addons:rw
    - /media/disk3/k/kit/odoo-14-docker-compose/etc:/etc/odoo:rw
version: '2'
```


## Steps to reproduce the issue

1. run `docker-compose up --build` against the following repo https://github.com/minhng92/odoo-14-docker-compose

### Observed result
[Firefox](https://i.imgur.com/l1B5hcJ.png)
[![Firefox][1]][1]

[Curl](https://i.imgur.com/hQPaoRF.png)
[![Curl][2]][2]


## Additional information

OS version / distribution, `docker-compose` install method, etc.
Linux 5.9.11-3-MANJARO / Manjaro Linux 20.2, docker-compose installed from package manager. 
I also tried docker-compose from github


[1]: https://i.imgur.com/l1B5hcJ.png
[2]: https://i.imgur.com/hQPaoRF.png
",,,,,,,,,,,,,,
8011,OPEN,Integrate compose into docker repositories,kind/feature,2020-12-24 17:41:19 +0000 UTC,tarfeef101,Opened,,"## Problem
`docker-compose` is updated fairly regularly, but since the method of distribution (especially in mainstream distros like ubuntu/debian, rhel) is just ""download it from github and put it into your path"", it's difficult to keep up to date.

## Proposed Solution
Docker already maintains repos at `https://download.docker.com/linux/` for distributing the core components of Docker. It'd be fantastic if compose was included in there, so we can use our package managers to keep up to date.

## Alternatives
Efforts could be made to keep packages in distro's main repos (e.g. I believe AUR for arch has someone maintaining a compose package), or users could be expected to script their own methods to keep things up to date in the current setup. These are not as ideal though, in my opinion.
",,,,,,,,,,,,,,
8010,OPEN,10 seconds to apply restart policy not working,kind/bug,2020-12-23 21:55:47 +0000 UTC,drasko,In progress,,"3. When making a bug report, make sure you provide all required information. The easier it is for
   maintainers to reproduce, the faster it'll be fixed.
-->

## Description of the issue

10 seconds readiness check not applied.

It is mentioned here: https://docs.docker.com/config/containers/start-containers-automatically/#restart-policy-details that:
A restart policy only takes effect after a container starts successfully. In this case, starting successfully means that the container is up for at least 10 seconds and Docker has started monitoring it.

- Is this 10 seconds interval hard-coded, or it can be configured (lowered)?

- Where is this limitation imposed in the code, because looking here: https://github.com/moby/moby/blob/c85fe2d2242fbd6f9e4ea5cdef75d24945018ede/restartmanager/restartmanager.go#L50 I see no limit of that kind at all

## Context information (for bug reports)

**Output of `docker-compose version`**
```
drasko@Mando:~$ docker-compose version
docker-compose version 1.25.0, build unknown
docker-py version: 4.1.0
CPython version: 3.8.6
OpenSSL version: OpenSSL 1.1.1h  22 Sep 2020

```

**Output of `docker version`**
```
drasko@Mando:~$ docker version
Client:
 Version:           19.03.13
 API version:       1.40
 Go version:        go1.15.5
 Git commit:        4484c46
 Built:             Fri, 27 Nov 2020 00:08:07 +0700
 OS/Arch:           linux/amd64
 Experimental:      false

Server:
 Engine:
  Version:          19.03.13
  API version:      1.40 (minimum version 1.12)
  Go version:       go1.15.5
  Git commit:       4484c46
  Built:            Thu Nov 26 17:08:07 2020
  OS/Arch:          linux/amd64
  Experimental:     false
 containerd:
  Version:          19.03.13
  GitCommit:        1.3.7
 runc:
  Version:          1.0.0~rc92+dfsg1
  GitCommit:        1.0.0~rc92+dfsg1-5
 docker-init:
  Version:          0.19.0
  GitCommit:        
```

**Output of `docker-compose config`**
(Make sure to add the relevant `-f` and other flags)
https://github.com/mainflux/mainflux/blob/master/docker/docker-compose.yml

## Steps to reproduce the issue

1. Start a composition
2. Kill the dependency container
3. Original container restarts

### Observed result
Container is immediately restarted

### Expected result
10 seconds check should be applied. This check should also be configurable - not hard-coded.

Additionally, it should be observable in the code - currently the only place where some 10s can be seen is for restart timeout: https://github.com/moby/moby/blob/c85fe2d2242fbd6f9e4ea5cdef75d24945018ede/restartmanager/restartmanager.go#L71 and this is not related to container readiness (successful start).

### Stacktrace / full error message

```
(paste here)
```

## Additional information
Debian Buster
",,,drasko,"
--
Seems to be duplicate of https://github.com/docker/compose/issues/7619

However, I'll use this issue to add further data for research we are doing around this issue.

It looks like container restart works quite normal (restart policy is applied), no matter how long it has been up. However, if it is up less than ~10s it's logs (logs of restarted container) will not appear in docker-compose logs. Container seems to join back the composition (at least it communicates with other containers in the composition and exchanges messages), it just does not appear in docker-compose logs.

Inspecting individual logs for that container however shows that it was restarted correctly, and booted, and all subsequent activity (which is not showed in docker-compose logs).
--

--
Can be eventually related to this: https://github.com/docker/compose/issues/6060 or this: https://github.com/docker/compose/issues/5451
--
",,,,,,,,,,
8006,OPEN,Python module dependencies break future docker compose,kind/bug,2020-12-21 19:19:00 +0000 UTC,ckorder,Opened,,"I used following requirements for another python project after the installation the error occurred.
I timeshifted and its relating to this action.

Installed:
#(python3-launchpadlib) | i guess unimportant

python requirements i installed (bug causing) :
protobuf==3.6.0
six==1.11.0
bsdiff4>=1.1.5


**Output of `docker-compose version`**
```
Ubuntu Package
docker-compose version 1.25.0, build unknown
docker-py version: 4.1.0
CPython version: 3.8.5
OpenSSL version: OpenSSL 1.1.1f  31 Mar 2020

```

**Output of `docker version`**
```
Ubuntu Package
 Version:           19.03.8
 API version:       1.40
 Go version:        go1.13.8
 Git commit:        afacb8b7f0
 Built:             Wed Oct 14 19:43:43 2020
 OS/Arch:           linux/amd64
 Experimental:      false

```

**Output of `docker-compose config`**

```
sudo docker-compose up --force-recreate -d
[sudo] password for user:                         
Traceback (most recent call last):
  File ""/usr/bin/docker-compose"", line 11, in <module>
    load_entry_point('docker-compose==1.25.0', 'console_scripts', 'docker-compose')()
  File ""/usr/lib/python3/dist-packages/compose/cli/main.py"", line 72, in main
    command()
  File ""/usr/lib/python3/dist-packages/compose/cli/main.py"", line 125, in perform_command
    project = project_from_options('.', options)
  File ""/usr/lib/python3/dist-packages/compose/cli/command.py"", line 53, in project_from_options
    return get_project(
  File ""/usr/lib/python3/dist-packages/compose/cli/command.py"", line 151, in get_project
    return Project.from_config(
  File ""/usr/lib/python3/dist-packages/compose/project.py"", line 102, in from_config
    service_networks = get_networks(service_dict, networks)
  File ""/usr/lib/python3/dist-packages/compose/network.py"", line 320, in get_networks
    networks[network.true_name] = netdef
  File ""/usr/lib/python3/dist-packages/compose/network.py"", line 125, in true_name
    self._set_legacy_flag()
  File ""/usr/lib/python3/dist-packages/compose/network.py"", line 146, in _set_legacy_flag
    data = self.inspect(legacy=True)
  File ""/usr/lib/python3/dist-packages/compose/network.py"", line 106, in inspect
    return self.client.inspect_network(self.legacy_full_name)
  File ""/usr/lib/python3/dist-packages/docker/utils/decorators.py"", line 19, in wrapped
    return f(self, resource_id, *args, **kwargs)
  File ""/usr/lib/python3/dist-packages/docker/api/network.py"", line 212, in inspect_network
    res = self._get(url, params=params)
  File ""/usr/lib/python3/dist-packages/docker/utils/decorators.py"", line 46, in inner
    return f(self, *args, **kwargs)
  File ""/usr/lib/python3/dist-packages/docker/api/client.py"", line 230, in _get
    return self.get(url, **self._set_request_timeout(kwargs))
  File ""/usr/lib/python3/dist-packages/requests/sessions.py"", line 546, in get
    return self.request('GET', url, **kwargs)
  File ""/usr/lib/python3/dist-packages/requests/sessions.py"", line 519, in request
    prep = self.prepare_request(req)
  File ""/usr/lib/python3/dist-packages/requests/sessions.py"", line 452, in prepare_request
    p.prepare(
  File ""/usr/lib/python3/dist-packages/requests/models.py"", line 313, in prepare
    self.prepare_url(url, params)
  File ""/usr/lib/python3/dist-packages/requests/models.py"", line 379, in prepare_url
    scheme, auth, host, port, path, query, fragment = parse_url(url)
  File ""/usr/lib/python3/dist-packages/urllib3/util/url.py"", line 407, in parse_url
    ensure_func = six.ensure_text
AttributeError: module 'six' has no attribute 'ensure_text'
Error in sys.excepthook:
Traceback (most recent call last):
  File ""/usr/lib/python3/dist-packages/apport_python_hook.py"", line 153, in apport_excepthook
    with os.fdopen(os.open(pr_filename,
FileNotFoundError: [Errno 2] No such file or directory: '/var/crash/_usr_bin_docker-compose.0.crash'

Original exception was:
Traceback (most recent call last):
  File ""/usr/bin/docker-compose"", line 11, in <module>
    load_entry_point('docker-compose==1.25.0', 'console_scripts', 'docker-compose')()
  File ""/usr/lib/python3/dist-packages/compose/cli/main.py"", line 72, in main
    command()
  File ""/usr/lib/python3/dist-packages/compose/cli/main.py"", line 125, in perform_command
    project = project_from_options('.', options)
  File ""/usr/lib/python3/dist-packages/compose/cli/command.py"", line 53, in project_from_options
    return get_project(
  File ""/usr/lib/python3/dist-packages/compose/cli/command.py"", line 151, in get_project
    return Project.from_config(
  File ""/usr/lib/python3/dist-packages/compose/project.py"", line 102, in from_config
    service_networks = get_networks(service_dict, networks)
  File ""/usr/lib/python3/dist-packages/compose/network.py"", line 320, in get_networks
    networks[network.true_name] = netdef
  File ""/usr/lib/python3/dist-packages/compose/network.py"", line 125, in true_name
    self._set_legacy_flag()
  File ""/usr/lib/python3/dist-packages/compose/network.py"", line 146, in _set_legacy_flag
    data = self.inspect(legacy=True)
  File ""/usr/lib/python3/dist-packages/compose/network.py"", line 106, in inspect
    return self.client.inspect_network(self.legacy_full_name)
  File ""/usr/lib/python3/dist-packages/docker/utils/decorators.py"", line 19, in wrapped
    return f(self, resource_id, *args, **kwargs)
  File ""/usr/lib/python3/dist-packages/docker/api/network.py"", line 212, in inspect_network
    res = self._get(url, params=params)
  File ""/usr/lib/python3/dist-packages/docker/utils/decorators.py"", line 46, in inner
    return f(self, *args, **kwargs)
  File ""/usr/lib/python3/dist-packages/docker/api/client.py"", line 230, in _get
    return self.get(url, **self._set_request_timeout(kwargs))
  File ""/usr/lib/python3/dist-packages/requests/sessions.py"", line 546, in get
    return self.request('GET', url, **kwargs)
  File ""/usr/lib/python3/dist-packages/requests/sessions.py"", line 519, in request
    prep = self.prepare_request(req)
  File ""/usr/lib/python3/dist-packages/requests/sessions.py"", line 452, in prepare_request
    p.prepare(
  File ""/usr/lib/python3/dist-packages/requests/models.py"", line 313, in prepare
    self.prepare_url(url, params)
  File ""/usr/lib/python3/dist-packages/requests/models.py"", line 379, in prepare_url
    scheme, auth, host, port, path, query, fragment = parse_url(url)
  File ""/usr/lib/python3/dist-packages/urllib3/util/url.py"", line 407, in parse_url
    ensure_func = six.ensure_text
AttributeError: module 'six' has no attribute 'ensure_text'

```


## Steps to reproduce the issue

Build the docker container: https://github.com/binhex/arch-delugevpn
on  Ubuntu Focal 20.04


1. Install the dependencies for https://github.com/vm03/payload_dumper
2. Try to recreate the docker container with: sudo docker-compose up --force-recreate -d

Thank you for looking into the issue.
",,,,,,,,,,,,,,
8004,OPEN,"ERROR: Invalid interpolation format for ""environment""",,2020-12-20 00:02:17 +0000 UTC,bdorr1105,Opened,,"3. When making a bug report, make sure you provide all required information. The easier it is for
   maintainers to reproduce, the faster it'll be fixed.
-->

## Description of the issue

## Context information (for bug reports)

```
Output of ""docker-compose version""
```
docker-compose version 1.17.1, build unknown
docker-py version: 2.5.1
CPython version: 2.7.17
OpenSSL version: OpenSSL 1.1.1  11 Sep 2018
```
Output of ""docker version""
```
Client:
 Version:           19.03.6
 API version:       1.40
 Go version:        go1.12.17
 Git commit:        369ce74a3c
 Built:             Wed Oct 14 19:00:27 2020
 OS/Arch:           linux/amd64
 Experimental:      false

Server:
 Engine:
  Version:          19.03.6
  API version:      1.40 (minimum version 1.12)
  Go version:       go1.12.17
  Git commit:       369ce74a3c
  Built:            Wed Oct 14 16:52:50 2020
  OS/Arch:          linux/amd64
  Experimental:     false
 containerd:
  Version:          1.3.3-0ubuntu1~18.04.2
  GitCommit:        
 runc:
  Version:          spec: 1.0.1-dev
  GitCommit:        
 docker-init:
  Version:          0.18.0
  GitCommit:        
```
Output of ""docker-compose config""
```
ERROR: Invalid interpolation format for ""environment"" option in service ""elastiflow-elasticsearch"": ""spomefpasswitha#$""

## Steps to reproduce the issue

1. I have added quotes around the password cause there is a # in my password which usually means it will comment out
2.
3.

### Observed result

### Expected result - Expect things to work, except they don't

### Stacktrace / full error message

```
(if applicable)
```

## Additional information

OS version / distribution, `docker-compose` install method, etc.

Ubuntu 18.0.5 LTS / apt install docker-compose
",,,,,,,,,,,,,,
8003,OPEN,--await for healthcheck,kind/feature,2020-12-18 23:08:42 +0000 UTC,JamesTheAwesomeDude,In progress,,"When running `docker up -d`, I'd like to be able to block until the container is actually running and ""healthy"", if possible.

e.g., a service will wait for its dependencies to be healthy before starting, but I'm kicked back out to the shell (or shell script, as it were,) before waiting for the actual _invokation_ to mature to health.

I propose syntax along the lines of

```sh
#!/bin/sh
docker up -d --await=web &&\
  echo ""The service is running and healthy."" ||\
  echo ""There was a problem bringing up the service.""
```",,,JamesTheAwesomeDude,"
--
While there are [3rd-party hacks](https://github.com/vishnubob/wait-for-it), as well as e.g. simply `until wget --spider localhost:4000 ; do sleep 1 ; done`, it seems a bit strange that there's no _built-in_ way to `await` the healthchecks that we've _already_ so carefully coded into our `docker-compose.yml` files.
--
",,,,,,,,,,
8002,OPEN,Volume ownership on creation inconsistent between docker and docker-compose,kind/bug,2020-12-26 09:28:15 +0000 UTC,Neutrino-Sunset,Opened,,"Using the following dockerfile node_modules is created owned by user 'node' and all 'npm' commands work correctly with no permission issues.

    FROM node:lts-alpine
    USER node
    WORKDIR /home/node/app
    RUN mkdir /home/node/app/node_modules
<!-- -->    
    martin@DESKTOP-SDE0C3N:~/workspaces/node8$ docker build -t node8 .
    martin@DESKTOP-SDE0C3N:~/workspaces/node8$ docker run -it --rm -v $(pwd):/home/node/app -v /home/node/app/node_modules node8 sh -c ""ls -g""
    total 32
    -rw-r--r--    1 node           210 Dec 18 10:40 Dockerfile
    -rw-r--r--    1 node           192 Dec 18 10:35 docker-compose.yml
    drwxr-sr-x    2 node          4096 Dec 18 10:26 node_modules
    -rw-r--r--    1 node           250 Dec 18 10:19 package.json
    
If however I use the following docker-compose.yml and the exact same dockerfile, then node_modules is owned by 'root' and all manner of stuff stops working.

    version: ""3.8""
    services:
      node8:
        build: ./
        user: node
        tty: true
        stdin_open: true
        volumes:
          - ./:/home/node/app
          - /home/node/app/node_modules
        command: ls -g
<!-- -->
     martin@DESKTOP-SDE0C3N:~/workspaces/node8$ docker build -t node8 .
     martin@DESKTOP-SDE0C3N:~/workspaces/node8$ docker-compose up
     Starting node8_node8_1 ... done
     Attaching to node8_node8_1
     node8_1  | total 36
     node8_1  | -rw-r--r--    1 node           210 Dec 18 10:40 Dockerfile
     node8_1  | -rw-r--r--    1 node           192 Dec 18 10:42 docker-compose.yml
     node8_1  | drwxr-xr-x    2 root          4096 Dec 16 22:17 node_modules
     node8_1  | -rw-r--r--    1 node           250 Dec 18 10:19 package.json
     node8_node8_1 exited with code 0

Firstly. How can it make sense for two tools for the same product to act completely differently and inconsistently on the exact same configuration?

And secondly, how do I control the ownership of volumes created using docker-compose?


**Output of `docker-compose version`**
```
docker-compose version 1.27.4, build 40524192
docker-py version: 4.3.1
CPython version: 3.7.7
OpenSSL version: OpenSSL 1.1.0l  10 Sep 2019
```

**Output of `docker version`**
```
Client: Docker Engine - Community
 Cloud integration: 1.0.2
 Version:           19.03.13
 API version:       1.40
 Go version:        go1.13.15
 Git commit:        4484c46d9d
 Built:             Wed Sep 16 17:02:36 2020
 OS/Arch:           linux/amd64
 Experimental:      false

Server: Docker Engine - Community
 Engine:
  Version:          19.03.13
  API version:      1.40 (minimum version 1.12)
  Go version:       go1.13.15
  Git commit:       4484c46d9d
  Built:            Wed Sep 16 17:07:04 2020
  OS/Arch:          linux/amd64
  Experimental:     false
 containerd:
  Version:          v1.3.7
  GitCommit:        8fba4e9a7d01810a393d5d25a3621dc101981175
 runc:
  Version:          1.0.0-rc10
  GitCommit:        dc9208a3303feef5b3839f4323d9beb36df0a9dd
 docker-init:
  Version:          0.18.0
  GitCommit:        fec3683
```

**Output of `docker-compose config`**
(Make sure to add the relevant `-f` and other flags)
```
services:
  node8:
    build:
      context: /home/martin/workspaces/node8
    command: ls -g
    stdin_open: true
    tty: true
    user: node
    volumes:
    - /home/martin/workspaces/node8:/home/node/app:rw
    - /home/node/app/node_modules
version: '3.8'
```

OS version: Win 10 Pro",,,Neutrino,"
--
Help me out please guys, this is a showstopper.
--

--
Does someone need some more information or something? Seems like a pretty clear issue to me. So is this a bug that needs fixing or a known limitation with known workarounds?
--
",,,,,,,,,,
7998,OPEN,"Problem with ""--name"" in docker-compose run",,2020-12-16 10:31:23 +0000 UTC,htarnacki,Opened,,"docker-compose --version
docker-compose version 1.27.4, build unknown

docker-compose run --rm --name env_01_tumrestapi_loadTumPrivileges loadTumPrivileges
Creating env_01_loadTumPrivileges_run ... done

Am i wrong assuming that container name should be equal to ""env_01_tumrestapi_loadTumPrivileges"" ?",,,,,,,,,,,,,,
7993,OPEN,Adding support for docker-compose.<context name>.override.yml and <context name>.override.env,kind/feature,2020-12-12 11:38:07 +0000 UTC,maydanw-qrg,Opened,,"**Is your feature request related to a problem? Please describe.**
I would like to multiple deployment parameters to be context-specific allowing me to run a local testing environment, on cloud integration tests, production each with its subtle adaptations.   

**Describe the solution you'd like**
I want the .override. files to be loaded per context and extend/override the general configuration.
When loading the overriding files the loaded files (or even the specific extended/overridden configuration) should be stated if some verbose debug mode is set.

**Describe alternatives you've considered**
It should be possible to create multiple files and load a specific compose file, each loading a specific predefined .env file. Yet, as most of (my) configurations are common any change need to be replicated and may be a cause of errors.
",,,,,,,,,,,,,,
7992,OPEN,DNS may not work if network_mode is not set in the config,kind/bug,2021-02-08 10:29:36 +0000 UTC,0x7162,Opened,,"## Description of the issue
Some of CentOS setups may experience DNS issues with config below.
I found a work-around to set `network_mode` explicitly to the default value.
Also, I found a similar discussion here (#4177, by @turtlemonvh):
https://github.com/docker/compose/issues/4177#issue-191056655


I noticed just one change after adding the work-around:
at container side `/etc/resolv.conf` takes exact the same values from HOST machine (CentOS).
Without work-around `/etc/resolv.conf` refers to `127.0.x.x`
(which refers to docker implementation of dns forwarding)

## Context information (for bug reports)
Example of config causing DNS issues on some CentOS setups:
(
```
version: ""3.8""
services:
  blabla:
    # Set up the build root path, where Dockerfile for this service lives
    build:
      context: ./blabla2
      dockerfile: Dockerfile
    # Keep the container running
    tty: true
    volumes:
      # Let's mount the current directory into the container's /chepuha3
      - ${PWD}/:/chepuha3
```


Example of work-around config:
```
version: ""3.8""
services:
  blabla:
   # here: if we'll omit line below - dns may not work correctly
   # setting network_mode to the default value
    network_mode: bridge
    # Set up the build root path, where Dockerfile for this service lives
    build:
      context: ./blabla2
      dockerfile: Dockerfile
    # Keep the container running
    tty: true
    volumes:
      # Let's mount the current directory into the container's /chepuha3
      - ${PWD}/:/chepuha3
```

**Output of `docker-compose version`**
```
docker-compose version 1.27.4, build 40524192
docker-py version: 4.3.1
CPython version: 3.7.7
OpenSSL version: OpenSSL 1.1.0l  10 Sep 2019
```

**Output of `docker version`**
```
Client: Docker Engine - Community
 Version:           19.03.14
 API version:       1.40
 Go version:        go1.13.15
 Git commit:        5eb3275d40
 Built:             Tue Dec  1 19:20:42 2020
 OS/Arch:           linux/amd64
 Experimental:      false

Server: Docker Engine - Community
 Engine:
  Version:          19.03.14
  API version:      1.40 (minimum version 1.12)
  Go version:       go1.13.15
  Git commit:       5eb3275d40
  Built:            Tue Dec  1 19:19:17 2020
  OS/Arch:          linux/amd64
  Experimental:     false
 containerd:
  Version:          1.3.9
  GitCommit:        ea765aba0d05254012b0b9e595e995c09186427f
 runc:
  Version:          1.0.0-rc10
  GitCommit:        dc9208a3303feef5b3839f4323d9beb36df0a9dd
 docker-init:
  Version:          0.18.0
  GitCommit:        fec3683
```

**Output of `docker-compose config`**
(Make sure to add the relevant `-f` and other flags)
```
# Dockerfile
# yml is mentioned in the lines above
FROM python:3.8-slim
WORKDIR /chepuha3
```


## Steps to reproduce the issue
The issue is intermittent and happens on some random CentOS setups only
```
docker-compose -f config.yml down
# change config (remove to reproduce or add network_mode for work-around)
docker-compose -f config.yml up -d
docker exec image_name ping yahoo.com
```


### Observed result
dns is not working, though traffic routes ok

### Expected result
both traffic and dns are working fine

### Stacktrace / full error message
```
N/A
```",,,tobias,"
--
If your container is in an external bridge network (docker network create...) setting the network_mode to bridge will put the container in the default bridge network and out of the external network you've specified in the compose file. In my case this was not what I was looking for. I had the issue that the DNS servers I've specified myself where not added to the /etc/resolv.conf file of the container.
--
",,,,,,,,,,
7991,OPEN,Sticky session in docker swarm,kind/feature,2020-12-11 06:02:32 +0000 UTC,anandtripathi5,Opened,,"I'm implementing the WebSocket application using docker swarm.
My Nginx and backend application is in docker swarm and Nginx is forwarding the request to backend service using reverse proxy.

I have 2 replicas of the backend application and used the service name in the reverse proxy of Nginx. But the WebSocket requests are failing cause the request are handled by any of the two replicas. I want to have a sticky session based on ip_hash so that on the basis of the request will go to one replica only.

I checked on the web and it seems there is only one solution that is using **Traefik** as a loadbalancer. But I cannot do that cause we are using AWS load balancer for it and we cannot replace AWS load balancer with Traefik.

Any plan on introducing the sticky session concept in docker!!",,,,,,,,,,,,,,
7976,OPEN,Extends not working properly for multiple compose files,kind/bug,2020-12-04 20:08:49 +0000 UTC,mdelapenya,Opened,,"3. When making a bug report, make sure you provide all required information. The easier it is for
   maintainers to reproduce, the faster it'll be fixed.
-->

## Description of the issue
When running docker-compose with multiple compose files, I see different behaviours when extending a service in files not being the base ones.

**docker-compose.yml**
```yml
version: '3'
services:
    a:
        image: nginx
        environment:
            - DEBUG=1
        cpu_shares: 5
```

**docker-compose-extended.yml**
```yml
version: '3'
services:
    web:
        image: nginx
        environment:
            - DEBUG=1
        cpu_shares: 5

    important_web:
        extends: web
        cpu_shares: 10
```

## Context information (for bug reports)

**Output of `docker-compose version`**
```
docker-compose version 1.27.4, build 40524192
docker-py version: 4.3.1
CPython version: 3.7.7
OpenSSL version: OpenSSL 1.1.1g  21 Apr 2020
```

**Output of `docker version`**
```
Client: Docker Engine - Community
 Cloud integration  0.1.18
 Version:           19.03.13
 API version:       1.40
 Go version:        go1.13.15
 Git commit:        4484c46d9d
 Built:             Wed Sep 16 16:58:31 2020
 OS/Arch:           darwin/amd64
 Experimental:      false

Server: Docker Engine - Community
 Engine:
  Version:          19.03.13
  API version:      1.40 (minimum version 1.12)
  Go version:       go1.13.15
  Git commit:       4484c46d9d
  Built:            Wed Sep 16 17:07:04 2020
  OS/Arch:          linux/amd64
  Experimental:     false
 containerd:
  Version:          v1.3.7
  GitCommit:        8fba4e9a7d01810a393d5d25a3621dc101981175
 runc:
  Version:          1.0.0-rc10
  GitCommit:        dc9208a3303feef5b3839f4323d9beb36df0a9dd
 docker-init:
  Version:          0.18.0
  GitCommit:        fec3683
```

**Output of `docker-compose config`**
(Make sure to add the relevant `-f` and other flags)
```shell
$ cd /tmp/foo
$ docker-compose -f docker-compose.yml -f docker-compose-extended.yml config 
ERROR: Cannot extend service 'web' in /private/tmp/foo/docker-compose.yml: Service not found
```

But when running config setting the extended as base file, it works:
```shell
$ cd /tmp/foo
$ docker-compose -f docker-compose-extended.yml -f docker-compose.yml config 
services:
  a:
    cpu_shares: 5
    environment:
      DEBUG: '1'
    image: nginx
  important_web:
    cpu_shares: 10
    environment:
      DEBUG: '1'
    image: nginx
  web:
    cpu_shares: 5
    environment:
      DEBUG: '1'
    image: nginx
version: '3'
```


## Steps to reproduce the issue

1. create both docker-compose and docker-compose-extended YML files in a directory
2. run config with -f, setting the base compose file the docker-compose.ym file: 
```shell
docker-compose -f docker-compose.yml -f docker-compose-extended.yml config 
```
>It happens the same with `up, down...` subcommands

### Observed result
The `web` service cannot be extended, I guess because it's

### Expected result
The `web` service is extended, no matter if it's in the base file or in an extension/override.

### Stacktrace / full error message
```
ERROR: Cannot extend service 'web' in /private/tmp/foo/docker-compose.yml: Service not found
```

## Additional information
Running on MacOS

",,,,,,,,,,,,,,
7973,OPEN,Invalid missing a healthcheck configuration error,kind/bug,2020-12-04 12:47:39 +0000 UTC,ilkkao,Opened,,"## Description of the issue

`docker-compose run` doesn't accept valid version 2.3 `docker-compose.yml` file.

## Context information (for bug reports)

**Output of `docker-compose version`**
```
docker-compose version 1.27.4, build 40524192
```

**Output of `docker version`**
```
Client: Docker Engine - Community
 Cloud integration: 1.0.2
 Version:           19.03.13
 API version:       1.40
 Go version:        go1.13.15
 Git commit:        4484c46d9d
 Built:             Wed Sep 16 16:58:31 2020
 OS/Arch:           darwin/amd64
 Experimental:      false

Server: Docker Engine - Community
 Engine:
  Version:          19.03.13
  API version:      1.40 (minimum version 1.12)
  Go version:       go1.13.15
  Git commit:       4484c46d9d
  Built:            Wed Sep 16 17:07:04 2020
  OS/Arch:          linux/amd64
  Experimental:     false
 containerd:
  Version:          v1.3.7
  GitCommit:        8fba4e9a7d01810a393d5d25a3621dc101981175
 runc:
  Version:          1.0.0-rc10
  GitCommit:        dc9208a3303feef5b3839f4323d9beb36df0a9dd
 docker-init:
  Version:          0.18.0
  GitCommit:        fec3683
```

**docker-compose.yml file**
```
version: '2.3'

services:
  one:
    image: hello-world
    healthcheck:
      test: [""CMD"", ""pwd""]
      interval: 1s
      timeout: 10s
      retries: 30
  two:
    image: hello-world
    depends_on:
      one:
        condition: service_healthy
```


## Steps to reproduce the issue

1. `docker-compose run two`

### Observed result

`ERROR: for two  Service ""one"" is missing a healthcheck configuration`

### Expected result

```
Starting one_1 ... done

Hello from Docker!
...
```

## Additional information

This error doesn't happen with docker-compose version 1.26.2. Similar bug has existed before in https://github.com/docker/for-mac/issues/1341 Maybe this is a regression from the `Merge 2.x and 3.x compose formats and align with COMPOSE_SPEC schema` change?

`condition: service_healthy` is going away with the version 3 but should work until support for 2.x versions is removed completely I believe.",,,,,,,,,,,,,,
7972,OPEN,The deployment of this job to staging did not succeed.,kind/question,2020-12-04 11:55:15 +0000 UTC,yjinnox,In progress,,"**In my .gitlab-ci.yml file, for the deployment step I wrote this:**

deploy_staging_job:
    stage: deploy
    image: docker:stable
    script:
        - apk add --no-cache openssh-client py-pip python-dev libffi-dev openssl-dev gcc libc-dev make
        - pip install docker-compose~=1.23.0
        - export DOCKER_HOST=tcp://$PLAYWD.direct.labs.play-with-docker.com:2375
        - docker-compose down
        - docker-compose up -d
    environment:
        name: staging
        url: http://$PLAYWD-8080.direct.labs.play-with-docker.com


**Job goes into error. with this display:**

![image](https://user-images.githubusercontent.com/62578453/101156976-b4cfac00-3629-11eb-9a06-dd896ed15952.png)
",,,yjinnox,"
--
Can you help me solve the problem please...
--
",,,,,,,,,,
7967,OPEN,While following logs; allow for a keystroke to stop following without needing a Ctrl-C,kind/feature,2020-12-03 03:30:32 +0000 UTC,Calrain,Opened,,"**Problem description**
There are times when a workflow is needed with NPM scripts where you will start a docker image, issue some other commands, and then end up by following the docker logs to monitor that output.

An example of a workflow to start, configure, follow, and stop an application in a docker-compose environment includes:
User issues `npm run start` which:
1. Start the containers: `docker-compose {params} start`
2. Configure containers with app specific commands: `custom scripts and/or commands`
3. Follows the logs: `docker-compose {params} follow`
...wait until the user exits and then...
4. Stops the containers: `docker-compose {params} stop`

The issue is that when a user is following the logs on step 3, the only way for them to stop following the logs is to press `Control-C`. The issue is that `Control-C` issues a break command that is echoed up to the parent calling script, which causes the caller to handle the break (in this case it is NPM) and it stops the automation, stopping step 4 from automatically executing.

**Describe the solution you'd like**
Add a keystroke the user can press to close `docker-compose` while `follow`ing logs. Some keystroke like `q` or `Control-Z` (or anything) would then gracefully stop the `docker-compose` process and not generate a non-zero exit code, or echo up a break command to its caller.

**Describe alternatives you've considered**
The solution I have now is that people press Control-C and break the app, and then there is another command the devs have to type such as `npm run stop` which then stops the containers.

It would be great if that extra step wasn't required.


**Additional context**
I don't think the fundamental issue here is that it's an NPM issue, it's just that in this example NPM is the caller and is being forced to treat the break signal as indicating the spawned process had a problem.

If a user wants to stop following the logs then they should be able to issue a command, without killing the app.

Thanks for your consideration!
",,,,,,,,,,,,,,
7966,OPEN,Document passing project from stdin,kind/feature,2020-12-02 20:31:12 +0000 UTC,metametadata,Opened,,"**Is your feature request related to a problem? Please describe.**
Even though it's a common convention, it's not obvious that stdin can be used instead of the physical file. I.e. that `--file -` works.

**Describe the solution you'd like**
`--file` option description in `docker-compose help` should mention that `-` means `stdin`.

Maybe update the official documentation too.

**Describe alternatives you've considered**
There're none.

**Additional context**
docker-compose version 1.27.4",,,,,,,,,,,,,,
7964,OPEN,Compose config with --no-interpolate fails as it tries to validate environment variables as ports,kind/bug,2020-12-02 11:50:02 +0000 UTC,padraic-padraic,Opened,,"3. When making a bug report, make sure you provide all required information. The easier it is for
   maintainers to reproduce, the faster it'll be fixed.
-->

## Description of the issue

When trying combine compose and override files with `docker-compose config --no-interpolate`, I get an validation error in  the `ports` block for a service that uses environment variables.

## Context information (for bug reports)

**Output of `docker-compose version`**
```
docker-compose version 1.25.0, build unknown
```

**Output of `docker version`**
```
Docker version 19.03.8, build afacb8b7f0
```

**Output of `docker-compose config`**
(Make sure to add the relevant `-f` and other flags)
The issue relates to config!

## Steps to reproduce the issue

1. Small example file
    ```YAML
     #compose.yml
     version: '3'
     services:
        test:
          image: hello-world
          ports:
              - ""${DUMMY_PORT}:${DUMMY_PORT}""
    ```
2. `docker-compose -f compose.yml config --no-interpolate`

### Observed result
`services.test.ports is invalid: Invalid port ""${DUMMY_PORT}:${DUMMY_PORT}"", should be [[remote_ip:]remote_port[-remote_port]:]port[/protocol]`
### Expected result
```
version: '3'
services:
  test:
    image: hello-world
    ports:
      - ""${DUMMY_PORT}:${DUMMY_PORT}""
```
### Stacktrace / full error message

```
compose.config.config.find: Using configuration files: ./compose.yml
ERROR: compose.cli.main.main: The Compose file './compose.yml' is invalid because:
services.test.ports is invalid: Invalid port ""${DUMMY_PORT}:${DUMMY_PORT}"", should be [[remote_ip:]remote_port[-remote_port]:]port[/protocol]

```

## Additional information

OS version / distribution, `docker-compose` install method, etc.
Pop! OS 20.04, using system packages for docker / docker-compose.
",,,,,,,,,,,,,,
7963,OPEN,commands within docker-compose block don't work with docker machine,kind/bug,2020-12-10 01:59:56 +0000 UTC,Cally99,In progress,,"Below block of code works fine locally (MAC Mojave) for project and runs django server, also works on EC2 ubuntu when docker and docker-compose are installed. 

If I create a docker-machine env and run the project inside the vm the sh -c command won't work.
./wait-for-it.sh db:5432 not found. None of the commands work inside the block. 

Is there any explanation why docker this type of command block won't work with docker machine? 
Does a projects structure change inside a docker machine vm?

Really funny a file isn't found when using compose locally without docker machine env
 ```django:
    container_name: django  
    build:
      context: ./backend
    env_file: .env
    environment: 
      - DEBUG=True
    command: >
      sh -c ""./wait-for-it.sh db:5432 && 
            ./autobets/manage.py collectstatic --no-input &&
            ./autobets/manage.py makemigrations &&
            ./autobets/manage.py migrate --no-input &&
            ./autobets/manage.py runserver_plus 0.0.0.0:8000
            ""
    ports:
      - ""8000:8000""  
    volumes:
      - ./backend:/app
    depends_on:
      - db
    restart: on-failure``` ",,,Cally99,"
--
8 Days and no response? Why isn't docker compose commands compatible with docker machine?
--
",,,,,,,,,,
7958,OPEN,About networks on compose' ipam config,kind/question,2020-11-30 07:32:45 +0000 UTC,lpdswing,Opened,,"Please post on our forums: https://forums.docker.com for questions about using `docker-compose`.

Posts that are not a bug report or a feature/enhancement request will not be addressed on this issue tracker.
```
networks:
  default:
    name: et-network
    driver_opts:
      com.docker.network.bridge.name: ""et0""
    ipam:
      config: 
        - gateway: ""172.20.0.1""
          subnet: ""172.20.0.0/16""
```

I have a service to use the docker's gateway, if dont  use ipam config static gateway ip,can use a alias replace that like aliases on services -> servicename -> networks -> aliases",,,,,,,,,,,,,,
7957,OPEN,Node logs says can't find Password and keeps retrying every 15 sec.,kind/bug,2020-11-29 20:52:55 +0000 UTC,bMuTech,Opened,,I using intel NUC i5 with Ubuntu 20.04 1TB HD 32GB RAM. ,,,,,,,,,,,,,,
7955,OPEN,Environment variables with blank values are omitted,kind/bug,2021-01-05 00:13:02 +0000 UTC,avdi,In progress,,"Occasionally, it is significant for an environment variable to be explicitly set-to-blank, as opposed to unset. docker-compose appears not to support this case.

### Description of the issue

**Expected**

Given a docker-compose.yml containing:

```yaml
services:
  app:
    environment:
      HONEYCOMB_WRITE_KEY: """"
```
or

```yaml
...
HONEYCOMB_WRITE_KEY: 
```

Then in the app container, `HONEYCOMB_WRITE_KEY` should be set to the blank string. Equivalent to executing:

```shell
$ export HONEYCOMB_WRITE_KEY=""""
```

**Actual**

`HONEYCOMB_WRITE_KEY` is omitted from the container environment.

## Context information (for bug reports)

**Output of `docker-compose version`**
```
docker-compose version 1.27.4, build 40524192
docker-py version: 4.3.1
CPython version: 3.7.4
OpenSSL version: OpenSSL 1.1.1c  28 May 2019
```

**Output of `docker version`**
```
Client: Docker Engine - Community
 Cloud integration: 1.0.2
 Version:           19.03.13
 API version:       1.40
 Go version:        go1.13.15
 Git commit:        4484c46d9d
 Built:             Wed Sep 16 17:00:27 2020
 OS/Arch:           windows/amd64
 Experimental:      false

Server: Docker Engine - Community
 Engine:
  Version:          19.03.13
  API version:      1.40 (minimum version 1.12)
  Go version:       go1.13.15
  Git commit:       4484c46d9d
  Built:            Wed Sep 16 17:07:04 2020
  OS/Arch:          linux/amd64
  Experimental:     false
 containerd:
  Version:          v1.3.7
  GitCommit:        8fba4e9a7d01810a393d5d25a3621dc101981175
 runc:
  Version:          1.0.0-rc10
  GitCommit:        dc9208a3303feef5b3839f4323d9beb36df0a9dd
 docker-init:
  Version:          0.18.0
  GitCommit:        fec3683
```
",,,UlrichEckhardt,"
--
According to https://github.com/compose-spec/compose-spec/blob/master/spec.md#environment, the second of your examples seems not a bug. It says

> Environment variables MAY be declared by a single key (no value to equals sign). In such a case Compose implementations SHOULD rely on some user interaction to resolve the value. If they do not, the variable is unset and will be removed from the service container environment.

Note that the ""user interaction"" which this refers to probably means ""take from the calling environment"". In any case, it would be interesting whether a similarly named variable is set in your environment and what it's value is.
--
",avdi,"
--
> According to https://github.com/compose-spec/compose-spec/blob/master/spec.md#environment, the second of your examples seems not a bug. 

I'm OK with this. I still think the first example resulting in environment variable removal is both quite surprising and problematic for the (occasional) case where some tool or library considers set-to-blank to be significant.
--
",,,,,,,,
7954,OPEN,the docker-compose arm based releases are missing,kind/feature,2020-11-27 08:06:26 +0000 UTC,hillbilly-mark,Opened,,"I can't seem to find the arm based docker-compose files.   i can only find x86 files.   Can you, please, point me to where they are hidden?  Thanks!",,,,,,,,,,,,,,
7948,OPEN,String interpolation with `-e X=Y`,kind/bug,2020-12-02 09:42:25 +0000 UTC,uuf6429,In progress,,"## Description of the issue

`-e` option of `docker-compose run` does not seem to work for `command` (as expected).

Or perhaps this is intentional but not obvious or sufficiently documented.

## Context information (for bug reports)

**Output of `docker-compose version`**
```
docker-compose version 1.27.4, build 40524192
```

**Output of `docker version`**
```
Docker version 19.03.13, build 4484c46d9d
```

**Output of `docker-compose config`**
(Make sure to add the relevant `-f` and other flags)
```
services:
  test:
    command:
    - /bin/echo
    - not-set
    environment:
      SOME_VAR: from-dc-env
    image: busybox
version: '3.4'
```

## Steps to reproduce the issue

Given the following `docker-compose.yml`:
```yaml
version: '3.4'
services:
  test:
    image: busybox
    environment:
      SOME_VAR: from-dc-env
    command:
      - /bin/echo
      - ${SOME_VAR-not-set}
```
1. run `docker-compose run -e SOME_VAR=from-arg test` (fails)
2. also run `SOME_VAR=from-env docker-compose run test` (works)

### Observed result
1. ```
   Creating xxx_test_run ... done
   not-set                                            
   ```
2. ```
   Creating xxx_test_run ... done
   from-env
   ```

### Expected result
1. ```
   Creating xxx_test_run ... done
   from-arg
   ```
2. ```
   Creating xxx_test_run ... done
   from-env
   ```

### Stacktrace / full error message

n/a

## Additional information
macOS 11.0.1 (Big Sur), `docker-compose` from ""Docker for Mac""

I'd like to point out that I ended up using this approach after exhausting several other options that for whatever reason docker-compose does not (fully) implement, namely:
- _disabling certain services (since they're ""utility"" services that depend on a main service)_ - docker-compose does not support this (#1896)
- _implementing healthchecks on the main service so that the utility services run after it's up and running_ - docker-compose depends_on is (in my opinion) half-baked and [does not support this anymore] and the alternative is to hammer in a ""wait"" shell script + curl/wget (https://docs.docker.com/compose/compose-file/#depends_on)
- running a service directly hoping docker-compose is intelligent enough to _ignore mandatory variables of unrelated services_ (to no avail)
- spending way too much time to realise that _-e is not supported for `docker-compose up`_",,,aiordache,"
--
Hi @uuf6429 . You need to escape the env vars (use `$$`) that you don't want to be substituted when processing the Compose file. Try something like this:
```yaml
services:
  test:
    image: alpine
    environment:
      SOME_VAR: from-dc-env
    command: sh -c ""/bin/echo $${SOME_VAR-not_set}""
```
or 
```yaml
services:
  test:
    image: alpine
    environment:
      SOME_VAR: from-dc-env
    command:
      - sh
      - -c
      - /bin/echo $${SOME_VAR-not_set}
```
You need a shell to get that variable set according to what you want.


--

--
@uuf6429 You can run a `docker-compose config` to output the compose file after variable substitution.
```
$ docker-compose config
WARNING: The NAME variable is not set. Defaulting to a blank string.
services:
  test:
    image: ''
```
 
```
$ NAME=toto docker-compose config
services:
  test:
    image: toto
```
--

--
The -e flag vars are passed to the container, those are not used for substitution.
--
",uuf6429,"
--
Hello @aiordache!

I actually want them substituted... I think. 

Your example worked and I see what you did, but I don't understand why it wouldn't work earlier (as in my case).
So your example ends up executing `sh -c ""/bin/echo ${SOME_VAR-not_set}""` whereas in my case I was expecting to execute `sh -c ""/bin/echo from-arg""` (because I expected substitution to be performed earlier).

So maybe the real question is, what does string substitution in docker-compose really do?
```
services:
  test:
    image: $NAME
```
how is $NAME substituted?
--

--
I've seen that already, but presumably it should also support the -e flag (which it doesn't).

So yeah, this flag seems to be more trouble than it's worth... 
--

--
That would explain the whole situation... but I must say this is not at all obvious from the documentation: https://docs.docker.com/compose/reference/run/
It might have been hinted at here: https://docs.docker.com/compose/environment-variables/#set-environment-variables-in-containers 

--
",,,,,,,,
7942,OPEN,How to run some commands/scripts when stopping docker-compose,kind/feature,2020-11-26 16:50:36 +0000 UTC,alanwilter,In progress,,"The problem that brought me here is described here
https://stackoverflow.com/questions/64992099/how-to-run-a-closing-script-when-issuing-docker-compose-stop-or-crtl-c

Essentially, I'm not finding a solution where doing `ctrl-c` in a session started with `docker-compose up` or, from another terminal, `docker-compose stop/down`, I'd like to run few commands or scripts before seeing
```bash
...
frontend_1  |
^CGracefully stopping... (press Ctrl+C again to force)
Stopping app_browser_frontend_1   ... done
```",,,alanwilter,"
--
I found out that the issue is on how to `trap` `netlify dev`. If I use a zombie line instead, like, `while true; do :; done`, stopping the docker service, no matter how, except with a pure `kill`, will trigger the routine`cleanup`.

Honestly, an `exitpoint:` pragma in `docker-compose.yml` would be all I ever wanted.
--

--
In the end, this worked for me by amending `entrypoint.sh` with:

```bash
...
netlify dev | tee dev.log &
wait
```
But I'm still hoping for a better solution, like the suggest `exitpoint:...`
--
",,,,,,,,,,
7941,OPEN,QinQ support,kind/feature,2020-11-30 16:05:21 +0000 UTC,gcantho,In progress,,"Seems that docker compose does not support QinQ. 

The docker command that I usually run is as follows.
`docker network create -d macvlan --gateway=X.X.X.X --subnet=X.X.X.X/XX --ip_range=X.X.X.X/XX -o parent=eth0.20.200 vlan20-200`

When converting over my commands over to docker compose. This is what is included in my yaml.
```
networks:
  qinq_network:
    driver: macvlan
      driver_opts:
        parent: eth0.20.200
      ipam:
        config:
          - subnet: X.X.X.X/XX
            gateway: X.X.X.X
            ip_range: X.X.X.X/XX
```
I have no issues when running the `docker network create` command. However docker-compose throws an Error ` ERROR: required interface name format is: name.vlan_id, ex. eth0.10 for vlan 10, instead received eth0.20.200`

Is there a sugested work around? Can this be supported in future releases/",,,ulyssessouza,"
--
Hello @gcantho! Thank you for the issue!

Looking at the issue's description, I can see something that looks like a typo on the error message.
I also assume that it's a copy&paste from the terminal. And the characters `c` and `t` are switched on `eth0.20.200`.
Can you confirm that?
--
",gcantho,"
--
> Hello @gcantho! Thank you for the issue!
> 
> Looking at the issue's description, I can see something that looks like a typo on the error message.
> I also assume that it's a copy&paste from the terminal. And the characters `c` and `t` are switched on `eth0.20.200`.
> Can you confirm that?

@ulyssessouza 
Thanks for pointing that out. It was not a copy and paste. I hand jammed from another network.
--
",,,,,,,,
7936,OPEN,Scope limit secrets. Allow some secrets to be available on build time,kind/feature,2020-12-18 17:56:22 +0000 UTC,Maks3w,Opened,,"**Is your feature request related to a problem? Please describe.**
Docker secrets support can be used for runtime secrets (like database passwords) and also while building the container (pull dependencies from private repositories)

Actually all the secrets defined in the composer service are available while the container is running.

The proposal is allow to specify when the secret should be deployed with the container or only available when building the container.

The actual way is to build the service in a step apart from the rest of services declared in the compose file. The downsides are:

* Lack of parallelism (specific containers must to be build apart from the rest before or after)
* Extra CLI steps & commands (require the use of build scripts)
* Manage a list of exceptions when building some containers with `docker-compose build` vs containers built with `docker build`

**Describe the solution you'd like**
An option it could be add a config key in the service secret long syntax. Like

`service.<service name>.secrets.<secret name>.scope = all/build`

Ex:

```yml
version: ""3.8""
services:
  redis:
    image: redis:latest
    deploy:
      replicas: 1
    secrets:
      - source: ssh_key
        scope: build
secrets:
  ssh_key:
    file: ./ssh_key
```

By default it must have the `all` value for backward compatibility.

**Describe alternatives you've considered**
There is an alternative proposed in https://github.com/docker/compose/pull/7046 where the ""secrets"" service key can be placed as a subkey of service build key (`service.<service name>.build.secrets: -<secret name>`)

However I think is not a good approach to spawn secrets as subkeys as they make difficult to audit and to learn about the specifics. To have a config key in the parent service secrets key make easier to documentate and also make people aware about the risks about not limiting the scope.


**Additional context**
This is related with other features like https://github.com/docker/compose/issues/7025 and https://github.com/docker/compose/pull/7046",,,,,,,,,,,,,,
7934,OPEN,Intermittent compose command failures with compose cli 1.0.2,kind/bug,2020-11-19 17:41:29 +0000 UTC,asampal,Opened,,"## Description of the issue
With the new Docker Desktop Community 2.5.1.0 I'm now often getting a ""FileNotFoundError"" when attempting to invoke a docker-compose command, eg.e `docker-compose stop <service>` or `docker-compose up -d <service>`. This was not happening with the previous Edge release, 2.4.2.0. I notice `compose-cli` was upgraded so maybe that's the problem. The exact stack I'm seeing varies depending on the invoked command.

```
> docker-compose stop portainer
Traceback (most recent call last):
  File ""bin/docker-compose"", line 3, in <module>
  File ""compose/cli/main.py"", line 67, in main
  File ""compose/cli/main.py"", line 123, in perform_command
  File ""compose/cli/command.py"", line 69, in project_from_options
  File ""compose/cli/command.py"", line 125, in get_project
  File ""compose/cli/command.py"", line 184, in get_project_name
  File ""posixpath.py"", line 383, in abspath
FileNotFoundError: [Errno 2] No such file or directory
[18714] Failed to execute script docker-compose
```

```
> docker-compose config
Traceback (most recent call last):
  File ""bin/docker-compose"", line 3, in <module>
  File ""compose/cli/main.py"", line 67, in main
  File ""compose/cli/main.py"", line 120, in perform_command
  File ""compose/cli/main.py"", line 324, in config
  File ""compose/cli/command.py"", line 99, in get_config_from_options
  File ""compose/config/config.py"", line 406, in load
  File ""compose/config/config.py"", line 520, in load_services
  File ""compose/config/config.py"", line 501, in build_services
  File ""compose/config/config.py"", line 501, in <listcomp>
  File ""compose/config/config.py"", line 480, in build_service
  File ""compose/config/config.py"", line 289, in with_abs_paths
  File ""posixpath.py"", line 383, in abspath
FileNotFoundError: [Errno 2] No such file or directory
[18840] Failed to execute script docker-compose
```

These commands are being invoked from a bash shell in WSL 2. When the failure happens in one shell, opening another shell and re-running the command seems to succeed. In the original shell repeating the command fails continuously. It's difficult to say how often the compose cli commands fail. Sometimes the same set of commands which previously failed in a different shell instance will succeed without any failure.

## Context information (for bug reports)
Windows Version	10.0.19042 Build 19042
Docker Desktop 2.5.1.0

**Output of `docker-compose version`**
```
docker-compose version 1.27.4, build 40524192
docker-py version: 4.3.1
CPython version: 3.7.7
OpenSSL version: OpenSSL 1.1.0l  10 Sep 2019
```

**Output of `docker version`**
```
Client: Docker Engine - Community
 Cloud integration: 1.0.2
 Version:           20.10.0-rc1
 API version:       1.41
 Go version:        go1.13.15
 Git commit:        5cc2396
 Built:             Tue Nov 17 22:51:50 2020
 OS/Arch:           linux/amd64
 Context:           default
 Experimental:      true

Server: Docker Engine - Community
 Engine:
  Version:          20.10.0-rc1
  API version:      1.41 (minimum version 1.12)
  Go version:       go1.13.15
  Git commit:       131bf7e
  Built:            Tue Nov 17 22:52:57 2020
  OS/Arch:          linux/amd64
  Experimental:     true
 containerd:
  Version:          v1.4.1
  GitCommit:        c623d1b36f09f8ef6536a057bd658b3aa8632828
 runc:
  Version:          1.0.0-rc92
  GitCommit:        ff819c7e9184c13b7c2607fe6c30ae19403a7aff
 docker-init:
  Version:          0.19.0
  GitCommit:        de40ad0
```

**Output of `docker-compose config`**
(Make sure to add the relevant `-f` and other flags)
```
Cannot include, contains proprietary information.
```


## Steps to reproduce the issue

1. Install Docker Desktop for Win 2.5.1.0
2. invoke various compose commands from a WSL 2 bash shell
3. Observe intermittent failures
4. When command fails, open another shell and invoke the same command - observe success. 

### Observed result
Intermittent failures. When command fails, open another shell and invoke the same command - observe success. 

### Expected result
Consistent success


## Additional information

Windows Version	10.0.19042 Build 19042
Docker Desktop 2.5.1.0
",,,,,,,,,,,,,,
7933,OPEN,The image for the service you're trying to recreate has been removed,,2020-11-17 18:02:01 +0000 UTC,CrimsonGlory,Opened,,"The following error happens when the user is trying to up a service using an image from a private docker hub repo without being logged into docker hub:

> ""ERROR: The image for the service you're trying to recreate has been removed. If you continue, volume data could be lost. Consider backing up your data before continuing.""

Maybe we could change that description to indicate that the user is not logged into docker hub:

> ""ERROR: The image for the service you're trying to recreate has been removed (or the image is private and you may require 'docker login'). If you continue, volume data could be lost. Consider backing up your data before continuing.""

I don't know if it is easy for compose to check weather the user is logged in in docker hub. If so, compose could show the second message only when the user is not logged in.

This was tested with the latest docker compose.

```
user@host:~/foldername$ sudo docker-compose --version
docker-compose version 1.27.4, build 40524192
user@host:~/foldername$ sudo docker-compose -f distributed.yml up -d --no-recreate worker_no_vt
WARNING: Found orphan containers (foldername_db1_1, foldername_syslog_1) for this project. If you removed or renamed this service in your compose file, you can run this command with the --remove-orphans flag to clean it up.
Pulling worker_no_vt (dockerhubuser123/foldername:worker_cg_3344)...
ERROR: The image for the service you're trying to recreate has been removed. If you continue, volume data could be lost. Consider backing up your data before continuing.

Continue with the new image? [yN]N
ERROR: pull access denied for dockerhubuser123/foldername, repository does not exist or may require 'docker login'
user@host:~/foldername$ sudo docker pull dockerhubuser123/foldername:worker_cg_3344
Error response from daemon: pull access denied for dockerhubuser123/foldername, repository does not exist or may require 'docker login'
user@host:~/foldername$ sudo docker login
Login with your Docker ID to push and pull images from Docker Hub. If you don't have a Docker ID, head over to https://hub.docker.com to create one.
Username: dockerhubuser123
Password:
WARNING! Your password will be stored unencrypted in /home/user/.docker/config.json.
Configure a credential helper to remove this warning. See
https://docs.docker.com/engine/reference/commandline/login/#credentials-store

Login Succeeded
user@host:~/foldername$ sudo docker-compose -f distributed.yml up -d --no-recreate worker_no_vt
WARNING: Found orphan containers (foldername_syslog_1, foldername_db1_1) for this project. If you removed or renamed this service in your compose file, you can run this command with the --remove-orphans flag to clean it up.
Pulling worker_no_vt (dockerhubuser123/foldername:worker_cg_3344)...
worker_cg_3344: Pulling from dockerhubuser123/foldername
7568c21980bd: Pulling fs layer
4a9f2207c812: Downloading [>                                                  ]  110.1kB/10.8MB
6fe350d2b140: Download complete
d95a2fdc8b3d: Waiting
760eb225f9e8: Waiting
4acc342562b4: Waiting
a7903e427e3f: Waiting
44360edd3f02: Waiting
d7721ae168a3: Waiting
962c432e3e38: Waiting
8154812ac1d3: Waiting
0847dee02492: Waiting
2cbbcbace93f: Waiting
5c99f8c61911: Waiting
780a1b721474: Waiting
e6ab304bcd20: Waiting
1d7e5014f82a: Waiting
09a76902b260: Waiting
9bf84b26ef17: Waiting
166a889cbc4d: Waiting
5408056a1243: Waiting
c0f6a3cae015: Waiting
9debf7360ef6: Waiting
7235beb4b483: Waiting
9aa29cafb800: Waiting
dc8fc45e195c: Waiting
```

https://github.com/docker/compose/blob/8633939080095bc81f03b8a6a517d5c83d0dee93/compose/cli/main.py#L1077",,,,,,,,,,,,,,
7932,OPEN,Docker-compose log streaming crash when containers stops or restarts,kind/bug,2020-11-27 01:22:24 +0000 UTC,fgiovatreedom,Opened,,"3. When making a bug report, make sure you provide all required information. The easier it is for
   maintainers to reproduce, the faster it'll be fixed.
-->

## Description of the issue
Docker-compose log streaming crash when containers stops or restarts.

## Context information (for bug reports)

**Output of `docker-compose version`**
```
docker-compose version 1.27.4, build 40524192
docker-py version: 4.3.1
CPython version: 3.7.7
OpenSSL version: OpenSSL 1.1.1g  21 Apr 2020

```

**Output of `docker version`**
```
Client: Docker Engine - Community
 Cloud integration: 1.0.2
 Version:           19.03.13
 API version:       1.40
 Go version:        go1.13.15
 Git commit:        4484c46d9d
 Built:             Wed Sep 16 16:58:31 2020
 OS/Arch:           darwin/amd64
 Experimental:      false

Server: Docker Engine - Community
 Engine:
  Version:          19.03.13
  API version:      1.40 (minimum version 1.12)
  Go version:       go1.13.15
  Git commit:       4484c46d9d
  Built:            Wed Sep 16 17:07:04 2020
  OS/Arch:          linux/amd64
  Experimental:     false
 containerd:
  Version:          v1.3.7
  GitCommit:        8fba4e9a7d01810a393d5d25a3621dc101981175
 runc:
  Version:          1.0.0-rc10
  GitCommit:        dc9208a3303feef5b3839f4323d9beb36df0a9dd
 docker-init:
  Version:          0.18.0
  GitCommit:        fec3683
```

**Output of `docker-compose config`**
```
networks:
  default:
    external: true
    name: development
services:
  node:
    command:
    - npm
    - run
    - dev-new
    environment:
      NODE_ENV: development
    image: node:dubnium
    networks:
      default:
        aliases:
        - node.localhost
    ports:
    - published: 80
      target: 8080
    volumes:
    - ./node:/home/app:rw
    working_dir: /home/app
```


## Steps to reproduce the issue

1. Run ```docker-compose up```
2. Then change shell and run 
```
docker-compose stop; docker-compose rm; docker-compose up -d 
```
or 
```
docker-compose restart
```

### Observed result
On shell with logs attached:
```
node_1 exited with code 0
Exception in thread Thread-25:
Traceback (most recent call last):
  File ""site-packages/urllib3/response.py"", line 696, in _update_chunk_length
ValueError: invalid literal for int() with base 16: b''

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""site-packages/urllib3/response.py"", line 436, in _error_catcher
  File ""site-packages/urllib3/response.py"", line 763, in read_chunked
  File ""site-packages/urllib3/response.py"", line 700, in _update_chunk_length
http.client.IncompleteRead: IncompleteRead(0 bytes read)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""site-packages/requests/models.py"", line 751, in generate
  File ""site-packages/urllib3/response.py"", line 571, in stream
  File ""site-packages/urllib3/response.py"", line 792, in read_chunked
  File ""contextlib.py"", line 130, in __exit__
  File ""site-packages/urllib3/response.py"", line 454, in _error_catcher
urllib3.exceptions.ProtocolError: ('Connection broken: IncompleteRead(0 bytes read)', IncompleteRead(0 bytes read))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""threading.py"", line 926, in _bootstrap_inner
  File ""threading.py"", line 870, in run
  File ""compose/cli/log_printer.py"", line 214, in watch_events
  File ""compose/project.py"", line 575, in yield_loop
  File ""compose/project.py"", line 543, in build_container_event
  File ""compose/container.py"", line 44, in from_id
  File ""site-packages/docker/utils/decorators.py"", line 19, in wrapped
  File ""site-packages/docker/api/container.py"", line 771, in inspect_container
  File ""site-packages/docker/utils/decorators.py"", line 46, in inner
  File ""site-packages/docker/api/client.py"", line 228, in _get
  File ""site-packages/requests/sessions.py"", line 543, in get
  File ""site-packages/requests/sessions.py"", line 530, in request
  File ""site-packages/requests/sessions.py"", line 685, in send
  File ""site-packages/requests/models.py"", line 829, in content
  File ""site-packages/requests/models.py"", line 754, in generate
requests.exceptions.ChunkedEncodingError: ('Connection broken: IncompleteRead(0 bytes read)', IncompleteRead(0 bytes read))
```
And after that the log stream remain detached

### Expected result
```
node_1 exited with code 0
node_1            | 
node_1            | > node@0.0.1 dev-new /home/app
node_1            | > npm install --no-package-lock; nodemon --delay 1 ./bin/www --exec babel-node --presets env
node_1            | 
....
```
The log stream must be remain attached

### Stacktrace / full error message

```
Exception in thread Thread-25:
Traceback (most recent call last):
  File ""site-packages/urllib3/response.py"", line 696, in _update_chunk_length
ValueError: invalid literal for int() with base 16: b''

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""site-packages/urllib3/response.py"", line 436, in _error_catcher
  File ""site-packages/urllib3/response.py"", line 763, in read_chunked
  File ""site-packages/urllib3/response.py"", line 700, in _update_chunk_length
http.client.IncompleteRead: IncompleteRead(0 bytes read)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""site-packages/requests/models.py"", line 751, in generate
  File ""site-packages/urllib3/response.py"", line 571, in stream
  File ""site-packages/urllib3/response.py"", line 792, in read_chunked
  File ""contextlib.py"", line 130, in __exit__
  File ""site-packages/urllib3/response.py"", line 454, in _error_catcher
urllib3.exceptions.ProtocolError: ('Connection broken: IncompleteRead(0 bytes read)', IncompleteRead(0 bytes read))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""threading.py"", line 926, in _bootstrap_inner
  File ""threading.py"", line 870, in run
  File ""compose/cli/log_printer.py"", line 214, in watch_events
  File ""compose/project.py"", line 575, in yield_loop
  File ""compose/project.py"", line 543, in build_container_event
  File ""compose/container.py"", line 44, in from_id
  File ""site-packages/docker/utils/decorators.py"", line 19, in wrapped
  File ""site-packages/docker/api/container.py"", line 771, in inspect_container
  File ""site-packages/docker/utils/decorators.py"", line 46, in inner
  File ""site-packages/docker/api/client.py"", line 228, in _get
  File ""site-packages/requests/sessions.py"", line 543, in get
  File ""site-packages/requests/sessions.py"", line 530, in request
  File ""site-packages/requests/sessions.py"", line 685, in send
  File ""site-packages/requests/models.py"", line 829, in content
  File ""site-packages/requests/models.py"", line 754, in generate
requests.exceptions.ChunkedEncodingError: ('Connection broken: IncompleteRead(0 bytes read)', IncompleteRead(0 bytes read))
```

## Additional information
I'm running docker on macOS Catalina (10.15.7) ",,,grit96,"
--
I have the same issue on macOS Big Sur - the logs crash and don't reattach when containers are restarted.
--
",blixt,"
--
I'm reliably seeing this on macOS 11.0.1 (20B29) with:

```
docker-compose version 1.27.4, build 40524192
docker-py version: 4.3.1
CPython version: 3.7.7
OpenSSL version: OpenSSL 1.1.1g  21 Apr 2020
```

---

```
Client: Docker Engine - Community
 Cloud integration: 1.0.2
 Version:           19.03.13
 API version:       1.40
 Go version:        go1.13.15
 Git commit:        4484c46d9d
 Built:             Wed Sep 16 16:58:31 2020
 OS/Arch:           darwin/amd64
 Experimental:      false

Server: Docker Engine - Community
 Engine:
  Version:          19.03.13
  API version:      1.40 (minimum version 1.12)
  Go version:       go1.13.15
  Git commit:       4484c46d9d
  Built:            Wed Sep 16 17:07:04 2020
  OS/Arch:          linux/amd64
  Experimental:     false
 containerd:
  Version:          v1.3.7
  GitCommit:        8fba4e9a7d01810a393d5d25a3621dc101981175
 runc:
  Version:          1.0.0-rc10
  GitCommit:        dc9208a3303feef5b3839f4323d9beb36df0a9dd
 docker-init:
  Version:          0.18.0
  GitCommit:        fec3683
```
--
",thaJeztah,"
--
Wondering if this is related to https://github.com/docker/docker-py/issues/2696 /  https://github.com/docker/for-mac/issues/5059#issuecomment-726036933

@aiordache @simonferquel 
--

--
Does the problem go away if you make compose use the ""raw"" socket? You can set the `DOCKER_HOST` environment variable to switch;

```bash
export DOCKER_HOST=unix://""$HOME""/Library/Containers/com.docker.docker/Data/docker.raw.sock
```

And to unset that variable;

```bash
unset DOCKER_HOST
```

--

--
Ah, yes, read my ""big fat warning"" here; https://github.com/docker/docker-py/issues/2696#issuecomment-729636008
--
",BrianGilbert,"
--
Also getting this with Big Sur 11.0.1 (20B29) 

Issue is present with stable or edge version of Docker.

--

--
This seems to be resolved as of Docker for Mac edge 2.5.2 which came out today
--
",kelseym,"
--
I am seeing the same error on Catalina 10.15.7
Docker v19.03.13
docker-compose version 1.27.4, build 40524192
--
",simonferquel,"
--
Note, @thaJeztah suggestion is only to narrow the problem down a little bit, you should not mount the raw socket in a container, as it won't be able to handle bind-mounts of your mac files.
--
"
7925,OPEN,Ports Published Dynamically via Range or {{.Task.Slot}},kind/feature,2020-11-12 15:47:15 +0000 UTC,Shinoby92,Opened,,"I hope there are enough people out there for this feature request:

- I need to dynamically publish ports of the replicas and wishing to do this with 


```
services:
  image1:
    user: root
    image: image1:latest
    ports:
    - target: 6901
      published: {{.Task.Slot}}
    networks:
      - my-attachable-overlay
....so on 
```



as an example dynamically with the Task Slot property delivered in stack deploy in stack deploy.

",,,,,,,,,,,,,,
7924,OPEN,docker login fails on different containers,kind/bug,2020-11-12 11:47:34 +0000 UTC,AthulMuralidhar,Opened,,"3. When making a bug report, make sure you provide all required information. The easier it is for
   maintainers to reproduce, the faster it'll be fixed.
-->

## Description of the issue
- the docker compose up command fails to build after running `docker system prune -a` 
- seems like the login details are forgotten after runing the prune command

## Context information (for bug reports)

**Output of `docker-compose version`**
```
docker-compose version 1.27.4, build 40524192
```

**Output of `docker version`**
```
Client: Docker Engine - Community
 Version:           19.03.13
 API version:       1.40
 Go version:        go1.13.15
 Git commit:        4484c46d9d
 Built:             Wed Sep 16 16:58:31 2020
 OS/Arch:           darwin/amd64
 Experimental:      false

Server: Docker Engine - Community
 Engine:
  Version:          19.03.13
  API version:      1.40 (minimum version 1.12)
  Go version:       go1.13.15
  Git commit:       4484c46d9d
  Built:            Wed Sep 16 17:07:04 2020
  OS/Arch:          linux/amd64
  Experimental:     false
 containerd:
  Version:          v1.3.7
  GitCommit:        8fba4e9a7d01810a393d5d25a3621dc101981175
 runc:
  Version:          1.0.0-rc10
  GitCommit:        dc9208a3303feef5b3839f4323d9beb36df0a9dd
 docker-init:
  Version:          0.18.0
  GitCommit:        fec3683
```


## Steps to reproduce the issue

1. run `docker system prune -a`
2. run `docker-compose up --build`

### Observed result
```
ERROR: pull access denied for <image name>, repository does not exist or may require 'docker login': denied: requested access to the resource is denied
```

### Expected result
- the containers should just be built

### Stacktrace / full error message

```
ERROR: pull access denied for <image name>, repository does not exist or may require 'docker login': denied: requested access to the resource is denied
``` 

## Additional information

OS version / distribution, `docker-compose` install method, etc.
- macOS catalina version: 10.15.7
",,,,,,,,,,,,,,
7923,OPEN,Cross-container file truncation when using nested bind mounts,kind/bug,2020-11-11 22:53:58 +0000 UTC,mkochco,Opened,,"## Description of the issue

On MacOS, when using a nested bind mount in one docker-compose project 
```
volumes:
   "".:/var/www/tmp"",
   ""test_file.txt:/var/www/tmp/should-not-be-zero-length.txt""
```
And when a separate project ALSO does a bind mount of any kind
```
volumes:
  ""test_file.txt:/tmp/test.file.txt""
```
Then after the first container is started we have a successful mount and file size.
But when the second container, in a separate project, is started, the bind mounted file in the first project will be truncated (0 file size)

[macos-nested-file-mount-repro.zip](https://github.com/docker/compose/files/5527145/macos-nested-file-mount-repro.zip)

## Context information (for bug reports)

**Output of `docker-compose version`**
```
docker-compose version 1.25.5, build unknown
```

**Output of `docker version`**
```
Docker version 19.03.13, build 4484c46d9d
```

**Output of `docker-compose config`**
Two docker-compose.yml contained in attachement
```
(paste here)
```

## Steps to reproduce the issue
```
1. unzip macos-nested-file-mount-repro.zip
2. cd macos-nested-file-mount-repro
3. cd project-a
4. docker-compose up -d
5. docker exec project-a-test ls -al /var/www/tmp/
6. cd ../project-b
7. docker-compose up -d
8. docker exec project-a-test ls -al /var/www/tmp/
```
### Observed result

```
$ cd macos-nested-file-mount-repro
$ cd project-a
$ docker-compose up -d
Recreating project-a-test ... done
$ docker exec project-a-test ls -al /var/www/tmp/
total 20
drwxr-xr-x 6 root root  192 Nov 11 21:46 .
drwxr-xr-x 3 root root 4096 Nov 11 21:30 ..
-rw-r--r-- 1 root root   26 Nov  7 21:51 should-not-be-zero-length.txt
$ cd ../project-b
$ docker-compose up -d
$ docker exec project-a-test ls -al /var/www/tmp/should-not-be-zero-length.txt
-rwxr-xr-x 1 root root 0 Nov 11 22:02 /var/www/tmp/should-not-be-zero-length.txt
```


### Expected result
```
$ cd macos-nested-file-mount-repro
$ cd project-a
$ docker-compose up -d
Recreating project-a-test ... done
$ docker exec project-a-test ls -al /var/www/tmp/should-not-be-zero-length.txt
-rw-r--r-- 1 root root 26 Nov  7 21:51 /var/www/tmp/should-not-be-zero-length.txt
$ cd ../project-b
$ docker-compose up -d
$ docker exec project-a-test ls -al /var/www/tmp/should-not-be-zero-length.txt
-rwxr-xr-x 1 root root 26
 Nov 11 22:02 /var/www/tmp/should-not-be-zero-length.txt
```

### Stacktrace / full error message

```
(paste here)
```

## Additional information

MacOS Catalina - Docker Desktop for Mac - 2.5.0.0",,,thaJeztah,"
--
@djs55 PTAL
--
",,,,,,,,,,
7922,OPEN,docker-compose build fails in rootless environment,kind/bug,2021-01-11 02:04:59 +0000 UTC,gertvanantwerpentno,In progress,,"3. When making a bug report, make sure you provide all required information. The easier it is for
   maintainers to reproduce, the faster it'll be fixed.
-->

## Description of the issue

## Context information (for bug reports)

**Output of `docker-compose version`**
```
docker-compose version 1.27.4, build 40524192
docker-py version: 4.3.1
CPython version: 3.7.7
OpenSSL version: OpenSSL 1.1.0l  10 Sep 2019
```

**Output of `docker version`**
```
Client: Docker Engine - Community
 Version:           master-dockerproject-2020-11-06
 API version:       1.41
 Go version:        go1.13.15
 Git commit:        b07e921289
 Built:             Fri Nov  6 23:52:51 2020
 OS/Arch:           linux/amd64
 Context:           default
 Experimental:      true

Server: Docker Engine - Community
 Engine:
  Version:          master-dockerproject-2020-11-06
  API version:      1.41 (minimum version 1.12)
  Go version:       go1.13.15
  Git commit:       b5ea9ab
  Built:            Fri Nov  6 23:56:47 2020
  OS/Arch:          linux/amd64
  Experimental:     true
 containerd:
  Version:          v1.4.1
  GitCommit:        c623d1b36f09f8ef6536a057bd658b3aa8632828
 runc:
  Version:          1.0.0-rc92
  GitCommit:        ff819c7e9184c13b7c2607fe6c30ae19403a7aff
 docker-init:
  Version:          0.19.0
  GitCommit:        de40ad0

```

**Output of `docker-compose config`**
(Make sure to add the relevant `-f` and other flags)
```
services:
  test:
    build:
      context: /home/gert/dockertest/testje
      dockerfile: Dockerfile
    image: testjegva
    user: 0:0
version: '3.8'
```


## Steps to reproduce the issue

1. In ""testje"" is only a Dockerfile, containing: FROM busybox
2. I am running rootless-docker with userid 81525 (which is > 65536, which maybe caused the error)
3. docker-compose build

### Observed result
ERROR: Error processing tar file(exit status 1): lchown /Dockerfile: invalid argument
When I trace the dockerd, I see it doing a fchown(""/Dockerfile"",81525,1250,AT_SYMLINK_NOFOLLOW) -> -1
Why is it doing a fchown of this file? The dockerd is already running with the right user, so the file will already have the right owner. Note, I am running in rootless mode, so outside docker 81525 is inside docker 0.
### Expected result
I expect a normal build.
### Stacktrace / full error message

```
ERROR: Error processing tar file(exit status 1): lchown /Dockerfile: invalid argument
```

## Additional information
Running Ubuntu-18.04",,,oToToT,"
--
I found that if we run docker-compose with rootlesskit (like `rootlesskit docker-compose build`), then it works perfectly.
--

--
@gertvanantwerpentno my real uid is 69031 on my system. It is greater than 65536.
--

--
@gertvanantwerpentno  
Sorry, I'm not familiar to subuid mechanism, but I guess this is my /etc/subuid `ototot:1106509824:65536` about my account.  
What does uid not fits in that range means?

Thanks.
--

--
According to your statement, it seems like I have my outside UID be 69031 which is larger than the last number (65536), but it works great for me.  
Maybe this is helpful for those who wants to solve this problem.
--
",gertvanantwerpentno,"
--
What is your uid? On my system it also works perfectly, but on systems where my uid > 65536 I had this problem.
--

--
What is the range you have in the /etc/subuid file? I had the problem when the uid not fits in that range
--

--
The middle number is the start of the user-id range you get inside the docker namespace.
The 65536 is the number of user-ids you can use.
I had the problem in cases where my outside UID was larger than the last number.
But I am not sure docker-compose is the source of the problem.

From: Tommy Chiang <notifications@github.com>
Sent: zaterdag 26 december 2020 14:31
To: docker/compose <compose@noreply.github.com>
Cc: Antwerpen, G. (Gert) van <gert.vanantwerpen@tno.nl>; Mention <mention@noreply.github.com>
Subject: Re: [docker/compose] docker-compose build fails in rootless environment (#7922)


@gertvanantwerpentno<https://github.com/gertvanantwerpentno>
Sorry, I'm not familiar to subuid mechanism, but I guess this is my /etc/subuid ototot:1106509824:65536 about my account.
What does uid not fits in that range means?

Thanks.


You are receiving this because you were mentioned.
Reply to this email directly, view it on GitHub<https://github.com/docker/compose/issues/7922#issuecomment-751355870>, or unsubscribe<https://github.com/notifications/unsubscribe-auth/ARBAPURTQZOYTAS2ZFDXKM3SWXQPZANCNFSM4TR3TD6Q>.
This message may contain information that is not intended for you. If you are not the addressee or if this message was sent to you by mistake, you are requested to inform the sender and delete the message. TNO accepts no liability for the content of this e-mail, for the manner in which you use it and for damage of any kind resulting from the risks inherent to the electronic transmission of messages.

--

--
I will see what I can do to find a more precise condition why it happens to me.

From: Tommy Chiang <notifications@github.com>
Sent: zaterdag 26 december 2020 18:29
To: docker/compose <compose@noreply.github.com>
Cc: Antwerpen, G. (Gert) van <gert.vanantwerpen@tno.nl>; Mention <mention@noreply.github.com>
Subject: Re: [docker/compose] docker-compose build fails in rootless environment (#7922)


According to your statement, it seems like I have my outside UID be 69031 which is larger than the last number (65536), but it works great for me.
Maybe this is helpful for those who wants to solve this problem.


You are receiving this because you were mentioned.
Reply to this email directly, view it on GitHub<https://github.com/docker/compose/issues/7922#issuecomment-751377450>, or unsubscribe<https://github.com/notifications/unsubscribe-auth/ARBAPUR6DS6M7JWRTRYUAYTSWYMNXANCNFSM4TR3TD6Q>.
This message may contain information that is not intended for you. If you are not the addressee or if this message was sent to you by mistake, you are requested to inform the sender and delete the message. TNO accepts no liability for the content of this e-mail, for the manner in which you use it and for damage of any kind resulting from the risks inherent to the electronic transmission of messages.

--

--
I can still reproduce the problem, using newest rootless docker and docker-compose:

docker-compose 1.27.4
docker 20.10.1
debian-10
username: test (uid=80000)
/etc/subuid: test:10655536:65536

docker-compose build
Building test
ERROR: Error processing tar file(exit status 1): lchown /Dockerfile: invalid argument
--
",ZeePal,"
--
I was having this error as well (uid=66644 gid=66049). I changed /etc/subuid & /etc/subgid from:
`USERNAME:100000:65535` to `USERNAME:100000:99999`

I then restarted the rootless docker service and it working now :D

Is it just adding your UID/GID onto the starting range (100000) so its overflowing perhaps?
--
",,,,,,
7920,OPEN,Wrong image name breaks docker-compose build,kind/bug,2020-12-12 11:29:36 +0000 UTC,maxkratz,In progress,,"3. When making a bug report, make sure you provide all required information. The easier it is for
   maintainers to reproduce, the faster it'll be fixed.
-->

## Description of the issue

`docker-compose build` crashes with a useless error message if the specified image name (target) for a build does not meet the Docker requirements.

## Context information (for bug reports)

**Output of `docker-compose version`**
```
docker-compose version 1.25.4, build 8d51620a
docker-py version: 4.1.0
CPython version: 3.7.5
OpenSSL version: OpenSSL 1.1.0l  10 Sep 2019
```

**Output of `docker version`**
```
Client: Docker Engine - Community
 Version:           19.03.13
 API version:       1.40
 Go version:        go1.13.15
 Git commit:        4484c46d9d
 Built:             Wed Sep 16 17:02:36 2020
 OS/Arch:           linux/amd64
 Experimental:      false

Server: Docker Engine - Community
 Engine:
  Version:          19.03.13
  API version:      1.40 (minimum version 1.12)
  Go version:       go1.13.15
  Git commit:       4484c46d9d
  Built:            Wed Sep 16 17:01:06 2020
  OS/Arch:          linux/amd64
  Experimental:     false
 containerd:
  Version:          1.3.7
  GitCommit:        8fba4e9a7d01810a393d5d25a3621dc101981175
 runc:
  Version:          1.0.0-rc10
  GitCommit:        dc9208a3303feef5b3839f4323d9beb36df0a9dd
 docker-init:
  Version:          0.18.0
  GitCommit:        fec3683
```

**Output of `docker-compose config`**
(Make sure to add the relevant `-f` and other flags)
```
services:
  app:
    build:
      context: /home/maxkratz/gits/vfl
    cpu_count: 2
    cpu_percent: 75
    environment:
      TZ: Europe/Berlin
    image: registry/test/XYZ:latest
    mem_limit: 4G
    memswap_limit: 4G
    ports:
    - 8080:8080/tcp
    restart: unless-stopped
version: '2.4'
```


## Steps to reproduce the issue

1. Create a `docker-compose.yml` with an image name that does not meet the docker requirements, e.g. ""registry/test/XYZ:latest"" (In this example the UPPERCASE letters are invalid symbols.)
2. Run `docker-compose build --no-cache`

### Observed result

`docker-compose` shows a message, that it couldn't connect to Docker daemon (see later section with output trace).

Docker itself provides a helpful error message e.g. if I run `docker build -t registry/test/XYZ:latest . --no-cache`:

```
invalid argument ""registry/test/XYZ:latest"" for ""-t, --tag"" flag: invalid reference format: repository name must be lowercase
See 'docker build --help'.
```

### Expected result

A helpful error message e.g. ""Specified docker image name does not meet requirement(s) xy.""

### Stacktrace / full error message

```
Building app
ERROR: Couldn't connect to Docker daemon at http+docker://localhost - is it running?

If it's at a non-standard location, specify the URL with the DOCKER_HOST environment variable.
```

## Additional information

OS version / distribution:
* Linux Mint 19.2 Tina x86_64 with Linux Kernel 5.6.17-050617-generic.

`docker-compose` install method
* `docker-compose` was installed as described here: https://docs.docker.com/compose/install/ (Downloaded from github release pages and marked as executable.)",,,Hackebein,"
--
> * Create a `docker-compose.yml` with an image name that does not meet the docker requirements, e.g. ""registry/test/XYZ:latest"" (In this example the UPPERCASE letters are invalid symbols.)
> * Run `docker-compose build --no-cache`

As i found out it depends on files in the same folder (or sub folders) with docker-compose.yml.
For example:
* Take an empty folder.
* Create an invalid `docker-compose.yml` file as descripted above.
* Install npm package lodash (`npm install lodash`)
* Try `docker-compose build` (to get the error message).

After removing the `node_modules` folder, `docker-compose build` is working as expected again.

My research can be found here: https://github.com/Hackebein/github-action-docker-compose-connection-error-example

Here some context Informations from where i tryed my tests:
```
# uname -a
Linux server01 5.4.0-54-generic #60-Ubuntu SMP Fri Nov 6 10:37:59 UTC 2020 x86_64 x86_64 x86_64 GNU/Linux
# docker-compose version
docker-compose version 1.22.0, build f46880fe
docker-py version: 3.4.1
CPython version: 3.6.6
OpenSSL version: OpenSSL 1.1.0f  25 May 2017
# docker version
Client: Docker Engine - Community
 Version:           20.10.0
 API version:       1.41
 Go version:        go1.13.15
 Git commit:        7287ab3
 Built:             Tue Dec  8 18:59:40 2020
 OS/Arch:           linux/amd64
 Context:           default
 Experimental:      true

Server: Docker Engine - Community
 Engine:
  Version:          20.10.0
  API version:      1.41 (minimum version 1.12)
  Go version:       go1.13.15
  Git commit:       eeddea2
  Built:            Tue Dec  8 18:57:45 2020
  OS/Arch:          linux/amd64
  Experimental:     false
 containerd:
  Version:          1.4.3
  GitCommit:        269548fa27e0089a8b8278fc4fc781d7f65a939b
 runc:
  Version:          1.0.0-rc92
  GitCommit:        ff819c7e9184c13b7c2607fe6c30ae19403a7aff
 docker-init:
  Version:          0.19.0
  GitCommit:        de40ad0
```
```
# uname -a
Linux server02 5.4.0-54-generic #60-Ubuntu SMP Fri Nov 6 10:37:59 UTC 2020 x86_64 x86_64 x86_64 GNU/Linux
# docker-compose version
docker-compose version 1.27.4, build 40524192
docker-py version: 4.3.1
CPython version: 3.7.7
OpenSSL version: OpenSSL 1.1.0l  10 Sep 2019
# docker version
Client: Docker Engine - Community
 Version:           20.10.0
 API version:       1.41
 Go version:        go1.13.15
 Git commit:        7287ab3
 Built:             Tue Dec  8 18:59:40 2020
 OS/Arch:           linux/amd64
 Context:           default
 Experimental:      true

Server: Docker Engine - Community
 Engine:
  Version:          20.10.0
  API version:      1.41 (minimum version 1.12)
  Go version:       go1.13.15
  Git commit:       eeddea2
  Built:            Tue Dec  8 18:57:45 2020
  OS/Arch:          linux/amd64
  Experimental:     false
 containerd:
  Version:          1.4.3
  GitCommit:        269548fa27e0089a8b8278fc4fc781d7f65a939b
 runc:
  Version:          1.0.0-rc92
  GitCommit:        ff819c7e9184c13b7c2607fe6c30ae19403a7aff
 docker-init:
  Version:          0.19.0
  GitCommit:        de40ad0
```
```
# uname -a
Linux Hinkelstein 4.19.128-microsoft-standard #1 SMP Tue Jun 23 12:58:10 UTC 2020 x86_64 x86_64 x86_64 GNU/Linux
$ docker-compose version
docker-compose version 1.27.4, build 40524192
docker-py version: 4.3.1
CPython version: 3.7.7
OpenSSL version: OpenSSL 1.1.0l  10 Sep 2019
$ docker version
Client: Docker Engine - Community
 Cloud integration: 1.0.4
 Version:           20.10.0
 API version:       1.41
 Go version:        go1.13.15
 Git commit:        7287ab3
 Built:             Tue Dec  8 18:59:53 2020
 OS/Arch:           linux/amd64
 Context:           default
 Experimental:      true

Server: Docker Engine - Community
 Engine:
  Version:          20.10.0
  API version:      1.41 (minimum version 1.12)
  Go version:       go1.13.15
  Git commit:       eeddea2
  Built:            Tue Dec  8 18:58:04 2020
  OS/Arch:          linux/amd64
  Experimental:     false
 containerd:
  Version:          v1.4.3
  GitCommit:        269548fa27e0089a8b8278fc4fc781d7f65a939b
 runc:
  Version:          1.0.0-rc92
  GitCommit:        ff819c7e9184c13b7c2607fe6c30ae19403a7aff
 docker-init:
  Version:          0.19.0
  GitCommit:        de40ad0
```
```
$ uname -a
Linux fv-az212-682 5.4.0-1031-azure #32-Ubuntu SMP Tue Oct 6 09:47:33 UTC 2020 x86_64 x86_64 x86_64 GNU/Linux
$ docker-compose version
docker-compose version 1.27.4, build 40524192
docker-py version: 4.3.1
CPython version: 3.7.7
OpenSSL version: OpenSSL 1.1.0l  10 Sep 2019
$ docker version
Client:
 Version:           19.03.13+azure
 API version:       1.40
 Go version:        go1.13.15
 Git commit:        cd8016b6bcc51a51f577bcffb37e6a870f7813f9
 Built:             Tue Sep 15 23:02:04 2020
 OS/Arch:           linux/amd64
 Experimental:      false

Server:
 Engine:
  Version:          19.03.13+azure
  API version:      1.40 (minimum version 1.12)
  Go version:       go1.13.15
  Git commit:       bd33bbf0497b2327516dc799a5e541b720822a4c
  Built:            Mon Mar 12 00:00:00 2018
  OS/Arch:          linux/amd64
  Experimental:     false
 containerd:
  Version:          1.3.7+azure
  GitCommit:        8fba4e9a7d01810a393d5d25a3621dc101981175
 runc:
  Version:          1.0.0-rc92
  GitCommit:        ff819c7e9184c13b7c2607fe6c30ae19403a7aff
 docker-init:
  Version:          0.18.0
  GitCommit:        
```
Error Message with `--verbose`:
```
compose.config.config.find: Using configuration files: ./docker-compose.fails.yml
docker.utils.config.find_config_file: Trying paths: ['/home/runner/.docker/config.json', '/home/runner/.dockercfg']
docker.utils.config.find_config_file: Found file at path: /home/runner/.docker/config.json
docker.utils.config.find_config_file: Trying paths: ['/home/runner/.docker/config.json', '/home/runner/.dockercfg']
docker.utils.config.find_config_file: Found file at path: /home/runner/.docker/config.json
docker.auth.load_config: Found 'auths' section
docker.auth.parse_auth: Found entry (registry='https://index.docker.io/v1/', username='githubactions')
urllib3.connectionpool._make_request: http://localhost:None ""GET /version HTTP/1.1"" 200 905
urllib3.connectionpool._make_request: http://localhost:None ""GET /v1.40/version HTTP/1.1"" 200 905
compose.cli.docker_client.get_client: docker-compose version 1.27.4, build 40524192
docker-py version: 4.3.1
CPython version: 3.7.7
OpenSSL version: OpenSSL 1.1.0l  10 Sep 2019
compose.cli.docker_client.get_client: Docker base_url: http+docker://localhost
compose.cli.docker_client.get_client: Docker version: Platform={'Name': ''}, Components=[{'Name': 'Engine', 'Version': '19.03.13+azure', 'Details': {'ApiVersion': '1.40', 'Arch': 'amd64', 'BuildTime': '2018-03-12T00:00:00.000000000+00:00', 'Experimental': 'false', 'GitCommit': 'bd33bbf0497b2327516dc799a5e541b720822a4c', 'GoVersion': 'go1.13.15', 'KernelVersion': '5.4.0-1031-azure', 'MinAPIVersion': '1.12', 'Os': 'linux'}}, {'Name': 'containerd', 'Version': '1.3.7+azure', 'Details': {'GitCommit': '8fba4e9a7d01810a393d5d25a3621dc101981175'}}, {'Name': 'runc', 'Version': '1.0.0-rc92', 'Details': {'GitCommit': 'ff819c7e9184c13b7c2607fe6c30ae19403a7aff'}}, {'Name': 'docker-init', 'Version': '0.18.0', 'Details': {'GitCommit': ''}}], Version=19.03.13+azure, ApiVersion=1.40, MinAPIVersion=1.12, GitCommit=bd33bbf0497b2327516dc799a5e541b720822a4c, GoVersion=go1.13.15, Os=linux, Arch=amd64, KernelVersion=5.4.0-1031-azure, BuildTime=2018-03-12T00:00:00.000000000+00:00
compose.cli.verbose_proxy.proxy_callable: docker inspect_network <- ('null_default')
urllib3.connectionpool._make_request: http://localhost:None ""GET /v1.40/networks/null_default HTTP/1.1"" 404 45
compose.service.build: Building latest
compose.cli.verbose_proxy.proxy_callable: docker build <- (path='/home/runner/work/null/null', tag='Hackebein/null:latest', rm=True, forcerm=False, pull=False, nocache=False, dockerfile='Dockerfile', cache_from=None, labels=None, buildargs={}, network_mode=None, target=None, shmsize=None, extra_hosts=None, container_limits={'memory': None}, gzip=False, isolation=None, platform=None)
docker.api.build._set_auth_headers: Looking for auth config
docker.api.build._set_auth_headers: Sending auth config ('https://index.docker.io/v1/')
compose.cli.errors.exit_with_error: Couldn't connect to Docker daemon at http+docker://localhost - is it running?

If it's at a non-standard location, specify the URL with the DOCKER_HOST environment variable.
Error: Process completed with exit code 1.
```
--

--
okay, i can't confirm that on my system. Are we using the exact same `docker-compose.yml` file? Or is there any hidden files? (`tree` doesn't show them by default)

```
$ ls -la
total 0
drwxrwxrwx 1 user user 4096 Dec 11 22:22 .
drwxrwxrwx 1 user user 4096 Dec 11 22:18 ..
-rwxrwxrwx 1 user user  296 Dec 11 22:22 docker-compose.yml
$ cat docker-compose.yml
services:
  app:
    build:
      context: /home/maxkratz/gits/vfl
    cpu_count: 2
    cpu_percent: 75
    environment:
      TZ: Europe/Berlin
    image: registry/test/XYZ:latest
    mem_limit: 4G
    memswap_limit: 4G
    ports:
     - 8080:8080/tcp
    restart: unless-stopped
version: '2.4'
$ docker-compose build
Building app

Traceback (most recent call last):
  File ""compose/cli/main.py"", line 67, in main
  File ""compose/cli/main.py"", line 126, in perform_command
  File ""compose/cli/main.py"", line 302, in build
  File ""compose/project.py"", line 468, in build
  File ""compose/project.py"", line 450, in build_service
  File ""compose/service.py"", line 1147, in build
compose.service.BuildError: (<Service: app>, {'message': 'invalid reference format: repository name must be lowercase'})

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""bin/docker-compose"", line 3, in <module>
  File ""compose/cli/main.py"", line 78, in main
TypeError: can only concatenate str (not ""dict"") to str
[2655] Failed to execute script docker-compose
```
--
",maxkratz,"
--
> As i found out it depends on files in the same folder (or sub folders) with docker-compose.yml.

@Hackebein as I understand, the error also occurs inside an empty folder (except for `docker-compose.yml`) on my machine:

```
  maxkratz@thinkbrett  ~/test  tree                                    
.
 docker-compose.yml

0 directories, 1 file
```

The error mentioned above still occurs:

```
 maxkratz@thinkbrett  ~/test  docker-compose build
Building app
ERROR: Couldn't connect to Docker daemon at http+docker://localhost - is it running?

If it's at a non-standard location, specify the URL with the DOCKER_HOST environment variable.
```
--

--
There are no hidden files and as far as I can see, we are using the exact same `docker-compose.yml` file:

```
 maxkratz@thinkbrett  ~/test  ls -la
insgesamt 48
drwxrwxr-x 2 maxkratz maxkratz  4096 Dez 11 20:17 .
drwxr-xr-x 6 maxkratz maxkratz 28672 Dez 11 20:36 ..
-rw-rw-r-- 1 maxkratz maxkratz   295 Dez 11 20:17 docker-compose.yml
 maxkratz@thinkbrett  ~/test  docker-compose build
Building app
ERROR: Couldn't connect to Docker daemon at http+docker://localhost - is it running?

If it's at a non-standard location, specify the URL with the DOCKER_HOST environment variable.
  maxkratz@thinkbrett  ~/test  cat docker-compose.yml         
services:
  app:
    build:
      context: /home/maxkratz/gits/vfl
    cpu_count: 2
    cpu_percent: 75
    environment:
      TZ: Europe/Berlin
    image: registry/test/XYZ:latest
    mem_limit: 4G
    memswap_limit: 4G
    ports:
    - 8080:8080/tcp
    restart: unless-stopped
version: '2.4'
 maxkratz@thinkbrett  ~/test  
```
--
",,,,,,,,
7918,OPEN,docker-compose config breaks when not interpolating environment variables,kind/bug,2020-11-10 14:28:07 +0000 UTC,AndreSteenveld,Opened,,"## Description of the issue

More or less as the title says; when running `docker-compose config` allowing it to interpolate values from the environment it behaves as expected. When disabling interpolation by setting using the `--no-interpolation` flag it fails, but with a seemingly unrelated type issue.

I've created a little one-liner to reproduce this issue which I tried on my windows machine using a bash shell and on Debian 10.

## Context information (for bug reports)

**Output of `docker-compose version`**
```
# On windows:
docker-compose version 1.26.2, build eefe0d31
docker-py version: 4.2.2
CPython version: 3.7.4
OpenSSL version: OpenSSL 1.1.1c  28 May 2019

# On debian
docker-compose version 1.27.4, build 40524192
docker-py version: 4.3.1
CPython version: 3.7.7
OpenSSL version: OpenSSL 1.1.0l  10 Sep 2019
```

I've omitted `docker version` and `docker-compose config` as these are either not relevant or the entire reproduction case in a single line. 

## Steps to reproduce the issue

Using your shell of choice run the following:
```bash
$ docker-compose --file - config --no-interpolate <<<'
{
  ""version"": ""3.8"",
  ""services"": {
    ""hello-world"": {
      ""image"": ""hello-world:latest"",
      ""ports"": [{ ""published"": ""8080"", ""target"": ""8080"" }],
      ""labels"": { ""current-path"": ""$PWD"" }
    }
  }
}
'
```
### Observed result

```
The Compose file is invalid because:
services.hello-world.ports.target contains ""8080"", which is an invalid type, it should be an integer
```

### Expected result

```yaml
services:
  hello-world:
    image: hello-world:latest
    labels:
      current-path: $PWD
    ports:
    - published: 8080
      target: 8080
version: '3.8'

```

Even though the error is technically correct it seems weird and inconsistent, when running the command without the `--no-interpolate` flag it outputs the expected yaml. On my debian machine this looks like this:

```bash
docker@docker-host:/tmp$ docker-compose --file - config <<<'
> {
>   ""version"": ""3.8"",
>   ""services"": {
>     ""hello-world"": {
>       ""image"": ""hello-world:latest"",
>       ""ports"": [{ ""published"": ""8080"", ""target"": ""8080"" }],
>       ""labels"": { ""current-path"": ""$PWD"" }
>     }
>   }
> }
> '
services:
  hello-world:
    image: hello-world:latest
    labels:
      current-path: /tmp
    ports:
    - published: 8080
      target: 8080
version: '3.8'

docker@docker-host:/tmp$
```

Clearly when converting the `publised` and `target` fields to integers it also works.
",,,,,,,,,,,,,,
7916,OPEN,Extend service with `depends_on` should work,kind/feature,2020-11-09 12:56:31 +0000 UTC,superlevure,Opened,,"-->

**Is your feature request related to a problem? Please describe.**
Extending services with `depends_on` does not work and fails with:
```
services with 'depends_on' cannot be extended
``` 

**Describe the solution you'd like**
From the documentation: 

> Note: links, volumes_from, and depends_on are never shared between services using extends. These exceptions exist to avoid implicit dependenciesyou always define links and volumes_from locally. This ensures dependencies between services are clearly visible when reading the current file. Defining these locally also ensures changes to the referenced file dont result in breakage.

I interpret this as follows: Extending services with `depends_on` should work, but you have to redefine your dependencies locally. Which would totally make sense to me.

**Describe alternatives you've considered**
I don't want to use multiple `docker-compose.yml` files as there would be no notion of extension of a service (although it is exactly what I want) and it feels like a hacky way to do it. 

**Additional context**
Issue already mentioned:
- https://github.com/docker/compose/issues/3220#issuecomment-275639048
- https://github.com/docker/compose/issues/3220#issuecomment-706766485
",,,,,,,,,,,,,,
7915,OPEN,compose raises exception when it can't connect to docker socket,kind/bug,2020-11-17 02:31:46 +0000 UTC,BretFisher,In progress,,"3. When making a bug report, make sure you provide all required information. The easier it is for
   maintainers to reproduce, the faster it'll be fixed.
-->

## Description of the issue
Rather than the previous friendly error of:

```
ERROR: Couldn't connect to Docker daemon at http+docker://localhost - is it running?

If it's at a non-standard location, specify the URL with the DOCKER_HOST environment variable.
```

We now get an exception when unable to connect in compose 1.27:

```
Traceback (most recent call last):
  File ""site-packages/urllib3/connectionpool.py"", line 677, in urlopen
  File ""site-packages/urllib3/connectionpool.py"", line 392, in _make_request
  File ""http/client.py"", line 1252, in request
  File ""http/client.py"", line 1298, in _send_request
  File ""http/client.py"", line 1247, in endheaders
  File ""http/client.py"", line 1026, in _send_output
  File ""http/client.py"", line 966, in send
  File ""site-packages/docker/transport/unixconn.py"", line 43, in connect
ConnectionRefusedError: [Errno 61] Connection refused
........
```

## Context information (for bug reports)

**Output of `docker-compose version`**
```
docker-compose version 1.27.4, build 40524192
docker-py version: 4.3.1
CPython version: 3.7.7
OpenSSL version: OpenSSL 1.1.1g  21 Apr 2020
```

**Output of `docker version`**
```
Client: Docker Engine - Community
 Cloud integration: 0.1.22
 Version:           20.10.0-beta1
 API version:       1.41
 Go version:        go1.13.15
 Git commit:        ac365d7
 Built:             Tue Oct 13 18:13:53 2020
 OS/Arch:           darwin/amd64
 Context:           default
 Experimental:      true

Server: Docker Engine - Community
 Engine:
  Version:          20.10.0-beta1
  API version:      1.41 (minimum version 1.12)
  Go version:       go1.13.15
  Git commit:       9c15e82
  Built:            Tue Oct 13 18:17:18 2020
  OS/Arch:          linux/amd64
  Experimental:     true
 containerd:
  Version:          v1.4.1
  GitCommit:        c623d1b36f09f8ef6536a057bd658b3aa8632828
 runc:
  Version:          1.0.0-rc92
  GitCommit:        ff819c7e9184c13b7c2607fe6c30ae19403a7aff
 docker-init:
  Version:          0.19.0
  GitCommit:        de40ad0
```



",,,rfay,"
--
@BretFisher could you please specify the version of docker-compose that had your expected ""ERROR: Couldn't connect to Docker daemon at http+docker://localhost - is it running?""
--
",BretFisher,"
--
I have this on a different Ubuntu machine
```
docker-compose version
docker-compose version 1.25.0-rc2, build 661ac20e
docker-py version: 4.0.1
CPython version: 3.7.4
OpenSSL version: OpenSSL 1.1.0k  28 May 2019
```

--
",xiuyi0312,"
--
I use the same version exactly as yours, and when I connect to the wifi in my company, the same problem occurs, and then I connect to my iphone's personal hotspot, it started downloading.
--
",,,,,,
7914,OPEN,Composition as an operating hub,kind/feature,2020-11-06 16:14:07 +0000 UTC,Nayte91,Opened,,"Hi there,

Heres an idea that doesnt want to let me go, about what you can do for docker-compose (v4?). Im fairly new to docker (barely noobish), but I may think that a fresh point of view can benefit all sometime, if:

- It takes time to present his idea, 
- and experienced minds take time to think about the idea. 

Lets try it.

# Actually
The docker-compose fakes at containing the embedded containers. You have to type docker-compose exec app whatever-command-line to execute something; docker-compose only provides alias for containers, nothing more.

![Docker-compose actual use](http://robic.julien.free.fr/docker1.png)

*Host : your machine, your OS
Webserver: Nginx, Apache, Caddy, whatever
Programming language : cli access to PHP, nodejs, ruby, python, whatever
Package manager, versioning : The tools you for sure need when developing (or deploying sometimes). Can be also frameworks console helper, SQL soft, curl, whatever.*

To help with this, you build a container with your langage CLI, and your everyday tools : that is where you type your commands when you dev. The responsibility of calling existing images to build your image and having access to your tools is given to the dockerfile; but the responsibility of providing other services (like web-server Apache/Nginx/Caddy/whatever or DBMS SQL/Mongo/any) is given to docker-compose. In fact, you alter the language container to be your toolbox container and do stuff.

## Common footage of a php image

```
# ""php"" stage
FROM php:${PHP_VERSION}-fpm-alpine
 
# persistent / runtime deps
RUN apk add --no-cache \
        acl \
        fcgi \
        file \
        gettext \
        git \
        jq \
    ;
 
[...]
 
# Composer installation
COPY --from=composer:latest /usr/bin/composer /usr/bin/composer
 
[...]
```

We charge from the Alpines package manager (apk) and from dockers images, in order to give tools to user. The php image is transformed into a future toolbox container, where developers will connect to. For example in php (yeah you guessed right... I'm a java dev !), you will use composer as the package manager for dependencies and new bundles, symfony framework has a command line helper you use often, and so on.

# Suggested

It creates sort of an Operating System, where you literally do your operations with every containers of your composition : nothing more, nothing less, created in a minute, isolated, and every other avantages Docker brings. No faking with another container loading your bunch of tools, every tools (as long as you declare them in composition) are available in this central, global container.  

![Docker-compose suggested use](http://robic.julien.free.fr/docker2.png)

A dockerfile can expose a port, a volume, or now a CLI. This command is only meant to be used into a composition.
Declare it : 
`Commandincompositionbash:commandinthecontainer`
A docker-compose.yml file must not have 2 identical commandincompositionbash, and will be checked when reading the file.
Maybe the OS where the commands are linked should be declared in the docker-compose.yml, with an image of a vanilla distro.
When the composition runs, 2 choices : 
`docker-compose exec mycommand whateverparameter`  This will exec from the host cmd
`docker-compose bash`  will give access to the distro bash, where you can use every command also.

## Why

1. Docker-compose now makes a real composition! Cool enough, isnt it?
2. Stop altering one of the images, commonly the language one, where actually you use the container either for command lines and for web serving, so you need your bunch of tools into this container.
3. No need anymore to know the subtleties of every container launched by your compose, everything you need is available on the composition bash.
4. As a side effect of previous point, docker-compose become auto-documented, as every commands available can be found easily into the file when chasing the cli entrypoints.
5. You can now avoid using a single container for 2 purposes : example given of a php web application, you commonly use PHP container for CLI commands during dev or deployment, and for FPM link with your web server. This system allows the use of 2 distinct containers that arent dockerfile-ized. Because again, logic of composition is now more delayed to the compose.yml file, Dockerfile is more about creating proper images and running commands. (NOTE: OK ok, you can already call 2 separate PHP containers if you want currently... But its still up to the dockerfile to compose the php you will use in cli with your tools, so you deal with less standardized containers for just adding Standard tools.)

# up to you

Im not sure if everything here is interesting, or just the CLI entrypoint, or anything, but I feel the need to share what I have in my head, if that can help something anyhow, Im happy. Please think about it seriously, find if there is something good to keep, throw the rest, and if there was nothing to keep, sorry for the time! Thank you for reading me!
",,,,,,,,,,,,,,
7913,OPEN,Failed to run a self-build docker container using docker-compose?,kind/question,2020-11-06 00:32:06 +0000 UTC,hongyi-zhao,Opened,,"I sent it in the wrong place at the first time, so see [here](https://github.com/moby/moby/issues/41643) for more info.  ",,,,,,,,,,,,,,
7912,OPEN,docker-compose running inside a container on Fedora CoreOS cannot access filesystem or docker socket,kind/bug,2020-11-11 19:44:24 +0000 UTC,robertoetcheverryr,In progress,,"3. When making a bug report, make sure you provide all required information. The easier it is for
   maintainers to reproduce, the faster it'll be fixed.
-->

## Description of the issue
docker-compose running inside a container on Fedora CoreOS cannot access the host's filesystem nor the docker pipe. I noticed that docker-compose up was failing with a ""cannot find file docker-compose.yml file"" error but the command was being invoked in the right directory.

**Output of `docker-compose version`**
```
docker-compose version 1.27.4, build 4052419
docker-py version: 4.3.1
CPython version: 3.7.7
OpenSSL version: OpenSSL 1.1.1g  21 Apr 2020
```

**Output of `docker version` inside the docker-compose container**
```
Client: Docker Engine - Community
 Version:           19.03.8
 API version:       1.40
 Go version:        go1.12.17
 Git commit:        afacb8b7f0
 Built:             Wed Mar 11 01:22:56 2020
 OS/Arch:           linux/amd64
 Experimental:      false
Got permission denied while trying to connect to the Docker daemon socket at unix:///var/run/docker.sock: Get http://%2Fvar%2Frun%2Fdocker.sock/v1.40/version: dial unix /var/run/docker.sock: connect: permission denied

```
**Output of `docker version` from CoreOS**
```
Client:
 Version:           19.03.11
 API version:       1.40
 Go version:        go1.14.3
 Git commit:        42e35e6
 Built:             Sun Jun  7 21:16:58 2020
 OS/Arch:           linux/amd64
 Experimental:      false

Server:
 Engine:
  Version:          19.03.11
  API version:      1.40 (minimum version 1.12)
  Go version:       go1.14.3
  Git commit:       42e35e6
  Built:            Sun Jun  7 00:00:00 2020
  OS/Arch:          linux/amd64
  Experimental:     false
 containerd:
  Version:          1.3.3
  GitCommit:
 runc:
  Version:          1.0.0-rc10+dev
  GitCommit:        fbdbaf85ecbc0e077f336c03062710435607dbf1
 docker-init:
  Version:          0.18.0
  GitCommit:
```

**Output of `docker-compose config`**
(Make sure to add the relevant `-f` and other flags)
```
fails due to not being able to read the host's filesystem.
```


## Steps to reproduce the issue

1. Install a vanilla Fedora CoreOS installation
2. Install docker-compose as a container
3. Place a docker-compose.yml file
4. sudo docker-compose up

### Observed result
compose fails to find the configuration file
### Expected result
compose should find the configuration file and build/start the services/containers
### Stacktrace / full error message

```
[core@coreos-0 app]$ sudo docker-compose up
ERROR:
        Can't find a suitable configuration file in this directory or any
        parent. Are you in the right directory?

        Supported filenames: docker-compose.yml, docker-compose.yaml

[core@coreos-0 app]$ ls
docker-compose.yml
```

## Additional information

Vanilla Fedora CoreOS 32.20201018.2.0 installation
docker-compose installed as a container using:
sudo curl -L --fail https://github.com/docker/compose/releases/download/1.27.4/run.sh -o /usr/local/bin/docker-compose
sudo chmod +x /usr/local/bin/docker-compose

I found out that the filesystem issue can be solved by modifying the docker-compose launcher script to add the :Z parameter to the volume mounts but I found no equivalent for the socket.",,,robertoetcheverryr,"
--
I suppose the socket issue is related to SELinux. Adding --privileged to the docker run invocation in the script solved the socket issue.
--
",,,,,,,,,,
7911,OPEN,Networking During Build Time?,kind/question,2020-11-06 16:21:26 +0000 UTC,dm17,In progress,,"Docker's build has ""--network"" which seems to allow networking during build time:
https://docs.docker.com/engine/reference/commandline/build/

Is there a way to get networking (in my case between already running containers) during another container's build time?
Thanks! ",,,dm17,"
--
Nowhere to be found in docker-compose documentation, it seems :(
--

--
@delvalle Considering your ""dockerize NextJS"" articles, maybe you have some idea how to dockerize after using this feature, which requires networking between services during build time: 
https://nextjs.org/docs/advanced-features/automatic-static-optimization
--

--
> @dm17 it's in the compose-file documentation; https://docs.docker.com/compose/compose-file/#network
> 
> <img alt=""Screenshot 2020-11-06 at 16 53 11"" width=""562"" src=""https://user-images.githubusercontent.com/1804568/98386526-94bfc380-2050-11eb-87d7-5e6e26ab0700.png"">

So that network is available *at* build time? @thaJeztah - I've not been able to get it to work. Can I give it access to the network from the primary docker-compose network section that way?
```
networks:
  default:
   external:
      name: traefik
```
--

--
Seems the answer to my question is yes :) That worked! Thanks :) 
--

--
@thaJeztah I guess one sort of related question: is there a way to use depends_on such that some services are running @ another service's build time?
If not, then I suppose the best way is:
```
docker-compose build some_services
docker-compose up -d some_services
docker-compose build the_rest
```
Thoughts?
--
",thaJeztah,"
--
@dm17 it's in the compose-file documentation; https://docs.docker.com/compose/compose-file/#network

<img width=""562"" alt=""Screenshot 2020-11-06 at 16 53 11"" src=""https://user-images.githubusercontent.com/1804568/98386526-94bfc380-2050-11eb-87d7-5e6e26ab0700.png"">

--
",,,,,,,,
7910,OPEN,Fails to build at network location,kind/bug,2020-11-05 14:06:26 +0000 UTC,yukihiko-shinoda,Opened,,"## Description of the issue

Docker compose fails to build at network location.
For WSL, we can avoid this issue by running Docker Compose from WSL Shell.
However, it's inconvenient in case when we execute batch container on network storage from PC.

## Context information (for bug reports)

**Output of `docker-compose version`**

```console
$ docker-compose --version
docker-compose version 1.27.4, build 40524192
```

**Output of `docker version`**

```console
$ docker --version
Docker version 19.03.13, build 4484c46d9d
```

**Output of `docker-compose config`**
(Make sure to add the relevant `-f` and other flags)

```
$ docker-compose config
services:
  test-build:
    build:
      context: \\wsl$$\Ubuntu\root\workspace\test-docker-build
version: '3.8'
```


## Steps to reproduce the issue

1.
Put following files into somewhere on the network place.

docker-compose.yml:

```yaml
version: ""3.8""
services:
  test-build:
    build: .
```

Dockerfile:

```Dockerfile
FROM debian
```

2.
Run command:

```console
docker-compose build
```

### Observed result

Failed to execute docker-compose.

### Expected result

Will build successfully.

### Stacktrace / full error message

```console
$ docker-compose build
Building test-build
Traceback (most recent call last):
  File ""docker-compose"", line 3, in <module>
  File ""compose\cli\main.py"", line 67, in main
  File ""compose\cli\main.py"", line 126, in perform_command
  File ""compose\cli\main.py"", line 302, in build
  File ""compose\project.py"", line 468, in build
  File ""compose\project.py"", line 450, in build_service
  File ""compose\service.py"", line 1125, in build
  File ""site-packages\docker\api\build.py"", line 148, in build
TypeError: You must specify a directory to build in path
[968] Failed to execute script docker-compose
```

## Additional information

OS version / distribution, `docker-compose` install method, etc.

Windows 10 Pro 1909
Installed docker-compose as part of Docker Desktop into windows by Chocolatey.

Following code works well:

```yaml
version: ""3.8""
services:
  test-build:
    build: ""\\\\?\\UNC\\wsl$$\\Ubuntu\\root\\workspace\\test-docker-build""
```

I guess following method.
[compose/service.py at 675c9674e1701cc22763bab2bcd429ac5b82e102  docker/compose](https://github.com/docker/compose/blob/675c9674e1701cc22763bab2bcd429ac5b82e102/compose/service.py#L1766)

In case when path is network place,
it have to not add `WINDOWS_LONGPATH_PREFIX` but replace `\\` prefix with `\\\\?\\UNC\\`

cf. [Answer: What does \\?\ mean when prepended to a file path](https://stackoverflow.com/a/21194605/12721873?stw=2)",,,,,,,,,,,,,,
7909,OPEN,Docker-compose crash if service mount device with colon in path,kind/bug,2020-11-04 22:00:41 +0000 UTC,flucciarini,Opened,,"Hi everyone,
I need to mount in service a host's path with colon (real case below) but docker-compose when start fail 
How can escape or encode comma?
...
devices:
     - ""/sys/bus/iio/devices/iio::device0:/sys/bus/iio/devices/iio::device0:rw""
....

$ docker-compose up -d
...
Creating edgex-device-gpio ... error

ERROR: for edgex-device-gpio  Cannot start service device-gpio: error gathering device information while adding custom device ""/sys/bus/iio/devices/iio"": no such file or directory

ERROR: for device-gpio  Cannot start service device-gpio: error gathering device information while adding custom device ""/sys/bus/iio/devices/iio"": no such file or directory
ERROR: Encountered errors while bringing up the project.

$ docker-compose -version
docker-compose version 1.27.2, build 18f557f9

SO: Ubuntu 18.04
",,,,,,,,,,,,,,
7908,OPEN,Cannot override the specified file on volumes,kind/question,2020-11-24 02:48:07 +0000 UTC,midoridge,In progress,,"I updated docker to 19.03.13 a few days ago.
After that, cannot override the specified file on volumes.

Summary of docker-compose.yml is the following
```
version: '3'

services:
  app:
    volumes:
      - ./app/html:/var/www/html
      - ./app/env.dev:/var/www/html/.env
```

./app/html has .env file. 
Before updating docker, it was override .env file by ./app/env.dev. But now cannot override it.
Docker or docker-compose are change specification or have some bugs?

My environment is the following.

docker version
```
Client: Docker Engine - Community
 Cloud integration: 1.0.1
 Version:           19.03.13
 API version:       1.40
 Go version:        go1.13.15
 Git commit:        4484c46d9d
 Built:             Wed Sep 16 16:58:31 2020
 OS/Arch:           darwin/amd64
 Experimental:      false

Server: Docker Engine - Community
 Engine:
  Version:          19.03.13
  API version:      1.40 (minimum version 1.12)
  Go version:       go1.13.15
  Git commit:       4484c46d9d
  Built:            Wed Sep 16 17:07:04 2020
  OS/Arch:          linux/amd64
  Experimental:     true
 containerd:
  Version:          v1.3.7
  GitCommit:        8fba4e9a7d01810a393d5d25a3621dc101981175
 runc:
  Version:          1.0.0-rc10
  GitCommit:        dc9208a3303feef5b3839f4323d9beb36df0a9dd
 docker-init:
  Version:          0.18.0
  GitCommit:        fec3683
```

docker-compose version
```
docker-compose version 1.27.4, build 40524192
docker-py version: 4.3.1
CPython version: 3.7.7
OpenSSL version: OpenSSL 1.1.1g  21 Apr 2020
```",,,midoridge,"
--
Additional information.

https://docs.docker.com/docker-for-mac/release-notes/
Docker Desktop Community 2.5.0.0 => Don't work (cannot override file on directory)
Docker Desktop Community 2.4.0.0 => work (can override file on directory)
--

--
I posted the same issue to docker-for-mac https://github.com/docker/for-mac/issues/5053
Because Both Docker Desktop 2.4.0.0 and 2.5.0.0 has the same docker-compose version 1.27.4, build 40524192 but 2.5.0.0 does not work. I think Docker Desktop (docker-for-mac) has some bugs about it.
--
",andryyy,"
--
Can confirm that this stopped working for me, too.
--
",,,,,,,,
7905,OPEN,docker-compose build and docker build lead to different IDs,kind/bug,2020-11-25 09:11:38 +0000 UTC,knyttl,In progress,,"These two issues has been closed for duplicity and then for staleness respectively. 

- https://github.com/docker/compose/issues/5873
- https://github.com/docker/compose/issues/883

We don't have a right to reopen it while the problem persists, so creating a new issue",,,JeremyLoy,"
--
Copying my comment for emphasis 

> I can build the same image with THREE different hashes.

> docker build .
docker-compose up --build
COMPOSE_DOCKER_CLI_BUILD=true docker-compose up --build
This results in 3 fully functional docker images, all with different hashes.

> I think it has something to do when using a COPY command on a directory.

> I get cache hits for all of my Dockerfile steps until the first COPY command that is a directory (COPY commands that are individual files work and cache hit correctly)
--
",knyttl,"
--
For me it does not work even without COPY. When I have Dockerfile with two commands, where the second command fails, then the first command will always be executed again. This doesn't happen with common docker.
--
",x,"
--
@knyttl Show the `Dockerfile`, please. And desirably, steps to reproduce.

I'm not sure about you, but for me different IDs presumably amount to `docker-compose` ignoring valid cache. If that's the case for you I'd update the title.

And the IDs [are not][5] content hashes:

> Also worth noting that since these IDs are not content hashes, they will never generate the same ID unless its using cache even when the content is exactly the same.

[5]: https://github.com/docker/compose/issues/883#issuecomment-73323371

My understanding is the changes are not caused by the files themselves, but by differences in the archives sent to `docker` (by `COPY`). `docker-compose` and `docker` use different `tar` implementations.

From what I can see the [resolution][2] ([issue][1]) was blocked by [changes in `docker`][3]. @shin-, the PR is merged, still a blocker?

Also, next year a [python package][4], that uses the docker client directly (whatever that means), might become publicly available. Just spreading rumors :)

[1]: https://github.com/docker/docker-py/issues/998
[2]: https://github.com/docker/docker-py/pull/1582
[3]: https://github.com/moby/moby/pull/33935
[4]: https://github.com/docker/docker-py/issues/2230#issuecomment-723593257
--

--
Unfortunately it doesn't help in my case:

`docker-compose-production-2.yml`:

```yaml
version: ""3""

services:
  nginx:
    build:
      context: .
      dockerfile: docker2/Dockerfile2
      target: nginx

  php:
    build:
      context: .
      dockerfile: docker2/Dockerfile2
      target: php
```

`docker2/Dockerfile2`:

```dockerfile
# 30

FROM node AS assets
WORKDIR /app
COPY package.json package-lock.json ./
COPY docker2 docker2
RUN npm i

FROM node as php

FROM node as nginx
```

```
$ docker image prune -f; COMPOSE_DOCKER_CLI_BUILD=1 docker-compose -f docker-compose-production2.yml build; echo -e '\a'
...
WARNING: Native build is an experimental feature and could change at any time
Building nginx
Sending build context to Docker daemon  12.93MB

Step 1/7 : FROM node AS assets
 ---> 969d445a1755
Step 2/7 : WORKDIR /app
 ---> Using cache
 ---> 8ca5d55207e2
Step 3/7 : COPY package.json package-lock.json ./
 ---> e34bb291de3a
Step 4/7 : COPY docker2 docker2
 ---> e5e2a5673096
Step 5/7 : RUN npm i
 ---> Running in ba90f021defe

added 1088 packages, and audited 1088 packages in 12s

14 vulnerabilities (5 low, 9 high)

To address all issues, run:
  npm audit fix

Run `npm audit` for details.
npm notice
npm notice New patch version of npm available! 7.0.8 -> 7.0.14
npm notice Changelog: <https://github.com/npm/cli/releases/tag/v7.0.14>
npm notice Run `npm install -g npm@7.0.14` to update!
npm notice
Removing intermediate container ba90f021defe
 ---> 2551b7161ee8
Step 6/7 : FROM node as php
 ---> 969d445a1755
Step 7/7 : FROM node as nginx
 ---> 969d445a1755
Successfully built 969d445a1755
Successfully tagged mangorv-backend_nginx:latest
Building php
Sending build context to Docker daemon  12.93MB

Step 1/6 : FROM node AS assets
 ---> 969d445a1755
Step 2/6 : WORKDIR /app
 ---> Using cache
 ---> 8ca5d55207e2
Step 3/6 : COPY package.json package-lock.json ./
 ---> Using cache
 ---> e34bb291de3a
Step 4/6 : COPY docker2 docker2
 ---> c66e5ed778a7
Step 5/6 : RUN npm i
 ---> Running in 0fd47a63b807

added 1088 packages, and audited 1088 packages in 12s

14 vulnerabilities (5 low, 9 high)

To address all issues, run:
  npm audit fix

Run `npm audit` for details.
npm notice
npm notice New patch version of npm available! 7.0.8 -> 7.0.14
npm notice Changelog: <https://github.com/npm/cli/releases/tag/v7.0.14>
npm notice Run `npm install -g npm@7.0.14` to update!
npm notice
Removing intermediate container 0fd47a63b807
 ---> 1aaa33dccaa3
Step 6/6 : FROM node as php
 ---> 969d445a1755
Successfully built 969d445a1755
Successfully tagged mangorv-backend_php:latest
```

`npm i` is executed twice.

The mistery is that `vim` has to keep `docker2/Dockerfile2` open for it to reproduce.

--

--
I tried to dockerignore it, but apparently I mistyped. Indeed by default vim creates a swap files alongside every open file (`a.txt` -> `.a.txt.swp`). And for some reason on save it changes the swap file twice (mtime, ctime). Once immediately, and once after 8 seconds. (Actually the same happens if you change a file but don't save.) And I was able to reproduce my issue locally.
--
",thaJeztah,"
--
> Also, next year a python package, that uses the docker client directly (whatever that means), might become publicly available. Just spreading rumors :)

compose already supports this; set the `COMPOSE_DOCKER_CLI_BUILD=1` environment variable to use the native cli for building (and `DOCKER_BUILDKIT=1` to use buildkit); can also bet set in the  .env file https://github.com/docker/docker.github.io/blob/master/.env
--

--
> The mistery is that vim has to keep docker2/Dockerfile2 open for it to reproduce.

Could it be it's writing a temp file to the `docker2` directory? (https://stackoverflow.com/questions/607435/why-does-vim-save-files-with-a-extension)

you can try adding the dockerfile and such temp/swap files to .dockerignore

Does it make a difference if you enable buildkit?



--
",,,,
7904,OPEN,"Cannot start service redis: OCI runtime create failed: container_linux.go:349: starting container process caused ""process_linux.go:449: container init caused \""sethostname: invalid argument\",kind/question,2020-12-17 17:50:57 +0000 UTC,hgySandy,Opened,,"Cannot start service redis: OCI runtime create failed: container_linux.go:349: starting container process caused ""process_linux.go:449: container init caused \""sethostname: invalid argument\",,,shentonfreude,"
--
@hgySandy  I just encountered this. It turns out my hostname was 65 characters. Shortening to 64 or less fixed it.

It would be helpful if the error msg were improved to say this. I don't see any mention of size limits in the docs.
--
",,,,,,,,,,
7900,OPEN,Windows Client; Linux Server; relative volume path regression,kind/bug,2021-01-15 18:32:15 +0000 UTC,djherbis,Opened,,"Copied from my comment: https://github.com/docker/compose/pull/7762#issuecomment-713286741

I execute docker-compose on Windows, with a remote docker host on Linux. The 'relative path' expansion/abs path transformation from #7762 ends up converting Linux absolute paths in my config (like /path/from/root), into Windows-style paths (like C:/path/from/root), which ends up as an invalid path on the remote filesystem (and caused my volumes to report that the 'device' changed even though I haven't changed my docker-compose file in years).

Example error:
```
ERROR: Configuration for volume config specifies ""device"" driver_opt C:\volume1\MEDIA-SHARE\config, but a volume with the same name uses a different ""device"" driver_opt (/volume1/MEDIA-SHARE/config). If you wish to use the new configuration, please remove the existing volume ""config"" first:
$ docker volume rm config
```

## Context information (for bug reports)

**Output of `docker-compose version`**
```
docker-compose version 1.27.4, build 40524192
docker-py version: 4.3.1
CPython version: 3.7.4
OpenSSL version: OpenSSL 1.1.1c  28 May 2019
```

**Output of `docker version`**
```
Client:
 Version:           19.03.12
 API version:       1.39
 Go version:        go1.13.12
 Git commit:        0ed913b8-
 Built:             07/28/2020 16:36:03
 OS/Arch:           windows/amd64
 Experimental:      false

Server:
 Engine:
  Version:          18.09.8
  API version:      1.39 (minimum version 1.12)
  Go version:       go1.11
  Git commit:       3a371f3
  Built:            Fri Mar 13 06:44:35 2020
  OS/Arch:          linux/amd64
  Experimental:     false
```

**Output of `docker-compose config`**
(Make sure to add the relevant `-f` and other flags)
```
version: '3.8'
volumes:
  config:
    driver: local
    driver_opts:
      device: C:\volume1\MEDIA-SHARE\config
      o: bind
```

**Actual config file**
```
version: '3.8'
volumes:
  config:
    driver: local
    driver_opts:
      device: /volume1/MEDIA-SHARE/config
      o: bind
```


## Steps to reproduce the issue

1. Setup a docker host on linux.
2. Setup docker-compose on windows, point DOCKER_HOST to the linux docker server.
3. Add a docker-compose.yaml with a volume with a linux-style path.
4. Try to run docker-compose up for that config and observe the incorrect paths (starting from C:\ instead of the linux root).

### Observed result

I get errors about the volume path being different, even though it hasn't changed. Thankfully my volume already exists, or else I expect docker-compose just wouldn't be able to create the volume.

### Expected result

This should work as it did before the change, and the volume path should be relative to the server filesystem, not the docker-compose client filesystem.

### Stacktrace / full error message

```
ERROR: Configuration for volume config specifies ""device"" driver_opt C:\volume1\MEDIA-SHARE\config, but a volume with the same name uses a different ""device"" driver_opt (/volume1/MEDIA-SHARE/config). If you wish to use the new configuration, please remove the existing volume ""config"" first:
$ docker volume rm config
```

## Additional information

Windows 10 docker-compose client
Linux docker host.",,,thaJeztah,"
--
I guess it needs something similar to https://github.com/docker/cli/pull/1990 (but then in Python of course )

@aiordache PTAL
--
",sti0,"
--
Faced the same issue with secret files defined in a compose file. On running `docker-compose up` with DOCKER_HOST=remote tcp the linux file paths are converted to absolute Windows paths with a leading C:\.
--
",OJFord,"
--
This is slightly related to #7838 (_relative_ paths expanded client-side, into an absolute paths that don't exist on the remote) in that the underlying issue in both cases is client-side interpretation of volume paths when a remote daemon is in use.
--
",,,,,,
7899,OPEN,docker-compose is unstable using Docker Desktop and WSL2,kind/bug,2021-02-15 12:47:32 +0000 UTC,FVolral,Opened,,"## Description of the issue
In some conditions, some command like `docker-compose up` or `docker-compose ps` leads to the following error : 

```
Traceback (most recent call last):
  File ""bin/docker-compose"", line 3, in <module>
  File ""compose/cli/main.py"", line 67, in main
  File ""compose/cli/main.py"", line 123, in perform_command
  File ""compose/cli/command.py"", line 69, in project_from_options
  File ""compose/cli/command.py"", line 125, in get_project
  File ""compose/cli/command.py"", line 184, in get_project_name
  File ""posixpath.py"", line 383, in abspath
FileNotFoundError: [Errno 2] No such file or directory
[3512] Failed to execute script docker-compose
```

Docker Desktop restart but it doesn't solve the problem. 


## Context information (for bug reports)

**docker-compose.yml**
```
version: '3.8'

services:
    mongo:
        image: mongo
        networks:
            mongo_net:
        volumes:
            - ""./mongodata:/data/db""
        ports:
            - 27017:27017
        restart: always
        environment:
            MONGO_INITDB_ROOT_USERNAME: root
            MONGO_INITDB_ROOT_PASSWORD: 1234567
        command: mongod --bind_ip 0.0.0.0
    app:
        build:
            context: ./app/
            dockerfile: app.dockerfile
        volumes:
            - ""./app:/app""
        networks:
            - mongo_net
        entrypoint: python
        tty: true
        stdin_open: true
        depends_on:
            - mongo
networks:
    mongo_net:
volumes:
    mongodata:
```

**app/app.dockerfile**
```
FROM python:3

WORKDIR /app

COPY requirements.txt /requirements.txt
RUN python -m pip install --upgrade pip
RUN pip install --no-cache-dir -r /requirements.txt

WORKDIR /app
```

**WSL2 / Win10 version**

```
> ver
Microsoft Windows [version 10.0.19041.572]
```

```
>wsl -l -v
  NAME                   STATE           VERSION
* Ubuntu                 Running         2
  docker-desktop         Running         2
  docker-desktop-data    Running         2
```

**Output of `docker-compose version`**
```
docker-compose version 1.27.4, build 40524192
docker-py version: 4.3.1
CPython version: 3.7.7
OpenSSL version: OpenSSL 1.1.0l  10 Sep 2019
```

**Output of `docker version`**
```
Client:
 Version:           19.03.8
 API version:       1.40
 Go version:        go1.13.8
 Git commit:        afacb8b7f0
 Built:             Wed Oct 14 19:43:43 2020
 OS/Arch:           linux/amd64
 Experimental:      true

Server: Docker Engine - Community
 Engine:
  Version:          20.10.0-beta1
  API version:      1.41 (minimum version 1.12)
  Go version:       go1.13.15
  Git commit:       9c15e82
  Built:            Tue Oct 13 18:17:18 2020
  OS/Arch:          linux/amd64
  Experimental:     true
 containerd:
  Version:          v1.4.1
  GitCommit:        c623d1b36f09f8ef6536a057bd658b3aa8632828
 runc:
  Version:          1.0.0-rc92
  GitCommit:        ff819c7e9184c13b7c2607fe6c30ae19403a7aff
 docker-init:
  Version:          0.19.0
  GitCommit:        de40ad0
```

**Output of `docker-compose config`**
(Make sure to add the relevant `-f` and other flags)
```
Traceback (most recent call last):
  File ""bin/docker-compose"", line 3, in <module>
  File ""compose/cli/main.py"", line 67, in main
  File ""compose/cli/main.py"", line 120, in perform_command
  File ""compose/cli/main.py"", line 324, in config
  File ""compose/cli/command.py"", line 99, in get_config_from_options
  File ""compose/config/config.py"", line 406, in load
  File ""compose/config/config.py"", line 520, in load_services
  File ""compose/config/config.py"", line 501, in build_services
  File ""compose/config/config.py"", line 501, in <listcomp>
  File ""compose/config/config.py"", line 480, in build_service
  File ""compose/config/config.py"", line 289, in with_abs_paths
  File ""posixpath.py"", line 383, in abspath
FileNotFoundError: [Errno 2] No such file or directory
[3611] Failed to execute script docker-compose
```


## Steps to reproduce the issue
I tried many solutions to solve this and now I'm a bit lost. Docker has worked while few months like a charm on an another project. I don't understand what causes that instability. It happens after a `docker-compose up`. Yesterday, I had this error and tried to reinstall Docker 2.4.0.0 Stable but I had various problem with it (Installer unable to finish its installation, Docker Desktop unstable, Docker service trying to start forever, Stuck when restoring factory default) That was a mess so I removed the previous version of docker and installed the 2.4.2.0 Edge version of Docker Desktop which can be found [here](https://docs.docker.com/docker-for-windows/edge-release-notes/#docker-desktop-community-2420). 

Docker become more stable after that and I was able to Clean / Purge data then Reset to factory defaults (looks stupid to do that since the installation was fresh but he).

I thought my ordeal was over but this problem come back now. 
",,,carlsonad,"
--
I'm having a very similar behavior.  I'm getting the exact same error message as reported as the OP.  But I am able to work around this by opening a new command window.  Once I've got a new command window open I seem to be able to use docker-compose for a few commands then it will start throwing the reported error.  Once I get that error I'll have to open a new command window to continue working.  It's not consistent on how many commands I can execute.  Sometimes it's 1 or 2.   Other times it's 7 or 8 commands.  But it always seems to eventually corrupt.

I recently switched to WSL and seems to happen regardless if I'm running on the windows command prompt or on a Linux command prompt.  I do not recall this happening before I switched to WSL.  

WSL2 / Win10 version
```
>ver
Microsoft Windows [Version 10.0.18363.1139]
```

```
>wsl -l -v
  NAME                   STATE           VERSION
* Ubuntu-20.04           Running         2
  docker-desktop-data    Running         2
  docker-desktop         Running         2
```

Output of `docker-compose version`
```
docker-compose version 1.27.4, build 40524192
docker-py version: 4.3.1
CPython version: 3.7.4
OpenSSL version: OpenSSL 1.1.1c  28 May 2019
```

Output of `docker version`

```
Client: Docker Engine - Community
 Cloud integration: 1.0.2
 Version:           19.03.13
 API version:       1.40
 Go version:        go1.13.15
 Git commit:        4484c46d9d
 Built:             Wed Sep 16 17:00:27 2020
 OS/Arch:           windows/amd64
 Experimental:      false

Server: Docker Engine - Community
 Engine:
  Version:          19.03.13
  API version:      1.40 (minimum version 1.12)
  Go version:       go1.13.15
  Git commit:       4484c46d9d
  Built:            Wed Sep 16 17:07:04 2020
  OS/Arch:          linux/amd64
  Experimental:     false
 containerd:
  Version:          v1.3.7
  GitCommit:        8fba4e9a7d01810a393d5d25a3621dc101981175
 runc:
  Version:          1.0.0-rc10
  GitCommit:        dc9208a3303feef5b3839f4323d9beb36df0a9dd
 docker-init:
  Version:          0.18.0
  GitCommit:        fec3683
```
--
",chadbrewbaker,"
--
Just happened to me after I updated the Windows side docker to Docker version 19.03.13, build 4484c46d9d, then called a docker-compose down from Ubuntu 20.04 Docker version 19.03.8, build afacb8b7f0

I'm guessing the solution is to upgrade the WSL2 linux land docker client?
--
",bcheronn,"
--
## Description of the issue
Got hit by the same and the workaround above helped

> But I am able to work around this by opening a new command window. Once I've got a new command window open I seem to be able to use docker-compose for a few commands then it will start throwing the reported error. Once I get that error I'll have to open a new command window to continue working.

## Context information
**Output of `docker-compose version`**
```
docker-compose version 1.27.4, build 40524192
docker-py version: 4.3.1
CPython version: 3.7.7
OpenSSL version: OpenSSL 1.1.0l  10 Sep 2019
```

**Output of `docker version`**
```
Client: Docker Engine - Community
 Cloud integration: 1.0.2
 Version:           19.03.13
 API version:       1.40
 Go version:        go1.13.15
 Git commit:        4484c46d9d
 Built:             Wed Sep 16 17:02:36 2020
 OS/Arch:           linux/amd64
 Experimental:      false

Server: Docker Engine - Community
 Engine:
  Version:          19.03.13
  API version:      1.40 (minimum version 1.12)
  Go version:       go1.13.15
  Git commit:       4484c46d9d
  Built:            Wed Sep 16 17:07:04 2020
  OS/Arch:          linux/amd64
  Experimental:     false
 containerd:
  Version:          v1.3.7
  GitCommit:        8fba4e9a7d01810a393d5d25a3621dc101981175
 runc:
  Version:          1.0.0-rc10
  GitCommit:        dc9208a3303feef5b3839f4323d9beb36df0a9dd
 docker-init:
  Version:          0.18.0
  GitCommit:        fec3683
```

**Output of `docker-compose config`**
```
services:
  composer:
    image: composer
    volumes:
    - /mnt/c/wamp64/www/parisportif1/code:/app:rw
    - /mnt/c/wamp64/www/parisportif1/.git:/.git:rw
  db:
    environment:
      MYSQL_ALLOW_EMPTY_PASSWORD: ""true""
    image: mysql
    restart: on-failure
    volumes:
    - db-volume:/var/lib/mysql:rw
  mailhog:
    image: mailhog/mailhog
    labels:
      traefik.http.services.mailhog.loadbalancer.server.port: '8025'
    restart: on-failure
    volumes:
    - mail-volume:/maildir:rw
  php:
    build:
      cache_from:
      - php:7.4-apache
      context: /mnt/c/wamp64/www/parisportif1/docker/php74-xdebug
    depends_on:
      db:
        condition: service_started
      mailhog:
        condition: service_started
    restart: on-failure
    volumes:
    - /mnt/c/wamp64/www/parisportif1/code:/app:rw
  phpmyadmin:
    depends_on:
      db:
        condition: service_started
    environment:
      PMA_ABSOLUTE_URI: http://phpmyadmin-parisportif1.docker.localhost/
    image: phpmyadmin
    restart: on-failure
  traefik:
    depends_on:
      mailhog:
        condition: service_started
      php:
        condition: service_started
      phpmyadmin:
        condition: service_started
    image: traefik
    ports:
    - published: 80
      target: 80
    - published: 8080
      target: 8080
    restart: on-failure
    volumes:
    - /mnt/c/wamp64/www/parisportif1/docker/traefik/conf/traefik.yml:/etc/traefik/traefik.yml:rw
    - /var/run/docker.sock:/var/run/docker.sock:ro
version: '3'
volumes:
  db-volume: {}
  mail-volume: {}
```

## Steps to reproduce the issue
1. Execute any docker-compose command
2. Output of `docker-compose run composer update` as example below, but I got the same error stack with all docker-composer commands

### Observed result
It fails with the stack trace below. Note that I do not get a stack trace if I run a `docker-compose` without command. I get the expected usage message.

### Expected result
Execute the command passed to docker-compose

### Stacktrace / full error message
```
Traceback (most recent call last):
  File ""bin/docker-compose"", line 3, in <module>
  File ""compose/cli/main.py"", line 67, in main
  File ""compose/cli/main.py"", line 123, in perform_command
  File ""compose/cli/command.py"", line 69, in project_from_options
  File ""compose/cli/command.py"", line 125, in get_project
  File ""compose/cli/command.py"", line 184, in get_project_name
  File ""posixpath.py"", line 383, in abspath
FileNotFoundError: [Errno 2] No such file or directory
[2527] Failed to execute script docker-compose
```

## Additional information
**Output of `ver`**
```
Microsoft Windows [version 10.0.19041.630]
```

**Output of `wsl -l -v`**
```
  NAME                   STATE           VERSION
* Debian                 Running         2
  docker-desktop         Running         2
  docker-desktop-data    Running         2
```

`docker-compose` installed via `Docker Desktop Installer.exe`

--
",F21,"
--
Seeing the problem with the latest version of Windows 10 2004 with WSL 2 and Docker Desktop for Windows 2.5.0.1 stable.

I think the problem is because the version of compose that ships with Docker for Windows is located in the Windows filesystem and due to some instability in WSL2 volume mounts, it doesn't work correctly.

A workaround I am using is to just install docker-compose directly into WSL2. If you execute `which docker-compose` you should see that the copy in WSL2 should shadow/override the one from Docker for WIndows and it should be much more stable.

--
",pasisavolainen,"
--
Seeing this as well.

Closing docker, `wsl --shutdown` and restarting docker has cleared this up at least once now.
--
",jlu1202,"
--
I ran into this problem just now and was able to do a couple of things to have it resolved.
1. Ensure the docker cli version in WSL 2 matches up the one on your Windows 10 (I'm on Version 10.0.19042.685).
2. Ensure the current working directory is NOT a mount point from Windows, e.g. /mnt/c/..., this is especially important when you are running a script or an utility like 'make'.
--
"
7898,OPEN,The differents among the requirements the requirements*.txt.,kind/question,2020-10-29 01:19:42 +0000 UTC,hongyi-zhao,Opened,," Hi,

There are four requirements*.txt files in this repo. Only based on the files shown as following, but I still can't figure out their respective usage occasions.

```
$ ls -1 requirements*.txt
requirements-build.txt
requirements-dev.txt
requirements-indirect.txt
requirements.txt
```
Any hints will be highly appreciated.

Regards,
HY  ",,,,,,,,,,,,,,
7896,OPEN,Errors running up,kind/bug,2021-02-02 19:56:27 +0000 UTC,Glioburd,In progress,,"Hello, when I run `docker compose up` I get the following errors :
```
$ docker-compose up -d
Traceback (most recent call last):
  File ""/usr/lib/python3.8/site-packages/urllib3/connectionpool.py"", line 670, in urlopen
    httplib_response = self._make_request(
  File ""/usr/lib/python3.8/site-packages/urllib3/connectionpool.py"", line 392, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File ""/usr/lib/python3.8/http/client.py"", line 1255, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File ""/usr/lib/python3.8/http/client.py"", line 1301, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File ""/usr/lib/python3.8/http/client.py"", line 1250, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File ""/usr/lib/python3.8/http/client.py"", line 1010, in _send_output
    self.send(msg)
  File ""/usr/lib/python3.8/http/client.py"", line 950, in send
    self.connect()
  File ""/usr/lib/python3.8/site-packages/docker/transport/unixconn.py"", line 43, in connect
    sock.connect(self.unix_socket)
FileNotFoundError: [Errno 2] No such file or directory

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""/usr/lib/python3.8/site-packages/requests/adapters.py"", line 439, in send
    resp = conn.urlopen(
  File ""/usr/lib/python3.8/site-packages/urllib3/connectionpool.py"", line 726, in urlopen
    retries = retries.increment(
  File ""/usr/lib/python3.8/site-packages/urllib3/util/retry.py"", line 403, in increment
    raise six.reraise(type(error), error, _stacktrace)
  File ""/usr/lib/python3.8/site-packages/urllib3/packages/six.py"", line 734, in reraise
    raise value.with_traceback(tb)
  File ""/usr/lib/python3.8/site-packages/urllib3/connectionpool.py"", line 670, in urlopen
    httplib_response = self._make_request(
  File ""/usr/lib/python3.8/site-packages/urllib3/connectionpool.py"", line 392, in _make_request
    conn.request(method, url, **httplib_request_kw)
  File ""/usr/lib/python3.8/http/client.py"", line 1255, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File ""/usr/lib/python3.8/http/client.py"", line 1301, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File ""/usr/lib/python3.8/http/client.py"", line 1250, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File ""/usr/lib/python3.8/http/client.py"", line 1010, in _send_output
    self.send(msg)
  File ""/usr/lib/python3.8/http/client.py"", line 950, in send
    self.connect()
  File ""/usr/lib/python3.8/site-packages/docker/transport/unixconn.py"", line 43, in connect
    sock.connect(self.unix_socket)
urllib3.exceptions.ProtocolError: ('Connection aborted.', FileNotFoundError(2, 'No such file or directory'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""/usr/lib/python3.8/site-packages/docker/api/client.py"", line 205, in _retrieve_server_version
    return self.version(api_version=False)[""ApiVersion""]
  File ""/usr/lib/python3.8/site-packages/docker/api/daemon.py"", line 181, in version
    return self._result(self._get(url), json=True)
  File ""/usr/lib/python3.8/site-packages/docker/utils/decorators.py"", line 46, in inner
    return f(self, *args, **kwargs)
  File ""/usr/lib/python3.8/site-packages/docker/api/client.py"", line 228, in _get
    return self.get(url, **self._set_request_timeout(kwargs))
  File ""/usr/lib/python3.8/site-packages/requests/sessions.py"", line 543, in get
    return self.request('GET', url, **kwargs)
  File ""/usr/lib/python3.8/site-packages/requests/sessions.py"", line 530, in request
    resp = self.send(prep, **send_kwargs)
  File ""/usr/lib/python3.8/site-packages/requests/sessions.py"", line 643, in send
    r = adapter.send(request, **kwargs)
  File ""/usr/lib/python3.8/site-packages/requests/adapters.py"", line 498, in send
    raise ConnectionError(err, request=request)
requests.exceptions.ConnectionError: ('Connection aborted.', FileNotFoundError(2, 'No such file or directory'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""/usr/bin/docker-compose"", line 33, in <module>
    sys.exit(load_entry_point('docker-compose==1.27.4', 'console_scripts', 'docker-compose')())
  File ""/usr/lib/python3.8/site-packages/compose/cli/main.py"", line 67, in main
    command()
  File ""/usr/lib/python3.8/site-packages/compose/cli/main.py"", line 123, in perform_command
    project = project_from_options('.', options)
  File ""/usr/lib/python3.8/site-packages/compose/cli/command.py"", line 60, in project_from_options
    return get_project(
  File ""/usr/lib/python3.8/site-packages/compose/cli/command.py"", line 131, in get_project
    client = get_client(
  File ""/usr/lib/python3.8/site-packages/compose/cli/docker_client.py"", line 41, in get_client
    client = docker_client(
  File ""/usr/lib/python3.8/site-packages/compose/cli/docker_client.py"", line 170, in docker_client
    client = APIClient(**kwargs)
  File ""/usr/lib/python3.8/site-packages/docker/api/client.py"", line 188, in __init__
    self._version = self._retrieve_server_version()
  File ""/usr/lib/python3.8/site-packages/docker/api/client.py"", line 212, in _retrieve_server_version
    raise DockerException(
docker.errors.DockerException: Error while fetching server API version: ('Connection aborted.', FileNotFoundError(2, 'No such file or directory'))
```

It seems that some files ares missing? But I don't know which one.

OS : Linux Manjaro
```
$ docker -v
Docker version 19.03.12-ce, build 48a66213fe
```
```
$ docker-compose version
docker-compose version 1.27.4, build unknown
docker-py version: 4.3.1
CPython version: 3.8.5
OpenSSL version: OpenSSL 1.1.1h  22 Sep 2020
```
I tried by installing compose via **pacman**, **pip**, or by taking directly the binary via **curl**.
It seems that all the needed dependencies are installed, exemple by installing with pip:
```
$ pip install docker-compose
Defaulting to user installation because normal site-packages is not writeable
Collecting docker-compose
  Downloading docker_compose-1.27.4-py2.py3-none-any.whl (110 kB)
     || 110 kB 2.8 MB/s
Requirement already satisfied: cached-property<2,>=1.2.0 in /usr/lib/python3.8/site-packages (from docker-compose) (1.5.2)
Requirement already satisfied: PyYAML<6,>=3.10 in /usr/lib/python3.8/site-packages (from docker-compose) (5.3.1)
Requirement already satisfied: docopt<1,>=0.6.1 in /usr/lib/python3.8/site-packages (from docker-compose) (0.6.2)
Requirement already satisfied: requests<3,>=2.20.0 in /usr/lib/python3.8/site-packages (from docker-compose) (2.24.0)
Requirement already satisfied: docker[ssh]<5,>=4.3.1 in /usr/lib/python3.8/site-packages (from docker-compose) (4.3.1)
Requirement already satisfied: python-dotenv<1,>=0.13.0 in /usr/lib/python3.8/site-packages (from docker-compose) (0.14.0)
Requirement already satisfied: dockerpty<1,>=0.4.1 in /usr/lib/python3.8/site-packages (from docker-compose) (0.4.1)
Requirement already satisfied: jsonschema<4,>=2.5.1 in /usr/lib/python3.8/site-packages (from docker-compose) (3.2.0)
Requirement already satisfied: texttable<2,>=0.9.0 in /usr/lib/python3.8/site-packages (from docker-compose) (1.6.3)
Requirement already satisfied: distro<2,>=1.5.0 in /usr/lib/python3.8/site-packages (from docker-compose) (1.5.0)
Requirement already satisfied: websocket-client<1,>=0.32.0 in /usr/lib/python3.8/site-packages (from docker-compose) (0.57.0)
Requirement already satisfied: chardet>=3.0.2 in /usr/lib/python3.8/site-packages (from requests<3,>=2.20.0->docker-compose) (3.0.4)
Requirement already satisfied: idna>=2.5 in /usr/lib/python3.8/site-packages (from requests<3,>=2.20.0->docker-compose) (2.10)
Requirement already satisfied: urllib3>=1.21.1 in /usr/lib/python3.8/site-packages (from requests<3,>=2.20.0->docker-compose) (1.25.10)
Requirement already satisfied: six>=1.4.0 in /usr/lib/python3.8/site-packages (from docker[ssh]<5,>=4.3.1->docker-compose) (1.15.0)
Requirement already satisfied: paramiko>=2.4.2 in /usr/lib/python3.8/site-packages (from docker[ssh]<5,>=4.3.1->docker-compose) (2.7.2)
Requirement already satisfied: attrs>=17.4.0 in /usr/lib/python3.8/site-packages (from jsonschema<4,>=2.5.1->docker-compose) (20.2.0)
Requirement already satisfied: pyrsistent>=0.14.0 in /usr/lib/python3.8/site-packages (from jsonschema<4,>=2.5.1->docker-compose) (0.17.3)
Requirement already satisfied: setuptools in /usr/lib/python3.8/site-packages (from jsonschema<4,>=2.5.1->docker-compose) (50.3.0)
Requirement already satisfied: bcrypt>=3.1.3 in /usr/lib/python3.8/site-packages (from paramiko>=2.4.2->docker[ssh]<5,>=4.3.1->docker-compose) (3.2.0)
Requirement already satisfied: cryptography>=2.5 in /usr/lib/python3.8/site-packages (from paramiko>=2.4.2->docker[ssh]<5,>=4.3.1->docker-compose) (3.1.1)
Requirement already satisfied: pynacl>=1.0.1 in /usr/lib/python3.8/site-packages (from paramiko>=2.4.2->docker[ssh]<5,>=4.3.1->docker-compose) (1.4.0)
Requirement already satisfied: cffi>=1.1 in /usr/lib/python3.8/site-packages (from bcrypt>=3.1.3->paramiko>=2.4.2->docker[ssh]<5,>=4.3.1->docker-compose) (1.14.3)
Requirement already satisfied: pycparser in /usr/lib/python3.8/site-packages (from cffi>=1.1->bcrypt>=3.1.3->paramiko>=2.4.2->docker[ssh]<5,>=4.3.1->docker-compose) (2.20)
Installing collected packages: docker-compose
Successfully installed docker-compose-1.27.4
```
Thanks for your help.",,,thenexxuz,"
--
I have run into this exact issue. I solved this by making sure that I run `sudo systemctl start docker` and then running `sudo docker-compose up`
--

--
I second this suggestion of proper error message like ""Error: Docker process not running""
--
",KoWu,"
--
Jup this happens if docker is not running (which is the default for arch/manjaro). Instead of some meaningless backtrace it should print some proper error message in this case. As far as I remember, earlier versions of compose did that.
--
",Glioburd,"
--
> I have run into this exact issue. I solved this by making sure that I run `sudo systemctl start docker` and then running `sudo docker-compose up`

Oh, thanks a lot. It was indeed simply Docker which was not running. I was so sure I already started Docker that I didn't thought about it.

> Jup this happens if docker is not running (which is the default for arch/manjaro). Instead of some meaningless backtrace it should print some proper error message in this case. As far as I remember, earlier versions of compose did that.

Yeah I agree too.
--

--
> You shouldn't close this issue then. This needs proper error message.

Heh you're right, I reopened it.
--
",asokani,"
--
You shouldn't close this issue then. This needs proper error message.
--
",gnubyte,"
--
Receiving the same error message today on docker-compose version 1.27.4, build 40524192
debian 9 x64

Edit: I found it. Turns out that it was actually that I had docker compose installed but not docker itself.
--
",rvdende,"
--
Was very confused getting this error. Just a simple ""Are you sure docker is running?"" would solve this.
--
"
7894,OPEN,/etc/hosts not updated on restart,kind/bug,2020-10-27 21:34:07 +0000 UTC,adrianandreias,Opened,,"## Description of the issue

`docker-compose restart` does not update `/etc/hosts` inside the container to new value defined in yml

`/etc/hosts` **is updated though** if using `docker-compose down && docker-compose up -d`

I've read about a docker limitation here: https://github.com/docker/compose/issues/696
though the user was no longer able to reproduce it.
Is this still a docker issue?

## Context information (for bug reports)

**Output of `docker-compose version`**
```
docker-compose version 1.25.4, build 8d51620a
docker-py version: 4.1.0
CPython version: 3.7.5
OpenSSL version: OpenSSL 1.1.0l  10 Sep 2019
```

**Output of `docker version`**
```
Docker version 19.03.11, build 42e35e61f3
```

**Output of `docker-compose config`**

```
services:
  bogus:
    command: tail -f /dev/null
    extra_hosts:
    - somedns.com:8.8.4.4
    image: busybox
version: '3.7'

```


## Steps to reproduce the issue

1. create this docker-compose.yml
```
version: ""3.7""

services:
  bogus:
    image: busybox
    command: tail -f /dev/null
    extra_hosts:
      - ""somedns.com:8.8.8.8""
```
2. 
```bash
docker-compose up
docker exec -it compose_bogus_1 sh
cat /etc/hosts
...
8.8.8.8	somedns.com  # shows ok
```
CTRL+D # to exit container

3. edit docker-compose.yml and change just two characters in the extra_hosts entry:
```
version: ""3.7""

services:
  bogus:
    image: busybox
    command: tail -f /dev/null
    extra_hosts:
      - ""somedns.com:8.8.4.4""
```
4. docker-compose restart

### Observed result
5.
```bash
docker exec -it compose_bogus_1 sh
docker exec -it compose_bogus_1 sh
cat /etc/hosts
....
8.8.8.8	somedns.com  # STILL shows initial value:
```

### Expected result

The `/etc/hosts` entry should change on restart to the new value: **8.8.4.4**.

Note that if instead of `docker-compose restart`, these two are used: `doker-compose down ; docker-compose up -d` the entry updates correctly to **8.8.4.4**

## Additional information

Ubuntu 18.04
",,,,,,,,,,,,,,
7893,OPEN,Docker compose version 1.27.3 changed docker-compose config behavior,kind/bug,2021-01-08 14:33:16 +0000 UTC,dragonpiper,Opened,,"Previously, docker compose would only mutate volume opts at runtime for bind mounts. After version 1.27.3 This happens when using the docker-compose config command.

This is an issue because previously, I had a docker-compose.yml file which I used for local dev testing. This used the same storage volume name, but used the local drive with bind mounts.

I used a second file called deploy.docker-compose.yml which included the changes needed for running in prod environment which include volume.driver_opt changes and environment changes.  After the latest changes, the docker-compose config tool becomes useless for generating platform agnostic compose files. 

This is a gist that reproduces the issue.
https://gist.github.com/dragonpiper/0f81ce16c9da18715c2d5ebb6a4cf845",,,LaXiS96,"
--
I believe I stumbled upon this same bug when I last updated Docker Desktop from 2.3.0.5 (which included compose 1.27.2) to 2.4.0.0 (compose 1.27.4) and I couldn't deploy anymore from a Windows client to a Linux Docker host.

My configuration includes a bind mount with Linux paths for the specific Linux Docker host I am deploying to: the reported error showed that compose prepended a random (?) Windows partition identifier (like ""C:"") and converted path separators to Windows.

I had to revert to 2.3.0.5, and haven't upgraded yet. I'm quite surprised very few people noticed this problem.
@dragonpiper any news?
--
",,,,,,,,,,
7892,OPEN,Document/implement support for cache-to and cache-from parameters for docker buildx build,kind/feature,2020-10-27 12:35:32 +0000 UTC,n1ru4l,Opened,,"I struggle to find any documentation on how I can use the `--cache-from` and `--cache-to` parameters which can be passed to `docker buildx build`. (https://docs.docker.com/engine/reference/commandline/buildx_build/)

(**Note:** docker buildx can be used by setting the `COMPOSE_DOCKER_CLI_BUILD=1 DOCKER_BUILDKIT=1`  environment variables)

This would allow efficient docker image builds on CI systems with docker buildx.

There is currently a `cache_from` option that can be passed to the `build` option, however, the documentation does not clearly state what that option actually does. https://docs.docker.com/compose/compose-file/#cache_from

",,,,,,,,,,,,,,
7901,OPEN,"Unnecessary warning that flag '--parallel' is ignored when building with COMPOSE_DOCKER_CLI_BUILD=1""",,2020-11-02 17:59:36 +0000 UTC,phao5814,Opened,,"### Actual behavior

When I run the below command, I receive a warning in the shell that ""Flag '--parallel' is ignored when building with COMPOSE_DOCKER_CLI_BUILD=1"". However, it appears that `docker-compose build` is running in parallel when I'm using the `--parallel` flag so I'm not sure the warning message is correct or required.

```
$ COMPOSE_DOCKER_CLI_BUILD=1 docker-compose -f docker-compose.dev.yml build --parallel

WARNING: Native build is an experimental feature and could change at any time
WARNING: Flag '--parallel' is ignored when building with COMPOSE_DOCKER_CLI_BUILD=1
Building db      ...
Building server  ...
Building client  ...
Building cypress ...
Building db
Building client
Building cypress
Building server
Sending build context to Docker daemon  1.392MB
```

### Expected behavior

No warning message about the `--parallel` flag should be present when used in conjunction with `COMPOSE_DOCKER_CLI_BUILD=1`.

### Information
  - macOS Version: 10.15.6

### Diagnostic logs
<!-- Full output of the diagnostics from ""Diagnose & Feedback"" in the menu ... -->
```
Docker for Mac: 2.4.0.0
```",,,,,,,,,,,,,,
7891,OPEN,Docs on docker/compose at Docker Hub is not up-to-date,kind/feature,2020-10-27 01:49:10 +0000 UTC,tnir,Opened,,"**Is your feature request related to a problem? Please describe.**
README.md available at https://hub.docker.com/r/docker/compose is obsolete and far away from https://github.com/docker/compose/blob/master/README.md.

**Describe the solution you'd like**
README.md at https://hub.docker.com/r/docker/compose should be the same as https://github.com/docker/compose/blob/master/README.md. Automated process is preferred.

**Describe alternatives you've considered**
One-off manual sync operation from https://github.com/docker/compose/blob/master/README.md to README.md at https://hub.docker.com/r/docker/compose.

**Additional context**
Add any other context or screenshots about the feature request here.
",,,,,,,,,,,,,,
7886,OPEN,What happened with docker-compose bundle cli command ?!,kind/bug,2020-10-26 14:40:34 +0000 UTC,Z-a-r-a-k-i,Opened,,"Hey I cannot find any information about what happened with bundle cli command, except that in docker-compose version 1.23.2, the command is there and in docker-compose version 1.27.4 it's not there anymore.

The sadness is that we are using it a lot in an open source project (https://github.com/pathwar/pathwar) and I cannot find any information anywhere (google, github issue, etc) about what happened with this cli command.

Could anyone tell me what happened and what are the future-proof alternatives ?
Meanwhile I'll add a check to be sure that we are using an old and outdated version of docker-compose in the project..",,,,,,,,,,,,,,
7885,OPEN,docker-compose down don't remove volumes,kind/bug,2020-10-28 12:39:03 +0000 UTC,EhsanSarshar,In progress,,"as the doc said the `docker-compose down` only persist volumes that are `external`. but I normally make volumes and it still persist even after `docker-compose down`
",,,InteNs,"
--
named volumes are also persisted, only anonymous volumes will we deleted by `docker-compose down` by default, if you want to also remove named volumes that are not external you can add `-v`:

> '-v, --volumes' Remove named volumes declared in the `volumes`
> section of the Compose file and anonymous volumes
> attached to containers.
--

--
i quoted the command options part of the docs from here:
https://docs.docker.com/compose/reference/down/
--
",EhsanSarshar,"
--
@InteNs do it mentioned in docs ?
--
",,,,,,,,
7884,OPEN,Nested env var expansion doesn't work,kind/bug,2020-10-25 13:20:31 +0000 UTC,GrigoriyMikhalkin,Opened,,"3. When making a bug report, make sure you provide all required information. The easier it is for
   maintainers to reproduce, the faster it'll be fixed.
-->

## Description of the issue
Nested env var expansion doesn't work.

## Context information (for bug reports)

**Output of `docker-compose version`**
```
docker-compose version 1.27.3, build 4092ae5d
docker-py version: 4.3.1
CPython version: 3.7.7
OpenSSL version: OpenSSL 1.1.0l  10 Sep 2019
```

**Output of `docker version`**
```
Client:
 Version:           19.03.8
 API version:       1.40
 Go version:        go1.13.8
 Git commit:        afacb8b7f0
 Built:             Wed Oct 14 19:43:43 2020
 OS/Arch:           linux/amd64
 Experimental:      false

Server:
 Engine:
  Version:          19.03.8
  API version:      1.40 (minimum version 1.12)
  Go version:       go1.13.8
  Git commit:       afacb8b7f0
  Built:            Wed Oct 14 16:41:21 2020
  OS/Arch:          linux/amd64
  Experimental:     false
 containerd:
  Version:          1.3.3-0ubuntu2
  GitCommit:        
 runc:
  Version:          spec: 1.0.1-dev
  GitCommit:        
 docker-init:
  Version:          0.18.0
  GitCommit:
```

## Steps to reproduce the issue
For testing you can use [this compose config file](https://gist.github.com/GrigoriyMikhalkin/5cbfec78ccc629bcf7b221d0911a216f).

### Case 1
Run `docker-compose up` without setting any env vars. 

**Got**
```
ERROR: Named volume ""${HOME/test}:/test:rw"" is used in service ""bash"" but no declaration was found in the volumes section.
```

**Expected**
Create `test` directory in `$HOME/test` directory

### Case 2
Set `TEST_DIR` variable and run `docker-compose up` again. 

**Got**
Inside `TEST_DIR`, `test}` directory is created with `test` subdirectory.

**Expected**
Just `test` directory inside `TEST_DIR`

## Additional information

OS: Ubuntu 20.04.1 LTS",,,,,,,,,,,,,,
7883,OPEN,Cannot start service web: error while creating mount source path,kind/bug,2020-10-23 21:36:40 +0000 UTC,shahidkarimi,Opened,,"My docker-compose.yml

```
version: ""3.8""
services:
  web:
    build: .
    ports:
      - ""5000:5000""
    volumes:
      - ./src/hanoo_brain:/var/www/html/
  redis:
    image: ""redis:alpine""
```


```
ERROR: for aff1d57496bf_ubuntu-6-nginx-ansible_web_1  Cannot start service web: error while creating mount source path '/var/docker-apps/ubuntu-6-nginx-ansible/src/hanoo_brain': mkdir /var/docker-apps: read-only file system

ERROR: for web  Cannot start service web: error while creating mount source path '/var/docker-apps/ubuntu-6-nginx-ansible/src/hanoo_brain': mkdir /var/docker-apps: read-only file system
ERROR: Encountered errors while bringing up the project.
```

What is the hell problem? Why its not mounting to /var/www/html on the target machine?",,,,,,,,,,,,,,
7881,OPEN,run command could converge dependencies,kind/feature,2020-10-21 18:44:10 +0000 UTC,benesch,Opened,,"**Is your feature request related to a problem? Please describe.**

Presently `docker-compose run SERVICE COMMAND...` will start any dependencies of `SERVICE` if they are not already started. This is great!

Unfortunately, if you change the configuration of one of these dependencies, `docker-compose run SERVICE` will not recreate this dependency. This is the opposite of what `docker-compose up SERVICE` will do in this situation, and was very surprising/confusing behavior to me.

**Describe the solution you'd like**

Teach `docker-compose run SERVICE` to recreate any dependencies that have changed (""convergence"").

**Describe alternatives you've considered**

Conditionally adding this behavior behind a `--recreate-deps-if-changed` flag, or somesuch, would also work!
",,,,,,,,,,,,,,
7880,OPEN,EHOSTUNREACH in production when I can ping host and it works on dev machine,kind/bug,2020-10-21 16:39:50 +0000 UTC,WebMatrixware,Opened,,"3. When making a bug report, make sure you provide all required information. The easier it is for
   maintainers to reproduce, the faster it'll be fixed.
-->

## Description of the issue
Simple web app with DB on mysql. Works on dev machine, when `docker-compose up` is run on production machine EHOSTUNREACH error throws when connecting to DB container rather than working. This is despite being able to ping the DB container from the app container that is throwing the error.

## Context information (for bug reports)

**Output of `docker-compose version` for dev**
```
docker-compose version 1.27.4, build 40524192
docker-py version: 4.3.1
CPython version: 3.7.4
OpenSSL version: OpenSSL 1.1.1c  28 May 2019
```

**Output of `docker-compose version` for prod**
```
docker-compose version 1.25.0, build 0a186604
docker-py version: 4.1.0
CPython version: 3.7.4
OpenSSL version: OpenSSL 1.1.0l  10 Sep 2019
```

**Output of `docker version` for dev**
```
Client: Docker Engine - Community
 Cloud integration  0.1.18
 Version:           19.03.13
 API version:       1.40
 Go version:        go1.13.15
 Git commit:        4484c46d9d
 Built:             Wed Sep 16 17:00:27 2020
 OS/Arch:           windows/amd64
 Experimental:      false

Server: Docker Engine - Community
 Engine:
  Version:          19.03.13
  API version:      1.40 (minimum version 1.12)
  Go version:       go1.13.15
  Git commit:       4484c46d9d
  Built:            Wed Sep 16 17:07:04 2020
  OS/Arch:          linux/amd64
  Experimental:     false
 containerd:
  Version:          v1.3.7
  GitCommit:        8fba4e9a7d01810a393d5d25a3621dc101981175
 runc:
  Version:          1.0.0-rc10
  GitCommit:        dc9208a3303feef5b3839f4323d9beb36df0a9dd
 docker-init:
  Version:          0.18.0
  GitCommit:        fec3683
```

**Output of `docker version` for prod**
```
Client: Docker Engine - Community
 Version:           19.03.13
 API version:       1.40
 Go version:        go1.13.15
 Git commit:        4484c46d9d
 Built:             Wed Sep 16 17:02:36 2020
 OS/Arch:           linux/amd64
 Experimental:      false

Server: Docker Engine - Community
 Engine:
  Version:          19.03.13
  API version:      1.40 (minimum version 1.12)
  Go version:       go1.13.15
  Git commit:       4484c46d9d
  Built:            Wed Sep 16 17:01:11 2020
  OS/Arch:          linux/amd64
  Experimental:     false
 containerd:
  Version:          1.3.7
  GitCommit:        8fba4e9a7d01810a393d5d25a3621dc101981175
 runc:
  Version:          1.0.0-rc10
  GitCommit:        dc9208a3303feef5b3839f4323d9beb36df0a9dd
 docker-init:
  Version:          0.18.0
  GitCommit:        fec3683
```

**Output of `docker-compose config` for dev**
(Make sure to add the relevant `-f` and other flags)
```
version: ""3""

volumes:
  db:
  
services:
  app:
    image: blanning/widow:v1.0.13
    container_name: widow_v1.0.13
    ports:
      - ""8585:80""
    depends_on:
      - mysql
    restart: unless-stopped
    environment:
      API_PORT: 8585
      API_SERVER: localhost
    stdin_open: true
    tty: true
  
  mysql:
    image: mysql:5
    container_name: mysql-v1
    ports:
      - ""34760:3306""
    expose:
      - ""3306""
    volumes:
      - ""C:/docker/widow/mysql-init:/docker-entrypoint-initdb.d""
    command: --default-authentication-plugin=mysql_native_password
    environment:
      MYSQL_ROOT_PASSWORD: testing
    restart: unless-stopped
    stdin_open: true
    tty: true
```

**Output of `docker-compose config` for prod**
(Make sure to add the relevant `-f` and other flags)
```
version: ""3""

volumes:
  db:
  
services:
  app:
    image: blanning/widow:v1.0.13
    container_name: widow_v1.0.13
    ports:
      - ""8585:80""
    depends_on:
      - mysql
    restart: unless-stopped
    environment:
      API_PORT: 8585
      API_SERVER: net.amc.local
    stdin_open: true
    tty: true
  
  mysql:
    image: mysql:5
    container_name: mysql-v1
    ports:
      - ""34760:3306""
    expose:
      - ""3306""
    volumes:
      - ""C:/docker/widow/mysql-init:/docker-entrypoint-initdb.d""
    command: --default-authentication-plugin=mysql_native_password
    environment:
      MYSQL_ROOT_PASSWORD: testing
    restart: unless-stopped
    stdin_open: true
    tty: true
```


## Steps to reproduce the issue

1.Run `docker-compose up` on production machine

### Observed result

Pings to the name of the db container succeed (tested from docker exec to app container), but calls to the database from the app container fail with EHOSTUNREACH error on syscall ""connect""

### Expected result

Connections to the database should work on production server like they do on the dev machine.

### Stacktrace / full error message

```
widow_v1.0.12 | Error: connect EHOSTUNREACH 172.19.0.2:3306
widow_v1.0.12 |     at TCPConnectWrap.afterConnect [as oncomplete] (net.js:1145:16)
widow_v1.0.12 |     --------------------
widow_v1.0.12 |     at Protocol._enqueue (/opt/widow/app/node_modules/mysql/lib/protocol/Protocol.js:144:48)
widow_v1.0.12 |     at Protocol.handshake (/opt/widow/app/node_modules/mysql/lib/protocol/Protocol.js:51:23)
widow_v1.0.12 |     at PoolConnection.connect (/opt/widow/app/node_modules/mysql/lib/Connection.js:116:18)
widow_v1.0.12 |     at Pool.getConnection (/opt/widow/app/node_modules/mysql/lib/Pool.js:48:16)
widow_v1.0.12 |     at Pool.query (/opt/widow/app/node_modules/mysql/lib/Pool.js:202:8)
widow_v1.0.12 |     at /opt/widow/app/node_modules/promise-mysql/lib/helper.js:26:45
widow_v1.0.12 |     at Promise._execute (/opt/widow/app/node_modules/bluebird/js/release/debuggability.js:384:9)
widow_v1.0.12 |     at Promise._resolveFromExecutor (/opt/widow/app/node_modules/bluebird/js/release/promise.js:518:18)
widow_v1.0.12 |     at new Promise (/opt/widow/app/node_modules/bluebird/js/release/promise.js:103:10)
widow_v1.0.12 |     at Pool.promiseCallback (/opt/widow/app/node_modules/promise-mysql/lib/helper.js:8:16)
widow_v1.0.12 |     at pool.query (/opt/widow/app/node_modules/promise-mysql/lib/pool.js:57:32)
widow_v1.0.12 |     at getSystems (/opt/widow/app/handlers.js:36:23)
widow_v1.0.12 |     at exports.Manager.execute (/opt/widow/app/node_modules/@hapi/hapi/lib/toolkit.js:57:29)
widow_v1.0.12 |     at Object.internals.handler (/opt/widow/app/node_modules/@hapi/hapi/lib/handler.js:46:48)
widow_v1.0.12 |     at exports.execute (/opt/widow/app/node_modules/@hapi/hapi/lib/handler.js:31:36)
widow_v1.0.12 |     at Request._lifecycle (/opt/widow/app/node_modules/@hapi/hapi/lib/request.js:370:68) {
widow_v1.0.12 |   errno: -113,
widow_v1.0.12 |   code: 'EHOSTUNREACH',
widow_v1.0.12 |   syscall: 'connect',
widow_v1.0.12 |   address: '172.19.0.2',
widow_v1.0.12 |   port: 3306,
widow_v1.0.12 |   fatal: true
widow_v1.0.12 | }
widow_v1.0.12 | 201021/152021.307, (1603293621307:ec545399a55f:18:kgjjmb36:10019) [response,get,systems] http://0.0.0.0:80: get /systems {""sort"":""alpha""} 500 (1064ms)

```

## Additional information

Dev machine is windows 10 workstation running docker for desktop. Production machine is CentOS8 server.
",,,,,,,,,,,,,,
7878,OPEN,Forward mount options,,2020-10-21 15:27:29 +0000 UTC,darkdragon-001,Opened,,"## Description of the issue

When using `docker run -v p:p:opt,ions` all `opt,ions` are used as (bind) mount options. This allows mounting tmpfs as `exec` instead of `noexec`, overwriting `uid`/`gid` and so on. I think _docker-compose_ should use the same syntax as _docker_ itself.

## Context information (for bug reports)

```
docker-compose version 1.27.4, build unknown
docker-py version: 4.3.1
CPython version: 3.9.0
OpenSSL version: OpenSSL 1.1.1g FIPS  21 Apr 2020
```

```
Client:
 Version:           19.03.13
 API version:       1.40
 Go version:        go1.15.1
 Git commit:        4484c46
 Built:             Fri Oct  2 19:31:30 2020
 OS/Arch:           linux/amd64
 Experimental:      false

Server:
 Engine:
  Version:          19.03.13
  API version:      1.40 (minimum version 1.12)
  Go version:       go1.15.1
  Git commit:       4484c46
  Built:            Fri Oct  2 00:00:00 2020
  OS/Arch:          linux/amd64
  Experimental:     false
 containerd:
  Version:          1.4.1
  GitCommit:        
 runc:
  Version:          1.0.0-rc92+dev
  GitCommit:        c9a9ce0286785bef3f3c3c87cd1232e535a03e15
 docker-init:
  Version:          0.18.0
  GitCommit: 
```

## Steps to reproduce the issue

1. Bind-mount a local folder inside the container, bind-mount a tmpfs into a subfolder of the previously mounted folder

### Observed result

Currently, _docker-compose_ supports only selected options for `volumes` and none for `tmpfs`. I would like to create my build directory tmpfs and run tests inside it, which is not possible because of `noexec`. Furthermore, on Fedora, when I create a mount to a non-existing mount point, it is owned by root and not my local (container) user.

### Expected result

Defaults are oky, but I would like to overwrite those in `docker-compose.yml`.

## Additional information

Fedora 33 with cgroups v1 via `moby` and `docker-compose` packages.
",,,,,,,,,,,,,,
7873,OPEN,The context path of build section is required although building isn't needed,kind/bug,2021-01-12 14:17:40 +0000 UTC,sim6,Opened,,"## Description of the issue

`docker-compose up` requires context path of build section but building it isn't needed because the image was get via `docker-compose pull`. Also for `docker-compose config`.

## Context information (for bug reports)

**Output of `docker-compose version`**
Installed via `pip install docker-compose`
```
docker-compose version 1.27.4, build unknown
docker-py version: 4.3.1
CPython version: 3.8.6
OpenSSL version: OpenSSL 1.1.1g  21 Apr 2020
```

**Output of `docker version`**
Installed via `apt install docker.io`
```
Client:
 Version:           19.03.13
 API version:       1.40
 Go version:        go1.15.2
 Git commit:        4484c46
 Built:             Tue, 22 Sep 2020 16:21:48 +0700
 OS/Arch:           linux/amd64
 Experimental:      false

Server:
 Engine:
  Version:          19.03.12
  API version:      1.40 (minimum version 1.12)
  Go version:       go1.14.7
  Git commit:       48a6621
  Built:            Mon Aug 31 05:46:39 2020
  OS/Arch:          linux/amd64
  Experimental:     false
 containerd:
  Version:          19.03.12
  GitCommit:        481103c8793316c118d9f795cde18060847c370e
 runc:
  Version:          1.0.0~rc92+dfsg1
  GitCommit:        1.0.0~rc92+dfsg1-5
 docker-init:
  Version:          0.19.0
  GitCommit:
```

**Output of `docker-compose config`**
(Make sure to add the relevant `-f` and other flags)
```
ERROR: build path /tmp/docker-compose-build-context-test/nonexists either does not exist, is not accessible, or is not a valid URL.
```

## Steps to reproduce the issue
```
 % mkdir /tmp/docker-compose-build-context-test
 % cd /tmp/docker-compose-build-context-test
 % cat > docker-compose.yml <<<'
services:
  test-build-context:
    build:
      context: nonexists
    image: debian:stable
'
 % docker-compose pull
Pulling test-build-context ... done
 % docker-compose up  
ERROR: build path /tmp/docker-compose-build-context-test/nonexists either does not exist, is not accessible, or is not a valid URL.
 % docker-compose version 
docker-compose version 1.27.4, build unknown
docker-py version: 4.3.1
CPython version: 3.8.6
OpenSSL version: OpenSSL 1.1.1g  21 Apr 2020
 % docker-compose config
ERROR: build path /tmp/docker-compose-build-context-test/nonexists either does not exist, is not accessible, or is not a valid URL.
```

### Observed result

The context path of the build secction is needed when build is not required.

### Expected result

Ignore build section and start the container.

### Stacktrace / full error message

```
 % docker-compose --verbose up    
compose.config.config.find: Using configuration files: ./docker-compose.yml
ERROR: compose.cli.main.main: build path /tmp/docker-compose-build-context-test/nonexists either does not exist, is not accessible, or is not a valid URL.
```

## Additional information
docker-compose installed via `pip install docker-compose` on Debian unstable.
```
 % cat /etc/debian_version 
bullseye/sid
 % apt list docker.io
Listing... Done
docker.io/testing,now 19.03.13+dfsg1-2 amd64 [installed]
```
",,,,,,,,,,,,,,
7870,OPEN,docker-compose up with multiple file does not include all container as service,,2020-10-19 15:26:27 +0000 UTC,dintifla,Opened,,"## Description of the issue

I have a setup with two docker-compose files (both version 3):
1. `docker-compose.yml` with my production setup
2. `docker-compose.test.yml` which extends the first file with some other container names, env. variables and also **adds** new containers (e.g. a database)

`docker-compose -f docker-compose.yml -f docker-compose.test.yml -p my-proj up --force-recreate --build --detach`
creates and starts all containers.
now `docker-compose -p my-proj logs -f my-container-from-2nd-file` does not work.

All the containers are up and running, but the ones from the 2nd file do not seem to be added to the composition.
`docker-compose config --services` does not list any container defined in the 2nd file.

Same if `-p` is omitted.


I deploy production and test system from this script:

```bash
docker-compose -p $prodProjectName stop
docker-compose -f docker-compose.yml -f docker-compose.test.yml -p $testProjectName up --force-recreate --build --detach
docker-compose -p $projectName logs -f cypress
docker-compose -p $testProjectName stop
# some other non-docker stuff goes here
docker-compose -p $prodProjectName -f docker-compose.yml up --force-recreate --build --detach
```

## Context information (for bug reports)

```
docker-compose version 1.27.4, build 40524192
docker-py version: 4.3.1
CPython version: 3.7.4
OpenSSL version: OpenSSL 1.1.1c  28 May 2019
```

```
Client: Docker Engine - Community
 Cloud integration  0.1.18
 Version:           19.03.13
 API version:       1.40
 Go version:        go1.13.15
 Git commit:        4484c46d9d
 Built:             Wed Sep 16 17:00:27 2020
 OS/Arch:           windows/amd64
 Experimental:      false

Server: Docker Engine - Community
 Engine:
  Version:          19.03.13
  API version:      1.40 (minimum version 1.12)
  Go version:       go1.13.15
  Git commit:       4484c46d9d
  Built:            Wed Sep 16 17:07:04 2020
  OS/Arch:          linux/amd64
  Experimental:     false
 containerd:
  Version:          v1.3.7
  GitCommit:        8fba4e9a7d01810a393d5d25a3621dc101981175
 runc:
  Version:          1.0.0-rc10
  GitCommit:        dc9208a3303feef5b3839f4323d9beb36df0a9dd
 docker-init:
  Version:          0.18.0
  GitCommit:        fec3683
```

## Steps to reproduce the issue

1. Write your main docker-compose.yml
2. Write a 2nd docker-compose.xyz.yml which adds more container
3. Run docker compose up with both files (2x -f flag) in detach mode
4. Run `docker-compose -p <your-project> logs -f <a-container-from-2nd-file>

### Observed result

`docker-compose config --services` lists only containers from first yml-file

### Expected result

`docker-compose config --services` lists containers from first *and second* yml-file

## Additional information
OS: Windows 10 2004 build 10.0.19041
WSL2
",,,,,,,,,,,,,,
7867,OPEN,Local volumes fail on up.,kind/bug,2020-10-15 18:19:44 +0000 UTC,cgardens,Opened,,"## Description of the issue
Docker compose succeeds on _first_ try with local volumes, but fails to come up on subsequent attempts. It appears compose does not recognize local volumes that it creates.

## Context information (for bug reports)
I think the issue is in this bit of code: https://github.com/docker/compose/blob/master/compose/volume.py#L150-L158. It seems like on the first try it runs through the first branch of the conditional because the volume doesn't exist yet and it successfully creates it. On subsequent runs it runs through the other branch and tries to make sure the volume is configured properly, but fails because that paths don't match. While this code hasn't changed recently, my guess is it might be related to the path that gets passed in from above (perhaps caused by some of the recent changes to support relative paths (in this issue: https://github.com/docker/compose/issues/6343)? 

**Output of `docker-compose version`**
```
docker-compose version 1.27.4, build 40524192
docker-py version: 4.3.1
CPython version: 3.7.7
OpenSSL version: OpenSSL 1.1.1g  21 Apr 2020
```

**Output of `docker version`**
```
Client: Docker Engine - Community
 Cloud integration  0.1.18
 Version:           19.03.13
 API version:       1.40
 Go version:        go1.13.15
 Git commit:        4484c46d9d
 Built:             Wed Sep 16 16:58:31 2020
 OS/Arch:           darwin/amd64
 Experimental:      false

Server: Docker Engine - Community
 Engine:
  Version:          19.03.13
  API version:      1.40 (minimum version 1.12)
  Go version:       go1.13.15
  Git commit:       4484c46d9d
  Built:            Wed Sep 16 17:07:04 2020
  OS/Arch:          linux/amd64
  Experimental:     false
 containerd:
  Version:          v1.3.7
  GitCommit:        8fba4e9a7d01810a393d5d25a3621dc101981175
 runc:
  Version:          1.0.0-rc10
  GitCommit:        dc9208a3303feef5b3839f4323d9beb36df0a9dd
 docker-init:
  Version:          0.18.0
  GitCommit:        fec3683
```

**Output of `docker-compose config`**
`docker-compose config`
```
services:
  service1:
    command: /bin/sh -c "" echo /my_local_volume; ""
    image: alpine
    volumes:
    - compose_issue:/my_local_volume:rw
version: '3.7'
volumes:
  compose_issue:
    driver: local
    driver_opts:
      device: /tmp/dev_local
      o: bind
      type: none
    name: dev-local1
```

## Steps to reproduce the issue

here's my `docker-compose.yaml` (simplified for sake of illustrating the issue).
```
version: ""3.7""

services:
  service1:
    image: alpine
    command: /bin/sh -c ""
      echo /my_local_volume;
      ""
    volumes:
      - compose_issue:/my_local_volume

volumes:
  compose_issue:
    name: dev-local1
    driver: local
    driver_opts:
      o: bind
      type: none
      device: /tmp/dev_local
```

1. `mkdir -p  /tmp/dev_local`
2. `docker-compose -f docker-compose.yaml up`
4. `docker-compose -f docker-compose.yaml up` (again, after the first one exits successfully)
(the first up succeeds, but then all subsequent ups fail)

### Observed result
* error.

### Expected result
* I expect compose up to run without error.

### Stacktrace / full error message

```
  compose_issue git:(master)  docker-compose -f docker-compose.yaml up

Creating volume ""dev-local1"" with local driver
Pulling service1 (alpine:)...
latest: Pulling from library/alpine
df20fa9351a1: Pull complete
Digest: sha256:185518070891758909c9f839cf4ca393ee977ac378609f700f60a771a2dfe321
Status: Downloaded newer image for alpine:latest
Creating compose_issue_service1_1 ... done
Attaching to compose_issue_service1_1
service1_1  | /my_local_volume
compose_issue_service1_1 exited with code 0
  compose_issue git:(master)  docker-compose -f docker-compose.yaml up

ERROR: Configuration for volume dev-local1 specifies ""device"" driver_opt /tmp/dev_local, but a volume with the same name uses a different ""device"" driver_opt (/host_mnt/private/tmp/dev_local). If you wish to use the new configuration, please remove the existing volume ""dev-local1"" first:
$ docker volume rm dev-local1
```

## Additional information

Using docker for mac (2.4.0.0). OS: Catalina 10.15.7

Also worth noting that if i I change the device in the volume to `/host_mnt/private/tmp/dev_local` after the first try, things work again. This is not really a viable work around but is probably useful for diagnosing what's going on.

This code worked on previous version so it seems to be an issue introduced in `1.27.4`.",,,sherifnada,"
--
Also seeing this issue
--
",,,,,,,,,,
7861,OPEN,Environment variable VIRTUAL_ENV not passed to container,kind/bug,2020-10-10 07:49:45 +0000 UTC,jnns,Opened,,"## Preface

I hope that what I'm reporting is not just a user error. If it is, then I'm really sorry for the noise. I did my best to see where my setup could be flawed and didn't find anything.

## Description of the issue

I'm trying to pass on an environment variable called `VIRTUAL_ENV` to a container just like documentation suggests:

> You can also pass a variable through from the shell by not giving it a value:
> 
> ```docker-compose run -e DEBUG web python console.py```
>
> The value of the DEBUG variable in the container is taken from the value for the same variable in the shell in which Compose is run.

The problem is that it only works with variables not named `VIRTUAL_ENV`. Please refer to the minimal reproducible example  below. 

```yaml
version: '3.8'

services:
  test:
    image: alpine
    environment:
      - VIRTUAL_ENV
      - VIRTUAL_ENV1
      - VIRTUAL_ENV2
    command: sh -c 'env | grep VIRTUAL'
```

Fish shows that the variable is actually exported in the calling shell:

```sh
set --show VIRTUAL_ENV
$VIRTUAL_ENV: not set in local scope
$VIRTUAL_ENV: set in global scope, exported, with 1 elements
$VIRTUAL_ENV[1]: length=3 value=|foo|
$VIRTUAL_ENV: not set in universal scope
```

Starting the container just sets all other variables but not the one in question:


```sh
docker-compose run -e VIRTUAL_ENV -e VIRTUAL_ENV1 -e VIRTUAL_ENV2 --rm test 
Creating jnns_test_run ... done
VIRTUAL_ENV1=foo
VIRTUAL_ENV2=foo
```

## Context information (for bug reports)

**Output of `docker-compose version`**

```
docker-compose version 1.27.4, build 40524192
```

**Output of `docker version`**

```
Docker version 19.03.13, build 4484c46d9d
```

**Output of `docker-compose config`**

```yaml
services:
  test:
    command: sh -c 'env | grep VIRTUAL'
    environment:
      VIRTUAL_ENV: null
      VIRTUAL_ENV1: null
      VIRTUAL_ENV2: null
    image: alpine
version: '3.8'
```


## Steps to reproduce the issue

Run `docker-compose run --rm -e VIRTUAL_ENV=foo -e VIRTUAL_ENV1=foo -e VIRTUAL_ENV2=foo test`

### Observed result

```sh
Creating network ""jnns_default"" with the default driver
Creating jnns_test_run ... done
VIRTUAL_ENV1=foo
VIRTUAL_ENV2=foo
```

### Expected result
```sh
Creating network ""jnns_default"" with the default driver
Creating jnns_test_run ... done
VIRTUAL_ENV=foo  # This env variable is not set.
VIRTUAL_ENV1=foo
VIRTUAL_ENV2=foo
```

## Additional information

I've tried the example using Bash 5.0.16 and Fish 3.1.0 and received the same results. I'm using Ubuntu 20.04 LTS ""focal"" and installed Docker Compose using the method described on the Installation docs:

```sh
sudo curl -L ""https://github.com/docker/compose/releases/download/1.27.4/docker-compose-$(uname -s)-$(uname -m)"" -o /usr/local/bin/docker-compose
```",,,,,,,,,,,,,,
7860,OPEN,build context bug: folder name conflicts,kind/bug,2020-10-09 13:19:02 +0000 UTC,IainVM,Opened,,"## Description of the issue
Building of Dockerfile fails with
`/var/lib/docker/tmp/docker-builderXXXXXX/db_scripts: no such file or directory`


As you can see there are 2 folders called `db_scripts` and it seems that docker-compose is trying to push additional files into the build context from it's own context. Even when the build context was specified as `./dockerfiles/database`

When renaming `./dockerfiles/database/db_scripts` to ./dockerfiles/database/sql` the issue went away. 


## Context information (for bug reports)

**Output of `docker-compose version`**

This issue didn't appear with `docker-compose version 1.25.1-rc1, build d92e9bee`
It was present on `docker-compose version 1.27.4, build 40524192`
The changes mentioned above fixed `1.27.4`

**Output of `docker version`**
```
Docker version 19.03.13, build 4484c46d9d
```

**Output of `docker-compose config`**
[simplified for error recreation]
```
version: ""3.4""

services:
  alembic-migration:
    build:
      context: ./dockerfiles/database
```


## Steps to reproduce the issue

1. The folder structure was as such [simplified for error recreation]
```
project/
    docker-compose.yml
    db_scripts/
        some_other_files
    dockerfiles/
        database/
            Dockerfile
            db_scripts/
                some.sql
```

Dockerfile
```
FROM python:3.7

COPY ./db_scripts/some.sql /db_scripts/some.sql
```
2. run `docker-compose up -d`

### Observed result
`/var/lib/docker/tmp/docker-builderXXXXXX/db_scripts: no such file or directory`

### Expected result
Build without error

### Stacktrace / full error message

```
ERROR: Service 'alembic-migration' failed to build : COPY failed stat /var/lib/docker/tmp/docker-builder145438417/db_scripts: no such file or directory
```

## Additional information
Both tests done on Ubuntu 20.04

When renaming `./dockerfiles/database/db_scripts` to ./dockerfiles/database/sql` the issue went away. 
",,,,,,,,,,,,,,
7859,OPEN,Add an option to config: entries to name the config by content hash,kind/feature,2020-10-09 11:19:41 +0000 UTC,douardda,Opened,,"(Not sure it's the right repo for this issue)

The idea is that when one uses a `config:` declaration in a docker-compose deployed with `docker stack deploy` (swarm mode), like:
```
configs:
  nginx:
    file: conf/nginx.conf
```
for example, then any modification made to the source nginx.conf file is not that easy to deploy due to the immutable nature of the config object.

A possible solution is proposed in https://blog.sunekeller.dk/2019/01/docker-stack-deploy-update-configs/ 
in which the name of the config entry is made dependent on the file content.

So I believe it would be really handy to have an option in a `config` entry to automatically generate a name for the config that is dependent on its content (using a md5 or sha hash for example). Having the `name` automatically generated according the hash of the file.

Does it make sense?

thx,

David

FTR, using docker 19.03.13 in swarm mode with a compose 3.8 file format. ",,,,,,,,,,,,,,
7858,OPEN,node_module's content is hidden on Ubuntu,kind/bug,2020-10-09 10:47:21 +0000 UTC,samandera,Opened,,"## Description of the issue
OS: Ubuntu 20.04.1 LTS
The content of node_module's directory is hidden from every place except docker container (checked in terminal, Atom editor and GUI files app)
I was able to make content visible by following steps in [this comment](https://github.com/api-platform/api-platform/issues/1155#issuecomment-496453705), however it's a hack and it should't be set this way.
## Context information (for bug reports)

**Output of `docker-compose version`**
```
1.26.2
```

**Output of `docker version`**
```
19.03.13
```

**`docker-compose.yml` excerpt**
```
services:
  dev:
    ...
    volumes:
      - .:/app
      - node_modules:/app/node_modules
    ...
```

**Output of `docker-compose config`**
```
services:
  dev:
    ...
    tty: true
    volumes:
    - /path/to/app/directory:/app:rw
    - node_modules:/app/node_modules:rw
  ...

```


## Steps to reproduce the issue

Run npm install inside docker container on Ubuntu with docker-compose using setting from the excerpt.

### Observed result
Empty node_modules folder. All other ignored/hidden folders are able to display their content.

### Expected result
Filled node_modules folder.
",,,,,,,,,,,,,,
7857,OPEN,existence of secret files are checked locally instead of remotely when using remote docker daemon with DOCKER_HOST,kind/bug,2020-10-09 09:00:23 +0000 UTC,danny-p93,Opened,,"3. When making a bug report, make sure you provide all required information. The easier it is for
   maintainers to reproduce, the faster it'll be fixed.
-->

## Description of the issue
I'm using an remote docker daemon (DOCKER_HOST is set). In my docker-compose.yml i have specified some secrets for use in my service. These secrets use a file that is only given on the remote system. Every time i use docker-compose on my local system it shows me a warning, that my service uses an undefined file. For my luck it is just a warning and the service starts and indeed uses the given files from the remote daemon.

## Context information (for bug reports)

**Output of `docker-compose version`**
```
docker-compose version 1.27.4, build 40524192
docker-py version: 4.3.1
CPython version: 3.7.7
OpenSSL version: OpenSSL 1.1.0l  10 Sep 2019
```

**Output of `docker version`**
```
Client: Docker Engine - Community
 Version:           19.03.13
 API version:       1.40
 Go version:        go1.13.15
 Git commit:        4484c46d9d
 Built:             Wed Sep 16 17:02:36 2020
 OS/Arch:           linux/amd64
 Experimental:      false

Server: Docker Engine - Community
 Engine:
  Version:          19.03.10
  API version:      1.40 (minimum version 1.12)
  Go version:       go1.13.3
  Git commit:       9424aea
  Built:            Thu Aug  6 02:55:27 2020
  OS/Arch:          linux/amd64
  Experimental:     false
 containerd:
  Version:          1.2.10
  GitCommit:        b34a5c8af56e510852c35414db4c1f4fa6172339
 runc:
  Version:          1.0.0-rc9
  GitCommit:        d736ef14f0288d6993a1845745d6756cfc9ddd5a
 docker-init:
  Version:          0.18.0
  GitCommit:        fec3683
```

**Output of `docker-compose config`**
(Make sure to add the relevant `-f` and other flags)
```
secrets:
  my_sec:
    file: /path/on/remote/system
services:
  my_ser:
    container_name: custom
    environment:
      SOMEENV: foo
    image: myimage:latest
    ports:
    - published: 1234
      target: 4321
    restart: always
    secrets:
    - source: my_sec
      target: /apps/project/path/in/container
    volumes:
    - /another/remote/path:/apps/project/path:rw
version: '3.7'
```


## Steps to reproduce the issue

1. setup an remote docker daemon, that exposes the daemon port correctly
2. install docker-cli and docker-compose locally
3. specify DOCKER_HOST to the remote daemon
4. configure a local docker-compose.yml file, that includes a configuration for a secret, which uses a file, that only exists on the remote system
5. run the compose file

### Observed result
i get a warning for the secret file
definition of remote volume works without warning

### Expected result
i get a warning when the file is not present on the remote system and the local system should be ignored

### Stacktrace / full error message
```
WARNING: Service ""my_ser"" uses an undefined secret file ""/path/on/remote/system"", the following file should be created ""/path/on/remote/system""
```

## Additional information
my remote system is a photon-os, my local system is ubuntu18.04 on WSL1
docker and docker-compose installed as documented
",,,,,,,,,,,,,,
7856,OPEN,"Between 1.27.0 and 1.27.4 the handling of volume config option ""device"" has changed",kind/bug,2021-01-08 14:53:05 +0000 UTC,maaarghk,Opened,,"## Description of the issue
I have a compose file with a section like this:

```yaml
volumes:
  app_data:
    driver_opts:
      type: none
      device: ""${PWD}/../../www/""
      o: bind
```

On docker-compose 1.27.0 a volume is created like so:

```
$ docker inspect --format='{{ .Options.device }}' composeproject_app_data
/home/mark/Code/composeproject/ops/dev/../../www/
```

After upgrading to 1.27.4 the following error is raised after trying to bring the containers up:

```
ERROR: Configuration for volume app_data specifies ""device"" driver_opt /home/mark/Code/composeproject/www, but a volume with the same name uses a different ""device"" driver_opt (/home/mark/Code/composeproject/ops/dev/../../www/). If you wish to use the new configuration, please remove the existing volume ""composeproject_app_data"" first
```

In other words, 1.27.4 is resolving the ""../.."" in the path whereas 1.27.0 is not.

This behaviour should only change with a new compose file definition version.

Of course you will also need to worry about people who just freshly installed 1.27.4 coming in and whinging like me that backwards compatibility was broken between .4 and .5 when you make the fix :) :medal_sports: 

## Context information (for bug reports)

**Output of `docker-compose version`**
Broken:
```
docker-compose version 1.27.4, build unknown
docker-py version: 4.3.1
CPython version: 3.8.5
OpenSSL version: OpenSSL 1.1.1h  22 Sep 2020
```

Working:
```
docker-compose version 1.27.0, build unknown
docker-py version: 4.3.1
CPython version: 3.8.5
OpenSSL version: OpenSSL 1.1.1h  22 Sep 2020
```

**Output of `docker version`**
```
Client:
 Version:           19.03.12-ce
 API version:       1.40
 Go version:        go1.14.5
 Git commit:        48a66213fe
 Built:             Sat Jul 18 01:33:21 2020
 OS/Arch:           linux/amd64
 Experimental:      false

Server:
 Engine:
  Version:          19.03.12-ce
  API version:      1.40 (minimum version 1.12)
  Go version:       go1.14.5
  Git commit:       48a66213fe
  Built:            Sat Jul 18 01:32:59 2020
  OS/Arch:          linux/amd64
  Experimental:     false
 containerd:
  Version:          v1.4.1.m
  GitCommit:        c623d1b36f09f8ef6536a057bd658b3aa8632828.m
 runc:
  Version:          1.0.0-rc92
  GitCommit:        ff819c7e9184c13b7c2607fe6c30ae19403a7aff
 docker-init:
  Version:          0.18.0
  GitCommit:        fec3683
```

## Steps to reproduce the issue

1. Have a volume mount specified as per above with relative paths
2. Start with 1.27.0
3. Upgrade
4. Fail to start with 1.27.4

### Observed result
Containers don't come up

### Expected result
Containers come up

## Additional information
Manjaro Linux on kernel 5.9-rc3",,,B4RteQPl,"
--
I can confirm that I'm playing with this bug since upgrade to 1.27.4 
--
",LaXiS96,"
--
I believe issue #7893 is somewhat related.

Around compose 1.27.3 or .4 something changed and prevented me from successfully deploying from Windows to a Linux Docker host.

I don't have concrete proof as I decided to just stick to the old version (and it was over 3 months ago), but the situation was like this:
- docker-compose.yml included a volume with `device: /mnt/sda3/data`
- the error reported after running `docker-compose up` included something like `C:\mnt\sda3\data`
The prepending of ""C:"" and conversion to Windows-style path separators tells me something is wrong. The `/mnt/sda3/data` is specific to and valid for the Linux Docker host I was deploying to.

It doesn't look like any recent commit has addressed this problem, I only see ""Remove path checks for bind mounts"" in the 1.27.4 release changelog but it is not clear where this is reflected in the code.
--
",,,,,,,,
7854,OPEN,Bind mount never find host files or directories in Ubuntu 20.04 LTS,kind/bug,2021-01-08 14:54:34 +0000 UTC,lauyilouis,Opened,,"## Description of the issue
Bind mount of docker-compose can never find host files or directories in Ubuntu 20.04 LTS. It instead create directories with the same name of the host path. Same docker and docker compose version and config files with Ubuntu 18.04.5 LTS works.

**Output of `docker-compose version`**
```
docker-compose version 1.27.4, build 40524192
```

**Output of `docker version`**
```
Docker version 19.03.13, build 4484c46d9d
```

**Output of `docker-compose config`**
(Make sure to add the relevant `-f` and other flags)
```
services:
  app:
    image: [any image]
    ports:
    - published: 80
      target: 4000
    volumes:
    - ./firebase-adminsdk-pk.json:/tmp/keys/firebase-adminsdk-pk.json:ro
```

## Steps to reproduce the issue

1. copy a json file with random content and name it `firebase-adminsdk-pk.json`.
2. run `docker-compose up -d` to spin up the service with any images.
3. run `docker-compose exec app cat /tmp/keys/firebase-adminsdk-pk.json` to examine the file.

### Observed result
The terminal will prompt something similar to `read error: firebase-adminsdk-pk.json Is a directory`. This is because the docker compose cannot find the host file and then create a folder named with the host file instead.

### Expected result
The content of the JSON file should be displayed.

OS version
Ubuntu 20.04.01 LTS (tried at Google Cloud Computing and Window WSL)
",,,LaXiS96,"
--
Probably related: #7856
--
",,,,,,,,,,
7853,OPEN,Please expose current user and group ID as new variables for use inside docker-compose.yml,kind/feature,2021-01-04 15:02:53 +0000 UTC,hartwork,In progress,,"**Is your feature request related to a problem? Please describe.**
Hi, docker-compose rocks, keep up the good work! :pray: 
I had cases where the container should be running with the same user and group ID as the docker-compose process, e.g. so that files created inside the container will start out with the right owner without any need for initial root permissions (which is not cool for security) or `chown`'ing files et cetera.

As of today, inside `docker-compose.yml` a service definition can already ask for a specific user by means of syntax `user: ""<user_id>:<group_id>""` but there are no predefined variables to effectively achieve something *like* `user: ""$(id -u):$(id -g)""` from inside the YAML file with convenice. The list of [Compose file and CLI variables](https://docs.docker.com/compose/env-file/#compose-file-and-cli-variables) does not document any variables like that.

Here's a few documented examples for other people trying to achieve the same, and they all need to resort to means *outside* the `docker-compose.yml` file: [[1]](https://stackoverflow.com/questions/55916455/export-current-user-id-in-makefile-for-docker-compose) [[2]](https://medium.com/faun/set-current-host-user-for-docker-container-4e521cef9ffc#b470) [[3]](https://jtreminio.com/blog/running-docker-containers-as-current-host-user/) [[4]](https://gist.github.com/prog/48341108404cae266d72ed4a470c1bc3) [[5]](https://stackoverflow.com/questions/56844746/how-to-set-uid-and-gid-in-docker-compose/56844765) [[6]](https://dev.to/acro5piano/specifying-user-and-group-in-docker-i2e).

**Describe the solution you'd like**
It would be great to have two more predefined variables:
- `COMPOSE_USER_ID` predefined with the effective user ID, as return by `$(id -u)`
- `COMPOSE_GROUP_ID` predefined with the effective group ID, as return by `$(id -g)`

With those two variables, a docker-compose.yml file could now use syntax `user: ""${COMPOSE_USER_ID?}:${COMPOSE_GROUP_ID?}""` to conveniently have a container running as the same user as the one calling docker-compose. Wouldn't that be nice! :smiley: 

Feature request #3849 seems to be rooted in a similar need, but my impression was that the door to arbitrary code execution has been kept shut for security reasons so far and adding two variables should work without questioning the current threat model.

**Describe alternatives you've considered**
You could define `COMPOSE_USER_ID` and `COMPOSE_GROUP_ID` *outside* of `docker-compose.yml` e.g.
```
COMPOSE_USER_ID=""$(id -u)"" COMPOSE_GROUP_ID=""$(id -g)"" docker-compose run ...
```
but it's not very convenient, does not work out of the box, and it's not standardized.

**Additional context**
```console
# cat docker-compose.yml 
version: ""3""

services:
  debian:
    image: debian:sid
    user: ""${COMPOSE_USER_ID?}:${COMPOSE_GROUP_ID?}""

# COMPOSE_USER_ID=""$(id -u)"" COMPOSE_GROUP_ID=""$(id -g)"" docker-compose run debian sh -c id  # unpatched
Creating tmpyvecgpc8mx_debian_run ... done
uid=1000 gid=1000 groups=1000

# docker-compose run debian sh -c id  # patched future release, same effect
Creating tmpyvecgpc8mx_debian_run ... done
uid=1000 gid=1000 groups=1000
```",,,hartwork,"
--
Any thoughts?
--
",prokher,"
--
Honestly, I am waiting for this feature for years already, this is the last thing keeping me from throwing away scriptware around the Docker Compose. I need UID & GID for the same purpose I suppose.
--
",muxator,"
--
Hi, I think this is a much needed feature. Currently, security-sensitive users need to invert all sorts of alternatives to run containers as a restricted user. Or worse, there may be someone who just does not care and leaves files owned by root laying around in the system.

This proposal seems to be sufficiently simple to be embraced by the sheer majority of the community.
--
",,,,,,
7848,OPEN,Inconsistent value of $PWD variable,kind/bug,2020-10-06 08:21:09 +0000 UTC,nomysz,In progress,,"3. When making a bug report, make sure you provide all required information. The easier it is for
   maintainers to reproduce, the faster it'll be fixed.
-->

## Description of the issue
`$PWD` variable sometimes returnes path with `/host_mnt` prefix and sometimes without prefix.

## Context information (for bug reports)

**Output of `docker-compose version`**
```
docker-compose version 1.27.4, build 40524192
docker-py version: 4.3.1
CPython version: 3.7.7
OpenSSL version: OpenSSL 1.1.1g  21 Apr 2020
```

**Output of `docker version`**
```
Client: Docker Engine - Community
 Cloud integration  0.1.18
 Version:           19.03.13
 API version:       1.40
 Go version:        go1.13.15
 Git commit:        4484c46d9d
 Built:             Wed Sep 16 16:58:31 2020
 OS/Arch:           darwin/amd64
 Experimental:      false

Server: Docker Engine - Community
 Engine:
  Version:          19.03.13
  API version:      1.40 (minimum version 1.12)
  Go version:       go1.13.15
  Git commit:       4484c46d9d
  Built:            Wed Sep 16 17:07:04 2020
  OS/Arch:          linux/amd64
  Experimental:     true
 containerd:
  Version:          v1.3.7
  GitCommit:        8fba4e9a7d01810a393d5d25a3621dc101981175
 runc:
  Version:          1.0.0-rc10
  GitCommit:        dc9208a3303feef5b3839f4323d9beb36df0a9dd
 docker-init:
  Version:          0.18.0
  GitCommit:        fec3683
```

**Output of `docker-compose config`**
```
networks:
  default:
    driver: bridge
    name: my_network
services:
  my_service:
    command: sleep 5
    image: alpine
    volumes:
    - my_code:/tmp/any:rw
version: '3.7'
volumes:
  my_code:
    driver: local
    driver_opts:
      device: /Users/me/Projects/project
      o: bind
      type: none
```


## Steps to reproduce the issue


1. Run this config with `docker-compose up`
```
version: '3.7'

volumes:
    my_code:
        driver: local
        driver_opts:
            type: none
            device: $PWD
            o: bind


services:
    my_service:
        image: alpine
        command: sleep 5
        volumes:
            - my_code:/tmp/any


networks:
    default:
        driver: bridge
        name: my_network
```
2. Wait 5 seconds or stop `Ctrl+C`
3. Run again

### Observed result
Error below

### Expected result
Running instance

### Stacktrace / full error message

```
ERROR: Configuration for volume my_code specifies ""device"" driver_opt /Users/me/Projects/project, but a volume with the same name uses a different ""device"" driver_opt (/host_mnt/Users/me/Projects/project). If you wish to use the new configuration, please remove the existing volume ""my_code"" first:
```

## Additional information

Docker for Mac, MacOS Catalina 10.15.6",,,thaJeztah,"
--
I think compose needs to pick the `$PWD` up from the shell; are you sure the variable is set? There could be cases where it's not (also see https://github.com/docker/compose/issues/5003#issuecomment-314209681)

That said; from the compose file, I _think_ your intent is to make the bind-mount's source relative to the compose file's path (so to work similar to the shorthand `volumes: - <local-path>:<container-path>`)?

Perhaps we could use a special variable / substitution that could be used that would always point to the full path of the compose file.

/cc @ndeloof @ulyssessouza 
--

--
Hmmm.. possibly the `/host_mnt` is something that's set in the API proxy that's used on Docker Desktop to translate paths. @djs55 @StefanScherer do you know?
--

--
I see what's happening. It looks like the adjustments that the Docker Desktop API makes are not symmetrical; when _creating_ the volume, the API prepends `/host_mnt` to `/Users/stefanscherer/code/compose`, but when _inspecting_ the volume, it doesn't _remove_ the `/host_mnt` prefix. (I recall we had some discussions about similar changes that the API made for IP-addresses)

Compose therefore (rightfully) complains that the options do not match for the volume. Ideally such a check would be done by the daemon (I created a tracking issue for that https://github.com/moby/moby/issues/16068; I _think_ there's some checks already, but those may not yet cover volume _options_)

I think the first fix would be for the Docker Desktop API to strip the `/host_mnt` prefix when inspecting volumes
--
",nomysz,"
--
@thaJeztah 
> I think compose needs to pick the $PWD up from the shell; are you sure the variable is set? 

It is set.

The point is not that it is not set. But that it returns different values. Once with `/host_mnt` prefix. Once without.

My intention is to have shared volume between two containers (while also being directory on my local machine) - while I was testing I got same behaviour with simpler config - that's why I'm posting simpler config with this bug. Real one would be with two services sharing same volume. That worked for me until recently $PWD broke and I get mentioned error message (same config - just docker stack update). I was updating docker with regular update tool for Docker for Mac.


--

--
I have found that comment of @djs55 here https://github.com/docker/for-mac/issues/4859 but like you see on attached screenshots it is not the case. With my versions it should work (in theory).

<img width=""919"" alt=""Zrzut ekranu 2020-10-5 o 17 37 42"" src=""https://user-images.githubusercontent.com/3172684/95100629-9b95a680-0731-11eb-85e7-8a8b96f75112.png"">

<img width=""494"" alt=""Zrzut ekranu 2020-10-5 o 17 38 09"" src=""https://user-images.githubusercontent.com/3172684/95100639-9df80080-0731-11eb-82f3-f57f380c0b81.png"">

--

--
Also looks like it's not only `$PWD` issue. I'm getting same error message for following config (double `up` to get error message):

```
version: '3.7'

volumes:
    my_code:
        driver: local
        driver_opts:
            type: none
            device: .
            o: bind

services:
    my_service:
        image: alpine
        command: sleep 5
        volumes:
            - my_code:/tmp/any

networks:
    default:
        driver: bridge
        name: my_network
```
--

--
@thaJeztah so is this a right place for bug report or should I create it in another repository?
--
",StefanScherer,"
--
At least I can reproduce the issue. I also have DD 2.4.0.0 Stable installed with gRPC FUSE setting active. It works when I switched back to osxfs setting.
Here's the output with gRPC FUSE:

```
$ docker-compose up
Creating network ""my_network"" with driver ""bridge""
Creating volume ""compose_my_code"" with local driver
Pulling my_service (alpine:)...
latest: Pulling from library/alpine
df20fa9351a1: Pull complete
Digest: sha256:185518070891758909c9f839cf4ca393ee977ac378609f700f60a771a2dfe321
Status: Downloaded newer image for alpine:latest
Creating compose_my_service_1 ... done
Attaching to compose_my_service_1
compose_my_service_1 exited with code 0
~/code/compose
$ docker-compose up
ERROR: Configuration for volume my_code specifies ""device"" driver_opt /Users/stefanscherer/code/compose, but a volume with the same name uses a different ""device"" driver_opt (/host_mnt/Users/stefanscherer/code/compose). If you wish to use the new configuration, please remove the existing volume ""compose_my_code"" first:
$ docker volume rm compose_my_code
```

The volume is created with `/host_mnt` prefix on first `docker-compose up`. 

```
$ docker volume inspect compose_my_code
[
    {
        ""CreatedAt"": ""2020-10-05T15:57:12Z"",
        ""Driver"": ""local"",
        ""Labels"": {
            ""com.docker.compose.project"": ""compose"",
            ""com.docker.compose.version"": ""1.27.4"",
            ""com.docker.compose.volume"": ""my_code""
        },
        ""Mountpoint"": ""/var/lib/docker/volumes/compose_my_code/_data"",
        ""Name"": ""compose_my_code"",
        ""Options"": {
            ""device"": ""/host_mnt/Users/stefanscherer/code/compose"",
            ""o"": ""bind"",
            ""type"": ""none""
        },
        ""Scope"": ""local""
    }
]
```

On the second call docker-compose seems to compare the existing value (with the prefix) with the new calculated $PWD and complains that these differ.


--

--
It's a known bug listed here https://docs.docker.com/docker-for-mac/release-notes/#known-issues for version 2.4.0.0
See also docker/for-mac#4859 A fix will land in next Edge release first.

--
",,,,,,
7847,OPEN,Multiple --env-file?,kind/feature,2020-11-25 12:33:03 +0000 UTC,leppaott,Opened,,"`docker-compose --env-file=.env --env-file=.custom_env up -d
`
Doesn't seem to work but docker-run takes in multiple --env-file? I'd like to merge two env files and now only option seems to be: to include all variables in one env file.",,,elovin,"
--
This would be a very useful feature, because if you have multiple docker-compose files you might want to have some development only env variables to extend/overwrite the env variables for the base `docker-compose` file. 

E.g. I expose some ports in the `docker-compose.dev.yml` that are used for debugging, I would like to make them configurable through env variables defined in a `.dev.env` file.

@leppaott
I'm using `export $(xargs <  .dev.env) ` before running docker-compose up, take a look at [this](https://stackoverflow.com/questions/19331497/set-environment-variables-from-file-of-key-value-pairs) stackoverflow question.
This can however only extend the environment variables from the --env-file file since it runs before docker-compose, so it can not be used to overwrite environment variables. 
--
",,,,,,,,,,
7849,OPEN,"docker.errors.DockerException: Credentials store error: StoreError('Unexpected OS error ""Access is denied""; errno=13')",,2020-10-05 16:10:28 +0000 UTC,KRDMTech,In progress,,"After updating to 2.4.0.0 
When I run docker-compose inside of Visual Studio 2019. I get this error.

Severity	Code	Description	Project	File	Line	Suppression State
Error	DT1001	docker.errors.DockerException: Credentials store error: StoreError('Unexpected OS error ""Access is denied"", errno=13')
If the error persists, try restarting Docker Desktop.	docker-compose	C:\Program Files (x86)\Microsoft Visual Studio\2019\Enterprise\MSBuild\Sdks\Microsoft.Docker.Sdk\build\Microsoft.VisualStudio.Docker.Compose.targets	385	

<!--
Please, check https://docs.docker.com/docker-for-windows/troubleshoot/.
Issues without logs and details cannot be debugged, and will be closed.

Issues unrelated to Docker Desktop will be closed.  In particular, see
  - https://github.com/moby/moby/issues for Docker daemon, e.g. running on Windows Server with Docker EE
  - https://github.com/docker/compose/issues for docker-compose
  - https://github.com/docker/machine/issues for docker-machine
  - https://github.com/docker/docker.github.io/issues for the documentation
-->

<!-- Click these checkboxes after submitting. -->
<!-- Download Docker Desktop 'Edge' (latest build) here: https://hub.docker.com/editions/community/docker-ce-desktop-windows -->
  - [x] I have tried with the latest version of my channel (Stable or Edge)
  - [x] I have uploaded Diagnostics
  - Diagnostics ID: 4E2B37E9-2801-4AD2-BF65-8C141ADC66E4/20201002185449

",,,stephen,"
--
Does it work outside Visual Studio?
--

--
Thanks. The stack trace shows that this is a docker compose error, so I'm going to move this ticket into the compose repository.
--
",KRDMTech,"
--
I opened a command prompt, went into the project folder and ran docker-compose up. These are the results (same error)

Creating network ""blah"" with driver ""bridge""
Building fakeproject
Traceback (most recent call last):
  File ""site-packages\docker\credentials\store.py"", line 80, in _execute
  File ""subprocess.py"", line 395, in check_output
  File ""subprocess.py"", line 472, in run
  File ""subprocess.py"", line 775, in __init__
  File ""subprocess.py"", line 1178, in _execute_child
PermissionError: [WinError 5] Access is denied

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""docker-compose"", line 3, in <module>
  File ""compose\cli\main.py"", line 67, in main
  File ""compose\cli\main.py"", line 126, in perform_command
  File ""compose\cli\main.py"", line 1070, in up
  File ""compose\cli\main.py"", line 1066, in up
  File ""compose\project.py"", line 615, in up
  File ""compose\service.py"", line 362, in ensure_image_exists
  File ""compose\service.py"", line 1125, in build
  File ""site-packages\docker\api\build.py"", line 261, in build
  File ""site-packages\docker\api\build.py"", line 308, in _set_auth_headers
  File ""site-packages\docker\auth.py"", line 302, in get_all_credentials
  File ""site-packages\docker\credentials\store.py"", line 71, in list
  File ""site-packages\docker\credentials\store.py"", line 104, in _execute
docker.credentials.errors.StoreError: Unexpected OS error ""Access is denied"", errno=13
[212420] Failed to execute script docker-compose
--
",,,,,,,,
7842,OPEN,stacktrace using buildkit,kind/bug,2020-10-02 15:55:47 +0000 UTC,xenoterracide,Opened,,"## Description of the issue

```
#11 [stage-1 2/2] COPY --from=builder /usr/local/share/postgresql/extension/...
#11 DONE 0.3s
[3163] Failed to execute script docker-compose
Traceback (most recent call last):
  File ""bin/docker-compose"", line 3, in <module>
  File ""compose/cli/main.py"", line 67, in main
  File ""compose/cli/main.py"", line 126, in perform_command
  File ""compose/cli/main.py"", line 1070, in up
  File ""compose/cli/main.py"", line 1066, in up
  File ""compose/project.py"", line 615, in up
  File ""compose/service.py"", line 362, in ensure_image_exists
  File ""compose/service.py"", line 1129, in build
  File ""compose/progress_stream.py"", line 22, in stream_output
  File ""compose/utils.py"", line 50, in split_buffer
  File ""compose/utils.py"", line 26, in stream_as_text
  File ""compose/service.py"", line 1876, in build
IndexError: list index out of range
Error: Process completed with exit code 255
```


## Context information (for bug reports)

```
docker-compose version 1.27.3, build 4092ae5d
Docker version 19.03.12+azure, build 0ed913b885c8919944a2e4c8d0b80a318a8dd48b
services:
  db:
    build:
      context: /home/runner/work/services/services/postgres
    environment:
      POSTGRES_DB: production
      POSTGRES_PASSWORD: DontUseThisPassword
      POSTGRES_USER: postgres
    image: cloud-stack/postgres:latest
    networks:
      default:
        aliases:
        - db.host
    ports:
    - 5432:5432/tcp
  liquibase:
    build:
      context: /home/runner/work/services/services/migrations/liquibase
    depends_on:
      db:
        condition: service_started
    environment:
      DB_HOST: db.host
      DB_PASSWORD: DontUseThisPassword
      DB_USERNAME: postgres
      LIQUIBASE_CONTEXTS: test
    image: cloud-stack/service-db-main-migration:latest
    networks:
      default: null
    volumes:
    - /home/runner/work/services/services/migrations/liquibase/changelog:/liquibase/changelog:rw
  rabbitmq:
    build:
      context: /home/runner/work/services/services/rabbitmq
    environment:
      RABBITMQ_DEFAULT_PASS: HoppingDownTheBunnyTrail
      RABBITMQ_DEFAULT_USER: PeterCottontail
    image: cloud-stack/rabbitmq:latest
    networks:
      default:
        aliases:
        - rabbitmq.host
    ports:
    - 1883:1883/tcp
    - 5672:5672/tcp
    - 15672:15672/tcp
version: '3.7'
```

## Additional information

OS version / distribution, `docker-compose` install method, etc.
```
Linux fv-az184 5.4.0-1025-azure #25~18.04.1-Ubuntu SMP Sat Sep 5 15:28:57 UTC 2020 x86_64 x86_64 x86_64 GNU/Linux
```

this is running in a github workflow, here's the relevant workflow information

```yaml
name: Main
on:
  schedule:
    - cron: '0 6 * * *'
  push:
jobs:
  build-postgres:
    runs-on: ubuntu-latest
    timeout-minutes: 2
    steps:
      - uses: actions/checkout@v2
        with:
          fetch-depth: 0
      - uses: docker/setup-buildx-action@v1
        with:
          install: true
      - uses: actions/cache@v2
        with:
          path: /tmp/.buildx-cache
          key: ${{ runner.os }}-buildx-${{ github.sha }}
          restore-keys: |
            ${{ runner.os }}-buildx-
      - uses: ./.github/actions/git-short-ref
        id: ref
      - uses: aws-actions/configure-aws-credentials@v1
        with:
          aws-access-key-id: ${{ secrets.ECR_AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.ECR_AWS_SECRET_ACCESS_KEY }}
          aws-region: us-east-1
      - uses: aws-actions/amazon-ecr-login@v1
        id: login-ecr
      - uses: docker/build-push-action@v2
        with:
          context: postgres
          file: postgres/Dockerfile
          push: true
          tags: ${{ steps.login-ecr.outputs.registry }}/cloud-stack/postgres:${{ steps.ref.outputs.ref }}
          cache-from: type=local,src=/tmp/.buildx-cache
          cache-to: type=local,dest=/tmp/.buildx-cache
      - name: Slack Notification
        uses: rtCamp/action-slack-notify@master
        if: failure() && !contains( github.ref, 'feature' )
        env:
          SLACK_COLOR: '#ff0000'
          SLACK_TITLE: You have failed this project!
          SLACK_WEBHOOK: ${{ secrets.SLACK_DEV_NOTIFICATIONS_WEBHOOK }}

  build-migrations:
    runs-on: ubuntu-latest
    timeout-minutes: 5
    steps:
      - uses: actions/checkout@v2
        with:
          fetch-depth: 0
      - uses: docker/setup-buildx-action@v1
        with:
          install: true
      - uses: actions/cache@v2
        with:
          path: /tmp/.buildx-cache
          key: ${{ runner.os }}-buildx-${{ github.sha }}
          restore-keys: |
            ${{ runner.os }}-buildx-
      - uses: docker/build-push-action@v2
        with:
          context: migrations/liquibase
          file: migrations/liquibase/Dockerfile
          tags: cloud-stack/service-db-migrations:latest
          cache-from: type=local,src=/tmp/.buildx-cache
          cache-to: type=local,dest=/tmp/.buildx-cache
      - name: Slack Notification
        uses: rtCamp/action-slack-notify@master
        if: failure() && !contains( github.ref, 'feature' )
        env:
          SLACK_COLOR: '#ff0000'
          SLACK_TITLE: You have failed this project!
          SLACK_WEBHOOK: ${{ secrets.SLACK_DEV_NOTIFICATIONS_WEBHOOK }}

  test-migrations:
    needs: [build-postgres, build-migrations]
    runs-on: ubuntu-latest
    timeout-minutes: 5
    steps:
      - uses: actions/checkout@v2
        with:
          fetch-depth: 0
      - uses: docker/setup-buildx-action@v1
        with:
          install: true
      - uses: actions/cache@v2
        with:
          path: /tmp/.buildx-cache
          key: ${{ runner.os }}-buildx-${{ github.sha }}
          restore-keys: |
            ${{ runner.os }}-buildx-
      - run: docker-compose --version && docker --version && docker-compose config
      - run: docker-compose up db liquibase
        env:
          COMPOSE_DOCKER_CLI_BUILD: 1
          DOCKER_BUILDKIT: 1
      - run: cd migrations/test && docker-compose up
      - name: Slack Notification
        uses: rtCamp/action-slack-notify@master
        if: failure() && !contains( github.ref, 'feature' )
        env:
          SLACK_COLOR: '#ff0000'
          SLACK_TITLE: You have failed this project!
          SLACK_WEBHOOK: ${{ secrets.SLACK_DEV_NOTIFICATIONS_WEBHOOK }}
```

and docker files

```Dockerfile
FROM postgis/postgis:11-2.5-alpine AS builder
ENV PGTAP_VERSION '1.1.0'
RUN apk add --update-cache build-base git perl
RUN git clone https://github.com/theory/pgtap.git
WORKDIR pgtap
RUN git checkout v$PGTAP_VERSION
RUN make
RUN make install

FROM postgis/postgis:11-2.5-alpine
ENV DEST /usr/local/share/postgresql/extension/
COPY --from=builder $DEST $DEST
ENTRYPOINT [""docker-entrypoint.sh""]

EXPOSE 5432
CMD [""postgres""]

HEALTHCHECK --interval=30s --timeout=30s --start-period=5s --retries=3 CMD [ ""pg_isready"", ""--host=localhost"", ""--username=postgres"", ""--dbname=production"" ]
```
```Dockerfile
FROM alpine:latest AS waitforit
RUN apk add wget
RUN mkdir /root/src
WORKDIR /root/src
RUN wget --quiet https://raw.githubusercontent.com/vishnubob/wait-for-it/master/wait-for-it.sh
RUN chmod +x wait-for-it.sh

FROM liquibase/liquibase:latest
USER root
ENV DB_PORT=5432
ENV DB_HOST=
ENV LIQUIBASE_LOG_LEVEL=info
ENV LIQUIBASE_CONTEXTS=
RUN apt-get update && apt-get install -y postgresql-client && rm -rf /var/lib/apt/lists/*
COPY --from=waitforit /root/src /liquibase
COPY entrypoint.sh /
COPY changelog /liquibase/changelog
USER liquibase
ENTRYPOINT [ ""/entrypoint.sh"" ]
```

sorry that this is probably more information than a minimal reproduction, hopefully you can reproduce.",,,,,,,,,,,,,,
7841,OPEN,try pull first,kind/feature,2020-09-30 19:36:01 +0000 UTC,xenoterracide,Opened,,"Problem: I have base images that I want to pull in 1 context (CI), but want to build in another (localdev)

Here's what I'm thinking

```Dockerfile
FROM ${IMAGE} AS main
ENV DB_PORT=5432
ENV DB_HOST=
ENV LIQUIBASE_LOG_LEVEL=info
ENV LIQUIBASE_CONTEXTS=
COPY entrypoint.sh /
COPY changelog /liquibase/changelog
ENTRYPOINT [ ""/entrypoint.sh"" ]
```

```yaml
&liquibase_image: myorg/image:latest
images:
   liquibase:
      image: *liquibase_image
      build: ...  # same things as what's in services
      pull_first: true
services:
  liquibase:
    build:
      context: ./migrations/liquibase
      args:
        IMAGE: *liquibase-image
      target: main
    image: cloud-stack/migration:latest
```
     
",,,,,,,,,,,,,,
7839,OPEN,Breaking Changes: Internal/External Secrets and Name/Label Problems with External Secrets,kind/bug,2020-10-08 16:12:03 +0000 UTC,jamiejackson,Opened,,"# Description of the issue

### Part 1: External secret clashes with `name` and `label`

Something in the last week or two (docker or docker-compose updates, presumably) has broken my secrets configuration. (Update: It seems that docker-compose version 1.27.0 introduced the problem. Things work up to 1.26.3.)

Because secrets management is awkward with docker-compose (https://github.com/moby/moby/issues/29882) I've had a successful workaround which uses tooling to inspect the compose files and handles of renaming secrets, at deploy time, if their content changes. It's convoluted, but it works great. I don't have to jump through hoops and change compose files in source control when secrets change. I know of other folks in the wild who have similar workarounds.

It is based on a compose file that looks something like this:

```yaml
# docker-compose.yml
version: '3.6'

services:

  myservice:
    image: alpine
    secrets:
      - source: credentials
        target: credentials.json

secrets:
  credentials:
    # my workaround plumbing preprocesses this metadata to create an external secret whose name is based on the secret value

    # a dynamic name is crucial. the env var is supplied later
    name: credentials-${SECRET_SUM_credentials:-0}

    # my workaround plumbing sets this external variable, so yeah, it's external
    external: true

    # my workaround plumbing uses this metadata
    labels:
      # secret name in AWS
      name: ""/secret/env/main_cms/${CREDENTIALS_ENV:-CREDENTIALS_ENV}/e2e/credentials""
      # this secret happens to come from parameter store, versus secrets manager
      store: ""ssmps""
```

What happens now:

```
$ docker-compose -f docker-compose.yml config
ERROR: Secret credentials declared as external but specifies additional attributes (name, labels).
$ docker-compose -f docker-compose.yml  up
ERROR: Secret credentials declared as external but specifies additional attributes (name, labels).
```

Assuming that this is the breaking change I suspect it is, is there a workaround? A breaking change would be really bad news for us. Please, oh please, don't take away this morsel of extensibility away from the community.

### Part 2: Secret `external` flag not overriding with `true` properly

Here's a second thing that is acting differently. I would expect that if the following compose file were to be layered on top of the one, above, that it would no longer be an external secret. We use this sort of thing for local development, where the secret is just file-based (instead of coming from AWS).

```yaml
# docker-compose-local.yml
version: '3.6'
    
secrets:
  credentials:
    name: credentials-${SECRET_SUM_credentials:-0}
    file: ../support/local_credentials.json
    # i would expect this to override the previous compose and make the secret ""not-external""
    external: false
```

However:

```
$ docker-compose -f docker-compose.yml -f docker-compose-local.yml config
ERROR: Secret credentials declared as external but specifies additional attributes (name, labels).
$ docker-compose -f docker-compose.yml -f docker-compose-local.yml up
ERROR: Secret credentials declared as external but specifies additional attributes (name, labels).
```

Even if you're a hard-liner against ""part 1,"" I think you'd have to agree that ""part 2"" is a bug.

Both of these problems started happening at the same time.

## Context information (for bug reports)

**Output of `docker-compose version`**
```
docker-compose --version
docker-compose version 1.27.2, build 18f557f9
```

**Output of `docker version`**
```
Client: Docker Engine - Community
 Azure integration  0.1.15
 Version:           19.03.12
 API version:       1.40
 Go version:        go1.13.10
 Git commit:        48a66213fe
 Built:             Mon Jun 22 15:41:33 2020
 OS/Arch:           darwin/amd64
 Experimental:      false

Server: Docker Engine - Community
 Engine:
  Version:          19.03.12
  API version:      1.40 (minimum version 1.12)
  Go version:       go1.13.10
  Git commit:       48a66213fe
  Built:            Mon Jun 22 15:49:27 2020
  OS/Arch:          linux/amd64
  Experimental:     false
 containerd:
  Version:          v1.2.13
  GitCommit:        7ad184331fa3e55e52b890ea95e65ba581ae3429
 runc:
  Version:          1.0.0-rc10
  GitCommit:        dc9208a3303feef5b3839f4323d9beb36df0a9dd
 docker-init:
  Version:          0.18.0
  GitCommit:        fec3683
```

**Output of `docker-compose config`**

See description.

## Steps to reproduce the issue

See description.

### Observed result

See description.

### Expected result

### Stacktrace / full error message

N/A

## Additional information

Docker Desktop 2.3.0.5 on Mac Catalina 10.15.6
",,,,,,,,,,,,,,
7838,OPEN,Compose treats file as directory when using a remote docker daemon,kind/bug,2021-01-15 18:29:42 +0000 UTC,titiyoyo,In progress,,"3. When making a bug report, make sure you provide all required information. The easier it is for
   maintainers to reproduce, the faster it'll be fixed.
-->

## Description of the issue
When using a remote docker daemon, compose treats file as directory, leading to failure in building container.
No such problem when using a local daemon.

## Context information (for bug reports)

docker-compose.yml
```
version: '3'
services:
    web:
        build:
            context: ./docker/nginx
        ports:
            - ""8888:80""
        volumes:
            - ./docker/nginx/symfony.conf:/etc/nginx/conf.d/default.conf
```

./docker/nginx/symfony.conf
```
server {
    listen 80;
    server_name web;
    root /var/www/myapp/www;

    location / {
        # try to serve file directly, fallback to index.php
        try_files $uri /index.php$is_args$args;
    }

    location ~ ^/index\.php(/|$) {
        #fastcgi_pass unix:/var/run/php7.2-fpm.sock;
        fastcgi_pass php:9000;
        fastcgi_split_path_info ^(.+\.php)(/.*)$;
        include fastcgi_params;
        fastcgi_param SCRIPT_FILENAME $realpath_root$fastcgi_script_name;
        fastcgi_param DOCUMENT_ROOT $realpath_root;
        fastcgi_buffer_size 128k;
        fastcgi_buffers 4 256k;
        fastcgi_busy_buffers_size 256k;
        internal;
    }

    location ~ \.php$ {
        return 404;
    }

    error_log /var/log/nginx/project_error.log;
    access_log /var/log/nginx/project_access.log;
}
```

Shell Variables
```
DOCKER_HOST=tcp://192.168.1.1:2376
DOCKER_TLS_VERIFY=1
```

**Output of `docker-compose version`**
```
docker-compose version 1.26.2, build eefe0d31
docker-py version: 4.2.2
CPython version: 3.7.7
OpenSSL version: OpenSSL 1.1.1g  21 Apr 2020
```

**Output of `docker version`**
```
Client: Docker Engine - Community
 Version:           19.03.12
 API version:       1.40
 Go version:        go1.13.10
 Git commit:        48a66213fe
 Built:             Mon Jun 22 15:41:33 2020
 OS/Arch:           darwin/amd64
 Experimental:      false

Server: Docker Engine - Community
 Engine:
  Version:          19.03.12
  API version:      1.40 (minimum version 1.12)
  Go version:       go1.13.10
  Git commit:       48a66213fe
  Built:            Mon Jun 22 15:44:21 2020
  OS/Arch:          linux/amd64
  Experimental:     false
 containerd:
  Version:          1.2.13
  GitCommit:        7ad184331fa3e55e52b890ea95e65ba581ae3429
 runc:
  Version:          1.0.0-rc10
  GitCommit:        dc9208a3303feef5b3839f4323d9beb36df0a9dd
 docker-init:
  Version:          0.18.0
  GitCommit:        fec3683
```

## Steps to reproduce the issue

1. setup a remote docker daemon
2. create `docker-compose` file along with `symfony.conf` file
3. `docker-compose up --build -d`

### Observed result
Error, not building container, stack down

### Expected result
stack up, container built

### Stacktrace / full error message

```
Recreating 5c4df28e297f_atlas-contrib_web_1 ... error

ERROR: for 5c4df28e297f_atlas-contrib_web_1  Cannot start service web: OCI runtime create failed: container_linux.go:349: starting container process caused ""process_linux.go:449: container init caused \""rootfs_linux.go:58: mounting \\\""/Users/myself/Sites/myapp/docker/nginx/symfony.conf\\\"" to rootfs \\\""/var/lib/docker/overlay2/dd9cbb1e25c6f2b29ffebc3dd18e0709acec8d78d858d3676f0ff12bebb038cc/merged\\\"" at \\\""/var/lib/docker/overlay2/dd9cbb1e25c6f2b29ffebc3dd18e0709acec8d78d858d3676f0ff12bebb038cc/merged/etc/nginx/conf.d/default.conf\\\"" caused \\\""not a directory\\\""\"""": unknown: Are you trying to mount a directory onto a file (or vice-versa)? Check if the specified host path exists and is the expected type

ERROR: for web  Cannot start service web: OCI runtime create failed: container_linux.go:349: starting container process caused ""process_linux.go:449: container init caused \""rootfs_linux.go:58: mounting \\\""/Users/myself/Sites/myapp/docker/nginx/symfony.conf\\\"" to rootfs \\\""/var/lib/docker/overlay2/dd9cbb1e25c6f2b29ffebc3dd18e0709acec8d78d858d3676f0ff12bebb038cc/merged\\\"" at \\\""/var/lib/docker/overlay2/dd9cbb1e25c6f2b29ffebc3dd18e0709acec8d78d858d3676f0ff12bebb038cc/merged/etc/nginx/conf.d/default.conf\\\"" caused \\\""not a directory\\\""\"""": unknown: Are you trying to mount a directory onto a file (or vice-versa)? Check if the specified host path exists and is the expected type
ERROR: Encountered errors while bringing up the project.
```

## Additional information

Docker daemon host: debian 10, latest version
Docker client host: mac os 10.15.6

",,,titiyoyo,"
--
Any news on the matter ?
--
",mattsoftware,"
--
This is a blocker for me. Had to downgrade to docker desktop 2.3.0.5 (mac osx). My error was slightly different...

```ERROR: for xxxx-lb_1  Cannot start service lb: error while creating mount source path '/host_mnt/Users/xxx/lb/default.conf': mkdir /host_mnt/Users/xxx/lb/default.conf: file exists```
--
",OJFord,"
--
The problem is that the path is being expanded to an absolute one on the client machine; and then doesn't exist (at least, I assume you don't have a `/Users` dir on Debian) on the remote.

Thus, a workaround is to replace `- ./...` volumes with an absolute path, that on the remote machine, e.g. `- /home/xxx/lb/...`.

(Maybe change the title to something like 'Relative path volumes don't work with a remote docker daemon'.)
--
",,,,,,
7834,OPEN,docker-compose cannot mount secrets,,2020-09-30 13:32:24 +0000 UTC,pmishev,In progress,,"### Expected behavior

Mounting secret file with no errors (as it does in Ubuntu)

### Actual behavior

Error: `Cannot create container for service db: invalid mount config for type ""bind"": bind source path does not exist`

### Information

Fresh install of docker (factory settings).

  - macOS Version: Catalina 10.15.7 (19H2)
  - Docker 2.3.0.5 (48029)
  - Compose 1.27.2

### Steps to reproduce the behavior

1. create dir `testproject` with 2 files in it:
- docker-compose.yml:
```
version: '3.8'

services:
    db:
        image: mariadb:10.5.4
        environment:
            MYSQL_DATABASE: test
            MYSQL_USER: test
            MYSQL_PASSWORD_FILE: /run/secrets/db_password
        secrets:
            - db_password

secrets:
    db_password:
        file: ./db_password.secret
```
- db_password.secret:
```
test
```

2. run `docker-compose up`
```
Creating testproject_db_1 ... error

ERROR: for testproject_db_1  Cannot create container for service db: invalid mount config for type ""bind"": bind source path does not exist: /Users/plamen/testproject/db_password.secret

ERROR: for db  Cannot create container for service db: invalid mount config for type ""bind"": bind source path does not exist: /Users/plamen/testproject/db_password.secret
ERROR: Encountered errors while bringing up the project.
```",,,jamiejackson,"
--
Because someone else will probably ask this: What does this give?

```
ls -l /Users/plamen/testproject/db_password.secret
```
--

--
Just for a sanity check, it works for me (well, after adding `MYSQL_ALLOW_EMPTY_PASSWORD: 1`).

MacOS 10.15.6

Docker Desktop 2.3.0.5

```
Client: Docker Engine - Community
 Azure integration  0.1.15
 Version:           19.03.12
 API version:       1.40
 Go version:        go1.13.10
 Git commit:        48a66213fe
 Built:             Mon Jun 22 15:41:33 2020
 OS/Arch:           darwin/amd64
 Experimental:      false

Server: Docker Engine - Community
 Engine:
  Version:          19.03.12
  API version:      1.40 (minimum version 1.12)
  Go version:       go1.13.10
  Git commit:       48a66213fe
  Built:            Mon Jun 22 15:49:27 2020
  OS/Arch:          linux/amd64
  Experimental:     false
 containerd:
  Version:          v1.2.13
  GitCommit:        7ad184331fa3e55e52b890ea95e65ba581ae3429
 runc:
  Version:          1.0.0-rc10
  GitCommit:        dc9208a3303feef5b3839f4323d9beb36df0a9dd
 docker-init:
  Version:          0.18.0
  GitCommit:        fec3683
```
docker-compose version 1.27.2, build 18f557f9


--
",pmishev,"
--
```
  testproject ls -l /Users/plamen/testproject/db_password.secret
-rw-r--r--  1 plamen  staff  5 27 Sep 11:53 /Users/plamen/testproject/db_password.secret
  testproject cat /Users/plamen/testproject/db_password.secret
test
```
--
",,,,,,,,
7832,OPEN,Environment variable validation not handling ambiguous duplicate entries (array style),kind/bug,2020-09-28 13:38:10 +0000 UTC,burl,Opened,,"3. When making a bug report, make sure you provide all required information. The easier it is for
   maintainers to reproduce, the faster it'll be fixed.
-->

## Description of the issue

when in a service, the 'environment' (of the ""list"" form) contains duplicate variables, the apparent validation does not seem to do what it should.  It seems that if there is validation of the names and values that duplicate names should not be allowed.  However, if an entry is listed twice with the same value, then that is not flagged as an error.  However, if the same variable name is listed twice with different values, then that does result in an error.  It seems that both should be errors.

## Context information (for bug reports)

**Output of `docker-compose version`**
```
docker-compose version 1.27.2, build 18f557f9
docker-py version: 4.3.1
CPython version: 3.7.7
OpenSSL version: OpenSSL 1.1.1g  21 Apr 2020
```

**Output of `docker version`**
```
Client: Docker Engine - Community
 Azure integration  0.1.15
 Version:           19.03.12
 API version:       1.40
 Go version:        go1.13.10
 Git commit:        48a66213fe
 Built:             Mon Jun 22 15:41:33 2020
 OS/Arch:           darwin/amd64
 Experimental:      false

Server: Docker Engine - Community
 Engine:
  Version:          19.03.12
  API version:      1.40 (minimum version 1.12)
  Go version:       go1.13.10
  Git commit:       48a66213fe
  Built:            Mon Jun 22 15:49:27 2020
  OS/Arch:          linux/amd64
  Experimental:     false
 containerd:
  Version:          v1.2.13
  GitCommit:        7ad184331fa3e55e52b890ea95e65ba581ae3429
 runc:
  Version:          1.0.0-rc10
  GitCommit:        dc9208a3303feef5b3839f4323d9beb36df0a9dd
 docker-init:
  Version:          0.18.0
  GitCommit:        fec3683
```

**Output of `docker-compose config`**
(Make sure to add the relevant `-f` and other flags)
```
ERROR: The Compose file './docker-compose.yaml' is invalid because:
services.foo.environment contains non-unique items, please remove duplicates from ['FOO=bar', 'BAR=baz', 'FOO=bar']
```


## Steps to reproduce the issue

This will result in an error because 'FOO' is listed twice with a differnt value:

```yaml
version: '3.5'
  services:
    foo:
      image: alpine
      environment:
       - FOO=bar
       - BAR=baz
       - FOO=hork
```

But, this will not result in an error.  Foo is listed twice with the same value:

```yaml
version: '3.5'
  services:
    foo:
      image: alpine
      environment:
       - FOO=bar
       - BAR=baz
       - FOO=bar
```

### Observed result

Duplicate named variables are allowed when the values are the same in each instance.  But not allowed when the values are different. 

### Expected result

I expect validation on the variables to consider only the names of the variables and when there are duplicate names listed in the same 'environment:' object (in ""list mode"") of the same yaml document, then that should at least be a warning, if not an error.

### Stacktrace / full error message

```
(paste here)
```

## Additional information

OS version / distribution, `docker-compose` install method, etc.
",,,,,,,,,,,,,,
7831,OPEN,Cannot set empty file attribute on external secret in 1.27.x,kind/bug,2020-09-25 17:29:37 +0000 UTC,kinghuang,Opened,,"## Description of the issue

With Docker Compose 1.27.x, I cannot declare an external secret with an empty file attribute. It produces an error. Docker Compose 1.26 and earlier allowed this.

## Context information (for bug reports)

**Output of `docker-compose version`**
```
docker-compose version 1.27.2, build 18f557f9
docker-py version: 4.3.1
CPython version: 3.7.7
OpenSSL version: OpenSSL 1.1.1g  21 Apr 2020
```

**Output of `docker version`**
```
Client: Docker Engine - Community
 Version:           19.03.13-beta2
 API version:       1.40
 Go version:        go1.13.14
 Git commit:        ff3fbc9d55
 Built:             Mon Aug  3 14:58:48 2020
 OS/Arch:           darwin/amd64
 Experimental:      true
Server: Docker Engine - Community
 Engine:
  Version:          19.03.13-beta2
  API version:      1.40 (minimum version 1.12)
  Go version:       go1.13.14
  Git commit:       ff3fbc9d55
  Built:            Mon Aug  3 15:06:50 2020
  OS/Arch:          linux/amd64
  Experimental:     true
 containerd:  Version:          v1.2.13
  GitCommit:        7ad184331fa3e55e52b890ea95e65ba581ae3429  Version:          1.0.0-rc10
  GitCommit:        dc9208a3303feef5b3839f4323d9beb36df0a9dd
 docker-init:
  Version:          0.18.0
  GitCommit:        fec3683
```

**Output of `docker-compose config`**
(Make sure to add the relevant `-f` and other flags)
```
ERROR: Secret docker-api-ca declared as external but specifies additional attributes (name, file).
```

## Steps to reproduce the issue

I have Compose files with parameterized secrets like this example.

```yaml
secrets:
  docker-api-ca:
    external: $DOCKER_API_TLS_EXTERNAL
    name: $DOCKER_API_TLS_CA_NAME
    file: $DOCKER_API_TLS_CA_FILE
```

With Docker Compose 1.26 and earlier, I can set `DOCKER_API_TLS_EXTERNAL=true` and `DOCKER_API_TLS_CA_FILE=` (an empty value), and it will accept the configuration. With Docker Compose 1.27, it raises an error.

### Observed result

```
 traefik-1 git:(traefik-1)  docker-compose config
ERROR: Secret docker-api-ca declared as external but specifies additional attributes (name, file).
```

### Expected result

Be able to generate a config with an external secret.

### Stacktrace / full error message

```
ERROR: Secret docker-api-ca declared as external but specifies additional attributes (name, file).
```

## Additional information

Using Docker Desktop 2.3.7.0 (48173) on macOS 10.14.6.
",,,,,,,,,,,,,,
7794,OPEN,Support nested parameter expansion,kind/feature,2020-09-25 02:30:52 +0000 UTC,MarilynFranklin,Opened,,"-->

**Is your feature request related to a problem? Please describe.**
I've come across several instances at work where I've wanted to use nested parameter expansion to provide an alternative value if an environment variable isn't set, but this isn't currently supported.

For example, hard coded default values for parameter expansion are supported (`${FOO:-bar}`) but I can't use another environment variable as the default (`${FOO:-$BAR}`)

**Describe the solution you'd like**
I would like to use nested parameter expansion in docker-config.yml files:

```
${FOO:-$BAR}
```

**Describe alternatives you've considered**
For now, I'm hard coding default values.",,,,,,,,,,,,,,
7793,OPEN,Apparent errors in docker-compose JSON Schema,kind/bug,2020-09-24 15:23:59 +0000 UTC,myitcv,Opened,,"## Description of the issue

I believe there are a couple of errors in the current version of the JSON Schema specification of the `docker-compose` format: https://github.com/docker/compose/blob/a24843e1e4ffda8c94eb8cefd5605a8973483b8a/compose/config/config_schema_compose_spec.json

Firstly, the following usage of `uniqueItems` appear to be incorrectly declared as a field on the `items` object as opposed to the containing object which has a field `""type"": ""array""`:

https://github.com/docker/compose/blob/a24843e1e4ffda8c94eb8cefd5605a8973483b8a/compose/config/config_schema_compose_spec.json#L429

Reference: https://json-schema.org/draft/2019-09/json-schema-validation.html#rfc.section.6.4

Secondly, the following usage of `patternProperties` appears to be invalid for the specification of a field of type `array`:

https://github.com/docker/compose/blob/a24843e1e4ffda8c94eb8cefd5605a8973483b8a/compose/config/config_schema_compose_spec.json#L613

because arrays are numerically indexed and cannot have additional or pattern properties. ",,,,,,,,,,,,,,
7791,OPEN,Mounting is failing with wsl2,kind/question,2021-01-14 19:39:18 +0000 UTC,giorgos321,Opened,,"Hi I am using docker-compose on Win 10 with WSL2 and ubuntu 20.04 distro
I'am trying to mount the volume but it keeps failing and I don't know why,

I use docker-compose up and I get:
<------------------------------LOG START------------------------------------------>
Creating network ""backend_default"" with the default driver
Creating volume ""backend_mongo-data"" with default driver
Creating backend_mongo_1 ... error
Creating backend_s3_1    ...

ERROR: for backend_mongo_1  Cannot start service mongo: error while mounting volume '/var/lib/docker/volumes/backend_mongo-data/_data': failed to mount local volume: mount /c/Users/hrthe/Desktop/aluplast-data/db:/var/lib/docker/volumes/backCreating backend_s3_1    ... done

ERROR: for mongo  Cannot start service mongo: error while mounting volume '/var/lib/docker/volumes/backend_mongo-data/_data': failed to mount local volume: mount /c/Users/hrthe/Desktop/aluplast-data/db:/var/lib/docker/volumes/backend_mongo-data/_data, flags: 0x1000: no such file or directory
ERROR: Encountered errors while bringing up the project.
<--------------------------------LOG END------------------------------------------>

My sysinfo:

Client:
 Debug Mode: false

Server:
 Containers: 3
  Running: 1
  Paused: 0
  Stopped: 2
 Images: 20
 Server Version: 19.03.12
 Storage Driver: overlay2
  Backing Filesystem: extfs
  Supports d_type: true
  Native Overlay Diff: true
 Logging Driver: json-file
 Cgroup Driver: cgroupfs
 Plugins:
  Volume: local
  Network: bridge host ipvlan macvlan null overlay
  Log: awslogs fluentd gcplogs gelf journald json-file local logentries splunk syslog
 Swarm: inactive
 Runtimes: runc
 Default Runtime: runc
 Init Binary: docker-init
 containerd version: 7ad184331fa3e55e52b890ea95e65ba581ae3429
 runc version: dc9208a3303feef5b3839f4323d9beb36df0a9dd
 init version: fec3683
 Security Options:
  seccomp
   Profile: default
 Kernel Version: 4.19.128-microsoft-standard
 Operating System: Docker Desktop
 OSType: linux
 Architecture: x86_64
 CPUs: 6
 Total Memory: 6.072GiB
 Name: docker-desktop
 ID: XGKG:Y6DR:KF2O:Y4BY:D2AG:LSHK:BG6J:PUXP:3VZY:EDFB:2DSL:STNT
 Docker Root Dir: /var/lib/docker
 Debug Mode: true
  File Descriptors: 50
  Goroutines: 64
  System Time: 2020-09-24T13:12:47.8022126Z
  EventsListeners: 3
 Registry: https://index.docker.io/v1/
 Labels:
 Experimental: false
 Insecure Registries:
  127.0.0.0/8
 Live Restore Enabled: false
 Product License: Community Engine

WARNING: bridge-nf-call-iptables is disabled
WARNING: bridge-nf-call-ip6tables is disabled

And the docker-ompose.yml I try to run:

version: ""3.2""
services:
  mongo:
    image: mongo:3.6
    volumes:
      - type: volume
        source: mongo-data
        target: /data/db
        volume:
          nocopy: true
    ports:
      - ""27017:27017""

  s3:
    build: ./s3/
    volumes:
      - /home/user/Desktop/aluplast-data/s3:/fakes3_root
    ports:
      - ""4569:4569""

  node:
    restart: always
    build: .
    command: ""npm run watch-node dist/server.js""
    ports:
      - ""3000:3000""
    environment:
      - MONGODB_URI=mongodb://mongo:27017/aluplast
      - SECRET=yep
      - NODE_ENV=development
      - AWS_ENDPOINT=s3:4569
      - S3_BUCKET_NAME=myaluplast
      - AWS_SECRET_ACCESS_KEY=fake
      - AWS_ACCESS_KEY_ID=alsofake
      - EMAIL_HOST=smtp.zoho.eu
      - EMAIL_USER=test@myaluplast.gr
      - EMAIL_PASSWORD=5NKa7FXkkf8wxlATE9uU
    links:
      - mongo
      - s3
    depends_on:
      - mongo
      - s3
    volumes:
      - ./dist:/files/dist:ro
      - ./emails:/files/emails:ro

volumes:
  mongo-data:
    driver_opts:
      type: none
      device: /c/Users/user/Desktop/aluplast-data/db
      o: bind


I am trying to make it work for the past day",,,tomer,"
--
I have the same issue in macOS after upgrading to docker desktop `2.4.0.0`.

I have a compose file which runs MongoDB using a mounted volume and I got this error:
```
ERROR: for mongo Cannot start service mongo: error while mounting volume '/var/lib/docker/volumes/backend_mongo-data/_data': failed to mount local volume: mount /.../mount/location/:/var/lib/docker/volumes/backend_mongo-data/_data, flags: 0x1000: no such file or directory
ERROR: Encountered errors while bringing up the project.
```

Downgraded to `2.2.0.5` and the issue is gone
--
",chalmagr,"
--
Facing the same issue on 2.5.0.1 (MacOS - Catalina)
![image](https://user-images.githubusercontent.com/4968250/101830085-9e2dc700-3af9-11eb-8af1-2f2f85904ea2.png)
```
Creating network ""mac-issue_default"" with the default driver
Creating volume ""mac-issue_data"" with default driver
Creating mac-issue_service_1 ... error

ERROR: for mac-issue_service_1  Cannot start service service: error while mounting volume '/var/lib/docker/volumes/mac-issue_data/_data': failed to mount local volume: mount /opt/data:/var/lib/docker/volumes/mac-issue_data/_data, flags: 0x1000: no such file or directory

ERROR: for service  Cannot start service service: error while mounting volume '/var/lib/docker/volumes/mac-issue_data/_data': failed to mount local volume: mount /opt/data:/var/lib/docker/volumes/mac-issue_data/_data, flags: 0x1000: no such file or directory
ERROR: Encountered errors while bringing up the project.
```

The issue in my case is happening with a minimal docker-compose.yml is defined as below:

```
version: ""3.8""
services:
  service:
    image: centos:7
    volumes:
      - data:/opt/data
    command:
      - /bin/bash
      - -c
      - sleep 5

volumes:
  data:
    driver_opts:
      type: none
      device: /opt/data
      o: bind
```

But running the same using regular `docker run` works fine
`docker run --rm -it -v /opt/data:/opt/data centos:7 /bin/bash -c ""sleep 5""`

--
",mikazp,"
--
As temporary solution do not declare named volumes, this works for me:
```
version: '3.8'

services:
  test:
    build: .
    volumes:
      - ./:/app
    working_dir: /app
```

instead of
```
...
volumes:
  source:
    driver_opts:
      type: none
      device: .
      o: bind
```


--
",,,,,,
7789,OPEN,ANSI support for when no-tty option is used (-t),kind/feature,2020-09-23 11:09:18 +0000 UTC,gapipro,Opened,,"**Is your feature request related to a problem? Please describe.**
When using docker-compose with -t option (no-tty) there isn't any ANSI color output.  
My use-case is for example when running docker-compose in Intellij Idea as external tool. Output is generated in non-tty enabled console that results in plain colors.

**Describe the solution you'd like**
I would with that there is an option to force --ansi even when no-tty is used.

**Describe alternatives you've considered**
It works ok if output console supports tty, but in other cases there isn't a clear alternative to this, except piping output to temp file and displaying that in output via some other command that supports ansi

",,,,,,,,,,,,,,
7788,OPEN,logs of docker-compose up not real time,kind/bug,2020-09-28 03:31:08 +0000 UTC,anhtu812,In progress,,"if I use ""docker run"" or ""docker-compose run"", logs is real time. When I use ""docker-compose up"", some logs lost and some logs showed after about 15 minutes. I use docker-compose 1.17.1 and my processes in container use c++ code and python code. Please fix this issue, I can not debug with lost logs and delay logs.",,,ulyssessouza,"
--
Could you please test it with the latest version?
--
",anhtu812,"
--
I installed 1.27.4, no change.
--
",,,,,,,,
7785,OPEN,s390x support for docker-compose,kind/feature,2020-09-22 12:45:35 +0000 UTC,Prabhav-Thali,Opened,,"Hello,

Since s390x is already a part of existing [Jenkins CI](https://ci-next.docker.com/public/job/compose/), Will it be possible to release binaries and docker images for s390x architecture?

Note: Currently, docker-compose can be installed successfully using pip on s390x. However, It would be good to have binaries and images for complete support.",,,,,,,,,,,,,,
7780,OPEN,JSON Schema draft 2019-09 requires `$id` to be an absolute URI,,2020-09-20 20:07:55 +0000 UTC,Relequestual,Opened,,"Hi there. Great to see you're using JSON Schema draft 2019-09!
The value of `$id` for draft 2019-09 is required to be an Absolute URI.
The URI must not be expected by others to be network addressable.

Please shout if you have any questions. I work on the JSON Schema specification.

Paging @aiordache as the file author.
For reference:

https://github.com/docker/compose/blob/1ff05ac060b2aaba2b0396d5bccebf80d4543699/compose/config/config_schema_compose_spec.json#L3

",,,,,,,,,,,,,,
7777,OPEN,`docker-compose` unexpectly ran docker-credential-glcoud,kind/question,2020-11-10 06:07:00 +0000 UTC,shockw4ver,In progress,,"**Question**:
How to disable docker-credential-gcloud?

**Description**:
As I ran `docker-compose`, a error reported that CANNOT find command `docker-credential-gcloud`.
Then [I ask the container's team](https://github.com/Requarks/wiki/issues/2468) if this container requires google cloud sdk, but they explained maybe this is a environment problem.
But I never do things about `docker-credential-gcloud`, so how can I disable this using?

**Output**:
```
[31 ms] Start: Resolving remote
[33 ms] Setting up container for folder or workspace: /Users/zhangyongchao/selfspace/wiki.js/wiki

[34 ms] Start: Check Docker is running
[34 ms] Start: Run: docker info
[147 ms] Start: Run: docker-compose version --short
[596 ms] Start: Run: docker ps -q -a --filter label=com.docker.compose.project=containers --filter label=com.docker.compose.service=wiki
[640 ms] Start: Run: docker-compose -f /Users/zhangyongchao/selfspace/wiki.js/wiki/dev/containers/docker-compose.yml config --services
[1097 ms] db
adminer
wiki
[1097 ms] 
[1098 ms] Start: Run: docker events --format {{json .}} --filter status=start
[1103 ms] Start: Run: docker-compose --project-name containers -f /Users/zhangyongchao/selfspace/wiki.js/wiki/dev/containers/docker-compose.yml up -d --build
Building wiki
Traceback (most recent call last):
  File ""/Library/Frameworks/Python.framework/Versions/3.7/bin/docker-compose"", line 10, in <module>
    sys.exit(main())
  File ""/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/compose/cli/main.py"", line 67, in main
    command()
  File ""/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/compose/cli/main.py"", line 126, in perform_command
    handler(command, command_options)
  File ""/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/compose/cli/main.py"", line 1070, in up
    to_attach = up(False)
  File ""/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/compose/cli/main.py"", line 1066, in up
    cli=native_builder,
  File ""/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/compose/project.py"", line 615, in up
    svc.ensure_image_exists(do_build=do_build, silent=silent, cli=cli)
  File ""/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/compose/service.py"", line 346, in ensure_image_exists
    self.build(cli=cli)
  File ""/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/compose/service.py"", line 1125, in build
    platform=self.platform,
  File ""/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/docker/api/build.py"", line 261, in build
    self._set_auth_headers(headers)
  File ""/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/docker/api/build.py"", line 308, in _set_auth_headers
    auth_data = self._auth_configs.get_all_credentials()
  File ""/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/docker/auth.py"", line 311, in get_all_credentials
    reg, store_name
  File ""/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/docker/auth.py"", line 262, in _resolve_authconfig_credstore
    store = self._get_store_instance(credstore_name)
  File ""/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/docker/auth.py"", line 287, in _get_store_instance
    name, environment=self._credstore_env
  File ""/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/docker/credentials/store.py"", line 25, in __init__
    self.program
docker.credentials.errors.InitializationError: docker-credential-gcloud not installed or not available in PATH
[2419 ms] Command failed: docker-compose --project-name containers -f /Users/zhangyongchao/selfspace/wiki.js/wiki/dev/containers/docker-compose.yml up -d --build
```
",,,iongion,"
--
Using this on ubuntu 20.10
```
docker-compose --version
docker-compose version 1.27.4, build 40524192
```

Getting the above issue

```
Traceback (most recent call last):
  File ""bin/docker-compose"", line 3, in <module>
  File ""compose/cli/main.py"", line 67, in main
  File ""compose/cli/main.py"", line 126, in perform_command
  File ""compose/cli/main.py"", line 302, in build
  File ""compose/project.py"", line 468, in build
  File ""compose/project.py"", line 450, in build_service
  File ""compose/service.py"", line 1125, in build
  File ""docker/api/build.py"", line 261, in build
  File ""docker/api/build.py"", line 308, in _set_auth_headers
  File ""docker/auth.py"", line 311, in get_all_credentials
  File ""docker/auth.py"", line 262, in _resolve_authconfig_credstore
  File ""docker/auth.py"", line 287, in _get_store_instance
  File ""docker/credentials/store.py"", line 25, in __init__
docker.credentials.errors.InitializationError: docker-credential-gcloud not installed or not available in PATH
```

Something is creating this file `~/.docker/config.json` with this content

```
{
  ""credHelpers"": {
    ""gcr.io"": ""gcloud"",
    ""us.gcr.io"": ""gcloud"",
    ""eu.gcr.io"": ""gcloud"",
    ""asia.gcr.io"": ""gcloud"",
    ""staging-k8s.gcr.io"": ""gcloud"",
    ""marketplace.gcr.io"": ""gcloud""
  }
}

```

I do not have any google cloud sdk or anything related installed on my computer.
If I remove the file, `docker-compose` works again
--
",shockw4ver,"
--
@iongion thx I'll try this
--
",,,,,,,,
7776,OPEN,Add command line option to disable connection to stdin,kind/bug,2020-09-23 09:35:28 +0000 UTC,skrech,Opened,,"Hello,

Using shell's heredoc feature I wanted to automate some test environment setup today. I had a situation similar to the following:
```
$ ssh user@some.domain.com << EOF
> docker-compose run --rm container sh -c 'echo aaa'
> echo bbb
> EOF
```

Unfortunately, ""bbb"" was never printed on my screen but the script exited with success status of 0. 

It turned out that docker-compose is **always** connecting container's stdin to shell's stdin. Since heredoc is form of shell redirection, the commands following `docker-compose run` are supplied to the container's stdin and when `docker-compose run` finishes, there is nothing left in the stdin anymore and the script exits successfully.

The same would happen if one uses `docker run -i` in place of `docker-compose run` command above. However, with `docker` the user can specify whether to use this option or not, while with `docker-compose` it's not possible.

So, is it possible to add `-I` option to `docker-compose`, similar to the `-T` option to support use-cases like this? I think that using small multi-line scripts over ssh is quite common use-case.

docker-compose version 1.26.2, build eefe0d31
Docker version 19.03.10, build 9424aea
OS is PhotonOS 3.
",,,x,"
--
In my case it was:

```sh
echo $'line1\nline2\nline3' | while IFS= read -r; do
    docker-compose exec -T app sh -c 'echo test'
done
```

But since `docker-compose` consumes all the input, ""test"" is outputted only once. Workaround:

```sh
echo $'line1\nline2\nline3' | while IFS= read -r; do
    echo | docker-compose exec -T app sh -c 'echo test'
done
```
--
",,,,,,,,,,
7775,OPEN,Multiple docker-compose file with different context path,kind/bug,2020-09-18 12:31:57 +0000 UTC,timini,Opened,,"I have 2 docker-compose files that I need to run together, the locations of the files are like

/home/project1/docker-compose.yml

and

/home/project2/docker-compose.yml

so clearly both the services should have different contextpath

But when I run below docker compose command

docker-compose -f /home/project1/docker-compose.yml -f /home/project2/docker-compose.yml config

I get to see, Both the service are getting the same context path

app:
    build:
      context: /home/project1
      dockerfile: Dockerfile
app2:
    build:
      context: /home/project1
      dockerfile: Dockerfile
How can I resolve this issue I want both my services to have their own project path ie.

app service should have context path /home/project1

and

app2 service should have context path /home/project2

https://stackoverflow.com/questions/62368714/multiple-docker-compose-file-with-different-context-path",,,,,,,,,,,,,,
7774,OPEN,cpus value type in output of config command is not consistent in version 1.27.3,kind/bug,2020-09-18 10:35:19 +0000 UTC,gingerhot,Opened,,"3. When making a bug report, make sure you provide all required information. The easier it is for
   maintainers to reproduce, the faster it'll be fixed.
-->

## Description of the issue

After I upgrade compose version to `1.27.3`,  when I run `docker-compose -f example.yml config`, the `cpus` value type in `limits` and `reservations` is not consistent in the output, the one in the `limits` is without quote mark as the one in the `reservations` does:

```yaml
services:
  redis:
    deploy:
      resources:
        limits:
          cpus: 0.8
          memory: 600M
        reservations:
          cpus: '0.10'
          memory: 300M
    image: redis:alpine
version: '3.8'
```

is this a bug or just it is designed to be?  I test this in `1.26.2` has not this problem.

the `example.yml` file:

```
version: ""3.8""
services:

  redis:
    image: redis:alpine
    deploy:
      resources:
        limits:
          cpus: '0.80'
          memory: 600M
        reservations:
          cpus: '0.10'
          memory: 300M
```

**Output of `docker-compose version`**

```
docker-compose version 1.27.3, build 4092ae5d
docker-py version: 4.3.1
CPython version: 3.7.7
OpenSSL version: OpenSSL 1.1.0l  10 Sep 2019
```

**Output of `docker version`**

```
Client: Docker Engine - Community
 Version:           19.03.12
 API version:       1.40
 Go version:        go1.13.10
 Git commit:        48a66213fe
 Built:             Mon Jun 22 15:45:36 2020
 OS/Arch:           linux/amd64
 Experimental:      false

Server: Docker Engine - Community
 Engine:
  Version:          19.03.12
  API version:      1.40 (minimum version 1.12)
  Go version:       go1.13.10
  Git commit:       48a66213fe
  Built:            Mon Jun 22 15:44:07 2020
  OS/Arch:          linux/amd64
  Experimental:     false
 containerd:
  Version:          1.2.13
  GitCommit:        7ad184331fa3e55e52b890ea95e65ba581ae3429
 runc:
  Version:          1.0.0-rc10
  GitCommit:        dc9208a3303feef5b3839f4323d9beb36df0a9dd
 docker-init:
  Version:          0.18.0
  GitCommit:        fec3683
```

## Steps to reproduce the issue

1. docker-compose -f example.yml config

### Observed result

```yaml
services:
  redis:
    deploy:
      resources:
        limits:
          cpus: 0.8
          memory: 600M
        reservations:
          cpus: '0.10'
          memory: 300M
    image: redis:alpine
version: '3.8'
```

### Expected result

```yaml
services:
  redis:
    deploy:
      resources:
        limits:
          cpus: '0.8'
          memory: 600M
        reservations:
          cpus: '0.10'
          memory: 300M
    image: redis:alpine
version: '3.8'
```

## Additional information

Ubuntu 18.04.5 LTS
",,,,,,,,,,,,,,
7771,OPEN,`config` output strips quote marks and loses version number,kind/bug,2021-01-22 08:49:35 +0000 UTC,sixeyed,Opened,,"## Description of the issue

`docker-compose config` has a reversion in the 1.27 release. The output strips the minor version number and removes quote marks for cpu limits and ports. This turns a valid input file into invalid output, so it can't be deployed as a stack in Swarm mode.

## Context information (for bug reports)

This is an issue because you can't join multiple Compose files together for a stack deploy, so you use `config` to join all your overrides into a single stack file to deploy. I guess this will break a lot of pipelines (and the exercises in chapter 14 of [Learn Docker in a Month of Lunches](https://www.manning.com/books/learn-docker-in-a-month-of-lunches?utm_source=affiliate&utm_medium=affiliate&a_aid=elton&a_bid=5890141b)). 

**Output of `docker-compose version`**

```
PS>docker-compose version
docker-compose version 1.27.0, build 980ec85b
docker-py version: 4.3.1
CPython version: 3.7.4
OpenSSL version: OpenSSL 1.1.1c  28 May 2019
```

## Steps to reproduce the issue

Input:

```
PS>cat .\docker-compose.yml
version: ""3.7""  

services:       
  nginx:        
    image: nginx
    deploy:
      resources:
        limits:
          cpus: ""0.75""
```

Output from 1.27:

```
PS>docker-compose config   
services:
  nginx:
    deploy:
      resources:
        limits:
          cpus: 0.75
    image: nginx
version: '3'
```

Version 3.7 has become version 3, and the cpu has lost its quotes. If you try to `stack deploy` the output then you get the error `services.nginx.deploy.resources.limits.cpus must be a string`. 

### Expected result

This is the output from 1.22 - which is correct and will deploy as a stack:

```
docker-compose config

services:
  nginx:
    deploy:
      resources:
        limits:
          cpus: '0.75'
    image: nginx
version: '3.7'
```

## Additional information

Docker Desktop Edge on Windows.
",,,HeavenVolkoff,"
--
Also experiencing this issue, reverting to docker-compose 1.26 solves it.
--
",chrisregnier,"
--
I also, just hit this with docker-compose 1.27.4 for both mac and linux which breaks my builds cause we use the `docker-compose config` output in docker swarm, which apparently only allows strings.
The issue https://github.com/docker/compose/issues/7766 is related, but doesn't fix the output here
--
",lnking81,"
--
As a workaround I just use `docker-compose config|sed -E ""s/cpus: ([0-9\\.]+)/cpus: '\\1'/""`
--
",,,,,,
7770,OPEN,'deploy: replicas:' behaving differently after update to 2.3.0.5,,2020-12-14 08:57:06 +0000 UTC,jeffkingtg,Opened,,"

<!--
Replace `- [ ]` with `- [x]`, or click after having submitted the issue.
-->

  - [x] I have tried with the latest version of my channel (Stable or Edge)
  - [x] I have uploaded Diagnostics
  - Diagnostics ID: B0DEC5A8-C324-4B0D-BEB7-D3369A8D406A/20200916202610

### Expected behavior
When starting web service using docker-compose up, version '3', 'deploy: replicas: 2' should be ignored - https://docs.docker.com/compose/compose-file/#deploy
### Actual behavior
Since the setting is set to 2, a second web server is started during docker-compose up.  Causing an error due to the port being allocated to web_1.  Setting the value to 'deploy: replicas: 1' fixes the issue.
### Information
<!--
Please, help us understand the problem.  For instance:
  - Is it reproducible?
  - Is the problem new?
  - Did the problem appear with an update?
  - A reproducible case if this is a bug, Dockerfiles FTW.
-->
  - macOS Version: 10.14.6

Immediately after updating to 2.3.0.5 I started experiencing an error using 'docker-compose up' on my local machine:

> WARNING: The ""web"" service specifies a port on the host. If multiple containers for this service are created on a single host, the port will clash.
Creating server_web_1        ... 
Creating server_web_1        ... done
Creating server_web_2        ... error

> ERROR: for server_web_2  Cannot start service web: driver failed programming external connectivity on endpoint server_web_2 (b1ce68d35c4442072cf1f1fe1dc300e113baf57518c86aa2ff247cd2870a8cca): Bind for 0.0.0.0:9999 failed: port is already allocated

After running 'docker-compose down', I looked for anything using ports 8080 or 9999 and nothing came up.

Original setting:

> version: '3'
services:
  web:
    image: ""jetty:9.4.9-jre8""
    ...
    ports:
      - ""8080:8080""
      - ""9999:9999""
    deploy:
      replicas: 2

After some tinkering, I changed replicas to 1 from 2 which fixed the error:

From looking at the documentation, it seems that the deploy setting should be ignored when using 'docker-compose up' (https://docs.docker.com/compose/compose-file/#deploy).  The 2.3.0.5 update seems to no longer ignore this setting.
### Diagnostic logs
<!-- Full output of the diagnostics from ""Diagnose & Feedback"" in the menu ... -->
```
Docker for Mac: version...

```

### Steps to reproduce the behavior
<!--
A reproducible case, Dockerfiles FTW.
-->

  1. Add 'deploy: replicas: 2' to a service (with a port specified?)
  2. Using 'docker-compose up' attempt to start the service
  3. An error should be thrown due to a port clash
",,,stephen,"
--
Thanks for the report, I'm moving this into the compose bug tracker.
--
",jamshid,"
--
FWIW this new behavior where `up` respects `deploy: replicas:` (treating it like older `scale:`) was always desired by a lot of users e.g. https://github.com/docker/compose/issues/1661#issuecomment-319871947
--
",cbows,"
--
It seems like some other keys in `deploy` besides `replicas` are also treated (incorrectly?) by docker-compose.                                                                                       
See this minimal example:                                                                                                                                                                             
                                                                                                                                                                                                      
```yaml                                                                                                                                                                                               
---                                                                                                                                                                                                   
version: ""3.8""                                                                                                                                                                                        
services:                                                                                                                                                                                             
  whoami:                                                                                                                                                                                             
    image: traefik/whoami                                                                                                                                                                             
    deploy:                                                                                                                                                                                           
      mode: replicated                                                                                                                                                                                
      replicas: 4                                                                                                                                                                                     
      restart_policy:                                                                                                                                                                                 
        condition: on-failure                                                                                                                                                                         
        delay: 10s                                                                                                                                                                                    
        max_attempts: 5                                                                                                                                                                               
        window: 120s                                                                                                                                                                                  
```                                                                                                                                                                                                   
                                                                                                                                                                                                      
When I spin up the service with docker-compose 1.27.4 I get the following output:

```sh
$ docker-compose up
WARNING: The following deploy sub-keys are not supported and have been ignored: restart_policy.delay, restart_policy.window
Starting ..._whoami_1 ... done
Starting ..._whoami_2 ... done
Starting ..._whoami_3 ... done
Starting ..._whoami_4 ... done
Attaching to ..._whoami_1, ..._whoami_2, ..._whoami_3, ..._whoami_4
..._whoami_4 | Starting up on port 80
..._whoami_3 | Starting up on port 80
..._whoami_2 | Starting up on port 80
..._whoami_1 | Starting up on port 80
```

So, four replicas have been started, but it also tells me that `restart_policy.delay` and `restart_policy.window` are ignored. Consequently, the others are not ignored? Let's try:

```yaml
---
version: ""3.8""
services:
  whoami:
    image: traefik/whoami
    deploy:
      mode: replicated
      replicas: 4
      restart_policy:
        condition: any
        delay: 10s
        max_attempts: 5
        window: 120s
```

I changed `restart_policy.condition` to `any` and see if that has any effect:

```sh
$ docker-compose up
WARNING: The following deploy sub-keys are not supported and have been ignored: restart_policy.delay, restart_policy.window
Recreating ..._whoami_1 ... error
Recreating ..._whoami_2 ... error
Recreating ..._whoami_3 ... error
Recreating ..._whoami_4 ... error

ERROR: for ..._whoami_4  Cannot create container for service whoami: maximum retry count cannot be used with restart policy 'always'

ERROR: for ..._whoami_1  Cannot create container for service whoami: maximum retry count cannot be used with restart policy 'always'

ERROR: for ..._whoami_3  Cannot create container for service whoami: maximum retry count cannot be used with restart policy 'always'

ERROR: for ..._whoami_2  Cannot create container for service whoami: maximum retry count cannot be used with restart policy 'always'

ERROR: for whoami  Cannot create container for service whoami: maximum retry count cannot be used with restart policy 'always'
ERROR: Encountered errors while bringing up the project.
```

It seems that this key is also read by compose and interpreted as restart policy 'always'
--
",,,,,,
7763,OPEN,Passed through environment variables have newlines stripped,kind/bug,2020-10-06 10:59:19 +0000 UTC,frankh,In progress,,"3. When making a bug report, make sure you provide all required information. The easier it is for
   maintainers to reproduce, the faster it'll be fixed.
-->

## Description of the issue
When passing through an environment variable (either through `-e` command line flag or in the `environment:` key) newlines are stripped from the value

## Context information (for bug reports)

**Output of `docker-compose version`**
```
docker-compose version 1.26.2, build eefe0d31
```

**Output of `docker version`**
```
Client: Docker Engine - Community
 Version:           19.03.12
 API version:       1.40
 Go version:        go1.13.10
 Git commit:        48a66213fe
 Built:             Mon Jun 22 15:41:33 2020
 OS/Arch:           darwin/amd64
 Experimental:      false

Server: Docker Engine - Community
 Engine:
  Version:          19.03.12
  API version:      1.40 (minimum version 1.12)
  Go version:       go1.13.10
  Git commit:       48a66213fe
  Built:            Mon Jun 22 15:49:27 2020
  OS/Arch:          linux/amd64
  Experimental:     false
 containerd:
  Version:          v1.2.13
  GitCommit:        7ad184331fa3e55e52b890ea95e65ba581ae3429
 runc:
  Version:          1.0.0-rc10
  GitCommit:        dc9208a3303feef5b3839f4323d9beb36df0a9dd
 docker-init:
  Version:          0.18.0
  GitCommit:        fec3683
```

**Output of `docker-compose config`**
(Make sure to add the relevant `-f` and other flags)
```
services:
  web:
    command: sleep infinity
    image: ubuntu
version: '3.5'
```


## Steps to reproduce the issue

```
$ export VAR=""1
2
3""
$ echo $VAR
1
2
3
$ docker-compose run -e VAR web bash -c 'echo $VAR'
1 2 3
```

### Observed result
with docker-compose -e VAR it prints ""1 2 3"" with no newlines

### Expected result
should print the same result as `echo $VAR` without docker-compose

### Stacktrace / full error message
n/a

## Additional information
both MacOS + linux

",,,jarulsamy,"
--
One more piece of information that may be helpful, I notice this happens with `docker run` as well:
```
$ export VAR=""1
2
3""

$ echo $VAR
1
2
3

$ docker run -e VAR -it busybox:latest /bin/sh -c 'echo $VAR'
1 2 3
```

Looking briefly through the source indicates that `compose` handles environment variables pretty transparently. That is, it does not actually edit them in any way. Dumping the output of the command line options of confirms this:

```yml
simple:
    image: busybox:1.27.2
    command: echo ""Hello, World!""
```

```
$ docker-compose run -e VAR simple /bin/sh -c 'echo $VAR'
{'--': False,
 '--detach': False,
 '--entrypoint': None,
 '--label': [],
 '--name': None,
 '--no-deps': False,
 '--publish': [],
 '--rm': False,
 '--service-ports': False,
 '--use-aliases': False,
 '--user': None,
 '--volume': [],
 '--workdir': None,
 '-T': False,
 '-e': ['VAR'], # Compose never sees the contents of VAR
 'ARGS': ['-c', 'echo $VAR'],
 'COMMAND': '/bin/sh',
 'SERVICE': 'simple'}
1 2 3
```
--
",frankh,"
--
good find @jarulsamy, I guess it's a `docker` bug then
--
",,,,,,,,
7760,OPEN,docker-compose on raspberry blocks vnc,kind/bug,2020-09-14 08:14:34 +0000 UTC,catalindevops,Opened,,"I installed docker compose on a new raspberry with raspberry pi os (debian 10) and when i'm running docker-compose up , if i try to connect with vnc viewer it connects but it freeze. If i stop docker-compose it connects and works.

Docker-compose was installed using pip3.

sudo apt-get install libffi-dev libssl-dev
sudo apt install python3-dev
sudo apt-get install -y python3 python3-pip
sudo pip3 install docker-compose


Docker version 19.03.12, build 48a6621
docker-compose version 1.26.2, build unknown

",,,,,,,,,,,,,,
7759,OPEN,`docker-compose stop` doesn't stop things,kind/bug,2020-09-16 14:01:19 +0000 UTC,WhyNotHugo,In progress,,"## Description of the issue

Issuing `docker-compose stop` doesn't stop services. However, it does report them as stopped:

```console
$ docker-compose stop
Stopping REDACTED_frontend_1  ... done
Stopping REDACTED_minio_1     ... done
Stopping REDACTED_memcached_1 ... done
Stopping REDACTED_mailhog_1   ... done
Stopping REDACTED_postgres_1  ... done
Stopping REDACTED_rabbitmq_1  ... done

$ docker-compose stop  # Issuing the same command here.
Stopping REDACTED_minio_1    ... done
Stopping REDACTED_mailhog_1  ... done
Stopping REDACTED_postgres_1 ... done

$ docker-compose stop  # Issuing the same command here.
Stopping REDACTED_minio_1    ... done
Stopping REDACTED_mailhog_1  ... done
Stopping REDACTED_postgres_1 ... done

$  # Several containers are still running at this point.
```

## Context information (for bug reports)

**Output of `docker-compose version`**
```console
$ docker-compose version
docker-compose version 1.26.2, build unknown
docker-py version: 4.3.1
CPython version: 3.8.5
OpenSSL version: OpenSSL 1.1.1g  21 Apr 2020

```

**Output of `docker version`**
```console
$ docker version
Client:
 Version:           19.03.12-ce
 API version:       1.40
 Go version:        go1.14.5
 Git commit:        48a66213fe
 Built:             Sat Jul 18 01:33:21 2020
 OS/Arch:           linux/amd64
 Experimental:      false

Server:
 Engine:
  Version:          19.03.12-ce
  API version:      1.40 (minimum version 1.12)
  Go version:       go1.14.5
  Git commit:       48a66213fe
  Built:            Sat Jul 18 01:32:59 2020
  OS/Arch:          linux/amd64
  Experimental:     false
 containerd:
  Version:          v1.4.0.m
  GitCommit:        09814d48d50816305a8e6c1a4ae3e2bcc4ba725a.m
 runc:
  Version:          1.0.0-rc92
  GitCommit:        ff819c7e9184c13b7c2607fe6c30ae19403a7aff
 docker-init:
  Version:          0.18.0
  GitCommit:        fec3683

```

**Output of `docker-compose config`**
(Make sure to add the relevant `-f` and other flags)
```
services:
  celery:
    build:
      context: /home/hugo/workspace/REDACTED
    command: celery -A idf.core worker -l info --scheduler django_celery_beat.schedulers:DatabaseScheduler
    depends_on:
    - mailhog
    - memcached
    - postgres
    - rabbitmq
    environment:
      REDACTED: REDACTED
    healthcheck:
      test: /app/scripts/healthcheck-celery
    image: app
    user: django
    volumes:
    - /home/hugo/workspace/REDACTED:/app:ro
    - static:/static:rw
  django:
    build:
      context: /home/hugo/workspace/REDACTED
    command: django-admin runserver 0.0.0.0:8000
    depends_on:
    - frontend
    - mailhog
    - memcached
    - minio
    - postgres
    - rabbitmq
    - translations
    environment:
      REDACTED: REDACTED
    extra_hosts:
    - www.REDACTED.localhost:127.0.0.1
    - static.REDACTED.localhost:127.0.0.1
    healthcheck:
      test: /app/scripts/healthcheck-django
    image: app
    ports:
    - 8000:8000/tcp
    user: django
    volumes:
    - /home/hugo/workspace/REDACTED:/app:rw
    - static:/static:rw
  frontend:
    command: yarn build --watch --dest dists/REDACTED --target app
    environment:
      SASS_PATH: REDACTED
    image: node:latest
    restart: on-failure
    volumes:
    - /home/hugo/workspace/REDACTED:/app:rw
    working_dir: /app
  mailhog:
    healthcheck:
      test: echo | telnet 127.0.0.1 25
    image: mailhog/mailhog
    ports:
    - 8025:8025/tcp
  memcached:
    image: memcached:latest
    ports:
    - 11211:11211/tcp
  minio:
    command: minio server /data
    environment:
      REDACTED: REDACTED
    healthcheck:
      test:
      - CMD
      - curl
      - -f
      - http://localhost:9000/minio/health/live
    image: minio/minio
    ports:
    - 9000:9000/tcp
    volumes:
    - buckets:/data:rw
  postgres:
    healthcheck:
      test:
      - CMD
      - pg_isready
      - --username
      - postgres
    image: mdillon/postgis:11-alpine
    ports:
    - 5432:5432/tcp
    volumes:
    - postgres_data:/var/lib/postgresql/data:rw
  rabbitmq:
    image: rabbitmq:latest
    ports:
    - 5672:5672/tcp
  translations:
    build:
      context: /home/hugo/workspace/REDACTED
    command: django-admin compilemessages
    environment:
      REDACTED: REDACTED
    image: app
    user: django
    volumes:
    - /home/hugo/workspace/REDACTED:/app:rw
version: '3.0'
volumes:
  buckets: {}
  postgres_data: {}
  static: {}


```


## Steps to reproduce the issue

1. `docker-compose up`
1. `docker-compose stop`

### Observed result

Services should either be stopped, or an error should be reported.

### Expected result

Services don't stop AND `docker-compose` indicates they're stopped (when
they're not!).

## Additional information

Running on ArchLinux:

    Linux aphrodite 5.8.6-arch1-1 #1 SMP PREEMPT Thu, 03 Sep 2020 17:27:39 +0000 x86_64 GNU/Linux

",,,WhyNotHugo,"
--
I'm happy to provide extra context here, I've no idea what's up here.

But this has become a huge nuisance, I just keep having to resort to `sudo pkill -KILL -f docker`.
--
",aiordache,"
--
Hi @WhyNotHugo! I am trying to reproduce this issue with a simple compose file(3 nginx services) but the stop command seems to work fine with it. Can you provide a simple docker-compose file that can let me reproduce it?
--
",,,,,,,,
7757,OPEN,Remove detached containers with `run --rm -d`,kind/feature,2020-10-08 12:20:45 +0000 UTC,bartolootrit,Opened,,"`--rm` and `-d` options work together in Docker since PR [#20848](https://github.com/moby/moby/pull/20848)
Are there any plans to support this in Docker Compose?
",,,,,,,,,,,,,,
7750,OPEN,compose up via SSH fails with ERROR: Secsh channel 21 open FAILED: open failed: Connect failed,kind/bug,2021-02-07 02:31:39 +0000 UTC,tze,Opened,,"## Description of the issue
Trying to start an application via compose over SSH fails after a random number of services (or none) from the compose file were started successfully.

## Context information (for bug reports)
**Output of `docker-compose version`**
```
docker-compose version 1.26.2, build eefe0d31
docker-py version: 4.2.2
CPython version: 3.7.4
OpenSSL version: OpenSSL 1.1.1c  28 May 2019
```

**Output of `docker version`**
```
Client: Docker Engine - Community
 Version:           19.03.12
 API version:       1.40
 Go version:        go1.13.10
 Git commit:        48a66213fe
 Built:             Mon Jun 22 15:43:18 2020
 OS/Arch:           windows/amd64
 Experimental:      false

Server: Docker Engine - Community
 Engine:
  Version:          19.03.12
  API version:      1.40 (minimum version 1.12)
  Go version:       go1.13.10
  Git commit:       48a66213fe
  Built:            Mon Jun 22 15:49:27 2020
  OS/Arch:          linux/amd64
  Experimental:     false
 containerd:
  Version:          v1.2.13
  GitCommit:        7ad184331fa3e55e52b890ea95e65ba581ae3429
 runc:
  Version:          1.0.0-rc10
  GitCommit:        dc9208a3303feef5b3839f4323d9beb36df0a9dd
 docker-init:
  Version:          0.18.0
  GitCommit:        fec3683
```

**Output of `docker-compose config`**
(Make sure to add the relevant `-f` and other flags)
```
services:
  backend:
    image: company/backend:latest
    volumes:
    - /tmp/company-docker/logs/backend:/opt/app/log:rw
  frontend:
    image: company/frontend:latest
    volumes:
    - /tmp/company-docker/logs-frontend:/var/log/nginx:rw
  proxy:
    depends_on:
    - backend
    - frontend
    image: company/proxy:latest
    ports:
    - published: 58010
      target: 80
version: '3.8'
```


## Steps to reproduce the issue

1. compose file with multiple containers
2. Start on remote host via SSH

### Observed result
Compose file contains three services, sometimes the error occurs for the first service. In the following occurrence it happened to work for the first 2/3. However it never works for 3/3. 

### Expected result
All services are started.

### Stacktrace / full error message

```
$ DOCKER_HOST=""ssh://user@host"" docker-compose -p project --env-file production.env up
project_frontend_1 is up-to-date
Starting project_backend_1 ... done
Creating project_proxy_1   ... 
ERROR: Secsh channel 21 open FAILED: open failed: Connect failed

ERROR: for project_proxy_1  ChannelException(2, 'Connect failed')

ERROR: for proxy  ChannelException(2, 'Connect failed')
Traceback (most recent call last):
  File ""docker-compose"", line 6, in <module>
  File ""compose\cli\main.py"", line 72, in main
  File ""compose\cli\main.py"", line 128, in perform_command
  File ""compose\cli\main.py"", line 1078, in up
  File ""compose\cli\main.py"", line 1074, in up
  File ""compose\project.py"", line 576, in up
  File ""compose\parallel.py"", line 112, in parallel_execute
  File ""compose\parallel.py"", line 210, in producer
  File ""compose\project.py"", line 562, in do
  File ""compose\service.py"", line 547, in execute_convergence_plan
  File ""compose\service.py"", line 468, in _execute_convergence_create
  File ""compose\parallel.py"", line 112, in parallel_execute
  File ""compose\parallel.py"", line 210, in producer
  File ""compose\service.py"", line 466, in <lambda>
  File ""compose\service.py"", line 458, in create_and_start
  File ""compose\service.py"", line 624, in start_container
  File ""compose\service.py"", line 660, in connect_container_to_networks
  File ""site-packages\docker\utils\decorators.py"", line 19, in wrapped
  File ""site-packages\docker\api\network.py"", line 248, in connect_container_to_network
  File ""site-packages\docker\api\client.py"", line 289, in _post_json
  File ""site-packages\docker\utils\decorators.py"", line 46, in inner
  File ""site-packages\docker\api\client.py"", line 226, in _post
  File ""site-packages\requests\sessions.py"", line 581, in post
  File ""site-packages\requests\sessions.py"", line 533, in request
  File ""site-packages\requests\sessions.py"", line 646, in send
  File ""site-packages\requests\adapters.py"", line 449, in send
  File ""site-packages\urllib3\connectionpool.py"", line 677, in urlopen
  File ""site-packages\urllib3\connectionpool.py"", line 392, in _make_request
  File ""http\client.py"", line 1244, in request
  File ""http\client.py"", line 1290, in _send_request
  File ""http\client.py"", line 1239, in endheaders
  File ""http\client.py"", line 1026, in _send_output
  File ""http\client.py"", line 966, in send
  File ""site-packages\docker\transport\sshconn.py"", line 32, in connect
  File ""site-packages\paramiko\transport.py"", line 879, in open_session
  File ""site-packages\paramiko\transport.py"", line 1017, in open_channel
paramiko.ssh_exception.ChannelException: ChannelException(2, 'Connect failed')
[5300] Failed to execute script docker-compose
```

## Additional information

OS version / distribution, `docker-compose` install method, etc.
",,,fletchowns,"
--
I've been sporadically running into this with Debian hosts & containers when using remote context via SSH. Seems there was an existing ticket for this issue with a fix but the [merge may have been missed](https://github.com/docker/compose/issues/6463#issuecomment-694768175).
--
",,,,,,,,,,
7743,OPEN,Adding the service name to build --parallel,kind/feature,2020-09-10 05:29:51 +0000 UTC,adirburke,Opened,,Is it possible for the output of build parallel to add the service name to the steps or even better every line ?,,,,,,,,,,,,,,
7723,OPEN,docker-compose up -d --force-recreate should also create brand new containers,kind/feature,2020-09-02 20:42:12 +0000 UTC,willnx,Opened,,"-->

**Is your feature request related to a problem? Please describe.**
I was surprised to find that adding a container/service to a `docker-compose.yaml`, then running `docker-compose up -d --force-recreate` did not create the new container. Instead, it only re-created the previously existing ones.

**Describe the solution you'd like**
I'd like to avoid running two command to recreate my application. Currently, I have to run `docker-compose down` and then run `docker-compose up -d` if I add a new container/service to my yaml file.

**Describe alternatives you've considered**
Using an `&&` in my script to bring down everything, then restart it.

**Additional context**
Here's an example yaml file:
```
version: '3'
services:
  proxy:
    image: nginx:1.17-alpine
    ports:
      - ""80:80""
```

If I run `docker-compose up -d`, everything works as expected. If I now edit the yaml file to look like this:
```
version: '3'
services:
  proxy:
    image: nginx:1.17-alpine
    ports:
      - ""80:80""
  web:
    image: tutum/hello-world
```
And run `docker-compose up -d --force-recreate`, the `web` service doesn't run.
",,,,,,,,,,,,,,
7719,OPEN,Docker-compose created container cannot access Internet,kind/question,2020-09-10 15:25:50 +0000 UTC,payalord,Opened,,"https://forums.docker.com/t/docker-compose-created-container-cannot-access-internet/98199
Host OS is CentOS 8. Im not behind proxy, at least as i know. `firewalld` is not installed due to conflict with `docker`. But my hosting company uses its own DNS servers. Here are the problem, when I run from the container that has been created by `docker-compose` im getting every time `Connection timeout`:
```
apt-get update
Err:1 http://archive.ubuntu.com/ubuntu bionic InRelease
  Could not connect to archive.ubuntu.com:80 (91.189.88.152), connection timed out Could not connect to archive.ubuntu.com:80 (91.189.88.142), connection timed out
Err:2 http://archive.ubuntu.com/ubuntu bionic-updates InRelease
  Unable to connect to archive.ubuntu.com:http:
Err:3 http://archive.ubuntu.com/ubuntu bionic-backports InRelease
  Unable to connect to archive.ubuntu.com:http:
Err:4 http://downloads.mariadb.com/MariaDB/mariadb-10.4/repo/ubuntu bionic InRelease
  Could not connect to downloads.mariadb.com:80 (172.67.32.229), connection timed out Could not connect to downloads.mariadb.com:80 (104.20.68.208), connection timed out Could not connect to downloads.mariadb.com:80 (104.20.67.208), connection timed out
Err:5 http://security.ubuntu.com/ubuntu bionic-security InRelease
  Could not connect to security.ubuntu.com:80 (91.189.91.38), connection timed out Could not connect to security.ubuntu.com:80 (91.189.88.152), connection timed out Could not connect to security.ubuntu.com:80 (91.189.91.39), connection timed out Could not connect to security.ubuntu.com:80 (91.189.88.142), connection timed out
Reading package lists... Done
W: Failed to fetch http://archive.ubuntu.com/ubuntu/dists/bionic/InRelease  Could not connect to archive.ubuntu.com:80 (91.189.88.152), connection timed out Could not connect to archive.ubuntu.com:80 (91.189.88.142), connection timed out
W: Failed to fetch http://archive.ubuntu.com/ubuntu/dists/bionic-updates/InRelease  Unable to connect to archive.ubuntu.com:http:
W: Failed to fetch http://archive.ubuntu.com/ubuntu/dists/bionic-backports/InRelease  Unable to connect to archive.ubuntu.com:http:
W: Failed to fetch http://security.ubuntu.com/ubuntu/dists/bionic-security/InRelease  Could not connect to security.ubuntu.com:80 (91.189.91.38), connection timed out Could not connect to security.ubuntu.com:80 (91.189.88.152), connection timed out Could not connect to security.ubuntu.com:80 (91.189.91.39), connection timed out Could not connect to security.ubuntu.com:80 (91.189.88.142), connection timed out
W: Failed to fetch http://downloads.mariadb.com/MariaDB/mariadb-10.4/repo/ubuntu/dists/bionic/InRelease  Could not connect to downloads.mariadb.com:80 (172.67.32.229), connection timed out Could not connect to downloads.mariadb.com:80 (104.20.68.208), connection timed out Could not connect to downloads.mariadb.com:80 (104.20.67.208), connection timed out
W: Some index files failed to download. They have been ignored, or old ones used instead.
```
iptables rules outside the container(on host machine):
```
sudo iptables -L
Chain INPUT (policy ACCEPT)
target     prot opt source               destination

Chain FORWARD (policy DROP)
target     prot opt source               destination
DOCKER-USER  all  --  anywhere             anywhere
DOCKER-ISOLATION-STAGE-1  all  --  anywhere             anywhere
ACCEPT     all  --  anywhere             anywhere             ctstate RELATED,ESTABLISHED
DOCKER     all  --  anywhere             anywhere
ACCEPT     all  --  anywhere             anywhere
ACCEPT     all  --  anywhere             anywhere
ACCEPT     all  --  anywhere             anywhere             ctstate RELATED,ESTABLISHED
DOCKER     all  --  anywhere             anywhere
ACCEPT     all  --  anywhere             anywhere
ACCEPT     all  --  anywhere             anywhere
ACCEPT     all  --  anywhere             anywhere             ctstate RELATED,ESTABLISHED
DOCKER     all  --  anywhere             anywhere
ACCEPT     all  --  anywhere             anywhere
ACCEPT     all  --  anywhere             anywhere

Chain OUTPUT (policy ACCEPT)
target     prot opt source               destination

Chain DOCKER (3 references)
target     prot opt source               destination
ACCEPT     tcp  --  anywhere             172.17.0.2           tcp dpt:mysql
ACCEPT     tcp  --  anywhere             172.17.0.3           tcp dpt:https
ACCEPT     tcp  --  anywhere             172.17.0.3           tcp dpt:http

Chain DOCKER-ISOLATION-STAGE-1 (1 references)
target     prot opt source               destination
DOCKER-ISOLATION-STAGE-2  all  --  anywhere             anywhere
DOCKER-ISOLATION-STAGE-2  all  --  anywhere             anywhere
DOCKER-ISOLATION-STAGE-2  all  --  anywhere             anywhere
RETURN     all  --  anywhere             anywhere

Chain DOCKER-ISOLATION-STAGE-2 (3 references)
target     prot opt source               destination
DROP       all  --  anywhere             anywhere
DROP       all  --  anywhere             anywhere
DROP       all  --  anywhere             anywhere
RETURN     all  --  anywhere             anywhere

Chain DOCKER-USER (1 references)
target     prot opt source               destination
RETURN     all  --  anywhere             anywhere
```
/etc/docker/daemon.json
```
{
  ""dns"": [
    ""10.255.250.40"",
    ""10.255.251.40""
  ],
  ""debug"": true
}
```
`ping` works fine on host machine without any loss. Same with docker run with `busybox ping`:
```docker run --rm busybox ping google.com -c 2
PING google.com (172.217.14.110): 56 data bytes
64 bytes from 172.217.14.110: seq=0 ttl=113 time=76.651 ms
64 bytes from 172.217.14.110: seq=1 ttl=113 time=64.544 ms

--- google.com ping statistics ---
2 packets transmitted, 2 packets received, 0% packet loss
round-trip min/avg/max = 64.544/70.597/76.651 ms
```
I know that with docker run it uses `docker0` network and it works fine. While with `docker-compose` it creates new networks for services and instead of using `/etc/resolv.conf` it uses built in DNS. But as we can see, everything works fine with DNS, since I can see IP addresses when I run apt-get update inside of container. Plus debug logs shows that dns `10.255.250.40` resolves them fine too. Its just connection time out. So something doesnt let the traffic pass after dns resolved everything fine.

Can anyone help me with this problem? Thanks.",,,kronenpj,"
--
I think I see this as well, but without anything in /etc/docker/docker.json. 
Package versions:
moby-engine-19.03.11-1.ce.git42e35e6.fc32.x86_64
docker-compose-1.25.4-1.fc32.noarch

Two 'equivalent' containers were created:
$ docker run -d --name nginx nginx:alpine
$ docker-compose up -d
$ cat docker-compose.yml
```
version: '2'
services:
    nginx:
      image: nginx:alpine
```

Different results:
$ docker exec -it nginx cat /etc/resolv.conf | grep nameserver
nameserver 172.16.42.1
$ docker exec -it dnstest_nginx_1 cat /etc/resolv.conf | grep nameserver
nameserver 127.0.0.11

And the real problem:
$ docker exec -it nginx ping -c2 google.com
PING google.com (64.233.177.113): 56 data bytes
64 bytes from 64.233.177.113: seq=0 ttl=103 time=25.080 ms
64 bytes from 64.233.177.113: seq=1 ttl=103 time=22.554 ms

--- google.com ping statistics ---
2 packets transmitted, 2 packets received, 0% packet loss
round-trip min/avg/max = 22.554/23.817/25.080 ms

$ docker exec -it dnstest_nginx_1 ping -c2 google.com
ping: bad address 'google.com'

I can't seem to figure out whether the embedded DNS server is broken or if it's not set up correctly with docker-compose. 

*UPDATE: Never mind. I verified on FC31 that everything works as expected but it's broken on FC32 with the same package versions.*
--
",,,,,,,,,,
7709,OPEN,Reopen Issue 6336,kind/bug,2021-01-26 16:46:41 +0000 UTC,snwfdhmp,Opened,,"The issue https://github.com/docker/compose/issues/6336 has not been reopened yet despite being **critical and security related** and despite having **lots of developers reporting this bug**.

Please take a moment to acknowledge this bug and try to fix it.

If you don't consider this important enough to fix, please announce it on the issue so we don't expect any improvement on this topic.

Thank you.",,,rolpaul,"
--
I agree that this is a critical issue. ssh is important in professional company networks. 
I can still reproduce this problem still exists on docker-compose 1.25.0 linux (ubuntu)
I can not confirm the statement in #6338 that this was fixed and merged in https://github.com/docker/compose/pull/6388.
As @sampwing points out please acknowledge this bug and tell us how to proceeed, either here in #7709 or in reopened #6336.
--
",konzinov,"
--
For those who facing the same issue:

After digging into paramiko i figured out it tries to establish ssh connection throught many network interfaces using ipv6 option first. 

This can lead to some timeout Error (it's the same error that appears) due to network configurations or ssh over ipv6 configurations on the target host (See AddressFamily option for SSH).

**To fix it i just disabled ipv6 on my computer.** 
it can be done on mac with `networksetup -setv6off Ethernet && networksetup -setv6off Wi-Fi`

But if you definitely want to use ipv6 make sure you can ssh using ipv6 and it should work with paramiko too.

refers to #6336 
--
",,,,,,,,
7707,OPEN,Windows-build stuck on OpenSSL 1.1.1c (28.May 2019),kind/bug; stale,2021-02-23 23:01:25 +0000 UTC,Herr-Sepp,Opened,,"3. When making a bug report, make sure you provide all required information. The easier it is for
   maintainers to reproduce, the faster it'll be fixed.
-->

## Description of the issue
The Windowsbuild of Docker-compose does contain not the current version of OpenSSL.

## Context information (for bug reports)

**Output of `docker-compose version`**
```
docker-compose version 1.26.2, build eefe0d31
docker-py version: 4.2.2
CPython version: 3.7.4
OpenSSL version: OpenSSL 1.1.1c  28 May 2019
```

## Steps to reproduce the issue

1.Download newest docker-compose
2. run ""docker-compse version""

### Observed result
OpenSSL version: OpenSSL 1.1.1c  28 May 2019
### Expected result
OpenSSL version: OpenSSL 1.1.1g (Like in MacOS Builds)

Release Notes 1.26:
Bumped OpenSSL from 1.1.1f to 1.1.1g.  << not true for Windows

Windows 10 All Versions

",,,stale,"
--
This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you for your contributions.

--
",,,,,,,,,,
7702,OPEN,Error when using a remote ssh context running under Ubuntu,kind/bug; stale,2021-02-21 22:55:09 +0000 UTC,PalatinCoder,Opened,,"3. When making a bug report, make sure you provide all required information. The easier it is for
   maintainers to reproduce, the faster it'll be fixed.
-->

## Description of the issue

Running docker-compose on windows against a remote context (Ubuntu bionic server) via ssh results in an error saying it couldn't connect to the Docker daemon. The Docker daemon is running, which can easily be verified by running `docker ps`. Furthermore, the ssh connection is in fact working. As you can see in the  attached [verbose](https://github.com/docker/compose/files/5114043/verbose.txt) output, there are some successful requests until it hits the error at this call: `compose.cli.verbose_proxy.proxy_callable: docker inspect_container <- ('fd1b13a88d2ff7e4444633fb39b726c53bec864d1d8e79a50ca4537ea392cfb5')`

## Context information (for bug reports)

**Output of `docker-compose version`**
```
docker-compose version 1.26.2, build eefe0d31
docker-py version: 4.2.2
CPython version: 3.7.4
OpenSSL version: OpenSSL 1.1.1c  28 May 2019
```

**Output of `docker version`**
```
Client: Docker Engine - Community
 Version:           19.03.12
 API version:       1.40
 Go version:        go1.13.10
 Git commit:        48a66213fe
 Built:             Mon Jun 22 15:43:18 2020
 OS/Arch:           windows/amd64
 Experimental:      false

Server:
 Engine:
  Version:          19.03.6
  API version:      1.40 (minimum version 1.12)
  Go version:       go1.12.17
  Git commit:       369ce74a3c
  Built:            Wed Feb 19 01:06:16 2020
  OS/Arch:          linux/amd64
  Experimental:     false
 containerd:
  Version:          1.3.3-0ubuntu1~18.04.2
  GitCommit:
 runc:
  Version:          spec: 1.0.1-dev
  GitCommit:
 docker-init:
  Version:          0.18.0
  GitCommit:
```

**Output of `docker-compose config`**
(Make sure to add the relevant `-f` and other flags)
```
networks:
  internal: {}
  public: {}
services:
  cache:
    image: redis:alpine
    networks:
      internal: null
    restart: unless-stopped
    volumes:
    - cache:/data:rw
  db:
    image: mariadb
    networks:
      internal: null
    restart: unless-stopped
    volumes:
    - db:/var/lib/mysql:rw
  neos:
    build:
      args:
        context: production
      context: (..)
    depends_on:
    - cache
    - db
    image: neos:prod
    networks:
      internal: null
      public: null
    restart: unless-stopped
    volumes:
    - data:/neos/Data/Persistent/:rw
version: '3.4'
volumes:
  cache: {}
  data: {}
  db: {}
```


## Steps to reproduce the issue

1. Create a docker context against Ubuntu bionic server via ssh
2. Raise `MaxSessions` on the ssh server to mitigate the known issue with to many connections
3. Set the context active `docker context use ubuntu` and run `docker-compose ps` OR run `docker-compose --context ubuntu ps`

### Observed result
Error message
### Expected result
List of running containers
### Stacktrace / full error message (see also [verbose.txt](https://github.com/docker/compose/files/5114043/verbose.txt))

```
ERROR: Couldn't connect to Docker daemon at http+docker://ssh - is it running?

If it's at a non-standard location, specify the URL with the DOCKER_HOST environment variable.
```

## Additional information

I read about the issue with MaxSessions on the ssh server, so I raised that value, but didn't make a difference. Also, I tried it with sshd's LogLevel set to DEBUG3. It said that there was a session opened with six channels. It started to send data until channel 6 was closed suddenly (apparently client-side). There was no indication that sshd was limiting something here. Also, I tried it with disabled firewall on the server, as it could potentially limit connections - again with no luck.


When using another remote machine, which is running Fedora CoreOS, everything works as expected. The fcos machine is running the following versions: 
```
Server:
 Engine:
  Version:          19.03.11
  API version:      1.40 (minimum version 1.12)
  Go version:       go1.14.3
  Git commit:       42e35e6
  Built:            Sun Jun  7 00:00:00 2020
  OS/Arch:          linux/amd64
  Experimental:     false
 containerd:
  Version:          1.3.3
  GitCommit:
 runc:
  Version:          1.0.0-rc10+dev
  GitCommit:        fbdbaf85ecbc0e077f336c03062710435607dbf1
 docker-init:
  Version:          0.18.0
  GitCommit:
```
",,,stale,"
--
This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you for your contributions.

--
",,,,,,,,,,
7701,OPEN,Suppress or hide Docker Steps and other default outputs in the console,kind/feature,2020-08-23 04:21:49 +0000 UTC,jessewilliams1,Opened,,"I have a Dockerfile where I would like to customize the output console.

**Simplified example:**

```bash
FROM node:Alpine

RUN echo 'Starting container build'
RUN echo 'Copying files...'

WORKDIR /that
COPY ./this /that

RUN echo 'Copy complete. Directory contents:'
RUN ls
```

**I would expect an output like so:**

```bash
Starting container build
Copying files...
Copy complete. Directory contents:
file1.ts
file2.ts
file3.ts
...
```

However, Docker adds these ""Step x/x : "" and ""Running in 314159265359"" messages, giving a messy output

**Actual output:**

```bash
Step 1/7 : FROM node:Alpine
 ---> 314159265359
Step 2/7 : RUN echo 'Starting container build'
 ---> Running in 314159265359
Starting container build
Removing intermediate container 314159265359
 ---> 314159265359
Step 3/7 : RUN echo 'Copying files...'
 ---> Running in 314159265359
Copying files...
Removing intermediate container 314159265359
 ---> 725d85e0131c
Step 4/7 : WORKDIR /that
 ---> Running in 314159265359
Removing intermediate container 314159265359
 ---> 314159265359
Step 5/7 : COPY ./this /that
 ---> 314159265359
Step 6/7 : RUN echo 'Copy complete. Directory contents:'
 ---> Running in 314159265359
Copy complete. Directory contents:
Removing intermediate container 314159265359
 ---> 314159265359
Step 7/7 : RUN ls
 ---> Running in 314159265359
file1.ts
file2.ts
file3.ts
...
```

Not a huge issue but vanity is important... especially when one is fond of ASCII art :-)",,,,,,,,,,,,,,
7697,OPEN,Docker-compose + Qnap storage,kind/question; stale,2021-02-18 04:11:36 +0000 UTC,sirsiegfrieds,Opened,,"Hello i'm trying to mount files from a qnap 
directly in a docker-compose.yml with plex

I'm beginner and i'm trying to understand what i do...

**That's  the part of a  docker-compose.yml i'm trying to adapt at my case.**

```
[root@docker docker-mirror]# cat nfs-compose.yml
version: ""3.2""

services:
     rsyslog:
       image: jumanjiman/rsyslog
       ports:
         - ""514:514""
         - ""514:514/udp""
       volumes:
         - type: volume
           source: example
           target: /nfs
           volume:
             nocopy: true
volumes:
     example:
       driver_opts:
         type: ""nfs""
         o: ""addr=10.40.0.199,nolock,soft,rw""
         device: "":/docker/example""

```

**And my try is :**

```
version: ""2.1""
services:
  plex:
    image: linuxserver/plex
    container_name: plex
    network_mode: host
    environment:
      - PUID=1001
      - PGID=1001
      - VERSION=docker
      - UMASK_SET=022 #optional
      - PLEX_CLAIM= #optional
    volumes:
      - /opt/docker/plex/config/:/config
      - type: volume
          source: souvenir
          target: /plex/souvenir ## file from Nas
          volume:
            nocopy: true ## i don't want that the container download my file, i prefer keep them on Nas
volumes:
  souvenir:
    driver_opts:
         type: ""nfs""
         o: ""addr=xx.xxx.xx.xx,nolock,soft,rw""
         device: "":/opt/docker/plex/data/prive/souvenir""
    
    restart: unless-stopped
```



I don't know if i'm doing it well, but i'm trying my best.
I could put them on fstab, but i'm not sure that's is a good idea of sharing all my file in Host.
And i have had problem in a Vm, that at reboot my nas files aren't mount .

Sorry for my english, i'm trying my best.
Thank's for help.",,,stale,"
--
This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you for your contributions.

--
",,,,,,,,,,
7693,OPEN,Fix path resolution between multiple projects in docker-compose,stale,2021-02-18 04:11:37 +0000 UTC,bruno-oliveira,Opened,,"Is there a solution for this?

A design document, or a better ticket describing exactly how or where to fix it?

I think this is really important.

In my case scenario, I have a monorepo with lets say 3 projects:

proj1, proj2, proj3

each of them with their own Dockerfile and docker-compose to run integration tests using testcontainers.

Now, inside a `docker-compose` for proj3, I want to reference the Dockerfile for proj1 to build a service.

What do I need to do such that, from a docker-compose in proj3, this works:

```yml
my-test-api-wtv:
       build: ../../../../whatever/folder/where/dockerfile/for/proj1/is
```

where inside this ecosystem can we see the exact place where this resolution happens?

With some pointers, I'd really be glad to help since this is partially blocking the IT setup we want to achieve at my $DAYJOB.

_Originally posted by @bruno-oliveira in https://github.com/docker/compose/issues/3874#issuecomment-678252508_",,,bruno,"
--
So I was looking into the actual `config.py`:

```python
if 'build' in service_dict:
        build = service_dict.get('build', {})

        if isinstance(build, str):
            build_path = build
        elif isinstance(build, dict) and 'context' in build:
            build_path = build['context']
        else:
            # We have a build section but no context, so nothing to validate
            return

        if (
            not is_url(build_path) and
            (not os.path.exists(build_path) or not os.access(build_path, os.R_OK))
        ):
            raise ConfigurationError(
                ""build path %s either does not exist, is not accessible, ""
                ""or is not a valid URL."" % build_path)
```

so the Dockerfile path I have is clearly not a URL, so first condition is true, which means that for this exception to be thrown, either the build path DOES NOT exist (making the first piece of the OR to be true) OR that it exists but it is not accessible for reading.

In this case:

It exists, because it is part of a monorepo

the permissions on the folder where the dockerfile sits are:
`drwxr-xr-x`

So it would seem that the permissions too, are correct.

In essence, the exception should not be thrown, so, I wonder exactly how the resolution of the `build:` attribute is being done.

Also, how is the file access checked by Python internally? Because in the same monorepo, three projects created separately will all have the same permissions (string above) and additionally, the path should also exist.
--

--
Okay some more digging:
Specifying the context together with dockerfile in this fashion:

```yml
my-test-api:
    build:
      context: ./../../../../
      dockerfile: <root project where the dockerfile is>/Dockerfile
```

Gives me:
Cannot locate specified Dockerfile: <root project where the dockerfile is>/Dockerfile

My context is specified like that as I am traversing the tree from the `resources/test` folder inside a certain subproject, to get to where I need to be.

Adding the directory to the context fails.

Do you know if the `context` variable containing a directory that is an IntelliJ project can fail?

--
",stale,"
--
This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you for your contributions.

--
",,,,,,,,
7691,OPEN,`docker-compose --compatibility config` should not force output to version 2.3,kind/bug; stale,2021-02-18 04:11:38 +0000 UTC,jamshid,Opened,,"## Description of the issue

`docker-compose --compatibility config` should not force output to version 2.3, it should remain the same as the input.
Hopefully this is already being taken care of by the removal / relaxing of compose file version numbers.

## Context information (for bug reports)

**Output of `docker-compose version`**
```
docker-compose version 1.26.2, build eefe0d31
```

**Output of `docker version`**
```
 Version:           19.03.12
```

## Steps to reproduce the issue

1. Run `docker-compose --compatibility config` on a version 3 docker-compose.yml and it will output a `version: '2.3'` yaml.

### Observed result

the compose yaml format is 2.3
### Expected result
the output should remain the same version as the input file, as when `--compatibility` is not used

",,,stale,"
--
This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you for your contributions.

--
",,,,,,,,,,
7690,OPEN,Docker Compose vs Kaspersky,kind/bug; stale,2021-02-23 23:01:25 +0000 UTC,PeterAlb,In progress,,"## Description of the issue

Running docker-compose is extremely slow. Even simple tasks like ```docker-compose --version``` are taking more than 10 minutes. Looking into the Activity Monitor on my Macbook i can clearly see that the process ```kav``` is immediately taking over all the CPU of my machine. This is an anti-virus (Kaspersky) process.

So the question is:
Why is a simple command like checking the version number such an issue?

I also followed the advice given in the docker documentation to add the docker data directory to Kaspersky's exclusion list.
https://docs.docker.com/engine/security/antivirus/

While this appears to improve the time of ```docker-compose up```, its still taking a long time.

Fun fact:
Running all the commands for this bug report took around 50 minutes.  

## Context information (for bug reports)

**Output of `docker-compose version`**
```
docker-compose version 1.26.2, build eefe0d31
```

**Output of `docker version`**
```
Docker version 19.03.12, build 48a66213fe
```


## Steps to reproduce the issue

1. Install Kaspersky Endpoint Security and Docker Compose
2. Run ```docker-compose --version```

### Observed result

Very long execution time. (> 10 minutes)

### Expected result

Very short execution time. E.g. like for ```docker --version``` (< 1 second).

## Additional information

OS version / distribution: macOS Mojave (10.14.6)
`docker-compose` install method: Docker Desktop for Mac
",,,PeterAlb,"
--
A small update from my side:
I checked if a manually installed version of ```docker-compose``` would have the same issues. This is not the case. ```docker-compose``` is running fast again with this approach. So installing ```docker-compose``` manually and overwriting the link to it is the current workaround for me.

For anyone interested here are the steps with homebrew after the installation of ""Docker for Mac"":
```brew reinstall docker-compose```
```brew link --overwrite docker-compose```

This way all ```docker-compose``` calls will now call your manually installed version. I also did some testing what happens when ""Docker for Mac"" performs an update. Its basically overwriting the link again to point to the ```docker-compose``` inside the application. Which is nice. Should prevent unwanted side effects after upgrading in the future.

A real solution would be awesome nevertheless.
--
",stale,"
--
This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you for your contributions.

--
",,,,,,,,
7688,OPEN,docker-compose -f docker-compose.yml.dev -H ssh://user@ip uses wrong file / gets cached,kind/bug,2020-11-04 12:38:59 +0000 UTC,cmmmhub,Opened,,"3. When making a bug report, make sure you provide all required information. The easier it is for
   maintainers to reproduce, the faster it'll be fixed.
-->

## Description of the issue
I have a folder with multiple .yml files in: docker-compose.yml.dev and docker-compose.yml.uat. When I use docker-compose -f docker-compose.yml.dev -H ssh://ip up -d I expect it to up the image, container and network from .dev but instead it will load from docker-compose.yml.uat only when I run docker-compose.yml.uat again will it actually load the uat version of the file.

This does the same the other way around as well. Like its cached and needs to be ran 2 times for it to actually get the correct file. It seems to use the previous file even though -f has changed
.
## Context information (for bug reports)

**Output of `docker-compose version`**
```
1.25.5, build 8a1c60f6
```

**Output of `docker version`**
```
 19.03.12, build 48a66213fe
```

**Output of `docker-compose config`**
(Make sure to add the relevant `-f` and other flags)
```
dev:
networks:
  project-network: {}
services:
  node:
    container_name: site-dev
    image: ?????/repo:site-dev
    networks:
      project-network: null
    ports:
    - 8233:3000/tcp
    restart: unless-stopped
    stdin_open: true
    user: docker-user:docker-user
version: '3.0'

uat:
networks:
  project-uat-network: {}
services:
  node:
    container_name: site-uat
    image: ?????/repo:site-uat
    networks:
      project-uat-network: null
    ports:
    - 8234:3000/tcp
    restart: unless-stopped
    stdin_open: true
    user: docker-user:docker-user
version: '3.0'
```


## Steps to reproduce the issue

1. create 2 docker-compose files in the same directory
2. docker-compose -f docker-compose.yml.dev -H ssh://ip up -d. If nothing has loaded before it then it will load dev but if docker-compose.yml.uat was loaded before it then it will load the container for uat.

### Observed result

switching the files for the first  up -d doesnt work its only the second that loads the correct file

### Expected result

when i switch the file using -f I expect it to use that file when doing docker-compose up -d

### Stacktrace / full error message

```
no error
```

## Additional information

OS version / distribution, `docker-compose` install method, etc.
",,,TMInnovations,"
--
Same problem here.

Only a guess.. I always add prefixes to my container names. You do so too in your example. Maybe it has to do something with the fact that (, when docker-compose builds the container_name itself, ) docker-compose inludes the parrent directory's name as prefix..
--
",,,,,,,,,,
7687,OPEN,Not able to install docker-compose on redhat 7 of ppc64le arch type.,kind/bug,2020-09-01 17:29:24 +0000 UTC,venkat44488,Opened,,"
<!--

Welcome to the docker-compose issue tracker! Before creating an issue, please heed the following:

1. This tracker should only be used to report bugs and request features / enhancements to docker-compose
    - For questions and general support, use https://forums.docker.com
    - For documentation issues, use https://github.com/docker/docker.github.io
    - For issues with the `docker stack` commands and the version 3 of the Compose file, use
      https://github.com/docker/cli
2. Use the search function before creating a new issue. Duplicates will be closed and directed to
   the original discussion.
3. When making a bug report, make sure you provide all required information. The easier it is for
   maintainers to reproduce, the faster it'll be fixed.
-->

## Description of the issue
**As I am trying to install docker-compose on redhat 7 power9 server its arch type is : ppc64le. getting below error Hardware is IBM power9 server**


## Context information (for bug reports)

[root@prh0706A1 software]# pip install docker-compose
Traceback (most recent call last):
  File ""/usr/local/bin/pip"", line 8, in <module>
    sys.exit(main())
  File ""/usr/lib/python2.7/site-packages/pip/_internal/cli/main.py"", line 73, in main
    command = create_command(cmd_name, isolated=(""--isolated"" in cmd_args))
  File ""/usr/lib/python2.7/site-packages/pip/_internal/commands/__init__.py"", line 104, in create_command
    module = importlib.import_module(module_path)
  File ""/usr/lib64/python2.7/importlib/__init__.py"", line 37, in import_module
    __import__(name)
  File ""/usr/lib/python2.7/site-packages/pip/_internal/commands/install.py"", line 14, in <module>
    from pip._internal.cache import WheelCache
  File ""/usr/lib/python2.7/site-packages/pip/_internal/cache.py"", line 15, in <module>
    from pip._internal.utils.temp_dir import TempDirectory, tempdir_kinds
  File ""/usr/lib/python2.7/site-packages/pip/_internal/utils/temp_dir.py"", line 11, in <module>
    from pip._vendor.six import ensure_text
ImportError: cannot import name ensure_text

**Output of `docker-compose version`**
```
(paste here)
```

**Output of `docker version`**
```
(paste here)
```

**Output of `docker-compose config`**
(Make sure to add the relevant `-f` and other flags)
```
(paste here)
```


## Steps to reproduce the issue

1.
2.
3.

### Observed result

### Expected result

### Stacktrace / full error message

```
(paste here)
```

## Additional information

OS version / distribution, `docker-compose` install method, etc.
",,,aiordache,"
--
Hi @venkat44488. Python2.7 is not supported anymore, please try with Python3.5 or later.
--
",,,,,,,,,,
7686,OPEN,OpenSSL version mismatch. Built against 1010106f; you have 101000cf,kind/bug,2021-02-21 23:22:51 +0000 UTC,Legion2,Opened,,"## Description of the issue

Error when using `docker-compose exec` with `DOCKER_HOST=ssh://...`

## Context information (for bug reports)

**Output of `docker-compose version`**
```
docker-compose version 1.26.2, build eefe0d31
docker-py version: 4.2.2
CPython version: 3.7.7
OpenSSL version: OpenSSL 1.1.0l  10 Sep 2019
```

**Output of `docker version`**
```
Client: Docker Engine - Community
 Version:           19.03.12
 API version:       1.40
 Go version:        go1.13.10
 Git commit:        48a66213fe
 Built:             Mon Jun 22 15:45:36 2020
 OS/Arch:           linux/amd64
 Experimental:      false

Server: Docker Engine - Community
 Engine:
  Version:          19.03.12
  API version:      1.40 (minimum version 1.12)
  Go version:       go1.13.10
  Git commit:       48a66213fe
  Built:            Mon Jun 22 15:49:27 2020
  OS/Arch:          linux/amd64
  Experimental:     false
 containerd:
  Version:          v1.2.13
  GitCommit:        7ad184331fa3e55e52b890ea95e65ba581ae3429
 runc:
  Version:          1.0.0-rc10
  GitCommit:        dc9208a3303feef5b3839f4323d9beb36df0a9dd
 docker-init:
  Version:          0.18.0
  GitCommit:        fec3683
```

**Output of `docker-compose config`**
```
version: '3'

services:
  portainer:
    image: portainer/portainer:1.24.1
    command: -H unix:///var/run/docker.sock
    volumes:
      - data:/data
      - /var/run/docker.sock:/var/run/docker.sock
    restart: unless-stopped

volumes:
  data:

```

## Steps to reproduce the issue

1. create a `.env` file and add `DOCKER_HOST=ssh://...` with a valid ssh host with docker engine
2. `docker-compose up -d`
3. `docker-compose exec portainer bash`

### Observed result
```
error during connect: Get http://docker/v1.40/containers/a1a823ab0e6b66087bf0fd609c34da5e70c23446cf19791f66d6bf277f14f89a/json: command [ssh -- example.org docker system dial-stdio] has exited with exit status 255, please make sure the URL is valid, and Docker 18.09 or later 
is installed on the remote host: stderr=OpenSSL version mismatch. Built against 1010106f, you have 101000cf
```
### Expected result

Open a bash terminal in the `portainer` container on the remote docker engine.

### Stacktrace / full error message

```
error during connect: Get http://docker/v1.40/containers/a1a823ab0e6b66087bf0fd609c34da5e70c23446cf19791f66d6bf277f14f89a/json: command [ssh -- example.org docker system dial-stdio] has exited with exit status 255, please make sure the URL is valid, and Docker 18.09 or later 
is installed on the remote host: stderr=OpenSSL version mismatch. Built against 1010106f, you have 101000cf
```

## Additional information

OS version / distribution, `docker-compose` install method, etc.
Running on WSL 2 Ubuntu on windows 10. The docker-compose is the one mounted from docker desktop.
But I also tested with a native linux machine.

I tested with two remote hosts, one google vm and one raspberry pi.
On the google vm:
```
Client:
 Version:           19.03.6
 API version:       1.40
 Go version:        go1.13.5
 Git commit:        369ce74
 Built:             Tue May 19 10:01:57 2020
 OS/Arch:           linux/amd64
 Experimental:      false

Server:
 Engine:
  Version:          19.03.6
  API version:      1.40 (minimum version 1.12)
  Go version:       go1.13.5
  Git commit:       369ce74
  Built:            Tue May 19 10:00:30 2020
  OS/Arch:          linux/amd64
  Experimental:     false
 containerd:
  Version:          1.3.2
  GitCommit:        ff48f57fc83a8c44cf4ad5d672424a98ba37ded6
 runc:
  Version:          1.0.0-rc10
  GitCommit:
 docker-init:
  Version:          0.18.0
  GitCommit:        fec3683b971d9c3ef73f284f176672c44b448662
```

On the raspberrypi:
```
Client: Docker Engine - Community
 Version:           19.03.12
 API version:       1.40
 Go version:        go1.13.10
 Git commit:        48a6621
 Built:             Mon Jun 22 15:53:41 2020
 OS/Arch:           linux/arm
 Experimental:      false

Server: Docker Engine - Community
 Engine:
  Version:          19.03.12
  API version:      1.40 (minimum version 1.12)
  Go version:       go1.13.10
  Git commit:       48a6621
  Built:            Mon Jun 22 15:47:34 2020
  OS/Arch:          linux/arm
  Experimental:     false
 containerd:
  Version:          1.2.13
  GitCommit:        7ad184331fa3e55e52b890ea95e65ba581ae3429
 runc:
  Version:          1.0.0-rc10
  GitCommit:        dc9208a3303feef5b3839f4323d9beb36df0a9dd
 docker-init:
  Version:          0.18.0
  GitCommit:        fec3683
```
I also tested with older docker compose version 1.25.5 and the newer 1.27.0-rc1.
",,,zorion79,"
--
I can run
```
docker-compose -H ssh://user@machine up
docker-compose -H ssh://user@machine build
docker -H ssh://user@machine up image prune -f
```
but this return error.
```
docker-compose -H ssh://user@machine run esb-kav
Creating esb-kav_esb-kav_run ... done
error during connect: Get http://docker/v1.40/containers/3c6e7690875470e51e1eca48100933e87a9aca25c298a70d5b48e09f33bd3de7/json: command [ssh -l user -- machine docker system dial-stdio] has exited with exit status 255, please make sure the URL is valid, and Docker 18.09 or later is installed on the remote host: stderr=OpenSSL version mismatch. Built against 1010106f, you have 101000cf
```
All version docker 19.03.12, docker-compose 1.27.2, openssl 1.1.1f - equals.
--
",qalex,"
--
I'm having the same issue. Guess this is because docker-compose is built against OpenSSL 1.1.0l:
```
$ docker-compose version 
docker-compose version 1.27.2, build 18f557f9
docker-py version: 4.3.1
CPython version: 3.7.7
OpenSSL version: OpenSSL 1.1.0l  10 Sep 2019
```
--
",mnowaczyk,"
--
As a workaround you can install docker-compose from PIP.
--
",al,"
--
I can reproduce the same behavior on Ubuntu 20.04:

#### OS Version
```
# lsb_release -a
No LSB modules are available.
Distributor ID:Ubuntu
Description:Ubuntu 20.04.2 LTS
Release:20.04
Codename:focal
```

#### Output of docker-compose version
```
# docker-compose version
docker-compose version 1.28.2, build 67630359
docker-py version: 4.4.1
CPython version: 3.7.9
OpenSSL version: OpenSSL 1.1.0l  10 Sep 2019
```
#### Result
```
# docker-compose -H ssh://user@machine up
OpenSSL version mismatch. Built against 1010106f, you have 101000cf
```

Any chance @chris-crone to fix the issue without using pip approach?


--
",adamburgess,"
--
Happened to me also on 20.04.
Using 1.28.0 works fine for now, and curiously it seems to be using a more recent version of openssl compared to 1.28.2:

```
$ docker-compose version
docker-compose version 1.28.0, build d02a7b1a
docker-py version: 4.4.1
CPython version: 3.9.0
OpenSSL version: OpenSSL 1.1.1d  10 Sep 2019
```
--
",laszukdawid,"
--
Can confirm that had the exact same issue with `1.28.2` but `1.28.0` worked fine. Downloaded releases directly from github.

```
$ openssl version
OpenSSL 1.1.1f  31 Mar 2020
$ uname -a
Linux junk 5.8.0-43-generic #49~20.04.1-Ubuntu SMP Fri Feb 5 09:57:56 UTC 2021 x86_64 x86_64 x86_64 GNU/Linux
```

--
"
7685,OPEN,docker-compose exec fails with No such container when using contexts,kind/bug,2020-11-23 20:32:24 +0000 UTC,charles-cooper,Opened,,"# Description of the issue
No such container is thrown when using a context referencing a remote host. The same command using docker, or docker-compose explicitly using the `-H` flag works fine.

## Context information (for bug reports)

**Output of `docker-compose version`**
```
docker-compose version 1.26.2, build unknown
```

**Output of `docker version`**
```
(local) Docker version 19.03.8, build afacb8b7f0
(remote) Docker version 19.03.8, build afacb8b7f0
```

**Output of `docker-compose config`**
(Make sure to add the relevant `-f` and other flags)
```
services:
  postgres:
...
```


## Steps to reproduce the issue
```
1. docker context create remote --docker ""host=tcp://<host>:<port>""
2. docker-compose --context remote up -d
3. docker-compose --context remote exec postgres echo 1
```
### Observed result
```
Error: No such container: <container_hash>
```

### Expected result
```
1
```

## Additional information

The same thing works in the following scenarios:
- `docker --context ask exec -it <container_id> echo 1`
- `docker-compose -H ""<host>:<port>"" exec postgres echo 1`
",,,abronin,"
--
I have the same issue. This make docker-compose with context completely useless for me.
--
",vdroznik,"
--
just ran into the same issue
--
",,,,,,,,
7675,OPEN,[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self signed certificate when using docker compose with DOCKER_HOST,kind/bug,2021-02-17 20:33:03 +0000 UTC,ivictbor,In progress,,"3. When making a bug report, make sure you provide all required information. The easier it is for
   maintainers to reproduce, the faster it'll be fixed.
-->

## Context information (for bug reports)

**Output of `docker-compose version`**
```
docker-compose version 1.26.2, build eefe0d31
docker-py version: 4.2.2
CPython version: 3.7.7
OpenSSL version: OpenSSL 1.1.0l  10 Sep 2019
```

**Output of `docker version`**
```
Client:
 Version:           19.03.6
 API version:       1.40
 Go version:        go1.12.17
 Git commit:        369ce74a3c
 Built:             Fri Feb 28 23:45:43 2020
 OS/Arch:           linux/amd64
 Experimental:      false

Server:
 Engine:
  Version:          19.03.6
  API version:      1.40 (minimum version 1.12)
  Go version:       go1.12.17
  Git commit:       369ce74a3c
  Built:            Wed Feb 19 01:06:16 2020
  OS/Arch:          linux/amd64
  Experimental:     false
 containerd:
  Version:          1.3.3-0ubuntu1~18.04.2
  GitCommit:
 runc:
  Version:          spec: 1.0.1-dev
  GitCommit:
 docker-init:
  Version:          0.18.0
  GitCommit:
```

**Output of `docker-compose config`**
(Make sure to add the relevant `-f` and other flags)
```
does not matter
```


## Steps to reproduce the issue

1. I want to use docker-compose with DOCKER_HOST setting and custom self signed certificates to deploy to another host
2. I copied `ca.pem`  `cert.pem`  `key.pem` generated on my server to `~/.docker`
3. did `export DOCKER_HOST=tcp://my.host:2376 DOCKER_TLS_VERIFY=1`
4. did `docker ps` and it works perfectly:
```
CONTAINER ID        IMAGE               COMMAND             CREATED             STATUS              PORTS               NAMES
```

### Observed result

Then, executing
```
docker-compose ps
ERROR: SSL error: HTTPSConnectionPool(host='my.host', port=2376): Max retries exceeded with url: /v1.30/volumes/deploy_v-db-data (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self signed certificate (_ssl.c:1076)')))
```

### Expected result

`docker-compose ps` works without an error and using same Environment variables

## Additional information

Checked another env variables which might prevent requests used in dockercompose to work wrong like `echo $REQUESTS_CA_BUNDLE`, they are empty.

How to debug it?
Thanks",,,ckotte,"
--
Does it work if you execute ```CURL_CA_BUNDLE='' docker-compose ps```?
--

--
Maybe it's an openssl issue? I could fix it by downgrading openssl from ```1.1.1h``` to ```1.1.1g```
```
# docker-compose version
docker-compose version 1.27.4, build unknown
docker-py version: 4.3.1
CPython version: 3.8.5
OpenSSL version: OpenSSL 1.1.1g  21 Apr 2020
```
--

--
@jankatins What versions are you using? Downgrading docker-compose didn't work on my side - only downgrading openssl... I also use a QNAP NAS. I suspect the certs are invalid and a change introduced in openssl 1.1.1h could be the issue
--

--
I bet it works if you downgrade openssl. I think it's related to this change: ""Disallow explicit curve parameters in verifications chains when X509_V_FLAG_X509_STRICT is used"". The docker certificates on QNAP are regenerated automatically before they expire, but I couldn't find a way to regenerate them manually. It's probably an issue with the certificates and maybe it could be resolved with new certificates...
--

--
@krugerm-4c I didn't say ```CURL_CA_BUNDLE=""""``` is a valid option. It's just a workaround to be able to use docker-compose. What's your workaround??? May I ask what openssl version you are using?
--
",ivictbor,"
--
> Does it work if you execute `CURL_CA_BUNDLE='' docker-compose ps`?

Thanks a lot for reply, seams like this env var was also empty, but I will recheck soon and let know. 

For now we use ssh url in docker_host which seams to be slower. 

@ckotte Most interesting fact for me - why does it work perfectly when certs are generated by docker-machine? I tried and all environment variables were same! Only differece is that I generated certificates with openssl.
--

--
@krugerm-4c Just in case, might be useful for you - when I faced the issue, I had really no time to properly investigate it, so now I am using plain SSH in DOCKER_HOST, details are here if you need it: https://hinty.io/ivictbor/deploy-docker-compose-using-drone-ci/ 
We are using it for tens prod instances and I really satisfied, so even don't want to spend time on certificates now.

Pros:
- Really simple setup, what you need is just `export DOCKER_HOST=ssh://root@ip` and no certificates staff at all, no docker machines, plus couple of lines in ssh config to accept multiple connections (added in post above).
- SSH is pretty secure way to connect

Drawbacks:
- Might be slower, takes several additional second for each layer to build? But not a big deal if you set up layers in Dockerfiles in a right way.


--
",jankatins,"
--
I had the same error (running against qnap nas, which gave me the cert bundle to install in ~/.docker) and the following fixed it for me. I run a debian unstable on my laptop and just updated docker-compose with pip.

> Does it work if you execute CURL_CA_BUNDLE='' docker-compose ps?
--

--
QNAP is on latest version for my NAS (4.4.3.1444) and docker compose is  1.27.4. OS on laptop is debian unstable. Openssl debian package is `openssl   1.1.1h-1`:

``` 
$ docker-compose version
docker-compose version 1.27.4, build unknown
docker-py version: 4.3.1
CPython version: 3.8.6
OpenSSL version: OpenSSL 1.1.1h  22 Sep 2020
``` 
--
",krugerm,"
--
Hi, I am also having this issue where I followed the official Docker Documentation to setup TLS on the Docker Daemon (https://docs.docker.com/engine/security/https/), but I'm also getting the `[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self signed certificate` issue.

Surely there needs to be a way to point `docker-compose` to the generated certificates to allow it?

I honestly don't think setting ` CURL_CA_BUNDLE=''` is a viable option as this technically circumvents the verify check.
--

--
@ckotte For the time being I am using the `CURL_CA_BUNDLE` environment variable just to be able to continue with my work.  Currently I have the following OpenSSL versions (docker-compose and host-level respectively).

`
docker-compose version 1.27.4, build 40524192
docker-py version: 4.3.1
CPython version: 3.7.7
OpenSSL version: OpenSSL 1.1.0l  10 Sep 2019
`

`
OpenSSL 1.0.2k-fips  26 Jan 2017
`

Unfortunately I am not in a position to change the host's openssl version as this is approved and managed by our security team.  Thus I am looking for an elegant solution from the application's (docker-compose) perspective without having to compromise security elements.
--

--
> Most likely this is a bug that needs to be corrected.
> My best guess is that docker-compose is not passing (or passing correctly) the DOCKER_CERT_PATH variable, from the Docker environment variables.
> Anyone managed to get docker-compose to work?

Nope. This has still been an issue for me.
--
",hholst80,"
--
I can reproduce this with just docker-py version: 4.3.1

```
import docker
print(""docker-py version: %s"" % docker.__version__)
client = docker.from_env()
```
--

--
docker compose uses docker-py, and docker-py has the issue. its a problem upstream from docker-compose.

the workaround is to set `export DOCKER_CERT_PATH=""$HOME/.docker""`
--
",sceptic30,"
--
 Most likely this is a bug that needs to be corrected.
My best guess is that docker-compose is not passing (or passing correctly) the DOCKER_CERT_PATH variable, from the Docker environment variables.
Anyone managed to get docker-compose to work?


--
"
7674,OPEN,`docker-compose up --no-build` should not require the existence of the build context directories,kind/feature,2021-01-22 21:23:56 +0000 UTC,zeehio,Opened,,"-->

**Is your feature request related to a problem? Please describe.**
In a production system, I would like to use `docker-compose up --no-build` but I can't when the build context directory does not exist, even though it is not used:



    ERROR: build path my/build/context either does not exist, is not accessible, or is not a valid URL.


**Describe the solution you'd like**
`docker-compose up --no-build` should not require the existence of build context directories.

**Describe alternatives you've considered**
I can run `mkdir -p my/build/context` before `docker-compose up --no-build`, but it's kind of annoying to have to do that.

**Additional context**

Discussion at: https://stackoverflow.com/q/53389151/446149
",,,woo2,"
--
Looks like this was fixed in [1.27.0](https://github.com/docker/compose/releases/tag/1.27.0)!
--
",,,,,,,,,,
7672,OPEN,Logging docker commands generated from compose files,kind/feature,2020-08-17 05:59:15 +0000 UTC,ozkanonur,In progress,,Wouldn't it be perfect if docker-compose can log the docker commands in a log file? This can work tremendously for many projects and helps us to reduce time in the development process. Compose already runs everything as a docker commands right ? I think it shouldn't be hard to do this feature. Tell me if this request is reasonable so I can start creating this feature and PR it to main repository.,,,m3yilmazz,"
--
The feature that mentioned above will be great if it become alive.
--
",ftahirops,"
--
@ozkanonur Can you please further elaborate with some example? what do you mean by docker compose commands? 
--
",ozkanonur,"
--
> @ozkanonur Can you please further elaborate with some example? what do you mean by docker compose commands?

An example, I will use docker-compose for only development purpose and docker commands with kubernetes on production. Since every service in compose file has its counterpart in the docker command, it would be fantastic if we can get that instead of writing manually for each container.
--
",,,,,,
7669,OPEN,Add docker-compose tag <service> <tag> and allow to push a specific tag by using push command,kind/feature,2020-08-14 14:42:57 +0000 UTC,Jokero,Opened,,"-->

**Is your feature request related to a problem? Please describe.**
I have several applications with their own Dockerfile within one project and in order to build, launch and test them locally I'm using docker-compose.

It seems like a good idea to reuse docker-compose commands to build, test and push images to registry from CI, so I decided to use them in Jenkinsfile. Project has package.json file with current version which is incremented during CI build. This version is used as tag for docker images.

docker-compose.yaml:
```
version: '2'

services:
  app1:
    image: my-registry.com/app1
    build:
      context: ./app1
    // other fields
  app2:
    image: my-registry.com/app2
    build:
      context: ./app2
    // other fields
  app3:
    image: my-registry.com/app3
    build:
      context: ./app3
    // other fields
```

The current CI pipeline looks as follows:
```
1) Build images
docker-compose build // generates images with ""latest"" tag

2) Test images
docker-compose run --rm app1 <test command> // the same for app2 and app3

3) If tests passed, increment version and use it as the next docker tag
npm version <patch/minor/major>
newVersion = readJSON('package.json').version

4) Tag and push images
composeServices = readYaml('docker-compose.yaml').services // { app1: { image: my-registry.com/app1 }, ... }
image = composeServices.app1.image // the same for app2 and app3
docker tag <image> <image>:<newVersion>
docker push <image>:<newVersion>
```
This pipeline works but I have to read compose file to get image that will be used in ""docker tag"" and ""docker push"" commands.


**Describe the solution you'd like**
I'd like to have a new command:
```
docker-compose tag <service> <tag>
// for my example
docker-compose tag app1 <version from updated package.json>
```
And I want ""push"" command to support tag postfix:
```
docker-compose push <service>:<tag>
// for my example
docker-compose push app1:<version from updated package.json>
```

**Describe alternatives you've considered**
Using ""docker tag"" and ""docker push"" explicitly but for that I need to read images from docker-compose.yaml file
",,,,,,,,,,,,,,
7667,OPEN,docker-compose never runs on Mac Catalina,kind/bug,2020-10-02 09:34:38 +0000 UTC,deepakSense,Opened,,"
## Description of the issue
I am using Docker App on mac and when I hit docker-compose command it does this

`docker-compose version
Killed: 9`

## Context information (for bug reports)

**Output of `docker-compose version`**
```
Killed: 9
```

**Output of `docker version`**
```
Client: Docker Engine - Community
 Version:           19.03.8
 API version:       1.40
 Go version:        go1.12.17
 Git commit:        afacb8b
 Built:             Wed Mar 11 01:21:11 2020
 OS/Arch:           darwin/amd64
 Experimental:      false

Server: Docker Engine - Community
 Engine:
  Version:          19.03.8
  API version:      1.40 (minimum version 1.12)
  Go version:       go1.12.17
  Git commit:       afacb8b
  Built:            Wed Mar 11 01:29:16 2020
  OS/Arch:          linux/amd64
  Experimental:     false
 containerd:
  Version:          v1.2.13
  GitCommit:        7ad184331fa3e55e52b890ea95e65ba581ae3429
 runc:
  Version:          1.0.0-rc10
  GitCommit:        dc9208a3303feef5b3839f4323d9beb36df0a9dd
 docker-init:
  Version:          0.18.0
  GitCommit:        fec3683
```

**Output of `docker-compose config`**
(Make sure to add the relevant `-f` and other flags)
```
Killed: 9
```


## Steps to reproduce the issue

1. I installed Docker App for Mac.
2. Created a Yaml file for Compose
3. Tried running docker-compose
4. Enabled ""Experimental Features"" in the Command Line preferences of the App and tried again.

### Observed result
docker-compose doesn't run

### Expected result
docker-compose should run

### Stacktrace / full error message

```
Killed: 9
```

## Additional information

OS version / distribution, `docker-compose` install method, etc.
",,,erfan,"
--
I could not reproduce this problem in mac os catalina using exactly the same version of docker app.
--
",kuklyy,"
--
Could you please attach your compose file?
--
",,,,,,,,
7652,OPEN,unable to trap signal when containers are shut down with --abort-on-container-exit,kind/bug,2021-02-06 15:43:06 +0000 UTC,marten-seemann,Opened,,"3. When making a bug report, make sure you provide all required information. The easier it is for
   maintainers to reproduce, the faster it'll be fixed.
-->

## Description of the issue

It looks like it's not possible to trap the SIGTERM signal when a container is shut down when another container exits and `--abort-on-container-exit` is used.

## Context information (for bug reports)

**Output of `docker-compose version`**
```
docker-compose version 1.26.2, build eefe0d31
docker-py version: 4.2.2
CPython version: 3.7.7
OpenSSL version: OpenSSL 1.1.1g  21 Apr 2020
```

**Output of `docker version`**
```
Client: Docker Engine - Community
 Version:           19.03.12
 API version:       1.40
 Go version:        go1.13.10
 Git commit:        48a66213fe
 Built:             Mon Jun 22 15:41:33 2020
 OS/Arch:           darwin/amd64
 Experimental:      false

Server: Docker Engine - Community
 Engine:
  Version:          19.03.12
  API version:      1.40 (minimum version 1.12)
  Go version:       go1.13.10
  Git commit:       48a66213fe
  Built:            Mon Jun 22 15:49:27 2020
  OS/Arch:          linux/amd64
  Experimental:     true
 containerd:
  Version:          v1.2.13
  GitCommit:        7ad184331fa3e55e52b890ea95e65ba581ae3429
 runc:
  Version:          1.0.0-rc10
  GitCommit:        dc9208a3303feef5b3839f4323d9beb36df0a9dd
 docker-init:
  Version:          0.18.0
  GitCommit:        fec3683
```

**Output of `docker-compose config`**

This is the `docker-compose.yml`:
```yaml
version: ""3.5""
services:
  short:
    build: .
    environment: 
    - DURATION=2
  long:
    build: .
    container_name: long
    environment: 
    - DURATION=100
```

## Steps to reproduce the issue

The containers are built using the following `Dockerfile`:
```Dockerfile
FROM ubuntu:latest

COPY run.sh .
RUN chmod +x run.sh
ENTRYPOINT [ ""./run.sh"" ]
```

with the following `run.sh`:
```bash
#!/bin/bash

trap ""echo EXIT"" EXIT
trap ""echo SIGNIT"" SIGINT
trap ""echo SIGTERM"" SIGTERM
trap ""echo SIGKILL"" SIGKILL
trap ""echo SIGQUIT"" SIGQUIT

echo ""Sleeping $DURATION seconds.""
sleep $DURATION & wait
```

### Observed result

When starting the containers with `docker-compose up`, and then shutting down container `long` using `docker stop long`, it receives both a SIGTERM and an EXIT signal.
When starting the containers with `docker-compose up --abort-on-container-exit`, container `long` is stopped, but doesn't receive any signal.

### Expected result

I expected container `long` to trap the same signals as when using `docker stop long`.


",,,stale,"
--
This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you for your contributions.

--

--
This issue has been automatically marked as not stale anymore due to the recent activity.

--
",marten,"
--
This issue is not stale. Its just that nobody has bothered to even look at it, as far as I can tell.
--
",,,,,,,,
7649,OPEN,using multiple compose files in different directories leads to undefined behavior,kind/bug,2020-09-05 07:07:11 +0000 UTC,Zorigt,Opened,,"Depending on what directory I am calling docker compose, my docker service names reflect the local directory `docker-compose.yml` file. To get around it, I have to use -p flag like so.

`docker-compose -p desired-prefix -f /path/docker-compose.yml`

It should use the docker-compose.yml file specified in the path. 






",,,franzwong,"
--
It is more like a design decision instead of bug to me. I guess the maintainer chose the current folder instead of the folder of yaml file because you can provide multiple yaml files to `docker-compose`. Then some people will ask to use the first one while some other people will ask to use the last one.
--
",,,,,,,,,,
7648,OPEN,disable env variable substitution in docker compose env files,kind/feature,2021-01-11 17:10:55 +0000 UTC,simonm11,In progress,,"I updated docker and notice a significant change of behavior when using my env files in docker-compose

I have the following:

```
env_file:
      - ./file.env
```
and, in file.env
```
property=${something}
```
Before updating, doing `echo $property` in my running container would produce the string `${something}`. Which was what I wanted.

Now (docker 19.03.12), `$property` is empty because docker is trying to find `$something` from my system env variables.

What caused this change of behavior? Is there a way to disable it or work around it?",,,ImDevinC,"
--
This looks similar to the issue I reported awhile ago, unfortunately no response yet: #7601 
--

--
@simonm11 I found that removing the `{}` from my variable seemed to help. IE: Changing `${SAMPLE_ARG}` to `$SAMPLE_ARG`. I'm sure there are some situations where the brackets will be needed, but I lucked out in my case where they weren't needed
--

--
It's been awhile since I've visited this, but I've been using the workaround above for my solution, just remove the `{}` from your variable so instead of `${xxx}` you can use `$xxx`
--
",simonm11,"
--
did you find some kind of work around in the meanwhile?
--

--
Is it a bug or an intended feature ?
--
",dominikbraun,"
--
> What caused this change of behavior?

Possibly https://github.com/docker/compose/pull/7150.
--
",nikasioMel,"
--
Hi @ImDevinC, we are having same issue.

We update docker-compose from **1.25.4** to **1.27.4** and start trying to subtitute `${xxx}` variables. Unfortunatly we can't remove brackets as you mentioned in previous comment.
Is there any way to tell compose to not to replace variables?

--

--
Unfortunately **Spring** needs brackets to replace the variables when it starts the application, as docker replacement occurred before the variable is erased at the moment Spring needs it. We will continue using **1.25.5**
It would be great if it could be disabled in docker-compose
Thanks anyway.
--
",,,,
7645,OPEN,[BUG] Overriding of the 'ports' directive doesn't working when original port already in use,kind/bug,2021-02-02 15:14:38 +0000 UTC,chief93,In progress,,"Hi everyone! I've encountered this behavior, by creating the `docker-compose.override.yml`. The files used:

`docker-compose.yml`:
```yml
version: '3.2'
services:
  app:
    build:
      context: ./
    ports:
     - ""8000:80""
    volumes:
     - ./:/app
```

`docker-compose.override.yml`:
```yml
version: '3.2'
services:
  app:
    ports:
     - ""8001:80""
```

That gives me following UNEXPECTED error:
```
ERROR: for my_app_1  Cannot start service app: driver failed programming external connectivity on endpoint my_app_1 (9235372fe636fba32be67f9f101a3432139c691a41fc6d207e53c98e25139a29): Bind for 0.0.0.0:8000 failed: port is already allocated

ERROR: for app  Cannot start service app: driver failed programming external connectivity on endpoint my_app_1 (9235372fe636fba32be67f9f101a3432139c691a41fc6d207e53c98e25139a29): Bind for 0.0.0.0:8000 failed: port is already allocated
ERROR: Encountered errors while bringing up the project.
```

I expected that `ports` directive in `docker-compose.override.yml` will override same in the `docker-compose.yml` (the `8000` port on my machine is already allocated by another application, that's why I tried the overriding) but this does not happen, which is wrong and seems like a bug.

OS: `Windows 10`
Docker: `19.03.12, build 48a66213fe`",,,stale,"
--
This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you for your contributions.

--

--
This issue has been automatically marked as not stale anymore due to the recent activity.

--
",chief93,"
--
I think that auto-closing of the issues is the very bad practice...
--
",,,,,,,,
7642,OPEN,Check engine API and warn user for feature that can't be implemented,kind/feature,2020-08-03 12:06:46 +0000 UTC,aiordache,Opened,,"Docker Compose should check API exposed by the engine (docker info ApiVersion) and warn user if some of the fields set by his `docker-compose.yml` file can't be implemented with this version of the API.

Related to https://github.com/docker/compose/issues/7201
",,,,,,,,,,,,,,
7636,OPEN,Embed config in docker-compose.yaml file,kind/feature,2020-07-28 04:29:26 +0000 UTC,yegle,Opened,,"-->

**Is your feature request related to a problem? Please describe.**

One common way of using a container image built by some other people is by mounting a config file into the container.

E.g. if I want to run `coredns`, I will grab `coredns/coredns` image, mount my own config to `/Corefile`, and run the container.

But doing this means after I edit my `Corefile`, I'll need to remember run `docker restart coredns` or `docker-compose restart coredns`, instead of simply running `docker-compose up -d`.

**Describe the solution you'd like**
The easiest way is to be able to embed the Corefile inside the `docker-compose.yaml` file, something like this:

```
services:
  coredns:
    image: coredns/coredns
    config:
      - path: /Corefile
        content:|
          # Embedded Corefile
          . {
              whoami
          }
```

This way I can either just embed the config, or use tools like `jsonnet` to generate a `docker-compose.yaml` with embedded config.

**Describe alternatives you've considered**

Alternatively we can support `src_file` like this, and use the change of file hash to signal the need to restart the container:

```
services:
  coredns:
    image: coredns/coredns
    config:
      - path: /Corefile
        src_file: ./Corefile
```

Without adding this as a new feature I don't see a simple way to support what I need (edit config file A result in `docker-compose up -d` to restart container B).

**Additional context**
Add any other context or screenshots about the feature request here",,,,,,,,,,,,,,
7630,OPEN,Connection broken: IncompleteRead,kind/bug,2020-11-09 10:35:56 +0000 UTC,dayrim,Opened,,"## Description of the issue

Receiving an error while running a docker compose command inside a CI/CD pipeline hosted on bitbucket. Works locally but not in a CI/CD pipeline that is using latest docker/compose image from docker hub. The error appears during a specific Dockerfile step which is running a NodeJS script for building react application (react-scripts build). 

## Context information (for bug reports)

**Output of `docker-compose version`**
```
docker-compose version 1.26.2, build eefe0d3
docker-py version: 4.2.2
CPython version: 3.7.7
OpenSSL version: OpenSSL 1.1.1g  21 Apr 2020
```

**Output of `docker version`**
```
Client: Docker Engine - Community
 Version:           19.03.8
 API version:       1.39 (downgraded from 1.40)
 Go version:        go1.12.17
 Git commit:        afacb8b7f0
 Built:             Wed Mar 11 01:22:56 2020
 OS/Arch:           linux/amd64
 Experimental:      false
Server: Docker Engine - Community
 Engine:
  Version:          18.09.1
  API version:      1.39 (minimum version 1.12)
  Go version:       go1.10.6
  Git commit:       4c52b90
  Built:            Wed Jan  9 19:41:57 2019
  OS/Arch:          linux/amd64
  Experimental:     false
```

**Output of `docker-compose config`**
(Make sure to add the relevant `-f` and other flags)
```
services:
  web-legion:
    build:
      args:
        NODE_ENV: production
      context: /opt/atlassian/pipelines/agent/build/apps/web-legion
      dockerfile: Dockerfile
    image: ftwopen/web-legion:0.1.10
    labels:
      kompose.service.expose: ""true""
      kompose.service.type: loadbalancer
    ports:
    - 80:80/tcp
version: '3.0'
```

### Observed result
Received an error while running react-scripts build step.

### Expected result
Proceed to next step of Dockerfile build order. 

### Stacktrace / full error message

```
Step 11/11 : RUN yarn run build
 ---> Running in 04312ffc1a3f
yarn run v1.22.4
$ react-scripts build
Creating an optimized production build...
[52] Failed to execute script docker-compose
Traceback (most recent call last):
  File ""http/client.py"", line 554, in _get_chunk_left
  File ""http/client.py"", line 521, in _read_next_chunk_size
ValueError: invalid literal for int() with base 16: b''
During handling of the above exception, another exception occurred:
Traceback (most recent call last):
  File ""http/client.py"", line 586, in _readinto_chunked
  File ""http/client.py"", line 556, in _get_chunk_left
http.client.IncompleteRead: IncompleteRead(0 bytes read)
During handling of the above exception, another exception occurred:
Traceback (most recent call last):
  File ""site-packages/urllib3/response.py"", line 437, in _error_catcher
  File ""site-packages/urllib3/response.py"", line 519, in read
  File ""http/client.py"", line 457, in read
  File ""http/client.py"", line 491, in readinto
  File ""http/client.py"", line 602, in _readinto_chunked
http.client.IncompleteRead: IncompleteRead(0 bytes read)
During handling of the above exception, another exception occurred:
Traceback (most recent call last):
  File ""bin/docker-compose"", line 6, in <module>
  File ""compose/cli/main.py"", line 72, in main
  File ""compose/cli/main.py"", line 128, in perform_command
  File ""compose/cli/main.py"", line 304, in build
  File ""compose/project.py"", line 403, in build
  File ""compose/project.py"", line 385, in build_service
  File ""compose/service.py"", line 1110, in build
  File ""compose/progress_stream.py"", line 25, in stream_output
  File ""compose/utils.py"", line 61, in split_buffer
  File ""compose/utils.py"", line 37, in stream_as_text
  File ""site-packages/docker/api/client.py"", line 345, in _stream_helper
  File ""site-packages/urllib3/response.py"", line 541, in read
  File ""contextlib.py"", line 130, in __exit__
  File ""site-packages/urllib3/response.py"", line 455, in _error_catcher
urllib3.exceptions.ProtocolError: ('Connection broken: IncompleteRead(0 bytes read)', IncompleteRead(0 bytes read))
```

## Additional information

Running the latest docker/compose image. Linux/amd64. https://hub.docker.com/layers/docker/compose/latest/images/sha256-b60a020c0f68047b353a4a747f27f5e5ddb17116b7b018762edfb6f7a6439a82?context=explore

Related: https://github.com/docker/compose/issues/3387

",,,mdczaplicki,"
--
Same here in bitbucket pipelines. But bitbucket says whats going on:
```
Container 'docker' exceeded memory limit.
```
You can increase docker memory limit:
https://support.atlassian.com/bitbucket-cloud/docs/run-docker-commands-in-bitbucket-pipelines/#RunDockercommandsinBitbucketPipelines-Dockermemorylimits
--
",Madvinking,"
--
same issue with jenkins pipeline.
ubuntu xenial
docker-compose version 1.27.4
Docker version 19.03.13
--
",,,,,,,,
7627,OPEN,Docker-Compose Ignores Exposed TCP/UDP on same Port,kind/bug,2020-10-21 09:20:38 +0000 UTC,moloch--,Opened,,"# Description of the issue

Docker Compose ignore rules mapping both TCP and UDP to the same port, and does not produce an error or warning.

For example:

```
version: '3.8'

services:
  foobar:
    build: ./foobar-server
    ports:
      - ""13100:13100/tcp""
      - ""13101:13101/tcp""
      - ""13102:13102/tcp""
      - ""13100:13100/udp""
      - ""13101:13101/udp""
      - ""13102:13102/udp""
```

Results in:

```
$ docker ps
CONTAINER ID        IMAGE               COMMAND                  CREATED             STATUS              PORTS                                  NAMES
59468a55e31b        foo_bar       ""/opt/entrypoint con""   35 minutes ago      Up 7 minutes        0.0.0.0:13100-13102->13100-13102/tcp   foo_bar_1
```

Docker inspect shows:

```
        ""NetworkSettings"": {
            ""Bridge"": """",
            ""SandboxID"": ""d797c60152a36a7762e6bb77f01119cc3d39e40333d3b6c98aa19d5587425663"",
            ""HairpinMode"": false,
            ""LinkLocalIPv6Address"": """",
            ""LinkLocalIPv6PrefixLen"": 0,
            ""Ports"": {
                ""13100/tcp"": [
                    {
                        ""HostIp"": ""0.0.0.0"",
                        ""HostPort"": ""13100""
                    }
                ],
                ""13101/tcp"": [
                    {
                        ""HostIp"": ""0.0.0.0"",
                        ""HostPort"": ""13101""
                    }
                ],
                ""13102/tcp"": [
                    {
                        ""HostIp"": ""0.0.0.0"",
                        ""HostPort"": ""13102""
                    }
                ]
            },
```

## Context information (for bug reports)

**Output of `docker-compose version`**
```
docker-compose version 1.26.2, build eefe0d31
docker-py version: 4.2.2
CPython version: 3.7.7
OpenSSL version: OpenSSL 1.1.0l  10 Sep 2019
```

**Output of `docker version`**

```
Client: Docker Engine - Community
 Version:           19.03.12
 API version:       1.40
 Go version:        go1.13.10
 Git commit:        48a66213fe
 Built:             Mon Jun 22 15:45:44 2020
 OS/Arch:           linux/amd64
 Experimental:      false

Server: Docker Engine - Community
 Engine:
  Version:          19.03.12
  API version:      1.40 (minimum version 1.12)
  Go version:       go1.13.10
  Git commit:       48a66213fe
  Built:            Mon Jun 22 15:44:15 2020
  OS/Arch:          linux/amd64
  Experimental:     false
 containerd:
  Version:          1.2.13
  GitCommit:        7ad184331fa3e55e52b890ea95e65ba581ae3429
 runc:
  Version:          1.0.0-rc10
  GitCommit:        dc9208a3303feef5b3839f4323d9beb36df0a9dd
 docker-init:
  Version:          0.18.0
  GitCommit:        fec3683
```

**Output of `docker-compose config`**
(Make sure to add the relevant `-f` and other flags)
```
$ docker-compose config
services:
  foo:
    build:
      context: /home/moloch/foo/foo-server
    ports:
    - protocol: tcp
      published: 13100
      target: 13100
    - protocol: tcp
      published: 13101
      target: 13101
    - protocol: tcp
      published: 13102
      target: 13102
    - protocol: udp
      published: 13100
      target: 13100
    - protocol: udp
      published: 13101
      target: 13101
    - protocol: udp
      published: 13102
      target: 13102
    volumes:
    - /home/moloch/foo/data:/data:rw
version: '3.8'
```


## Steps to reproduce the issue

1. Map a TCP/UDP port 
2. `docker-compose up`

### Observed result

Docker compose only maps the TCP port (or first occurrence).

### Expected result

Docker Compose maps both TCP/UDP to the specified port, or produces an error message.
",,,quentinsf,"
--
As a workaround, I found that if I didn't make the port specifications identical, it would accept both.  In my case, I wanted both tcp and udp on port 24224, so I requested UDP for that port and TCP for a range which included it.
```
    ports:
      - ""24223-24225:24223-24225/tcp""
      - ""24224:24224/udp""
```

This seems to have worked, though I confess I haven't tested it with actual code yet! 

--
",,,,,,,,,,
7624,OPEN,Env files require strict whitespace,kind/bug,2020-11-21 01:54:06 +0000 UTC,joerobot,Opened,,"## Description of the issue

As of version 1.26.0 and using `python-dotenv` for env files, env files must have strict whitespace else error is triggered:

>WARNING: Python-dotenv could not parse statement starting at line 1
>WARNING: The FOO variable is not set. Defaulting to a blank string.

For example:
```
.env
FOO={""white"":""space""} // OK (no spaces)

FOO={ ""white"" : ""space"" } // OK (single spaces)

FOO={  ""white"":""space""} // NOT OK (double spaces)

FOO={    ""white"":""space""} // NOT OK (multiple spaces)
```

This became an issue for me as I have several `.env` files that are dynamically created, obviously I could more strictly write these files as a fix but figured other people might experience this issue as they update. An update to documentation would be a sufficent fix I suppose :)

## Context information (for bug reports)

**Output of `docker-compose version`**
```
docker-compose version 1.26.2, build eefe0d31
docker-py version: 4.2.2
CPython version: 3.7.7
OpenSSL version: OpenSSL 1.1.1g  21 Apr 2020
```

**Output of `docker version`**
```
Client: Docker Engine - Community
 Azure integration  0.1.7
 Version:           19.03.12
 API version:       1.40
 Go version:        go1.13.10
 Git commit:        48a66213fe
 Built:             Mon Jun 22 15:41:33 2020
 OS/Arch:           darwin/amd64
 Experimental:      true

Server: Docker Engine - Community
 Engine:
  Version:          19.03.12
  API version:      1.40 (minimum version 1.12)
  Go version:       go1.13.10
  Git commit:       48a66213fe
  Built:            Mon Jun 22 15:49:27 2020
  OS/Arch:          linux/amd64
  Experimental:     true
 containerd:
  Version:          v1.2.13
  GitCommit:        7ad184331fa3e55e52b890ea95e65ba581ae3429
 runc:
  Version:          1.0.0-rc10
  GitCommit:        dc9208a3303feef5b3839f4323d9beb36df0a9dd
 docker-init:
  Version:          0.18.0
  GitCommit:        fec3683
```

**Output of `docker-compose config`**
(Make sure to add the relevant `-f` and other flags)
```
WARNING: Python-dotenv could not parse statement starting at line 1
WARNING: The FOO variable is not set. Defaulting to a blank string.
services:
  test:
    build:
      context: .
    command: 'echo '
version: '3.0'


.env
FOO={""foo"":  ""bar""}
```


## Steps to reproduce the issue

1. Include a double space in a `.env` file
2. Echo variable in `docker-compose.yaml`
3. `docker-compose up`

### Observed result

```
WARNING: Python-dotenv could not parse statement starting at line 1
WARNING: The FOO variable is not set. Defaulting to a blank string.
WARNING: Python-dotenv could not parse statement starting at line 1
WARNING: Python-dotenv could not parse statement starting at line 1
Recreating test ... done
Attaching to composetest_test_1
test_1  | 
composetest_test_1 exited with code 0
```

### Expected result
Foo variable is echoed. 
",,,Pomax,"
--
As a team member on a project that never installed python-dotenv, running into this has been quite the frustration: rather than a mere docs update, there is no reason to force a stricter .env format: can this rule be turned off again? We don't even have complex rules, it's tripping up over things that are absolutely supposed to work, like `CSP_FONT_SRC='self' https://fonts.gstatic.com https://fonts.googleapis.com`, and it doesn't even seem to offer anything helpful beyond saying ""something"" is wrong, not ""what"" is wrong:
```
WARNING: Python-dotenv could not parse statement starting at line 47
WARNING: Python-dotenv could not parse statement starting at line 51
WARNING: Python-dotenv could not parse statement starting at line 53
WARNING: Python-dotenv could not parse statement starting at line 55
WARNING: Python-dotenv could not parse statement starting at line 56
WARNING: Python-dotenv could not parse statement starting at line 57
WARNING: Python-dotenv could not parse statement starting at line 47
WARNING: Python-dotenv could not parse statement starting at line 51
WARNING: Python-dotenv could not parse statement starting at line 53
WARNING: Python-dotenv could not parse statement starting at line 55
WARNING: Python-dotenv could not parse statement starting at line 56
WARNING: Python-dotenv could not parse statement starting at line 57
WARNING: Python-dotenv could not parse statement starting at line 47
WARNING: Python-dotenv could not parse statement starting at line 51
WARNING: Python-dotenv could not parse statement starting at line 53
WARNING: Python-dotenv could not parse statement starting at line 55
WARNING: Python-dotenv could not parse statement starting at line 56
WARNING: Python-dotenv could not parse statement starting at line 57
WARNING: Python-dotenv could not parse statement starting at line 47
WARNING: Python-dotenv could not parse statement starting at line 51
WARNING: Python-dotenv could not parse statement starting at line 53
WARNING: Python-dotenv could not parse statement starting at line 55
WARNING: Python-dotenv could not parse statement starting at line 56
WARNING: Python-dotenv could not parse statement starting at line 57
WARNING: Python-dotenv could not parse statement starting at line 47
WARNING: Python-dotenv could not parse statement starting at line 51
WARNING: Python-dotenv could not parse statement starting at line 53
WARNING: Python-dotenv could not parse statement starting at line 55
WARNING: Python-dotenv could not parse statement starting at line 56
WARNING: Python-dotenv could not parse statement starting at line 57
```
--

--
yes, that's _one_ of the things you need to do in ""strict"" mode, but there is no reason for Docker to force strict env parsing in the first place, and at the very least that should be an option that can be turned on/off.
--
",tgsmith61591,"
--
Anyone make any progress on this?
--
",lil12t,"
--
> Anyone make any progress on this?

I've got the same problem, the issue was in CI/CD config, it was SERVICE_NAME:'value' instead of SERVICE_NAME=value.


--
",franzwong,"
--
I got the same problem when my env looks like this.

```
TEST=""Hello"",""World""
```
--
",cobolbaby,"
--
Need to add double quotes to the value.

e.g. `TEST=""'Hello','World'""`


--

--
From the [docker-compose release notes](https://docs.docker.com/compose/release-notes/#bug-fixes-2), I found that `python-dotenv` was introduced into version 1.26 . I suspect that the root cause of the problem is due to the compatibility of`python-dotenv`.
--
",,
7622,OPEN,docker-compose stopped responding to SIGINT and SIGTSTP,kind/bug,2021-02-14 00:26:34 +0000 UTC,rightisleft,In progress,,"3. When making a bug report, make sure you provide all required information. The easier it is for
   maintainers to reproduce, the faster it'll be fixed.
-->

## Description of the issue

docker-compose stopped responding to sig* signals and will not stop or background the process. Im running a remote server of Ubuntu 18.04 and im testing some services using docker-compose. When i ssh into the box and issue a stop or background command using ctrl-c or ctrl-z, the remote process is not responding. I have to close the session to detach.

After running docker-compose up - ctrl-z just shows:

```
^Z^Z^Z^Z^Z^Z
```
The services themselves are running correctly.

- docker-compose version 1.26.2, build eefe0d31
- ubuntu 18.04

## Context information (for bug reports)

This happens across multiple projects with their own docker-compose files 

## Additional information

OS version / distribution, `docker-compose` install method, etc.
```
sudo curl -L ""https://github.com/docker/compose/releases/download/1.26.2/docker-compose-$(uname -s)-$(uname -m)"" -o /usr/local/bin/docker-compose
```",,,rightisleft,"
--
FWIW: i uninstalled the docker-compose installed via the official instructions and replaced it with the one from pip3. 

The pip3 version worked as expected. 

Uninstalling the pip3, restoring the official version resulted in a return of the failed SIG* commands on Ubuntu 18.04 
--

--
It still happens....
--
",stale,"
--
This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you for your contributions.

--

--
This issue has been automatically marked as not stale anymore due to the recent activity.

--
",,,,,,,,
7618,OPEN,Allow overwriting the service names in the compose file,kind/feature,2020-07-25 14:28:40 +0000 UTC,AnmSaiful,In progress,,"**Is your feature request related to a problem? Please describe.**
In order to centralize the configuration and reuse the compose files, I'm trying to make use of environment variables as much as possible which include the service name as well.

But as long as service names are keys in the compose file, they can't be used as variables.

There are many use cases of this situation, for example using different service names of the same service type on the same network.

**Describe the solution you'd like**

I would like to propose a new **service level configuration** named `service` or `service_name` or something similar that will overwrite the service name during the build process.

Here is the `.env` file:

```bash
PROJECT_NAME=foo
NODE_VERSION=14.5.0
```

Here is the proposed `docker-compose.yml` file:

```yml
version: ""3.7""
services:
    app:
        service: ${PROJECT_NAME}_app
        image: node:${NODE_VERSION}
```

The final service name will be `foo_app` instead of `app` during the build.",,,dominikbraun,"
--
> There are many use cases of this situation, for example using different service names of the same service type on the same network.

Just being curious, what's the advantage of this? The service is eventually prefixed with the project name anyway  
--

--
Strictly speaking,
* containers of a service are prefixed with the project name - it would be odd if you couldn't run two services called `web` from two different projects at the same time.
* _inside_ a project, Docker Compose creates a network for its services, and these services can talk to each other by the name - without project prefix, as they're in the same project.
--

--
Now I understand your scenario :)

> This is exactly what I'm talking about. How could the services talk to each other if they are from different projects, having the same service name, and sharing the same network?

If they're on the same network, they can communicate via container name, which is `<project>_<service>_<container_number>`. 

You can prove this like so:

Central database in `/database/docker-compose.yml`:

```yaml
services:
    mysql:
        ...
```

Web app in `/web-app/docker-compose.yml`:

```yaml
services:
    php:
        ...
```

After starting both Compose projects ...

```shell script
$ docker-compose up -f /database/docker-compose.yml -d
$ docker-compose up -f /web-app/docker-compose.yml -d
```

... you can create a network and connect the containers.

```shell script
$ docker network create --driver bridge my-net
$ docker network connect my-net database_mysql_1
$ docker network connect my-net web-app_php_1
```

Now `database_mysql_1` should be a valid hostname for the `web-app_php_1` container. Of course, this isn't ergonomic because you would have to connect the containers each time you start the Compose projects.

Fortunately, you can instruct the `web-app` services to connect to a network _outside of the project_:

Central database in `/database/docker-compose.yml`:

```yaml
services:
    mysql:
        ...
networks:
    my-net:
        driver: bridge
```

Web app in `/web-app/docker-compose.yml`:

```yaml
services:
    php:
        ...
networks:
    my-net:
        external: true
```

That should work as well.
--
",AnmSaiful,"
--
@dominikbraun one of the use cases is `hostname` conflict resolution as long as service names can be used as hostnames within the network. But this can be resolved by using the `hostname` configuration.

I was not aware that the service names are prefixed with the project name as long as I could access the service names as hostnames which are not prefixed with the project name. 
--

--
@dominikbraun regarding your statement,

> inside a project, Docker Compose creates a network for its services, and these services can talk to each other by the name - without project prefix, as they're in the same project.

This is exactly what I'm talking about. How could the services talk to each other if they are from different projects, having the same service name, and sharing the same network? If this is achievable using the project prefix, then fine. Currently I'm achieving this by exclusively setting the hostname of the containers.

For my case in specific, I'm centralizing all the database services for all my projects. So all the projects are on the same (bridge) network in order to use the central database.

Hope this help clarify my concerns. :-)
--

--
@dominikbraun thank you so much for the details instruction. Let me share what I'm currently doing.

`db/docker-compose.yml`

```yml
networks:
  default:
    external:
      name: ${NETWORK_NAME}

services:
  db:
    container_name: ${DB_NAMESPACE}
    hostname      : ${DB_NAMESPACE}
    ...
```

`project/app/docker-compose.yml`

```yml
networks:
  default:
    external:
      name: ${NETWORK_NAME}

services:
  app:
    container_name: ${APP_NAMESPACE}
    hostname      : ${APP_NAMESPACE}
    ...
```

I'm communicating through the `hostname`.  :-)
--
",EricHripko,"
--
You can already do this in the following ways:

- [-p command-line flag](https://docs.docker.com/compose/reference/overview/)
- [COMPOSE_PROJECT_NAME environment variable](https://docs.docker.com/compose/reference/envvars/#compose_project_name)

As @dominikbraun described, `docker-compose` will prefix all objects it creates (containers, volumes, networks, etc.) with this name. If you don't set this via one of the methods above, it defaults to the folder name of your project.

--
",,,,,,
7616,OPEN,Wait or retry starting a container waiting for NFS volume to be mounted,kind/feature,2020-09-01 21:35:52 +0000 UTC,hadim,Opened,,"I have a bunch of services that depend on multiple Docker-compose-declared NFS volumes. All volumes depend on another machine running a single NFS server.

Upon power failure botch machines (the one running the NFS server and the ones running Docker compose services) are restarted and the machine running the NFS server is much slower to start than the other machine.

Docker services are correctly started upon machine reboot but most services fail to start because the NFS server is still down. Meaning than I need to manually restart them once the NFS server is up.

I was wondering if I could set a setting that tries to restart failed services or another config that will wait for the NFS volumes to be mounted. Or maybe a `depends` option that will depend on a volume to be ready (instead of a service).",,,Kianda,"
--
I'm currently handling the same issue with a 'not so clean' solution, a retry bash script:

> while [ ""$( docker container inspect -f '{{.State.Status}}' $container_name )"" != ""running"" ]; do
> 
> Try a docker compose up -d here, will fail if the NFS share volume is not available
> sleep 120
> 
> done



A 'depends' option on a volume would be great!
--
",gsi,"
--
Hello please I'm having the same issue my portainer container doesn't start until my volumes are not ready, how do you solve these?
--
",,,,,,,,
7613,OPEN,[Feature] Add flag to stop all dependent containers when using `run`,kind/feature,2020-07-17 23:00:19 +0000 UTC,bilby91,Opened,,"Hello,

I was wondering if it could be possible to consider adding a new flag to stop all dependent containers when using `docker-compose run`. 

Currently, `docker-compose up` has the `--abort-on-container-exit` flag which does a ""similar"" thing. As per the CLI documentation:  `Stops all containers if any container was stopped. Incompatible with -d.`

I can work on getting this implemented if it is something that would be desired. Not sure if the same name for the flag (`--abort-on-container-exit`) is the right verbiage since it's going to stop all containers once the ""main container"" of invoking run is stopped.

Looking forward for some feedback :)

Thanks!",,,,,,,,,,,,,,
7610,OPEN,[Feature] Reference external file URL for docker config creation,kind/feature,2020-07-16 19:27:11 +0000 UTC,jbmcfarlin31,Opened,,"**Is your feature request related to a problem? Please describe.**
When using configs with a compose file, you can specify a `file` attribute for where the config lives. For example:
```yaml
configs:
  conf1:
    name: testconfigfile
    file: ./testconfigfile.conf
```

This is expecting that the file exists on the machine that is running docker-compose presumably. However, if you specify a url to the config file instead, it breaks as it does not follow the url but rather just appends:
```yaml
configs:
  conf1:
    name: testconfigfile
    file: ""https://repo.example.com/mygroup/myproject/-/raw/master/testconfigfile.conf"" 
```

**Describe the solution you'd like**
I tried looking at the documentation and searching other issues but did not find an answer.

I would like to be able to specify either by the `file` attribute or another attribute like `url` or `external_url` a URL to my configuration file. This would help with pipelines utilizing `kompose` for translating docker compose into kubernetes yaml - specifically kubernetes ConfigMaps.

This also might be an issue with `kompose` so if it is please let me know and I will open a ticket with them.

Example:
```yaml
configs:
  conf1:
    name: testconfigfile
    file: ""https://repo.example.com/mygroup/myproject/-/raw/master/testconfigfile.conf""

# or
configs:
  conf1:
    name: testconfigfile
    url: ""https://repo.example.com/mygroup/myproject/-/raw/master/testconfigfile.conf""

# or
configs:
  conf1:
    name: testconfigfile
    ext_url: ""https://repo.example.com/mygroup/myproject/-/raw/master/testconfigfile.conf""
```
",,,,,,,,,,,,,,
7608,OPEN,docker-compose down is too slow if a service uses a custom logging driver,kind/bug,2021-01-14 12:51:51 +0000 UTC,dgzlopes,Opened,,"## Description of the issue
If in `docker-compose.yml`, a service uses a custom logging driver, running docker-compose down will take a lot of time. Also, sometimes https://github.com/docker/compose/issues/3927 pops up.

Removing custom logging configuration from the service lets the container shut down properly.



## Context information (for bug reports)

**Output of `docker-compose version`**
```
 docker-compose version
docker-compose version 1.26.0, build d4451659
docker-py version: 4.2.1
CPython version: 3.7.7
OpenSSL version: OpenSSL 1.1.0l  10 Sep 2019
```

**Output of `docker version`**
```
 docker version
Client: Docker Engine - Community
 Version:           19.03.12
 API version:       1.40
 Go version:        go1.13.10
 Git commit:        48a66213fe
 Built:             Mon Jun 22 15:45:44 2020
 OS/Arch:           linux/amd64
 Experimental:      false

Server: Docker Engine - Community
 Engine:
  Version:          19.03.12
  API version:      1.40 (minimum version 1.12)
  Go version:       go1.13.10
  Git commit:       48a66213fe
  Built:            Mon Jun 22 15:44:15 2020
  OS/Arch:          linux/amd64
  Experimental:     false
 containerd:
  Version:          1.2.13
  GitCommit:        7ad184331fa3e55e52b890ea95e65ba581ae3429
 runc:
  Version:          1.0.0-rc10
  GitCommit:        dc9208a3303feef5b3839f4323d9beb36df0a9dd
 docker-init:
  Version:          0.18.0
  GitCommit:        fec3683
```

## Steps to reproduce the issue

1. `docker-compose.yml`
```
version: ""3.4""
x-logging:
    &default-logging
    options:
       loki-url: ""http://localhost:3101/loki/api/v1/push""
    driver: loki
    #driver: json-file
services:

    redis:
        image: ""redis:alpine""
        logging: *default-logging

    # this loki instance collects the logs from the rest of services
    loki-internal:
        image: grafana/loki:1.5.0
        ports:
            - ""3101:3100""
        command: -config.file=/etc/loki/local-config.yaml
            
    grafana:
        image: grafana/grafana:latest
        ports:
            - ""3000:3000""
        volumes:
            - ./grafana/datasources:/etc/grafana/provisioning/datasources/
        logging: *default-logging
    
```
2. run `docker-compose up -d`
3. run `time docker-compose --verbose  down`
4. Comment custom logging driver and options. Uncomment `json-file` driver.
5. Re-run step 2 and 3.

### Observed result

Running `docker-compose down` with a custom logging plugin takes ~37s. If we use the default docker logging driver (`json-file`) only takes ~1s.

Looking at the output of `docker-compose --verbose down`, for when a custom logging driver is configured, the console is continuously printing compose.parallel.feed_queue: Pending: set()

Also, sometimes while using a bigger `docker-compose.yml` (w/ +15 services) #3927 pops up.

### Stacktrace / full error message

```
 time docker-compose --verbose  down
compose.config.config.find: Using configuration files: ./docker-compose.yml
docker.utils.config.find_config_file: Trying paths: ['/home/dgzlopes/.docker/config.json', '/home/dgzlopes/.dockercfg']
docker.utils.config.find_config_file: Found file at path: /home/dgzlopes/.docker/config.json
docker.utils.config.find_config_file: Trying paths: ['/home/dgzlopes/.docker/config.json', '/home/dgzlopes/.dockercfg']
docker.utils.config.find_config_file: Found file at path: /home/dgzlopes/.docker/config.json
docker.auth.load_config: Found 'auths' section
docker.auth.parse_auth: Found entry (registry='https://index.docker.io/v1/', username='dgzlopes')
urllib3.connectionpool._make_request: http://localhost:None ""GET /v1.30/version HTTP/1.1"" 200 860
compose.cli.docker_client.get_client: docker-compose version 1.26.0, build d4451659
docker-py version: 4.2.1
CPython version: 3.7.7
OpenSSL version: OpenSSL 1.1.0l  10 Sep 2019
compose.cli.docker_client.get_client: Docker base_url: http+docker://localhost
compose.cli.docker_client.get_client: Docker version: Platform={'Name': 'Docker Engine - Community'}, Components=[{'Name': 'Engine', 'Version': '19.03.12', 'Details': {'ApiVersion': '1.40', 'Arch': 'amd64', 'BuildTime': '2020-06-22T15:44:15.000000000+00:00', 'Experimental': 'false', 'GitCommit': '48a66213fe', 'GoVersion': 'go1.13.10', 'KernelVersion': '5.4.0-40-generic', 'MinAPIVersion': '1.12', 'Os': 'linux'}}, {'Name': 'containerd', 'Version': '1.2.13', 'Details': {'GitCommit': '7ad184331fa3e55e52b890ea95e65ba581ae3429'}}, {'Name': 'runc', 'Version': '1.0.0-rc10', 'Details': {'GitCommit': 'dc9208a3303feef5b3839f4323d9beb36df0a9dd'}}, {'Name': 'docker-init', 'Version': '0.18.0', 'Details': {'GitCommit': 'fec3683'}}], Version=19.03.12, ApiVersion=1.40, MinAPIVersion=1.12, GitCommit=48a66213fe, GoVersion=go1.13.10, Os=linux, Arch=amd64, KernelVersion=5.4.0-40-generic, BuildTime=2020-06-22T15:44:15.000000000+00:00
compose.cli.verbose_proxy.proxy_callable: docker inspect_network <- ('test_default')
urllib3.connectionpool._make_request: http://localhost:None ""GET /v1.30/networks/test_default HTTP/1.1"" 200 1324
compose.cli.verbose_proxy.proxy_callable: docker inspect_network -> {'Attachable': True,
 'ConfigFrom': {'Network': ''},
 'ConfigOnly': False,
 'Containers': {'3a01f6a4753b9a9301a25c0211ae90a6df171dd05418795d79ba4d25139c6e63': {'EndpointID': '1a03ea44f7fa7e6a19c406f0fc6997ceb91a334b072d24c03ff85b08e6a83b2f',
                                                                                     'IPv4Address': '192.168.96.3/20',
                                                                                     'IPv6Address': '',
                                                                                     'MacAddress': '02:42:c0:a8:60:03',
                                                                                     'Name': 'test_loki-internal_1'},
                '7951e8fed38866de145039360dd952fd8057582594f9262e27e06f3e807381a6': {'EndpointID': '4d59c4e0cbbe94f4f70b6c36b0063b2f43c1e68ea6d39fb94886bbbb4a97bf33',
                                                                                     'IPv4Address': '192.168.96.2/20',
...
compose.cli.verbose_proxy.proxy_callable: docker containers <- (all=False, filters={'label': ['com.docker.compose.project=test']})
urllib3.connectionpool._make_request: http://localhost:None ""GET /v1.30/containers/json?limit=-1&all=0&size=0&trunc_cmd=0&filters=%7B%22label%22%3A+%5B%22com.docker.compose.project%3Dtest%22%5D%7D HTTP/1.1"" 200 None
compose.cli.verbose_proxy.proxy_callable: docker containers -> (list with 3 items)
compose.cli.verbose_proxy.proxy_callable: docker inspect_container <- ('dc218ed252929341d018f0fb29d497a3c36225b6eeb1a4c9731881c4d5a993ef')
urllib3.connectionpool._make_request: http://localhost:None ""GET /v1.30/containers/dc218ed252929341d018f0fb29d497a3c36225b6eeb1a4c9731881c4d5a993ef/json HTTP/1.1"" 200 None
compose.cli.verbose_proxy.proxy_callable: docker inspect_container -> {'AppArmorProfile': 'docker-default',
 'Args': ['redis-server'],
 'Config': {'AttachStderr': False,
            'AttachStdin': False,
            'AttachStdout': False,
            'Cmd': ['redis-server'],
            'Domainname': '',
            'Entrypoint': ['docker-entrypoint.sh'],
            'Env': ['PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin',
                    'REDIS_VERSION=6.0.5',
...
compose.cli.verbose_proxy.proxy_callable: docker inspect_container <- ('7951e8fed38866de145039360dd952fd8057582594f9262e27e06f3e807381a6')
urllib3.connectionpool._make_request: http://localhost:None ""GET /v1.30/containers/7951e8fed38866de145039360dd952fd8057582594f9262e27e06f3e807381a6/json HTTP/1.1"" 200 None
compose.cli.verbose_proxy.proxy_callable: docker inspect_container -> {'AppArmorProfile': 'docker-default',
 'Args': [],
 'Config': {'AttachStderr': False,
            'AttachStdin': False,
            'AttachStdout': False,
            'Cmd': None,
            'Domainname': '',
            'Entrypoint': ['/run.sh'],
            'Env': ['PATH=/usr/share/grafana/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin',
                    'GF_PATHS_CONFIG=/etc/grafana/grafana.ini',
...
compose.cli.verbose_proxy.proxy_callable: docker inspect_container <- ('3a01f6a4753b9a9301a25c0211ae90a6df171dd05418795d79ba4d25139c6e63')
urllib3.connectionpool._make_request: http://localhost:None ""GET /v1.30/containers/3a01f6a4753b9a9301a25c0211ae90a6df171dd05418795d79ba4d25139c6e63/json HTTP/1.1"" 200 None
compose.cli.verbose_proxy.proxy_callable: docker inspect_container -> {'AppArmorProfile': 'docker-default',
 'Args': ['-config.file=/etc/loki/local-config.yaml'],
 'Config': {'AttachStderr': False,
            'AttachStdin': False,
            'AttachStdout': False,
            'Cmd': ['-config.file=/etc/loki/local-config.yaml'],
            'Domainname': '',
            'Entrypoint': ['/usr/bin/loki'],
            'Env': ['PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin'],
            'ExposedPorts': {'3100/tcp': {}},
...
Stopping test_redis_1         ... 
Stopping test_grafana_1       ... 
Stopping test_loki-internal_1 ... 
compose.parallel.feed_queue: Pending: {<Container: test_grafana_1 (7951e8)>, <Container: test_redis_1 (dc218e)>, <Container: test_loki-internal_1 (3a01f6)>}
compose.parallel.feed_queue: Starting producer thread for <Container: test_grafana_1 (7951e8)>
compose.cli.verbose_proxy.proxy_callable: docker stop <- ('7951e8fed38866de145039360dd952fd8057582594f9262e27e06f3e807381a6', timeout=10)
compose.parallel.feed_queue: Starting producer thread for <Container: test_redis_1 (dc218e)>
compose.cli.verbose_proxy.proxy_callable: docker stop <- ('dc218ed252929341d018f0fb29d497a3c36225b6eeb1a4c9731881c4d5a993ef', timeout=10)
compose.parallel.feed_queue: Starting producer thread for <Container: test_loki-internal_1 (3a01f6)>
compose.cli.verbose_proxy.proxy_callable: docker stop <- ('3a01f6a4753b9a9301a25c0211ae90a6df171dd05418795d79ba4d25139c6e63', timeout=10)
compose.parallel.feed_queue: Pending: set()
compose.parallel.feed_queue: Pending: set()
compose.parallel.feed_queue: Pending: set()
urllib3.connectionpool._make_request: http://localhost:None ""POST /v1.30/containers/3a01f6a4753b9a9301a25c0211ae90a6df171dd05418795d79ba4d25139c6e63/stop?t=10 HTTP/1.1"" 204 0
compose.cli.verbose_proxy.proxy_callable: docker stop -> None
Stopping test_loki-internal_1 ... done
compose.parallel.feed_queue: Pending: set()
####################
380 times the same line
####################
compose.parallel.feed_queue: Pending: set()
Stopping test_redis_1         ... done
compose.cli.verbose_proxy.proxy_callable: docker stop -> None
compose.parallel.parallel_execute_iter: Finished processing: <Container: test_redis_1 (dc218e)>
compose.parallel.feed_queue: Pending: set()
compose.cli.verbose_proxy.proxy_callable: docker containers <- (all=False, filters={'label': ['com.docker.compose.project=test', 'com.docker.compose.oneoff=False']})
urllib3.connectionpool._make_request: http://localhost:None ""GET /v1.30/containers/json?limit=-1&all=0&size=0&trunc_cmd=0&filters=%7B%22label%22%3A+%5B%22com.docker.compose.project%3Dtest%22%2C+%22com.docker.compose.oneoff%3DFalse%22%5D%7D HTTP/1.1"" 200 3
compose.cli.verbose_proxy.proxy_callable: docker containers -> (list with 0 items)
compose.cli.verbose_proxy.proxy_callable: docker containers <- (all=False, filters={'label': ['com.docker.compose.project=test', 'com.docker.compose.oneoff=False']})
urllib3.connectionpool._make_request: http://localhost:None ""GET /v1.30/containers/json?limit=-1&all=0&size=0&trunc_cmd=0&filters=%7B%22label%22%3A+%5B%22com.docker.compose.project%3Dtest%22%2C+%22com.docker.compose.oneoff%3DFalse%22%5D%7D HTTP/1.1"" 200 3
compose.cli.verbose_proxy.proxy_callable: docker containers -> (list with 0 items)
compose.cli.verbose_proxy.proxy_callable: docker containers <- (all=True, filters={'label': ['com.docker.compose.project=test', 'com.docker.compose.oneoff=False']})
urllib3.connectionpool._make_request: http://localhost:None ""GET /v1.30/containers/json?limit=-1&all=1&size=0&trunc_cmd=0&filters=%7B%22label%22%3A+%5B%22com.docker.compose.project%3Dtest%22%2C+%22com.docker.compose.oneoff%3DFalse%22%5D%7D HTTP/1.1"" 200 None
compose.cli.verbose_proxy.proxy_callable: docker containers -> (list with 3 items)
compose.cli.verbose_proxy.proxy_callable: docker inspect_container <- ('7951e8fed38866de145039360dd952fd8057582594f9262e27e06f3e807381a6')
urllib3.connectionpool._make_request: http://localhost:None ""GET /v1.30/containers/7951e8fed38866de145039360dd952fd8057582594f9262e27e06f3e807381a6/json HTTP/1.1"" 200 None
compose.cli.verbose_proxy.proxy_callable: docker inspect_container -> {'AppArmorProfile': 'docker-default',
 'Args': [],
 'Config': {'AttachStderr': False,
            'AttachStdin': False,
            'AttachStdout': False,
            'Cmd': None,
            'Domainname': '',
            'Entrypoint': ['/run.sh'],
            'Env': ['PATH=/usr/share/grafana/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin',
                    'GF_PATHS_CONFIG=/etc/grafana/grafana.ini',
...
compose.cli.verbose_proxy.proxy_callable: docker inspect_container <- ('dc218ed252929341d018f0fb29d497a3c36225b6eeb1a4c9731881c4d5a993ef')
urllib3.connectionpool._make_request: http://localhost:None ""GET /v1.30/containers/dc218ed252929341d018f0fb29d497a3c36225b6eeb1a4c9731881c4d5a993ef/json HTTP/1.1"" 200 None
compose.cli.verbose_proxy.proxy_callable: docker inspect_container -> {'AppArmorProfile': 'docker-default',
 'Args': ['redis-server'],
 'Config': {'AttachStderr': False,
            'AttachStdin': False,
            'AttachStdout': False,
            'Cmd': ['redis-server'],
            'Domainname': '',
            'Entrypoint': ['docker-entrypoint.sh'],
            'Env': ['PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin',
                    'REDIS_VERSION=6.0.5',
...
compose.cli.verbose_proxy.proxy_callable: docker inspect_container <- ('3a01f6a4753b9a9301a25c0211ae90a6df171dd05418795d79ba4d25139c6e63')
urllib3.connectionpool._make_request: http://localhost:None ""GET /v1.30/containers/3a01f6a4753b9a9301a25c0211ae90a6df171dd05418795d79ba4d25139c6e63/json HTTP/1.1"" 200 None
compose.cli.verbose_proxy.proxy_callable: docker inspect_container -> {'AppArmorProfile': 'docker-default',
 'Args': ['-config.file=/etc/loki/local-config.yaml'],
 'Config': {'AttachStderr': False,
            'AttachStdin': False,
            'AttachStdout': False,
            'Cmd': ['-config.file=/etc/loki/local-config.yaml'],
            'Domainname': '',
            'Entrypoint': ['/usr/bin/loki'],
            'Env': ['PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin'],
            'ExposedPorts': {'3100/tcp': {}},
...
compose.cli.verbose_proxy.proxy_callable: docker containers <- (all=True, filters={'label': ['com.docker.compose.project=test']})
urllib3.connectionpool._make_request: http://localhost:None ""GET /v1.30/containers/json?limit=-1&all=1&size=0&trunc_cmd=0&filters=%7B%22label%22%3A+%5B%22com.docker.compose.project%3Dtest%22%5D%7D HTTP/1.1"" 200 None
compose.cli.verbose_proxy.proxy_callable: docker containers -> (list with 3 items)
compose.cli.verbose_proxy.proxy_callable: docker inspect_container <- ('dc218ed252929341d018f0fb29d497a3c36225b6eeb1a4c9731881c4d5a993ef')
urllib3.connectionpool._make_request: http://localhost:None ""GET /v1.30/containers/dc218ed252929341d018f0fb29d497a3c36225b6eeb1a4c9731881c4d5a993ef/json HTTP/1.1"" 200 None
compose.cli.verbose_proxy.proxy_callable: docker inspect_container -> {'AppArmorProfile': 'docker-default',
 'Args': ['redis-server'],
 'Config': {'AttachStderr': False,
            'AttachStdin': False,
            'AttachStdout': False,
            'Cmd': ['redis-server'],
            'Domainname': '',
            'Entrypoint': ['docker-entrypoint.sh'],
            'Env': ['PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin',
                    'REDIS_VERSION=6.0.5',
...
compose.cli.verbose_proxy.proxy_callable: docker inspect_container <- ('7951e8fed38866de145039360dd952fd8057582594f9262e27e06f3e807381a6')
urllib3.connectionpool._make_request: http://localhost:None ""GET /v1.30/containers/7951e8fed38866de145039360dd952fd8057582594f9262e27e06f3e807381a6/json HTTP/1.1"" 200 None
compose.cli.verbose_proxy.proxy_callable: docker inspect_container -> {'AppArmorProfile': 'docker-default',
 'Args': [],
 'Config': {'AttachStderr': False,
            'AttachStdin': False,
            'AttachStdout': False,
            'Cmd': None,
            'Domainname': '',
            'Entrypoint': ['/run.sh'],
            'Env': ['PATH=/usr/share/grafana/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin',
                    'GF_PATHS_CONFIG=/etc/grafana/grafana.ini',
...
compose.cli.verbose_proxy.proxy_callable: docker inspect_container <- ('3a01f6a4753b9a9301a25c0211ae90a6df171dd05418795d79ba4d25139c6e63')
urllib3.connectionpool._make_request: http://localhost:None ""GET /v1.30/containers/3a01f6a4753b9a9301a25c0211ae90a6df171dd05418795d79ba4d25139c6e63/json HTTP/1.1"" 200 None
compose.cli.verbose_proxy.proxy_callable: docker inspect_container -> {'AppArmorProfile': 'docker-default',
 'Args': ['-config.file=/etc/loki/local-config.yaml'],
 'Config': {'AttachStderr': False,
            'AttachStdin': False,
            'AttachStdout': False,
            'Cmd': ['-config.file=/etc/loki/local-config.yaml'],
            'Domainname': '',
            'Entrypoint': ['/usr/bin/loki'],
            'Env': ['PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin'],
            'ExposedPorts': {'3100/tcp': {}},
...
Removing test_redis_1         ... 
Removing test_grafana_1       ... 
Removing test_loki-internal_1 ... 
compose.parallel.feed_queue: Pending: {<Container: test_grafana_1 (7951e8)>, <Container: test_redis_1 (dc218e)>, <Container: test_loki-internal_1 (3a01f6)>}
compose.parallel.feed_queue: Starting producer thread for <Container: test_grafana_1 (7951e8)>
compose.cli.verbose_proxy.proxy_callable: docker remove_container <- ('7951e8fed38866de145039360dd952fd8057582594f9262e27e06f3e807381a6', v=False)
compose.parallel.feed_queue: Starting producer thread for <Container: test_redis_1 (dc218e)>
compose.cli.verbose_proxy.proxy_callable: docker remove_container <- ('dc218ed252929341d018f0fb29d497a3c36225b6eeb1a4c9731881c4d5a993ef', v=False)
compose.parallel.feed_queue: Starting producer thread for <Container: test_loki-internal_1 (3a01f6)>
compose.cli.verbose_proxy.proxy_callable: docker remove_container <- ('3a01f6a4753b9a9301a25c0211ae90a6df171dd05418795d79ba4d25139c6e63', v=False)
urllib3.connectionpool._make_request: http://localhost:None ""DELETE /v1.30/containers/dc218ed252929341d018f0fb29d497a3c36225b6eeb1a4c9731881c4d5a993ef?v=False&link=False&force=False HTTP/1.1"" 204 0
compose.cli.verbose_proxy.proxy_callable: docker remove_container -> None
compose.cli.verbose_proxy.proxy_callable: docker remove_container -> NoneRemoving test_redis_1         ... done
compose.parallel.parallel_execute_iter: Finished processing: <Container: test_redis_1 (dc218e)>
Removing test_grafana_1       ... done
compose.parallel.parallel_execute_iter: Finished processing: <Container: test_grafana_1 (7951e8)>
compose.parallel.feed_queue: Pending: set()
urllib3.connectionpool._make_request: http://localhost:None ""DELETE /v1.30/containers/3a01f6a4753b9a9301a25c0211ae90a6df171dd05418795d79ba4d25139c6e63?v=False&link=False&force=False HTTP/1.1"" 204 0
compose.cli.verbose_proxy.proxy_callable: docker remove_container -> None
Removing test_loki-internal_1 ... done
compose.parallel.feed_queue: Pending: set()
compose.network.remove: Removing network test_default
compose.cli.verbose_proxy.proxy_callable: docker remove_network <- ('test_default')
urllib3.connectionpool._make_request: http://localhost:None ""DELETE /v1.30/networks/test_default HTTP/1.1"" 204 0
compose.cli.verbose_proxy.proxy_callable: docker remove_network -> None
docker-compose --verbose down > report.txt  0,47s user 0,04s system 1% cpu 38,274 total
```",,,stale,"
--
This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you for your contributions.

--

--
This issue has been automatically marked as not stale anymore due to the recent activity.

--
",pgassmann,"
--
Also reported in loki project. The issue there is marked as fixed, but it's not sure if there's not another issue. https://github.com/grafana/loki/issues/2361
--
",,,,,,,,
7605,OPEN,docker-compose up --scale rescales not specified service,kind/bug,2020-09-05 07:14:24 +0000 UTC,kolbma,Opened,,"## Description of the issue

I have multiple services (s1, s2, s3). s2 and s3 depends on s1.  
If I have scaled **s1** manually to e.g. **--scale s1=3** and afterwards call `docker-compose up --scale s2=1 s2`.  
Now the service **s1** gets also rescaled?!

## Context information (for bug reports)

**Output of `docker-compose version`**
```
docker-compose version 1.25.4, build unknown
docker-py version: 4.2.0
CPython version: 3.8.3
OpenSSL version: OpenSSL 1.1.1g  21 Apr 2020
```

**Output of `docker version`**
```
Client:
 Version:           19.03.11
 API version:       1.40
 Go version:        go1.13.11
 Git commit:        42e35e61f352e527082521280d5ea3761f0dee50
 Built:             Wed Jun  3 13:10:57 2020
 OS/Arch:           linux/amd64
 Experimental:      false

Server:
 Engine:
  Version:          19.03.11
  API version:      1.40 (minimum version 1.12)
  Go version:       go1.13.11
  Git commit:       42e35e61f352e527082521280d5ea3761f0dee50
  Built:            Wed Jun  3 13:09:45 2020
  OS/Arch:          linux/amd64
  Experimental:     false
 containerd:
  Version:          v1.3.4
  GitCommit:        814b7956fafc7a0980ea07e950f983d0837e5578
 runc:
  Version:          1.0.0-rc10
  GitCommit:        dc9208a3303feef5b3839f4323d9beb36df0a9dd
 docker-init:
  Version:          0.19.0
  GitCommit:
```

**Output of `docker-compose config`**
```
services:
  s1:
    build:
      context: /etc/docker/cfg
      dockerfile: Dockerfile.s1
    image: s1:latest
  s2:
    build:
      context: /etc/docker/cfg
      dockerfile: Dockerfile.s2
    depends_on:
    - s1
    image: s2:latest
  s3:
    build:
      context: /etc/docker/cfg
      dockerfile: Dockerfile.s3
    depends_on:
    - s1
    image: s3:latest
version: '3.4'
```


## Steps to reproduce the issue

1. docker-compose up -d --scale s1=3 s1
2. docker-compose up -d --scale s2=1 s2

### Observed result
For step 2:  
```
Stopping and removing s1_2 ... done
Stopping and removing s1_3 ... done
Starting s1_1              ... done
Starting s2_1              ... done
```

### Expected result
For step 2:
```
Starting s2_1              ... done
```

## Additional information

I know of `--no-deps` like `docker-compose up -d --no-deps --scale s2=1 s2`.  
But this wouldn't start any required **s1** instance if s1 service would be stopped before.

I think it would be more logic to simple recognize the command line on scaling.

```
# cat /etc/os-release 
NAME=""Alpine Linux""
ID=alpine
VERSION_ID=3.12.0
PRETTY_NAME=""Alpine Linux v3.12""
HOME_URL=""https://alpinelinux.org/""
BUG_REPORT_URL=""https://bugs.alpinelinux.org/""

# cat /etc/os-release 
NAME=""Alpine Linux""
ID=alpine
VERSION_ID=3.12.0
PRETTY_NAME=""Alpine Linux v3.12""
HOME_URL=""https://alpinelinux.org/""
BUG_REPORT_URL=""https://bugs.alpinelinux.org/""

# apk info | grep docker | while read p ; do apk search -x ""$p"" ; done
docker-engine-19.03.11-r0
docker-openrc-19.03.11-r0
docker-cli-19.03.11-r0
docker-19.03.11-r0
docker-doc-19.03.11-r0
docker-registry-2.7.1-r2
docker-registry-openrc-2.7.1-r2
dockerpy-creds-0.4.0-r2
docker-py-4.2.0-r0
py3-dockerpty-0.4.1-r2
docker-compose-1.25.4-r2
```",,,franzwong,"
--
Did you try this? Does s3 rescale too?

```
docker-compose up -d --scale s3=3 s3
docker-compose up -d --scale s2=1 s2
```
--
",,,,,,,,,,
7596,OPEN,How to change default IP range on windows ?,kind/question,2020-07-10 08:29:57 +0000 UTC,webmasterpf,Opened,,"Hello,

I desperate to find a way to change the default IP range on windows desktop. 
Actually docker use default 172.... All tutos I find talk about linux host. :/

Where can I fond the way to do it on windows machine ? 
https://docs.docker.com/docker-for-windows/networking/#features   explain docker0 doesn't exist on W10 but what can I do if I need to change IPs ?

Ideally, it would be great to do this with docker-compose but when I create a network like this:
`docker network create --subnet 10.100.0.0/16 --gateway=10.100.1.250 --ip-range 10.100.1.0/24 drupal8-multi_reseau_dg`

when I run my containers, docker4drupal create another network instead using I previously created. Weird thing.
```
60f5873e6918        drupal8-multi_drupal8-multi_reseau_dg   bridge              local
7b475c8e0d3b        drupal8-multi_reseau_dg                 bridge              local
```
If someone could help because actually my containers can't access internet because of enterprise network and proxy/firewall.

Thanks",,,,,,,,,,,,,,
7595,OPEN,Fish completion,kind/feature,2020-07-09 15:30:17 +0000 UTC,nihaals,Opened,,"**Is your feature request related to a problem? Please describe.**
The fish command completion is less extensive than Bash's or Zsh's.

**Describe the solution you'd like**
The fish command completion includes everything the others do including completing service names.

**Describe alternatives you've considered**
https://github.com/brgmnn/fish-docker-compose exists but as it is not maintained in the official repository it is/will be outdated when new commands are added and could be less extensive compared to if maintainers who know `docker-compose` more extensively contributed.

**Additional context**
This is similar to #6394, but the linked repository became archived and https://github.com/brgmnn/fish-docker-compose is licensed under MIT. Having it part of the official repository also allows for completions to be added dynamically (for example calling a function in `~/.config/fish/completions/docker-compose.fish` which would use the provided completions or call something similar to `docker-compose completions fish` meaning completions do not have to be updated manually after updating Docker compose. [The docs](https://docs.docker.com/compose/completion/) doesn't even include install instructions for fish despite [basic ones existing](https://github.com/docker/compose/blob/master/contrib/completion/fish/docker-compose.fish), implying fish support is almost ignored despite there being solutions.",,,,,,,,,,,,,,
7594,OPEN,Add memory-swap and memory-swappiness support to v3 since it was available in v2,kind/feature,2020-07-08 15:04:08 +0000 UTC,jamshid,Opened,,"**Is your feature request related to a problem? Please describe.**

You can configure `memswap_limit` and `mem_swappiness` in v2 compose files. 
Docs (https://docs.docker.com/compose/compose-file/#resources) claim v3 replaces these settings with `deploy: resources:`.
These docs are very misleading, these **swap settings simply cannot be configured in v3 format**.

**Describe the solution you'd like**
First, please make the current situation clear in the docs. These docs cause so much unnecessary confusion like:
https://forums.docker.com/t/memory-swap-vs-memory-swappiness-and-using-in-docker-compose/54889
https://stackoverflow.com/questions/44325949/how-to-replace-memswap-limit-in-docker-compose-3

If the answer as @shin- seemed to indicate is to keep using v2, then make it clear that v3 format is not needed and should not be used if you (very reasonably) want to configure swap settings for your services.

But really I'd like docker-compose to make the v3 format a complete replacement of v2, anything you could configure in v2  (or with `docker run`) should be available in v3. Also `--compatibility` should be default behavior. 

**Describe alternatives you've considered**
Switch back to v2 format? I'm not using docker swarm so I guess I could try but I'd like to deploy to k8s eventually.

**Additional context**
The problem I'm running into is that some services are using a lot of swap. I know I should probably disable swap on the host server but not always possible/easy.
This is mostly the same issue as https://github.com/docker/compose/issues/4513 but hopefully you will reconsider now that you're taking a fresh look at compose.",,,,,,,,,,,,,,
7591,OPEN,Disable interactivity of up command,kind/feature,2020-07-07 07:10:34 +0000 UTC,tomers,Opened,,"I use custom script which executes `docker-compose up`. In case some docker image in the `docker-compose.yml` is missing, the `yesno` method is called, prompting the user for action.

Since I execute the `docker-compose up` command in the context of a script, I would like to disable interactivity, and instead specify `--yes` or `--no`, or any other kind of solution, so the my script could overcome such case.

BTW in my case I run `subprocess.run(['docker-compose', '-f', 'docker-compose.yml', 'up', '-d'], check=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE, universal_newlines=True).stdout`, and the script stalls forever, not prompting the user with anything...


```
foo.exceptions.CalledProcessError: Exec failed: rc=1 cmd=docker-compose -f docker-compose.yml up -d
stdout=
Continue with the new image? [yN]
stderr=
Pulling some.image.name (some/repo)...
The image for the service you're trying to recreate has been removed. If you continue, volume data could be lost. Consider backing up your data before continuing.

pull access denied for some/repo, repository does not exist or may require 'docker login': denied: requested access to the resource is denied


```

- Docker compose version:
```
$ docker-compose -v
docker-compose version 1.8.1, build 878cff1
```

Relevant location in the code: https://github.com/docker/compose/blob/master/compose/cli/main.py#L1081",,,,,,,,,,,,,,
7585,OPEN,Attach to an already running container via service.,kind/feature,2020-07-05 22:32:15 +0000 UTC,collin5,Opened,,"-->
**Describe the solution you'd like**
Something like or better

```bash
$ docker-compose attach <service_name>
```
",,,,,,,,,,,,,,
7577,OPEN,"Docker Compose with volume stuck on ""compose.parallel.feed_queue: Pending: set()""",kind/bug,2021-02-10 09:13:28 +0000 UTC,darty,In progress,,"3. When making a bug report, make sure you provide all required information. The easier it is for
   maintainers to reproduce, the faster it'll be fixed.
-->

## Description of the issue

When using a bind volume in a yml file, docker-compose does not start the service, but is stuck on ""compose.parallel.feed_queue: Pending: set()"". If the volume declarations are removed from the yml file, the container starts.

## Context information (for bug reports)

**Output of `docker-compose version`**
```
docker-compose version 1.25.5, build 8a1c60f6
docker-py version: 4.1.0
CPython version: 3.7.4
OpenSSL version: OpenSSL 1.1.1c  28 May 2019
```

**Output of `docker version`**
```
Client: Docker Engine - Community
 Version:           19.03.8
 API version:       1.40
 Go version:        go1.12.17
 Git commit:        afacb8b
 Built:             Wed Mar 11 01:23:10 2020
 OS/Arch:           windows/amd64
 Experimental:      false

Server: Docker Engine - Community
 Engine:
  Version:          19.03.8
  API version:      1.40 (minimum version 1.12)
  Go version:       go1.12.17
  Git commit:       afacb8b
  Built:            Wed Mar 11 01:29:16 2020
  OS/Arch:          linux/amd64
  Experimental:     false
 containerd:
  Version:          v1.2.13
  GitCommit:        7ad184331fa3e55e52b890ea95e65ba581ae3429
 runc:
  Version:          1.0.0-rc10
  GitCommit:        dc9208a3303feef5b3839f4323d9beb36df0a9dd
 docker-init:
  Version:          0.18.0
  GitCommit:        fec3683

```

**Output of `docker-compose config`**
(Make sure to add the relevant `-f` and other flags)
```
networks:
  app:
    name: app
services:
  db:
    command: --character-set-server=utf8 --innodb-flush-method=littlesync --innodb-use-native-aio=OFF
      --log_bin=ON --skip-innodb-file-per-table
    container_name: backend-db-mysql
    environment:
      MYSQL_ROOT_PASSWORD: Xq54tGxtZt4MJha
    expose:
    - '3306'
    image: mysql:latest
    networks:
      app: null
    ports:
    - published: 3306
      target: 3306
    restart: always
    volumes:
    - source: D:\development\private\backend-db-test\backend-db-mysql\data
      target: /var/lib/mysql
      type: bind
    - source: D:\development\private\backend-db-test\backend-db-mysql\logs
      target: /var/log/mysql
      type: bind
version: '3.7'
```


## Steps to reproduce the issue

1. Use following yml file:
```
version: '3.7'

services:
   db:
    image: mysql:latest
    container_name: backend-db-mysql
    ports:
    - ""3306:3306""
    expose:
    - '3306'
    volumes:
      - type: bind
        source: ./backend-db-mysql/data
        target: /var/lib/mysql
      - type: bind
        source: ./backend-db-mysql/logs
        target: /var/log/mysql
    environment:
        MYSQL_ROOT_PASSWORD: ${PERSISTENT_DB_ROOT_PWD}
    restart: always
    command: --character-set-server=utf8 --innodb-flush-method=littlesync --innodb-use-native-aio=OFF --log_bin=ON --skip-innodb-file-per-table
    networks:
    - app
       
networks:
  app:
    name: app
```

Alternatively, I have tried to use the following volume definitions with the same result:

```
...
volumes:
      - ./backend-db-mysql/data:/var/lib/mysql:rw
      - ./backend-db-mysql/logs:/var/log/mysql:rw
...
```
2. Use following .env file:
```
# For building
DOCKERFILE=Dockerfile

# Environment forwarding
GLOBAL_ENV=.env

PERSISTENT_DB_PORT=3306
PERSISTENT_DB_DIALECT=mysql
PERSISTENT_DB_NAME=*HIDDEN*
PERSISTENT_DB_USER=*HIDDEN*
PERSISTENT_DB_PWD=*HIDDEN*
PERSISTENT_DB_ROOT_PWD=*HIDDEN*
```
3. Run command: `docker-compose --verbose up`

### Observed result

Following output is given:
```
compose.config.config.find: Using configuration files: .\docker-compose.yml
docker.utils.config.find_config_file: Trying paths: ['C:\\Users\\Donald\\.docker\\config.json', 'C:\\Users\\Donald\\.dockercfg']
docker.utils.config.find_config_file: Found file at path: C:\Users\Donald\.docker\config.json
docker.auth.load_config: Found 'auths' section
docker.auth.parse_auth: Auth data for https://index.docker.io/v1/ is absent. Client might be using a credentials store instead.
docker.auth.load_config: Found 'credsStore' section
urllib3.connectionpool._make_request: http://localhost:None ""GET /v1.38/version HTTP/1.1"" 200 853
compose.cli.command.get_client: docker-compose version 1.25.5, build 8a1c60f6
docker-py version: 4.1.0
CPython version: 3.7.4
OpenSSL version: OpenSSL 1.1.1c  28 May 2019
compose.cli.command.get_client: Docker base_url: http+docker://localnpipe
compose.cli.command.get_client: Docker version: Platform={'Name': 'Docker Engine - Community'}, Components=[{'Name': 'Engine', 'Version': '19.03.8', 'Details': {'ApiVersion': '1.40', 'Arch': 'amd64', 'BuildTime': '2020-03-11T01:29:16.000000000+00:00', 'Experimental': 'false', 'GitCommit': 'afacb8b', 'GoVersion': 'go1.12.17', 'KernelVersion': '4.19.76-linuxkit', 'MinAPIVersion': '1.12', 'Os': 'linux'}}, {'Name': 'containerd', 'Version': 'v1.2.13', 'Details': {'GitCommit': '7ad184331fa3e55e52b890ea95e65ba581ae3429'}}, {'Name': 'runc', 'Version': '1.0.0-rc10', 'Details': {'GitCommit': 'dc9208a3303feef5b3839f4323d9beb36df0a9dd'}}, {'Name': 'docker-init', 'Version': '0.18.0', 'Details': {'GitCommit': 'fec3683'}}], Version=19.03.8, ApiVersion=1.40, MinAPIVersion=1.12, GitCommit=afacb8b, GoVersion=go1.12.17, Os=linux, Arch=amd64, KernelVersion=4.19.76-linuxkit, BuildTime=2020-03-11T01:29:16.000000000+00:00
compose.cli.verbose_proxy.proxy_callable: docker inspect_network <- ('app')
urllib3.connectionpool._make_request: http://localhost:None ""GET /v1.38/networks/app HTTP/1.1"" 200 540
compose.cli.verbose_proxy.proxy_callable: docker inspect_network -> {'Attachable': True,
 'ConfigFrom': {'Network': ''},
 'ConfigOnly': False,
 'Containers': {},
 'Created': '2020-07-01T15:33:52.097459378Z',
 'Driver': 'bridge',
 'EnableIPv6': False,
 'IPAM': {'Config': [{'Gateway': '172.18.0.1', 'Subnet': '172.18.0.0/16'}],
          'Driver': 'default',
          'Options': None},
...
compose.cli.verbose_proxy.proxy_callable: docker info <- ()
urllib3.connectionpool._make_request: http://localhost:None ""GET /v1.38/info HTTP/1.1"" 200 None
compose.cli.verbose_proxy.proxy_callable: docker info -> {'Architecture': 'x86_64',
 'BridgeNfIp6tables': True,
 'BridgeNfIptables': True,
 'CPUSet': True,
 'CPUShares': True,
 'CgroupDriver': 'cgroupfs',
 'ClusterAdvertise': '',
 'ClusterStore': '',
 'ContainerdCommit': {'Expected': '7ad184331fa3e55e52b890ea95e65ba581ae3429',
                      'ID': '7ad184331fa3e55e52b890ea95e65ba581ae3429'},
...
compose.cli.verbose_proxy.proxy_callable: docker inspect_network <- ('app')
urllib3.connectionpool._make_request: http://localhost:None ""GET /v1.38/networks/app HTTP/1.1"" 200 540
compose.cli.verbose_proxy.proxy_callable: docker inspect_network -> {'Attachable': True,
 'ConfigFrom': {'Network': ''},
 'ConfigOnly': False,
 'Containers': {},
 'Created': '2020-07-01T15:33:52.097459378Z',
 'Driver': 'bridge',
 'EnableIPv6': False,
 'IPAM': {'Config': [{'Gateway': '172.18.0.1', 'Subnet': '172.18.0.0/16'}],
          'Driver': 'default',
          'Options': None},
...
compose.cli.verbose_proxy.proxy_callable: docker containers <- (all=False, filters={'label': ['com.docker.compose.project=backend-db-test', 'com.docker.compose.oneoff=False']})
urllib3.connectionpool._make_request: http://localhost:None ""GET /v1.38/containers/json?limit=-1&all=0&size=0&trunc_cmd=0&filters=%7B%22label%22%3A+%5B%22com.docker.compose.project%3Dbackend-db-test%22%2C+%22com.docker.compose.oneoff%3DFalse%22%5D%7D HTTP/1.1"" 200 3
compose.cli.verbose_proxy.proxy_callable: docker containers -> (list with 0 items)
compose.cli.verbose_proxy.proxy_callable: docker containers <- (all=False, filters={'label': ['com.docker.compose.project=backenddbtest', 'com.docker.compose.oneoff=False']})
urllib3.connectionpool._make_request: http://localhost:None ""GET /v1.38/containers/json?limit=-1&all=0&size=0&trunc_cmd=0&filters=%7B%22label%22%3A+%5B%22com.docker.compose.project%3Dbackenddbtest%22%2C+%22com.docker.compose.oneoff%3DFalse%22%5D%7D HTTP/1.1"" 200 3
compose.cli.verbose_proxy.proxy_callable: docker containers -> (list with 0 items)
compose.cli.verbose_proxy.proxy_callable: docker containers <- (all=True, filters={'label': ['com.docker.compose.project=backend-db-test', 'com.docker.compose.oneoff=False']})
urllib3.connectionpool._make_request: http://localhost:None ""GET /v1.38/containers/json?limit=-1&all=1&size=0&trunc_cmd=0&filters=%7B%22label%22%3A+%5B%22com.docker.compose.project%3Dbackend-db-test%22%2C+%22com.docker.compose.oneoff%3DFalse%22%5D%7D HTTP/1.1"" 200 1572
compose.cli.verbose_proxy.proxy_callable: docker containers -> (list with 1 items)
compose.cli.verbose_proxy.proxy_callable: docker inspect_container <- ('1f6296183499d299609f041dc6dccad6ee3fc027a03f64a8b9b5f25636d69738')
urllib3.connectionpool._make_request: http://localhost:None ""GET /v1.38/containers/1f6296183499d299609f041dc6dccad6ee3fc027a03f64a8b9b5f25636d69738/json HTTP/1.1"" 200 None
compose.cli.verbose_proxy.proxy_callable: docker inspect_container -> {'AppArmorProfile': '',
 'Args': ['--character-set-server=utf8',
          '--innodb-flush-method=littlesync',
          '--innodb-use-native-aio=OFF',
          '--log_bin=ON',
          '--skip-innodb-file-per-table'],
 'Config': {'AttachStderr': False,
            'AttachStdin': False,
            'AttachStdout': False,
            'Cmd': ['--character-set-server=utf8',
...
compose.cli.verbose_proxy.proxy_callable: docker containers <- (all=True, filters={'label': ['com.docker.compose.project=backend-db-test', 'com.docker.compose.service=db', 'com.docker.compose.oneoff=False']})
urllib3.connectionpool._make_request: http://localhost:None ""GET /v1.38/containers/json?limit=-1&all=1&size=0&trunc_cmd=0&filters=%7B%22label%22%3A+%5B%22com.docker.compose.project%3Dbackend-db-test%22%2C+%22com.docker.compose.service%3Ddb%22%2C+%22com.docker.compose.oneoff%3DFalse%22%5D%7D HTTP/1.1"" 200 1572
compose.cli.verbose_proxy.proxy_callable: docker containers -> (list with 1 items)
compose.cli.verbose_proxy.proxy_callable: docker inspect_container <- ('1f6296183499d299609f041dc6dccad6ee3fc027a03f64a8b9b5f25636d69738')
urllib3.connectionpool._make_request: http://localhost:None ""GET /v1.38/containers/1f6296183499d299609f041dc6dccad6ee3fc027a03f64a8b9b5f25636d69738/json HTTP/1.1"" 200 None
compose.cli.verbose_proxy.proxy_callable: docker inspect_container -> {'AppArmorProfile': '',
 'Args': ['--character-set-server=utf8',
          '--innodb-flush-method=littlesync',
          '--innodb-use-native-aio=OFF',
          '--log_bin=ON',
          '--skip-innodb-file-per-table'],
 'Config': {'AttachStderr': False,
            'AttachStdin': False,
            'AttachStdout': False,
            'Cmd': ['--character-set-server=utf8',
...
compose.cli.verbose_proxy.proxy_callable: docker inspect_image <- ('mysql:latest')
urllib3.connectionpool._make_request: http://localhost:None ""GET /v1.38/images/mysql:latest/json HTTP/1.1"" 200 None
compose.cli.verbose_proxy.proxy_callable: docker inspect_image -> {'Architecture': 'amd64',
 'Author': '',
 'Comment': '',
 'Config': {'ArgsEscaped': True,
            'AttachStderr': False,
            'AttachStdin': False,
            'AttachStdout': False,
            'Cmd': ['mysqld'],
            'Domainname': '',
            'Entrypoint': ['docker-entrypoint.sh'],
...
compose.cli.verbose_proxy.proxy_callable: docker containers <- (all=True, filters={'label': ['com.docker.compose.project=backend-db-test', 'com.docker.compose.service=db', 'com.docker.compose.oneoff=False']})
urllib3.connectionpool._make_request: http://localhost:None ""GET /v1.38/containers/json?limit=-1&all=1&size=0&trunc_cmd=0&filters=%7B%22label%22%3A+%5B%22com.docker.compose.project%3Dbackend-db-test%22%2C+%22com.docker.compose.service%3Ddb%22%2C+%22com.docker.compose.oneoff%3DFalse%22%5D%7D HTTP/1.1"" 200 1572
compose.cli.verbose_proxy.proxy_callable: docker containers -> (list with 1 items)
compose.cli.verbose_proxy.proxy_callable: docker inspect_image <- ('mysql:latest')
urllib3.connectionpool._make_request: http://localhost:None ""GET /v1.38/images/mysql:latest/json HTTP/1.1"" 200 None
compose.cli.verbose_proxy.proxy_callable: docker inspect_image -> {'Architecture': 'amd64',
 'Author': '',
 'Comment': '',
 'Config': {'ArgsEscaped': True,
            'AttachStderr': False,
            'AttachStdin': False,
            'AttachStdout': False,
            'Cmd': ['mysqld'],
            'Domainname': '',
            'Entrypoint': ['docker-entrypoint.sh'],
...
compose.cli.verbose_proxy.proxy_callable: docker inspect_container <- ('1f6296183499d299609f041dc6dccad6ee3fc027a03f64a8b9b5f25636d69738')
urllib3.connectionpool._make_request: http://localhost:None ""GET /v1.38/containers/1f6296183499d299609f041dc6dccad6ee3fc027a03f64a8b9b5f25636d69738/json HTTP/1.1"" 200 None
compose.cli.verbose_proxy.proxy_callable: docker inspect_container -> {'AppArmorProfile': '',
 'Args': ['--character-set-server=utf8',
          '--innodb-flush-method=littlesync',
          '--innodb-use-native-aio=OFF',
          '--log_bin=ON',
          '--skip-innodb-file-per-table'],
 'Config': {'AttachStderr': False,
            'AttachStdin': False,
            'AttachStdout': False,
            'Cmd': ['--character-set-server=utf8',
...
compose.service._containers_have_diverged: 1f6296183499_backend-db-mysql has diverged: c1165d4bccecc6ee29397c5b22b4a054c39c7da457e5348a4e4b072c88ffcf92 != 9523b380ab62ba94094ab258b744f0e8731b7ef353b46dfd02e37c4e570a5f08
compose.parallel.feed_queue: Pending: {<Service: db>}
compose.parallel.feed_queue: Starting producer thread for <Service: db>
Recreating 1f6296183499_backend-db-mysql ...
compose.parallel.feed_queue: Pending: {<Container: 1f6296183499_backend-db-mysql (1f6296)>}
compose.parallel.feed_queue: Starting producer thread for <Container: 1f6296183499_backend-db-mysql (1f6296)>
compose.cli.verbose_proxy.proxy_callable: docker stop <- ('1f6296183499d299609f041dc6dccad6ee3fc027a03f64a8b9b5f25636d69738', timeout=10)
urllib3.connectionpool._make_request: http://localhost:None ""POST /v1.38/containers/1f6296183499d299609f041dc6dccad6ee3fc027a03f64a8b9b5f25636d69738/stop?t=10 HTTP/1.1"" 304 0
compose.cli.verbose_proxy.proxy_callable: docker stop -> None
compose.cli.verbose_proxy.proxy_callable: docker inspect_image <- ('mysql:latest')
urllib3.connectionpool._make_request: http://localhost:None ""GET /v1.38/images/mysql:latest/json HTTP/1.1"" 200 None
compose.cli.verbose_proxy.proxy_callable: docker inspect_image -> {'Architecture': 'amd64',
 'Author': '',
 'Comment': '',
 'Config': {'ArgsEscaped': True,
            'AttachStderr': False,
            'AttachStdin': False,
            'AttachStdout': False,
            'Cmd': ['mysqld'],
            'Domainname': '',
            'Entrypoint': ['docker-entrypoint.sh'],
...
compose.cli.verbose_proxy.proxy_callable: docker inspect_image <- ('sha256:a77a35a8a140c4ed547209dc0c814cbc85112528bf6058315c7c8efa88fd070e')
urllib3.connectionpool._make_request: http://localhost:None ""GET /v1.38/images/sha256:a77a35a8a140c4ed547209dc0c814cbc85112528bf6058315c7c8efa88fd070e/json HTTP/1.1"" 200 None
compose.cli.verbose_proxy.proxy_callable: docker inspect_image -> {'Architecture': 'amd64',
 'Author': '',
 'Comment': '',
 'Config': {'ArgsEscaped': True,
            'AttachStderr': False,
            'AttachStdin': False,
            'AttachStdout': False,
            'Cmd': ['mysqld'],
            'Domainname': '',
            'Entrypoint': ['docker-entrypoint.sh'],
...
compose.cli.verbose_proxy.proxy_callable: docker inspect_image <- ('mysql:latest')
urllib3.connectionpool._make_request: http://localhost:None ""GET /v1.38/images/mysql:latest/json HTTP/1.1"" 200 None
compose.cli.verbose_proxy.proxy_callable: docker inspect_image -> {'Architecture': 'amd64',
 'Author': '',
 'Comment': '',
 'Config': {'ArgsEscaped': True,
            'AttachStderr': False,
            'AttachStdin': False,
            'AttachStdout': False,
            'Cmd': ['mysqld'],
            'Domainname': '',
            'Entrypoint': ['docker-entrypoint.sh'],
...
compose.service.build_container_labels: Added config hash: 9523b380ab62ba94094ab258b744f0e8731b7ef353b46dfd02e37c4e570a5f08
compose.cli.verbose_proxy.proxy_callable: docker create_host_config <- (links=[], port_bindings={'3306/tcp': ['3306']}, binds=[], volumes_from=[], privileged=False, network_mode='app', devices=None, dns=None, dns_opt=None, dns_search=None, restart_policy={'Name': 'always', 'MaximumRetryCount': 0}, runtime=None, cap_add=None, cap_drop=None, mem_limit=None, mem_reservation=None, memswap_limit=None, ulimits=None, log_config={'Type': '', 'Config': {}}, extra_hosts=None, read_only=None, pid_mode=None, security_opt=None, ipc_mode=None, cgroup_parent=None, cpu_quota=None, shm_size=None, sysctls=None, pids_limit=None, tmpfs=None, oom_kill_disable=None, oom_score_adj=None, mem_swappiness=None, group_add=None, userns_mode=None, init=None, init_path=None, isolation=None, cpu_count=None, cpu_percent=None, nano_cpus=None, volume_driver=None, cpuset_cpus=None, cpu_shares=None, storage_opt=None, blkio_weight=None, blkio_weight_device=None, device_read_bps=None, device_read_iops=None, device_write_bps=None, device_write_iops=None, mounts=[{'Target': '/var/log/mysql', 'Source': 'D:\\development\\private\\backend-db-test\\backend-db-mysql\\logs', 'Type': 'bind', 'ReadOnly': None}, {'Target': '/var/lib/mysql', 'Source': 'D:\\development\\private\\backend-db-test\\backend-db-mysql\\data', 'Type': 'bind', 'ReadOnly': None}], device_cgroup_rules=None, cpu_period=None, cpu_rt_period=None, cpu_rt_runtime=None)
compose.cli.verbose_proxy.proxy_callable: docker create_host_config -> {'Binds': [],
 'Links': [],
 'LogConfig': {'Config': {}, 'Type': ''},
 'Mounts': [{'ReadOnly': None,
             'Source': 'D:\\development\\private\\backend-db-test\\backend-db-mysql\\logs',
             'Target': '/var/log/mysql',
             'Type': 'bind'},
            {'ReadOnly': None,
             'Source': 'D:\\development\\private\\backend-db-test\\backend-db-mysql\\data',
             'Target': '/var/lib/mysql',
...
compose.cli.verbose_proxy.proxy_callable: docker create_container <- (command='--character-set-server=utf8 --innodb-flush-method=littlesync --innodb-use-native-aio=OFF --log_bin=ON --skip-innodb-file-per-table', environment=['MYSQL_ROOT_PASSWORD=Xq54tGxtZt4MJha'], image='mysql:latest', ports=[('3306', 'tcp'), '3306'], volumes={}, name='backend-db-mysql', detach=True, labels={'com.docker.compose.project': 'backend-db-test', 'com.docker.compose.service': 'db', 'com.docker.compose.oneoff': 'False', 'com.docker.compose.project.working_dir': 'D:\\development\\private\\backend-db-test', 'com.docker.compose.project.config_files': 'docker-compose.yml', 'com.docker.compose.container-number': '1', 'com.docker.compose.version': '1.25.5', 'com.docker.compose.config-hash': '9523b380ab62ba94094ab258b744f0e8731b7ef353b46dfd02e37c4e570a5f08'}, host_config={'NetworkMode': 'app', 'RestartPolicy': {'Name': 'always', 'MaximumRetryCount': 0}, 'VolumesFrom': [], 'Binds': [], 'PortBindings': {'3306/tcp': [{'HostIp': '', 'HostPort': '3306'}]}, 'Links': [], 'LogConfig': {'Type': '', 'Config': {}}, 'Mounts': [{'Target': '/var/log/mysql', 'Source': 'D:\\development\\private\\backend-db-test\\backend-db-mysql\\logs', 'Type': 'bind', 'ReadOnly': None}, {'Target': '/var/lib/mysql', 'Source': 'D:\\development\\private\\backend-db-test\\backend-db-mysql\\data', 'Type': 'bind', 'ReadOnly': None}]}, networking_config={'EndpointsConfig': {'app': {'Aliases': ['db'], 'IPAMConfig': {}}}})
compose.parallel.feed_queue: Pending: set()
compose.parallel.feed_queue: Pending: set()
compose.parallel.feed_queue: Pending: set()
compose.parallel.feed_queue: Pending: set()
compose.parallel.feed_queue: Pending: set()
compose.parallel.feed_queue: Pending: set()
compose.parallel.feed_queue: Pending: set()
compose.parallel.feed_queue: Pending: set()
compose.parallel.feed_queue: Pending: set()
compose.parallel.feed_queue: Pending: set()
compose.parallel.feed_queue: Pending: set()
compose.parallel.feed_queue: Pending: set()
compose.parallel.feed_queue: Pending: set()
compose.parallel.feed_queue: Pending: set()
compose.parallel.feed_queue: Pending: set()
compose.parallel.feed_queue: Pending: set()
compose.parallel.feed_queue: Pending: set()
compose.parallel.feed_queue: Pending: set()
compose.parallel.feed_queue: Pending: set()
compose.parallel.feed_queue: Pending: set()
compose.parallel.feed_queue: Pending: set()
compose.parallel.feed_queue: Pending: set()
compose.parallel.feed_queue: Pending: set()
compose.parallel.feed_queue: Pending: set()
compose.parallel.feed_queue: Pending: set()
compose.parallel.feed_queue: Pending: set()
...
```

### Expected result

Successful service start.

If the volumes definition is removed, the service starts, i.e. this yml file:

```
version: '3.7'

services:
   db:
    image: mysql:latest
    container_name: backend-db-mysql
    ports:
    - ""3306:3306""
    expose:
    - '3306'
    environment:
        MYSQL_ROOT_PASSWORD: ${PERSISTENT_DB_ROOT_PWD}
    restart: always
    command: --character-set-server=utf8 --innodb-flush-method=littlesync --innodb-use-native-aio=OFF --log_bin=ON --skip-innodb-file-per-table
    networks:
    - app
       
networks:
  app:
    name: app
```

Produces the following output:
```
compose.config.config.find: Using configuration files: .\docker-compose.yml
docker.utils.config.find_config_file: Trying paths: ['C:\\Users\\Donald\\.docker\\config.json', 'C:\\Users\\Donald\\.dockercfg']
docker.utils.config.find_config_file: Found file at path: C:\Users\Donald\.docker\config.json
docker.auth.load_config: Found 'auths' section
docker.auth.parse_auth: Auth data for https://index.docker.io/v1/ is absent. Client might be using a credentials store instead.
docker.auth.load_config: Found 'credsStore' section
urllib3.connectionpool._make_request: http://localhost:None ""GET /v1.38/version HTTP/1.1"" 200 853
compose.cli.command.get_client: docker-compose version 1.25.5, build 8a1c60f6
docker-py version: 4.1.0
CPython version: 3.7.4
OpenSSL version: OpenSSL 1.1.1c  28 May 2019
compose.cli.command.get_client: Docker base_url: http+docker://localnpipe
compose.cli.command.get_client: Docker version: Platform={'Name': 'Docker Engine - Community'}, Components=[{'Name': 'Engine', 'Version': '19.03.8', 'Details': {'ApiVersion': '1.40', 'Arch': 'amd64', 'BuildTime': '2020-03-11T01:29:16.000000000+00:00', 'Experimental': 'false', 'GitCommit': 'afacb8b', 'GoVersion': 'go1.12.17', 'KernelVersion': '4.19.76-linuxkit', 'MinAPIVersion': '1.12', 'Os': 'linux'}}, {'Name': 'containerd', 'Version': 'v1.2.13', 'Details': {'GitCommit': '7ad184331fa3e55e52b890ea95e65ba581ae3429'}}, {'Name': 'runc', 'Version': '1.0.0-rc10', 'Details': {'GitCommit': 'dc9208a3303feef5b3839f4323d9beb36df0a9dd'}}, {'Name': 'docker-init', 'Version': '0.18.0', 'Details': {'GitCommit': 'fec3683'}}], Version=19.03.8, ApiVersion=1.40, MinAPIVersion=1.12, GitCommit=afacb8b, GoVersion=go1.12.17, Os=linux, Arch=amd64, KernelVersion=4.19.76-linuxkit, BuildTime=2020-03-11T01:29:16.000000000+00:00
compose.cli.verbose_proxy.proxy_callable: docker inspect_network <- ('app')
urllib3.connectionpool._make_request: http://localhost:None ""GET /v1.38/networks/app HTTP/1.1"" 200 540
compose.cli.verbose_proxy.proxy_callable: docker inspect_network -> {'Attachable': True,
 'ConfigFrom': {'Network': ''},
 'ConfigOnly': False,
 'Containers': {},
 'Created': '2020-07-01T15:33:52.097459378Z',
 'Driver': 'bridge',
 'EnableIPv6': False,
 'IPAM': {'Config': [{'Gateway': '172.18.0.1', 'Subnet': '172.18.0.0/16'}],
          'Driver': 'default',
          'Options': None},
...
compose.cli.verbose_proxy.proxy_callable: docker info <- ()
urllib3.connectionpool._make_request: http://localhost:None ""GET /v1.38/info HTTP/1.1"" 200 None
compose.cli.verbose_proxy.proxy_callable: docker info -> {'Architecture': 'x86_64',
 'BridgeNfIp6tables': True,
 'BridgeNfIptables': True,
 'CPUSet': True,
 'CPUShares': True,
 'CgroupDriver': 'cgroupfs',
 'ClusterAdvertise': '',
 'ClusterStore': '',
 'ContainerdCommit': {'Expected': '7ad184331fa3e55e52b890ea95e65ba581ae3429',
                      'ID': '7ad184331fa3e55e52b890ea95e65ba581ae3429'},
...
compose.cli.verbose_proxy.proxy_callable: docker inspect_network <- ('app')
urllib3.connectionpool._make_request: http://localhost:None ""GET /v1.38/networks/app HTTP/1.1"" 200 540
compose.cli.verbose_proxy.proxy_callable: docker inspect_network -> {'Attachable': True,
 'ConfigFrom': {'Network': ''},
 'ConfigOnly': False,
 'Containers': {},
 'Created': '2020-07-01T15:33:52.097459378Z',
 'Driver': 'bridge',
 'EnableIPv6': False,
 'IPAM': {'Config': [{'Gateway': '172.18.0.1', 'Subnet': '172.18.0.0/16'}],
          'Driver': 'default',
          'Options': None},
...
compose.cli.verbose_proxy.proxy_callable: docker containers <- (all=False, filters={'label': ['com.docker.compose.project=backend-db-test', 'com.docker.compose.oneoff=False']})
urllib3.connectionpool._make_request: http://localhost:None ""GET /v1.38/containers/json?limit=-1&all=0&size=0&trunc_cmd=0&filters=%7B%22label%22%3A+%5B%22com.docker.compose.project%3Dbackend-db-test%22%2C+%22com.docker.compose.oneoff%3DFalse%22%5D%7D HTTP/1.1"" 200 3
compose.cli.verbose_proxy.proxy_callable: docker containers -> (list with 0 items)
compose.cli.verbose_proxy.proxy_callable: docker containers <- (all=False, filters={'label': ['com.docker.compose.project=backenddbtest', 'com.docker.compose.oneoff=False']})
urllib3.connectionpool._make_request: http://localhost:None ""GET /v1.38/containers/json?limit=-1&all=0&size=0&trunc_cmd=0&filters=%7B%22label%22%3A+%5B%22com.docker.compose.project%3Dbackenddbtest%22%2C+%22com.docker.compose.oneoff%3DFalse%22%5D%7D HTTP/1.1"" 200 3
compose.cli.verbose_proxy.proxy_callable: docker containers -> (list with 0 items)
compose.cli.verbose_proxy.proxy_callable: docker containers <- (all=True, filters={'label': ['com.docker.compose.project=backend-db-test', 'com.docker.compose.oneoff=False']})
urllib3.connectionpool._make_request: http://localhost:None ""GET /v1.38/containers/json?limit=-1&all=1&size=0&trunc_cmd=0&filters=%7B%22label%22%3A+%5B%22com.docker.compose.project%3Dbackend-db-test%22%2C+%22com.docker.compose.oneoff%3DFalse%22%5D%7D HTTP/1.1"" 200 1572
compose.cli.verbose_proxy.proxy_callable: docker containers -> (list with 1 items)
compose.cli.verbose_proxy.proxy_callable: docker inspect_container <- ('1f6296183499d299609f041dc6dccad6ee3fc027a03f64a8b9b5f25636d69738')
urllib3.connectionpool._make_request: http://localhost:None ""GET /v1.38/containers/1f6296183499d299609f041dc6dccad6ee3fc027a03f64a8b9b5f25636d69738/json HTTP/1.1"" 200 None
compose.cli.verbose_proxy.proxy_callable: docker inspect_container -> {'AppArmorProfile': '',
 'Args': ['--character-set-server=utf8',
          '--innodb-flush-method=littlesync',
          '--innodb-use-native-aio=OFF',
          '--log_bin=ON',
          '--skip-innodb-file-per-table'],
 'Config': {'AttachStderr': False,
            'AttachStdin': False,
            'AttachStdout': False,
            'Cmd': ['--character-set-server=utf8',
...
compose.cli.verbose_proxy.proxy_callable: docker containers <- (all=True, filters={'label': ['com.docker.compose.project=backend-db-test', 'com.docker.compose.service=db', 'com.docker.compose.oneoff=False']})
urllib3.connectionpool._make_request: http://localhost:None ""GET /v1.38/containers/json?limit=-1&all=1&size=0&trunc_cmd=0&filters=%7B%22label%22%3A+%5B%22com.docker.compose.project%3Dbackend-db-test%22%2C+%22com.docker.compose.service%3Ddb%22%2C+%22com.docker.compose.oneoff%3DFalse%22%5D%7D HTTP/1.1"" 200 1572
compose.cli.verbose_proxy.proxy_callable: docker containers -> (list with 1 items)
compose.cli.verbose_proxy.proxy_callable: docker inspect_container <- ('1f6296183499d299609f041dc6dccad6ee3fc027a03f64a8b9b5f25636d69738')
urllib3.connectionpool._make_request: http://localhost:None ""GET /v1.38/containers/1f6296183499d299609f041dc6dccad6ee3fc027a03f64a8b9b5f25636d69738/json HTTP/1.1"" 200 None
compose.cli.verbose_proxy.proxy_callable: docker inspect_container -> {'AppArmorProfile': '',
 'Args': ['--character-set-server=utf8',
          '--innodb-flush-method=littlesync',
          '--innodb-use-native-aio=OFF',
          '--log_bin=ON',
          '--skip-innodb-file-per-table'],
 'Config': {'AttachStderr': False,
            'AttachStdin': False,
            'AttachStdout': False,
            'Cmd': ['--character-set-server=utf8',
...
compose.cli.verbose_proxy.proxy_callable: docker inspect_image <- ('mysql:latest')
urllib3.connectionpool._make_request: http://localhost:None ""GET /v1.38/images/mysql:latest/json HTTP/1.1"" 200 None
compose.cli.verbose_proxy.proxy_callable: docker inspect_image -> {'Architecture': 'amd64',
 'Author': '',
 'Comment': '',
 'Config': {'ArgsEscaped': True,
            'AttachStderr': False,
            'AttachStdin': False,
            'AttachStdout': False,
            'Cmd': ['mysqld'],
            'Domainname': '',
            'Entrypoint': ['docker-entrypoint.sh'],
...
compose.cli.verbose_proxy.proxy_callable: docker containers <- (all=True, filters={'label': ['com.docker.compose.project=backend-db-test', 'com.docker.compose.service=db', 'com.docker.compose.oneoff=False']})
urllib3.connectionpool._make_request: http://localhost:None ""GET /v1.38/containers/json?limit=-1&all=1&size=0&trunc_cmd=0&filters=%7B%22label%22%3A+%5B%22com.docker.compose.project%3Dbackend-db-test%22%2C+%22com.docker.compose.service%3Ddb%22%2C+%22com.docker.compose.oneoff%3DFalse%22%5D%7D HTTP/1.1"" 200 1572
compose.cli.verbose_proxy.proxy_callable: docker containers -> (list with 1 items)
compose.cli.verbose_proxy.proxy_callable: docker inspect_image <- ('mysql:latest')
urllib3.connectionpool._make_request: http://localhost:None ""GET /v1.38/images/mysql:latest/json HTTP/1.1"" 200 None
compose.cli.verbose_proxy.proxy_callable: docker inspect_image -> {'Architecture': 'amd64',
 'Author': '',
 'Comment': '',
 'Config': {'ArgsEscaped': True,
            'AttachStderr': False,
            'AttachStdin': False,
            'AttachStdout': False,
            'Cmd': ['mysqld'],
            'Domainname': '',
            'Entrypoint': ['docker-entrypoint.sh'],
...
compose.cli.verbose_proxy.proxy_callable: docker inspect_container <- ('1f6296183499d299609f041dc6dccad6ee3fc027a03f64a8b9b5f25636d69738')
urllib3.connectionpool._make_request: http://localhost:None ""GET /v1.38/containers/1f6296183499d299609f041dc6dccad6ee3fc027a03f64a8b9b5f25636d69738/json HTTP/1.1"" 200 None
compose.cli.verbose_proxy.proxy_callable: docker inspect_container -> {'AppArmorProfile': '',
 'Args': ['--character-set-server=utf8',
          '--innodb-flush-method=littlesync',
          '--innodb-use-native-aio=OFF',
          '--log_bin=ON',
          '--skip-innodb-file-per-table'],
 'Config': {'AttachStderr': False,
            'AttachStdin': False,
            'AttachStdout': False,
            'Cmd': ['--character-set-server=utf8',
...
compose.service._containers_have_diverged: 1f6296183499_backend-db-mysql has diverged: c1165d4bccecc6ee29397c5b22b4a054c39c7da457e5348a4e4b072c88ffcf92 != 258d0ef2b49cc54667542c4a87a476fd1457e863bf50178db046193af9def3a9
compose.parallel.feed_queue: Pending: {<Service: db>}
compose.parallel.feed_queue: Starting producer thread for <Service: db>
Recreating 1f6296183499_backend-db-mysql ...
compose.parallel.feed_queue: Pending: {<Container: 1f6296183499_backend-db-mysql (1f6296)>}
compose.parallel.feed_queue: Starting producer thread for <Container: 1f6296183499_backend-db-mysql (1f6296)>
compose.cli.verbose_proxy.proxy_callable: docker stop <- ('1f6296183499d299609f041dc6dccad6ee3fc027a03f64a8b9b5f25636d69738', timeout=10)
urllib3.connectionpool._make_request: http://localhost:None ""POST /v1.38/containers/1f6296183499d299609f041dc6dccad6ee3fc027a03f64a8b9b5f25636d69738/stop?t=10 HTTP/1.1"" 304 0
compose.cli.verbose_proxy.proxy_callable: docker stop -> None
compose.cli.verbose_proxy.proxy_callable: docker inspect_image <- ('mysql:latest')
urllib3.connectionpool._make_request: http://localhost:None ""GET /v1.38/images/mysql:latest/json HTTP/1.1"" 200 None
compose.cli.verbose_proxy.proxy_callable: docker inspect_image -> {'Architecture': 'amd64',
 'Author': '',
 'Comment': '',
 'Config': {'ArgsEscaped': True,
            'AttachStderr': False,
            'AttachStdin': False,
            'AttachStdout': False,
            'Cmd': ['mysqld'],
            'Domainname': '',
            'Entrypoint': ['docker-entrypoint.sh'],
...
compose.cli.verbose_proxy.proxy_callable: docker inspect_image <- ('sha256:a77a35a8a140c4ed547209dc0c814cbc85112528bf6058315c7c8efa88fd070e')
urllib3.connectionpool._make_request: http://localhost:None ""GET /v1.38/images/sha256:a77a35a8a140c4ed547209dc0c814cbc85112528bf6058315c7c8efa88fd070e/json HTTP/1.1"" 200 None
compose.cli.verbose_proxy.proxy_callable: docker inspect_image -> {'Architecture': 'amd64',
 'Author': '',
 'Comment': '',
 'Config': {'ArgsEscaped': True,
            'AttachStderr': False,
            'AttachStdin': False,
            'AttachStdout': False,
            'Cmd': ['mysqld'],
            'Domainname': '',
            'Entrypoint': ['docker-entrypoint.sh'],
...
compose.cli.verbose_proxy.proxy_callable: docker inspect_image <- ('mysql:latest')
urllib3.connectionpool._make_request: http://localhost:None ""GET /v1.38/images/mysql:latest/json HTTP/1.1"" 200 None
compose.cli.verbose_proxy.proxy_callable: docker inspect_image -> {'Architecture': 'amd64',
 'Author': '',
 'Comment': '',
 'Config': {'ArgsEscaped': True,
            'AttachStderr': False,
            'AttachStdin': False,
            'AttachStdout': False,
            'Cmd': ['mysqld'],
            'Domainname': '',
            'Entrypoint': ['docker-entrypoint.sh'],
...
compose.service.build_container_labels: Added config hash: 258d0ef2b49cc54667542c4a87a476fd1457e863bf50178db046193af9def3a9
compose.cli.verbose_proxy.proxy_callable: docker create_host_config <- (links=[], port_bindings={'3306/tcp': ['3306']}, binds=['backend-db-test_db_data:/var/lib/mysql:rw'], volumes_from=[], privileged=False, network_mode='app', devices=None, dns=None, dns_opt=None, dns_search=None, restart_policy={'Name': 'always', 'MaximumRetryCount': 0}, runtime=None, cap_add=None, cap_drop=None, mem_limit=None, mem_reservation=None, memswap_limit=None, ulimits=None, log_config={'Type': '', 'Config': {}}, extra_hosts=None, read_only=None, pid_mode=None, security_opt=None, ipc_mode=None, cgroup_parent=None, cpu_quota=None, shm_size=None, sysctls=None, pids_limit=None, tmpfs=None, oom_kill_disable=None, oom_score_adj=None, mem_swappiness=None, group_add=None, userns_mode=None, init=None, init_path=None, isolation=None, cpu_count=None, cpu_percent=None, nano_cpus=None, volume_driver=None, cpuset_cpus=None, cpu_shares=None, storage_opt=None, blkio_weight=None, blkio_weight_device=None, device_read_bps=None, device_read_iops=None, device_write_bps=None, device_write_iops=None, mounts=None, device_cgroup_rules=None, cpu_period=None, cpu_rt_period=None, cpu_rt_runtime=None)
compose.cli.verbose_proxy.proxy_callable: docker create_host_config -> {'Binds': ['backend-db-test_db_data:/var/lib/mysql:rw'],
 'Links': [],
 'LogConfig': {'Config': {}, 'Type': ''},
 'NetworkMode': 'app',
 'PortBindings': {'3306/tcp': [{'HostIp': '', 'HostPort': '3306'}]},
 'RestartPolicy': {'MaximumRetryCount': 0, 'Name': 'always'},
 'VolumesFrom': []}
compose.cli.verbose_proxy.proxy_callable: docker create_container <- (command='--character-set-server=utf8 --innodb-flush-method=littlesync --innodb-use-native-aio=OFF --log_bin=ON --skip-innodb-file-per-table', environment=['MYSQL_ROOT_PASSWORD=Xq54tGxtZt4MJha', 'affinity:container==1f6296183499d299609f041dc6dccad6ee3fc027a03f64a8b9b5f25636d69738'], image='mysql:latest', ports=[('3306', 'tcp'), '3306'], volumes={}, name='backend-db-mysql', detach=True, labels={'com.docker.compose.project': 'backend-db-test', 'com.docker.compose.service': 'db', 'com.docker.compose.oneoff': 'False', 'com.docker.compose.project.working_dir': 'D:\\development\\private\\backend-db-test', 'com.docker.compose.project.config_files': 'docker-compose.yml', 'com.docker.compose.container-number': '1', 'com.docker.compose.version': '1.25.5', 'com.docker.compose.config-hash': '258d0ef2b49cc54667542c4a87a476fd1457e863bf50178db046193af9def3a9'}, host_config={'NetworkMode': 'app', 'RestartPolicy': {'Name': 'always', 'MaximumRetryCount': 0}, 'VolumesFrom': [], 'Binds': ['backend-db-test_db_data:/var/lib/mysql:rw'], 'PortBindings': {'3306/tcp': [{'HostIp': '', 'HostPort': '3306'}]}, 'Links': [], 'LogConfig': {'Type': '', 'Config': {}}}, networking_config={'EndpointsConfig': {'app': {'Aliases': ['db'], 'IPAMConfig': {}}}})
urllib3.connectionpool._make_request: http://localhost:None ""POST /v1.38/containers/create?name=backend-db-mysql HTTP/1.1"" 201 88
compose.cli.verbose_proxy.proxy_callable: docker create_container -> {'Id': '43bbbebb61cd99025df65565179181607b3cf3815eaec774ec5dc9e6dbedd93d',
 'Warnings': []}
compose.cli.verbose_proxy.proxy_callable: docker inspect_container <- ('43bbbebb61cd99025df65565179181607b3cf3815eaec774ec5dc9e6dbedd93d')
urllib3.connectionpool._make_request: http://localhost:None ""GET /v1.38/containers/43bbbebb61cd99025df65565179181607b3cf3815eaec774ec5dc9e6dbedd93d/json HTTP/1.1"" 200 None
compose.cli.verbose_proxy.proxy_callable: docker inspect_container -> {'AppArmorProfile': '',
 'Args': ['--character-set-server=utf8',
          '--innodb-flush-method=littlesync',
          '--innodb-use-native-aio=OFF',
          '--log_bin=ON',
          '--skip-innodb-file-per-table'],
 'Config': {'AttachStderr': False,
            'AttachStdin': False,
            'AttachStdout': False,
            'Cmd': ['--character-set-server=utf8',
...
compose.cli.verbose_proxy.proxy_callable: docker attach <- ('43bbbebb61cd99025df65565179181607b3cf3815eaec774ec5dc9e6dbedd93d', stdout=True, stderr=True, stream=True)
urllib3.connectionpool._make_request: http://localhost:None ""POST /v1.38/containers/43bbbebb61cd99025df65565179181607b3cf3815eaec774ec5dc9e6dbedd93d/attach?logs=0&stdout=1&stderr=1&stream=1 HTTP/1.1"" 101 0
urllib3.connectionpool._make_request: http://localhost:None ""GET /v1.38/containers/43bbbebb61cd99025df65565179181607b3cf3815eaec774ec5dc9e6dbedd93d/json HTTP/1.1"" 200 None
compose.cli.verbose_proxy.proxy_callable: docker attach -> <docker.types.daemon.CancellableStream object at 0x000001AD5B424F08>
compose.cli.verbose_proxy.proxy_callable: docker disconnect_container_from_network <- ('43bbbebb61cd99025df65565179181607b3cf3815eaec774ec5dc9e6dbedd93d', 'app')
urllib3.connectionpool._make_request: http://localhost:None ""POST /v1.38/networks/app/disconnect HTTP/1.1"" 200 0
compose.cli.verbose_proxy.proxy_callable: docker disconnect_container_from_network -> None
compose.cli.verbose_proxy.proxy_callable: docker connect_container_to_network <- ('43bbbebb61cd99025df65565179181607b3cf3815eaec774ec5dc9e6dbedd93d', 'app', aliases=['db', '43bbbebb61cd'], ipv4_address=None, ipv6_address=None, links=[], link_local_ips=None)
compose.parallel.feed_queue: Pending: set()
compose.parallel.feed_queue: Pending: set()
urllib3.connectionpool._make_request: http://localhost:None ""POST /v1.38/networks/app/connect HTTP/1.1"" 200 0
compose.cli.verbose_proxy.proxy_callable: docker connect_container_to_network -> None
compose.cli.verbose_proxy.proxy_callable: docker start <- ('43bbbebb61cd99025df65565179181607b3cf3815eaec774ec5dc9e6dbedd93d')
compose.parallel.feed_queue: Pending: set()
compose.parallel.feed_queue: Pending: set()
compose.parallel.feed_queue: Pending: set()
compose.parallel.feed_queue: Pending: set()
urllib3.connectionpool._make_request: http://localhost:None ""POST /v1.38/containers/43bbbebb61cd99025df65565179181607b3cf3815eaec774ec5dc9e6dbedd93d/start HTTP/1.1"" 204 0
compose.cli.verbose_proxy.proxy_callable: docker start -> None
compose.cli.verbose_proxy.proxy_callable: docker remove_container <- ('1f6296183499d299609f041dc6dccad6ee3fc027a03f64a8b9b5f25636d69738')
urllib3.connectionpool._make_request: http://localhost:None ""DELETE /v1.38/containers/1f6296183499d299609f041dc6dccad6ee3fc027a03f64a8b9b5f25636d69738?v=False&link=False&force=False HTTP/1.1"" 204 0
compose.cli.verbose_proxy.proxy_callable: docker remove_container -> None
Recreating 1f6296183499_backend-db-mysql ... done
compose.parallel.feed_queue: Pending: set()
compose.parallel.parallel_execute_iter: Finished processing: <Service: db>
compose.parallel.feed_queue: Pending: set()
compose.cli.verbose_proxy.proxy_callable: docker events <- (filters={'label': ['com.docker.compose.project=backend-db-test', 'com.docker.compose.oneoff=False']}, decode=True)
Attaching to backend-db-mysql
backend-db-mysql | 2020-07-01 16:02:18+00:00 [Note] [Entrypoint]: Entrypoint script for MySQL Server 8.0.20-1debian10 started.
urllib3.connectionpool._make_request: http://localhost:None ""GET /v1.38/events?filters=%7B%22label%22%3A+%5B%22com.docker.compose.project%3Dbackend-db-test%22%2C+%22com.docker.compose.oneoff%3DFalse%22%5D%7D HTTP/1.1"" 200 None
compose.cli.verbose_proxy.proxy_callable: docker events -> <docker.types.daemon.CancellableStream object at 0x000001AD5B3FEC48>
backend-db-mysql | 2020-07-01 16:02:18+00:00 [Note] [Entrypoint]: Switching to dedicated user 'mysql'
backend-db-mysql | 2020-07-01 16:02:18+00:00 [Note] [Entrypoint]: Entrypoint script for MySQL Server 8.0.20-1debian10 started.
backend-db-mysql | 2020-07-01T16:02:19.059185Z 0 [Warning] [MY-011070] [Server] 'Disabling symbolic links using --skip-symbolic-links (or equivalent) is the default. Consider not using this option as it' is deprecated and will be removed in a future release.
backend-db-mysql | 2020-07-01T16:02:19.059298Z 0 [System] [MY-010116] [Server] /usr/sbin/mysqld (mysqld 8.0.20) starting as process 1
backend-db-mysql | 2020-07-01T16:02:19.062102Z 0 [Warning] [MY-013242] [Server] --character-set-server: 'utf8' is currently an alias for the character set UTF8MB3, but will be an alias for UTF8MB4 in a future release. Please consider using UTF8MB4 in order to be unambiguous.
backend-db-mysql | 2020-07-01T16:02:19.068964Z 1 [System] [MY-013576] [InnoDB] InnoDB initialization has started.
backend-db-mysql | 2020-07-01T16:02:19.284476Z 1 [System] [MY-013577] [InnoDB] InnoDB initialization has ended.
backend-db-mysql | 2020-07-01T16:02:19.371873Z 0 [System] [MY-011323] [Server] X Plugin ready for connections. Socket: '/var/run/mysqld/mysqlx.sock' bind-address: '::' port: 33060
backend-db-mysql | 2020-07-01T16:02:19.428858Z 0 [Warning] [MY-010068] [Server] CA certificate ca.pem is self signed.
backend-db-mysql | 2020-07-01T16:02:19.432637Z 0 [Warning] [MY-011810] [Server] Insecure configuration for --pid-file: Location '/var/run/mysqld' in the path is accessible to all OS users. Consider choosing a different directory.
backend-db-mysql | 2020-07-01T16:02:19.446559Z 0 [System] [MY-010931] [Server] /usr/sbin/mysqld: ready for connections. Version: '8.0.20'  socket: '/var/run/mysqld/mysqld.sock'  port: 3306  MySQL Community Server - GPL.
```

### Stacktrace / full error message

```
See observed result
```

Alternatively, I have tried the following:

```
docker-compose --verbose build && docker-compose --verbose start db
```

Which gives the following output:
```
compose.config.config.find: Using configuration files: .\docker-compose.yml
docker.utils.config.find_config_file: Trying paths: ['C:\\Users\\Donald\\.docker\\config.json', 'C:\\Users\\Donald\\.dockercfg']
docker.utils.config.find_config_file: Found file at path: C:\Users\Donald\.docker\config.json
docker.auth.load_config: Found 'auths' section
docker.auth.parse_auth: Auth data for https://index.docker.io/v1/ is absent. Client might be using a credentials store instead.
docker.auth.load_config: Found 'credsStore' section
urllib3.connectionpool._make_request: http://localhost:None ""GET /v1.38/version HTTP/1.1"" 200 853
compose.cli.command.get_client: docker-compose version 1.25.5, build 8a1c60f6
docker-py version: 4.1.0
CPython version: 3.7.4
OpenSSL version: OpenSSL 1.1.1c  28 May 2019
compose.cli.command.get_client: Docker base_url: http+docker://localnpipe
compose.cli.command.get_client: Docker version: Platform={'Name': 'Docker Engine - Community'}, Components=[{'Name': 'Engine', 'Version': '19.03.8', 'Details': {'ApiVersion': '1.40', 'Arch': 'amd64', 'BuildTime': '2020-03-11T01:29:16.000000000+00:00', 'Experimental': 'false', 'GitCommit': 'afacb8b', 'GoVersion': 'go1.12.17', 'KernelVersion': '4.19.76-linuxkit', 'MinAPIVersion': '1.12', 'Os': 'linux'}}, {'Name': 'containerd', 'Version': 'v1.2.13', 'Details': {'GitCommit': '7ad184331fa3e55e52b890ea95e65ba581ae3429'}}, {'Name': 'runc', 'Version': '1.0.0-rc10', 'Details': {'GitCommit': 'dc9208a3303feef5b3839f4323d9beb36df0a9dd'}}, {'Name': 'docker-init', 'Version': '0.18.0', 'Details': {'GitCommit': 'fec3683'}}], Version=19.03.8, ApiVersion=1.40, MinAPIVersion=1.12, GitCommit=afacb8b, GoVersion=go1.12.17, Os=linux, Arch=amd64, KernelVersion=4.19.76-linuxkit, BuildTime=2020-03-11T01:29:16.000000000+00:00
compose.cli.verbose_proxy.proxy_callable: docker inspect_network <- ('app')
urllib3.connectionpool._make_request: http://localhost:None ""GET /v1.38/networks/app HTTP/1.1"" 200 540
compose.cli.verbose_proxy.proxy_callable: docker inspect_network -> {'Attachable': True,
 'ConfigFrom': {'Network': ''},
 'ConfigOnly': False,
 'Containers': {},
 'Created': '2020-07-01T15:33:52.097459378Z',
 'Driver': 'bridge',
 'EnableIPv6': False,
 'IPAM': {'Config': [{'Gateway': '172.18.0.1', 'Subnet': '172.18.0.0/16'}],
          'Driver': 'default',
          'Options': None},
...
compose.project.build: db uses an image, skipping
compose.config.config.find: Using configuration files: .\docker-compose.yml
docker.utils.config.find_config_file: Trying paths: ['C:\\Users\\Donald\\.docker\\config.json', 'C:\\Users\\Donald\\.dockercfg']
docker.utils.config.find_config_file: Found file at path: C:\Users\Donald\.docker\config.json
docker.auth.load_config: Found 'auths' section
docker.auth.parse_auth: Auth data for https://index.docker.io/v1/ is absent. Client might be using a credentials store instead.
docker.auth.load_config: Found 'credsStore' section
urllib3.connectionpool._make_request: http://localhost:None ""GET /v1.38/version HTTP/1.1"" 200 853
compose.cli.command.get_client: docker-compose version 1.25.5, build 8a1c60f6
docker-py version: 4.1.0
CPython version: 3.7.4
OpenSSL version: OpenSSL 1.1.1c  28 May 2019
compose.cli.command.get_client: Docker base_url: http+docker://localnpipe
compose.cli.command.get_client: Docker version: Platform={'Name': 'Docker Engine - Community'}, Components=[{'Name': 'Engine', 'Version': '19.03.8', 'Details': {'ApiVersion': '1.40', 'Arch': 'amd64', 'BuildTime': '2020-03-11T01:29:16.000000000+00:00', 'Experimental': 'false', 'GitCommit': 'afacb8b', 'GoVersion': 'go1.12.17', 'KernelVersion': '4.19.76-linuxkit', 'MinAPIVersion': '1.12', 'Os': 'linux'}}, {'Name': 'containerd', 'Version': 'v1.2.13', 'Details': {'GitCommit': '7ad184331fa3e55e52b890ea95e65ba581ae3429'}}, {'Name': 'runc', 'Version': '1.0.0-rc10', 'Details': {'GitCommit': 'dc9208a3303feef5b3839f4323d9beb36df0a9dd'}}, {'Name': 'docker-init', 'Version': '0.18.0', 'Details': {'GitCommit': 'fec3683'}}], Version=19.03.8, ApiVersion=1.40, MinAPIVersion=1.12, GitCommit=afacb8b, GoVersion=go1.12.17, Os=linux, Arch=amd64, KernelVersion=4.19.76-linuxkit, BuildTime=2020-03-11T01:29:16.000000000+00:00
compose.cli.verbose_proxy.proxy_callable: docker inspect_network <- ('app')
urllib3.connectionpool._make_request: http://localhost:None ""GET /v1.38/networks/app HTTP/1.1"" 200 540
compose.cli.verbose_proxy.proxy_callable: docker inspect_network -> {'Attachable': True,
 'ConfigFrom': {'Network': ''},
 'ConfigOnly': False,
 'Containers': {},
 'Created': '2020-07-01T15:33:52.097459378Z',
 'Driver': 'bridge',
 'EnableIPv6': False,
 'IPAM': {'Config': [{'Gateway': '172.18.0.1', 'Subnet': '172.18.0.0/16'}],
          'Driver': 'default',
          'Options': None},
...
Starting db ...
compose.parallel.feed_queue: Pending: {<Service: db>}
compose.parallel.feed_queue: Starting producer thread for <Service: db>
compose.cli.verbose_proxy.proxy_callable: docker containers <- (all=True, filters={'label': ['com.docker.compose.project=backend-db-test', 'com.docker.compose.service=db', 'com.docker.compose.oneoff=False']})
urllib3.connectionpool._make_request: http://localhost:None ""GET /v1.38/containers/json?limit=-1&all=1&size=0&trunc_cmd=0&filters=%7B%22label%22%3A+%5B%22com.docker.compose.project%3Dbackend-db-test%22%2C+%22com.docker.compose.service%3Ddb%22%2C+%22com.docker.compose.oneoff%3DFalse%22%5D%7D HTTP/1.1"" 200 3
compose.cli.verbose_proxy.proxy_callable: docker containers -> (list with 0 items)
compose.cli.verbose_proxy.proxy_callable: docker containers <- (all=True, filters={'label': ['com.docker.compose.project=backenddbtest', 'com.docker.compose.service=db', 'com.docker.compose.oneoff=False']})
urllib3.connectionpool._make_request: http://localhost:None ""GET /v1.38/containers/json?limit=-1&all=1&size=0&trunc_cmd=0&filters=%7B%22label%22%3A+%5B%22com.docker.compose.project%3Dbackenddbtest%22%2C+%22com.docker.compose.service%3Ddb%22%2C+%22com.docker.compose.oneoff%3DFalse%22%5D%7D HTTP/1.1"" 200 3
compose.cli.verbose_proxy.proxy_callable: docker containers -> (list with 0 items)
compose.parallel.parallel_execute_iter: Finished processing: <Service: db>
compose.cli.verbose_proxy.proxy_callable: docker containers <- (all=False, filters={'label': ['com.docker.compose.project=backend-db-test', 'com.docker.compose.service=db', 'com.docker.compose.oneoff=False']})
urllib3.connectionpool._make_request: http://localhost:None ""GET /v1.38/containers/json?limit=-1&all=0&size=0&trunc_cmd=0&filters=%7B%22label%22%3A+%5B%22com.docker.compose.project%3Dbackend-db-test%22%2C+%22com.docker.compose.service%3Ddb%22%2C+%22com.docker.compose.oneoff%3DFalse%22%5D%7D HTTP/1.1"" 200 3
compose.cli.verbose_proxy.proxy_callable: docker containers -> (list with 0 items)
compose.cli.verbose_proxy.proxy_callable: docker containers <- (all=False, filters={'label': ['com.docker.compose.project=backenddbtest', 'com.docker.compose.service=db', 'com.docker.compose.oneoff=False']})
urllib3.connectionpool._make_request: http://localhost:None ""GET /v1.38/containers/json?limit=-1&all=0&size=0&trunc_cmd=0&filters=%7B%22label%22%3A+%5B%22com.docker.compose.project%3Dbackenddbtest%22%2C+%22com.docker.compose.service%3Ddb%22%2C+%22com.docker.compose.oneoff%3DFalse%22%5D%7D HTTP/1.1"" 200 3
Starting db ... failed
compose.parallel.feed_queue: Pending: set()
compose.cli.main.exit_if: No containers to start

```
## Additional information

OS version / distribution, `docker-compose` install method, etc.

OS: Windows 10
Docker: standard installation
CLI: MINGW64 (from the Git for windows installation)

```
$ bash --version
GNU bash, version 4.4.23(1)-release (x86_64-pc-msys)
Copyright (C) 2016 Free Software Foundation, Inc.
License GPLv3+: GNU GPL version 3 or later <http://gnu.org/licenses/gpl.html>

This is free software; you are free to change and redistribute it.
There is NO WARRANTY, to the extent permitted by law.
```
",,,gavinc,"
--
FWIW confirming this from my setup:
OS: Ubuntu 18.04
Docker version 19.03.12, build 48a66213fe
docker-compose version 1.25.5, build 8a1c60f6

A service in my compose.yml was referencing a (currently) offline mount point, would not allow the container to start with the working volume mounts.
Volume commented out, container runs.

--
",angrave,"
--
Confirming this on Windows 10 (Docker version 19.03.12, build 48a66213fe).

It is also possible to reproduce this just with a logging option:
Remove `max-file: 10` and `docker-compose -f .\1.yml --verbose up -d` will complete,otherwise it is locked in feed_queue empty set forever.

```yml
version: ""3.4""

services:
  dbx:
    image: postgres:11.7
    # volumes:
    #   - ""./dbxdata:/var/lib/postgresql/data""

    logging:
         driver: ""json-file""
         options:
           max-file: 10
    environment:
      - POSTGRES_USER=u
      - POSTGRES_PASSWORD=p
    container_name: ""db""
```
--
",chrischu,"
--
I have the same problem as @angrave (same version of Docker).
--

--
I just figured out the problem: The max-file value needs to be a string (max-file: ""10""). Then it works as expected!
--
",darty,"
--
Original issue does not have a max-file option, so it does not help. After 3 months it would be great to receive some feedback.
--
",AmirrezaNasiri,"
--
Any update on this?
The issue still applies to the latest version (Engine: 19.03.13, Compose: 1.27.4) on Windows 10.
--

--
In my case, adding volume sources to ""Resources > File Sharing"" in Docker Desktop settings solved the issue. Interesting that they weren't added automatically, and the logs were quite misleading.

![pending_set_loop](https://user-images.githubusercontent.com/19557224/95001702-5f4f3280-05d9-11eb-87a3-9e8988d36d15.png)
--
",thijskaspers,"
--
Also seeing this issue after updating Docker for Mac to v2.5.0. Containers won't start because they are waiting for another container to start? The other container won't start though, because it depends on the one that starts before it.

After downgrading to v2.4.0 my containers are running fine again.
--
"
7566,OPEN,config and secret variable expansion,kind/feature,2020-06-29 19:09:23 +0000 UTC,aaronovz1,Opened,,"It would be great if the secrets and config sections of a compose file could do variable expansions with golang:

```
version: '3.8'
services:
  myapp:
    image: 127.0.0.1:6666/myapp
    build: ./myapp
    secrets:
      - source: private_key_{{.Task.Slot}}
        target: private_key

secrets:
  private_key_1:
    name: private_key_1
    file: ./keys/private_key_1
  private_key_2:
    name: private_key_2
    file: ./keys/private_key_2
  private_key_3:
    name: private_key_3
    file: ./keys/private_key_3
```

In this scenario, when scaling it would allow a service to pick a secret or config from a pool based on its task ID.
",,,,,,,,,,,,,,
7562,OPEN,Your kernel or machine may not be supported,kind/feature,2021-01-05 11:55:28 +0000 UTC,gvasquez95,In progress,,"Seems like docker-compose does not support the newest [AWS Graviton2](https://aws.amazon.com/about-aws/whats-new/2020/05/amazon-ec2-m6g-instances-powered-by-aws-graviton2-processors-generally-available/?nc1=h_ls) processor as trying to run it on an [r6g.xlarge](https://aws.amazon.com/ec2/instance-types/r6/) AWS [EC2](https://aws.amazon.com/ec2/) instance yields the following message: `Your kernel or machine may not be supported.`

Not sure what else should I provide for this feature request, but support for this new hardware is desired.

cc: @milo-ft",,,gvasquez95,"
--
Failure scenario:

Amazon Linux 2 LTS Arm64 AMI 2.0.20200520.1 arm64 HVM gp2
AMI: ami-02b5d851009884e20
Kernel: 4.14.177-139.254.amzn2.aarch64
Docker-compose: 1.26.0
--
",samip5,"
--
Basically a duplicate of #6831, #7051, #7472 and #7370.

What command yields that error?
--
",moper248,"
--
Hello,

just FYI.

i am able to compile successfully  docker-compose (compose-1.27.4) on `Graviton2 (4.14.209-160.339.amzn2.aarch64 #1 SMP Wed Dec 16 22:44:17 UTC 2020 aarch64 aarch64 aarch64 GNU/Linux)` AWS server. 

```
yum install docker git python3 python3-pip python3-devel gcc libffi-devel  openssl11-devel
service docker start
chkconfig docker on
pip3 install wheel
wget https://github.com/docker/compose/archive/1.27.4.tar.gz  
tar xzvf 1.27.4.tar.gz 
cd compose-1.27.4/
python3 -m pip install -IU docker-compose
```
--
",,,,,,
7558,OPEN,the use of docker in different os,kind/question,2020-12-21 07:49:27 +0000 UTC,alicera,In progress,,"
if I built a docker image in linux
and I want to use the docker image in windows system

how can I do ?",,,stale,"
--
This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you for your contributions.

--

--
This issue has been automatically marked as not stale anymore due to the recent activity.

--
",alicera,"
--
Anyone know?
--
",,,,,,,,
7544,OPEN,RUN sudo passwd alice without key any word,kind/question,2020-12-18 06:28:13 +0000 UTC,alicera,In progress,,"Please post on our forums: https://forums.docker.com for questions about using `docker-compose`.

Posts that are not a bug report or a feature/enhancement request will not be addressed on this issue tracker.

in the dokerfile 
RUN sudo passwd alice

it will happen
""""""
Enter new UNIX password: Retype new UNIX password: passwd: Authentication token manipulation error
passwd: password unchanged
""""""

how can I set the passwd  in the dockerfile
",,,GenaANTG,"
--
You no need to use a **sudo** command in your container. You can set a **USER** directive instead.
--
",alicera,"
--
I want to enter the container for user alice, so I dont have the root.

--

--
solved? 
--
",stale,"
--
This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you for your contributions.

--

--
This issue has been automatically marked as not stale anymore due to the recent activity.

--
",,,,,,
7542,OPEN,docker-compose over SSH returns ChannelException(2; 'Connect failed'),kind/bug,2020-12-11 11:25:16 +0000 UTC,hazcod,In progress,,"## Description of the issue
build over SSH via docker-compose works, but a run always ends with ChannelException(2, 'Connect failed').

## Context information (for bug reports)

**Output of `docker-compose version`**
```
docker-compose version 1.25.5, build 8a1c60f6
(also confirmed with version 1.26.0)
```

**Output of `docker version`**
```
Client: Docker Engine - Community
 Version:           19.03.8
 API version:       1.40
 Go version:        go1.12.17
 Git commit:        afacb8b
 Built:             Wed Mar 11 01:21:11 2020
 OS/Arch:           darwin/amd64
 Experimental:      false

Server: Docker Engine - Community
 Engine:
  Version:          19.03.8
  API version:      1.40 (minimum version 1.12)
  Go version:       go1.12.17
  Git commit:       afacb8b
  Built:            Wed Mar 11 01:29:16 2020
  OS/Arch:          linux/amd64
  Experimental:     false
 containerd:
  Version:          v1.2.13
  GitCommit:        7ad184331fa3e55e52b890ea95e65ba581ae3429
 runc:
  Version:          1.0.0-rc10
  GitCommit:        dc9208a3303feef5b3839f4323d9beb36df0a9dd
 docker-init:
  Version:          0.18.0
  GitCommit:        fec3683

```

## Steps to reproduce the issue

1. set docker context with `docker context create xxx --description ""xxx"" --docker ""host=ssh://root@$SSH_HOST"" --default-stack-orchestrator swarm`
2. `docker context use xxx`
3. `docker-compose build` and `docker-compose up`

### Observed result

### Expected result

### Stacktrace / full error message

```
2020-06-17T15:54:24.3292035Z Step 6/11 : COPY run.sh $APP_DIR/
2020-06-17T15:54:24.3293496Z  ---> Using cache
2020-06-17T15:54:24.3296097Z  ---> e2a57e955e9a
2020-06-17T15:54:24.3299692Z Step 7/11 : RUN $APP_DIR/post-install.sh
2020-06-17T15:54:24.3300660Z  ---> Using cache
2020-06-17T15:54:24.3301578Z  ---> 323d4c7ead3e
2020-06-17T15:54:24.3303848Z Step 8/11 : EXPOSE 8080
2020-06-17T15:54:24.3304499Z  ---> Using cache
2020-06-17T15:54:24.3305583Z  ---> 84d07026c232
2020-06-17T15:54:24.3307580Z Step 9/11 : USER $APP_USER
2020-06-17T15:54:24.3308205Z  ---> Using cache
2020-06-17T15:54:24.3310057Z  ---> 698b453faa79
2020-06-17T15:54:24.3312178Z Step 10/11 : HEALTHCHECK --interval=5s --timeout=3s --retries=3 CMD wget --tries=1 -O - --quiet http://localhost:8080/_status/ || exit 1
2020-06-17T15:54:24.3313128Z  ---> Using cache
2020-06-17T15:54:24.3315406Z  ---> a9688b412bca
2020-06-17T15:54:24.3317664Z Step 11/11 : CMD $APP_DIR/run.sh
2020-06-17T15:54:24.3318490Z  ---> Using cache
2020-06-17T15:54:24.3319843Z  ---> 154ce4a7592b
2020-06-17T15:54:24.3320282Z 
2020-06-17T15:54:24.3321263Z Successfully built 154ce4a7592b
2020-06-17T15:54:24.3388087Z Successfully tagged download:prod
2020-06-17T15:54:24.3395955Z Building web
2020-06-17T15:54:26.7155414Z Step 1/12 : FROM baseimage:prod
2020-06-17T15:54:26.7158395Z  ---> 12dfecf4398f
2020-06-17T15:54:26.7159189Z Step 2/12 : ENV ASSET_DIR ""$APP_DIR/asset""
2020-06-17T15:54:26.7185080Z  ---> Using cache
2020-06-17T15:54:26.7186068Z  ---> a8c25ab21e3d
2020-06-17T15:54:26.7186798Z Step 3/12 : RUN mkdir $ASSET_DIR/
2020-06-17T15:54:26.7187584Z  ---> Using cache
2020-06-17T15:54:26.7188418Z  ---> 662d287b7d57
2020-06-17T15:54:26.7189653Z Step 4/12 : RUN apk add --no-cache nginx 	&& rm -r /etc/nginx/ /var/tmp/nginx /var/log/nginx /var/lib/nginx/
2020-06-17T15:54:26.7193147Z  ---> Using cache
2020-06-17T15:54:26.7194154Z  ---> 033105961aee
2020-06-17T15:54:26.7194886Z Step 5/12 : COPY conf/ $CONF_DIR/
2020-06-17T15:54:26.7205388Z  ---> Using cache
2020-06-17T15:54:26.7206406Z  ---> 1d113c928e68
2020-06-17T15:54:26.7207509Z Step 6/12 : COPY run.sh $APP_DIR/
2020-06-17T15:54:26.7209950Z  ---> Using cache
2020-06-17T15:54:26.7210838Z  ---> 759545f0b148
2020-06-17T15:54:26.7211521Z Step 7/12 : ADD asset/ $ASSET_DIR/
2020-06-17T15:54:26.7324418Z  ---> Using cache
2020-06-17T15:54:26.7327302Z  ---> c45ee937aa65
2020-06-17T15:54:26.7331421Z Step 8/12 : RUN $APP_DIR/post-install.sh
2020-06-17T15:54:26.7334521Z  ---> Using cache
2020-06-17T15:54:26.7337586Z  ---> d9c75eded3e2
2020-06-17T15:54:26.7341203Z Step 9/12 : EXPOSE 8080 8443
2020-06-17T15:54:26.7348029Z  ---> Using cache
2020-06-17T15:54:26.7353156Z  ---> 461a9b85c635
2020-06-17T15:54:26.7358012Z Step 10/12 : USER $APP_USER
2020-06-17T15:54:26.7361133Z  ---> Using cache
2020-06-17T15:54:26.7364199Z  ---> 8d32caac9dd8
2020-06-17T15:54:26.7368323Z Step 11/12 : HEALTHCHECK --interval=5s --timeout=3s --retries=3 CMD wget --quiet --tries=1 --spider --no-check-certificate https://localhost:8443/_status/ || exit 1
2020-06-17T15:54:26.7371604Z  ---> Using cache
2020-06-17T15:54:26.7374678Z  ---> 6a11199270cb
2020-06-17T15:54:26.7378306Z Step 12/12 : CMD $APP_DIR/run.sh
2020-06-17T15:54:26.7381296Z  ---> Using cache
2020-06-17T15:54:26.7384302Z  ---> 2b4da9291b88
2020-06-17T15:54:26.7387004Z 
2020-06-17T15:54:26.7424699Z Successfully built 2b4da9291b88
2020-06-17T15:54:26.7480313Z Successfully tagged web:prod
2020-06-17T15:54:26.7937558Z + docker-compose -p venclave -f compose/network.yml -f compose/db.yml -f compose/php.yml -f compose/web.yml -f compose/download.yml -f compose/mq.yml -f compose/slave.yml -f compose/processor.yml -f compose/stages/prod/prod.yml up -d
2020-06-17T15:54:27.2793496Z Some services (db, download, mq, php, processor, slave, web) use the 'deploy' key, which will be ignored. Compose does not support 'deploy' configuration - use `docker stack deploy` to deploy to a swarm.
2020-06-17T15:54:43.4743772Z Starting download ... 
2020-06-17T15:54:43.4773389Z db is up-to-date
2020-06-17T15:54:43.4779050Z mq is up-to-date
2020-06-17T15:54:43.4804868Z Starting slave    ... 
2020-06-17T15:54:43.6501746Z Secsh channel 41 open FAILED: open failed: Connect failed
2020-06-17T15:54:43.8208622Z 
2020-06-17T15:54:43.8211047Z ERROR: for slave  ChannelException(2, 'Connect failed')
2020-06-17T15:54:43.8211491Z Creating php      ... 
2020-06-17T15:54:45.0129211Z [3A[2K
2020-06-17T15:54:45.0130159Z Starting download ... [32mdone[0m
2020-06-17T15:54:48.9541960Z [3B[1A[2K
2020-06-17T15:54:48.9542806Z Creating php      ... [32mdone[0m
2020-06-17T15:54:49.3842855Z [1BCreating web      ... 
2020-06-17T15:54:55.5721305Z [1A[2K
2020-06-17T15:54:55.5722054Z Creating web      ... [32mdone[0m
2020-06-17T15:54:55.5731642Z [1B[2744] Failed to execute script docker-compose
2020-06-17T15:54:55.5732404Z 
2020-06-17T15:54:55.5733972Z ERROR: for slave  ChannelException(2, 'Connect failed')
2020-06-17T15:54:55.5735415Z Traceback (most recent call last):
2020-06-17T15:54:55.5736234Z   File ""bin/docker-compose"", line 6, in <module>
2020-06-17T15:54:55.5737464Z   File ""compose/cli/main.py"", line 72, in main
2020-06-17T15:54:55.5738150Z   File ""compose/cli/main.py"", line 128, in perform_command
2020-06-17T15:54:55.5738750Z   File ""compose/cli/main.py"", line 1078, in up
2020-06-17T15:54:55.5739339Z   File ""compose/cli/main.py"", line 1074, in up
2020-06-17T15:54:55.5739922Z   File ""compose/project.py"", line 576, in up
2020-06-17T15:54:55.5740507Z   File ""compose/parallel.py"", line 112, in parallel_execute
2020-06-17T15:54:55.5741091Z   File ""compose/parallel.py"", line 210, in producer
2020-06-17T15:54:55.5741685Z   File ""compose/project.py"", line 562, in do
2020-06-17T15:54:55.5742272Z   File ""compose/service.py"", line 569, in execute_convergence_plan
2020-06-17T15:54:55.5742911Z   File ""compose/service.py"", line 511, in _execute_convergence_start
2020-06-17T15:54:55.5743528Z   File ""compose/parallel.py"", line 112, in parallel_execute
2020-06-17T15:54:55.5744134Z   File ""compose/parallel.py"", line 210, in producer
2020-06-17T15:54:55.5744723Z   File ""compose/service.py"", line 509, in <lambda>
2020-06-17T15:54:55.5745949Z   File ""compose/service.py"", line 621, in start_container_if_stopped
2020-06-17T15:54:55.5746636Z   File ""compose/service.py"", line 626, in start_container
2020-06-17T15:54:55.5747247Z   File ""compose/container.py"", line 241, in start
2020-06-17T15:54:55.5748345Z   File ""site-packages/docker/utils/decorators.py"", line 19, in wrapped
2020-06-17T15:54:55.5749402Z   File ""site-packages/docker/api/container.py"", line 1094, in start
2020-06-17T15:54:55.5750452Z   File ""site-packages/docker/utils/decorators.py"", line 46, in inner
2020-06-17T15:54:55.5751327Z   File ""site-packages/docker/api/client.py"", line 226, in _post
2020-06-17T15:54:55.5752494Z   File ""site-packages/requests/sessions.py"", line 581, in post
2020-06-17T15:54:55.5753299Z   File ""site-packages/requests/sessions.py"", line 533, in request
2020-06-17T15:54:55.5754121Z   File ""site-packages/requests/sessions.py"", line 646, in send
2020-06-17T15:54:55.5754935Z   File ""site-packages/requests/adapters.py"", line 449, in send
2020-06-17T15:54:55.5755794Z   File ""site-packages/urllib3/connectionpool.py"", line 677, in urlopen
2020-06-17T15:54:55.5756644Z   File ""site-packages/urllib3/connectionpool.py"", line 392, in _make_request
2020-06-17T15:54:55.5757579Z   File ""http/client.py"", line 1252, in request
2020-06-17T15:54:55.5758209Z   File ""http/client.py"", line 1298, in _send_request
2020-06-17T15:54:55.5758811Z   File ""http/client.py"", line 1247, in endheaders
2020-06-17T15:54:55.5759378Z   File ""http/client.py"", line 1026, in _send_output
2020-06-17T15:54:55.5759958Z   File ""http/client.py"", line 966, in send
2020-06-17T15:54:55.5760795Z   File ""site-packages/docker/transport/sshconn.py"", line 32, in connect
2020-06-17T15:54:55.5761863Z   File ""site-packages/paramiko/transport.py"", line 879, in open_session
2020-06-17T15:54:55.5762775Z   File ""site-packages/paramiko/transport.py"", line 1017, in open_channel
2020-06-17T15:54:55.5763694Z paramiko.ssh_exception.ChannelException: ChannelException(2, 'Connect failed')
2020-06-17T15:54:56.4111034Z + exit 1
2020-06-17T15:54:56.4117740Z ##[error]Process completed with exit code 1.
2020-06-17T15:54:56.4187762Z Post job cleanup.
2020-06-17T15:54:56.5088657Z [command]/usr/bin/git version
2020-06-17T15:54:56.5159219Z git version 2.27.0
2020-06-17T15:54:56.5195091Z [command]/usr/bin/git config --local --name-only --get-regexp core\.sshCommand
2020-06-17T15:54:56.5226595Z [command]/usr/bin/git submodule foreach --recursive git config --local --name-only --get-regexp 'core\.sshCommand' && git config --local --unset-all 'core.sshCommand' || :
2020-06-17T15:54:56.5469079Z [command]/usr/bin/git config --local --name-only --get-regexp http\.https\:\/\/github\.com\/\.extraheader
2020-06-17T15:54:56.5506862Z http.https://github.com/.extraheader
2020-06-17T15:54:56.5507766Z [command]/usr/bin/git config --local --unset-all http.https://github.com/.extraheader
2020-06-17T15:54:56.5544637Z [command]/usr/bin/git submodule foreach --recursive git config --local --name-only --get-regexp 'http\.https\:\/\/github\.com\/\.extraheader' && git config --local --unset-all 'http.https://github.com/.extraheader' || :
2020-06-17T15:54:56.5871180Z Cleaning up orphan processes
```

## Additional information

GitHub Actions -> debian",,,hazcod,"
--
Verbose output attached.
[logs_93.zip](https://github.com/docker/compose/files/4797507/logs_93.zip)

--

--
Possibly related to https://github.com/docker/docker-py/issues/2289
--

--
Temporary workaround:
```
        ssh -i .ssh/id_rsa -nNT -L ""$(pwd)""/docker.sock:/var/run/docker.sock root@$SSH_HOST &
        export DOCKER_HOST=""unix://$(pwd)/docker.sock""
```

Since this works, this appears to be an issue that only occurs with the SSH Python library?
--
",espoirMur,"
--
I had the same issue and google  brought me [here](https://github.com/docker/compose/issues/6463#issuecomment-623746349)
--
",guidorice,"
--
I also ran into lots of ssh channel exceptions when using docker-compose with a `ssh://` host. The unix domain socket workaround by @hazcod was working great for me, but then I ran into a problem with one of my docker-compose volume configs: 

>  invalid mount config for type ""bind"": bind source path does not exist: (local path...)

Curious if anyone has run into that as well and what did you do?
--
",Clindbergh,"
--
> ```
>         ssh -i .ssh/id_rsa -nNT -L ""$(pwd)""/docker.sock:/var/run/docker.sock root@$SSH_HOST &
>         export DOCKER_HOST=""unix://$(pwd)/docker.sock""
> ```
> 

In case you tried this on Windows (where it doesn't seem to help) in git bash and are now receiving `protocol not available` when running a docker command, run `unset DOCKER_HOST` and switch contexts. 

Using @espoirMur's solution worked for me.


--
",MartinJPaterson,"
--
Changing the MaxSessions parameter in /etc/ssh/sshd_config to 30 made this work for me.
--
",pyarun,"
--
Changing MaxSessions to 30 or 50, do not work for me. I am on mac machine!!
--
"
7517,OPEN,"Please add ""docker-compose config --images"" to list the images in the docker-compose.yml file.",kind/feature,2020-06-08 14:23:08 +0000 UTC,JesseChisholm,Opened,,"**Is your feature request related to a problem? Please describe.**
I want to be able to list the images from the docker-comose.yml file.

**Describe the solution you'd like**
I would like to be able to say:
``` docker-compose config --images ```
Similarly to how I can say:
``` docker-compose config --services ```
to get a list of the container by name.

**Describe alternatives you've considered**
I have tested a modification of the docker-compose-backup script
> https://gist.github.com/pirate/265e19a8a768a48cf12834ec87fb0eed
But this only lists images if your containers are running.
I have also tested various bash scripts that scan the file and extract this list. But they are fragile.

**Additional context**
My goal is to be able to include this list in a report.  I do not need to know whether the images are correct or pull-able or in my local cache.",,,,,,,,,,,,,,
7500,OPEN,docker-compose down only partially brings down stack and then stalls,,2020-06-28 19:06:21 +0000 UTC,asampal,In progress,,"After around docker-desktop 2.0.0.3 (Windows) or so, when I try to bring down a stack (with ""docker-compose down"") of 12 services started up with docker-compose, some of the containers stop, but most don't (e.g. out of 12 services only 3 are stopped) . Docker-Desktop seems to be hanging and the only thing I can do is restart it.
I usually start the services defined in docker-compose.yml individually or in smaller groups, with ""docker-compose up -d <service>""

  - [ x ] I have tried with the latest version of my channel (Stable or Edge)
  - [ x ] I have uploaded Diagnostics
  - Diagnostics ID: 5A90F905-5564-495B-BA91-1E55BFD40961/20200603153640

### Expected behavior
Expect complete stack of running services to stop

### Actual behavior
Docker-desktop brings down a few services only then seems to hang

### Information
This problem happens every time I try to bring down a larger number of services defined in my docker-compose.yml. 
The problem started happening after version 2.0.0.3 of Docker-for-Windows/Docker-Desktop.

  - Windows Version: Windows 10 Pro Version	10.0.19041 Build 19041
  - Docker Desktop Version: 2.3.0.3 (45519)
  - Are you running inside a virtualized Windows e.g. on a cloud server or on a mac VM: no

",,,ulyssessouza,"
--
Hello @asampal 
Could you please, provide the output of the following commands:
```
$ docker version
```
```
$ docker-compose version
```
```
$ docker-compose config
```

--
",asampal,"
--
As I mentioned, the complete stack defined in docker-compose.yml is quite big, but the problem manifests itself even with a small subset of services running. I've anonymized the YAML file for inclusion here. I'm using Docker with WSL2 at the moment, but the problem existed even when I was using Hyper-V.

```
$ docker version
Client: Docker Engine - Community
 Version:           19.03.8
 API version:       1.40
 Go version:        go1.12.17
 Git commit:        afacb8b
 Built:             Wed Mar 11 01:23:10 2020
 OS/Arch:           windows/amd64
 Experimental:      false

Server: Docker Engine - Community
 Engine:
  Version:          19.03.8
  API version:      1.40 (minimum version 1.12)
  Go version:       go1.12.17
  Git commit:       afacb8b
  Built:            Wed Mar 11 01:29:16 2020
  OS/Arch:          linux/amd64
  Experimental:     false
 containerd:
  Version:          v1.2.13
  GitCommit:        7ad184331fa3e55e52b890ea95e65ba581ae3429
 runc:
  Version:          1.0.0-rc10
  GitCommit:        dc9208a3303feef5b3839f4323d9beb36df0a9dd
 docker-init:
  Version:          0.18.0
  GitCommit:        fec3683
```

```
docker-compose version 1.25.5, build 8a1c60f6
docker-py version: 4.1.0
CPython version: 3.7.4
OpenSSL version: OpenSSL 1.1.1c  28 May 2019
```

[docker_config_output.txt](https://github.com/docker/compose/files/4748279/docker_config_output.txt)


--

--
I've noticed that the same three services seem to stall and now I'm not sure how to go about determining the cause. For example one for influxdb is defined with the following yaml:

```
  influxdb:
    logging:
      <<: *others-logging
    # Note the latest influxdb (1.3) image is no longer have the admin UI
    # Admin UI is replaced with chronograf on port 8888
    image: ${REPO_PATH}pmt-influxdb:${BUILD_NR}
    restart: ${RESTART_POLICY}
    # dns is necessary for kapacitor subscription service if running under local VM
    dns: 127.0.0.1
    # Ports are exposed for development only
    # ports:
    #   - ""8096:8086""
    expose:
      - ""8086""
    labels:
      - nginx-upstream=influxdb
    environment:
      - ""TZ=America/Toronto""
      - VAULT_URL
      - VAULT_REGION
      - VAULT_TOKEN
      - ""INFLUX_DATABASE=telegraf""
      - ""INLFUX_ADMIN_USER=grafana""
      - ""INFLUX_ADMIN_PASS=grafana""
    volumes:
      # :ro - mounts the directory as a read-only volume
      - influxdb-data:/var/lib/influxdb
      - ${HOST_PATH}/config/influxdb/influxdb.conf:/etc/influxdb/influxdb.conf:ro
      - ${HOST_PATH}/config/influxdb/init-paymentus.iql:/docker-entrypoint-initdb.d/init1-paymentus.iql:ro
      - ${HOST_PATH}/config/influxdb/update-influxdb.iql:/docker-entrypoint-initdb.d/init2-paymentus.iql:ro
```

I can start this with `docker-compose up -d influxdb`, but both `docker-compose down` , `docker-compose stop`, or `docker stop <container>` time out.
--
",,,,,,,,
7495,OPEN,`docker-compose up` fails in WSL 2 environment,kind/bug,2021-02-09 03:47:16 +0000 UTC,blake-mealey,Opened,,"## Description of the issue

Whenever I run `docker-compose up` in my WSL 2 environment, it fails with the error:

```
docker.credentials.errors.InitializationError: docker-credential-desktop.exe not installed or not available in PATH
[519] Failed to execute script docker-compose
```

It's complaining that docker-credential-desktop is not available, however in the same session I can run `docker-credential-desktop -h` and get the help text output.

I am also able to use `docker run` to build and run my container without any problems.

## Context information (for bug reports)

**Output of `docker-compose version`**
```
docker-compose version 1.25.5, build 8a1c60f6
docker-py version: 4.1.0
CPython version: 3.7.5
OpenSSL version: OpenSSL 1.1.0l  10 Sep 2019
```

**Output of `docker version`**
```
Client: Docker Engine - Community
 Version:           19.03.8
 API version:       1.40
 Go version:        go1.12.17
 Git commit:        afacb8b7f0
 Built:             Wed Mar 11 01:25:46 2020
 OS/Arch:           linux/amd64
 Experimental:      false

Server: Docker Engine - Community
 Engine:
  Version:          19.03.8
  API version:      1.40 (minimum version 1.12)
  Go version:       go1.12.17
  Git commit:       afacb8b
  Built:            Wed Mar 11 01:29:16 2020
  OS/Arch:          linux/amd64
  Experimental:     false
 containerd:
  Version:          v1.2.13
  GitCommit:        7ad184331fa3e55e52b890ea95e65ba581ae3429
 runc:
  Version:          1.0.0-rc10
  GitCommit:        dc9208a3303feef5b3839f4323d9beb36df0a9dd
 docker-init:
  Version:          0.18.0
  GitCommit:        fec3683
```

**Output of `docker-compose config`**
(Make sure to add the relevant `-f` and other flags)
```
services:
  happy:
    build:
      context: /home/blake/repos/happy
      dockerfile: Dockerfile
    container_name: happy
    environment:
      CHOKIDAR_USEPOLLING: ""true""
    ports:
    - published: 3001
      target: 3000
    volumes:
    - /home/blake/repos/happy:/app:rw
    - /app/node_modules
version: '3.7'
```

## Steps to reproduce the issue

1. Create a WSL 2 environment (I'm running Ubuntu 20.04)
2. Install Docker Desktop
3. Create a Dockerfile and attempt to run `docker-compose up` on it

### Observed result

The above error message

### Expected result

The container is built and run

### Stacktrace / full error message

```
Traceback (most recent call last):
  File ""bin/docker-compose"", line 6, in <module>
  File ""compose/cli/main.py"", line 72, in main
  File ""compose/cli/main.py"", line 128, in perform_command
  File ""compose/cli/main.py"", line 1077, in up
  File ""compose/cli/main.py"", line 1073, in up
  File ""compose/project.py"", line 548, in up
  File ""compose/service.py"", line 367, in ensure_image_exists
  File ""compose/service.py"", line 1106, in build
  File ""site-packages/docker/api/build.py"", line 261, in build
  File ""site-packages/docker/api/build.py"", line 308, in _set_auth_headers
  File ""site-packages/docker/auth.py"", line 301, in get_all_credentials
  File ""site-packages/docker/auth.py"", line 287, in _get_store_instance
  File ""site-packages/docker/credentials/store.py"", line 25, in __init__
docker.credentials.errors.InitializationError: docker-credential-desktop.exe not installed or not available in PATH
[519] Failed to execute script docker-compose
```

## Additional information

OS version: Windows 10 version 2004 build 19041.264
WSL 2 distro: Ubuntu 20.04

The way I got my setup was:

* Installed WSL 2 with latest Windows update
* Installed Docker Desktop and enabled the WSL features",,,blake,"
--
Update: something I didn't mention above was that I moved my WSL instance to my D drive (because my C drive is pretty full). I thought maybe that could cause problems so I just tried a fresh Ubuntu 20.04 install on the C drive and it seems to be working fine there. This is a temporary workaround which is fine for now but I would like the issue to be fixed still. Thanks :)
--
",akhdanbuchou,"
--
i have the same issue in Ubuntu 18.04, tried to reinstall both docker and the Ubuntu but still getting the same error. 
--
",Ahmed,"
--
same issue here, Im trying to run  docker-compose up for this project. 
https://github.com/big-data-europe/docker-hadoop
--

--
looks like they had same issue with mac.
https://github.com/docker/for-mac/issues/3785
I just added _  before credsStore in this file ( ~/.docker/config.json )   {""_credsStore"":""desktop.exe""}
I don't know what does that config do but I'm not getting the error anymore.
--
",gaddman,"
--
Removing the file worked for me:
`rm ~/.docker/config.json`
--
",SewonYun,"
--
I did this, and effect me
1. rm ~/.docker/config.json
2. docker execute command with sudo prefix : sudo docker-compose   -d --build####your option
--
",liuwenzhuang,"
--
In my WSL2 Debian, I disable windows path, so I add docker-credential-desktop.exe path to `~/.bashrc`:

```bash
DockerResourcesBin=""/mnt/c/Program Files/Docker/Docker/resources/bin""
export PATH=$PATH:$DockerResourcesBin
```

and after run `source ~/.bashrc`, my `docker-compose` work well.
--
"
7494,OPEN,Add plugin system,kind/feature,2020-06-02 15:01:41 +0000 UTC,54sledgehammer45,Opened,,"-->

**Is your feature request related to a problem? Please describe.**

I'm trying to use docker-compose in a dev environment with projects that depend on one another e.g Parent depends on Child which in turn depends on LeftBaby and RightBaby. Each project has their own `docker-compose.yml`s, but the parents have to either copy parts or even the entirety of the children into their own compose files and adapt them.

Obviously when a child `docker-compose.yml` changes, the parents have to be modified again. This is pretty unsustainable and without an ability to modify docker-compose easily, either the whole project has to be forked and maintained separately or a tool has to be written around docker-compose to support this scenario.

**Describe the solution you'd like**

A plugin system that allows developing plugins, which can hook into the lifecycle of docker-compose or add commands themselves, and can finally be registered/discovered by docker-compose.

**Describe alternatives you've considered**

- Fork docker-compose, modify to handle the specific scenario
- Create pull request with resolution to above issue that modifies docker-compose directly
- Script that generates `docker-compose.yml` per project

**Additional context**

None at the moment, but feel free to request more information
",,,,,,,,,,,,,,
7493,OPEN,Allow using wildcards in Docker-Compose network > aliases,kind/feature,2021-02-11 14:59:22 +0000 UTC,KevinGhadyani-minted,Opened,,"-->

**Is your feature request related to a problem? Please describe.**
When setting up a Proxy service in Docker-Compose, I need to always define hostnames both in my hosts file and in `networks > [NETWORK_NAME] > aliases`.

For instance:
- `frontend.myapp.localhost`
- `api.myapp.localhost`

I would like both domains to point at the proxy at whichever port I defined. This way, I can have multiple services running on the same port.

If my host machine targets `frontend.myapp.localhost` or `api.myapp.localhost`, because I have those domains setup in my hosts file, everything works fine.

The problem occurs when everything is behind the proxy. For instance, I'm doing server-side rendering and `frontend.myapp.localhost` now tries to call out to `api.myapp.localhost` before sending me some HTML. All of a sudden, I need to be using the docker-compose container name of `api` instead.

The way I fix this is by assigning aliases on the docker-compose `proxy` app network:
```yml
services:
  proxy:
    networks:
      proxy:
        aliases:
          - api.myapp.localhost
          - frontend.myapp.localhost
```

**Describe the solution you'd like**
1. It'd be a lot easier for me to do `*.myapp.localhost` instead of having to define each and every one.
2. If my proxy application could look into the directories of other apps, pull in their proxy configs, and create an alias file for docker-compose which generates the `aliases` property.

Either solution fits my needs, but #1 is far easier to implement. A combination of the two would be ideal because then anyone could use this proxy image and only need to ensure they're passing in a list of directories to check for configs.

**Describe alternatives you've considered**
Right now, I'm manually putting in every alias, but because my proxy app needs to be an independent repository, I have to manually add every possible alias by hand. In my case, that's 70+ applications to manage. If they change their URL, that's time I have to spend updating these local aliases.

Good luck to any dev that has to bisect older code in a different repo. It won't work if they changed the URL alias passed into the proxy.",,,,,,,,,,,,,,
7489,OPEN,[compose-in-a-container] Setup volume mounts based on -f; --file argument for compose in a container.,kind/feature,2020-07-16 07:04:24 +0000 UTC,EricsonMacedo,Opened,,"-->

When running docker-compose through compose in a container values given to -f, --file argument aren't evaluated, as such, sharing volumes in this situation doesn't work.

Evaluate values given to -f, --file argument when running compose in a container and setup volume mounts in order to make sharing volumes to work as expected in this situation.",,,FlyingOnion,"
--
I'm having similar question when I use drone (docker runner) to build CI/CD pipelines. How do I update the cluster (not a real one but I know no more other words) using compose in a container?
--
",,,,,,,,,,
7482,OPEN,up -d command halts / freezes for long running applications,kind/bug,2020-11-23 20:52:06 +0000 UTC,Samuel-Campbell,Opened,,"## Description of the issue
`up service_name` will make the service run, as well as it's dependencies, however the dependencies will freeze after running `N` line of codes. In my case it was always the exact same number of loops that resulted in the halting.

--

Running `up` without the service_name runs fine however.

## Context information (for bug reports)

**Output of `docker-compose version`**
```
docker-compose version 1.25.5, build 8a1c60f6
```

**Output of `docker version`**
```
Docker version 19.03.8, build afacb8b
```

## Steps to reproduce the issue
Example python code
```
counter = 1
while True:
   print(counter)
   counter += 1
```

Run this script as a dependency to another service and use `docker logs -f dependent_service` to monitor the output. It will eventually just stop on it's own (after a few seconds). This has been tested on Linux, Windows, and Mac, as well as several Ubuntu VMs
",,,stale,"
--
This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you for your contributions.

--

--
This issue has been automatically marked as not stale anymore due to the recent activity.

--
",Samuel,"
--
bump
--
",,,,,,,,
7481,OPEN,docker-run + --use-aliases behaviour,kind/feature,2020-05-26 13:31:04 +0000 UTC,jonathanclarke,Opened,,"**Is your feature request related to a problem? Please describe.**
Given I have defined aliases under a network in docker-compose.yml and I run the command
`docker-compose -f docker-compose.yml run --rm webapp /bin/sh -e -c /bin/bash`
Then I would expect that the network aliases defined in docker-compose.yml be honored as requested and the --use-aliases flag would default to true.  

**Describe the solution you'd like**
--use-aliases flag should default to true.  docker-compose run + docker-compose up should exhibit the same behaviour, including network specified settings. 

**Describe alternatives you've considered**
A clear and concise description of any alternative solutions or features you've considered.

**Additional context**
Additional containers are required to know alias hostnames + ips that are set using the alias function.  
",,,,,,,,,,,,,,
7474,OPEN,append additional hostname alias to existing container,kind/feature,2020-05-20 19:51:31 +0000 UTC,Zodzie,Opened,,"**Is your feature request related to a problem? Please describe.**
Problem - need to append additional hostname to multiple-repo/project/environment shared proxy to support container-to-container traffic. 

Example: 
    local project 1 (local_project1_webserver_1 container + local_project1_php_1 container)
    local project 2 (local_project2_webserver_1 container + local_project2_php_1 container)
    haproxy container (shared for both)

when local_project1_php_1 needs to hit local_project2_webserver_1 using php curl to https://domain.local/graphql , needs to terminate at haproxy. But local_project1_php_1 does not know where haproxy lives.

**Describe the solution you'd like**

I would like to be able to append or add additional host alias sequentially using `docker network connect --alias` instead of all alias at once.

**Describe alternatives you've considered**

Alternative solutions would be to modify /etc/hosts to point to shared haproxy

Also, could do this one-time with all aliases included:
`docker network disconnect` + `docker network connect --alias` 
However, sometimes we need to add additional alias which will not get rid of previous-set alias. 
Can not set them all at once for project cross pollination reasons!

",,,,,,,,,,,,,,
7472,OPEN,Please support ARM64 binary downloads,kind/bug,2021-02-17 03:25:00 +0000 UTC,CorruptComputer,In progress,,"
## Description of the issue
Docker Compose fails to run with the following error: 
```
user@hostname:~$ sudo curl -L ""https://github.com/docker/compose/releases/download/1.25.5/docker-compose-$(uname -s)-$(uname -m)"" -o /usr/local/bin/docker-compose
  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                 Dload  Upload   Total   Spent    Left  Speed
100     9  100     9    0     0     38      0 --:--:-- --:--:-- --:--:--    38
user@hostname:~$ sudo chmod +x /usr/local/bin/docker-compose
user@hostname:~$ docker-compose
/usr/local/bin/docker-compose: line 1: Not: command not found
```

## Context information (for bug reports)

**Output of `docker-compose version`**
```
Unable to run docker-compose
```

**Output of `docker version`**
```
user@hostname:~$ docker version
Client: Docker Engine - Community
 Version:           19.03.9
 API version:       1.40
 Go version:        go1.13.10
 Git commit:        9d98839
 Built:             Fri May 15 00:25:48 2020
 OS/Arch:           linux/arm64
 Experimental:      false
Got permission denied while trying to connect to the Docker daemon socket at unix:///var/run/docker.sock: Get http://%2Fvar%2Frun%2Fdocker.sock/v1.40/version: dial unix /var/run/docker.sock: connect: permission denied
```

**Output of `docker-compose config`**
(Make sure to add the relevant `-f` and other flags)
```
Unable to run docker-compose
```

## Steps to reproduce the issue

1. Install docker-compose using Linux instructions from docs: https://docs.docker.com/compose/install/
2. Try to run it
3. CRASH

### Observed result
The software crashes when trying to run it.

### Expected result
The software would run successfully.

### Stacktrace / full error message

```
/usr/local/bin/docker-compose: line 1: Not: command not found
```

## Additional information
Running OS: Ubuntu Server 20.04 LTS
",,,CorruptComputer,"
--
Also before someone says ""it says the command isn't found, you need to download and install the binary"" that error is from RUNNING the file.  This is the output if the file doesn't exist:
```
user@hostname:~$ sudo rm /usr/local/bin/docker-compose 
user@hostname:~$ docker-compose

Command 'docker-compose' not found, but can be installed with:

sudo apt install docker-compose
```
--

--
I KNEW someone would say that, which is why I made the above comment. It is finding the downloaded file, **the error is with running it, not with not finding it**. Please read what I previously said.
--

--
Ah, that does seem to be the same issue. Let me try the steps in the answer to see if that fixes it.

Thanks!
--

--
The OS is Ubuntu Server 20.04 and architecture is ARM64.

EDIT: Actually after running `uname -m` it comes out as `aarch64`. Which is the same as ARM64, just the linux-y way of saying it.
--

--
Changed the name, thanks! I had no idea it wasn't supported since there wasn't a note for compatibility on the documentation. 
--

--
@MaximeAubanel I did not, I ended up giving up on Docker and just installing the applications I was trying to run manually. Hopefully they support this someday, but for now its just not possible for me. Since one of the apps I use specifically says not to use the pip package for docker-compose, as it does not work.
--
",syntapy,"
--
This is not a bug in docker-compose

Check your `PATH` variable and make sure `/usr/local/bin` is in there

`sudo echo $PATH`

If not, add it to /root/.bashrc or something

Also I've always had to use `sudo docker-compose` which probably makes sense if you need sudo permissions to access docker itself
--

--
Hahaha! My bad

Yeah I misread that 

Right, it says `line 1: Not: Command not found` so its happening in the code

What OS and architecture are you on? On my machine it works on a fresh debian VM without docker. 

EDIT: 
Its not [this issue](https://stackoverflow.com/questions/58747879/docker-compose-usr-local-bin-docker-compose-line-1-not-command-not-found), since its actually downloading on your machine it seems...I wonder if docker-compose requires any external libraries that might be missing on your machine
--

--
Yeah, unfortunately doesnt seem like they post binaries for arm.

I have no idea how hard it would be to compile for source, but seems like they do [support at least arm32](https://github.com/ubiquiti/docker-compose-aarch64), although someone [had trouble](https://github.com/docker/compose/issues/6879) doing so

I did find [this](https://github.com/ubiquiti/docker-compose-aarch64). Its kind of old though

Also, may I suggest you change the title to ""Please support ARM64 binary downloads"" or something?
--
",el,"
--
Same issue, I am trying to install it on my Raspberry Pi - *_3 - Raspbian OS_

Edit 2: Managed to bypass it using https://github.com/AppTower/docker-compose

Got it from the discussion here: https://github.com/docker/compose/issues/6831#issuecomment-568815378 
--
",sshmaxime,"
--
Hey guys, same issue here. If you want to make sure it's the same issue just run `cat /usr/local/bin/docker-compose` you must see ""Not Found"".

@CorruptComputer Did you solve this issue ?
--

--
@CorruptComputer I made it works installing it with apt-get:

`sudo apt-get install docker-compose`
--
",chenxushuo,"
--
I installed docker-compose on centos7-arm64,
CMD
```
sudo yum install -y libffi libffi-devel openssl-devel python3 python3-pip python3-devel
sudo pip3 install docker-compose
``` 
If have some error,run it twice!
--
",justincormack,"
--
Hi, yes we currently recommend the pip install method for Arm64. I will see if we can get arm64 binaries built as well.
--
"
7463,OPEN,Completion in a separate repo,kind/feature,2020-05-17 08:54:53 +0000 UTC,ikhomutov,Opened,,"Right now, the installation process for completion is inconvenient. For zsh you can either use oh-my-zsh which has it's own completion file without recent updates, or manually download completion script but in this case you'll have to repeat this process from time to time to get the latest update.

If the completion was in a separate repository, it'd be possible to use it with zsh frameworks like antigen and it'd possible to include this repo as a submodule into personal dotfiles repo. Consider [zsh-completion](https://github.com/zsh-users/zsh-completions) as an example of the final result.",,,,,,,,,,,,,,
7460,OPEN,DOCKER_CONTEXT on `.env` file,kind/feature,2020-07-24 22:49:25 +0000 UTC,kosssi,In progress,,"I would like use `DOCKER_CONTEXT` variable on `.env` file, until now I use `DOCKER_HOST` but it's more verbose. And I don't see on documentation why is not supported.

### Before

.env:
```
DOCKER_HOST=ssh://kosssi@blue:42
COMPOSE_FILE=../../../services/traefik/docker-compose.yml
TRAEFIK_IMAGE=traefik:v2.2.1
```

### After

.env:
```
DOCKER_CONTEXT=blue
COMPOSE_FILE=../../../services/traefik/docker-compose.yml
TRAEFIK_IMAGE=traefik:v2.2.1
```

What do you think ?

```
$ docker --version
Docker version 19.03.8, build afacb8b7f0
$ docker-compose --version
docker-compose version 1.25.5, build 8a1c60f6",,,hholst80,"
--
Docker compose only started to support docker contexts in 1.26 rc4.
--

--
That makes sense to me. 
--
",kosssi,"
--
Thanks for your response

https://github.com/docker/compose/releases/tag/1.26.0-rc4
--

--
I reopen this issue because on 1.26.0 release it's only `--context` argument, I think it's cool to use also DOCKER_CONTEXT directly on `.env` file.

@hholst80 what do you think ?
--
",adampl,"
--
@kosssi I agree, though it's not limited to the `.env` file only.
--
",,,,,,
7454,OPEN,Conflict. The container name is already in use by container - running on host vs inside container,kind/bug,2020-10-26 12:37:09 +0000 UTC,fsproru,Opened,,"3. When making a bug report, make sure you provide all required information. The easier it is for
   maintainers to reproduce, the faster it'll be fixed.
-->

## Description of the issue
Running docker-compose up on the host or inside a docker container causes a name mismatch.

## Context information (for bug reports)

**Output of `docker-compose version`**
```
docker-compose version 1.25.5, build 8a1c60f6
docker-py version: 4.1.0
CPython version: 3.7.5
OpenSSL version: OpenSSL 1.1.1f  31 Mar 2020
```

**Output of `docker version`**
```
Client: Docker Engine - Community
 Version:           19.03.8
 API version:       1.40
 Go version:        go1.12.17
 Git commit:        afacb8b
 Built:             Wed Mar 11 01:21:11 2020
 OS/Arch:           darwin/amd64
 Experimental:      false

Server: Docker Engine - Community
 Engine:
  Version:          19.03.8
  API version:      1.40 (minimum version 1.12)
  Go version:       go1.12.17
  Git commit:       afacb8b
  Built:            Wed Mar 11 01:29:16 2020
  OS/Arch:          linux/amd64
  Experimental:     false
 containerd:
  Version:          v1.2.13
  GitCommit:        7ad184331fa3e55e52b890ea95e65ba581ae3429
 runc:
  Version:          1.0.0-rc10
  GitCommit:        dc9208a3303feef5b3839f4323d9beb36df0a9dd
 docker-init:
  Version:          0.18.0
  GitCommit:        fec3683
```

**Output of `docker-compose config`**
(Make sure to add the relevant `-f` and other flags)
```
services:
  redis:
    container_name: my-redis
    image: redis:alpine3.11
version: '3.0'
```


## Steps to reproduce the issue

1. Up the Redis service from a container mounting the host socket

```
$ docker run -it --rm -v /var/run/docker.sock:/var/run/docker.sock -v /path/to/test:/project-root --workdir=/project-root docker/compose:alpine-1.26.0-rc4  --file '/project-root/docker-compose.yml' up -d redis
Starting my-redis ... done
```

2. Up the Redis service from the host

```
$ cd /path/to/test; docker-compose  --file '/path/to/test/docker-compose.yml' up -d redis

ERROR: for my-redis  Cannot create container for service redis: Conflict. The container name ""/my-redis"" is already in use by container ""***"". You have to remove (or rename) that container to be able to reuse that name.
```

### Observed result

Docker Compose fails with the error on the host system:

```
ERROR: for my-redis  Cannot create container for service redis: Conflict. The container name ""/my-redis"" is already in use by container ""***"". You have to remove (or rename) that container to be able to reuse that name.
```

### Expected result
Since `/var/run/docker.sock` is mounted inside the docker container from step 1, I expected docker-compose to say that `my-redis` container is already started.

### Stacktrace / full error message

```
ERROR: for my-redis  Cannot create container for service redis: Conflict. The container name ""/my-redis"" is already in use by container ""***"". You have to remove (or rename) that container to be able to reuse that name.
```

## Additional information

OS version / distribution, `docker-compose` install method, etc.

Host: macOS Catalina
docker-compose is installed using [Homebrew](https://brew.sh/)
",,,adrianlubitz,"
--
Any insights by now?
Having a similar issue where I start some containers with docker-compose from the host system.
I have another container(`from docker/compose`), that does some backups and runs `docker-compose pull && docker-compose up -d` to spawn the newest version after the backup.
I get 

```
ERROR: for <CONTAINERNAME>  Cannot create container for service <CONTAINERNAME>: Conflict. The container name ""/<CONTAINERNAME>"" is already in use by container ""9d739a5422ebd99357efd8a67b998ea626befbf025e25dc73752f14477eaad06"". You have to remove (or rename) that container to be able to reuse that name.
```
--
",,,,,,,,,,
7450,OPEN,"At case command set ""/bin/bash -c"" in docker-compose.yml; container stops instantaneously in spite of tty: true.",kind/bug,2020-11-08 09:24:53 +0000 UTC,agrexgh,In progress,,"3. When making a bug report, make sure you provide all required information. The easier it is for
   maintainers to reproduce, the faster it'll be fixed.
-->

## Description of the issue

`docker-compose.yml` is below.

```yaml:docker-compose.yml
services:
  service1:
    command: /bin/bash -c ""some commands""
    container_name: xxxxx
    image: yyyyy
    tty: true
```

And type this.

```Console
docker-compose run --rm servise1
```

Because  `tty` is `true`, 
I expected **container waits inputs** after commands were executed,
but actually **container stops instantaneously** after commands were executed.

I'd like to know why this behavior occurs.
Is this behavior according to specifications?
If so, what docs tell that?
If not, is this bug?

### NOTE:
I have already known this solution,
which is changing `some commands` to `some commands && /bin/bash`.
But this causes 2 `bash` process runnning on container.
I think this is odd. I'd like to run only 1 process.

## Context information (for bug reports)

**Output of `docker-compose version`**

```Console
docker-compose version 1.17.1, build unknown
```

**Output of `docker version`**

```Console
Docker version 19.03.8, build afacb8b7f0
```

**Output of `docker-compose config`**
Please refer to ""Description of the issue"".


## Steps to reproduce the issue

1.describe following 2 option at `service1` in `docker-compose.yml`.

```yaml
command: /bin/bash -c ""some commands""
```

```yaml
tty: true
```

2.execute `docker-compose run --rm service1`

### Observed result

**Container stops instantaneously** after commands were executed.

### Expected result

**Container waits inputs** after commands were executed.


### Stacktrace / full error message

Not available.

## Additional information

OS: Ubuntu 18.04
How to install `docker-compose`: `sudo apt install docker-compose`
",,,stale,"
--
This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you for your contributions.

--

--
This issue has been automatically marked as not stale anymore due to the recent activity.

--
",agrexgh,"
--
Could somebody answer me?
--
",,,,,,,,
7444,OPEN,`up` does not re-use anonymous volume even without `--renew-anon-volumes` given,kind/bug,2020-11-18 23:11:24 +0000 UTC,FallenWarrior2k,In progress,,"3. When making a bug report, make sure you provide all required information. The easier it is for
   maintainers to reproduce, the faster it'll be fixed.
-->

## Description of the issue
Using an anonymous volume like `volumes: [ '/data' ]` in docker-compose.yml will result in any data written to that directory and its descendants not being visible after a `docker-compose down` followed by another `docker-compose up`.

## Context information (for bug reports)

**Output of `docker-compose version`**
```
 docker-compose version
docker-compose version 1.25.5, build unknown
docker-py version: 4.2.0
CPython version: 3.8.2
OpenSSL version: OpenSSL 1.1.1g  21 Apr 2020
```

**Output of `docker version`**
```
 docker version
Client:
 Version:           19.03.8-ce
 API version:       1.40
 Go version:        go1.14.1
 Git commit:        afacb8b7f0
 Built:             Thu Apr  2 00:04:36 2020
 OS/Arch:           linux/amd64
 Experimental:      false

Server:
 Engine:
  Version:          19.03.8-ce
  API version:      1.40 (minimum version 1.12)
  Go version:       go1.14.1
  Git commit:       afacb8b7f0
  Built:            Thu Apr  2 00:04:16 2020
  OS/Arch:          linux/amd64
  Experimental:     false
 containerd:
  Version:          v1.3.4.m
  GitCommit:        d76c121f76a5fc8a462dc64594aea72fe18e1178.m
 runc:
  Version:          1.0.0-rc10
  GitCommit:        dc9208a3303feef5b3839f4323d9beb36df0a9dd
 docker-init:
  Version:          0.18.0
  GitCommit:        fec3683
```

**Output of `docker-compose config`**
(Make sure to add the relevant `-f` and other flags)
```
 docker-compose config
services:
  test:
    command: sh -c 'while true; do sleep 60; done'
    image: alpine
    restart: always
    volumes:
    - /data
version: '3.0'
```


## Steps to reproduce the issue

1. Go to the directory with the sample `docker-compose.yml` above.
2. `docker-compose up -d`
3. `docker-compose exec test sh -c 'echo ""hello there"" > /data/test.txt'`
4. `docker-compose down`
5. Verify the file still exists with `find /var/lib/docker/volumes -type f -name 'test.txt'` (or optionally view its contents with `find /var/lib/docker/volumes/ -type f -name 'test.txt' -exec cat {} \;`)
6. `docker-compose up -d`
7. `docker-compose exec test ls /data`

### Observed result
The `ls` command prints nothing.

### Expected result
The `ls` command should have shown one file named `test.txt`

## Additional information
OS: Arch Linux
Both Docker and Compose installed from official repos via pacman.

Also tested (and initially noticed) on both Ubuntu 16.04 and 18.04 with Docker installed from repos, but a significantly older Compose:
```
docker-compose version 1.18.0, build 8dd22a9
docker-py version: 2.6.1
CPython version: 2.7.13
OpenSSL version: OpenSSL 1.0.1t  3 May 2016
```
",,,hholst80,"
--
Try doing a `docker-compose stop` instead of `docker-compose down`. Does that work?
--
",FallenWarrior2k,"
--
I don't have my machine right now, but I'm assuming that would work, as the containers are never removed, so the volumes stay attached.

If this is intended for `down`/`up`, however, I believe I'm misunderstanding the explanation for `--renew-anon-volumes`. The way it talks ""previous containers"" implies, to me, that not passing it will cause anonymous volumes from previously deleted containers to be re-used, which is not the case here.
--
",lognaturel,"
--
@hholst80 Yes, using `docker-compose stop`, anonymous volumes are reused on `up`. From the documentation, I would expect the same to be true for `docker-compose down`.

From https://docs.docker.com/compose/reference/down/:

> By default, the only things removed are:
> * Containers for services defined in the Compose file
> * Networks defined in the networks section of the Compose file
> * The default network, if one is used

~If it is intentional that anonymous volumes are detached on `down`, could that please be explicit in the documentation? I do agree with @FallenWarrior2k's assessment that this feels like a bug, though.~ Is it that because `down` removes containers, there's nowhere to keep the anonymous volume bindings? I think that does make sense but I still think a note would be helpful.
--

--
I've come across this looking at how to upgrade deployments and had the nasty surprise of finding out anonymous volume bindings are lost after a `down`. I've found the discussion starting at https://github.com/moby/moby/issues/30647#issuecomment-276882545 helpful.

And specifically: ""When not naming your volume you generally mean: I don't ""care"" about its data, it's ok to remove after the container is removed.""

Here is my proposed documentation change: https://github.com/docker/docker.github.io/pull/11601
--

--
I think this issue can be closed. https://docs.docker.com/compose/reference/down/ now says:

> Anonymous volumes are not removed by default. However, as they dont have a stable name, they will not be automatically mounted by a subsequent up. For data that needs to persist between updates, use host or named volumes.

I have posted a related [Stackoverflow question](https://stackoverflow.com/questions/64885337/how-can-a-docker-compose-configuration-transition-from-using-anonymous-volumes-t) about how to migrate a docker-compose configuration that uses anonymous volumes to using named volumes without (perceived) data loss.
--
",,,,,,
7443,OPEN,Support of Kompose to be able to deploy to virtually any orchestration engine,kind/feature,2020-05-11 09:19:55 +0000 UTC,PavelSosin-320,Opened,,"-->

**Is your feature request related to a problem? Please describe.**
A clear and concise description of what the problem is. Ex. I'm always frustrated when [...]
Docker-compose is able to deploy application only to Docker-swarm. It's hard to find today Clusters managed by swarm in the enterprise or Global cloud environment. There is Kubernetes kompose utility which converts docker-compose file into Kubernetes resource file and deploys docker-compose stack either to Kubernetes or OpenShift. It takes 5 minutes to install kompose for Windows and Linux.  
**Describe the solution you'd like**
Select the target engine as project properties or user's preference and deploy application stack to the desired engine with service publishing by one or two clicks.
A clear and concise description of what you want to happen.
1. Select the target engine in user or project preferences.
2. Create volumes ...
3. Create placeholders for secrets 
4. Deploy to the engine using a suitable deployment mechanism in one click
**Describe alternatives you've considered**
Everything can be done using bash script after learning to compose and resource file formats,i.e 1  months efforts.
A clear and concise description of any alternative solutions or features you've considered.

**Additional context**
Add any other context or screenshots about the feature request here.
Very little additional code if the proper **design pattern provider** is used
Deployment mechanism for dockerized applications evolved from Swarm to OpenShist, i.e. highly compatible ",,,,,,,,,,,,,,
7439,OPEN,Add --compress option to docker-compose up,kind/feature,2020-05-10 17:09:06 +0000 UTC,csbenjamin,Opened,,I know that `docker-compose build` already has the `--compress` option. But I would like to request that option to `docker-compose up` too. Right now I have to issue two commands: `docker-compose build --compress` and then `docker-compose up` instead a single command like `docker-compose up --build --compress`.,,,,,,,,,,,,,,
7437,OPEN,Option on `docker-compose up` to do a pull even if it already exists,kind/feature,2020-08-20 02:54:23 +0000 UTC,jamshid,Opened,,"**Is your feature request related to a problem? Please describe.**
I know I can do it in separate commands:
`docker-compose pull svc1 svc2 && docker-compose up -d --no-deps svc1 svc2`
but it would be very convenient and feels right for it to be available as an option on `up`. 
If not, I'd almost rather `up` not pull images at all, always require the pull step. (though yeah, matches `docker run`)

All the arguments in https://github.com/docker/compose/issues/3574 like consistency with `docker build --pull` probably still apply. 
Looks like the related https://github.com/docker/cli/pull/1498 will be available in docker v20.x.

**Describe the solution you'd like**
The `--pull` option on `up` e.g. `docker-compose up --pull -d --no-deps svc1 svc2` should attempt to pull and update the images even if they already exist. It should fail with a helpful message if the image registry is not accessible.

The `restart` command should probably also support `--pull`, if that's command is moving forward.

**Describe alternatives you've considered**
In fairness I can see the counter argument that ""pull"" should be a separate step from ""up"", to force admins to be aware of it, to avoid unnecessary failure due to a registry server being down.",,,hholst80,"
--
The rationale why build offers a --pull option is that is not possible to solve it in another way within the tool. It also matches docker build --pull... 
--
",dozer75,"
--
As the mentioned #3574 states, there is also a a view where it should be configurable in the docker-compose file. I think that it is a better solution since it may be that some images are more frequent do pull than others. E.g. I have a docker compose that consists of three services, but I only need to pull one of the images all the time, the others can live as they are.
--
",codefromthecrypt,"
--
this would be fixed by #7213 I think. If a pull option is unacceptable, possibly all the various issues asking for it should be closed as a dupe and say won't fix? It is hard for someone to navigate current status which I believe is wontfix

Possibly as this is such a popular missing feature, it could warrant a FAQ or RATIONALE in the source base to summarize why it is never going to be allowed (presumably due to hoping for a better solution one year)
--
",,,,,,
7436,OPEN,Source secret file needs world readable permission,kind/bug,2021-01-15 15:01:14 +0000 UTC,raratiru,Opened,,"3. When making a bug report, make sure you provide all required information. The easier it is for
   maintainers to reproduce, the faster it'll be fixed.
-->

## Description of the issue

When using [secrets in compose](https://docs.docker.com/engine/swarm/secrets/#use-secrets-in-compose), the secret file `/var/secrets/secret_file` (in the container) is not accessible unless the source file (in the host) is world readable.

This stands true even if the user in the container has the same `UID` or `GID` with the `user:group` assigned to the `secret_file` (which is `nobody:nogroup`).

## Context information (for bug reports)

**Output of `docker-compose version`**
```bash
docker-compose version 1.25.5, build 8a1c60f6
docker-py version: 4.1.0
CPython version: 3.7.5
OpenSSL version: OpenSSL 1.1.0l  10 Sep 2019

```

**Output of `docker version`**
```bash
Client: Docker Engine - Community
 Version:           19.03.8
 API version:       1.40
 Go version:        go1.12.17
 Git commit:        afacb8b7f0
 Built:             Wed Mar 11 01:25:56 2020
 OS/Arch:           linux/amd64
 Experimental:      false

Server: Docker Engine - Community
 Engine:
  Version:          19.03.8
  API version:      1.40 (minimum version 1.12)
  Go version:       go1.12.17
  Git commit:       afacb8b7f0
  Built:            Wed Mar 11 01:24:28 2020
  OS/Arch:          linux/amd64
  Experimental:     false
 containerd:
  Version:          1.2.13
  GitCommit:        7ad184331fa3e55e52b890ea95e65ba581ae3429
 runc:
  Version:          1.0.0-rc10
  GitCommit:        dc9208a3303feef5b3839f4323d9beb36df0a9dd
 docker-init:
  Version:          0.18.0
  GitCommit:        fec3683

```

**Output of `docker-compose config`**
(Make sure to add the relevant `-f` and other flags)
```yaml
secrets:
  pass:
    file: /home/flyer/bug/pass.txt
services:
  test:
    build:
      context: /home/flyer/bug
    command: 'bash -c ""ls -la /run/secrets && id && cat /run/secrets/pass""'
    container_name: test
    environment:
      PASSWORD_FILE: /run/secrets/pass
    secrets:
    - source: pass
version: '3.7'

```
**Dockerfile**
```bash
$ cat /home/flyer/bug/Dockerfile
FROM debian
USER nobody
```

**pass.txt permissions**
```bash
$ ls -la pass.txt
-rw-r----- 1 flyer flyer 8 May  9 00:31 pass.txt

```

**id nobody on the host**
```bash
$ id nobody
uid=65534(nobody) gid=65534(nogroup) groups=65534(nogroup)
```

## Steps to reproduce the issue

1. docker-compose up

### Observed result
```bash
$ docker-compose up
Creating test ... done
Attaching to test
test    | total 12

test    | drwxr-xr-x 2 root   root    4096 May  8 21:52 .
test    | drwxr-xr-x 1 root   root    4096 May  8 21:52 ..
test    | -rw-r----- 1 nobody nogroup    8 May  8 21:31 pass

test    | uid=65534(nobody) gid=65534(nogroup) groups=65534(nogroup)

test    | cat: /run/secrets/pass: Permission denied
test exited with code 1
```

### Expected result

* I would expect that the source file on the host should not be world readable. 
* Otherwise, I would expect the secret file to be accessible without world readable permissions if the `uid` or `gid` match.

## Additional information

Running on `Debian 10, Buster`

```
$ uname -a
Linux House 5.4.0-0.bpo.4-amd64 #1 SMP Debian 5.4.19-1~bpo10+1 (2020-03-09) x86_64 GNU/Linux

```

OS version / distribution, `docker-compose` install method, etc.
",,,stale,"
--
This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you for your contributions.

--

--
This issue has been automatically marked as not stale anymore due to the recent activity.

--
",sanmai,"
--
Not stale.
--
",mattpepin,"
--
I have the same problem. Surely, there must be a way!
--
",sdavids,"
--
https://github.com/moby/moby/issues/40046
--
",,,,
7434,OPEN,Context not found when given on docker-compose CLI,kind/bug,2020-09-25 16:23:17 +0000 UTC,impala454,In progress,,"3. When making a bug report, make sure you provide all required information. The easier it is for
   maintainers to reproduce, the faster it'll be fixed.
-->

## Description of the issue
When using the `docker-compose` command line `--context` parameter, the context reports not found, even though it's found when using `docker` commands.

## Context information (for bug reports)

**Output of `docker-compose version`**
```
docker-compose version 1.26.0-rc4, build d279b7a8
docker-py version: 4.2.0
CPython version: 3.7.7
OpenSSL version: OpenSSL 1.1.0l  10 Sep 2019
```

**Output of `docker version`**
```
Client: Docker Engine - Community
 Version:           19.03.8
 API version:       1.40
 Go version:        go1.12.17
 Git commit:        afacb8b7f0
 Built:             Wed Mar 11 01:25:46 2020
 OS/Arch:           linux/amd64
 Experimental:      false

Server: Docker Engine - Community
 Engine:
  Version:          19.03.8
  API version:      1.40 (minimum version 1.12)
  Go version:       go1.12.17
  Git commit:       afacb8b7f0
  Built:            Wed Mar 11 01:24:19 2020
  OS/Arch:          linux/amd64
  Experimental:     false
 containerd:
  Version:          1.2.13
  GitCommit:        7ad184331fa3e55e52b890ea95e65ba581ae3429
 runc:
  Version:          1.0.0-rc10
  GitCommit:        dc9208a3303feef5b3839f4323d9beb36df0a9dd
 docker-init:
  Version:          0.18.0
  GitCommit:        fec3683

```

**Output of `docker-compose config`**
(Make sure to add the relevant `-f` and other flags)
```yaml
services:
  test:
    container_name: test
    image: alpine
version: '3.6'
```


## Steps to reproduce the issue

1. Create a context (in this case with ssh): 
```
docker context create testctx --default-stack-orchestrator swarm --docker ""host=ssh://user@remote""
```
2. Verify context is functional: 
```
docker --context testctx ps
```
3. Issue a compose command on the context (this is what fails):
```
docker-compose --context testctx up -d
```

4. Issue the same compose command except with the host parameter to verify endpoint (this works for me):
```
docker-compose -H ssh://user@remote up -d
```

### Observed result
```
ERROR: Context 'testctx' not found
```

### Expected result
The docker-compose should remotely execute on the context's machine.

### Stacktrace / full error message
(with `--verbose`)
```
docker.utils.config.find_config_file: Trying paths: ['/home/user/.docker/config.json', '/home/user/.dockercfg']
docker.utils.config.find_config_file: No config file found
ERROR: compose.cli.main.main: Context 'testctx' not found
```

## Additional information

OS version / distribution, `docker-compose` install method, etc.

Ubuntu 18.04.

Docker installed via [this ansible role](https://github.com/nickjj/ansible-docker), docker-compose installed via ansible task:
```yaml
- name: Update docker-compose to bleeding edge # Required for docker context support
  get_url:
    url: https://github.com/docker/compose/releases/download/1.26.0-rc4/docker-compose-Linux-x86_64
    dest: /usr/local/bin/docker-compose
    checksum: sha256:3ad2031c7daae160b8987538a60261475b3e17dfccf6fb96c1ae67d23afecdb8
```",,,pandanoir,"
--
I saw same problem.
--

--
Maybe I have solved it.

Before running `docker-compose --context testctx`, I executed `docker context use testctx`. Then docker-compose recognized my context, even if I set the context back to ""default"".

However, I'm not sure why it works. So I cannot guarantee that it will work in your environment.

```
$ docker context use testctx
$ docker context use default
$ docker-compose --context testctx up
# docker-compose finds testctx and works fine
```
--

--
@impala454 

(I'm sorry if I misread your comment)

I tried `docker context use` to switch context, and then **back to previous context(default)**. I ran `docker-compose --context testctx up` in default context and docker-compose worked fine.

While my solution seems to do nothing at first glance, my solution has some side effects that make docker-compose work properly. I don't know what the side effect is.
--
",dougcooper,"
--
same issue here

docker-compose version 1.26.2, build eefe0d31
Docker version 19.03.12, build 48a66213fe

--
",zfogg,"
--
+1 docker-compose should respect the DOCKER_CONTEXT environment variable and the current user's docker context config files
--
",impala454,"
--
@pandanoir sure, issuing a `docker context use <>` would work because then you're in the proper context, but the `docker-compose --context` argument would be pointless if that was required.  The `--context` argument should either switch contexts only for that command, or only execute the given compose file on the context given.
--
",,,,
7431,OPEN,[RFC] deprecate push --ignore-push-failures and implement --skip-missing or --ignore-missing,kind/feature,2020-05-06 10:37:54 +0000 UTC,thaJeztah,Opened,,"**Is your feature request related to a problem? Please describe.**

See

- my observation in https://github.com/docker/compose/pull/7430#discussion_r420606842
- original implementation: https://github.com/docker/compose/pull/3595

The `docker-compose push` subcommand has an `--ignore-push-failures` option, which ignores any error that occurs when pushing (one of) the images built in the `docker-compose.yaml` file.

This flag can be useful for situations where multiple services define a `build:`, but (possibly) not all of those images have been build (and are thus missing in the local image cache).

However, currently _any_ error that occurs is ignored. I think this is bad behavior, as this may be hiding important failures (e.g., trying to push when I was not authenticated, trying to push but the registry is not reachable, or perhaps there's a failiure on the registry side).

Here's an example:

docker-compose file:

```yaml
version: ""3.7""
services:
  missing:
    build:
      context: .
      dockerfile: Dockerfile.example
    image: localhost:5000/foobar:missing
  built:
    build:
      context: .
      dockerfile: Dockerfile.example
    image: localhost:5000/foobar:built
  unreachable:
    build:
      context: .
      dockerfile: Dockerfile.example
    image: no-such-registry.example.com:5000/foobar:unreachable
  unauthenticated:
    build:
      context: .
      dockerfile: Dockerfile.example
    image: docker.io/library/foobar:unauthenticated
```

`Dockerfile.example`

```dockerfile
FROM busybox
RUN echo ""foo"" > /foo
```

Build images for the `built`, `unreachable`, and `unauthenticated` services:

```bash
docker-compose build built unreachable unauthenticated
```

Start a local registry, and push the images with `docker-compose push --ignore-push-failures`:

```bash
docker run -d --name registry -p 127.0.0.1:5000:5000 registry:2
docker-compose push --ignore-push-failures

Pushing missing (localhost:5000/foobar:missing)...
The push refers to repository [localhost:5000/foobar]
ERROR: tag does not exist: localhost:5000/foobar:missing
Pushing built (localhost:5000/foobar:built)...
The push refers to repository [localhost:5000/foobar]
554895133718: Pushed
5b0d2d635df8: Pushed
built: digest: sha256:2505d8793b4cfe865315715960a4e7eb2fa683f3cafaa7198a0303d9504022a6 size: 734
Pushing unreachable (no-such-registry.example.com:5000/foobar:unreachable)...
The push refers to repository [no-such-registry.example.com:5000/foobar]
ERROR: Get https://no-such-registry.example.com:5000/v2/: Service Unavailable
Pushing unauthenticated (docker.io/library/foobar:unauthenticated)...
The push refers to repository [docker.io/library/foobar]
554895133718: Preparing
5b0d2d635df8: Preparing
ERROR: denied: requested access to the resource is denied
```

Check the exit-code and see that the command exited succesfully:

```bash
echo $?
0
```


**Describe the solution you'd like**

I think we should deprecated the existing flag, and replace it with a `--skip-missing` or `--ignore-missing` flag;

- Without the flag set, `docker-compose push` will fail on any failure that occurs when pushing
- If the flag is set, docker compose will check if the image exists locally, and if not, skip pushing of the image
    - When skipping an image, it prints an `INFO` message, informing the user that no local image existed, and that pushing was skipped
",,,,,,,,,,,,,,
7429,OPEN,Docker-compose push skips second service if first has same image but no build section,kind/bug,2020-12-03 14:57:28 +0000 UTC,musikov,In progress,,"## Description of the issue
When you have multiple services with same image, but only one (not first) has `build` field, `docker-compose push` ignores it.

## Context information (for bug reports)

**Output of `docker-compose version`**
```
docker-compose version 1.25.4, build 8d51620a
docker-py version: 4.1.0
CPython version: 3.7.5
OpenSSL version: OpenSSL 1.1.1d  10 Sep 2019
```

**Output of `docker version`**
```
Client: Docker Engine - Community
 Version:           19.03.8
 API version:       1.40
 Go version:        go1.12.17
 Git commit:        afacb8b
 Built:             Wed Mar 11 01:21:11 2020
 OS/Arch:           darwin/amd64
 Experimental:      false

Server: Docker Engine - Community
 Engine:
  Version:          19.03.8
  API version:      1.40 (minimum version 1.12)
  Go version:       go1.12.17
  Git commit:       afacb8b
  Built:            Wed Mar 11 01:29:16 2020
  OS/Arch:          linux/amd64
  Experimental:     false
 containerd:
  Version:          v1.2.13
  GitCommit:        7ad184331fa3e55e52b890ea95e65ba581ae3429
 runc:
  Version:          1.0.0-rc10
  GitCommit:        dc9208a3303feef5b3839f4323d9beb36df0a9dd
 docker-init:
  Version:          0.18.0
  GitCommit:        fec3683
```

**Output of `docker-compose config`**
```
services:
  first:
    image: my_app
  second:
    build:
      context: /Users/musikov/docker_push_issue
    image: my_app
version: '3.7'
```


## Steps to reproduce the issue

1. Create dummy dir `mkdir ~/docker_push_issue`
2. Go to it `cd ~/docker_push_issue`
3. Create dummy Dockerfile `echo 'from python' > Dockerfile`
4. Create docker-compose.yml file as in issue:
```
echo ""services:
  first:
    image: my_app
  second:
    build: .
    image: my_app
version: '3.7'
"" > docker-compose.yml
```
5. Build project `docker-compose build`
6. Push project `docker-compose push`

### Observed result
Command runs, but nothing happened.
### Expected result
Image is pushed. (for current example we must receive `no permission` error)
### Stacktrace / full error message
```
# docker-compose -verbose push
docker-compose version 1.25.4, build 8d51620a
```

## Additional information

OS version / distribution, `docker-compose` install method, etc.
macOS 10.15.4 (19E287), docker desktop",,,samizdam,"
--
Same problem with `docker-compose version 1.25.5, build 8a1c60f6`. 
--
",stan,"
--
This seems to be due to condition in https://github.com/docker/compose/blob/854c003359bd07d0d3ca137d7a08509cfeab0436/compose/service.py#L1273-L1274

whereas earlier in the file 
https://github.com/docker/compose/blob/854c003359bd07d0d3ca137d7a08509cfeab0436/compose/service.py#L1161-L1162

Is `build` really needed to do push?
--
",musikov,"
--

> Is `build` really needed to do push?

Yes. Build section means we can have some changes we want to push sometime. If no build phrase in compose file - than we have nothing new to push
--
",,,,,,
7423,OPEN,docker-compose does not set environment variables,kind/bug,2021-02-21 11:55:55 +0000 UTC,Kytech,In progress,,"# Description of the issue

When using `docker-compose up` or `docker-compose run -e ENVIRONMENT_VAR=value`, environment variables are not being applied either through the `-e` command line parameters or from the docker-compose.yml file.

The docker-compose.yml file I am using is as follows:
```YML
version: '3'
services:
    nginx-reverse-proxy:
        image: nginx
        volumes:
         - C:/Users/<Username>/nginx-reverse-proxy/configdir:/etc/nginx/conf.d/
        ports:
         - ""80:80""
        environment:
            NGINX_SERVER_NAME: ""test.mysite.org""
            NGINX_REMOTE_URL: ""http://remote.mysiteengine.somehost.com:13345""
```

## Context information (for bug reports)

**Output of `docker-compose version`**
```
docker-compose version 1.25.5, build 8a1c60f6
```

**Output of `docker version`**
```
Client: Docker Engine - Community
 Version:           19.03.8
 API version:       1.40
 Go version:        go1.12.17
 Git commit:        afacb8b
 Built:             Wed Mar 11 01:23:10 2020
 OS/Arch:           windows/amd64
 Experimental:      false

Server: Docker Engine - Community
 Engine:
  Version:          19.03.8
  API version:      1.40 (minimum version 1.12)
  Go version:       go1.12.17
  Git commit:       afacb8b
  Built:            Wed Mar 11 01:29:16 2020
  OS/Arch:          linux/amd64
  Experimental:     false
 containerd:
  Version:          v1.2.13
  GitCommit:        7ad184331fa3e55e52b890ea95e65ba581ae3429
 runc:
  Version:          1.0.0-rc10
  GitCommit:        dc9208a3303feef5b3839f4323d9beb36df0a9dd
 docker-init:
  Version:          0.18.0
  GitCommit:        fec3683
```

**Output of `docker-compose config`**
```
WARNING: The NGINX_SERVER_NAME variable is not set. Defaulting to a blank string.
WARNING: The NGINX_REMOTE_URL variable is not set. Defaulting to a blank string.
services:
  nginx-reverse-proxy:
    environment:
      NGINX_SERVER_NAME: ""test.mysite.org""
      NGINX_REMOTE_URL: ""http://remote.mysiteengine.somehost.com:13345""
    image: nginx
    ports:
    - 80:80/tcp
    volumes:
    - C:\Users\<Username>\nginx-reverse-proxy\configdir:/etc/nginx/conf.d/:rw
version: '3.0'
```


## Steps to reproduce the issue

1. Create a docker-compose.yml file that sets environment variables
2. Run docker-compose up

### Observed result

Environment Variables are not applied

### Expected result

Environment variables should be applied to containers started by docker-compose

### Stacktrace / full error message

```
WARNING: The NGINX_SERVER_NAME variable is not set. Defaulting to a blank string.
WARNING: The NGINX_REMOTE_URL variable is not set. Defaulting to a blank string.
Creating network ""nginx-reverse-proxy_default"" with the default driver
```

## Additional information

OS Version: Windows 10 Pro v1909,
`docker-compose` install method: Docker Desktop for Windows Installer, followed by manual upgrade of docker-compose (Issue occurred on docker-compose version 1.25.4 which was included with Docker Desktop and with manual upgrade to 1.25.5)
",,,hholst80,"
--
???
This yaml is broken. Please post the actual yaml you are deploying with.
```
        volumes:
         - C:/Users/<Username>/nginx-reverse-proxy/configdir:/etc/nginx/conf.d/
```
--

--
.env file and env_file have different semantics. If you want to use variable interpolation in your compose file you have to use the .env file. 
--

--
My conclusion here is that the -e environment variables are treated with the same semantics as env_file. Consistent with docker cli run cmd. 
--
",Kytech,"
--
> ???
> This yaml is broken. Please post the actual yaml you are deploying with.
> ```
>         volumes:
>          - C:/Users/<Username>/nginx-reverse-proxy/configdir:/etc/nginx/conf.d/
> ```

This is the yaml I am using. It works exactly as expected on my local machine when I don't have environment variables included. I am using docker for Windows, so the file path format is different than with linux. I have not included my PC username for privacy purposes.
--

--
@kravchenkoloznia that should be a good workaround in the meantime.

I hope the docker team fixes this since it's broken just about every docker-compose file I've been using that specifies environment variables in the docker-compose.yml
--
",kravchenkoloznia,"
--
Facing the same issue.

And I found that environment variables are working only from `.env` file placed in the folder where the docker-compose command is executed (current working directory).

Providing environment variables from command line giving the same warnings as @Kytech mentioned.

```shell
$ docker-compose run -e PRODUCT=1 all
WARNING: The PRODUCT variable is not set. Defaulting to a blank string.
```

Providing environment variables from user-specific `docker-compose.env` file still resulting with the same warnings

```shell
$ cat docker-compose.env 
PRODUCT=1
RELEASE=0
FLASH=0
DEBUG=3

$ cat docker-compose.yml 
version: '3'
services:
  all:
    image: 82100_src:latest
    env_file: ./docker-compose.env
    volumes:
      - .:/home/user
    command: make PRODUCT=${PRODUCT} all RELEASE=${RELEASE} FLASH=${FLASH} DEBUG=${DEBUG}

$ docker-compose run all
WARNING: The PRODUCT variable is not set. Defaulting to a blank string.
WARNING: The RELEASE variable is not set. Defaulting to a blank string.
WARNING: The FLASH variable is not set. Defaulting to a blank string.
WARNING: The DEBUG variable is not set. Defaulting to a blank string.
```

I'm using Linux Debian 10 with next versions of Docker and Docker-compose:

```shell
$ docker-compose version
docker-compose version 1.23.2, build 1110ad01
docker-py version: 3.6.0
CPython version: 3.6.7
OpenSSL version: OpenSSL 1.1.0f  25 May 2017

$ docker version
Client: Docker Engine - Community
 Version:           19.03.9
 API version:       1.40
 Go version:        go1.13.10
 Git commit:        9d988398e7
 Built:             Fri May 15 00:25:25 2020
 OS/Arch:           linux/amd64
 Experimental:      false

Server: Docker Engine - Community
 Engine:
  Version:          19.03.9
  API version:      1.40 (minimum version 1.12)
  Go version:       go1.13.10
  Git commit:       9d988398e7
  Built:            Fri May 15 00:23:57 2020
  OS/Arch:          linux/amd64
  Experimental:     false
 containerd:
  Version:          1.2.13
  GitCommit:        7ad184331fa3e55e52b890ea95e65ba581ae3429
 runc:
  Version:          1.0.0-rc10
  GitCommit:        dc9208a3303feef5b3839f4323d9beb36df0a9dd
 docker-init:
  Version:          0.18.0
  GitCommit:        fec3683
```

--

--
@hholst80 indeed, my mistake.

After reading docker documentation one more time and few additional articles, it's now obvious for me that for substitution in docker-compose file itself used environment variables of my current shell, and to send environment variables inside docker container I may use either docker run CLI or env_file. 

Thanks!
--
",azryelryvel,"
--
Nothing is working for me, I can't use any environment variable :
```
/tmp/test$ curl -SsL ""https://github.com/docker/compose/releases/download/1.26.0/docker-compose-$(uname -s)-$(uname -m)"" -o docker-compose
/tmp/test$ ls -a
.  ..  docker-compose  docker-compose.yml
/tmp/test$ cat docker-compose.yml
version: '3'
services:
  test:
    image: 'busybox'
    command: env
    environment:
      - HELLO=WORLD
/tmp/test$ sudo ./docker-compose down
Removing network test_default
WARNING: Network test_default not found.
/tmp/test$ sudo ./docker-compose up -d
Creating network ""test_default"" with the default driver
Creating test_test_1 ... done
/tmp/test$ sudo docker logs test_test_1
PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin
HOSTNAME=b68e605e609d
HOME=/root
```

It doesn't work with env_file, .env or docker run -e either

EDIT: The problem disappeared after updating docker to 18.09.8
--
",Mahima,"
--
Hey,  While working on docker with Celery and Rabbitmq integration, I also faced the issue where the environment variables were not used up (set) though they can be seen using the env command in the container. I solved the issue by taking the below two steps.

1. I uninstalled the older docker-compose and installed the latest by following [https://docs.docker.com/compose/install/](https://docs.docker.com/compose/install/)
2. I renamed the service for which the environment variables were defined in the docker-compose.yml.

Later on, I rechecked with the old service name and found that the issue reappeared. Then I removed the older container and again did `docker-compose up`. This solved the issue. So I think, it might be the old container which does not let us see the new changes.

I am using Docker Engine v19.03.12 and docker-compose v 1.26.2

The contents (related to the issue) of my docker-compose.yml are:
```
version: ""3.8""

services:  
  rabbit:
    hostname: rabbit
    image: rabbitmq:management
    environment:
      - RABBITMQ_DEFAULT_USER=user1
      - RABBITMQ_DEFAULT_PASS=password1
    ports:
      - ""5672:5672""
      - ""15672:15672""

```
--
",agovindaraju,"
--
I am on the latest version of docker compose 1.27.4. I still see the same issue as other users have described above.
--
"
7408,OPEN,docker-compose logs no output if using log-driver,kind/bug; stale,2021-02-23 23:01:24 +0000 UTC,audunsolemdal,Opened,,"3. When making a bug report, make sure you provide all required information. The easier it is for
   maintainers to reproduce, the faster it'll be fixed.
-->

## Description of the issue

docker-compose logs does not show output when using external log-driver. I would like to access the logs from both places.

## Context information (for bug reports)

**Output of `docker-compose version`**
```
docker-compose version 1.25.1, build a82fef07
docker-py version: 4.1.0
CPython version: 3.7.4
OpenSSL version: OpenSSL 1.1.0l  10 Sep 2019
```

**Output of `docker version`**
```
Client: Docker Engine - Community
 Version:           19.03.8
 API version:       1.39 (downgraded from 1.40)
 Go version:        go1.12.17
 Git commit:        afacb8b
 Built:             Wed Mar 11 01:27:04 2020
 OS/Arch:           linux/amd64
 Experimental:      false
Server: Docker Engine - Community
 Engine:
  Version:          18.09.1
  API version:      1.39 (minimum version 1.12)
  Go version:       go1.10.6
  Git commit:       4c52b90
  Built:            Wed Jan  9 19:06:30 2019
  OS/Arch:          linux/amd64
  Experimental:     false
```

**Output of `docker-compose config`**
(Make sure to add the relevant `-f` and other flags)
```
services:
  app:
    entrypoint: ping host.docker.internal
    image: alpine:latest
    logging:
      driver: loki
      options:
        loki-url: http://host.docker.internal:3100/loki/api/v1/push
  grafana:
    environment:
      GF_EXPLORE_ENABLED: ""true""
    image: grafana/grafana:master
    ports:
    - published: 3000
      target: 3000
  loki:
    image: grafana/loki:master
    ports:
    - published: 3100
      target: 3100
version: '3.7'
```


## Steps to reproduce the issue

1. docker plugin install grafana/loki-docker-driver:latest --alias loki --grant-all-permissions
2. Set daemon.json config as described here https://github.com/grafana/loki/blob/v1.4.1/docs/clients/docker-driver/configuration.md#change-the-default-logging-driver
3. docker-compose up -d with the config above
4. docker-compose logs

### Observed result

From this issue https://github.com/grafana/loki/issues/1368
and this comment https://github.com/grafana/loki/issues/1368#issuecomment-606872659

`docker logs <containername>` works fine. `docker-compose logs` does not work.

### Expected result

I would expect `docker-compose logs` to be able to show output in the same fashion as `docker logs`

### Stacktrace / full error message

```
Attaching to test-container_loki_1, test-container_grafana_1, test-container_app_1
app_1      | WARNING: no logs are available with the 'loki' log driver
grafana_1  | WARNING: no logs are available with the 'loki' log driver
loki_1     | WARNING: no logs are available with the 'loki' log driver
```

## Additional information

OS version / distribution, `docker-compose` install method, etc.

CentOS 8.1, puppet module installation
",,,pgassmann,"
--
Closed Bug in loki project as they implement the necessary api: https://github.com/grafana/loki/issues/1487
--
",stale,"
--
This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you for your contributions.

--
",,,,,,,,
7405,OPEN,Ubuntu 20.04 I can not connect ports after VMware suspend,kind/bug,2020-11-04 12:55:50 +0000 UTC,berkayyildi,In progress,,"

## Description of the issue

Ubuntu 20.04
I can not connect ports after VMware suspended then resumed. It require docker restart command to connect.

## Context information (for bug reports)

**Output of `docker-compose version`**
```
docker-compose version 1.25.0, build unknown
docker-py version: 4.1.0
CPython version: 3.8.2
OpenSSL version: OpenSSL 1.1.1f  31 Mar 2020
```

**Output of `docker version`**
```
Client:
 Version:           19.03.8
 API version:       1.40
 Go version:        go1.13.8
 Git commit:        afacb8b7f0
 Built:             Wed Mar 11 23:42:35 2020
 OS/Arch:           linux/amd64
 Experimental:      false

Server:
 Engine:
  Version:          19.03.8
  API version:      1.40 (minimum version 1.12)
  Go version:       go1.13.8
  Git commit:       afacb8b7f0
  Built:            Wed Mar 11 22:48:33 2020
  OS/Arch:          linux/amd64
  Experimental:     false
 containerd:
  Version:          1.3.3-0ubuntu2
  GitCommit:        
 runc:
  Version:          spec: 1.0.1-dev
  GitCommit:        
 docker-init:
  Version:          0.18.0
  GitCommit:        
```

## Additional information

Linux ubuntu 5.4.0-26-generic #30-Ubuntu SMP Mon Apr 20 16:58:30 UTC 2020 x86_64 x86_64 x86_64 GNU/Linux
",,,dinyadin,"
--
@berkayyildi : can you tell me more details on this? 
I would like to work on this.
my email address: dineshprajapati838@yahoo.in
--
",berkayyildi,"
--
> @berkayyildi : can you tell me more details on this?
> I would like to work on this.
> my email address: [dineshprajapati838@yahoo.in](mailto:dineshprajapati838@yahoo.in)

I will give you more detailed info here.
I use VMware Workstation Technology Preview 20H1 Pro
Version: e.x.p build-15679048

I use ubuntu-20.04-desktop-amd64.iso

There is no problem in 16.04, but 20.04 has network problem.
When I suspend then  resume I can't connect to containers.
You can use any docker image to test but I realized while using this image 

> trafex/alpine-nginx-php7

While container working I can connect to port 80, I suspend and resume the VMware then I can not connect port 80 until I restart docker.

This is everything I know. When you try you will understand the problem easily.
--
",pluguern,"
--
Hello, 

I have the same issue when I moved from 18.04 to 20.04. I tested with 
plantuml/plantuml-server (configured with a tomcat container. 

I use VMware Workstation 15 Pro - 15.5.1 build-15018445. 

docker version 19.03.13, build 4484c46d9d

docker-compose version 1.27.4, build 40524192

Thx. 
--

--
Hello, 
I noticed that my docker network interface disappears after a suspend resume. 

Before (ifconfig): 
_```
docker0: flags=4163<UP,BROADCAST,RUNNING,MULTICAST>  mtu 1500
        inet 172.17.0.1  netmask 255.255.0.0  broadcast 172.17.255.255
        inet6 fe80::42:37ff:fec3:feea  prefixlen 64  scopeid 0x20<link>
        ether 02:42:37:c3:fe:ea  txqueuelen 0  (Ethernet)
        RX packets 18  bytes 1647 (1.6 KB)
        RX errors 0  dropped 0  overruns 0  frame 0
        TX packets 562  bytes 117634 (117.6 KB)
        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0
```_
After (ifconfig): 
docker0: interface is no longer present.
--
",,,,,,
7402,OPEN,Hierarchical resolution of environment files,kind/feature,2020-04-27 15:27:13 +0000 UTC,djechelon,Opened,,"**Is your feature request related to a problem? Please describe.**
I would like Docker-compose to resolve properties from multiple `env` files in a hierarchical order.

This way, the composer may define the default settings in the root `.env` file and, on startup, have Docker-compose (instructed with proper arguments as follows) resolve from the most specific file, e.g. `uat.env` to the default `.env`

Examples of files (I know that there are much better ways to store passwords)

- .env

```
APACHE_HTTPS_PORT=443 #That is the universal default
POSTGRES_PASSWORD=postgres #Simple password for everyone
WHERE_TO_FIND_CERTIFICATES= #Empty so you must override it
```

- Alice_laptop.env

```
WHERE_TO_FIND_CERTIFICATES=/home/alice/openssl
```


- Bob_laptop.env

```
WHERE_TO_FIND_CERTIFICATES=C:/users/bob/secrets
```

- uat.env

```
APACHE_HTTPS_PORT=8443 #Because 443 is taken
WHERE_TO_FIND_CERTIFICATES=/etc/openssl/private
```

- prod.env

```
WHERE_TO_FIND_CERTIFICATES=/etc/openssl/private
```


**Describe the solution you'd like**

##Proposal 1

When invoked with `--env-file`, resolve properties with the given file. For properties not defined in the file passed as parameter, try to fall back to `.env` if present

##Proposal 2

Have docker-compose accept multiple `--env-file` arguments and resolve the environment variables in a defined order, e.g. from the most specific file to the most generic file or vice versa

**Describe alternatives you've considered**
Currently I have to copy all the properties from the default .env file to customized env files and **maintain them**

**Additional context**
I need to create multiple environments in Docker compose where a single environment only overrides a few properties. Given that our company works on a ""product"" basis, i.e. we have no concept of single ""uat"" or ""prod"", because the same product lives in many different uat and prod instances, it is necessary only to change a few settings in different environments, like branding logo or where to find the database dumps, or other specific application settings.

And when giving developers the option to run the stack on their own laptop, I would like to assure them that minimum configuration is required.

For example, today I am stumbling upon different SSL certificates locations, while having to keep the rest of the properties maintanable.

In my example, SSL certificates on my work laptop are located under `D:\openssl` because I run on Windows host. In other hosts, I generally tend to use `/home/docker/ssl`.

When Bob wants to run the application, he would only override a few needed environment variables than copying the entire default env file and running the stack with his own property file. When the project maintainer (me) commits a new base env file, Bob would have to copy the new properties to his file. With this work, Bob would not have to _automatically_ copy the new properties, but rather stumble into a problem

**Research**
I obviously tried to see if this was already available or not.

From https://docs.docker.com/compose/environment-variables/ I can see that Docker Compose already uses an ordered checklist of environment variable resolution

> 1.    Compose file
> 2.    Shell environment variables
> 3.    Environment file
> 4.    Dockerfile
> 5.    Variable is not defined

What I am asking is different: change step 3 into a hierarchy of Environment files.

The following does not work. I expected the ports environment variables to be visible to the ports part. I must declare those variables into my env file

```
  apache2:
    environment:
      APACHE_SSL_MOUNT: """"
      APACHE_SSL_ROOT: /etc/ssl/private/
      APACHE_SSL_CERTS: acme.com.crt
      APACHE_SSL_PRIVATE: acme.com.key
      APACHE_SSL_CA_BUNDLE: acme.com.crt
      APACHE_SERVER_NAME: acme.com
      APACHE_SERVER_ADMIN: acme@acme.com
      PCP3_HTTP_PORT: 80
      PCP3_HTTPS_PORT: 443
    image: httpd:2.4-alpine
    #    build:
    #      dockerfile: src/main/docker/httpd.Dockerfile
    #      context: src/main/resources/httpd-context
    expose:
      - ""80/tcp""
      - ""443/tcp""
    ports:
      - ""${PCP3_HTTP_PORT}:80""
      - ""${PCP3_HTTPS_PORT}:443""
    volumes:
      - ""${APACHE_SSL_MOUNT}:/etc/ssl/private:ro""
      - ""${PROJECT_ROOT}/src/main/resources/httpd-context:/usr/local/apache2/conf:ro""

```",,,,,,,,,,,,,,
7400,OPEN,May I translate this project into Korean?,kind/feature,2020-04-27 07:31:38 +0000 UTC,ChaeHyun-Kim,Opened,,"Hi :) I am Chae Hyun Kim a university student in Kwangwoon University. 
I want to translate READ ME documentation for your project contribution and other Koreans who want to learn about docker.
So may I translate these infos into Korean?
If I could, plz tell me how I can share the translated results.
Thank you",,,,,,,,,,,,,,
7398,OPEN,Generating package-lock.json for production branch with mounted volumes during build,kind/feature,2020-04-24 11:59:02 +0000 UTC,jelafi,Opened,,"Hi,

I'm facing following issue.
When I branch my project for a production release I want to be sure which packages are used via npm install.
For that reason I do not want to use npm i anymore during each build of the branch but to use npm ci.
npm ci is then relying on the package-lock.json

But first for that the day I create the branch I have to genearte all the packe-lock.json.
That can be done manually and locally (but is not convenient if I create often new branches). That's why I wanted to create a build that I run once. Idea of this build is to start a build for the whole project (with docker-compose) and mounting the source code volumes. Doing that I'm able to copy in the source code repository all the packages-lock.json

After this intitial branching build I can run a stable build regularly using npm ci.

Without mounting the volumes in the docker-compose I have today to install curl everywhere in the dockers in order to copy the package-lock.json in my binary repo.
Then manually I have to copy all the package-lock.json into every source code directory.

This way is very inconvenient.

Wish is to have the possibility during build to mount a volume

The possibility to declare intermediate dockers during build what has been the answers to previous requests for requesting volume mounting during build does not apply here as this is not about the size of the docker but the possibility to create an artifact for generating automatically stable branches.

Thanks for considering this request.
",,,,,,,,,,,,,,
7397,OPEN,docker-compose up fails with symlinked Dockerfile,kind/bug,2020-11-21 18:16:09 +0000 UTC,davidhewitt,Opened,,"3. When making a bug report, make sure you provide all required information. The easier it is for
   maintainers to reproduce, the faster it'll be fixed.
-->

## Description of the issue

I have several microservices which share an identical `Dockerfile`. To simplify maintenance and reduce duplication I would like to replace all the Dockerfiles with a symlink to a single ""common"" `Dockerfile`.

Before symlinking, my directory structure looks like this:

```
- docker-compose.yaml
- microservice_a/
  - Dockerfile
- microservice_b/
  - Dockerfile
```

after, it looks like this:

```
- docker-compose.yaml
- common/
  - Dockerfile
- microservice_a/
  - Dockerfile  ->  ../common/Dockerfile
- microservice_b/
  - Dockerfile  ->  ../common/Dockerfile
```

Without symlinking, `docker-compose up` works as expected.

Once I switch to the symlink model, this no longer works, and I get errors related to `Dockerfile: no such file or directory`. See below for more detail:

## Context information (for bug reports)

**Output of `docker-compose version`**
```
docker-compose version 1.25.4, build 8d51620a
```

**Output of `docker version`**
```
Docker version 19.03.8, build afacb8b
```

(ommited docker-compose config because it contains confidential information like private keys which I'm configuring using env vars)

## Steps to reproduce the issue

1. Create two services with idential dockerfiles and reference them both in a compose file.
2. Move their dockerfile to a subdirectory 'common' and symlink it in the services' Dockerfiles.

### Observed result

`docker-compose` can no longer find the Dockerfile, even though it's still in ""the same place"" because of the symlink.

### Expected result

`docker-compose` continues to function, and can read the Dockerfile through the new symlink.

### Stacktrace / full error message

```
[+] Building 0.0s (2/2) FINISHED
=> [internal] load .dockerignore                                                 0.0s
=> => transferring context: 34B                                                  0.0s
=> [internal] load build definition from Dockerfile                                        0.0s
=> => transferring dockerfile: 70B                                                0.0s
failed to solve with frontend dockerfile.v0: failed to read dockerfile: open /var/lib/docker/tmp/buildkit-mount384971895/common/Dockerfile: no such file or directory
Traceback (most recent call last):
 File ""docker-compose"", line 6, in <module>
 File ""compose/cli/main.py"", line 72, in main
 File ""compose/cli/main.py"", line 128, in perform_command
 File ""compose/cli/main.py"", line 1077, in up
 File ""compose/cli/main.py"", line 1073, in up
 File ""compose/project.py"", line 548, in up
 File ""compose/service.py"", line 351, in ensure_image_exists
 File ""compose/service.py"", line 1110, in build
 File ""compose/progress_stream.py"", line 25, in stream_output
 File ""compose/utils.py"", line 61, in split_buffer
 File ""compose/utils.py"", line 37, in stream_as_text
 File ""compose/service.py"", line 1818, in build
FileNotFoundError: [Errno 2] No such file or directory: '/var/folders/7_/wk5b0_312sq4_9x59jhq0q_r0000gn/T/tmp0jhuoqwn'
[20348] Failed to execute script docker-compose
```

## Additional information

MacOS Catalina 10.15.4
",,,Code0x58,"
--
_From some investigation as an interested party:_

This log was generated while [`_CLIBuilder`](https://github.com/docker/compose/blob/1a688289b42c6927c3e05304c5259db1f85c69c4/compose/service.py#L1721) is in use, which happens when `COMPOSE_DOCKER_CLI_BUILD=1` which you may do if you want want to use Buildkit (so you'd have `DOCKER_BUILDKIT=1` set too). If that is not set, you get a [`docker.api.client.APIClient`](https://github.com/docker/docker-py/blob/4.2.0/docker/api/client.py#L49) instance instead - both share the [same interface](https://docker-py.readthedocs.io/en/stable/images.html#docker.models.images.ImageCollection.build), so this issue would occur regardless of that config.

The issue could be fixed with a fairly noninvasive change by always providing the Dockerfile using the [`fileobj` argument](https://docker-py.readthedocs.io/en/stable/images.html#docker.models.images.ImageCollection.build) of the low level build interface. This can be done by making the [abstracted build method](https://github.com/docker/compose/blob/1a688289b42c6927c3e05304c5259db1f85c69c4/compose/service.py#L1063) pass a `fileobj` instead, and updating `_CLIBuilder` to pass that through stdin [[docker CLI docs](https://docs.docker.com/engine/reference/commandline/build/#text-files)]. An optimisation that may be tempting is to only pass via `fileobj` iff the Dockerfile is a symlink, but I don't think that should be done at all.
--
",thaJeztah,"
--
Trying to reproduce the problem, but first checking the behavior with `docker build` (taking `docker-compose` out of the equation)



Create directories, create Dockerfile, and create symlink:


```bash
mkdir repro-7397 && cd repro-7397
mkdir common microservice_a

cat > common/Dockerfile <<EOF
FROM nginx:alpine
RUN echo hello
EOF

cd microservice_a && ln -s ../common/Dockerfile Dockerfile && cd ../
```

Result should look like:

```bash
tree
.
 common
  Dockerfile
 microservice_a
     Dockerfile -> ../common/Dockerfile
```

Performing a build in some combinations:


```bash
DOCKER_BUILDKIT=1 docker build -t repro-7397 microservice_a/
[+] Building 0.0s (2/2) FINISHED
=> [internal] load build definition from Dockerfile                                                                                                                                   0.0s
=> => transferring dockerfile: 60B                                                                                                                                                    0.0s
=> [internal] load .dockerignore                                                                                                                                                      0.0s
=> => transferring context: 2B                                                                                                                                                        0.0s
failed to solve with frontend dockerfile.v0: failed to read dockerfile: open /var/lib/docker/tmp/buildkit-mount184854581/common/Dockerfile: no such file or directory

DOCKER_BUILDKIT=0 docker build -t repro-7397 microservice_a/
unable to open Dockerfile: open : no such file or directory

DOCKER_BUILDKIT=1 docker build -t repro-7397 -f microservice_a/Dockerfile microservice_a/
[+] Building 0.0s (2/2) FINISHED
 => [internal] load .dockerignore                                                                                                                                                      0.0s
 => => transferring context: 2B                                                                                                                                                        0.0s
 => [internal] load build definition from Dockerfile                                                                                                                                   0.0s
 => => transferring dockerfile: 60B                                                                                                                                                    0.0s
failed to solve with frontend dockerfile.v0: failed to read dockerfile: open /var/lib/docker/tmp/buildkit-mount620518338/common/Dockerfile: no such file or directory

DOCKER_BUILDKIT=0 docker build -t repro-7397 -f microservice_a/Dockerfile microservice_a/
Sending build context to Docker daemon  2.095kB
Step 1/2 : FROM nginx:alpine
 ---> 377c0837328f
Step 2/2 : RUN echo hello
 ---> Using cache
 ---> 490312e05310
Successfully built 490312e05310
Successfully tagged repro-7397:latest
```

So looking at those combinations:

- :x: `DOCKER_BUILDKIT=0` and only build-context specified
- :x: `DOCKER_BUILDKIT=1` and only build-context specified
- :white_check_mark: `DOCKER_BUILDKIT=0` and both build-context and `-f` (path to Dockerfile)
- :x: `DOCKER_BUILDKIT=1` and both build-context and `-f` (path to Dockerfile)

Testing the same with `docker-compose`:

```bash
cat > docker-compose.yml <<EOF
version: ""3.7""
services:
  test:
    build:
      context: microservice_a
      dockerfile: Dockerfile
EOF
```

- :white_check_mark: `DOCKER_BUILDKIT=0 COMPOSE_DOCKER_CLI_BUILD=1 docker-compose build`
- :x: `DOCKER_BUILDKIT=1 COMPOSE_DOCKER_CLI_BUILD=1 docker-compose build`

Results there look the same; it looks like there's a difference in behavior between buildkit and non-buildkit; I think that should be fixed in the docker cli (or buildkit)
                             

--

--
ping @tonistiigi @tiborvass PTAL ^
--

--
From a conversation with @tonistiigi on Slack;

> this is similar to https://github.com/docker/cli/issues/2249 . same fix and workaround
> buildkit shares always need to have root path and symlinks are not allowed to escape out of it
> so if we dont want this to be true for dockerfile and think that dockerfile can be anywhere in the system we need to make a copy and share that instead.

Regarding this;

> buildkit shares always need to have root path and symlinks are not allowed to escape out of it

I think it makes sense to limit scope if only a build-context is passed (as in: if a build-context is passed, scope the build to that context). _However_ for the ""root"" of the build-context, we allow that root itself to be a symlink; this is what's currently supported:

1. resolve the root of the build-context
   - if the specified path is a symlink, follow that symlink, and use its target as the build-context
2. start the build using the resolved path

One use-case for this is, if (for example) one maintains a directory linking to projects stored elsewhere (the ""real"" project directory may be a path somewhere nested deeply);

```bash
mkdir repro-7397 && cd repro-7397
mkdir -p go/src/github.com/bar/project-a myprojects

cat > go/src/github.com/bar/project-a/Dockerfile <<EOF
FROM nginx:alpine
RUN echo hello project-a
EOF

cd myprojects \
&& ln -s ../go/src/github.com/bar/project-a project-a \
&& cd ..
```

Directory now looks like;

```bash
tree
.
 go
  src
      github.com
          bar
              project-a
                  Dockerfile
 myprojects
     project-a -> ../go/src/github.com/bar/project-a
```

With the above, these work:

```bash
DOCKER_BUILDKIT=0 docker build -t project-a myprojects/project-a
DOCKER_BUILDKIT=1 docker build -t project-a myprojects/project-a
```

However, escaping out of the _specified_ build-context should not work, so in the example below, ""project-b""'s Dockerfile is a symlink to ""project-a""'s Dockerfile:

```bash
mkdir -p go/src/github.com/bar/project-b-symlinked-dockerfile \
&& cd go/src/github.com/bar/project-b-symlinked-dockerfile \
&& ln -s ../project-a/Dockerfile Dockerfile \
&& cd ../../../../../myprojects/ \
&& ln -s ../go/src/github.com/bar/project-b-symlinked-dockerfile/ project-b \
&& cd ..

tree
.
 go
  src
      github.com
          bar
              project-a
               Dockerfile
              project-b-symlinked-dockerfile
                  Dockerfile -> ../project-a/Dockerfile
 myprojects
     project-a -> ../go/src/github.com/bar/project-a
     project-b -> ../go/src/github.com/bar/project-b-symlinked-dockerfile/
```

This currently fails (as expected), because although ""project-b""'s directory was found, the Dockerfile is outside of its context;

```bash
DOCKER_BUILDKIT=0 docker build -t project-b myprojects/project-b
unable to open Dockerfile: open : no such file or directory

DOCKER_BUILDKIT=1 docker build -t project-b myprojects/project-b
[+] Building 0.0s (2/2) FINISHED
 => [internal] load build definition from Dockerfile      0.0s
 => => transferring dockerfile: 63B                       0.0s
 => [internal] load .dockerignore                         0.0s
 => => transferring context: 2B                           0.0s
failed to solve with frontend dockerfile.v0: failed to read dockerfile: open /var/lib/docker/tmp/buildkit-mount011317083/project-a/Dockerfile: no such file or directory
```

I think the situation when explicitly providing the path to the Dockerfile _should_ work, and follow the same rules;

1. resolve the path of the specified Dockerfile
   - if the specified path is a symlink, follow that symlink, and use its target as the path for the Dockerfile
2. start the build using resolved Dockerfile

This currently works without buildkit (in this example, both the specified context and Dockerfile are resolved through symlinks before starting the build);

```bash
DOCKER_BUILDKIT=0 docker build -t project-b  -f myprojects/project-b/Dockerfile myprojects/project-b
```

But fails with BuildKit;

```bash
DOCKER_BUILDKIT=1 docker build -t project-b  -f myprojects/project-b/Dockerfile myprojects/project-b
```

One issue would not be ""resolved"" (and would have to be discussed, probably should not be supported);

BuildKit supports having a per-Dockerfile `.dockerignore (`Dockerfile.dockerignore`), so if the `Dockerfile` is resolved through a symlink, should;

- the `Dockerfile.dockerignore` also be looked for in the resolved _directory_ of the Dockerfile? Doing so would break the ""sandbox"" where no content outside of the context should be read
- should the `Dockerfile.dockerignore` be looked for in the ""build-context""? (resolved path of `myprojects/project-b` in this example)?

@tonistiigi WDYT?


--

--
.
--

--
Yes, it did have activity, lol. Let me reopen
--
",stale,"
--
This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you for your contributions.

--

--
This issue has been automatically closed because it had not recent activity during the stale period.

--

--
This issue has been automatically marked as not stale anymore due to the recent activity.

--

--
This issue has been automatically marked as not stale anymore due to the recent activity.

--
",fsaintjacques,"
--
I'm facing this issue.
--
",,,,
7394,OPEN,Run docker-compose pull on specific yml files,kind/feature,2020-04-21 22:06:48 +0000 UTC,lastb0isct,Opened,,"
**Is your feature request related to a problem? Please describe.**
`docker-compose pull` does not have the ability to use separate yml files to specify what docker compose file you would like to run the pull task on.  This renders the pull function useless for people who have multiple automated docker-compose files and wants to pull the latest images for all.

**Describe the solution you'd like**
Have the ability to specify a docker-compose file with `-f`

**Describe alternatives you've considered**
Allow the ability for people to run docker-compose with a `--pull` option such as requested here: https://github.com/docker/compose/issues/3574
",,,,,,,,,,,,,,
7392,OPEN,Support `runtime` parameter in 3.x schema,kind/feature,2020-04-21 15:46:26 +0000 UTC,khimaros,Opened,,"**Is your feature request related to a problem? Please describe.**
I am trying to upgrade my configs from 2.3 to 3.x configuration version. However, I currently use the `runtime` parameter to selectively enable `runsc` for some containers.

**Describe the solution you'd like**
Provide a way to specify `runtime` in the 3.x schema.

**Describe alternatives you've considered**
The only alternatives I see is remaining on 2.3 or migrating off of docker-compose for managing my runsc containers.

**Additional context**
It appears that some work was done on this here https://github.com/docker/compose/pull/6240 but it does not appear to have made its way into [the 3.8 schema](https://github.com/docker/compose/blob/master/compose/config/config_schema_v3.8.json).",,,,,,,,,,,,,,
7391,OPEN,Add --quiet-pull to docker-compose run,kind/feature,2020-04-21 12:45:48 +0000 UTC,alanbccoe,Opened,,"-->

**Is your feature request related to a problem? Please describe.**
`docker-compose run` prints info on images it pulls which makes it difficult to grab the output when used in shell scripts. 

**Describe the solution you'd like**
`docker-compose up` has a flag `--quiet-pull` to disable printing that information. I'd like the same flag on `run` please.

**Describe alternatives you've considered**
Pulling then running, but it's easy to forget if you've already pulled the image but are using this on e.g. a CD system that hasn't pulled it yet. Then extra garbage gets added to your captured stdout (e.g. when doing `name=$(docker-compose run bash print-name.sh)`)

Also, it seems to print to stdout, so redirecting 2>/dev/null doesn't seem to work.

",,,,,,,,,,,,,,
7373,OPEN,docker-compose just hangs; no response,,2020-10-05 06:09:10 +0000 UTC,opaessens,Opened,,"
  - [x] I have tried with the latest version of my channel (Stable or Edge)
  - [x] I have uploaded Diagnostics
  - Diagnostics ID: 0AB4FD43-EB28-4D5A-B37A-43423D0057B6/20200416125337

### Expected behavior

Start docker-compose

### Actual behavior

Command just hangs - no response, high CPU load. Even when running docker-compose --help .

### Information
  - macOS Version: 10.15.4 (19E287)

Issue started today after rebooting. Installed docker yesterday and it worked until then.
Did some reinstalls already.
Tried all of the troubleshooting tips or other docker-compose issues on Github. Issue's still there.
Other commands like docker ps or docker info are running fine.

When hitting control+c some Python related errors are printed:
e.g. (Errors are varying, but all seem to be related to PyInstaller)
`ImportError: Loader FrozenImporter cannot handle module contextlibImportError: Loader FrozenImporter cannot handle module contextlib`


",,,SteffenAnders,"
--
same issue for me. any updates here?
--

--
We have solved the problem by installing docker-compose as a container. 
See https://docs.docker.com/compose/install/  ""Alternative Install Options"".

```
sudo curl -L --fail https://github.com/docker/compose/releases/download/1.26.0/run.sh -o /usr/local/bin/docker-compose
sudo chmod +x /usr/local/bin/docker-compose

docker-compose --version
```
--
",massardc,"
--
I am not sure if that can be helpful for you guys but I figured it was because of Kaspersky on my laptop. Disabling it before running docker-compose would make the command run as fast as expected.
--
",giaosudau,"
--
> We have solved the problem by installing docker-compose as a container.
> See https://docs.docker.com/compose/install/  ""Alternative Install Options"".
> 
> ```
> sudo curl -L --fail https://github.com/docker/compose/releases/download/1.26.0/run.sh -o /usr/local/bin/docker-compose
> sudo chmod +x /usr/local/bin/docker-compose
> 
> docker-compose --version
> ```

This work for me.  On Mac 10.15.6. Edge version.
--
",,,,,,
7370,OPEN,Pre-built binary for aarch64?,kind/feature,2020-08-11 03:18:59 +0000 UTC,uberhacker,Opened,,"I was able to install from source on Debian 10 with Docker installed.
```bash
$ wget https://github.com/docker/compose/archive/1.25.5.tar.gz
$ tar xvf 1.25.5.tar.gz
$ cd compose-1.25.5
$ sudo apt install python3-pip libffi-dev
$ sudo python3 setup.py install
```",,,samip5,"
--
This really needs to be done. :)
--
",Doom4535,"
--
@samip5 or at least update the [install instructions](https://docs.docker.com/compose/install/) to document the build steps (or even just update the [README.md](https://github.com/docker/compose/blob/master/README.md) or add an INSTALL.txt file) to reference this if they don't want to post it yet on the site.
--
",,,,,,,,
7368,OPEN,docker-compose run on the openwrt routing system,kind/feature,2020-04-19 22:21:53 +0000 UTC,peterwillcn,Opened,,"Will docker-compose run on the openwrt routing system?

https://github.com/openwrt/packages/blob/d730fd501a2cc2759b9492778d5fd81308f529fe/utils/docker-ce/Makefile",,,jmarcet,"
--
I updated today all the pull requests. Sorry for the delay.

--
",,,,,,,,,,
7355,OPEN,Backport ports long syntax to file format 2,kind/feature,2020-04-11 05:22:07 +0000 UTC,SuperSandro2000,Opened,,"-->

**Is your feature request related to a problem? Please describe.**
I don't want to put a container in ``network_mode: host`` but still need the original ip of http requests.

**Describe the solution you'd like**
Backport https://docs.docker.com/compose/compose-file/#long-syntax-1 to file format 2.x so that I can publish a single port in host mode.

**Describe alternatives you've considered**
Switching to file format 3 which does not work for me as I need to limit memory usage for containers which is only possible in docker swarm mode which I am not using and don't plan to use in the future. I can't put the container in ``network_mode: host`` as it shouldn't have access to all other containers and I couldn't put it into networks anymore.

**Additional context**

",,,,,,,,,,,,,,
7352,OPEN,Request: handle quotation marks in .env files similar to other .env parsers,kind/feature,2020-07-28 07:39:24 +0000 UTC,mikemaccana,Opened,,"### Suggestions for a fix

Cases like https://github.com/docker/docker.github.io/issues/123 and https://github.com/docker/compose/issues/7164 show a lot of people have been bit by quotation marks becoming part of the value. People may be surprised about this, as most other `.env` parsers do not consider quotes part of the value. For example:

 - `dotenv`, the common node.js parser, handles quotes
 - Sourcing a `.env` on the shell will handle quotes
 - Most other platform specific parsers will handle quotes

https://github.com/docker/docker.github.io/blob/master/compose/env-file.md mentions:

> There is no special handling of quotation marks. This means that they are part of the VAL.

However rather than have people discover this, it may be better to simply handle quotation marks and not include the quote marks in the value. 

In our case, we have an iOS developer and a backend developer with different environments due to different parsing tools, and we've spent a bunch of time working out why an API key wasn't working, involving a third party, before working out that `docker-compose` doesn't handle quotes the same way as other tools, and eventually stumbling on the documentation that says that. I suspect we're not the only one.",,,cailloumajor,"
--
Hello, is this issue fixed by #7150?
--
",,,,,,,,,,
7348,OPEN,"docker-compose 1.26.0-rc3 from Docker Desktop for macOS doesn't use TLS (""Client sent an HTTP request to an HTTPS server."")",kind/bug,2020-09-24 12:52:59 +0000 UTC,mxl,Opened,,"## Context information (for bug reports)

**Output of `docker-compose version`**
```
docker-compose version 1.26.0-rc3, build 46118bc5
docker-py version: 4.2.0
CPython version: 3.7.6
OpenSSL version: OpenSSL 1.1.1d  10 Sep 2019
```

**Output of `docker version` (Docker Desktop for macOS)**
```
Client: Docker Engine - Community
 Version:           19.03.8
 API version:       1.40
 Go version:        go1.12.17
 Git commit:        afacb8b
 Built:             Wed Mar 11 01:21:11 2020
 OS/Arch:           darwin/amd64
 Experimental:      false

Server: Docker Engine - Community
 Engine:
  Version:          19.03.8
  API version:      1.40 (minimum version 1.12)
  Go version:       go1.12.17
  Git commit:       afacb8b
  Built:            Wed Mar 11 01:29:16 2020
  OS/Arch:          linux/amd64
  Experimental:     true
 containerd:
  Version:          v1.2.13
  GitCommit:        7ad184331fa3e55e52b890ea95e65ba581ae3429
 runc:
  Version:          1.0.0-rc10
  GitCommit:        dc9208a3303feef5b3839f4323d9beb36df0a9dd
 docker-init:
  Version:          0.18.0
  GitCommit:        fec3683
```

**Output of `docker version` (docker-ce package on Ubuntu)**
```
Client: Docker Engine - Community
 Version:           19.03.8
 API version:       1.40
 Go version:        go1.12.17
 Git commit:        afacb8b7f0
 Built:             Wed Mar 11 01:25:46 2020
 OS/Arch:           linux/amd64
 Experimental:      false

Server: Docker Engine - Community
 Engine:
  Version:          19.03.8
  API version:      1.40 (minimum version 1.12)
  Go version:       go1.12.17
  Git commit:       afacb8b7f0
  Built:            Wed Mar 11 01:24:19 2020
  OS/Arch:          linux/amd64
  Experimental:     false
 containerd:
  Version:          1.2.13
  GitCommit:        7ad184331fa3e55e52b890ea95e65ba581ae3429
 runc:
  Version:          1.0.0-rc10
  GitCommit:        dc9208a3303feef5b3839f4323d9beb36df0a9dd
 docker-init:
  Version:          0.18.0
  GitCommit:        fec3683
```

**Output of `docker-compose config`**
(Make sure to add the relevant `-f` and other flags)
```
services:
  gitlab:
    container_name: gitlab
    domainname: gitlab.example.com
    hostname: gitlab
    image: gitlab/gitlab-ce:latest
    ports:
    - 127.0.0.1:8050:80/tcp
    - 0.0.0.0:2022:22/tcp
    restart: always
version: '2.0'
```

## Steps to reproduce the issue

1. Install Docker Desktop for Mac from edge channel version 2.2.3.0 (43965)
2. Install docker on remote host using docker-machine (see [this guide](https://dev.to/zac_siegel/using-docker-machine-to-provision-a-remote-docker-host-1267)) with name and host `example.com` (use your own docker host IP or domain here).
3. Run `eval $(docker-machine env example.com)` command in current shell which will setup following environment variables:
```
export DOCKER_TLS_VERIFY=""1""
export DOCKER_HOST=""tcp://example.com:2376""
export DOCKER_CERT_PATH=""/Users/mledin/.docker/machine/machines/example.com""
export DOCKER_MACHINE_NAME=""example.com""
```
4. Try to pull image for `gitlab` service (see above `docker-compose config` output) or run any other command that will interact with remote docker host.

```bash
$ docker-compose pull gitlab
```

### Observed result
```
ERROR: Client sent an HTTP request to an HTTPS server.
```
or with `--verbose` option:
```
compose.config.config.find: Using configuration files: ./docker-compose.yml
docker.utils.config.find_config_file: Trying paths: ['/Users/mledin/.docker/config.json', '/Users/mledin/.dockercfg']
docker.utils.config.find_config_file: Found file at path: /Users/mledin/.docker/config.json
docker.auth.load_config: Found 'auths' section
docker.auth.parse_auth: Auth data for https://index.docker.io/v1/ is absent. Client might be using a credentials store instead.
docker.auth.load_config: Found 'credsStore' section
urllib3.connectionpool._new_conn: Starting new HTTP connection (1): example.com:2376
urllib3.connectionpool._make_request: http://example.com:2376 ""GET /v1.22/version HTTP/1.1"" 400 None
Traceback (most recent call last):
  File ""site-packages/docker/api/client.py"", line 261, in _raise_for_status
  File ""site-packages/requests/models.py"", line 940, in raise_for_status
requests.exceptions.HTTPError: 400 Client Error: Bad Request for url: http://example.com:2376/v1.22/version

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""docker-compose"", line 6, in <module>
  File ""compose/cli/main.py"", line 72, in main
  File ""compose/cli/main.py"", line 125, in perform_command
  File ""compose/cli/command.py"", line 76, in project_from_options
  File ""compose/cli/command.py"", line 142, in get_project
  File ""compose/cli/docker_client.py"", line 50, in get_client
  File ""site-packages/docker/api/daemon.py"", line 181, in version
  File ""site-packages/docker/api/client.py"", line 267, in _result
  File ""site-packages/docker/api/client.py"", line 263, in _raise_for_status
  File ""site-packages/docker/errors.py"", line 31, in create_api_error_from_http_exception
docker.errors.APIError: 400 Client Error: Bad Request (""b'Client sent an HTTP request to an HTTPS server.'"")
[94780] Failed to execute script docker-compose
```

### Expected result

Pull gitlab image.

## Additional information

Removing /usr/local/bin/docker-compose symlink and installing docker-compose 1.25.4 from homebrew fixes the issue:

```
compose.config.config.find: Using configuration files: ./docker-compose.yml
docker.utils.config.find_config_file: Trying paths: ['/Users/mledin/.docker/config.json', '/Users/mledin/.dockercfg']
docker.utils.config.find_config_file: Found file at path: /Users/mledin/.docker/config.json
docker.auth.load_config: Found 'auths' section
docker.auth.parse_auth: Auth data for https://index.docker.io/v1/ is absent. Client might be using a credentials store instead.
docker.auth.load_config: Found 'credsStore' section
urllib3.connectionpool._new_conn: Starting new HTTPS connection (1): example.com:2376
urllib3.connectionpool._make_request: https://example.com:2376 ""GET /v1.22/version HTTP/1.1"" 200 860
compose.cli.command.get_client: docker-compose version 1.25.4, build unknown
docker-py version: 4.2.0
CPython version: 3.8.2
OpenSSL version: OpenSSL 1.1.1f  31 Mar 2020
compose.cli.command.get_client: Docker base_url: https://example.com:2376
compose.cli.command.get_client: Docker version: Platform={'Name': 'Docker Engine - Community'}, Components=[{'Name': 'Engine', 'Version': '19.03.8', 'Details': {'ApiVersion': '1.40', 'Arch': 'amd64', 'BuildTime': '2020-03-11T01:24:19.000000000+00:00', 'Experimental': 'false', 'GitCommit': 'afacb8b7f0', 'GoVersion': 'go1.12.17', 'KernelVersion': '4.15.0-91-generic', 'MinAPIVersion': '1.12', 'Os': 'linux'}}, {'Name': 'containerd', 'Version': '1.2.13', 'Details': {'GitCommit': '7ad184331fa3e55e52b890ea95e65ba581ae3429'}}, {'Name': 'runc', 'Version': '1.0.0-rc10', 'Details': {'GitCommit': 'dc9208a3303feef5b3839f4323d9beb36df0a9dd'}}, {'Name': 'docker-init', 'Version': '0.18.0', 'Details': {'GitCommit': 'fec3683'}}], Version=19.03.8, ApiVersion=1.40, MinAPIVersion=1.12, GitCommit=afacb8b7f0, GoVersion=go1.12.17, Os=linux, Arch=amd64, KernelVersion=4.15.0-91-generic, BuildTime=2020-03-11T01:24:19.000000000+00:00
compose.cli.verbose_proxy.proxy_callable: docker inspect_network <- ('gitlab_default')
urllib3.connectionpool._make_request: https://example.com:2376 ""GET /v1.22/networks/gitlab_default HTTP/1.1"" 404 41
...
```

Local machine OS where docker-compose and docker-machine are executed: macOS 10.15.4
docker-compose is installed with Docker Desktop for Mac from edge channel version 2.2.3.0 (43965).
Remote docker host OS: Ubuntu 18.04.4 LTS with 4.15.0-91-generic kernel.

docker on remote host is launched by systemd `/etc/systemd/system/docker.service`:
```
[Service]
ExecStart=/usr/bin/dockerd -H tcp://0.0.0.0:2376 -H unix:///var/run/docker.sock --storage-driver aufs --tlsverify --tlscacert /etc/docker/ca.pem --tlscert /etc/docker/server.pem --tlskey /etc/docker/server-key.pem --label provider=generic
LimitNOFILE=1048576
LimitNPROC=1048576
LimitCORE=infinity
Environment=

[Install]
WantedBy=multi-user.target
```",,,glenfordwilliams,"
--
having the same issue

docker-compose version

```
docker-compose version 1.26.0-rc3, build 46118bc5
docker-py version: 4.2.0
CPython version: 3.7.4
OpenSSL version: OpenSSL 1.1.1c  28 May 2019
```

docker version
``` 
Client: Docker Engine - Community
 Version:           19.03.8
 API version:       1.40
 Go version:        go1.12.17
 Git commit:        afacb8b
 Built:             Wed Mar 11 01:23:10 2020
 OS/Arch:           windows/amd64
 Experimental:      true

Server: Docker Engine - Community
 Engine:
  Version:          19.03.8
  API version:      1.40 (minimum version 1.12)
  Go version:       go1.12.17
  Git commit:       afacb8b
  Built:            Wed Mar 11 01:29:16 2020
  OS/Arch:          linux/amd64
  Experimental:     true
 containerd:
  Version:          v1.2.13
  GitCommit:        7ad184331fa3e55e52b890ea95e65ba581ae3429
 runc:
  Version:          1.0.0-rc10
  GitCommit:        dc9208a3303feef5b3839f4323d9beb36df0a9dd
 docker-init:
  Version:          0.18.0
  GitCommit:        fec3683
```
--
",gitoshh,"
--
Facing the same issue here. 
docker-compose version 
```1.26.0-rc3, build 46118bc5```
--
",oocx,"
--
I see the same problem. Fixed it by downgrading docker-compose to 1.25.4.
--
",scuml,"
--
Same issue in docker-compose version 1.26.0-rc4, build d279b7a8
--
",number5,"
--
Have same issue, upgraded docker-compose to 1.26.0 fixed it
```
 docker-compose version                                               [06-27 20:22]
docker-compose version 1.26.0, build unknown
docker-py version: 4.2.1
CPython version: 3.7.7
OpenSSL version: OpenSSL 1.1.1g  21 Apr 2020
```
--
",rlanore,"
--
Have same issue on dind alpine with pip install docker-compose
```
/builds/test-ci # docker-compose version
docker-compose version 1.27.3, build unknown
docker-py version: 4.3.1
CPython version: 3.8.5
OpenSSL version: OpenSSL 1.1.1g  21 Apr 2020
```

--
"
7347,OPEN,"docker-compose 1.26.0rc3 installed from pip fails with ""No module named 'dotenv'""",kind/bug,2020-11-18 00:18:16 +0000 UTC,mxl,Opened,,"## Description of the issue

docker-compose 1.26.0rc3 fails with ""No module named 'dotenv'"" error.

## Context information (for bug reports)

**Output of `docker-compose version`**
See above error.

**Output of `docker version`**
```
Client: Docker Engine - Community
 Version:           19.03.8
 API version:       1.40
 Go version:        go1.12.17
 Git commit:        afacb8b
 Built:             Wed Mar 11 01:21:11 2020
 OS/Arch:           darwin/amd64
 Experimental:      false

Server: Docker Engine - Community
 Engine:
  Version:          19.03.8
  API version:      1.40 (minimum version 1.12)
  Go version:       go1.12.17
  Git commit:       afacb8b
  Built:            Wed Mar 11 01:29:16 2020
  OS/Arch:          linux/amd64
  Experimental:     true
 containerd:
  Version:          v1.2.13
  GitCommit:        7ad184331fa3e55e52b890ea95e65ba581ae3429
 runc:
  Version:          1.0.0-rc10
  GitCommit:        dc9208a3303feef5b3839f4323d9beb36df0a9dd
 docker-init:
  Version:          0.18.0
  GitCommit:        fec3683
```

**Output of `docker-compose config`**

See above error.

## Steps to reproduce the issue

Install docker-compose 1.26.0rc3 from pip:
```bash
$ pip install docker-compose==1.26.0-rc3
```

Then running it:
```bash
$ docker-compose
```
gives:
```
Traceback (most recent call last):
  File ""/Users/mledin/.pyenv/versions/default/bin/docker-compose"", line 6, in <module>
    from compose.cli.main import main
  File ""/Users/mledin/.pyenv/versions/3.8.2/envs/default/lib/python3.8/site-packages/compose/cli/main.py"", line 24, in <module>
    from ..config import ConfigurationError
  File ""/Users/mledin/.pyenv/versions/3.8.2/envs/default/lib/python3.8/site-packages/compose/config/__init__.py"", line 5, in <module>
    from . import environment
  File ""/Users/mledin/.pyenv/versions/3.8.2/envs/default/lib/python3.8/site-packages/compose/config/environment.py"", line 8, in <module>
    import dotenv
ModuleNotFoundError: No module named 'dotenv'
```

Trying to install dotenv:
```bash
$ pip install dotenv
```
outputs
```
Collecting dotenv
  Using cached dotenv-0.0.5.tar.gz (2.4 kB)
    ERROR: Command errored out with exit status 1:
     command: /Users/mledin/.pyenv/versions/3.8.2/envs/default/bin/python3.8 -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'/private/var/folders/0v/9cjc_d9919qc2kk1wm9b4t5w0000gn/T/pip-install-62wejvik/dotenv/setup.py'""'""'; __file__='""'""'/private/var/folders/0v/9cjc_d9919qc2kk1wm9b4t5w0000gn/T/pip-install-62wejvik/dotenv/setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' egg_info --egg-base /private/var/folders/0v/9cjc_d9919qc2kk1wm9b4t5w0000gn/T/pip-install-62wejvik/dotenv/pip-egg-info
         cwd: /private/var/folders/0v/9cjc_d9919qc2kk1wm9b4t5w0000gn/T/pip-install-62wejvik/dotenv/
    Complete output (68 lines):
    Traceback (most recent call last):
      File ""/Users/mledin/.pyenv/versions/3.8.2/envs/default/lib/python3.8/site-packages/setuptools/sandbox.py"", line 154, in save_modules
        yield saved
      File ""/Users/mledin/.pyenv/versions/3.8.2/envs/default/lib/python3.8/site-packages/setuptools/sandbox.py"", line 194, in setup_context
        __import__('setuptools')
      File ""/private/var/folders/0v/9cjc_d9919qc2kk1wm9b4t5w0000gn/T/easy_install-b08izsyd/distribute-0.7.3/setuptools/__init__.py"", line 2, in <module>
      File ""/private/var/folders/0v/9cjc_d9919qc2kk1wm9b4t5w0000gn/T/easy_install-b08izsyd/distribute-0.7.3/setuptools/extension.py"", line 5, in <module>
      File ""/private/var/folders/0v/9cjc_d9919qc2kk1wm9b4t5w0000gn/T/easy_install-b08izsyd/distribute-0.7.3/setuptools/dist.py"", line 7, in <module>
      File ""/private/var/folders/0v/9cjc_d9919qc2kk1wm9b4t5w0000gn/T/easy_install-b08izsyd/distribute-0.7.3/setuptools/command/__init__.py"", line 8, in <module>
      File ""/private/var/folders/0v/9cjc_d9919qc2kk1wm9b4t5w0000gn/T/easy_install-b08izsyd/distribute-0.7.3/setuptools/command/install_scripts.py"", line 3, in <module>
      File ""/private/var/folders/0v/9cjc_d9919qc2kk1wm9b4t5w0000gn/T/easy_install-b08izsyd/distribute-0.7.3/pkg_resources.py"", line 1518, in <module>
    AttributeError: module 'importlib._bootstrap' has no attribute 'SourceFileLoader'

    During handling of the above exception, another exception occurred:

    Traceback (most recent call last):
      File ""<string>"", line 1, in <module>
      File ""/private/var/folders/0v/9cjc_d9919qc2kk1wm9b4t5w0000gn/T/pip-install-62wejvik/dotenv/setup.py"", line 13, in <module>
        setup(name='dotenv',
      File ""/Users/mledin/.pyenv/versions/3.8.2/envs/default/lib/python3.8/site-packages/setuptools/__init__.py"", line 144, in setup
        _install_setup_requires(attrs)
      File ""/Users/mledin/.pyenv/versions/3.8.2/envs/default/lib/python3.8/site-packages/setuptools/__init__.py"", line 139, in _install_setup_requires
        dist.fetch_build_eggs(dist.setup_requires)
      File ""/Users/mledin/.pyenv/versions/3.8.2/envs/default/lib/python3.8/site-packages/setuptools/dist.py"", line 716, in fetch_build_eggs
        resolved_dists = pkg_resources.working_set.resolve(
      File ""/Users/mledin/.pyenv/versions/3.8.2/envs/default/lib/python3.8/site-packages/pkg_resources/__init__.py"", line 780, in resolve
        dist = best[req.key] = env.best_match(
      File ""/Users/mledin/.pyenv/versions/3.8.2/envs/default/lib/python3.8/site-packages/pkg_resources/__init__.py"", line 1065, in best_match
        return self.obtain(req, installer)
      File ""/Users/mledin/.pyenv/versions/3.8.2/envs/default/lib/python3.8/site-packages/pkg_resources/__init__.py"", line 1077, in obtain
        return installer(requirement)
      File ""/Users/mledin/.pyenv/versions/3.8.2/envs/default/lib/python3.8/site-packages/setuptools/dist.py"", line 786, in fetch_build_egg
        return cmd.easy_install(req)
      File ""/Users/mledin/.pyenv/versions/3.8.2/envs/default/lib/python3.8/site-packages/setuptools/command/easy_install.py"", line 679, in easy_install
        return self.install_item(spec, dist.location, tmpdir, deps)
      File ""/Users/mledin/.pyenv/versions/3.8.2/envs/default/lib/python3.8/site-packages/setuptools/command/easy_install.py"", line 705, in install_item
        dists = self.install_eggs(spec, download, tmpdir)
      File ""/Users/mledin/.pyenv/versions/3.8.2/envs/default/lib/python3.8/site-packages/setuptools/command/easy_install.py"", line 890, in install_eggs
        return self.build_and_install(setup_script, setup_base)
      File ""/Users/mledin/.pyenv/versions/3.8.2/envs/default/lib/python3.8/site-packages/setuptools/command/easy_install.py"", line 1158, in build_and_install
        self.run_setup(setup_script, setup_base, args)
      File ""/Users/mledin/.pyenv/versions/3.8.2/envs/default/lib/python3.8/site-packages/setuptools/command/easy_install.py"", line 1144, in run_setup
        run_setup(setup_script, args)
      File ""/Users/mledin/.pyenv/versions/3.8.2/envs/default/lib/python3.8/site-packages/setuptools/sandbox.py"", line 233, in run_setup
        with setup_context(setup_dir):
      File ""/Users/mledin/.pyenv/versions/3.8.2/lib/python3.8/contextlib.py"", line 113, in __enter__
        return next(self.gen)
      File ""/Users/mledin/.pyenv/versions/3.8.2/envs/default/lib/python3.8/site-packages/setuptools/sandbox.py"", line 195, in setup_context
        yield
      File ""/Users/mledin/.pyenv/versions/3.8.2/lib/python3.8/contextlib.py"", line 131, in __exit__
        self.gen.throw(type, value, traceback)
      File ""/Users/mledin/.pyenv/versions/3.8.2/envs/default/lib/python3.8/site-packages/setuptools/sandbox.py"", line 166, in save_modules
        saved_exc.resume()
      File ""/Users/mledin/.pyenv/versions/3.8.2/envs/default/lib/python3.8/site-packages/setuptools/sandbox.py"", line 141, in resume
        six.reraise(type, exc, self._tb)
      File ""/Users/mledin/.pyenv/versions/3.8.2/envs/default/lib/python3.8/site-packages/setuptools/_vendor/six.py"", line 685, in reraise
        raise value.with_traceback(tb)
      File ""/Users/mledin/.pyenv/versions/3.8.2/envs/default/lib/python3.8/site-packages/setuptools/sandbox.py"", line 154, in save_modules
        yield saved
      File ""/Users/mledin/.pyenv/versions/3.8.2/envs/default/lib/python3.8/site-packages/setuptools/sandbox.py"", line 194, in setup_context
        __import__('setuptools')
      File ""/private/var/folders/0v/9cjc_d9919qc2kk1wm9b4t5w0000gn/T/easy_install-b08izsyd/distribute-0.7.3/setuptools/__init__.py"", line 2, in <module>
      File ""/private/var/folders/0v/9cjc_d9919qc2kk1wm9b4t5w0000gn/T/easy_install-b08izsyd/distribute-0.7.3/setuptools/extension.py"", line 5, in <module>
      File ""/private/var/folders/0v/9cjc_d9919qc2kk1wm9b4t5w0000gn/T/easy_install-b08izsyd/distribute-0.7.3/setuptools/dist.py"", line 7, in <module>
      File ""/private/var/folders/0v/9cjc_d9919qc2kk1wm9b4t5w0000gn/T/easy_install-b08izsyd/distribute-0.7.3/setuptools/command/__init__.py"", line 8, in <module>
      File ""/private/var/folders/0v/9cjc_d9919qc2kk1wm9b4t5w0000gn/T/easy_install-b08izsyd/distribute-0.7.3/setuptools/command/install_scripts.py"", line 3, in <module>
      File ""/private/var/folders/0v/9cjc_d9919qc2kk1wm9b4t5w0000gn/T/easy_install-b08izsyd/distribute-0.7.3/pkg_resources.py"", line 1518, in <module>
    AttributeError: module 'importlib._bootstrap' has no attribute 'SourceFileLoader'
    ----------------------------------------
ERROR: Command errored out with exit status 1: python setup.py egg_info Check the logs for full command output.
```

## Additional information

OS version: macOS 10.15.4
docker-compose 1.26.0rc3 installed with pip.
Tried both with Python 2.7 installed from homebrew and with Python 3.8.2 installed with pyenv-virtualenv.
",,,itavy,"
--
hi,

i encountered same error, i installed `python-dotenv` package and it worked

the error comes from missing dependency in [setup.py#L32](https://github.com/docker/compose/blob/1.26.x/setup.py#L32)

in master branch i see that python-dotenv is already listed as install dependency

Regards,
Octavian
--
",alexanderadam,"
--
~~I'm suddenly experiencing the same issue.~~ fixed in homebrew.
I installed [`docker-compose`](https://formulae.brew.sh/formula/docker-compose) ([source](https://github.com/Homebrew/homebrew-core/blob/master/Formula/docker-compose.rb)) via [Homebrew/Linuxbrew](https://docs.brew.sh/Homebrew-on-Linux) and I'm even getting this issue when checking the version:

```bash
$ docker-compose --version
Traceback (most recent call last):
  File ""/home/linuxbrew/.linuxbrew/bin/docker-compose"", line 33, in <module>
    sys.exit(load_entry_point('docker-compose==1.27.4', 'console_scripts', 'docker-compose')())
  File ""/home/linuxbrew/.linuxbrew/bin/docker-compose"", line 25, in importlib_load_entry_point
    return next(matches).load()
  File ""/home/linuxbrew/.linuxbrew/opt/python@3.9/lib/python3.9/importlib/metadata.py"", line 77, in load
    module = import_module(match.group('module'))
  File ""/home/linuxbrew/.linuxbrew/opt/python@3.9/lib/python3.9/importlib/__init__.py"", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File ""<frozen importlib._bootstrap>"", line 1030, in _gcd_import
  File ""<frozen importlib._bootstrap>"", line 1007, in _find_and_load
  File ""<frozen importlib._bootstrap>"", line 986, in _find_and_load_unlocked
  File ""<frozen importlib._bootstrap>"", line 680, in _load_unlocked
  File ""<frozen importlib._bootstrap_external>"", line 790, in exec_module
  File ""<frozen importlib._bootstrap>"", line 228, in _call_with_frames_removed
  File ""/home/linuxbrew/.linuxbrew/opt/python@3.9/lib/python3.9/site-packages/compose/cli/main.py"", line 20, in <module>
    from ..config import ConfigurationError
  File ""/home/linuxbrew/.linuxbrew/opt/python@3.9/lib/python3.9/site-packages/compose/config/__init__.py"", line 2, in <module>
    from . import environment
  File ""/home/linuxbrew/.linuxbrew/opt/python@3.9/lib/python3.9/site-packages/compose/config/environment.py"", line 5, in <module>
    import dotenv
ModuleNotFoundError: No module named 'dotenv'
```

There's also [a discussion at homebrew](https://github.com/Homebrew/discussions/discussions/37) for this.

**EDIT:** [this was fixed recently for homebrew](https://github.com/Homebrew/discussions/discussions/37#discussioncomment-93615)
--
",Anu2001dev,"
--
I first installed `python-dotenv` with `yay -S python-dotenv` and then I had to install `cached_property` with `pip install cached_property` after that everything was fine.
--
",,,,,,
7346,OPEN,Why does docker-compose log to STDERR for `Building ....` instead of STDOUT when executing docker-compose build,kind/bug,2020-11-29 16:03:16 +0000 UTC,devedse,In progress,,"3. When making a bug report, make sure you provide all required information. The easier it is for
   maintainers to reproduce, the faster it'll be fixed.
-->

## Description of the issue

I'm working on an Azure DevOps extension which needs to read the docker-compose build output. I was however running into the issue that the STDOUT had some missing log lines: (Lines with #### in front of it where missing from STDOUT)

```
##### Building sample1 <-- missing
Step 1/2 : FROM nginx:alpine
 ---> 377c0837328f
Step 2/2 : COPY . /usr/share/nginx/html
 ---> Using cache
 ---> 6cac8912ab73

Successfully built 6cac8912ab73
Successfully tagged sample1:latest
##### Building sample2 <-- missing
Step 1/2 : FROM nginx:alpine
 ---> 377c0837328f
Step 2/2 : COPY . /usr/share/nginx/html
 ---> Using cache
 ---> 6cac8912ab73

Successfully built 6cac8912ab73
Successfully tagged sample2:latest
```

I've been doing some investigation and have created a repository to reproduce this:
https://github.com/devedse/STDOUTMissingError/blob/master/README.md

As you can see there, apparently the lines `Building ...` are being written to STDERR instead of STDOUT.

Does anyone have any idea on why this is happening?

## Context information (for bug reports)

**Output of `docker-compose version`**
```
docker-compose version 1.25.4, build 8d51620a
```

**Output of `docker version`**
```
Client: Docker Engine - Community
 Version:           19.03.8
 API version:       1.40
 Go version:        go1.12.17
 Git commit:        afacb8b
 Built:             Wed Mar 11 01:23:10 2020
 OS/Arch:           windows/amd64
 Experimental:      false

Server: Docker Engine - Community
 Engine:
  Version:          19.03.8
  API version:      1.40 (minimum version 1.12)
  Go version:       go1.12.17
  Git commit:       afacb8b
  Built:            Wed Mar 11 01:29:16 2020
  OS/Arch:          linux/amd64
  Experimental:     false
 containerd:
  Version:          v1.2.13
  GitCommit:        7ad184331fa3e55e52b890ea95e65ba581ae3429
 runc:
  Version:          1.0.0-rc10
  GitCommit:        dc9208a3303feef5b3839f4323d9beb36df0a9dd
 docker-init:
  Version:          0.18.0
  GitCommit:        fec3683
```

**Output of `docker-compose config`**
See the repository linked above, I've added automated builds to that.

## Steps to reproduce the issue
1. Clone the repository linked above
2. Execute `tsc` in the ./src directory
3. Execute `node index.js` in the ./src directory

(Or simply check the build output in my repository)

### Observed result
```
Step 1/2 : FROM nginx:alpine
 ---> 377c0837328f
Step 2/2 : COPY . /usr/share/nginx/html
 ---> Using cache
 ---> 6cac8912ab73

Successfully built 6cac8912ab73
Successfully tagged sample1:latest
Step 1/2 : FROM nginx:alpine
 ---> 377c0837328f
Step 2/2 : COPY . /usr/share/nginx/html
 ---> Using cache
 ---> 6cac8912ab73

Successfully built 6cac8912ab73
Successfully tagged sample2:latest
```

### Expected result
```
Building sample1
Step 1/2 : FROM nginx:alpine
 ---> 377c0837328f
Step 2/2 : COPY . /usr/share/nginx/html
 ---> Using cache
 ---> 6cac8912ab73

Successfully built 6cac8912ab73
Successfully tagged sample1:latest
Building sample2
Step 1/2 : FROM nginx:alpine
 ---> 377c0837328f
Step 2/2 : COPY . /usr/share/nginx/html
 ---> Using cache
 ---> 6cac8912ab73

Successfully built 6cac8912ab73
Successfully tagged sample2:latest
```

### Stacktrace / full error message

Well technically :

```
Building sample1
Building sample2
```

But in fact, there's not really an error log.

## Additional information

Happens on both linux (Travis-ci) and windows (Appveyor)
",,,devedse,"
--
Could it have something to do with this line:

https://github.com/docker/compose/blob/13bacba2b9aecdf1f3d9a4aa9e01fbc1f9e293ce/compose/cli/main.py#L65

Apparently it was added in this commit by @bfirsh :
https://github.com/docker/compose/commit/6d0702e6075e8bdc9d4094fbd063214870f407cc

--

--
@shin- and everyone else

**STDOUT instead of STDERR**

I've been looking through some other Github issues and it seems that as of now this could be a choice made by the docker-compose team:

https://github.com/docker/compose/issues/5590
https://github.com/docker/compose/issues/5296
https://github.com/docker/compose/issues/5590#issuecomment-359110186

To me the choice to (ab)use STDERR to split logging for docker and docker-compose seems like a wrong decision.

StackExchange has some good information on how to use STDOUT and STDERR and I don't think docker-compose is complying to these standards:

https://unix.stackexchange.com/questions/331611/do-progress-reports-logging-information-belong-on-stderr-or-stdout

Let's see if the docker-compose team agrees on this as well and hopefully get this fixed as soon as possible.

**Some information on why this fix is important for me**

I'm currently parsing the logs of docker-compose but the best way to find out what build log belongs to what container is parsing through the log and finding the `Building ....` statement. As this states the beginning of a new container build. However since this specific line is missing in the docker-compose log it makes it a lot harder to find out what build belongs to what part of your docker-compose file.
--
",stale,"
--
This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you for your contributions.

--

--
This issue has been automatically marked as not stale anymore due to the recent activity.

--
",pwagland,"
--
I just came across this issue, since we have a build process that alerts us when something is printed to stderr we recently added `docker-compose`, and of course it alerts. We can (and are going to) redirected stderr to stdout, but then any _real_ errors won't be seen. It would be very useful to have this standard output _not_ turn up in the error stream.
--
",rjlasko,"
--
I agree that this is still an issue. Changing the log level does nothing to address writing output to STDERR.  I run this in cron and utilize cronic (which is highly regarded in the linux world) to send emails when actual errors occur. This is my crontab:

```
@hourly cronic docker-compose --log-level=ERROR --no-ansi --file ~/docker-compose.yml run --rm my_service
```

The log level does nothing for me, so i get the following in my emails:

```
Cronic detected failure or error output for the command:
docker-compose --log-level=ERROR --no-ansi --file ~/docker-compose.yml run --rm my_service

RESULT CODE: 0

ERROR OUTPUT:
Creating test_my_service_run ... 
Creating test_my_service_run ... done

STANDARD OUTPUT:
```
--
",phuxman,"
--
We are currently running into the same problem on our automatic deploy system. We have two solutions:
- Redirect STDERR -> No real error output. Make devs nervous.
- Leave it and ignore errors on deploy step.-> Pseudo-errors make devs nervous.

So we have nervous devs...

Maybe it is possible to do some intelligent redirecting by scripted parsing?


--
",ASHXOR,"
--
I have done something similar, redirected STDERR into a file, but then added a step into my pipe that will rely on an actual step failure to go and display the error log, I also added it as a step to display the error log on success pointing out that it contains these types of non error messages, then it was a matter of educating the devs about this.

--
"
7343,OPEN,Build same images only once; even they are used in multiple services,kind/feature,2020-04-03 10:28:46 +0000 UTC,adaamz,Opened,,"**Is your feature request related to a problem? Please describe.**
I'm always frustrated when same image is built multiple times.

**Describe the solution you'd like**
If one image (with same tag) is used in multiple services, docker-compose should be smart enough to not build it multiple times.

**Describe alternatives you've considered**
No existing alternative, `docker-compose up --build` also build it multiple times. Also I'm unable to use proper caching, because of https://github.com/docker/compose/issues/7342 problem.

**Additional context**
This docker-compose.yml should build only one image `web:${TAG}` once, not twice, when running command `docker-compose build`/`docker-compose up --build`.
Also when I run `docker-compose up my-web`/`my-web-saver`, it should build the image if not exists.
```yml
version: '3.2'
services:
    my-web:
        image: web:${TAG}
        build:
            cache_from:
                - web:${TAG}
                - web:latest
            context: web
            dockerfile: web/Dockerfile

    my-web-saver:
        image: web:${TAG}
        build:
            cache_from:
                - web:${TAG}
                - web:latest
            context: web
            dockerfile: web/Dockerfile
```",,,,,,,,,,,,,,
7341,OPEN,docker-compose up should support --tail option,kind/feature,2020-04-20 15:34:45 +0000 UTC,haggholm,Opened,,"-->

**Is your feature request related to a problem? Please describe.**

`docker-compose up` is usually the most straightforward way to run projects, but if existing containers have voluminous logs, it can tie up the output log for minutes at a time. 

**Describe the solution you'd like**

`docker-compose up` should support the same `--tail` option already provided by `docker-compose logs`. In particular, it would be great to have `docker-compose up --tail=0` to _not_ output any logs from previous runs.

**Describe alternatives you've considered**

I can sort of work around it with `docker-compose up --no-start ; docker-compose start ; docker-compose logs --follow --tail=100`, but thats convoluted and isnt quite as good UX even then, since `up` attaches to the logs in a more intuitive way.

**Additional context**

N/A",,,theycallmemac,"
--
@haggholm I too can see good use from this. I can take a look at this 
--
",,,,,,,,,,
7339,OPEN,Should not log a warning when environment variable value is specified in override file,kind/bug,2020-11-08 21:57:44 +0000 UTC,bburtin,Opened,,"3. When making a bug report, make sure you provide all required information. The easier it is for
   maintainers to reproduce, the faster it'll be fixed.
-->

## Description of the issue
When a **docker-compose.yml** property is set to an environment variable and **docker-compose.override.yml** specifies a fixed value, **docker-compose** incorrectly logs a warning.  This is misleading, and affects developer productivity.

This was reported in issue #4335.  I'm confused about why that issue was closed.  It sure looks like a bug to me.  Just because there's a workaround doesn't mean that the bug shouldn't be fixed.

## Context information (for bug reports)

**Output of `docker-compose version`**
```
$ docker-compose --version
docker-compose version 1.25.4, build 8d51620a
```

**Output of `docker version`**
```
$ docker --version                             
Docker version 19.03.8, build afacb8b7f0
```

**Output of `docker-compose config`**
(Make sure to add the relevant `-f` and other flags)
```
$ docker-compose config   
WARNING: The MYVAR_DEFAULT variable is not set. Defaulting to a blank string.
services:
  test:
    environment:
      MYVAR: my_value
    image: hello-world
version: '3.3'
```


## Steps to reproduce the issue

```
$ cat docker-compose.yml         
version: '3.3'
services:
  test:
    image: hello-world
    environment:
      MYVAR: ${MYVAR_DEFAULT}

$ cat docker-compose.override.yml 
version: '3.3'
services:
  test:
    environment:
      MYVAR: my_value
```

### Observed result
See **docker-compose config** output above.

### Expected result
Same result, but without the warning.

### Stacktrace / full error message

```
WARNING: The MYVAR_DEFAULT variable is not set. Defaulting to a blank string.
```

## Additional information

Ubuntu 18.04
",,,valtbarbos,"
--
Use --log-level ERROR (Set log level (DEBUG, INFO, WARNING, ERROR, CRITICAL))
--
",zoombinis,"
--
I also get this error with the following directory setup:
```
docker/base/.my.env
docker/base/docker-compose.yml     <- This contains my services that use the .env vars
docker/child/docker-compose.yml     <- This contains services that extend from base' services
```

When I run from `docker/child` directory: `docker-compose --env-file ../install/.my.env up`

It works great, no errors or warnings. But when I run `docker-compose down` I get the `WARNING` described in this issue, which is odd since the env vars work great during `up`.

Something to do with loading an env file in a directory separate from my context?


My use of `extends` in `docker/child/docker-compose.yml` is pretty basic:

```yml
  base:
    extends:
      file: ""../base/docker-compose.yml""
      service: ""extend-from-base""
```
--
",,,,,,,,
7337,OPEN,Error message on exec-ing a container that doesn't exist should honor container_name,kind/feature,2020-04-02 15:45:45 +0000 UTC,RussellRollins,Opened,,"-->

**Is your feature request related to a problem? Please describe.**
When a user `up`'s a docker-compose project with a service that has a `container_name` defined, then for some reason, that container dies, then the user attempts to `exec` into the service, they receive an error message with the default container name, rather than the name they have defined.

There have been some similar issues for `run` commands, but I did not see any discussion about the error message for `exec` commands.

**Describe the solution you'd like**
When a user `exec`'s a service where the container has died or been killed, the error message should use the `container_name` defined name.

**Describe alternatives you've considered**
It might also be possible to give a more generic message referencing the fact the container for the requested service has died, without providing the misleading default container name.



**Additional context**
Simple docker-compose File:

```yaml
version: ""2.0""

services:
  redis:
    image: redis:5.0.6
    container_name: ""my_project_redis
```

When I did:

```
$ docker-compose up --detach
Creating network ""test_default"" with the default driver
Creating my_project_redis ... done
$ docker-compose exec redis /bin/bash
root@e251d13265ee:/data# echo ""ok""
ok
root@e251d13265ee:/data# exit
exit
$ docker kill my_project_redis
my_project_redis
$ docker-compose exec redis /bin/bash
ERROR: No container found for redis_1
```

What I expected:

```
$ docker-compose exec redis /bin/bash
ERROR: No container found for my_project_redis
```

There was never a container for `redis_1`, it always had a different name. I think the behavior is correct, but the error message is misleading.",,,,,,,,,,,,,,
7326,OPEN,Support multiple .evn files,kind/feature,2020-09-15 05:21:56 +0000 UTC,aurelijusrozenas,Opened,,"It's pretty common to have multiple .env files to override settings and is used in many projects. Some of the examples would be:
- project may be configured for dev (`.env.dev`) and prod (`.env.prod`) stages and have general configuration applied to both stages (`.env`). 
- project may have standard configuration in `.env` and override some settings with `.env.local` for each developer.

Multiple file support is implemented for `docker run` and as `env_file` docker-compose property and it works well for environment variables in docker _container_. However different environment variables are very useful in _docker-compose.yaml_ too. E.g. I have a project where url is setup via labels and I do have different urls for prod and dev stages.

Right now I think the only way to have separated dev and prod stages is having two files with all options in both them but that is not DRY and error prone when adding/changing values.
",,,shaunco,"
--
Seems related to #7289 
--
",,,,,,,,,,
7323,OPEN,Support `extra_hosts` in `_CLIBuilder`,kind/feature,2020-08-27 11:19:03 +0000 UTC,tomaszzielinski,Opened,,"**Is your feature request related to a problem? Please describe.**

I'm using v2.4 yml as I need to pass `extra_hosts` to the builder and v3 doesn't seem to support that (yet). I'm evaluating using `docker-compose` with BuildKit but it seems that `extra_hosts` are not propagated all the way to the Docker CLI [1].

[1] https://github.com/docker/compose/blob/1.26.0-rc3/compose/service.py#L1790-L1802 

**Describe the solution you'd like**

It would be great if `_CLIBuilder` made use of `extra_hosts`, as they seem to be properly passed down to it [2].

[2] https://github.com/docker/compose/blob/1.26.0-rc3/compose/service.py#L1085-L1100

**Describe alternatives you've considered**

I tried mounting my own hosts file on top of `/etc/hosts` but it doesn't seem to be possible inside a ""normal"" (i.e. unpriviledged, etc.) container.

I also thought about patching `docker-compose` locally & maintaining a fork, but it doesn't really make sense given that the default (non-CLI) builder works correctly and that I don't stricly need BuildKit (it was meant to be a nice bonus).
",,,skokhanovskiy,"
--
Faced with same bug. I think that person who added `extra_hosts` support just forgot about existence of cli builder. So. that probably should be a bug.

Now I can't use buildkit because in my dockerfile there are images from intranet registry. The hostname of this registry are not resolving by google public dns.
--

--
So, i fixed issue with unavailable intranet DNS servers by using dnsmasq on the docker0 interface as dedicated DNS server for docker daemon.

Any way, I found that there are another unrealized command-line parameters:
* `labels` (fixed in #7242)
* `quiet`
* `rm`
*  `gzip` (`compress`) 
* `shmsize` (`shm-size`)
* `network_mode` (`network`)
* `extra_hosts` (`add-host`) 
* `isolation`

This options above are not working if they are specified in a docker-conpose file and `docker-compose build` start with the `COMPOSE_DOCKER_CLI_BUILD=1` environment variable.
--
",thaJeztah,"
--
Yes, not all options were added in the first implementation of the ""cli"" based build (also see https://github.com/docker/compose/pull/6584#issuecomment-513210065). I think it makes sense to add this though, so contributions welcome.

That said, I think this option can be added to the `v3` schema as well, to bring parity with `v2`. This option is already supported by both the ""classic"" and BuildKit builders, so I don't see a reason for not adding it.
--

--
opened https://github.com/docker/cli/pull/2517 - if that's accepted, this can be implemented in compose when support for the 3.9 schema is added
--

--
Not sure; there's changes merged in this repository to support the ""unified"" schema (https://github.com/compose-spec/compose-spec), so perhaps it's supported own the latest version

@aiordache do you know?
--
",syabro,"
--
@thaJeztah https://github.com/docker/cli/pull/2517 is merged. What's next here? :)
--

--
@thaJeztah any news?
--
",,,,,,
7320,OPEN,--renew-named-volumes option on `up` to reinitialize data,kind/feature,2020-03-26 06:31:49 +0000 UTC,slavdok,Opened,,"**Is your feature request related to a problem? Please describe.**
It is unnecessarily complicated to _refresh/update_ the contents of **named volume** from container.  When a named volume is created, it is initialized with the contents of directory from container. This behaviour is consistent between `docker` and `docker-compose` commands.

But if the image is updated and it changes that initial content, the volume is not reinitialized. Using `docker` it's possible to manually delete that volume. Using `docker-compose`, only `down -v` would delete it, but that applies to _all services_. The `down` command doesn't allow specifying a _single service_, and the `stop` command doesn't have the `-v` option. 

In a multi-service compose file, it is therefore outright impossible to reinitialize (or delete/recreate) the volume using `docker-compose`. Things only get more complicated when the named volume is shared by multiple services, as all containers must be removed (not just stopped) to delete/recreate the volume.

**Describe the solution you'd like**
Command `docker-compose up` has the following options:

```
-V, --renew-anon-volumes   Recreate anonymous volumes instead of retrieving
                           data from the previous containers.
```
The option to recreate volume is already there, but it's limited to anonymous volumes only. Why? I suppose that when it was added, named volumes didn't exist yet? Either way, why would anon volumes get this feature while named volumes wouldn't? 

I would like `--renew-named-volumes` option.

I understand there could be concurrency issues when using shared named volumes, but that could be mitigated when all other containers are mounting the volume as `ro` and only one does the (re)initialization. Please give me the option, print a warning if you must, and let me decide if I want to risk concurrency and/or open handles issues.

**Describe alternatives you've considered**
One alternative I had working was a complex shell script that identified all running/stopped containers using a specific named volume, and then removing containers, removing volume and re-creating containers with reinitialized volume. The trouble was that if some containers using this named volume were created outside the current compose file (using `volumes external: true`), there was no way to bring them back without knowing what compose file launched them (or if they were launched by `docker` instead). Also, so much downtime across so many services wasn't ideal.

Another solution that I am currently employing is keeping the image's volume-destined content outside of the actual volume, and then a needlessly large `entrypoint.sh` script `rsyncs` from this ""backup"" location on container into the volume location, based on `cmd` that's passed (cause I need to control when the volume is reinitialized and when it isn't). Dependency on `rsync` prevents me from using `FROM: scratch` filesystem-only image (which would be ideal for my scenario)",,,,,,,,,,,,,,
7319,OPEN,Failed to execute script docker-compose when doing docker-compose up on SSH context,kind/bug,2021-01-30 17:14:36 +0000 UTC,bibekg,Opened,,"3. When making a bug report, make sure you provide all required information. The easier it is for
   maintainers to reproduce, the faster it'll be fixed.
-->

## Description of the issue

[Saw this post detailing how to use contexts](https://www.docker.com/blog/how-to-deploy-on-remote-docker-hosts-with-docker-compose/) with the upcoming docker-compose 1.26.0-rc3 release and tried to give it a shot. I then installed that pre-release version on both my local machine which has the application source code and the new EC2 machine that I want to deploy to and created a context called `rolocha-staging` which connects to the docker engine in the EC2 instance. Then I tried to deploy my docker-compose app to it using either
```
docker context use rolocha-staging
docker-compose --env-file .env.staging -f docker-compose.yml -f docker-compose.staging.yml up -d
```
or
```
docker-compose --context rolocha-staging --env-file .env.staging -f docker-compose.yml -f docker-compose.staging.yml up -d
```
but both approaches are resulting in the error/stacktrace included below.

If I execute in the default context (i.e. use `--context default` argument or `docker context use default` command), everything works smoothly.

## Context information (for bug reports)

**Output of `docker-compose version`**
```
docker-compose version 1.26.0-rc3, build 46118bc5
```

**Output of `docker version`**
```
Docker version 19.03.8, build afacb8b
```

**Output of `docker-compose config`**
(Make sure to add the relevant `-f` and other flags)
```
networks:
  app-network:
    driver: bridge
services:
  client:
    build:
      context: /Users/bibek/Developer/RoloCha/client
    command: npx serve -s build -l 4000
    container_name: rolocha-client
    environment:
      APP_CLIENT_PORT: '4000'
      APP_SERVER_PORT: '3000'
      MONGO_DB_NAME: rolocha-dev
      MONGO_HOSTNAME: db
      MONGO_PASSWORD: [redacted]
      MONGO_PORT: '27017'
      MONGO_USERNAME: admin
      NODE_ENV: development
    expose:
    - '4000'
    image: roloch4/client-staging:latest
    networks:
      app-network: {}
    ports:
    - 4000:4000/tcp
    restart: always
  db:
    container_name: db
    environment:
      APP_CLIENT_PORT: '4000'
      APP_SERVER_PORT: '3000'
      MONGO_DB_NAME: rolocha-dev
      MONGO_HOSTNAME: db
      MONGO_INITDB_ROOT_PASSWORD: ''
      MONGO_INITDB_ROOT_USERNAME: ''
      MONGO_PASSWORD: [redacted]
      MONGO_PORT: '27017'
      MONGO_USERNAME: admin
      NODE_ENV: development
    image: mongo
    networks:
      app-network: {}
    ports:
    - 27017:27017/tcp
    volumes:
    - dbdata:/data/db:rw
  nginx:
    container_name: nginx
    image: nginx:latest
    networks:
      app-network: {}
    ports:
    - 80:80/tcp
    - 443:443/tcp
    restart: always
    volumes:
    - /Users/bibek/Developer/RoloCha/nginx-conf/nginx.conf:/etc/nginx/nginx.conf:rw
  server:
    build:
      context: /Users/bibek/Developer/RoloCha/server
    command: yarn start
    container_name: rolocha-server
    environment:
      APP_CLIENT_PORT: '4000'
      APP_SERVER_PORT: '3000'
      MONGO_DB_NAME: rolocha-dev
      MONGO_HOSTNAME: db
      MONGO_PASSWORD: [redacted]
      MONGO_PORT: '27017'
      MONGO_USERNAME: admin
      NODE_ENV: development
    expose:
    - '3000'
    image: roloch4/server-staging:latest
    networks:
      app-network: {}
    ports:
    - 3000:3000/tcp
    restart: always
version: '3.0'
volumes:
  dbdata: {}
  node_modules_c: {}
  node_modules_s: {}
```


## Steps to reproduce the issue

1. Create a remote context connecting to an EC2 instance via SSH using `docker context create`
2. Switch to that context using `docker context use <context-name>`
3. Try to deploy the local docker-compose app to the remote context using `docker-compose up`

### Observed result

Error message above

### Expected result

No error message, starts up the docker-compose services in remote machine

### Stacktrace / full error message

```
Traceback (most recent call last):
  File ""docker-compose"", line 6, in <module>
  File ""compose/cli/main.py"", line 72, in main
  File ""compose/cli/main.py"", line 125, in perform_command
  File ""compose/cli/command.py"", line 54, in project_from_options
  File ""compose/cli/docker_client.py"", line 41, in load_context
  File ""site-packages/docker/context/api.py"", line 97, in get_context
  File ""site-packages/docker/context/context.py"", line 61, in load_context
  File ""site-packages/docker/context/context.py"", line 87, in _load_meta
KeyError: 'StackOrchestrator'
[92007] Failed to execute script docker-compose
make: *** [stageup] Error 255
```

## Additional information

Running macOS Catalina 10.15.4

Installed docker-compose v1.2.6-rc3 on both local machine and EC2 instance using
```
curl -L https://github.com/docker/compose/releases/download/1.26.0-rc3/docker-compose-`uname -s`-`uname -m` -o /usr/local/bin/docker-compose
chmod +x /usr/local/bin/docker-compose
```
",,,icarus42,"
--
I was able to fix this issue by adding the parameter `--default-stack-orchestrator swarm` when creating the context:

    docker context create NAME --description ""DESCRIPTION"" --docker ""host=ssh://user@example"" --default-stack-orchestrator swarm

After that, I had the issue that compose could not access my encrypted SSH private key. I just decrypted it for now...

Worked for:
- docker compose: 1.26.0-rc3, build 46118bc5
- docker ce: 19.03.8
--
",kylelemons,"
--
I ran into the same issue:

```
$ docker-compose --context=remote logs letsencrypt
Traceback (most recent call last):
  File ""docker-compose"", line 6, in <module>
  File ""compose\cli\main.py"", line 72, in main
  File ""compose\cli\main.py"", line 125, in perform_command
  File ""compose\cli\command.py"", line 54, in project_from_options
  File ""compose\cli\docker_client.py"", line 41, in load_context
  File ""site-packages\docker\context\api.py"", line 97, in get_context
  File ""site-packages\docker\context\context.py"", line 61, in load_context
  File ""site-packages\docker\context\context.py"", line 87, in _load_meta
KeyError: 'StackOrchestrator'
[29084] Failed to execute script docker-compose
```

The same fix worked for me:
```
$ docker context update remote --default-stack-orchestrator swarm
```

---

Local (Windows 10):
```
$ docker version
Client: Docker Engine - Community
 Version:           19.03.8
 API version:       1.40
 Go version:        go1.12.17
 Git commit:        afacb8b
 Built:             Wed Mar 11 01:23:10 2020
 OS/Arch:           windows/amd64
 Experimental:      false

Server:
 Engine:
  Version:          19.03.6
  API version:      1.40 (minimum version 1.12)
  Go version:       go1.13.5
  Git commit:       369ce74
  Built:            Wed May  6 07:28:37 2020
  OS/Arch:          linux/amd64
  Experimental:     false
 containerd:
  Version:          1.3.2
  GitCommit:        ff48f57fc83a8c44cf4ad5d672424a98ba37ded6
 runc:
  Version:          1.0.0-rc10
  GitCommit:
 docker-init:
  Version:          0.18.0
  GitCommit:        fec3683b971d9c3ef73f284f176672c44b448662
```

Remote (gce instance running cos, latest stable):
```
$ docker --host=localhost:22122 version
Client: Docker Engine - Community
 Version:           19.03.8
 API version:       1.40
 Go version:        go1.12.17
 Git commit:        afacb8b
 Built:             Wed Mar 11 01:23:10 2020
 OS/Arch:           windows/amd64
 Experimental:      false

Server:
 Engine:
  Version:          19.03.6
  API version:      1.40 (minimum version 1.12)
  Go version:       go1.13.5
  Git commit:       369ce74
  Built:            Wed May  6 07:28:37 2020
  OS/Arch:          linux/amd64
  Experimental:     false
 containerd:
  Version:          1.3.2
  GitCommit:        ff48f57fc83a8c44cf4ad5d672424a98ba37ded6
 runc:
  Version:          1.0.0-rc10
  GitCommit:
 docker-init:
  Version:          0.18.0
  GitCommit:        fec3683b971d9c3ef73f284f176672c44b448662
```

Compose:
```
$ docker-compose version
docker-compose version 1.26.0-rc4, build d279b7a8
docker-py version: 4.2.0
CPython version: 3.7.4
OpenSSL version: OpenSSL 1.1.1c  28 May 2019     
```
--
",azhang,"
--
The above post by @kylelemons fixed some stuff for me, but I get the following issue with and without --context set for docker-compose.

```
~/s/b/d/nginx-certbot git:master  docker-compose-pre --context btapi-dev up                                                                   
Starting nginx-certbot_certbot_1 ... 
Starting nginx-certbot_nginx_1   ... 
ERROR: Secsh channel 12 open FAILED: open failed: Connect failed
Starting nginx-certbot_certbot_1 ... done
ERROR: for nginx-certbot_nginx_1  ChannelException(2, 'Connect failed')

ERROR: for nginx  ChannelException(2, 'Connect failed')
Traceback (most recent call last):
  File ""docker-compose"", line 6, in <module>
  File ""compose/cli/main.py"", line 72, in main
  File ""compose/cli/main.py"", line 128, in perform_command
  File ""compose/cli/main.py"", line 1078, in up
  File ""compose/cli/main.py"", line 1074, in up
  File ""compose/project.py"", line 576, in up
  File ""compose/parallel.py"", line 112, in parallel_execute
  File ""compose/parallel.py"", line 210, in producer
  File ""compose/project.py"", line 562, in do
  File ""compose/service.py"", line 569, in execute_convergence_plan
  File ""compose/service.py"", line 511, in _execute_convergence_start
  File ""compose/parallel.py"", line 112, in parallel_execute
  File ""compose/parallel.py"", line 210, in producer
  File ""compose/service.py"", line 509, in <lambda>
  File ""compose/service.py"", line 620, in start_container_if_stopped
  File ""compose/container.py"", line 215, in attach_log_stream
  File ""compose/container.py"", line 307, in attach
  File ""site-packages/docker/utils/decorators.py"", line 19, in wrapped
  File ""site-packages/docker/api/container.py"", line 60, in attach
  File ""site-packages/docker/utils/decorators.py"", line 46, in inner
  File ""site-packages/docker/api/client.py"", line 226, in _post
  File ""site-packages/requests/sessions.py"", line 581, in post
  File ""site-packages/requests/sessions.py"", line 533, in request
  File ""site-packages/requests/sessions.py"", line 646, in send
  File ""site-packages/requests/adapters.py"", line 449, in send
  File ""site-packages/urllib3/connectionpool.py"", line 677, in urlopen
  File ""site-packages/urllib3/connectionpool.py"", line 392, in _make_request
  File ""http/client.py"", line 1252, in request
  File ""http/client.py"", line 1298, in _send_request
  File ""http/client.py"", line 1247, in endheaders
  File ""http/client.py"", line 1026, in _send_output
  File ""http/client.py"", line 966, in send
  File ""site-packages/docker/transport/sshconn.py"", line 32, in connect
  File ""site-packages/paramiko/transport.py"", line 879, in open_session
  File ""site-packages/paramiko/transport.py"", line 1017, in open_channel
paramiko.ssh_exception.ChannelException: ChannelException(2, 'Connect failed')
[24485] Failed to execute script docker-compose
```

However I ran the command again and it worked. My ssh connection is very stable otherwise.
--
",ruanbekker,"
--
Getting the same as @azhang , im using:

```
$ /tmp/docker-compose -v
docker-compose version 1.26.0-rc4, build d279b7a8
```
--
",hazcod,"
--
Having the same issue with regular docker (non swarm), `DOCKER_HOST=ssh://host`.
```
+ docker-compose -p xxx -f compose/network.yml -f compose/db.yml -f compose/php.yml -f compose/web.yml -f compose/download.yml -f compose/mq.yml -f compose/slave.yml -f compose/processor.yml -f compose/stages/prod/prod.yml up -d
659
Some services (db, download, mq, php, processor, slave, web) use the 'deploy' key, which will be ignored. Compose does not support 'deploy' configuration - use `docker stack deploy` to deploy to a swarm.
660
Creating network ""xxx"" with driver ""bridge""
661
Creating volume ""xxx"" with default driver
662
Creating volume ""xxx-data"" with default driver
663
db is up-to-date
664
Creating download ... 
665
Creating mq       ... 
666
Secsh channel 49 open FAILED: open failed: Connect failed
667

668
ERROR: for download  ChannelException(2, 'Connect failed')
669
Secsh channel 51 open FAILED: open failed: Connect failed
670
[2838] Failed to execute script docker-compose
671

672
ERROR: for mq  ChannelException(2, 'Connect failed')
673

674
ERROR: for download  ChannelException(2, 'Connect failed')
675

676
ERROR: for mq  ChannelException(2, 'Connect failed')`
```
--

--
[logs_93.zip](https://github.com/docker/compose/files/4797505/logs_93.zip)
Verbose logs attached. (`docker-compose --verbose up`)
Also happens with compose 26.0.
--
",web3even,"
--
# Hi Guys , 
**I have build** `mtproxy` **but erore in runtime...**
 _Please Help Me... _

### Erore

> `docker.errors.DockerException: Error while fetching server API version: ('Connection aborted.', FileNotFoundError(2, 'No such file or directory'))
[26932] Failed to execute script docker-compose`

Thanx 
--

--
_Please like this erore to install _ `MTProxy` _On ubuntu 16 04_ 

> `Traceback (most recent call last):
  File ""urllib3/connectionpool.py"", line 677, in urlopen
  File ""urllib3/connectionpool.py"", line 392, in _make_request
  File ""http/client.py"", line 1252, in request
  File ""http/client.py"", line 1298, in _send_request
  File ""http/client.py"", line 1247, in endheaders
  File ""http/client.py"", line 1026, in _send_output
  File ""http/client.py"", line 966, in send
  File ""docker/transport/unixconn.py"", line 43, in connect
FileNotFoundError: [Errno 2] No such file or directory

During handling of the above exception, another exception occurred:


Traceback (most recent call last):
  File ""requests/adapters.py"", line 449, in send
  File ""urllib3/connectionpool.py"", line 727, in urlopen
  File ""urllib3/util/retry.py"", line 403, in increment
  File ""urllib3/packages/six.py"", line 734, in reraise
  File ""urllib3/connectionpool.py"", line 677, in urlopen
  File ""urllib3/connectionpool.py"", line 392, in _make_request
  File ""http/client.py"", line 1252, in request
  File ""http/client.py"", line 1298, in _send_request
  File ""http/client.py"", line 1247, in endheaders
  File ""http/client.py"", line 1026, in _send_output
  File ""http/client.py"", line 966, in send
  File ""docker/transport/unixconn.py"", line 43, in connect
urllib3.exceptions.ProtocolError: ('Connection aborted.', FileNotFoundError(2, 'No such file or directory'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""docker/api/client.py"", line 205, in _retrieve_server_version
  File ""docker/api/daemon.py"", line 181, in version
  File ""docker/utils/decorators.py"", line 46, in inner
  File ""docker/api/client.py"", line 228, in _get
  File ""requests/sessions.py"", line 543, in get
  File ""requests/sessions.py"", line 530, in request
  File ""requests/sessions.py"", line 643, in send
  File ""requests/adapters.py"", line 498, in send
requests.exceptions.ConnectionError: ('Connection aborted.', FileNotFoundError(2, 'No such file or directory'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""bin/docker-compose"", line 3, in <module>
  File ""compose/cli/main.py"", line 67, in main
  File ""compose/cli/main.py"", line 123, in perform_command
  File ""compose/cli/command.py"", line 69, in project_from_options
  File ""compose/cli/command.py"", line 132, in get_project
  File ""compose/cli/docker_client.py"", line 43, in get_client
  File ""compose/cli/docker_client.py"", line 170, in docker_client
  File ""docker/api/client.py"", line 188, in
 __init__
  File ""docker/api/client.py"", line 213, in _retrieve_server_version
docker.errors.DockerException: Error while fetching server API version: ('Connection aborted.', FileNotFoundError(2, 'No such file or directory'))
[27334] Failed to execute script docker-compose
omega@ADAKServer-fsn1-1239:~/docker-compose-mtproxy$` 


 ** _Please Help Me..._ **  
--
"
7314,OPEN,The Dockerfile could not find the docker-compose volume file,kind/bug,2021-02-03 16:02:45 +0000 UTC,jiangyanglinlan,Opened,,"## Dockerfile could not find the  docker-compose volume file when using the RUN command

## Context information (for bug reports)

**Output of `docker-compose version`**
```
docker-compose version 1.25.4, build 8d51620a
docker-py version: 4.1.0
CPython version: 3.7.4
OpenSSL version: OpenSSL 1.1.1c  28 May 2019
```

**Output of `docker version`**
```
Client: Docker Engine - Community
 Version:           19.03.8
 API version:       1.40
 Go version:        go1.12.17
 Git commit:        afacb8b
 Built:             Wed Mar 11 01:23:10 2020
 OS/Arch:           windows/amd64
 Experimental:      false

Server: Docker Engine - Community
 Engine:
  Version:          19.03.8
  API version:      1.40 (minimum version 1.12)
  Go version:       go1.12.17
  Git commit:       afacb8b
  Built:            Wed Mar 11 01:29:16 2020
  OS/Arch:          linux/amd64
  Experimental:     false
 containerd:
  Version:          v1.2.13
  GitCommit:        7ad184331fa3e55e52b890ea95e65ba581ae3429
 runc:
  Version:          1.0.0-rc10
  GitCommit:        dc9208a3303feef5b3839f4323d9beb36df0a9dd
 docker-init:
  Version:          0.18.0
  GitCommit:        fec3683
```

**Output of `docker-compose config`**
(Make sure to add the relevant `-f` and other flags)
```
services:
  pyweb:
    build:
      context: E:\dev\compose_demo
    ports:
    - 8000:5000/tcp
    volumes:
    - E:\dev\compose_demo:/code:rw
version: '3.0'
```


## Steps to reproduce the issue

This is a demo where I can reproduce the problemI have 4 files in the same path
1. app.py
``` python
# app.py
from flask import Flask


app = Flask(__name__)


@app.route('/')
def index():
    return 'Hello World'


if __name__ == ""__main__"":
    app.run(host=""0.0.0.0"", debug=True)
```

2. requirements.txt
``` 
click==7.1.1
Flask==1.1.1
itsdangerous==1.1.0
Jinja2==2.11.1
MarkupSafe==1.1.1
Werkzeug==1.0.0
```

3. docker-compose.yml
``` yml
version: '3'

services:
  pyweb:
    build: .
    ports:
      - ""8000:5000""
    volumes:
      - .:/code
```
4. Dockerfile
``` docker
FROM ubuntu:18.04

RUN apt update
RUN apt -y install python3 python3-pip
RUN pip3 install -r /code/requirements.txt

WORKDIR /code

CMD [""python3"", ""app.py""]
```

5. run `docker-compose up`

### Observed result
`RUN pip3 install -r /code/requirements.txt` error

### Expected result
It should work

### Stacktrace / full error message

```
Could not open requirements file: [Errno 2] No such file or directory: '/code/requirements.txt'
Service 'pyweb' failed to build: The command '/bin/sh -c pip3 install -r /code/requirements.txt' returned a non-zero code: 1
```

## Additional information
OS: Windows and Linux

I found these files exist when I entered the docker container, and `pip 3 install -r /code/requirements.txt` was able to run successfully in the docker container.
",,,aar3,"
--
Any updates here? 

Have spent the past 2 days trying to figure out whether I was crazy or whether or not this was an actual issue. 

Same exact thing with me on `Docker version 19.03.12, build 48a66213fe` and `docker-compose version 1.26.2, build eefe0d31` on OSX 10.15.6

`docker-compose` refuses to see the files mounted at the volume -- giving me a `container exited with status code 127 -- /bin/bash files not found`. 

However, if I `exec` into the container they are clearly there and work as expected. 

Is there any temporary workaround here?
--
",rmNyro,"
--
Hi,

Still no update here ?

I'm having the same issue

command  `cat /etc/os-release`
```
NAME=""Ubuntu""
VERSION=""20.04.1 LTS (Focal Fossa)""
ID=ubuntu
ID_LIKE=debian
PRETTY_NAME=""Ubuntu 20.04.1 LTS""
VERSION_ID=""20.04""
HOME_URL=""https://www.ubuntu.com/""
SUPPORT_URL=""https://help.ubuntu.com/""
BUG_REPORT_URL=""https://bugs.launchpad.net/ubuntu/""
PRIVACY_POLICY_URL=""https://www.ubuntu.com/legal/terms-and-policies/privacy-policy""
VERSION_CODENAME=focal
UBUNTU_CODENAME=focal
```

command `docker-compose version`
```
docker-compose version 1.25.0, build unknown
docker-py version: 4.1.0
CPython version: 3.8.5
OpenSSL version: OpenSSL 1.1.1f  31 Mar 2020
```

command `docker version`
```
Client:
 Version:           19.03.8
 API version:       1.40
 Go version:        go1.13.8
 Git commit:        afacb8b7f0
 Built:             Fri Dec 18 12:15:19 2020
 OS/Arch:           linux/amd64
 Experimental:      false

Server:
 Engine:
  Version:          19.03.8
  API version:      1.40 (minimum version 1.12)
  Go version:       go1.13.8
  Git commit:       afacb8b7f0
  Built:            Fri Dec  4 23:02:49 2020
  OS/Arch:          linux/amd64
  Experimental:     false
 containerd:
  Version:          1.3.3-0ubuntu2.2
  GitCommit:        
 runc:
  Version:          spec: 1.0.1-dev
  GitCommit:        
 docker-init:
  Version:          0.18.0
  GitCommit:
```

Example Dockerfile
```
FROM alpine

RUN ls /var/www
```
Example docker-compose.yml
```
version: ""3.3""
services:
  test:
    build: .
    volumes:
      - .:/var/www
```
Command to build `docker-compose --file docker-compose.yml build`

The output is :
```
Building test
Step 1/2 : FROM alpine
latest: Pulling from library/alpine
596ba82af5aa: Pull complete
Digest: sha256:d9a7354e3845ea8466bb00b22224d9116b183e594527fb5b6c3d30bc01a20378
Status: Downloaded newer image for alpine:latest
 ---> 7731472c3f2a
Step 2/2 : RUN ls /var/www
 ---> Running in 1bef6f5d866a
ls: /var/www: No such file or directory
ERROR: Service 'test' failed to build: The command '/bin/sh -c ls /var/www' returned a non-zero code: 1
```
Volume seems not mounted in the build process. It seems like it is the exact same issue as in march 2020, is this still a known bug? I've updated docker to latest version (20.10.2) but it doesn't seem to fix the issue.

If there is no fix, is there a workaround? @jiangyanglinlan and @aar3, did you manage to do what you wanted and if so did you find a workaround or something?

Thank you all in advance!
--
",,,,,,,,
7307,OPEN,Enable resource limits in non-swarm environments,kind/feature,2020-03-21 16:18:42 +0000 UTC,esantoro,Opened,,"I am deploying some non-critical serviecs using docker-compose, on a single host. 
Despite docker does support setting resource upper bounds (cpu/memory limits) they are ignored in pratice.


I am aware that this is  a documented behavior (https://docs.docker.com/compose/compose-file/#deploy is always open when I'm dealing with docker-compose).

However, I can't understand why it has been chosen not to enable these feature when running against a single docker daemon (instead of a swarm).

With this feature request I would like to ask for such options (the whole deployment.resources.limits subtree) to be enabled for non-swarm deployments too.

**Describe the solution you'd like**

Just pass the appropriate options to the underlying docker daemon.

**Describe alternatives you've considered**

Alternatives are the following:
1. running the containers in a vm -> nullifies the point of running containers
2. launch my containers using shell scripts that call the docker binary with appropriate options (I would really like not to).

",,,,,,,,,,,,,,
7306,OPEN,docker-compose exec: the input device is not a TTY,kind/bug,2020-11-18 17:30:08 +0000 UTC,carbolymer,In progress,,"3. When making a bug report, make sure you provide all required information. The easier it is for
   maintainers to reproduce, the faster it'll be fixed.
-->

## Description of the issue

Cannot start interactive shell (e.g. `/bin/bash`) using `docker-compose -f - exec`

## Context information (for bug reports)

**Output of `docker-compose version`**
```
docker-compose version 1.25.4, build unknown
docker-py version: 4.2.0
CPython version: 3.8.2
OpenSSL version: OpenSSL 1.1.1e  17 Mar 2020
```

**Output of `docker version`**
```
Client:
 Version:           19.03.8-ce
 API version:       1.40
 Go version:        go1.14
 Git commit:        afacb8b7f0
 Built:             Mon Mar 16 22:23:09 2020
 OS/Arch:           linux/amd64
 Experimental:      false

Server:
 Engine:
  Version:          19.03.8-ce
  API version:      1.40 (minimum version 1.12)
  Go version:       go1.14
  Git commit:       afacb8b7f0
  Built:            Mon Mar 16 22:22:53 2020
  OS/Arch:          linux/amd64
  Experimental:     false
 containerd:
  Version:          v1.3.3.m
  GitCommit:        d76c121f76a5fc8a462dc64594aea72fe18e1178.m
 runc:
  Version:          1.0.0-rc10
  GitCommit:        dc9208a3303feef5b3839f4323d9beb36df0a9dd
 docker-init:
  Version:          0.18.0
  GitCommit:        fec3683
```

## Steps to reproduce the issue

1. Run the following commands:
```
#!/bin/bash
read -d '' COMPOSE_FILE << EOF
version: '3'
services:
  hello:
    image: ""redis:alpine""
EOF

echo ""$COMPOSE_FILE""
echo ""$COMPOSE_FILE"" | docker-compose -f - up -d
echo ""$COMPOSE_FILE"" | docker-compose -f - exec hello /bin/sh
```

### Observed result
Command quits immediately with the following message:
```
the input device is not a TTY
```

### Expected result
Interactive shell starts",,,lingster,"
--
you can try either: 
`export COMPOSE_INTERACTIVE_NO_CLI=1`
or run:
`docker-compose exec -T ... `

see discussion: #5696
--
",carbolymer,"
--
@lingster neither of those works:
` export COMPOSE_INTERACTIVE_NO_CLI=1` results in error:
```
Traceback (most recent call last):
  File ""/usr/lib/python3.8/site-packages/dockerpty/pty.py"", line 334, in start
    self._hijack_tty(pumps)
  File ""/usr/lib/python3.8/site-packages/dockerpty/pty.py"", line 373, in _hijack_tty
    pump.flush()
  File ""/usr/lib/python3.8/site-packages/dockerpty/io.py"", line 367, in flush
    read = self.from_stream.read(n)
  File ""/usr/lib/python3.8/site-packages/dockerpty/io.py"", line 121, in read
    return os.read(self.fd.fileno(), n)
  File ""/usr/lib/python3.8/socket.py"", line 718, in fileno
    self._checkClosed()
ValueError: I/O operation on closed file.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""/usr/bin/docker-compose"", line 11, in <module>
    load_entry_point('docker-compose==1.25.4', 'console_scripts', 'docker-compose')()
  File ""/usr/lib/python3.8/site-packages/compose/cli/main.py"", line 72, in main
    command()
  File ""/usr/lib/python3.8/site-packages/compose/cli/main.py"", line 128, in perform_command
    handler(command, command_options)
  File ""/usr/lib/python3.8/site-packages/compose/cli/main.py"", line 519, in exec_command
    pty.start()
  File ""/usr/lib/python3.8/site-packages/dockerpty/pty.py"", line 338, in start
    io.set_blocking(pump, flag)
  File ""/usr/lib/python3.8/site-packages/dockerpty/io.py"", line 32, in set_blocking
    old_flag = fcntl.fcntl(fd, fcntl.F_GETFL)
  File ""/usr/lib/python3.8/site-packages/dockerpty/io.py"", line 351, in fileno
    return self.from_stream.fileno()
  File ""/usr/lib/python3.8/site-packages/dockerpty/io.py"", line 103, in fileno
    return self.fd.fileno()
  File ""/usr/lib/python3.8/socket.py"", line 718, in fileno
    self._checkClosed()
ValueError: I/O operation on closed file.
```

`-T` switch just silences the error and nothing happens


--

--
@jennydaman yes, it still does **not** work. 

Everyone else commenting here that `-T` solves the problem, doesn't understand what ""interactive shell"" means.
--
",dobleme,"
--
Experiencing the same issue!
--
",caugner,"
--
I'm experiencing this issue when running a `docker-compose exec` command from a crontab cronjob.
--

--
> I'm experiencing this issue when running a `docker-compose exec` command from a crontab cronjob.

`docker-compose exec -T` solved the issue for me. 
--
",abranhe,"
--
I am trying to backup a database from MySQL image and I am getting the same issue.

```
docker-compose exec db-service mysqldump -u root -proot db > ./db.sql
```
--
",Azatalion,"
--
Got similar problem, when was trying to run laravel schedule in docker via cron. 

My solution is type in host terminal: `crontab -e`
 
add this line: `* * * * * cd /path/to/docker.yml && docker exec <docker-container's name> php artisan schedule:run >> log.txt 2>&1`

save and look at log.txt
--
"
7304,OPEN,Environment Setting Unicode + become \u002,kind/bug,2020-03-19 08:15:14 +0000 UTC,Shadowman4205,Opened,,"Hello,

trying to pass some setting via enviroments but + become  \u002 and there is an error connecting to requested server because of unsuccesfull authentication.

Any solution?",,,,,,,,,,,,,,
7302,OPEN,Using .env behaves differently than env_file in compose file?,kind/bug,2020-09-15 05:20:07 +0000 UTC,ravensorb,Opened,,"I am not sure if this is a bug or a feature request.

I am using a custom env file via the env_file tag - the issue is, the variables in there are not being used within the compose file itself (they only seem to be passed to the Dockerfile)

In the following example I have a file called ""portainer.env"" that contains the following
```
ENV=dev
PLATFORM=linux
```
and then here is the compose file
```
version: ""3.3""

services:

  portainer:
      image: portainer/portainer
      container_name: ""portainer""
      restart: always
      env_file:
        - portainer.env
      volumes:
        - /var/run/docker.sock:/var/run/docker.sock
        - ./data:/data
      networks:
        - web
      labels:
        - ""traefik.enable=true""
        - ""traefik.http.routers.portainer.rule=Host(`portainer.localhost`) || Host(`portainer.${ENV}.${PLATFORM}.docker.home.local`)""
        - ""traefik.http.routers.portainer.entrypoints=web""
        # Uncomment this label if your Traefik instance is using a specific Docker network and replace the network name 
        # This is not necessary if you set your default network in Traefik config/parameters
        # - ""traefik.docker.network=your-traefik-network-name""

networks: 
  web:
    external: true
```
This fails saying that DEV and PLATFORM are not defined.  If I create a .env file with those variables -- everything works correctly.

So bug? or Feature Request?",,,stale,"
--
This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you for your contributions.

--

--
This issue has been automatically marked as not stale anymore due to the recent activity.

--
",shaunco,"
--
Dupe of #7289 
--
",,,,,,,,
7297,OPEN,Add DOCKER_COMPOSE_LOG_LEVEL env,kind/feature,2020-03-16 12:58:16 +0000 UTC,kindermax,Opened,,"Hi. It would be cool to add `DOCKER_COMPOSE_LOG_LEVEL` env which works like `--log-level` but for the whole docker-compose.

Why ?

For example, I have a lot of env vars in docker-compose, but they not always set, because env vars used in different services, and if I run `foo` service I'll pass only env vars for that service. Writing `docker-compose --log-level ERROR` each time is tedious.

Thanks.",,,,,,,,,,,,,,
7292,OPEN,Support podman as a backend,kind/feature,2020-04-08 00:24:14 +0000 UTC,westurner,In progress,,"**Is your feature request related to a problem? Please describe.**
I would like to use docker-compose and existing docker-compose.yml files with podman
(which supports socketless and rootless builds and containers, which are preferable for certain configurations where centralized logging and monitoring through the docker socket is not as important and systemd services are sufficient).

**Describe the solution you'd like**
Specify an environment variable or a CLI option to call `podman` instead of `docker`:

```bash
DOCKER_COMPOSE_DRIVER=podman
docker-compose --driver=podman
```

(And implement whichever interface/driver/adapter/plugin pattern is appropriate to call podman with subprocess instead of making socket API requests)

Where podman doesn't support a docker (swarm,) feature, just throw an error message that links to this or the meta-issue for podman support.

**Describe alternatives you've considered**
- There's podman-compose, which is not at feature parity and really shouldn't need to be separately maintained.
  - https://github.com/containers/podman-compose
    - https://github.com/containers/podman-compose/blob/devel/podman_compose.py
      - This could be an interface.

- There's kompose, which could be useful with e.g. k3s (which recently gained SELinux support) for smaller dev setups where uptime during upgrades is not a priority.

**Additional context**
Podman: https://github.com/containers/libpod :

> Supporting docker-compose. We believe that Kubernetes is the defacto standard for composing Pods and for orchestrating containers, making Kubernetes YAML a defacto standard file format. Hence, Podman allows the creation and execution of Pods from a Kubernetes YAML file (see podman-play-kube). Podman can also generate Kubernetes YAML based on a container or Pod (see podman-generate-kube), which allows for an easy transition from a local development environment to a production Kubernetes cluster. If Kubernetes does not fit your requirements, there are other third-party tools that support the docker-compose format such as kompose and podman-compose that might be appropriate for your environment.

""Refactor to be called as an interface implementation from docker-compose""
https://github.com/containers/podman-compose/issues/126",,,westurner,"
--
Is this now almost as simple as just specifying a different socket URI?

From https://github.com/containers/podman-compose/issues/126#issuecomment-599062808 :

> FYI the Podman apiv2 aims to be compatible with the docker API https://podman.io/blogs/2020/01/17/podman-new-api.html
--

--
I don't think that I understand your question?

- Docker depends upon LXC and the Docker Socket REST API.
- Podman depends upon LXC and now the Docker Socket REST API (instead of the podman v1 API)
- Docker-compose depends upon the Docker Socket REST API.
--
",,,,,,,,,,
7289,OPEN,Allow specifying the name of the docker-compose environment file other than `.env`,,2020-12-07 00:47:46 +0000 UTC,kurtwheeler,In progress,,"## Description of the issue

`.env` is a very generic filename. There's nothing about it that signifies that it is for docker-compose.

I want to have it included in my repo so that it can use sane defaults locally for environment variables that I want to configure differently in production. However in the context of the rest of my project, I don't think the name is specific enough. I'd like to name it `docker-compose.env` in my project.

However the [documentation for it](https://docs.docker.com/compose/env-file/) says 

> Compose supports declaring default environment variables in an environment file named **.env** placed in the folder where the docker-compose command is executed (current working directory).

So my question is, would it be possible to add a top level property to the docker-compose YAML file such as `envrionement-file:` that would allow specifying the name of the env file to be used? I think it would also make sense as a command line argument, although I'm less personally interested in that.",,,rrdlpl,"
--
Why is not the env_file option enough? 

https://docs.docker.com/compose/environment-variables/




```
web:
  env_file:
    - web-variables.env
```
--
",kurtwheeler,"
--
I think it is! I did not manage to find that in the docs but it looks like it's what I was looking for.

Thank you!
--

--
Sorry, I closed this too soon.

@rrdlpl the `env_file` option controls what env file the _container_ uses, I want an option to configure what env file _docker-compose_ uses. As far as I can tell it will only use env variables from a file named `.env`.
--
",thejimnicholson,"
--
There also should be a way to make docker-compose **not** use an env-file, and that should be the default. Too many tool use '.env', and there is little agreement on them regarding format (whitespace vs not, etc.)
--
",shaunco,"
--
+1

`env_file` should be a valid top-level section, along-side `version`, `services`, `networks`, `volumes`, `secrets`, `configs`, and extensions starting with `x-` so that multiple env files can be applied to the docker-compose rather than just the service containers, otherwise this still requires a separate `.env` file:
```yml
mongodb:
    env_file: 
      - .env.base
      - .env.local
    image: 'bitnami/mongodb:${MONGO_VERSION}'
    ports:
      - '${MONGO_PORT}:27017'
    volumes:
      - mongodb-data:/bitnami/mongodb
    networks:
      - my-network
```

as `docker-compose` can't find `MONGO_VERSION` or `MONGO_PORT` that are defined in `.env.base` or `.env.local`.

Having this at a top-level, where is applies to the docker-compose, would allow for the following with no separate `.env`:
```yml
env_file: 
  - .env.base
  - .env.local

mongodb:
    image: 'bitnami/mongodb:${MONGO_VERSION}'
    ports:
      - '${MONGO_PORT}:27017'
    volumes:
      - mongodb-data:/bitnami/mongodb
    networks:
      - my-network
```

Alternatively, the `env_file` section of a `service` entry should be processed before all other sections so that other sections can use environment variables from `env_file`.
--
",manaphp,"
--
> There also should be a way to make docker-compose **not** use an env-file, and that should be the default. Too many tool use '.env', and there is little agreement on them regarding format (whitespace vs not, etc.)

.docker-compose is intuitive
--
",,
7277,OPEN,no matching entries in group file,kind/bug,2020-09-06 19:31:58 +0000 UTC,tcurdt,In progress,,"## Description of the issue

Docker compose does not find some of the groups when setting a user.

## Context information

**Output of `docker-compose version`**
```
ocker-compose version 1.21.0, build unknown
docker-py version: 3.4.1
CPython version: 3.7.3
OpenSSL version: OpenSSL 1.1.1d  10 Sep 2019
```

**Output of `docker version`**
```
Client:
 Version:           18.09.1
 API version:       1.39
 Go version:        go1.11.6
 Git commit:        4c52b90
 Built:             Tue, 03 Sep 2019 19:59:35 +0200
 OS/Arch:           linux/amd64
 Experimental:      false

Server:
 Engine:
  Version:          18.09.1
  API version:      1.39 (minimum version 1.12)
  Go version:       go1.11.6
  Git commit:       4c52b90
  Built:            Tue Sep  3 17:59:35 2019
  OS/Arch:          linux/amd64
  Experimental:     false
```

**Output of `docker-compose config`**

```
services:
  alertmanager:
    command:
    - --config.file=/etc/alertmanager/config.yml
    - --storage.path=/alertmanager
    container_name: alertmanager
    image: prom/alertmanager:v0.20.0
    ports:
    - 127.0.0.1:9093:9093/tcp
    restart: unless-stopped
    user: nobody:docker
    volumes:
    - /srv/compose/alertmanager:/etc/alertmanager:ro
version: '3.6'
```


## Steps to reproduce the issue

The above works with the group `adm`. Now I've added a new group

    # grep docker /etc/group
    docker:x:113:

Changing the config to

    user: 'nobody:docker'

which then results in

    ERROR: for alertmanager  Cannot start service alertmanager: linux spec user: unable to find group docker: no matching entries in group file

but using the gid works correctly

    user: 'nobody:113'

Now the question is why does docker compose not find the group?
What group file does it check? It must be a different one.


### Observed result

1. resolves `adm` correctly.
2. fails to resolve `docker` correctly.

### Expected result

1. resolves `adm` correctly.
2. resolves `docker` correctly.

### Stacktrace / full error message

```
ERROR: for 5f66885213d0_alertmanager  Cannot start service alertmanager: linux spec user: unable to find group docker: no matching entries in group file

ERROR: for alertmanager  Cannot start service alertmanager: linux spec user: unable to find group docker: no matching entries in group file
ERROR: Encountered errors while bringing up the project.
```

## Additional information

This is on debian buster.
",,,stale,"
--
This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you for your contributions.

--

--
This issue has been automatically marked as not stale anymore due to the recent activity.

--
",tcurdt,"
--
AFAIK this still is an issue. Using gid is a very ugly work around.
--
",,,,,,,,
7273,OPEN,Windows docker fails to use build function of docker-compose,kind/bug,2021-02-17 14:42:14 +0000 UTC,Jn58,In progress,,"3. When making a bug report, make sure you provide all required information. The easier it is for
   maintainers to reproduce, the faster it'll be fixed.
-->

## Description of the issue
Errors about credential occurs on `build` within `docker-compose.yml` on Windows.

## Context information (for bug reports)

**Output of `docker-compose version`**
```
docker-compose version 1.25.4, build 8d51620a
docker-py version: 4.1.0
CPython version: 3.7.4
OpenSSL version: OpenSSL 1.1.1c  28 May 2019
```

**Output of `docker version`**
```
Client: Docker Engine - Community
 Version:           19.03.5
 API version:       1.40
 Go version:        go1.12.12
 Git commit:        633a0ea
 Built:             Wed Nov 13 07:22:37 2019
 Experimental:      false

Server: Docker Engine - Community
 Engine:
  Version:          19.03.5
  API version:      1.40 (minimum version 1.12)
  Go version:       go1.12.12
  Git commit:       633a0ea
  Built:            Wed Nov 13 07:29:19 2019
  OS/Arch:          linux/amd64
  Experimental:     false
 containerd:
  Version:          v1.2.10
  GitCommit:        b34a5c8af56e510852c35414db4c1f4fa6172339
 runc:
  Version:          1.0.0-rc8+dev
  GitCommit:        3e425f80a8c931f88e6d94a8c831b9d5aa481657
 docker-init:
  Version:          0.18.0
  GitCommit:        fec3683
```

**Output of `docker-compose config`**
(Make sure to add the relevant `-f` and other flags)
```
services:
  redis:
    image: redis:alpine
  web:
    build:
      context: C:\Users\cacog\OneDrive\Documents\composetest
    ports:
    - 5000:5000/tcp
version: '3.0'
```

## Steps to reproduce the issue

1. Follow `Step 1` to `Step 4` of [Get started with Docker Compose](https://docs.docker.com/compose/gettingstarted/)

### Observed result
`docker-compose up` of `Step 4` fails to build.

### Expected result
Successfull `docker-compose up`.

### Stacktrace / full error message

```
Building web
Traceback (most recent call last):
  File ""site-packages\docker\credentials\store.py"", line 80, in _execute
  File ""subprocess.py"", line 395, in check_output
  File ""subprocess.py"", line 487, in run
subprocess.CalledProcessError: Command '['C:\\Program Files\\Docker\\Docker\\resources\\bin\\docker-credential-desktop.EXE', 'list']' returned non-zero exit status 1.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""docker-compose"", line 6, in <module>
  File ""compose\cli\main.py"", line 72, in main
  File ""compose\cli\main.py"", line 128, in perform_command
  File ""compose\cli\main.py"", line 1077, in up
  File ""compose\cli\main.py"", line 1073, in up
  File ""compose\project.py"", line 548, in up
  File ""compose\service.py"", line 367, in ensure_image_exists
  File ""compose\service.py"", line 1106, in build
  File ""site-packages\docker\api\build.py"", line 261, in build
  File ""site-packages\docker\api\build.py"", line 308, in _set_auth_headers
  File ""site-packages\docker\auth.py"", line 302, in get_all_credentials
  File ""site-packages\docker\credentials\store.py"", line 71, in list
  File ""site-packages\docker\credentials\store.py"", line 93, in _execute
docker.credentials.errors.StoreError: Credentials store docker-credential-desktop exited with ""error listing credentials - err: exit status 1, out: `A specified logon session does not exist. It may alrea
dy have been terminated.`"".
[2780] Failed to execute script docker-compose
```

## Additional information

### OS version
- Edition : Windows 10 Pro
- Version : 1903
- OS build : 18362.657

### `docker-compose` install method
`docker-compose` is installed with official installer of `docker`.",,,Jn58,"
--
I find that this error only occurs over ssh.
I'm using ssh server on windows, [Win32 OpneSSH](https://github.com/PowerShell/Win32-OpenSSH) and when I use docker-compose build over ssh, above error occurs.
However, when I try docker build (not docker-compose build) over ssh, it works well. So I think it's still a problem of docker-compose and I'll leave this issue opened.
--

--
> Same here: docker and docker-compose versions are exactly the same, but running on WIndows 10 1909 (18363.418).
> The error also does occur when sitting right in front of the system (so not ssh'ing into Windows). Deleting %userprofile%.docker\config.json solves the problem and docker-compose pull runs without any errors. But config.json gets recreated after some time.

I tried this solution, but still have error over ssh.
--

--
@Hooch76 Thank you for advice, but even I change file name with `mv` command and retry, it shows same error.
--

--
> _Possible work around_ , After SSH'ing into your guest (linux) run the following commands :
> 
> ```
> $ sudo su
> $ docker-compose up
> ```
@luisegarduno
In this issue, we are talking about docker running on Windows. Not linux.
--
",Hooch76,"
--
Same here: docker and docker-compose versions are exactly the same, but running on WIndows 10 1909 (18363.418). 
The error also does occur when sitting right in front of the system (so not ssh'ing into Windows). Deleting %userprofile%\.docker\config.json solves the problem and docker-compose pull runs without any errors. But config.json gets recreated after some time. 
--

--
Try renaming the file instead of deleting it. The file will get re-created almost immediately after it is deleted. Renaming it (config.bla or whatever) gives you some extra seconds until it is also recreated.
--
",paulspartan14,"
--
It happens to me when I use git bash, when I run the command on the windows cmd this problem does not happen
--
",IamGroot19,"
--
> It happens to me when I use git bash, when I run the command on the windows cmd this problem does not happen. 


FWIW I can confirm the same issue. I am using Docker desktop on Windows 10 Home Single Language (version 2004, OS Build 19041.508 ) with WSL2. 
Here's the output of `docker-compose up` on Git Bash. (But if i run the `docker-compose up` on Windows command prompt it seems to be working fine)

```
 Traceback (most recent call last):
  File ""site-packages\docker\credentials\store.py"", line 80, in _execute
  File ""subprocess.py"", line 395, in check_output
  File ""subprocess.py"", line 487, in run
subprocess.CalledProcessError: Command '['C:\\Program Files\\Docker\\Docker\\resources\\bin\\docker-credential-desktop.EXE', 'get']' returned non-zero exit status 1.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""site-packages\docker\auth.py"", line 264, in _resolve_authconfig_credstore
  File ""site-packages\docker\credentials\store.py"", line 35, in get
  File ""site-packages\docker\credentials\store.py"", line 93, in _execute
docker.credentials.errors.StoreError: Credentials store docker-credential-desktop exited with ""error getting credentials - err: exec: ""docker-credential-wincred.exe"": executable file not found in %PATH%, out: ``"".

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""docker-compose"", line 6, in <module>
  File ""compose\cli\main.py"", line 72, in main
  File ""compose\cli\main.py"", line 128, in perform_command
  File ""compose\cli\main.py"", line 1078, in up
  File ""compose\cli\main.py"", line 1074, in up
  File ""compose\project.py"", line 548, in up
  File ""compose\service.py"", line 361, in ensure_image_exists
  File ""compose\service.py"", line 1250, in pull
  File ""compose\progress_stream.py"", line 102, in get_digest_from_pull
  File ""compose\service.py"", line 1215, in _do_pull
  File ""site-packages\docker\api\image.py"", line 396, in pull
  File ""site-packages\docker\auth.py"", line 48, in get_config_header
  File ""site-packages\docker\auth.py"", line 324, in resolve_authconfig
  File ""site-packages\docker\auth.py"", line 235, in resolve_authconfig
  File ""site-packages\docker\auth.py"", line 281, in _resolve_authconfig_credstore
docker.errors.DockerException: Credentials store error: StoreError('Credentials store docker-credential-desktop exited with ""error getting credentials - err: exec: ""docker-credential-wincred.exe"": executable file not foundial-wincred.exe"": executable file not found in %PATH%, out: ``"".')
[13052] Failed to execute script docker-compose
```

For more info about the docker version I am using is the output of `docker version` command from command prompt:

> Client: Docker Engine - Community
>  Version:           19.03.12
>  API version:       1.40
>  Go version:        go1.13.10
>  Git commit:        48a66213fe
>  Built:             Mon Jun 22 15:43:18 2020
>  OS/Arch:           windows/amd64
>  Experimental:      false
> 
> Server: Docker Engine - Community
>  Engine:
>   Version:          19.03.12
>   API version:      1.40 (minimum version 1.12)
>   Go version:       go1.13.10
>   Git commit:       48a66213fe
>   Built:            Mon Jun 22 15:49:27 2020
>   OS/Arch:          linux/amd64
>   Experimental:     false
>  containerd:
>   Version:          v1.2.13
>   GitCommit:        7ad184331fa3e55e52b890ea95e65ba581ae3429
>  runc:
>   Version:          1.0.0-rc10
>   GitCommit:        dc9208a3303feef5b3839f4323d9beb36df0a9dd
>  docker-init:
>   Version:          0.18.0
>   GitCommit:        fec3683

Thanks
--
",markoueis,"
--
Hey guys we are having the same issue. Any progress on this or workarounds. We too see it happening more over ssh (we have jenkins ssh-ing in and calling it) though I think we reproduced it once without (can't confirm for sure it was exactly the same thing). 

It seems intermittent so can't always tell if deleting the file is helping or not

Using docker desktop 2.4.0.0 (48506)

```
[4480] Failed to execute script docker-compose
Traceback (most recent call last):
  File ""site-packages\docker\credentials\store.py"", line 80, in _execute
  File ""subprocess.py"", line 395, in check_output
  File ""subprocess.py"", line 487, in run
subprocess.CalledProcessError: Command '['C:\\Program Files\\Docker\\Docker\\resources\\bin\\docker-credential-wincred.EXE', 'get']' returned non-zero exit status 1.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""site-packages\docker\auth.py"", line 264, in _resolve_authconfig_credstore
  File ""site-packages\docker\credentials\store.py"", line 35, in get
  File ""site-packages\docker\credentials\store.py"", line 93, in _execute
docker.credentials.errors.StoreError: Credentials store docker-credential-wincred exited with ""A specified logon session does not exist. It may already have been terminated."".

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""docker-compose"", line 3, in <module>
  File ""compose\cli\main.py"", line 67, in main
  File ""compose\cli\main.py"", line 126, in perform_command
  File ""compose\cli\main.py"", line 1070, in up
  File ""compose\cli\main.py"", line 1066, in up
  File ""compose\project.py"", line 615, in up
  File ""compose\service.py"", line 356, in ensure_image_exists
  File ""compose\service.py"", line 1267, in pull
  File ""compose\progress_stream.py"", line 99, in get_digest_from_pull
  File ""compose\service.py"", line 1234, in _do_pull
  File ""site-packages\docker\api\image.py"", line 396, in pull
  File ""site-packages\docker\auth.py"", line 48, in get_config_header
  File ""site-packages\docker\auth.py"", line 324, in resolve_authconfig
  File ""site-packages\docker\auth.py"", line 235, in resolve_authconfig
  File ""site-packages\docker\auth.py"", line 281, in _resolve_authconfig_credstore
docker.errors.DockerException: Credentials store error: StoreError('Credentials store docker-credential-wincred exited with ""A specified logon session does not exist. It may already have been 
terminated."".')
```
--
",luisegarduno,"
--
_Possible work around_ , After SSH'ing into your guest (linux) run the following commands :
```
$ sudo su
$ docker-compose up
```

Edit: ^ I forgot to specify that this solution was performed within a WSL2 environment on Windows 10.
--
"
7262,OPEN,docker-compose ups a bad build target with multiple compose files,kind/bug,2020-12-16 23:23:28 +0000 UTC,greg-md,Opened,,"## Description of the issue

A bad build target in used on containers up when working with multiple compose files.

Seems like the image check doesn't consider the `build.target` value.

## Context information (for bug reports)

**Output of `docker-compose version`**
```
docker-compose version 1.25.4, build 8d51620a
docker-py version: 4.1.0
CPython version: 3.7.5
OpenSSL version: OpenSSL 1.1.1d  10 Sep 2019
```

**Output of `docker version`**
```
Client: Docker Engine - Community
 Version:           19.03.5
 API version:       1.40
 Go version:        go1.12.12
 Git commit:        633a0ea
 Built:             Wed Nov 13 07:22:34 2019
 OS/Arch:           darwin/amd64
 Experimental:      false

Server: Docker Engine - Community
 Engine:
  Version:          19.03.5
  API version:      1.40 (minimum version 1.12)
  Go version:       go1.12.12
  Git commit:       633a0ea
  Built:            Wed Nov 13 07:29:19 2019
  OS/Arch:          linux/amd64
  Experimental:     false
 containerd:
  Version:          v1.2.10
  GitCommit:        b34a5c8af56e510852c35414db4c1f4fa6172339
 runc:
  Version:          1.0.0-rc8+dev
  GitCommit:        3e425f80a8c931f88e6d94a8c831b9d5aa481657
 docker-init:
  Version:          0.18.0
  GitCommit:        fec3683
```

## Steps to reproduce the issue

1. Use `Dockerfile`:
```
FROM node:13 AS builder

FROM builder AS development

CMD [""echo"", ""DEVELOPMENT""]

FROM builder AS ci

CMD [""echo"", ""CI""]
```

2. Create 3 different docker compose files:

`docker-compose.yml`:
```
version: '3.4'
services:
  api:
    build:
      context: .
      target: development
```

`docker-compose-ci.yml`:
```
version: '3.4'
services:
  api:
    build:
      context: .
      target: ci
```

`docker-compose-local.yml`:
```
version: '3.4'
services:
  api:
    build:
      context: .
      target: development
```

3. Run `docker-compose -f docker-compose.yml -f docker-compose-ci.yml up`.

4. Then run `docker-compose -f docker-compose.yml -f docker-compose-local.yml up`.

### Observed result

On the 1st run, it will use `ci` build target and will execute `echo CI`, which is expected.

On the 2nd run, it should use `development` build target, but it still uses the previous `ci` target build and executes the same ci command, which is NOT expected.

The same bug happens if you will run commands in reverse order.

### Expected result

Should run the expected build target based on extended docker file.

### Stacktrace / full error message

```
grigorii-duca:testapp greg$ docker-compose -f docker-compose.yml -f docker-compose-ci.yml up
Creating network ""testapp_default"" with the default driver
Building api
Step 1/5 : FROM node:13 AS builder
 ---> f7756628c1ee

Step 2/5 : FROM builder AS development
 ---> f7756628c1ee
Step 3/5 : CMD [""echo"", ""DEVELOPMENT""]
 ---> Running in 960536e7bd45
Removing intermediate container 960536e7bd45
 ---> 2a69c4326cad

Step 4/5 : FROM builder AS ci
 ---> f7756628c1ee
Step 5/5 : CMD [""echo"", ""CI""]
 ---> Running in c68aa47d3686
Removing intermediate container c68aa47d3686
 ---> 28cd629f5770

Successfully built 28cd629f5770
Successfully tagged testapp_api:latest
WARNING: Image for service api was built because it did not already exist. To rebuild this image you must use `docker-compose build` or `docker-compose up --build`.
Creating testapp_api_1 ... done
Attaching to testapp_api_1
api_1  | CI
testapp_api_1 exited with code 0
grigorii-duca:testapp greg$ docker-compose -f docker-compose.yml -f docker-compose-local.yml up
Recreating testapp_api_1 ... done
Attaching to testapp_api_1
api_1  | CI
testapp_api_1 exited with code 0
grigorii-duca:testapp greg$ 
```

## Additional information

MacOS

`docker-compose -f docker-compose.yml -f docker-compose-ci.yml config`
```
services:
  api:
    build:
      context: /htdocs/combats/testapp
      target: ci
version: '3.4'
```

`docker-compose -f docker-compose.yml -f docker-compose-local.yml config`
```
services:
  api:
    build:
      context: /htdocs/combats/testapp
      target: development
version: '3.4'
```
",,,DracotMolver,"
--
This is happening to me but with a different configuration. It's creating dangling images because when I target to `prod` it creates the `dev` stage as well, and this stage was previously created.

My docker file *(I removed some info)*:
```dockerfile

FROM node:12 as base

WORKDIR /server

COPY package.json ./

RUN npm install

COPY ./ ./

# ------------------------

FROM base as dev

ENV NODE_ENV=development
ENV APP_HOST=""0.0.0.0""

EXPOSE 3000

CMD [""npm"", ""run"", ""dev""]

# ------------------------

FROM base as prod

ENV NODE_ENV=production
ENV PORT=5000

EXPOSE 5000

CMD [""npm"", ""start""]
```

My docker-compose *(I removed some info too)*:
```docker-compose
version: ""3.7""
services:
  server:
    build:
      context: ./server
      dockerfile: Dockerfile
      target: dev
    volumes:
      - ./server:/server
      - /server/node_modules
    container_name: newlit_server
    depends_on:
      - db
    ports:
      - 3000:3000
      - 5000:5000

  db:
    image: mongo
    container_name: newlist_db
    ports:
      - 27017:27017
    volumes:
      - mongodb_data_container:/data/db

volumes:
  mongodb_data_container:
```

If I run `docker-compose up` for the very first time. It will pull the node image and then will use it as a base for the `dev` stage. The container is up and running fine.

*base stage*
<img width=""582"" alt=""Screen Shot 2020-04-09 at 18 12 16"" src=""https://user-images.githubusercontent.com/13334764/78945199-af679500-7a8d-11ea-8a7f-e60ebc158f36.png"">
*... I skipped all the instalation of npm*
*dev stage*
<img width=""339"" alt=""Screen Shot 2020-04-09 at 18 14 19"" src=""https://user-images.githubusercontent.com/13334764/78945329-0a998780-7a8e-11ea-9d3d-6dd41bc6ab4f.png"">

But then I face 2 situations when I change the target:
* If I change the `target` value to `prod`, the `docker-compose up` doesn't rebuild the image based on that stage on the Dockerfile. Instead, it's setting up my container like it was in development mode (devstage). Doesn't `docker-compose up` build (rebuild) the image if it doesn't exist (prod stage doesn't exist yet) and then run the container?. 

*rebuild dev stage*
![image](https://user-images.githubusercontent.com/13334764/78945547-94495500-7a8e-11ea-9860-d0c47e1863cc.png)

* When I run `docker-compose build` to avoid the step above. It rebuild the base image from cache, perfect!. The `dev` stage now is dangle because the `prod` stage has the same label **(Am I right why the dangle exist?)**. But when I see the terminal, it is building the `dev` stage and then the `prod`. It make sense If I think docker-compose build runs through all the Dockerfile. If that the case, it is inevitable don't go through the `dev` stage.

*images after all of that*
![image](https://user-images.githubusercontent.com/13334764/78945714-f73aec00-7a8e-11ea-84c9-bab887393db6.png)

Now. If I change again to `dev` and rebuild the image with `docker-compose up server --build`. It dangled the prev image (prod stage) and create again the `dev` from scratch, not form the cache. so know i have more dangle images, and this cycle will never ends.

![image](https://user-images.githubusercontent.com/13334764/78945853-4d0f9400-7a8f-11ea-88fb-95a256cb804d.png)

What I finally ended up doing was:
* Remove target from docker-compose.yml
* Create two images running `docker build ./server -t server-dev --target=dev` and `docker build ./server -t server-prod --target=prod`
* Using these images on docker-compose.yml when I need them.

```docker-compose
...
services:
  server:
    # for productions change it to server-prod
    image: sever-dev
...
```
--

--
In my case @bog-h i only work with one docker compose file. I'm using version 3.7
--

--
@skyeagle That's interesting but even though it doesn't fix the issue of docker-compose not skipping the stage that is not in the `target` param
--
",bog,"
--
Hello Guys! I'm glad that it is a common problem because I started to lose my mind :D 

Looks like docker-compose override is ignoring build: target argument. I thought the problem is in the cache, but not! 

If you will specify a target (ex debug or base) in the main docker-compose.yaml file then everything will work as expected in depends on your target
    build:
      target: debug|base

But if you will specify the target in an override file (ex: docker-compose.debug.yaml) then this parameter is ignored!
--
",skyeagle,"
--
@DracotMolver you might be missing DOCKER_BUILDKIT=1 

> As of Docker 18.09 you can use BuildKit. One of the benefits is skipping unused stages, 
> so all you should need to do is build with 
> DOCKER_BUILDKIT=1 docker build -t my-app --target prod 

https://stackoverflow.com/a/55320725/368144
--
",probablykasper,"
--
It seems to keep the `build.target` from whichever file you ran `docker-compose build` on.


For example, say my `docker-compose.yml` specifies `target: dev` and my `docker-compose.prod.yml` specifies `target: bin`. If I now run `docker-compose -f docker-compose.prod.yml build` and then `docker-compose up`, it starts the `bin` stage.

@aiordache Any word on this issue?
--

--
@eweidner For me, rebuilding does not fix it, and I'm not running multiple compose files at once. Do you think it's a different issue?

> It seems to keep the `build.target` from whichever file you ran `docker-compose build` on.
> 
> For example, say my `docker-compose.yml` specifies `target: dev` and my `docker-compose.prod.yml` specifies `target: bin`. If I now run `docker-compose -f docker-compose.prod.yml build` and then `docker-compose up`, it starts the `bin` stage.
--
",mellertson,"
--
I too am encountering this issue.  In my case, I have the two services in the same `docker-compose.yaml` file:

```yaml
services:

    server:
        image: registry.mydomain.com/algos_server:latest
        build:
            context: ./
            dockerfile: algos_server.dockerfile
            target: algos_server
        command: manage.py runserver --noreload 0.0.0.0:8000

    celery:
        image: registry.mydomain.com/algos_server:latest
        build:
            context: ./
            dockerfile: algos_server.dockerfile
            target: algos_celery
        command: celery -A algos.celery worker -l info
```

And I have the following in `algos_server.dockerfile`:
```
FROM python:3.7.7-buster AS algos_base
# bunch of commands to build the docker image

FROM algos_base as algos_server
RUN echo ""last build line in algos_server""
ENTRYPOINT [""/usr/local/algos/scripts/algos-server-entrypoint.sh""]

FROM algos_base as algos_celery
RUN echo ""last build line in algos_celery""
ENTRYPOINT [""/usr/local/algos/scripts/algos-celery-entrypoint.sh""]
```
And for completeness, I have these two entry point files.
`algos-server-entrypoint.sh`
```bash
#!/bin/bash
set -e
DIR=""$(cd ""$(dirname ""${BASH_SOURCE[0]}"")"" >/dev/null 2>&1 && pwd)""
# run migrations, import fixtures, etc... etc...
echo ""Starting up the Algos server...""
exec ""$@""
```

And in `algo-celery-entrypoint.sh` I have:
```bash
#!/bin/bash
set -e
DIR=""$(cd ""$(dirname ""${BASH_SOURCE[0]}"")"" >/dev/null 2>&1 && pwd)""
# run migrations, import fixtures, etc... etc...
echo ""Starting up the Algos Celery worker...""
exec ""$@""
```

**Result**

When I run `docker-compose -f docker-compose.yaml build && docker-compose -f docker-compose.yaml up` I get this output:

```
Successfully built 590673ed935d
Successfully tagged registry.mydomain.com/algos_server:latest
WARNING: Some networks were defined but are not used by any service: algos_public
WARNING: The Docker Engine you're using is running in swarm mode.

Compose does not use swarm mode to deploy services to multiple nodes in a swarm. All containers will be scheduled on the current node.

To deploy your application across the swarm, use `docker stack deploy`.

Recreating algos_server_1 ... done
Recreating algos_celery_1 ... done
Attaching to algos_celery_1, algos_server_1
celery_1    | --------------------------------------------------------------------------------
celery_1    | Starting up the Algos Celery worker...
celery_1    | --------------------------------------------------------------------------------
server_1    | --------------------------------------------------------------------------------
server_1    | Starting up the Algos Celery worker...
server_1    | --------------------------------------------------------------------------------
```

**Conclusion** 

For some reason docker-compose seems to be ignoring the `target` directive in `docker-compose.yaml`.  I will try separating both services into their own `docker-compose.yaml` file and see if that helps, but according to the docs for [docker-compose`](https://docs.docker.com/compose/compose-file/#target) and [multi-stage build docs](https://docs.docker.com/develop/develop-images/multistage-build/) I believe it should be executing each service's entrypoint, instead of executing the entrypoint for Algors Celery for both services.
--

--
I found a work around, which is to describe my two docker services in two separate `docker-compose.yaml` files.  

After I put `algos_server` into `algos-server-base.yaml` and `algos_celery` into `algos-celery-base.yaml`  I get the following output, which is as I expected it to be.
```log
server_1  | --------------------------------------------------------------------------------
server_1  | Starting up the Algos server...
server_1  | --------------------------------------------------------------------------------
celery_1    | --------------------------------------------------------------------------------
celery_1    | Starting up the Algos Celery worker...
celery_1    | --------------------------------------------------------------------------------
```

--
",eweidner,"
--
We've run into the original problem here and it appears that this is only a problem if you don't rebuild the target. Docker-compose is not detecting that the built container would be different in each run without re-building.

In the first run of `docker-compose -f docker-compose.yml -f docker-compose-ci.yml up`, the system sees it doesn't have an image so it builds with the `ci` target.

In the second run of `docker-compose -f docker-compose.yml -f docker-compose-local.yml up`, since it's just trying to bring up the container (not build) it doesn't recognize that the already built image is not the same as what would get created with the different build target, and just brings up the existing image.

I think this is not too surprising given that the target is in the ""build"" area. It's a bit of a more advanced mode to go reevaluate everything about the compose targets during an up.

To solve this, just execute a build before the 2nd up to trigger docker-compose to reevaluate the images and rebuild with the wanted target.

```
% docker-compose -f docker-compose.yml -f docker-compose-ci.yml up
Creating network ""docker-compose-target-bug-test_default"" with the default driver
Building api
Step 1/5 : FROM node:14-slim AS builder
 ---> cdb457aa69ed

Step 2/5 : FROM builder AS development
 ---> cdb457aa69ed
Step 3/5 : CMD [""echo"", ""DEVELOPMENT""]
 ---> Running in 9431c3d0516b
Removing intermediate container 9431c3d0516b
 ---> 1e13634516d7

Step 4/5 : FROM builder AS ci
 ---> cdb457aa69ed
Step 5/5 : CMD [""echo"", ""CI""]
 ---> Running in 4e5a7801767e
Removing intermediate container 4e5a7801767e
 ---> fc8d5a1871f0

Successfully built fc8d5a1871f0
Successfully tagged docker-compose-target-bug-test_api:latest
WARNING: Image for service api was built because it did not already exist. To rebuild this image you must use `docker-compose build` or `docker-compose up --build`.
Creating docker-compose-target-bug-test_api_1 ... done
Attaching to docker-compose-target-bug-test_api_1
api_1  | CI


% docker-compose -f docker-compose.yml -f docker-compose-local.yml build
Building api
Step 1/3 : FROM node:14-slim AS builder
 ---> cdb457aa69ed

Step 2/3 : FROM builder AS development
 ---> cdb457aa69ed
Step 3/3 : CMD [""echo"", ""DEVELOPMENT""]
 ---> Using cache
 ---> 1e13634516d7

Successfully built 1e13634516d7
Successfully tagged docker-compose-target-bug-test_api:latest


% docker-compose -f docker-compose.yml -f docker-compose-local.yml up
Recreating docker-compose-target-bug-test_api_1 ... done
Attaching to docker-compose-target-bug-test_api_1
api_1  | DEVELOPMENT
docker-compose-target-bug-test_api_1 exited with code 0
```
--

--
@probablykasper I don't see any details on your specifics so I'm not sure if your issue is different.

If you are seeing what DracotMolver is seeing then that may be a different issue. I cannot reproduce that in some of my local code that seems similar to theirs. My builds in that situation skips dev when I build prod.

I only reproduced the issue presented by the OP and doing a build in between worked for me.
--
"
7258,OPEN,`docker-compose pull` NOT failing if a service image is not found (and includes both image and build),kind/bug,2020-12-22 19:13:26 +0000 UTC,erks,Opened,,"3. When making a bug report, make sure you provide all required information. The easier it is for
   maintainers to reproduce, the faster it'll be fixed.
-->

## Description of the issue

https://github.com/docker/compose/issues/6464 described the behavior where `docker-compose pull` failing if a service includes both image and build as a bug. This was ""fixed"" in [1.25.1](https://github.com/docker/compose/pull/6494). We actually rely on this behavior to decide whether we need to build and push the image and don't think the pre-1.25.1 behavior was a bug.

The `pull` command should do as it says, which is to try to pull all the images specified in `docker-compose.yml`, and reports error appropriately regardless of whether `build` is specified.

## Context information (for bug reports)

**Output of `docker-compose version`**
```
docker-compose version 1.25.2, build 698e2846
docker-py version: 4.1.0
CPython version: 3.7.5
OpenSSL version: OpenSSL 1.1.1d  10 Sep 2019
```

**Output of `docker version`**
```
Client: Docker Engine - Community
 Version:           19.03.5
 API version:       1.40
 Go version:        go1.12.12
 Git commit:        633a0ea
 Built:             Wed Nov 13 07:22:34 2019
 OS/Arch:           darwin/amd64
 Experimental:      false

Server: Docker Engine - Community
 Engine:
  Version:          19.03.5
  API version:      1.40 (minimum version 1.12)
  Go version:       go1.12.12
  Git commit:       633a0ea
  Built:            Wed Nov 13 07:29:19 2019
  OS/Arch:          linux/amd64
  Experimental:     false
 containerd:
  Version:          v1.2.10
  GitCommit:        b34a5c8af56e510852c35414db4c1f4fa6172339
 runc:
  Version:          1.0.0-rc8+dev
  GitCommit:        3e425f80a8c931f88e6d94a8c831b9d5aa481657
 docker-init:
  Version:          0.18.0
  GitCommit:        fec3683
```

**Output of `docker-compose config`**
(Make sure to add the relevant `-f` and other flags)
```
services:
  build:
    build:
      context: /private/tmp/test
    command: echo ""from build""
    image: example
  test:
    command: echo ""from test""
    image: example
version: '3.0'
```

## Steps to reproduce the issue

1. Same as https://github.com/docker/compose/issues/6464

### Observed result

The service with both image and build didn't throw an error and was reported ""done"" 

```
$ docker-compose pull
Pulling build ... done
Pulling test  ... error

ERROR: for test  pull access denied for example, repository does not exist or may require 'docker login': denied: requested access to the resource is denied
ERROR: pull access denied for example, repository does not exist or may require 'docker login': denied: requested access to the resource is denied
```

### Expected result

The service with both image and build does the ""pull"" as instructed and reports appropriate errors if it fails to do so.

### Stacktrace / full error message

```
$ docker-compose pull
Pulling build ... done
Pulling test  ... error

ERROR: for test  pull access denied for example, repository does not exist or may require 'docker login': denied: requested access to the resource is denied
ERROR: pull access denied for example, repository does not exist or may require 'docker login': denied: requested access to the resource is denied
```

## Additional information

Darwin, downloaded docker from docker.com/get-started
",,,fabienrenaud,"
--
@collin5 Can we get the original behavior re-introduced? `pull` should just pull. Building on pull failure (issue #6464) should be an option (e.g: `docker-compose pull --build`), otherwise the change is not backward-compatible (docker-compose v1.x) and pull starts having new/undesirable side effects.
--

--
Still needed.
--
",seanmorris,"
--
> @collin5 Can we get the original behavior re-introduced? `pull` should just pull. Building on pull failure (issue #6464) should be an option (e.g: `docker-compose pull --build`), otherwise the change is not backward-compatible (docker-compose v1.x) and pull starts having new/undesirable side effects.

I second this. I already have separate compose files for dev, test and two for production (frontend/backend). I've also got a base file. I don't want development instrumentation in my test/prod container (ie xdebug) and I don't want testing instrumentation in my prod images (ie phpunit).

I've already got a makefile to manage this complexity and I don't want to add another layer of complication here. A flag would be very elegant.
--
",stale,"
--
This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you for your contributions.

--

--
This issue has been automatically marked as not stale anymore due to the recent activity.

--
",,,,,,
7256,OPEN,Environment variable expansion: environment variable in default fails,kind/bug,2021-01-30 16:03:41 +0000 UTC,vitaly-krugl,Opened,,"## Description of the issue
When I use an environment variable in the default value of an environment variable as follows:
```
version: '3'
services:
  dev:
    image: image_name
    build: .
    volumes:
      ""${SETTINGS_LOCAL-${PWD}/config/dummy_settings.json}:/a/etc/app/settings.json:ro""
```

`docker-compose config` and other sub-commands fail with ""ERROR: Named volume ""${PWD/config/dummy_settings.json}:/a/etc/app/settings.json:ro"" is used in service ""dev"" but no declaration was found in the volumes section.""


## Context information (for bug reports)

**Output of `docker-compose version`**
```
docker-compose version 1.25.4, build 8d51620a
docker-py version: 4.1.0
CPython version: 3.7.5
OpenSSL version: OpenSSL 1.1.1d  10 Sep 2019
```

**Output of `docker version`**
```
Client: Docker Engine - Community
 Version:           19.03.5
 API version:       1.40
 Go version:        go1.12.12
 Git commit:        633a0ea
 Built:             Wed Nov 13 07:22:34 2019
 OS/Arch:           darwin/amd64
 Experimental:      false

Server: Docker Engine - Community
 Engine:
  Version:          19.03.5
  API version:      1.40 (minimum version 1.12)
  Go version:       go1.12.12
  Git commit:       633a0ea
  Built:            Wed Nov 13 07:29:19 2019
  OS/Arch:          linux/amd64
  Experimental:     false
 containerd:
  Version:          v1.2.10
  GitCommit:        b34a5c8af56e510852c35414db4c1f4fa6172339
 runc:
  Version:          1.0.0-rc8+dev
  GitCommit:        3e425f80a8c931f88e6d94a8c831b9d5aa481657
 docker-init:
  Version:          0.18.0
  GitCommit:        fec3683
```

**Output of `docker-compose config`**
(Make sure to add the relevant `-f` and other flags)
```
ERROR: Named volume ""${PWD/config/dummy_settings.json}:/a/etc/app/settings.json:ro"" is used in service ""dev"" but no declaration was found in the volumes section.
```


## Steps to reproduce the issue

1. In the volumes section of a service, use an environment variable inside the default value of an environment variable.
2. Run `docker-compose config` or `docker-compose build`
3.

### Observed result
```
ERROR: Named volume ""${PWD/config/dummy_settings.json}:/a/etc/app/settings.json:ro"" is used in service ""dev"" but no declaration was found in the volumes section.
```

### Expected result
Expected `${PWD}` to be substituted correctly within the default value of `SETTINGS_LOCAL` environment variable.

## Additional information

```
macOS Catalina. v 10.15.3
```
",,,caringco,"
--
Hi All,
Unsure if this is related to this bug - but below is my issue:

**docker-compose.yml**
```
version: '3'

services:
  test:
    build: 
      context: .    
    environment:
      - NODE_ENV=production
      - DATABASE_MASTER=master
    command: echo $DATABASE_MASTER + $NODE_ENV
```
**Dockerfile**
```
FROM alpine
```
**docker version**
```
Client: Docker Engine - Community
 Version:           19.03.5
 API version:       1.40
 Go version:        go1.12.12
 Git commit:        633a0ea
 Built:             Wed Nov 13 07:22:34 2019
 OS/Arch:           darwin/amd64
 Experimental:      false

Server: Docker Engine - Community
 Engine:
  Version:          19.03.5
  API version:      1.40 (minimum version 1.12)
  Go version:       go1.12.12
  Git commit:       633a0ea
  Built:            Wed Nov 13 07:29:19 2019
  OS/Arch:          linux/amd64
  Experimental:     false
 containerd:
  Version:          v1.2.10
  GitCommit:        b34a5c8af56e510852c35414db4c1f4fa6172339
 runc:
  Version:          1.0.0-rc8+dev
  GitCommit:        3e425f80a8c931f88e6d94a8c831b9d5aa481657
 docker-init:
  Version:          0.18.0
  GitCommit:        fec3683
```
**docker-compose version**
```
docker-compose version 1.25.4, build 8d51620a
docker-py version: 4.1.0
CPython version: 3.7.5
OpenSSL version: OpenSSL 1.1.1d  10 Sep 2019
```

**docker-compose config**
```
WARNING: The DATABASE_MASTER variable is not set. Defaulting to a blank string.
WARNING: The NODE_ENV variable is not set. Defaulting to a blank string.
services:
  test:
    build:
      context: /Users/***/workspace/test
    command: 'echo  + '
    environment:
      DATABASE_MASTER: master
      NODE_ENV: production
version: '3.0'
```
Mac OS Catalina 10.15.3

Expected result should be that the environment variables should be getting picked up.
Please can anyone help me solve this? I do not want to use .env files etc.






--
",Mahima,"
--
@caringco  You can visit [my comment on the same issue](https://github.com/docker/compose/issues/7423#issuecomment-667059548) 

I solved the issue by taking the below two steps.

1. I uninstalled the older docker-compose and installed the latest by following [official documentation](https://docs.docker.com/compose/install/)
2. I renamed the service for which the environment variables were defined in the docker-compose.yml.

Later on, I rechecked with the old service name and found that the issue reappeared. Then I removed the older container and again did docker-compose up. This solved the issue. So I think, it might be the old container which does not let us see the new changes.

Hope this helps.
--
",stale,"
--
This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you for your contributions.

--

--
This issue has been automatically marked as not stale anymore due to the recent activity.

--
",vitaly,"
--
Could the maintainer please state whether this issue has been fixed?
--
",,,,
7253,OPEN,have a permanent link for the latest version such as: https://github.com/docker/compose/releases/download/latest/,kind/feature,2020-02-27 13:31:39 +0000 UTC,JOduMonT,Opened,,"I understand my [question/comment/bug](https://github.com/docker/compose/issues/7243) is kinda silly but why it is impossible to simply install docker-compose such as a link pointing to the last version so we could do something like the to update it

````bash
curl -L ""https://github.com/docker/compose/releases/download/latest/docker-compose-$(uname -s)-$(uname -m)"" -o /usr/local/bin/docker-compose
````

instead of

````bash
DockerComposeVersion=""$(curl -fsSL https://github.com/docker/compose/releases/latest|grep Release|grep title|rev|cut -d' ' -f5|rev)""

curl -L ""https://github.com/docker/compose/releases/download/${DockerComposeVersion}/docker-compose-$(uname -s)-$(uname -m)"" -o /usr/local/bin/docker-compose
````",,,,,,,,,,,,,,
7252,OPEN,Dockerfile parsing error when using mount flag,kind/bug,2021-01-31 16:17:17 +0000 UTC,grafoo,Opened,,"## Description of the issue
Parsing the `Dockerfile` fails for the `build` command with ""ERROR: Dockerfile parse error line ...: Unknown flag: mount"", when using e.g. ""RUN --mount=type=ssh"" in the `Dockerfile`.
## Context information (for bug reports)
- `DOCKER_BUILDKIT` is enabled
- `docker build --ssh default ...` works as expected
**Output of `docker-compose version`**
```
docker-compose version 1.25.4, build 8d51620a
docker-py version: 4.1.0
CPython version: 3.7.5
OpenSSL version: OpenSSL 1.1.0l  10 Sep 2019
```

**Output of `docker version`**
```
Client: Docker Engine - Community
 Version:           19.03.6
 API version:       1.40
 Go version:        go1.12.16
 Git commit:        369ce74a3c
 Built:             Thu Feb 13 01:27:59 2020
 OS/Arch:           linux/amd64
 Experimental:      false

Server: Docker Engine - Community
 Engine:
  Version:          19.03.6
  API version:      1.40 (minimum version 1.12)
  Go version:       go1.12.16
  Git commit:       369ce74a3c
  Built:            Thu Feb 13 01:26:33 2020
  OS/Arch:          linux/amd64
  Experimental:     false
 containerd:
  Version:          1.2.12
  GitCommit:        35bd7a5f69c13e1563af8a93431411cd9ecf5021
 runc:
  Version:          1.0.0-rc10
  GitCommit:        dc9208a3303feef5b3839f4323d9beb36df0a9dd
 docker-init:
  Version:          0.18.0
  GitCommit:        fec3683
```

**Output of `docker-compose config`**
(Make sure to add the relevant `-f` and other flags)
```
services:
  service:
    build:
      context: /tmp
      dockerfile: d
    environment:
      DOCKER_BUILDKIT: '1'
    image: debian
version: '3.7'
```


## Steps to reproduce the issue
```
cat <<EOF >Makefile
docker-build:
        DOCKER_BUILDKIT=1 docker -l debug build --no-cache --ssh default -t foo .
compose-build:
        DOCKER_BUILDKIT=1 docker-compose build --build-arg ""'--ssh'=default""
EOF
```

### Observed result
Build fails with  ""ERROR: Dockerfile parse error line ...: Unknown flag: mount""
### Expected result
Build should also work with `docker-compose` as it those with `docker`.
### Stacktrace / full error message

```
DOCKER_BUILDKIT=1 docker-compose build --build-arg ""'--ssh'=default""
Building service
ERROR: Dockerfile parse error line ...: Unknown flag: mount
```

## Additional information

- 9.12 / debian
- installed using ""https://github.com/docker/compose/releases/download/1.25.4/docker-compose-Linux-x86_64""
",,,agronholm,"
--
Perhaps you forgot to set `COMPOSE_DOCKER_CLI_BUILD=1`?
--

--
@sj26 What does your Dockerfile look like?
--

--
Works fine here.
--

--
Yeah, sorry, it does give me an error when doing `docker-compose run` directly.
--
",devniel,"
--
Yes,  `export COMPOSE_DOCKER_CLI_BUILD=1` and `export DOCKER_BUILDKIT=1` resolve it.
--
",kmr0877,"
--
@grafoo 
Did the above fix work? If not, r u still getting the same error? 
Also this is not necessarily a bug?
--

--
You can alternatively try building with `buildx` , see [here](https://docs.docker.com/buildx/working-with-buildx/#build-with-buildx) for more info. As it says :
**Buildx builds using the BuildKit engine and does not require DOCKER_BUILDKIT=1 environment variable to start the builds.**

You can run below command to create buildx instance and give it a try if it works. See [here](https://github.com/docker/buildx/#working-with-builder-instances) for more information
`docker buildx create --use --name buildkit && docker buildx inspect`
--
",GunnerGuyven,"
--
I have the same problem as this ticket mentions.  Adding `COMPOSE_DOCKER_CLI_BUILD=1` and `DOCKER_BUILDKIT=1` do indeed invoke the newer build engine, but do not resolve this issue for me.

I have the addition problem / question of how to express this build argument properly within the `docker-compose.yml` file?  My compose file handles more than one image, and I don't need the `--ssh=default` for all of them.
--

--
Not to speak for OP, but I know for me the issue isn't manual building.  I have a build script that builds my images no sweat.  The problem is delegating the build responsibility to docker-compose for the many host of reasons you'd want to do that in normal circumstances.  Docker-compose can trigger builds, but in the circumstance of using the `--ssh` flag it cannot.  That's the crux of the friction as I see it.
--
",weima,"
--
If you still have not solve this problem. Please remember to add 
`# syntax=docker/dockerfile:experimental`
To the very beginning of your Dockerfile. I struggled for almost 2 hours before realizing this was my problem. 
--
",sj26,"
--
I have a Dockerfile which works great with `DOCKER_BUILDKIT=1 docker build -t app .`, and am using docker-compose 1.26.2, yet `COMPOSE_DOCKER_CLI_BUILD=1 DOCKER_BUILDKIT=1 docker-compose run app` fails with a `ERROR: Dockerfile parse error line ...: Unknown flag: mount` when using a cache mount.

```
$ docker version
Client: Docker Engine - Community
 Version:           19.03.12
 API version:       1.40
 Go version:        go1.13.10
 Git commit:        48a66213fe
 Built:             Mon Jun 22 15:41:33 2020
 OS/Arch:           darwin/amd64
 Experimental:      false

Server: Docker Engine - Community
 Engine:
  Version:          19.03.12
  API version:      1.40 (minimum version 1.12)
  Go version:       go1.13.10
  Git commit:       48a66213fe
  Built:            Mon Jun 22 15:49:27 2020
  OS/Arch:          linux/amd64
  Experimental:     false
 containerd:
  Version:          v1.2.13
  GitCommit:        7ad184331fa3e55e52b890ea95e65ba581ae3429
 runc:
  Version:          1.0.0-rc10
  GitCommit:        dc9208a3303feef5b3839f4323d9beb36df0a9dd
 docker-init:
  Version:          0.18.0
  GitCommit:        fec3683

$ docker-compose version
docker-compose version 1.26.2, build eefe0d31
docker-py version: 4.2.2
CPython version: 3.7.7
OpenSSL version: OpenSSL 1.1.1g  21 Apr 2020
```
--

--
Here's a reproducing case:
https://gist.github.com/sj26/5c403481267a455dede515906ca0462c

```
$ COMPOSE_DOCKER_CLI_BUILD=1 DOCKER_BUILDKIT=1 docker-compose run app true
Building app
ERROR: Dockerfile parse error line 9: Unknown flag: mount
```
--

--
Yes, `docker-compose build ...` works fine:

```
$ COMPOSE_DOCKER_CLI_BUILD=1 DOCKER_BUILDKIT=1 docker-compose build app     
WARNING: Native build is an experimental feature and could change at any time
Building app
[+] Building 3.9s (8/13)                                                                                                                                       
 => [internal] load .dockerignore                                                                                                                         0.0s
 => => transferring context: 2B                                                                                                                           0.0s
 => [internal] load build definition from Dockerfile                                                                                                      0.0s
 => => transferring dockerfile: 2.06kB                                                                                                                    0.0s
 => resolve image config for docker.io/docker/dockerfile:experimental                                                                                     2.5s
 => CACHED docker-image://docker.io/docker/dockerfile:experimental@sha256:de85b2f3a3e8a2f7fe48e8e84a65f6fdd5cd5183afa6412fff9caa6871649c44                0.0s
 => [internal] load metadata for docker.io/library/ruby:2.6.5                                                                                             0.0s
 => https://www.postgresql.org/media/keys/ACCC4CF8.asc                                                                                                    1.2s
 => [base 1/5] FROM docker.io/library/ruby:2.6.5                                                                                                          0.0s
 => https://deb.nodesource.com/gpgkey/nodesource.gpg.key                                                                                                  0.0s
 => https://dl.yarnpkg.com/debian/pubkey.gpg                                                                                                              0.1s
```

This seems like a big in docker-compose run?
--
"
7248,OPEN,Save running containers as a compose file,kind/feature,2020-02-25 06:01:02 +0000 UTC,cartsp,Opened,,"Hi,

I assume a lot of us get a setup we like but would like the ability to move all our containers easily.  Portainer is able to see what I am running and the configuration I am using so would it not be possible to introduce a command to capture the running containers and their configuration and generate a compose file so it can easily be moved among hosts/if the user chooses to change their Distro/reinstalls etc?",,,,,,,,,,,,,,
7239,OPEN,Accept Circular dependency between containers,kind/feature,2020-02-19 11:14:18 +0000 UTC,augnustin,Opened,,"**Is your feature request related to a problem? Please describe.**

I have this config:

```
services:
  app:
    image: node:latest
    command: npm start
  nginx:
    image: nginx:latest
    depends_on: 
      - app
    ports:
      - 80:80
```

I set `nginx` depends on `app` since if `app` is not started, `nginx` doesn't work.

But in my local environment, I want to have an interactive console to being able to run commands in my working environment.

Hence `docker-compose run --rm --service-ports app bash` is the way to go. There, I can for instance `npm install`, `rm cache_files` etc.

But if I do that, `nginx` is not started and the port 80 is not opened. 

**Describe the solution you'd like**

I suggest to allow:

```
services:
  app:
    image: node:latest
    command: npm start
    depends_on: 
      - nginx
  nginx:
    image: nginx:latest
    depends_on: 
      - app
```

So that if `app` is started, `nginx` also is and the other way round. 

The circular dependency thing doesn't seem to be such a thing: when looking at the `depends_on` list, if it is started, do nothing, otherwise start it. There could be an issue when stopping a service, but either `docker-compose` could remember which service started the other so that children get closed in the meantime, or do nothing is also a valid solution : it is not a big deal if my DB is not shut down after I stop my app afterall.

I read somewhere that `depends_on` has to do with networking, which may have implications I don't anticipate. If there really is something blocking there, one could imagine another key like `start_with`, which would simply handle the start behavior, not the dependency one.

**Describe alternatives you've considered**

1. I can add to `docker-compose.override.yml` a port to `app`:

```
services:
  app:
   ports:
     - 80:3000
```

But then I need to switch every time I change from `docker-compose run` to `docker-compose up` (which is still very useful to be closer to prod config). This is a pain and brings much confusion.

2. Another solution is to always `docker-compose up` and then `docker-compose exec app bash` ([which is buggy](https://github.com/docker/compose/issues/7228)) to have the interactive terminal, but usually changes require a server restart, which means I need to

```
docker-compose restart app
```
in another terminal, and it closes my `docker-compose exec` session (as the container is stopped), so that's way too many actions for a simple server config change.

3. Another solution I looked for would have been to being able to have an interactive terminal when running `docker-compose up`. I looked at the `tty: true` option, but apparently it is not meant to do what I'd like: https://github.com/docker/compose/issues/5741

So I guess I need to stick with `docker-compose run`.

4. Finally, I could imagine having the following `docker-compose.override.yml`

```
services:
  app:
    depends_on: 
      - nginx
  nginx:
    depends_on: NONE
```

so that in local environment, the dependency in switched. I did open an issue to being able to remove key with overrides, but it doesn't seem to be approved for now: https://github.com/docker/compose/issues/7231

So for now, I can't find any decent solution. :disappointed: 
",,,,,,,,,,,,,,
7230,OPEN,Abort on non-zero exit code,kind/feature,2020-03-06 18:57:50 +0000 UTC,mangas,Opened,,"**Is your feature request related to a problem? Please describe.**
When using docker-compose to run finite tasks, like tests, is hard to detect a failure from the exit code as there is no way of cascading just non-zero errors

**Describe the solution you'd like**
An option very similar to --abort-on-container-exit that will only abort of failure i.e non-zero exit code 

**Describe alternatives you've considered**
Using bash scripts and docker inspect to figure out the exit code for each container 

Happy to submit a PR if this is something you'd be happy to accept as an additional docker-compose up option
",,,ricmzn,"
--
Have you tried using `docker-compose run` instead of `docker-compose up` for running tests and scripts? That will give you the exit code when the container finishes, but you will need to run each script/test separately.
--
",,,,,,,,,,
7227,OPEN,Error: for web-dev UnixHTTPConnectionPool(Host='localhost'; Port=None): Read timed out.,kind/bug,2020-12-29 10:21:16 +0000 UTC,waxim,Opened,,"3. When making a bug report, make sure you provide all required information. The easier it is for
   maintainers to reproduce, the faster it'll be fixed.
-->

## Description of the issue
When mounting a volume in docker-compose to a symlink'd folder that does not exist this error is returned (it seems due to a memory leak in `com.docker.osxfs`) 

## Context information (for bug reports)

**Output of `docker-compose version`**
```
docker-compose version 1.25.2, build 698e2846
docker-py version: 4.1.0
CPython version: 3.7.5
OpenSSL version: OpenSSL 1.1.1d  10 Sep 2019
```

**Output of `docker version`**
```
Client: Docker Engine - Community
 Version:           19.03.5
 API version:       1.40
 Go version:        go1.12.12
 Git commit:        633a0ea
 Built:             Wed Nov 13 07:22:34 2019
 OS/Arch:           darwin/amd64
 Experimental:      false

Server: Docker Engine - Community
 Engine:
  Version:          19.03.5
  API version:      1.40 (minimum version 1.12)
  Go version:       go1.12.12
  Git commit:       633a0ea
  Built:            Wed Nov 13 07:29:19 2019
  OS/Arch:          linux/amd64
  Experimental:     false
 containerd:
  Version:          v1.2.10
  GitCommit:        b34a5c8af56e510852c35414db4c1f4fa6172339
 runc:
  Version:          1.0.0-rc8+dev
  GitCommit:        3e425f80a8c931f88e6d94a8c831b9d5aa481657
 docker-init:
  Version:          0.18.0
  GitCommit:        fec3683
```

**Output of `docker-compose config`**
(Make sure to add the relevant `-f` and other flags)
```
version: '3'

services:
  web-dev:
    tty: true
    environment:
      - COMPOSER_HOME=/composer
      - XDEBUG=on
      - PHP_IDE_CONFIG=serverName=api.web.io
      # Uncomment the following variables to enable and configure blackfire.
      #- BLACKFIRE_CLIENT_ID=
      #- BLACKFIRE_CLIENT_TOKEN=
      #- BLACKFIRE_SERVER_ID=
      #- BLACKFIRE_SERVER_TOKEN=
    build: ./docker/
    container_name: web-dev
    security_opt:
      - seccomp:unconfined
    ports:
      - ""10080:10080"" # API HTTP
      - ""10443:10443"" # API HTTPS
      - ""13080:13080"" # SEG HTTP
      - ""13443:13443"" # SEG HTTPS
    volumes:
      # web-Nurv
      - ./source/nurv-2.0:/var/www/html/web.dev/nurv/2.0
      - ./source/nurv-2.0/private/config/web.dev:/var/www/html/web.dev/nurv/2.0/config
      - ./source/nurv-2.0/private/config/simon:/var/www/html/web.dev/nurv/2.0/config/simon
      - ./source/nurv-2.0/private/config/routing:/var/www/html/web.dev/nurv/2.0/config/routing
      - ./source/nurv-2.0/index_dev.php:/var/www/html/web.dev/nurv/2.0/index.php

      # web-API
      - ./source/api-1.1:/var/www/html/web.dev/api/1.1
      - ./source/api-1.1/private/config/web.dev:/var/www/html/web.dev/api/1.1/config
      - ./source/api-1.1/private/config/simon:/var/www/html/web.dev/api/1.1/config/simon
      - ./source/api-1.1/private/config/routing:/var/www/html/web.dev/api/1.1/config/routing
      - ./source/api-1.1/index_dev.php:/var/www/html/web.dev/api/1.1/index.php

      # Seg-2.0
      - ./source/seg-api-2.0/2.0/api:/var/www/html/web.dev/seg/2.0/api

      # Simon
      - ./source/simon:/var/www/html/web.dev/simon

      # web-Book
      - ./source/book:/var/www/html/web.dev/book

      # Auth file
      - ./source/api-1.1/private/config/web.dev/.htpasswd:/var/www/html/web.dev/.htpasswd

      # Custom init script
      - ./docker/my_init/:/etc/my_init.d/

      # Nginx Config
      - ./docker/conf/nginx/:/etc/nginx/
      - ./docker/conf/php-fpm.d:/etc/php/7.2/fpm/pool.d/

      # PHP Config
      - ./docker/conf/php/xdebug.ini:/etc/php/7.2/mods-available/xdebug.ini
      - ./docker/conf/php/xdebug.ini:/etc/php/7.2/cli/conf.d/xdebug.ini
      - ./source/api/private/config/web.dev/opcache.blacklist:/etc/php/7.2/fpm/conf.d/opcache.blacklist
      - ./docker/conf/php/blackfire.ini:/etc/php/7.2/fpm/conf.d/20-blackfire.ini
      - ./docker/conf/php/opcache.ini:/etc/php/7.2/cli/conf.d/10-opcache.ini
      - ./docker/conf/php/custom.ini:/etc/php/7.2/fpm/conf.d/99-custom.ini
      - ./docker/conf/php/php.ini:/etc/php/7.2/fpm/php.ini
      - ./docker/conf/etc/blackfire-agent:/etc/blackfire/agent

      # SSH Config
      - ./source/.ssh:/root/.ssh_

      # Composer Cache
      - ./.composer:/composer:delegated

      # Scripts
      - ./docker/scripts:/root/scripts
    ulimits:
      nproc: 65535
      nofile:
        soft: 20000
        hard: 40000
    working_dir: /var/www/html/web.dev
    logging:
      driver: ""json-file""
      options:
        max-size: ""1m""
        max-file: ""1""
```


## Steps to reproduce the issue

1. Add a volume that maps to a symlink'd local folder that does not exist

### Observed result
`com.docker.osxfs` spikes in memory usage and maxes out all available memory, then docker-compose failes with the following error

```
Error: for web-dev UnixHTTPConnectionPool(Host='localhost', Port=None): Read timed out. 
```

### Expected result
docker compose should gracefully return an error explaining the volume could not be mounted because it does not exist. 

## Additional information

OS version / distribution, `docker-compose` install method, etc.
  Model Name:	MacBook Air
  Model Identifier:	MacBookAir8,1
  Processor Name:	Dual-Core Intel Core i5
  Processor Speed:	1.6 GHz
  Number of Processors:	1
  Total Number of Cores:	2
  L2 Cache (per Core):	256 KB
  L3 Cache:	4 MB
  Hyper-Threading Technology:	Enabled
  Memory:	8 GB
  Boot ROM Version:	1037.80.53.0.0 (iBridge: 17.16.13050.0.0,0)",,,Manubi,"
--
Any news? :)
--
",gautamsinghania95,"
--
+1
--
",,,,,,,,
7215,OPEN,Volumes for other service fail service to start,kind/enhancement,2021-02-07 19:03:19 +0000 UTC,ilons,In progress,,"## Description of the issue
When starting a service in a compose file with multiple services, volumes for services not affected by the current invocation are resolved and fails the command if not resolved correctly.
This was discovered when running docker-compose logs on a service, and it failed when it could not resolve the volume for another service in the file.

## Context information (for bug reports)

**Output of `docker-compose version`**
```
docker-compose version 1.24.1, build 4667896
docker-py version: 3.7.3
CPython version: 2.7.16
OpenSSL version: OpenSSL 1.1.1d FIPS  10 Sep 2019
```

**Output of `docker version`**
```
Client: Docker Engine - Community
 Version:           19.03.3
 API version:       1.40
 Go version:        go1.12.10
 Git commit:        a872fc2f86
 Built:             Tue Oct  8 00:58:27 2019
 OS/Arch:           linux/amd64
 Experimental:      false

Server: Docker Engine - Community
 Engine:
  Version:          19.03.3
  API version:      1.40 (minimum version 1.12)
  Go version:       go1.12.10
  Git commit:       a872fc2f86
  Built:            Tue Oct  8 00:57:04 2019
  OS/Arch:          linux/amd64
  Experimental:     false
 containerd:
  Version:          1.2.10
  GitCommit:        b34a5c8af56e510852c35414db4c1f4fa6172339
 runc:
  Version:          1.0.0-rc8+dev
  GitCommit:        3e425f80a8c931f88e6d94a8c831b9d5aa481657
 docker-init:
  Version:          0.18.0
  GitCommit:        fec3683
```

**Output of `docker-compose config`**
(Make sure to add the relevant `-f` and other flags)
```
$ docker-compose -f compose-logs.yml config
ERROR: Named volume ""test:/test:rw"" is used in service ""unused-service"" but no declaration was found in the volumes section.
```
The actual configuration file:
```
version: ""3.7""
services:
  test-service:
    image: busybox
  unused-service:
    image: busybox
    volumes:
      - ${MY_PATH_VAR:-}test:/test
```

## Steps to reproduce the issue

1. Create a compose-file with two services: 
```
services:
  test-service:
    image: busybox
  unused-service:
    image: busybox
    volumes:
      - ${MY_PATH_VAR:-}test:/test
```
2. Try to run any docker-compose command involving only `test-service`, such as `docker-compose up test-service`

### Observed result
Docker-Compose tries to resolve volumes for the `unused-service` service, which fails. Even if this service is not affected by the command being run.
```
ERROR: Named volume ""test:/test:rw"" is used in service ""unused-service"" but no declaration was found in the volumes section.
```

### Expected result
The `test-service` should start

### Stacktrace / full error message
```
ERROR: Named volume ""test:/test:rw"" is used in service ""unused-service"" but no declaration was found in the volumes section.
```

## Additional information
The use-case for using this config are that we run docker-compose with the help of `make`, which then calculates and feeds in the `MY_PATH_VAR` value to be used.
This works as expected, the problem occurs when we try to run `docker-compose` directly, such as checking logs for a dependency service, or when doing `docker-compose down`.

I understand that this is probably due to the whole configuration file being parsed when running docker-compose, regardless of what command is being used.
That being said, I think this should not fail, as for example, if you instead specify a mount-point which does not exist (setting the `MY_PATH_VAR` to any value), it works just fine, as the volume is never actually mounted.

OS version / distribution, `docker-compose` install method, etc.
Probably not relevant;
OS: Fedora 30
Kernel: 5.2.18-200.fc30.x86_64
Installation method: yum",,,ndeloof,"
--
We could indeed consider implementing sort of ""lazy-validation"" of service configuration so that unused services just get ignored.
--
",bartier,"
--
@ilons Is this issue still relevant? I'm new here and I could not reproduce following the steps:

Docker-compose: 1.26.0dev
Docker version 19.03.9, build 9d988398e7


```
$ docker-compose -f compose-logs.yml config # this should be an error instead of the current output
services:
  test-service:
    image: busybox
  unused-service:
    image: busybox
    volumes:
    - /test:/test:rw
version: '3.7'

$ cat compose-logs.yml 
version: ""3.7""
services:
  test-service:
    image: busybox
  unused-service:
    image: busybox
    volumes:
      - ${MY_PATH_VAR:-}test:/test
```

If I were able to reproduce this, I'd try to fix this if possible
--
",ilons,"
--
Sorry about the late reply.

This is indeed still relevant  (version details at bottom).
Smaller `docker-compose.yml` to reproduce, `cat docker-compose.yml`:
```
version: ""3""
services:
  test-service:
    image: busybox
  unused-service:
    image: busybox
    volumes:
      - test:/test
```
`docker-compose -f docker-compose.yml config`, (or specifically: `docker-compose -f docker-compose.yml up test-service`):
```
ERROR: Named volume ""test:/test:rw"" is used in service ""unused-service"" but no declaration was found in the volumes section.
```

## Version info
`docker-compose version`
```
docker-compose version 1.25.4, build unknown
docker-py version: 4.2.0
CPython version: 3.8.3
OpenSSL version: OpenSSL 1.1.1g FIPS  21 Apr 2020
```
`docker version`
```
Client:
 Version:           19.03.11
 API version:       1.40
 Go version:        go1.14.3
 Git commit:        42e35e6
 Built:             Sun Jun  7 21:16:58 2020
 OS/Arch:           linux/amd64
 Experimental:      false

Server:
 Engine:
  Version:          19.03.11
  API version:      1.40 (minimum version 1.12)
  Go version:       go1.14.3
  Git commit:       42e35e6
  Built:            Sun Jun  7 00:00:00 2020
  OS/Arch:          linux/amd64
  Experimental:     false
 containerd:
  Version:          1.3.3
  GitCommit:        
 runc:
  Version:          1.0.0-rc10+dev
  GitCommit:        fbdbaf85ecbc0e077f336c03062710435607dbf1
 docker-init:
  Version:          0.18.0
  GitCommit:    
```
--

--
> @ilons Is this issue still relevant? I'm new here and I could not reproduce following the steps:
> 
> Docker-compose: 1.26.0dev
> Docker version 19.03.9, build 9d988398e7
> 
> ```
> $ docker-compose -f compose-logs.yml config # this should be an error instead of the current output
> services:
>   test-service:
>     image: busybox
>   unused-service:
>     image: busybox
>     volumes:
>     - /test:/test:rw
> version: '3.7'
> 
> $ cat compose-logs.yml 
> version: ""3.7""
> services:
>   test-service:
>     image: busybox
>   unused-service:
>     image: busybox
>     volumes:
>       - ${MY_PATH_VAR:-}test:/test
> ```
> 
> If I were able to reproduce this, I'd try to fix this if possible

@ndeloof response above.
--
",stale,"
--
This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you for your contributions.

--

--
This issue has been automatically marked as not stale anymore due to the recent activity.

--
",,,,
7203,OPEN,Allow turning off error checking in the config command,kind/feature,2020-07-02 15:43:18 +0000 UTC,chrisjohnson,Opened,,"**Is your feature request related to a problem? Please describe.**

We use docker-compose with multiple config files. We want to begin testing these files with conftest. In order to be able to pass the composed configuration to conftest, we use `docker-compose -f foo.yml -f bar.yml config | conftest test -`

However, foo.yml and/or bar.yml may have variable interpolation baked in. So we can add `--no-interpolate` to the config command so that conftest is able to get the non-interpolated value (and we can write a policy that, for instance, determines that the `image` is set to the value `${IMAGE}:${TAG}`, or that one and only one port is set to `${PORT}:3000`).

Unfortunately, docker-compose config also validates that the output it produces is valid. And `${PORT}:3000` is not a valid port definition.

**Describe the solution you'd like**
A `--no-error` flag added to `docker-compose config` would allow us the following setup:

`docker-compose -f a.yml -f b.yml config --no-error --no-interpolate | conftest test -`

This would produce a yaml file that is merged according to the algorithm docker-compose uses, without any interpolation applied, and pass that to conftest for policy checks

**Describe alternatives you've considered**
Right now, we are doing: `yq merge a.yml b.yml | conftest test -` but I can already tell this will come back to bite us because the docker-compose merge algorithm is not the same as the yq one.",,,carlfischerjba,"
--
Here's a minimal example.

### Steps

docker-compose.yml
```
version: ""3.5""
services:
  shell:
    image: busybox
    environment:
        - FOO=${FOO:-foo}
    volumes:
        - ${DIR:-./}:/data:ro

```

```
$ docker-compose -f test.yml config --no-interpolate
```

### Actual result

```
ERROR: Volume ${DIR:-./}:/data:ro has incorrect format, should be external:internal[:mode]
```

### Expected result

Outputs a compose file identical to the input.


### Practical use case

In practice I'd like to combine multiple compose files so I can use the output in [Portainer](https://www.portainer.io/) which currently only supports a single compose file per stack. So I'd like to run a command like this.

```
docker-compose -f docker-compose.yml -f docker-compose.traefik.yml -f docker-compose.extras.yml config --no-interpolate > docker-compose.full.yml
```
--
",,,,,,,,,,
7201,OPEN,Validate compose file on supported API; not version,area/config; format/v2; format/v3; kind/feature,2020-06-22 07:55:17 +0000 UTC,ndeloof,In progress,,"**Is your feature request related to a problem? Please describe.**
docker-compose validates a docker-compose.yml file based on `version` top-level element, and use matching json schema for this purpose.

Doing so:

- if a newcomer copy/paste some sample configuration without using the adequate version, an error will occur
- docker-compose will reject fields introduced in a recent version until user updates `version` accordingly, whenever this field is fully supported and mapping to docker engine implemented
- docker-compose will select Docker API according to `version`, not based on actual needs. User to select a recent `version` will get his docker-compose.yaml file rejected when using an old version of the engine (some distro still only support 1.13), whenever new API might not be actually needed.
- multiple compose files to be merged MUST use the *exact* same version.

note: `version` is required to distinguish with 1.x format

2.x and 3.x are mostly [always adding new fields](https://docs.docker.com/compose/compose-file/compose-versioning/) or just replacing them with alternative equivalent fields. 3.x major version removed some fields that are still implemented by docker-compose and artificially rejected withing the code by version range checks.

**Describe the solution you'd like**
Better than locking features based on declared `version` field, docker-compose should check API exposed by the engine (docker info `ApiVersion`) and warn user if some of the fields set by his docker-compose.yml file *can't* be implemented with this version of the API.

So I propose docker-compose to evolve so that:
- version of the compose schema used for validation supports all 2.x and 3.x fields
- all configuration fields are implemented regardless version declared in compose file(s)
- docker-compose check engine API and warn user for feature that can't be implemented
- `version` field is made optional. As long as docker-compose.yaml file is valid according to schema is is considered valid. If it doesn't docker-compose will attempt to parse as a 1.x file for backward compatibility, and warn user for deprecation


**Describe alternatives you've considered**


**Additional context**
",,,justincormack,"
--
I am not even convinced we need to deprecate v1, just try parsing that schema as well.
--
",sudo,"
--
(Speaking as a user so take this as an uninformed opinion.)

I am a little concerned of how this might impact error handling. If a yml file is not parseable with any of the versions, it may be difficult to identify what the user was trying to do and give a good error message.  This concern comes from seeing users mixing version 1 and version 2/3 syntax in a single file, so it's not clear if you should error that there are invalid parameters to the service named ""services"" or if you should flag the invalid top level keyword from the v1 service name.

I do like the idea of merging the 2.0 - 3.x versions into a single parsing since they are all relatively compatible and I've run into plenty of errors for minor version number mismatches that could have been ignored.

A few thoughts for how to improve things going forward:

- Deprecate the implicit version 1 syntax, instead requiring an explicit version line. Generate a warning that the version line is missing. Then make a best effort at parsing the file. If all parsing attempts fail then the error can be a missing version line.
- Make the `version: 2` and `version: 3` lines automatically match the highest version rather than 2.0 and 3.0 respectively. This would better follow expectations from users accustomed to semver.
- Consider a `requires` top level clause to allow dependencies on functionality added in a specific version. Docker could then error out when parsing with an older version. This would solve the version mismatch issue when merging multiple files since each file could require something different, while all files are loaded into the most recent available version syntax.
- As an alternative to the `requires`, automatically up-convert versions when merging files rather than requiring versions to match.

I'm also hesitant to remove the version completely since future releases may need major syntax redesigns the way v1 to v2 did. For instance, adding a ""pod"" concept to docker services may require a v4 syntax.
--

--
> itentifying a v1 file is easy as its top-level structure is distinct from v2/v3

Identify v1 vs v2/v3 in well formatted files should be easy enough, I'm thinking more of the error scenarios when users try to parse:

```
redis:
  image: redis
services:
  app:
    image: my-app
```

Do you error that `app` is not a valid field, or that `redis` is not a valid top level. Here's an [example of this from a few days ago](https://stackoverflow.com/q/59939077/596285). My suggestion is to error ""parsing failed, version field missing"" rather than assuming one or the other. But that unfortunately goes against the premise of this RfC.
--
",thaJeztah,"
--
> some distro still only support 1.13

Those 1.13 versions are a fork of Docker, and have many, many issues anyway (not something we should take into account).

> Better than locking features based on declared version field, docker-compose should check API exposed by the engine (docker info ApiVersion) and warn user if some of the fields set by his docker-compose.yml file can't be implemented with this version of the API.

This is actually what the `docker` CLI does; it performs API version negotiation (using `HEAD /_ping` or `GET /_ping`), and based on that information downgrades the API version to use (if needed) to a lower version, and disables features if those are not supported by the negotiated version of the API; https://github.com/moby/moby/blob/ecdb0b22393bb669325099320d26d18687425e5f/client/client.go#L200-L246



>  If it doesn't docker-compose will attempt to parse as a 1.x file for backward compatibility, and warn user for deprecation

Wondering if we should just error out. My concern here is a bit that compose v1.x may be _parseable_ as a v2.x file, but has a different behavior for the same options (e.g. no network is created for the project, and all containers are started using the default ""bridge"" network, use legacy `--link` to communicate, no DNS based resolution of services).

This is also my biggest concern with this approach; same fields/options may have different behavior defined between versions; we cannot heuristically determine which of those to pick.


I'm slightly tempted to;

- still have a `v2` or `v3` version in there
- ignore ""minor"" version; minor version should not be needed:
    - if a field is found that's not supported(*), we can produce an error

(*) note that this means we cannot have ""allow additional properties"" (so always have `""additionalProperties"": false`) in the schema, otherwise properties will be silently ignored, and running the compose file could cause settings to not be set without the user knowing.

--

--
> As an alternative to the requires, automatically up-convert versions when merging files rather than requiring versions to match.

At first glance, this makes sense to do. But.. it's also assuming that `v2` and `v3` are fully compatible (`v2` a superset of `v3`). Following SemVer though, `v3` is a major update (breaking changes) so there _could_ be properties in use that are not in the v3 syntax, so after merging the files, the result should be parsed as `v<max of merged files>` and validated against that schema (correct?).
--
",ndeloof,"
--
itentifying a v1 file is easy as its top-level structure is distinct from v2/v3. So for those if we want to keep backward compatibility we can keep existing code in place, and still rely on `--links` etc. We don't need a `version` attribute just for this purpose.

on v2/v3 none of the fields AFAICT have significantly changed their meaning. Some where deperecated and replaced, but none switched to a distinct implementation model. v3 is a major update due to field removal, but is mostly compatible if we re-introduce them

about a possible v4, this would introduce much more confusion that we already have, if we want to introduce concepts like `pod`, we better should look for an extended way to define a service, with not just one single container.
--

--
I would expect this one to fail as `""redis"" is not a valid field`. Whenever we can support v1 syntax it would be saner to just deprecate this format, at least so that users stop posting sample config using it on stackoverflow ;)
--

--
This has been approved by the Compose Spec community meeting.
PR to update the spec https://github.com/compose-spec/compose-spec/pull/82
Should be pretty easy to implement in docker-compose as this is mostly about removing all the version checks to enable attributes support
--
",,,,
7200,OPEN,[RfC] generalize support for custom extensions,kind/feature,2020-01-31 11:10:23 +0000 UTC,ndeloof,Opened,,"**Is your feature request related to a problem? Please describe.**
Compose file format is used to define applications for platforms it was not initialy designed for.
- Kubernetes: with https://github.com/kubernetes/kompose and https://github.com/docker/compose-on-kubernetes
- Amazon ECS: https://docs.aws.amazon.com/AmazonECS/latest/developerguide/cmd-ecs-cli-compose-parameters.html

While the abstract model of Compose file can be adapted for such platforms, they might miss some specific configuration attributes. To workaround this limitation, a sibling config file might be necessary (see for example https://docs.aws.amazon.com/AmazonECS/latest/developerguide/cmd-ecs-cli-compose-ecsparams.html)

Compose file format do support `x-*` extension fields. Docker cli use [such extension](https://github.com/docker/cli/blob/master/cli/command/stack/kubernetes/convert.go#L27) for `docker stack deploy` command to support kubernetes-specific configuration attributes (pull-policy, pull-secrets, service-type).

But x-* fields are restricted to root and top-level elements only. Platform specific extension should be allowed anywhere, so one can declare custom fields where it makes much sense within Compose model. 

Also, `x-*` are not platform-scoped, which means Platforms A and B could both support some `x-magic` extension but with a very different effect.


**Describe the solution you'd like**

1. Allow a Compose file to use `x-*` extensions everywhere
1. Recommend use of vendor prefixes, like Docker cli does with `x-kubernetes*`

Bonus point : this allows more experimentation with Compose file format, and comparable extensions supported by a significant set of platforms could then be adopted by next iteration of the Compose file format. (the same way CSS browser extensions get adopted)

**Describe alternatives you've considered**


**Additional context**

",,,,,,,,,,,,,,
7193,OPEN,"Allow Docker ""label""s to be modeled as yaml objects",kind/feature,2020-04-27 17:52:04 +0000 UTC,LookitheFirst,Opened,,"-->

**Is your feature request related to a problem? Please describe.**

I'm using docker-compose with the Traefik reverse proxy. To configure the integration, Traefik expects specific labels on a specific Docker service. In a docker-compose file this can look like this:

```yaml
version: '3.7'

services:
  apache:
    image: httpd
    labels:
      - ""traefik.enable=true""
      - ""traefik.http.routers.app.tls=true""
      - ""traefik.http.routers.app.rule=Host(`subdomain.example.com`)""
      - ""traefik.http.routers.app.middlewares=app@file""
      - ""traefik.http.routers.app.service=app@file""
    restart: always
```

As you can see, this can become very verbose. On some other platforms supported by Traefik one is able to write this config in a yaml-like syntax, which reduces clutter and makes this configuration much more readable

**Describe the solution you'd like**

I would like to write the label configuration like this:

```yaml
version: '3.7'

services:
  apache:
    image: httpd
    labels:
      traefik:
        enable: true
        http:
          routers:
            app:
              tls: true
              rule: ""Host(`subdomain.example.com`)""
              middlewares: ""app@file""
              service: ""app@file""
    restart: always
```

Of course, Docker expects labels to contain text instead of objects. This is why docker-compose would have to convert this object notation to dot-notation. The generated container would **still contain the labels in dot-notation**. The object notation should **only** apply for the docker-compose.yml file.
Also this should be completely optional, so you can still define the labels the old way

**Describe alternatives you've considered**

To make the file even more readable, middle packages could also be shortened like this:

```yaml
version: '3.7'

services:
  apache:
    image: httpd
    labels:
      traefik:
        enable: true
        http.routers.app:
          tls: true
          rule: ""Host(`subdomain.example.com`)""
          middlewares: app@file
          service: app@file
    restart: always
```

**Additional context**
none
",,,codecat,"
--
I just got exactly the same idea while writing some traefik configurations! :+1:

Actually kinda surprised this isn't possible yet; the dot notation makes this kind of an ""obvious"" feature to have in my opinion.

I hope this gets implemented at some point!
--
",,,,,,,,,,
7188,OPEN,"Port conflict with multiple ""host:<port range>:port"" services",kind/bug,2021-01-22 10:22:52 +0000 UTC,andrei-m,Opened,,"3. When making a bug report, make sure you provide all required information. The easier it is for
   maintainers to reproduce, the faster it'll be fixed.
-->

## Description of the issue

If a compose file defines multiple services that share an overlapping port range, a port conflict occurs when `docker-compose up` is executed. This behavior started to happen for me when upgrading to Docker Desktop 2.2.0 (Stable) for Mac. The version I was previously running (I believe 2.1.5) was able to select distinct ports for the two services without conflicting. Here is a POC Docker Compose file:

```
version: '2.1'
services:
  postgres-foo:
    image: postgres
    ports:
      - ""127.0.0.1:32768-61000:5432""

  postgres-bar:
    image: postgres
    ports:
      - ""127.0.0.1:32768-61000:5432""
```

## Context information (for bug reports)

**Output of `docker-compose version`**

```
docker-compose version 1.25.2, build 698e2846
docker-py version: 4.1.0
CPython version: 3.7.5
OpenSSL version: OpenSSL 1.1.1d  10 Sep 2019
```

**Output of `docker version`**
```
Client: Docker Engine - Community
 Version:           19.03.5
 API version:       1.40
 Go version:        go1.12.12
 Git commit:        633a0ea
 Built:             Wed Nov 13 07:22:34 2019
 OS/Arch:           darwin/amd64
 Experimental:      false

Server: Docker Engine - Community
 Engine:
  Version:          19.03.5
  API version:      1.40 (minimum version 1.12)
  Go version:       go1.12.12
  Git commit:       633a0ea
  Built:            Wed Nov 13 07:29:19 2019
  OS/Arch:          linux/amd64
  Experimental:     false
 containerd:
  Version:          v1.2.10
  GitCommit:        b34a5c8af56e510852c35414db4c1f4fa6172339
 runc:
  Version:          1.0.0-rc8+dev
  GitCommit:        3e425f80a8c931f88e6d94a8c831b9d5aa481657
 docker-init:
  Version:          0.18.0
  GitCommit:        fec3683
```

**Output of `docker-compose config`**
(Make sure to add the relevant `-f` and other flags)
```
services:
  postgres-bar:
    image: postgres
    ports:
    - 127.0.0.1:32768-61000:5432/tcp
  postgres-foo:
    image: postgres
    ports:
    - 127.0.0.1:32768-61000:5432/tcp
version: '2.1'
```


## Steps to reproduce the issue

1. `docker-compose up`

### Observed result

Services fail to start and a port conflict error occurs

### Expected result

Services start up. An available port within the overlapping range is selected for each service.

### Stacktrace / full error message

```
docker-compose up
Starting docker-bug-poc_postgres-foo_1 ...
Starting docker-bug-poc_postgres-bar_1 ... error
Starting docker-bug-poc_postgres-foo_1 ... error
ERROR: for docker-bug-poc_postgres-bar_1  Cannot start service postgres-bar: Ports are not available: listen tcp 127.0.0.1:32768: bind: address already in use

ERROR: for docker-bug-poc_postgres-foo_1  Cannot start service postgres-foo: Ports are not available: listen tcp 127.0.0.1:37587: socket: too many open files

ERROR: for postgres-bar  Cannot start service postgres-bar: Ports are not available: listen tcp 127.0.0.1:32768: bind: address already in use

ERROR: for postgres-foo  Cannot start service postgres-foo: Ports are not available: listen tcp 127.0.0.1:37587: socket: too many open files
ERROR: Encountered errors while bringing up the project.

```

## Additional information

I uploaded diagnostic information with the ID `37C41A27-71E7-4431-AFBE-5DA0EEC74A3C/20200126225028`",,,cosmincrihan,"
--
I am experiencing a similar issue that may come from the same cause.
The context is the same: upgrading to Docker Desktop 2.2.0 on MacOS breaks the port publishing when trying to run an NFS server container.
To reproduce:
```
docker run -d --privileged --restart=always -v /exported_folder:/exported_folder -e NFS_EXPORT_DIR_1=/exported_folder -e NFS_EXPORT_DOMAIN_1=\* -e NFS_EXPORT_OPTIONS_1=rw,no_root_squash -p 111:111 -p 111:111/udp -p 2049:2049 -p 2049:2049/udp -p 32765:32765 -p 32765:32765/udp -p 32766:32766 -p 32766:32766/udp -p 32767:32767 -p 32767:32767/udp fuzzle/docker-nfs-server:latest
```
The error shown:
```
docker: Error response from daemon: driver failed programming external connectivity on endpoint <CONTAINER_NAME> (ad6b1dccbfe77e3708e687b5eed9311cf1a6f828e36c739f18f5daa5803461b7): Error starting userland proxy: listen tcp 0.0.0.0:111: bind: address already in use
```
I have already taken down every component related to NFS on the Mac itself, and nothing is occupying that port.
The output of `sudo lsof -iTCP -sTCP:LISTEN -n -P`:
```
COMMAND    PID    USER   FD   TYPE             DEVICE SIZE/OFF NODE NAME
launchd      1    root    8u  IPv4 0xd9679bbeeddece79      0t0  TCP *:22 (LISTEN)
launchd      1    root    9u  IPv6 0xd9679bbeedde7269      0t0  TCP *:22 (LISTEN)
launchd      1    root   11u  IPv4 0xd9679bbeeddece79      0t0  TCP *:22 (LISTEN)
launchd      1    root   14u  IPv6 0xd9679bbeedde7269      0t0  TCP *:22 (LISTEN)
dnscrypt-  955  nobody    8u  IPv4 0xd9679bbef0fb0e79      0t0  TCP 127.0.0.1:53 (LISTEN)
com.docke 1190 <USERNAME>    8u  IPv4 0xd9679bbef5ad2801      0t0  TCP 127.0.0.1:49273 (LISTEN)
```

Just downgrading to Docker Desktop 2.1.x solves everything.
Does anybody have any idea for a workaround?
--

--
@thaJeztah should I file a separate issue, as it is not directly related to Docker compose?

> Wondering how this would've worked before, as it wouldn't be possible to have two processes listening on the same port 


--
",thaJeztah,"
--
Wondering how this would've worked before, as it wouldn't be possible to have two processes listening on the same port 
--
",ravishaheshan,"
--
Also when you add scale and run the command multiple times, it will create more containers than the ""scale"" value. For example when I ran it with --scale=3 for the first time it creates one container successfully and two containers fail with port conflicts. Second time 2 containers success 1 fails, 3rd time 2 success 1 fails. when I execute `docker ps` it shows 5 containers. 
Note: I also have port range in my compose file. Before the 2.2.0 update It worked perfectly and created 3 containers and assigned ports within the given range.
--
",MartinLyne,"
--
Any news on this? After upgrading docker on mac to > 2.0 my compose script using port ranges on scalable service also fails. It works perfectly on docker < 2.0. 
--
",weimingwill,"
--
@MartinLyne Did you find any solutions for this?
--
",head1328,"
--
Same problem on MacOS with Docker Desktop v3.1.0 (51484) with the following docker-compose.yml:

    version: '3.5'

    services:
      zookeeper:
        image: strimzi/kafka:0.19.0-kafka-2.5.0
        command:
          - sh
          - -c
          - bin/zookeeper-server-start.sh config/zookeeper.properties
        ports:
          - ""2181-2182:2181""
        environment:
          LOG_DIR: /tmp/logs
      
      kafka:
        image: strimzi/kafka:0.19.0-kafka-2.5.0
        command:
          - sh
          - -c
          - bin/kafka-server-start.sh config/server.properties 
            --override listeners=$${KAFKA_LISTENERS} 
            --override advertised.listeners=$${KAFKA_ADVERTISED_LISTENERS} 
            --override zookeeper.connect=$${KAFKA_ZOOKEEPER_CONNECT} 
            --override num.partitions=$${KAFKA_NUM_PARTITIONS}
        depends_on:
          - zookeeper
        ports:
          - ""9092-9094:9092""
        environment:
          LOG_DIR: /tmp/logs
          KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092
          KAFKA_LISTENERS: PLAINTEXT://0.0.0.0:9092
          KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
          KAFKA_NUM_PARTITIONS: 3

First call fails, second call works:

        # first call fails
        docker-compose up -d --scale kafka=3 --scale zookeeper=2 kafka
        Creating network ""kafka_default"" with the default driver
        WARNING: The ""zookeeper"" service specifies a port on the host. If multiple containers for this service are created on a single host, the port will clash.
        Creating kafka_zookeeper_1 ... error
        Creating kafka_zookeeper_2 ... done

        ERROR: for kafka_zookeeper_1  Cannot start service zookeeper: Ports are not available: listen tcp 0.0.0.0:2181: bind: address already in use

        ERROR: for zookeeper  Cannot start service zookeeper: Ports are not available: listen tcp 0.0.0.0:2181: bind: address already in use
        ERROR: Encountered errors while bringing up the project.

        # second call works
        docker-compose up -d --scale kafka=3 --scale zookeeper=2 kafka
        WARNING: The ""zookeeper"" service specifies a port on the host. If multiple containers for this service are created on a single host, the port will clash.
        Starting kafka_zookeeper_1 ... done
        WARNING: The ""kafka"" service specifies a port on the host. If multiple containers for this service are created on a single host, the port will clash.
        Creating kafka_kafka_1     ... done
        Creating kafka_kafka_2     ... done
        Creating kafka_kafka_3     ... done

So I tried: `docker-compose up -d kafka && docker-compose up -d --scale kafka=3 --scale zookeeper=2 kafka` and this works as well. It seems there is a problem with initial start & scaling and the same time.
--
"
7184,OPEN,docker-compose 1.25.1 buildkit support and --ssh option,kind/question,2020-10-28 14:28:32 +0000 UTC,hecbuma,Opened,,"Hi 

it's great being available to use the buildkit options with the latest docker-compose version thanks for the amazing work around this.

Now, I'm trying to use `--ssh` which is described here https://docs.docker.com/develop/develop-images/build_enhancements/#using-ssh-to-access-private-data-in-builds I'm able to do it with docker CLI but I don't know how to pass the --ssh option while building with docker-compose
```
COMPOSE_DOCKER_CLI_BUILD=1 DOCKER_BUILDKIT=1 docker-compose build
```

is it possible? ",,,Maks3w,"
--
Duplicated of https://github.com/docker/compose/issues/7025
--
",sajusat,"
--
@hecbuma @Maks3w Please implement this as soon as possible. It is a really pain to do the docker build separately with --ssh option. I have been waiting for a while now...
--

--
It has been more than a year. Unfortunately at job I have used this feature to build a lot of docker images referring the ssh keys. Now I am stuck... I have to build separately and use those images with docker-compose. Whenever there is a change in the dockerfile l have to build separately. 
Please state clearly about the state of the this feature. Will it be implemented or not. 
--
",stale,"
--
This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you for your contributions.

--

--
This issue has been automatically marked as not stale anymore due to the recent activity.

--
",ArcticSnowman,"
--
bump...

--
",thegass,"
--
anyone working on this?
--
",AdemUstaReminiz,"
--
Any update on this ?
--
"
7158,OPEN,Add backup/restore commands,kind/feature,2020-01-18 11:26:27 +0000 UTC,jpic,Opened,,"This suggestion is to add `backup` and `restore` options to docker-compose.yml. Example:

```
services:
  db:
    image: postgres
    backup: pg_dumpall -f /dump/db/pg.dump
    restore: psql < /dump/db/pg.dump
    volumes:
    - ./dump:/dump

  web:
    image: wordpress
    backup: rsync /uploads /dumps/uploads
    restore: rsync /dumps/uploads /uploads
    volumes:
    - ./dump:/dump
```

With this configuration, it makes it possible to add `backup` and `restore` commands. The responsibility to encrypt and upload backups somewhere is left to the user.",,,,,,,,,,,,,,
7157,OPEN,Ephemeral deployments,kind/feature,2020-01-18 11:18:15 +0000 UTC,jpic,Opened,,"To keep the master branch clean on my projects, I use CI to deploy compose stacks with something like `HOST=${BRANCH}.ci.example.com docker-compose --project-name=review-${BRANCH}`. Then when a dev pushes a branch they can get feedback from the product team on the ""review"" deployment, without having to merge half-finished stuff into master and thus block it from being deployable to production.

The problem is that resources are not unlimited. So, I made this ephemeral deployments to **not** auto-restart, so that I can reboot the CI server and then run `docker system prune -af`. This is not an ideal solution of course, but still a small price to pay to keep the master branch deployable at any time which is priceless as you can fairly imagine.

I've been looking into solutions for a while, of course I could setup a cron job that would go over stacks which project name start with `review-` and if they are say 5 days old then drop them. As such, if a developer does not push anything to the branch during 5 days then the stack auto-removes.

But now I think that the best would be to add a lifetime to the stack. For example: `docker-compose up --lifetime=5d` would make the stack auto-remove itself after 5 days of uptime. The only thing I'm wondering about, is if this can be done purely in compose, or if it would require to contribute a lifetime option to docker containers/volumes/networks and so on.

What do you think ?",,,,,,,,,,,,,,
7147,OPEN,docker-compose up brings up extra containers which docker-compose down doesn't remove,kind/bug; status/0-triage,2020-01-17 03:08:35 +0000 UTC,jyjyj,In progress,,"3. When making a bug report, make sure you provide all required information. The easier it is for
   maintainers to reproduce, the faster it'll be fixed.
-->

## Description of the issue
docker-compose up brings up extra containers which docker-compose down doesn't remove

I can't show much information as this is a company-classified project, but I'm using CentOS7 and docker 3. There are containers that are brought up by ""docker-compose up"", that do not go down when I type ""docker-compose down"", and that are causing port locking issues (these are dockerised APIs). These containers also do not disappear when I kill these ports using ""kill -9 $(lsof -t -i:PORT_NUM)"".

These extra containers also have a different name shown (e.g. I am in folder XYZ and my expected services have names XYZ_.... while these extra ones are named ABC_...), so I was wondering if Compose is somehow using multiple yml files in its ""up"", but there aren't any others in my current working directory.

Am trying to write a crontab that stops and starts my Docker services. Any help is appreciated, thank you!",,,ndeloof,"
--
We hardly can diagnose this issue without a reproduction scenario.

Please `docker inspect` such ABC_* container and check for labels, to confirm those are created by docker-compose

Does by chance any of your services bind mount `docker.sock`, which would mean your application do create additional containers outside control from docker-compose ?
--
",jyjyj,"
--
Hi, I have used inspect and found that I had Swarm enabled, which was creating extra containers based on its defined namespace. I still deployed using docker-compose up; do you know why doing so with Swarm enabled would create double containers for each of my services? Disabling Swarm removes this issue. Thanks for the tip!
--
",,,,,,,,
7146,OPEN,Unable to configure HTTPS endpoint. No server certificate was specified; and the default developer certificate could not be found,kind/question; status/0-triage,2020-06-10 22:55:29 +0000 UTC,CrestApps,Opened,,"I am trying to run an ASP.NET Core 3.1 framework based app on an Ubuntu (18.04.3 LTS) server using Docker container.

First I created run the `nginx-proxy` image using the following docker-compose.yml` file


    version: '3.4'
    services:
      nginx-proxy:
        image: jwilder/nginx-proxy
        container_name: nginx-proxy
        ports:
          - ""80:80""
        volumes:
          - /var/run/docker.sock:/tmp/docker.sock:ro
    
    networks:
      default:
        external:
          name: nginx-proxy
    secrets:
      server.cert:
        file: ./server.cert
      server.key:
        file: ./server.key

Both `server.cert` and `server.key` files are stored next to the `docker-compose.yml` file and were created using the following command

    sudo openssl req -new -newkey rsa:4096 -days 3650 -nodes -x509 -subj ""/C=US/ST=CA/L=SF/O=Docker-demo/CN=nginx-proxy.example.com"" -keyout server.key -out server.cert

I ran that image using `docker-composer up -d` command.

Now that my nginx proxy is running, I created my first app using the following `docker-composer.yml` file


    version: '3.4'
    
    services:
      private_image:
        image: private_image:latest
        environment:
          - VIRTUAL_HOST=sub.domainsname.com
          - ASPNETCORE_ENVIRONMENT=Production
          - ASPNETCORE_URLS=https://+:443;http://+:80
        expose:
          - 80
          - 443
        ports:
          - 51736:80
          - 44344:443
        volumes:
          - storage:/storage
          - ${APPDATA}/Microsoft/UserSecrets:/root/.microsoft/usersecrets:ro
          - ${APPDATA}/ASP.NET/Https:/root/.aspnet/https:ro
        container_name: realestatestorage
    volumes:
      storage:
    networks:
      default:
        external:
          name: nginx-proxy
    secrets:
      sub.domainsname.com.cert:
        file: ./sub.domainsname.com.cert
      sub.domainsname.com.key:
        file: ./sub.domainsname.com.key


Both `sub.domainsname.com.cert` and `sub.domainsname.com.key` files are stored next to the `docker-compose.yml` file and were created using the following command

    sudo openssl req -new -newkey rsa:4096 -days 3650 -nodes -x509 -subj ""/C=US/ST=CA/L=SF/O=PrivateImage/CN=sub.domainsname.com"" -keyout sub.domainsname.com.key -out sub.domainsname.com.cert

When I run my private image using `docker-compose up` I get the following

    WARNING: The APPDATA variable is not set. Defaulting to a blank string.
    Recreating private_image ... done
    Attaching to private_image
    private_image    | crit: Microsoft.AspNetCore.Server.Kestrel[0]
    private_image    |       Unable to start Kestrel.
    private_image    | System.InvalidOperationException: Unable to configure HTTPS endpoint. No server certificate was specified, and the default developer certificate could not be found or is out of date.
    private_image    | To generate a developer certificate run 'dotnet dev-certs https'. To trust the certificate (Windows and macOS only) run 'dotnet dev-certs https --trust'.
    private_image    | For more information on configuring HTTPS see https://go.microsoft.com/fwlink/?linkid=848054.
    private_image    |    at Microsoft.AspNetCore.Hosting.ListenOptionsHttpsExtensions.UseHttps(ListenOptions listenOptions, Action`1 configureOptions)
    private_image    |    at Microsoft.AspNetCore.Hosting.ListenOptionsHttpsExtensions.UseHttps(ListenOptions listenOptions)
    private_image    |    at Microsoft.AspNetCore.Server.Kestrel.Core.Internal.AddressBinder.AddressesStrategy.BindAsync(AddressBindContext context)
    private_image    |    at Microsoft.AspNetCore.Server.Kestrel.Core.Internal.AddressBinder.BindAsync(IServerAddressesFeature addresses, KestrelServerOptions serverOptions, ILogger logger, Func`2 createBinding)
    private_image    |    at Microsoft.AspNetCore.Server.Kestrel.Core.KestrelServer.StartAsync[TContext](IHttpApplication`1 application, CancellationToken cancellationToken)
    private_image    | Unhandled exception. System.InvalidOperationException: Unable to configure HTTPS endpoint. No server certificate was specified, and the default developer certificate could not be found or is out of date.
    private_image    | To generate a developer certificate run 'dotnet dev-certs https'. To trust the certificate (Windows and macOS only) run 'dotnet dev-certs https --trust'.
    private_image    | For more information on configuring HTTPS see https://go.microsoft.com/fwlink/?linkid=848054.
    private_image    |    at Microsoft.AspNetCore.Hosting.ListenOptionsHttpsExtensions.UseHttps(ListenOptions listenOptions, Action`1 configureOptions)
    private_image    |    at Microsoft.AspNetCore.Hosting.ListenOptionsHttpsExtensions.UseHttps(ListenOptions listenOptions)
    private_image    |    at Microsoft.AspNetCore.Server.Kestrel.Core.Internal.AddressBinder.AddressesStrategy.BindAsync(AddressBindContext context)
    private_image    |    at Microsoft.AspNetCore.Server.Kestrel.Core.Internal.AddressBinder.BindAsync(IServerAddressesFeature addresses, KestrelServerOptions serverOptions, ILogger logger, Func`2 createBinding)
    private_image    |    at Microsoft.AspNetCore.Server.Kestrel.Core.KestrelServer.StartAsync[TContext](IHttpApplication`1 application, CancellationToken cancellationToken)
    private_image    |    at Microsoft.AspNetCore.Hosting.GenericWebHostService.StartAsync(CancellationToken cancellationToken)
    private_image    |    at Microsoft.Extensions.Hosting.Internal.Host.StartAsync(CancellationToken cancellationToken)
    private_image    |    at Microsoft.Extensions.Hosting.HostingAbstractionsHostExtensions.RunAsync(IHost host, CancellationToken token)
    private_image    |    at Microsoft.Extensions.Hosting.HostingAbstractionsHostExtensions.RunAsync(IHost host, CancellationToken token)
    private_image    |    at Microsoft.Extensions.Hosting.HostingAbstractionsHostExtensions.Run(IHost host)
    private_image    |    at private_image.Program.Main(String[] args) in /src/private_image/Program.cs:line 17
    private_image exited with code 139


The command `dotnet dev-certs https --trust` works on Windows and macOS only. But how can I fix this issue on Ubuntu?
",,,caiocsgomes,"
--
Have you found a solution? I'm facing the same issue
--
",CSharp,"
--
I'm experiencing the same issue here. Ubuntu's service with ""dotnet myapp.dll"" would not work. It's displaying the same exact error message. 
--
",profjordanov,"
--
Me too :(
--
",jforward5,"
--
Any idea on the fix?
--
",tomaszek92,"
--
Same problem
--
",HitchBmv,"
--
@CrestApps 
Did you try to use pfx file instead of cert files?
--
"
7137,OPEN,map docker engine API to actual needs; not compose file version,kind/feature,2020-01-13 11:41:23 +0000 UTC,ndeloof,Opened,,"**Is your feature request related to a problem? Please describe.**
docker-compose has requirement for docker API per compose file version. So I can't just use ""latest"" without having to take care of implementation details.

**Describe the solution you'd like**
I'd like docker-compose to check engine API is right so it can run my compose-file, and only fail as some attribute in my compose file require engine API version xyz, but not because I copy/pasted `version: ""3.x""` without carrefully checking I could use a lower version number. 

Could alternatively consider `version: ""3""` as a shortcut for ""_version 3.whatever according to docker engine API_"". Today it's an alias for ""3.0"" which is obsolete and inconsistent UX with docker image tags (for sample: `redis:5` is an alias for `redis:5.<latest minor>`, not `redis:5.0`)

**Additional context**
Add any other context or screenshots about the feature request here.
",,,,,,,,,,,,,,
7130,OPEN,CPU pinning not possible with v3 compose,kind/enhancement; kind/feature,2020-01-09 09:01:26 +0000 UTC,qlyoung,Opened,,"3. When making a bug report, make sure you provide all required information. The easier it is for
   maintainers to reproduce, the faster it'll be fixed.
-->

## Description of the issue

Compose v3 does not support CPU pinning.

## Context information (for bug reports)

Based on the config schema there is no extant option for specifying core pinning on a service, which I'd expect to be under the `deploy` section. This seems like a bug. CPU pinning is essential for some workloads.",,,,,,,,,,,,,,
7127,OPEN,Problem using ignore-pull-failures,kind/bug,2020-06-09 16:12:16 +0000 UTC,core23,Opened,,"# Description of the issue

There is an issue in the current docker-compose version (1.25.1) when using `--ignore-pull-failures`. The version 1.25.0 works as expected.

## Context information (for bug reports)

**Output of `docker-compose version`**
```
docker-compose version 1.25.1, build a82fef0

```

**Output of `docker version`**
```
Client:
 Version:           18.06.1-ce
 API version:       1.38
 Go version:        go1.10.3
 Git commit:        e68fc7a
 Built:             Tue Aug 21 17:24:51 2018
 OS/Arch:           linux/amd64
 Experimental:      false

Server:
 Engine:
  Version:          18.06.1-ce
  API version:      1.38 (minimum version 1.12)
  Go version:       go1.10.3
  Git commit:       e68fc7a
  Built:            Tue Aug 21 17:23:15 2018
  OS/Arch:          linux/amd64
  Experimental:     false
```

**Output of `docker-compose config`**
(Make sure to add the relevant `-f` and other flags)
```
services:
  consul:
    depends_on:
    - mongo
    - rabbit-puppet-portal
    healthcheck:
      interval: 5s
      retries: 30
      test:
      - CMD
      - curl -f localhost:8500/v1/catalog/nodes
      timeout: 3s
    image: consul:1.2.1
    logging:
      driver: json-file
    volumes:
    - /home/anon/workspace/something-persistence-service/smoke/consul:/consul/config:rw
  mongo:
    environment:
      MONGO_INITDB_ROOT_PASSWORD: test
      MONGO_INITDB_ROOT_USERNAME: test
    healthcheck:
      test:
      - CMD
      - echo 'db.runCommand(""ping"").ok' | mongo localhost:27017/test --quiet
    image: mongo:4.1.11-bionic
    logging:
      driver: json-file
  rabbit-puppet-portal:
    environment:
      RABBITMQ_DEFAULT_PASS: admin
      RABBITMQ_DEFAULT_USER: admin
      RABBITMQ_DEFAULT_VHOST: portal
    healthcheck:
      interval: 5s
      retries: 5
      test:
      - CMD
      - rabbitmqctl
      - status
      timeout: 5s
    image: rabbitmq:3.7
  something-persistence-service:
    depends_on:
    - consul
    - mongo
    - rabbit-puppet-portal
    environment:
      HOST_IP: consul
      MONGODB_AUTH: ""true""
      MONGODB_DATABASE: admin
      MONGODB_PASSWORD: test
      MONGODB_RS_NAME: none
      MONGODB_USERNAME: test
      RABBIT_PORTAL_PASSWORD: admin
      RABBIT_PORTAL_USERNAME: admin
      RABBIT_PORTAL_VIRTUALHOST: portal
    healthcheck:
      test:
      - CMD
      - curl -f http://localhost:11030/somethingpersistenceservice/v1/intern/health
    image: something-persistence-service:dev
    logging:
      driver: json-file
    ports:
    - 0:11030/tcp
    volumes:
    - /home/anon/workspace/something-persistence-service/build/service-logs:/anon/something-persistence-service/logs:rw
version: '3.0'
```


## Steps to reproduce the issue

1. Create a docker-compose file with a local image that does not exist inside a shared docker registry. Here it is `something-persistence-service`
2. Execute `docker-compose pull --ignore-pull-failures`

### Observed result
The command will exit with code 1

```
docker-compose pull --ignore-pull-failures
Pulling mongo                         ... done
Pulling rabbit-puppet-portal          ... done
Pulling consul                        ... done
Pulling something-persistence-service ... error
```

### Expected result
The command will exit with code 0

```
docker-compose pull --ignore-pull-failures
Pulling mongo                         ... done
Pulling rabbit-puppet-portal          ... done
Pulling consul                        ... done
Pulling something-persistence-service ... done
```


## Additional information

```
No LSB modules are available.
Distributor ID: Ubuntu
Description:  Ubuntu 18.04.3 LTS
Release:  18.04
Codename: bionic
```
",,,bramswenson,"
--
This is a significant bug for anyone who is scripting with `docker-compose pull --ignore-pull-failures`.
--

--
If this is expected behavior then we at least have a semantic versioning failure and 1.25.1 should have been 1.26?
--
",ndeloof,"
--
This probably is a side effect of https://github.com/docker/compose/pull/7052 and all the confusion within Build vs Image (https://github.com/docker/compose/issues/6464)
Clearly unexpected.
--

--
Please note that, if the image you refer to in your compose file that is not available on a registry do declare a `build` section, then compose 1.25.1 will *not* fail but let you know this one should be built :

```
 docker-compose pull 
Pulling mongo                         ... done
Pulling rabbit-puppet-portal          ... done
Pulling consul                        ... done
Pulling something-persistence-service ... done
WARNING: Some service image(s) must be built from source by running:
    docker-compose build something-persistence-service
```
(exit with code 0)

This behaviour is sane imho, as without this build definition, compose model is incomplete, and docker-compose would need to assume image is built by another service it can't control. For sure you can consider you're in charge for this, but I don't see any reason _not_ to tell compose how to build (or rebuild) this image

wdyt ?
--

--
root cause is we neglected in previous fix that `--no-parallel` isn't the default pull behaviour, and buid_vs_image fix need to be applied in two places.
--
",ahharu,"
--
That makes me sad :-1: 
--

--
Probably they will just close the issue @PierreBeucher 
--
",PierreBeucher,"
--
Still happening with `1.26.0`. We are stuck with `1.25.0` because of this bug. Any plan for solving this?
--

--
Just saw related MR https://github.com/docker/compose/pull/7134, hopefully it will be the reason for this issue to be closed :)
--
",,,,
7112,OPEN,Dockerfile become truncated in certain circumstances,kind/bug,2020-01-06 10:55:18 +0000 UTC,Ovsyanka,Opened,,"## Description of the issue

### conditions

1. Dockerfile out of the context directory
2. Dockerfile has cyrillic symbols (or other non-latin symbols I suppose)

### result:

On `docker-compose build` Dockerfile truncated by amount of cyrillic symbols in it.

For example, if I got 7 cyrillic symbols in the Dockerfile last 7 symbols of the end of file become ""cutted off"".

## Context information (for bug reports)

**Output of `docker-compose version`**
```
docker-compose version 1.25.0, build unknown
docker-py version: 4.1.0
CPython version: 3.8.1
OpenSSL version: OpenSSL 1.1.1d  10 Sep 2019
```

**Output of `docker version`**
```
Client:
 Version:           19.03.5-ce
 API version:       1.40
 Go version:        go1.13.4
 Git commit:        633a0ea838
 Built:             Fri Nov 15 03:19:09 2019
 OS/Arch:           linux/amd64
 Experimental:      false

Server:
 Engine:
  Version:          19.03.5-ce
  API version:      1.40 (minimum version 1.12)
  Go version:       go1.13.4
  Git commit:       633a0ea838
  Built:            Fri Nov 15 03:17:51 2019
  OS/Arch:          linux/amd64
  Experimental:     false
 containerd:
  Version:          v1.3.2.m
  GitCommit:        d50db0a42053864a270f648048f9a8b4f24eced3.m
 runc:
  Version:          1.0.0-rc9
  GitCommit:        d736ef14f0288d6993a1845745d6756cfc9ddd5a
 docker-init:
  Version:          0.18.0
  GitCommit:        fec3683
```

**Output of `docker-compose config`**

```
see in the ""steps to reproduce""
```

## Steps to reproduce the issue

Create `context` (empty) directory, `docker-compose.yml` and `Dockerfile`

### docker-compose.yml

```
version: '3.7'

services:
  test-pass:
    build:
      context: .
      dockerfile: Dockerfile
  test-fail:
    build:
      context: context
      # path relative to the context
      dockerfile: ../Dockerfile
```

#### Dockerfile

```
FROM alpine

#   

RUN touch test
```

Run `docker-compose build test-fail`

### Observed result

```
docker-compose build test-fail
Building test-fail
Step 1/2 : FROM alpine
 ---> cdf98d1859c1
Step 2/2 : RUN touc
 ---> Running in fc83cc1f2b69
/bin/sh: touc: not found
ERROR: Service 'test-fail' failed to build: The command '/bin/sh -c touc' returned a non-zero code: 127
```

The string `h test\n` (7 symbols) was disappeared.

This problem doesn't appear if the Dockerfile is in the context folder (look at the test-pass service).

This problem doesn't appear by using `docker build`.

### Expected result

Expected result is succesfully created image, like by using `docker build`:

```
docker build -f Dockerfile context
Sending build context to Docker daemon  1.583kB
Step 1/2 : FROM alpine
 ---> cdf98d1859c1
Step 2/2 : RUN touch test
 ---> Using cache
 ---> bb6362bff392
Successfully built bb6362bff392
```

### Stacktrace / full error message

```
N/A
```
",,,ndeloof,"
--
thanks for reporting this issue with clear reproduction sample and initial investigation on breaking conditions. I'll investigate this issue next week
--

--
As a workaround, you can enable native CLI builder by setting `COMPOSE_DOCKER_CLI_BUILD=true` (I expect this to become default value in a future release)
--

--
issue (afaict) is caused by https://github.com/docker/docker-py/blob/master/docker/utils/build.py#L107-L109

tar size is computed as `len(contents)` == character counts, while the actual tar entry is set by `contents.encode('utf-8')`, which will then be truncated as some characters will be encoded on N>1 bytes.
--
",,,,,,,,,,
7102,OPEN,Support ${parameter:+word} style variable substitution,kind/feature,2020-02-25 00:06:22 +0000 UTC,andrewodri,Opened,,"Most continuous integration systems have a `$CI` variable to that acts as a flag that lets you know when you're in a CI environment. While `docker-compose.yml` allows for substitution when a variable **is not** defined/set (e.g. [`${parameter:-word}`](https://docs.docker.com/compose/compose-file/#variable-substitution)), it would be great to allow for substitution when a variable **is** defined/set.

Bash allows you to define this with [the following syntax](https://www.gnu.org/software/bash/manual/html_node/Shell-Parameter-Expansion.html):

> `${parameter:+word}`
> 
> If _parameter_ is null or unset, nothing is substituted, otherwise the expansion of _word_ is substituted.

Here are some examples of some CI systems/services that support the `$CI` flag:

* https://docs.travis-ci.com/user/environment-variables/#default-environment-variables
* https://circleci.com/docs/2.0/env-vars/#built-in-environment-variables
* https://docs.gitlab.com/ee/ci/variables/predefined_variables.html#variables-reference",,,thaJeztah,"
--
I think the official specs (non-bash) can be found here; https://pubs.opengroup.org/onlinepubs/009695399/utilities/xcu_chap02.html
--

--
I'd generally prefer sticking to the POSIX set of options, otherwise we'd end up implementing regex matching and the whole shebang
--
",ndeloof,"
--
Sounds reasonable to me, both because this would enable interesting use-cases like the one you describe, and also because this would make the syntax consistent with what any shell script author would expect.
--

--
We probably could support most or all [bash parameter expansion](https://www.gnu.org/software/bash/manual/html_node/Shell-Parameter-Expansion.html).


--
",bradynpoulsen,"
--
Following POSIX, would the substitution value also be evaluated for other substitutions?

 My use-case is I'm wanting to conditionally pass a value in my `command` when a value is set
```yaml
services:
  my-service:
    command: |
      -abc
      --do-something
      ${MY_DEFAULT_PASSWORD+--with-default-credentials ""${MY_DEFAULT_USERNAME:-user}:${MY_DEFAULT_PASSWORD}""}
```

My workarounds are currently limited to:
1. throw a substitution error
    ```
    --with-default-credenitals ""${MY_DEFAULT_USERNAME:-user}:${MY_DEFAULT_PASSWORD?Password is required!}""
    ```
2. inject a custom bash script that I can override the `entrypoint` to run the original entry point, with the command arguments, and run the same substitution I specified above
--
",,,,,,
7095,OPEN,[Question|Feature Request] Dockerfile inside docker-compose.yml,kind/feature,2020-02-26 08:54:35 +0000 UTC,ThaDaVos,In progress,,"I don't know if this is possible already or even in the scope of docker compose but one feature I would love is to include Dockerfile inside the docker-compose.yaml using a block mapping. This is especially useful if you need to extend a image and only run 1 command inside, without needing the context etc.
For example, you need the PHP image and you want to enable some extensions etc.

My proposal would look as follow:
```yaml
version: '3.7'
services:
  app:
    image: php
    build: |
      FROM php AS Base
      RUN docker-php-ext-enable pdo_mysql
```
This way, one could extend on the PHP image and enable the pdo_mysql extension",,,ThaDaVos,"
--
Any news about this? I was almost about to create a new issue as I couldn't find this one, some more info (as it seems there's an template now):

**Is your feature request related to a problem? Please describe.**
_A clear and concise description of what the problem is. Ex. I'm always frustrated when [...]_
Partially, the thing is, I need to add a single `RUN` to a existing image to run a command which sets php.ini related settings [Directus Custom Upload Limits](https://github.com/directus/docker/blob/master/examples/custom-upload-limits/Dockerfile).
I know I can just add a dockerfile especially for this, reference it in the docker-compose.yml and use it. But, it will also setup a context (while there's no need to `COPY` anything).

**Describe the solution you'd like**
_A clear and concise description of what you want to happen._
I would like to propose a solution as below to make it possible to embed small dockerfiles which need **no** context to be build inside the docker-compose.yml file:
```yaml
version: ""x.x""
services:
  my-amazing-service:
    build:
      dockerfile: |
      from directus/directus:v8-apache
      RUN php-ini-add ""upload_max_filesize=1G""
    ports:
      - 80
```
or even, but just a little unclear:
```yaml
version: ""x.x""
services:
  my-amazing-service:
    image: directus/directus:v8-apache
    build:
      dockerfile: |
      RUN php-ini-add ""upload_max_filesize=1G""
    ports:
      - 80
```

**Describe alternatives you've considered**
_A clear and concise description of any alternative solutions or features you've considered._
Creating a dockerfile and using that, but it will also setup a context, which isn't needed
--
",,,,,,,,,,
7083,OPEN,Make `--env-file` a repeatable option,kind/feature,2020-05-11 18:02:59 +0000 UTC,khs1994,Opened,,"**Is your feature request related to a problem? Please describe.**
`--env-file` support list (like `-f` do)so one can use many env files, example `docker-compose --env-file a.env --env-file b.env`

**Describe the solution you'd like**
like `-f`, i want to use many `env file`.

**Describe alternatives you've considered**
we can exec `docker-compose --env-file a.env --env-file b.env`,use many env file

",,,ndeloof,"
--
Sounds a reasonable enhancement.

Implementation is not even complex, I just noticed due to https://github.com/docopt/docopt/issues/275 we can't declare `--env-file` as a repeatable option without changing the top-level Usage sample, which would highlight this option over others in a weird way.

--
",hholst80,"
--
Workaround for bash,
```
docker-compose --env-file <(cat a.env b.env)
```
--
",,,,,,,,
7082,OPEN,Proposal: use docker CLI dial-stdio to access docker engine,kind/feature,2019-12-05 12:58:37 +0000 UTC,ndeloof,Opened,,"docker-compose has to re-implement all the configuration parsing and protocol support as implemented docker CLI. `docker system dial-stdio` offers an alternative to this by providing a proxy to target docker engine by plain stdio. We should offer this as a connexion option, at least this could help resolve some issues with ssh protocol, but can also be considered an initial step toward https://github.com/docker/compose/issues/7078 

",,,,,,,,,,,,,,
7078,OPEN,Proposal: rely on docker CLI,kind/epic,2020-06-11 23:43:41 +0000 UTC,ndeloof,In progress,,"In a few circumstances, docker-compose demonstrates some problematic differences with the docker CLI, from slowness to actual bugs (typically: ssh URL support).

People end-up writing their own scripts as workarounds, see https://github.com/docker/compose/issues/4748#issuecomment-561438269

There's a few places docker-compose do _not_ rely on docker-py API client implementation, but just execute the plain docker CLI, to run interactive mode on Windows, or to benefit BuilKit for image builds (see compose.cli.main.call_docker).

We don't expect many users to have docker-compose installed but not the docker CLI, and having to maintain both docker Go client library and docker-py in perfect sync is a challenge.

This proposal is about introducing `COMPOSE_USE_CLI` environment variable, default to `false` as initial round, so that we can offer a plain CLI implementation of the most problematic commands (maybe all of them, long terms).

Side benefits is that this offers a simple way for people to check a reported issue is caused by some docker-py implementation glitches, or just a plain docker-compose bug. 

",,,thaJeztah,"
--
Thanks; this is matching my proposal for native build through the docker cli; see my comments on https://github.com/docker/compose/pull/6584#issuecomment-501680138, https://github.com/docker/compose/pull/6584#issuecomment-502099098 and https://github.com/docker/compose/pull/6584#issuecomment-513210065

Which (roughly) translates to;

1. Introduce an option (environment variable for now?) allowing users to opt-in on delegating functionality to the docker cli
2. Where applicable, mark the python equivalent as frozen (no new features, but continue fixing bugs)
3. Encourage people to opt-in, and collect feedback (catch side-effects that we didn't think about, or due to esoteric use-cases/situations ""in the wild)
4. After X release(s), make it the default
5. Allow users to opt-out (`FEATURE_ENV_VAR=0`)
6. (where applicable) work on improvements in other projects (docker cli, docker app) to gain native support for Compose files (improving the experience further).


Worth discussing:

- are environment variables the most convenient construct for this, or should we have other ways? (configuration file(s)? also a way to integrate with `docker context`?)
    - env-vars are convenient for ""per shell"" / ""per session"" opt-in/out and easy to implement, but don't integrate easily into `docker context`, nor is it easy to configure them through (e.g.) the Docker Desktop UI
- is a single environment variable ok, or should we have individual env-vars for separate features (allowing more granular ""promotion"" of features to default to using the cli)
    - currently, we have `COMPOSE_NATIVE_BUILDER=1` to use the cli for building


Related to the ""collect feedback""; we should create an epic or tracking issue for each feature/functionality that we delegate to the CLI so that we can describe outstanding issues / roadmap, and make it easier to refer to feedback related to it.
--
",ndeloof,"
--
I fully agree with your execution scenario, for a smooth transition

opt-in by environment variable seems a good option (docker CLI does already for experimental features, or buildkit support). We could in parallel consider improvements in the context management and Desktop integration to make this even simpler, including one click opt-in/out and per-context configuration.

I also considered option to have individual fine grained variables to opt-in/out per command, but I wonder this will just make configuration a terrible experience, and source for many more confusion. With a shorter release cycle, I expect we are able to provide fixes for reported issues, as we introduce CLI implementation for a command.
--
",philomory,"
--
Personally, I'd really love to see the flag for this moved into the `docker-compose.yaml` file; either as an option under the `build` key for a service (my preferred solution), or maybe globally as a header comment similar to the `# syntax = docker/dockerfile:1.0-experimental` header in Dockerfiles.
--
",,,,,,
7051,OPEN,Raspberry crashes on docker-compose up,kind/bug,2021-02-02 09:52:40 +0000 UTC,RSWilli,In progress,,"3. When making a bug report, make sure you provide all required information. The easier it is for
   maintainers to reproduce, the faster it'll be fixed.
-->

## Description of the issue

I am running Manjaro ARM on my raspberry PI 3B. I tried to start the `homeassistant/raspberry3-homassistant` image from docker-compose

It did not work, and the PI froze (needed a hard reset to work again)

## Context information (for bug reports)

The issue was, that i tried to start a arm32 image on my arm64 pi, and Manjaro lacks the support for arm32

Running the image with `docker` gave this error: `standard_init_linux.go:211: exec user process caused ""exec format error""` (which is totally user-unfriendly btw)

docker-compose straight up crashed the whole system instead

**Output of `docker-compose version`**
```
docker-compose version 1.25.0, build unknown
docker-py version: 4.1.0
CPython version: 3.8.0
OpenSSL version: OpenSSL 1.1.1d  10 Sep 2019
```

**Output of `docker version`**
```
Client:
 Version:           19.03.5-ce
 API version:       1.40
 Go version:        go1.13.4
 Git commit:        633a0ea838
 Built:             Sat Nov 16 00:08:25 2019
 OS/Arch:           linux/arm64
 Experimental:      false

Server:
 Engine:
  Version:          19.03.5-ce
  API version:      1.40 (minimum version 1.12)
  Go version:       go1.13.4
  Git commit:       633a0ea838
  Built:            Sat Nov 16 00:07:54 2019
  OS/Arch:          linux/arm64
  Experimental:     false
 containerd:
  Version:          v1.3.0.m
  GitCommit:        d50db0a42053864a270f648048f9a8b4f24eced3.m
 runc:
  Version:          1.0.0-rc9
  GitCommit:        d736ef14f0288d6993a1845745d6756cfc9ddd5a
 docker-init:
  Version:          0.18.0
  GitCommit:        fec3683
```

**Output of `docker-compose config`**
```
services:
  homeassistant:
    container_name: home-assistant
    environment:
      TZ: Europe/Berlin
    image: homeassistant/raspberrypi3-homeassistant:stable
    ports:
    - published: 8123
      target: 8123
    restart: always
    volumes:
    - /home/whale/hassio/config:/config:rw
version: '3.7'
```


## Steps to reproduce the issue

1. Raspberry PI with Manjaro ARM (Maybe other distros work as well)
2. `docker run --name=""home-assistant"" -e ""TZ=Europe/Berlin"" -v $PWD/config:/config -p 8123:8123 homeassistant/raspberrypi3-homeassistant:latest`
and `docker-compose up` with the given config
3. observe the difference ;)

### Observed result

docker-compose crashes the system, while docker gives an error

### Expected result

docker-compose gives an error

### Stacktrace / full error message
for docker:
```
standard_init_linux.go:211: exec user process caused ""exec format error""
```
docker-compose:
no error, since Pi crashes

## Additional information

OS version / distribution, `docker-compose` install method, etc.
Linux raspi 5.3.12-1-MANJARO-ARM #1 SMP Wed Nov 20 16:23:31 UTC 2019 aarch64 GNU/Linux

docker-compose installed through `yay -S docker-compose`",,,ndeloof,"
--
Note: at time writting, ARM is not an officially suported plaform for docker-compose (even we are aware many users do rely on it).

The issue you describe is pretty weird, as docker-compose do fully rely on the docker engine to run containers by it's HTTP API, and as such could fail with ugly errors, but I harldy understand how a python process can crash the system this way.
Can you please try to run the same docker-compose file with `-d` (dettached) parameter ? Doing so compose will ask engine to run container in a ""fire an forget"" style, which might limit interactions with the engine and help understand what's causing this issue
--
",RSWilli,"
--
I tried that, but the shell never came back

I was connected via SSH to my Pi, and after `docker-compose up (-d)` the shell never came back and the SSH session timed out
A reconnect was only possible after i un- and replugged the powercable from the Pi. Meanwhile my router didn't show my Pi as connected to the network
--
",danc,"
--
Hi !
Exact same problem on an olimex pine64
```
uname -m
aarch64

docker-compose up -d
standard_init_linux.go:211: exec user process caused ""exec format error""
```

--
",ypicard,"
--
Same here, `docker-compose up` crashes my raspberry pi 4 with Raspbian Buster Lite

```
uname -m
armv7l
```
--
",leifle,"
--
Just to add something to those that might look for the reason of this. In my case it happens almost 100% of the time.
The Pi completely dies on me in that moment. Not even an entry in the syslog.
Now the real problem starts. When I turn on the pi again, I get 5 or so pings and it is dead again. I have to assume this is exactly because the containers come back up and the same thing crashes.
So there is as good as no way to get back onto the pi. Only turning on and off until it works is the way.

My path took me in the strangest corners:
For a while I thought it is the problem with the HDMI frequency problem and the network adapters not working.
Also I had ""success"" with putting the pi in the fridge as I thought maybe the electronics is too hot.
The latest things is the stupid MAC randomization. Whomever had that idea and how long it takes to find out that this might be a reason. If one tests hardware like this obviously one boots ""a lot"". So the routers device list in the DHCP runs out of space.

Bottom line
There is something wrong in the docker-compose up (-d) function that makes it crash. Not all the time. So after 10 or more boots I am fine. But that can not be. Usually I don't copy syslog to anybody, but maybe it helps the developers. You can see when I executed docker-compose up -d this happened:
~~~
Aug 21 16:14:13 raspberrypi NetworkManager[400]: <info>  [1598019253.7421] device (vethb774c34): released from master device br-ee59a112e310
Aug 21 16:14:13 raspberrypi systemd[1]: run-docker-netns-afeff46e4915.mount: Succeeded.
Aug 21 16:14:13 raspberrypi systemd[629]: run-docker-netns-afeff46e4915.mount: Succeeded.
Aug 21 16:14:13 raspberrypi systemd[1]: var-lib-docker-containers-02b57ec546052fbe88f9ebc810ba37a49157ba676bc752c8e633cab99c88fdb5-mounts-shm.mount: Succeeded.
Aug 21 16:14:13 raspberrypi systemd[629]: var-lib-docker-containers-02b57ec546052fbe88f9ebc810ba37a49157ba676bc752c8e633cab99c88fdb5-mounts-shm.mount: Succeeded.
Aug 21 16:14:13 raspberrypi systemd[1]: var-lib-docker-overlay2-2fd767b8a8025133e1fe4154f7c22966702fcfb25a4e2d9082e10541aa439fcb-merged.mount: Succeeded.
Aug 21 16:14:13 raspberrypi systemd[629]: var-lib-docker-overlay2-2fd767b8a8025133e1fe4154f7c22966702fcfb25a4e2d9082e10541aa439fcb-merged.mount: Succeeded.
Aug 21 16:14:25 raspberrypi systemd[1]: run-docker-runtime\x2drunc-moby-b2a7a9664f86b0f5be0697083874c65cd3bfc8a492e1b8bc6f8b6b06d3876dcb-runc.ehI0YR.mount: Succeeded.
Aug 21 16:14:25 raspberrypi systemd[629]: run-docker-runtime\x2drunc-moby-b2a7a9664f86b0f5be0697083874c65cd3bfc8a492e1b8bc6f8b6b06d3876dcb-runc.ehI0YR.mount: Succeeded.
Aug 21 16:14:29 raspberrypi systemd[1]: run-docker-runtime\x2drunc-moby-23263b0ba8578ef3376693e00df807ce2bbedcf064c842391003ece11e6553ad-runc.akcmnN.mount: Succeeded.
Aug 21 16:14:29 raspberrypi systemd[629]: run-docker-runtime\x2drunc-moby-23263b0ba8578ef3376693e00df807ce2bbedcf064c842391003ece11e6553ad-runc.akcmnN.mount: Succeeded.
Aug 21 15:54:41 raspberrypi systemd-modules-load[117]: Inserted module 'i2c_dev'
Aug 21 15:54:41 raspberrypi fake-hwclock[114]: Fri 21 Aug 2020 12:13:19 PM UTC
Aug 21 15:54:41 raspberrypi systemd-fsck[128]: e2fsck 1.44.5 (15-Dec-2018)
Aug 21 15:54:41 raspberrypi systemd-fsck[128]: root: clean, 284639/1929536 files, 2967855/7712256 blocks
~~~
--

--
Looks to me like it is not really too widely a problem as few write. Shortly after my post I just created a new SD with Raspian again, the version with GUI and few applications.

Everything works fine with multiple restarts and updates when I did this to install docker and docker-compose. The steps before this are just update things and zsh.
```shell
        6)
            echo ""----- Install docker""
            sudo apt install -y docker.io
            sudo systemctl enable --now docker
            docker --version
            docker run hello-world
            ;;
        7)
            echo ""----- Install docker-compose""
            sudo apt install -y docker-compose
            docker-compose version
            ;;
        8)
            echo ""Add current user to docker group""
            sudo usermod -aG docker ${USER}
            ;;
```
I presume it is caused by something else I have running or an experiment that left stuff behind.

Just so somebody doing a pure docker installation knows that it is easy. Just new install and run the few lines above.

Good luck ...
--

--
Hi tam481!

Here I give you the whole script that I run right after a new raspberry install. After this I clone one more git with my docer compose thing and that is the whole thing.

What I experienced with docker and obviously with docker-compose is that sometimes the containers that are `latest` have issues. Somehow they don't work right for a few days. If it is the manifest or outright the wrong container in the sense that a x86 binary is in somewhere but the Pi is ARM. Try to chose older versions of the container where you know that they proved themselves.
Due to this problem one of my next projects is to write some scripts that revert back to older containers and I will go also further and put them on my own repository. Reason being that dockerhub is overflowing with data and they can not provide this for free anymore. So they just announced a few weeks ago that they will delete images which are not or rarely used. So I think the best is if you safe the functioning images, however you do it. I for my part will setup a docker environment on a cloud server where I have a git repository already so I am not dependent on company decissions by git or dockerhub.

I removed some things that are specific to my setup and files that you don't have.

If you have a completely naked installation of Raspian, this should work. Besides the hello-world you have portainer which gives you at least some GUI. Maybe you can see something there. Also pulling images of different versions is possibly easier for you. At least it is in some cases for me.

Else I can only wish you the best of luck. Mine is still working fine and when I update my images everything starts up fine as well.



~~~bash
#!/bin/bash
# Load package dialog if it is not installed
pkgs='dialog'
if ! dpkg -s $pkgs >/dev/null 2>&1; then
sudo apt-get install -y $pkgs
fi

# Dialog stuff
cmd=(dialog --separate-output --checklist ""Select options:"" 22 76 16)
options=(1 ""Update"" on    # any option can be set to default to ""on""
         2 ""Upgrade"" on
         3 ""Full Upgrade"" off
         4 ""Install GIT"" off
         5 ""Install ZSH (Oh-My-ZSH)"" off
         6 ""Install Docker"" off
         7 ""Install Docker-Compose"" off
         8 ""Add current user to docker group"" off
         9 ""Start Portainer in Docker"" off
         10 ""STILL TO COME!! - Start Portainer in Docker-Compose Stack SYS with others"" off
         11 ""Add .bash_aliases function"" off
         12 ""Install Python3 and PIP3"" off
         20 ""REBOOT WITHOUT ASKING!!!"" off)
choices=$(""${cmd[@]}"" ""${options[@]}"" 2>&1 >/dev/tty)
clear
for choice in $choices
do
    case $choice in
        1)
            sudo apt-get -y update
            ;;
        2)
            sudo apt-get -y upgrade
            ;;
        3)
            sudo apt-get -y full-upgrade
            ;;
        4)
            sudo apt install -y git
            git --version
            ;;
        5)
            # bash SUB/ZSH/first-inst-zsh.sh
            ;;
        6)
            echo ""----- Install docker""
            sudo apt install -y docker.io
            sudo systemctl enable --now docker
            docker --version
            docker run hello-world
            ;;
        7)
            echo ""----- Install docker-compose""
            sudo apt install -y docker-compose
            docker-compose version
            ;;
        8)
            echo ""Add current user to docker group""
            sudo usermod -aG docker ${USER}
            ;;
        9)
            echo ""----- Portainer""
            echo ""----- Create Volume for Portainer""
            docker volume create portainer_data
            echo ""----- Run Portainer""
            docker run -d -p 9000:9000 -p 8000:8000 --name portainer --restart always -v /var/run/docker.sock:/var/run/docker.sock -v portainer_data:/data portainer/portainer
            ;;
        10)
            echo ""The function to mount stack SYS is still to come!""
            ;;
        11)            
            # This is to make it global for bash. You need to enter your user password. Works only if you are a sudoer.
            ;;
        12)
            sudo apt install -y python3-pip
            pip3 --version
            echo ""As for the installation of Python3 you should already have it installed with the OS""
            echo ""If not use: sudo apt-get install python3.6 or whatever is current.""
            ;;
        20)
            sudo reboot now
            ;;
     esac
done
~~~

Here you have my docker-compose.yml. It will not work like this for you because you are missing the environment files with the passwords and so on, but just so you see what I load. If you load something similar I can change some of the environment files.

~~~
version: '2'
services:

  portainer:
    container_name: portainer
    image: portainer/portainer-ce
    restart: unless-stopped
    ports:
      - 9000:9000
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
      - ./volumes/portainer/data:/data

  nodered:
    container_name: nodered
    build: ./services/nodered/.
    restart: unless-stopped
    user: ""0""
    privileged: true
    env_file: ./services/nodered/nodered.env
    ports:
      - 1880:1880
    volumes:
      - ./volumes/nodered/data:/data

  influxdb:
    container_name: influxdb
    image: ""influxdb:latest""
    restart: unless-stopped
    ports:
      - 8086:8086
      - 8083:8083
      - 2003:2003
    env_file:
      - ./services/influxdb/influxdb.env
    volumes:
      - ./volumes/influxdb/data:/var/lib/influxdb
      - ./backups/influxdb/db:/var/lib/influxdb/backup

  grafana:
    container_name: grafana
    image: grafana/grafana:latest
    restart: unless-stopped
    user: ""0""
    ports:
      - 3000:3000
    env_file:
      - ./services/grafana/grafana.env
    volumes:
      - ./volumes/grafana/data:/var/lib/grafana
      - ./volumes/grafana/log:/var/log/grafana

  mosquitto:
    container_name: mosquitto
    image: eclipse-mosquitto
    restart: unless-stopped
    user: ""1883""
    ports:
      - 1883:1883
      - 9001:9001
    volumes:
      - ./volumes/mosquitto/data:/mosquitto/data
      - ./volumes/mosquitto/log:/mosquitto/log
      - ./services/mosquitto/mosquitto.conf:/mosquitto/config/mosquitto.conf

  pihole:
    container_name: pihole
    image: pihole/pihole:latest
    ports:
      - ""53:53/tcp""
      - ""53:53/udp""
      - ""67:67/udp""
      - ""8089:80/tcp""
      #- ""443:443/tcp""
    env_file:
      - ./services/pihole/pihole.env
    volumes:
       - ./volumes/pihole/etc-pihole/:/etc/pihole/
       - ./volumes/pihole/etc-dnsmasq.d/:/etc/dnsmasq.d/
    dns:
      - 127.0.0.1
      - 1.1.1.1
    # Recommended but not required (DHCP needs NET_ADMIN)
    #   https://github.com/pi-hole/docker-pi-hole#note-on-capabilities
    cap_add:
      - NET_ADMIN
    restart: unless-stopped

  tradfri-mqtt:
    container_name: tradfri-mqtt
    image: hemtjanst/tradfri-mqtt:arm7
    env_file:
      - ./services/tradfri-mqtt/tradfri-mqtt.env
    volumes:
      - ./volumes/tradfri-mqtt/data:/app/data
    restart: unless-stopped

~~~
By the way this is a slightly changed version of what you can make out of IOThub.
--
",tam481,"
--
Hi all,
I'm getting a similar thing with my RPi 4. It only happens with multiple docker-compose.yml files. If I start a single project with multiple docker images it works fine but if I start another project with multiple images from a docker-compose.yml file it works fine until I shutdown or reboot then it starts up, pings for a few seconds and I can SSH in but then shortly afterwards it freezes. 

I'm running docker-compose 1.26.2
--

--
Hi 
I tried the steps above but it's still not working. No matter what I do, if I reboot or shutdown and start the Raspberry Pi, it comes up for a few seconds and then stops responding.

I tried the latest release 1.27.3. It doesn't crash, the containers start fine the Pi itself dies after a reboot. Otherwise, it carries on working fine if left powered on
--
"
7036,OPEN,Compose build hangs instead of giving error message in case of uppercase image name.,kind/bug; status/0-triage,2020-05-04 05:24:43 +0000 UTC,pratiksanglikar,In progress,,"3. When making a bug report, make sure you provide all required information. The easier it is for
   maintainers to reproduce, the faster it'll be fixed.
-->

## Description of the issue
Docker Compose doesn't support uppercase characters for image names, so when a user puts an uppercase character in the `docker-compose.yml` file and tries to build, `docker-compose` should give an error rather than hanging.


## Context information (for bug reports)

**Output of `docker-compose version`**
```
docker-compose version 1.24.1, build 4667896b
docker-py version: 3.7.3
CPython version: 3.6.8
OpenSSL version: OpenSSL 1.0.2q  20 Nov 2018
```

**Output of `docker version`**
```
Client: Docker Engine - Community
 Version:           19.03.5
 API version:       1.40
 Go version:        go1.12.12
 Git commit:        633a0ea
 Built:             Wed Nov 13 07:22:37 2019
 OS/Arch:           windows/amd64
 Experimental:      true

Server: Docker Engine - Community
 Engine:
  Version:          19.03.5
  API version:      1.40 (minimum version 1.24)
  Go version:       go1.12.12
  Git commit:       633a0ea
  Built:            Wed Nov 13 07:36:50 2019
  OS/Arch:          windows/amd64
  Experimental:     true
```

**Output of `docker-compose config`**
```
docker-compose  -f ""C:\Users\nouser\source\repos\WebApplication2\docker-compose.yml"" -f ""C:\Users\nouser\source\repos\WebApplication2\docker-compose.override.yml"" -f ""C:\Users\nouser\source\repos\WebApplication2\obj\Docker\docker-compose.vs.debug.g.yml"" -p dockercompose14357808182777382152 --no-ansi config
services:
  webapplication2:
    build:
      context: C:\Users\nouser\source\repos\WebApplication2
      dockerfile: WebApplication2\Dockerfile
      labels:
        com.microsoft.created-by: visual-studio
        com.microsoft.visual-studio.project-name: WebApplication2
      target: base
    container_name: WebApplication2
    entrypoint: C:\\remote_debugger\\x64\\msvsmon.exe /noauth /anyuser /silent /nostatus
      /noclrwarn /nosecuritywarn /nofirewallwarn /nowowwarn /timeout:2147483646 /LogDebuggeeOutputToStdOut
    environment:
      ASPNETCORE_ENVIRONMENT: Development
      ASPNETCORE_LOGGING__CONSOLE__DISABLECOLORS: ""true""
      ASPNETCORE_URLS: https://+:443;http://+:80
      DOTNET_USE_POLLING_FILE_WATCHER: '1'
      NUGET_FALLBACK_PACKAGES: c:\.nuget\fallbackpackages
      NUGET_PACKAGES: C:\.nuget\packages
    image: webapplication2-UPPERCASE:dev
    labels:
      com.microsoft.visualstudio.debuggee.arguments: ' --additionalProbingPath c:\.nuget\packages
        --additionalProbingPath c:\.nuget\fallbackpackages  ""C:\app\bin\Debug\netcoreapp3.1\WebApplication2.dll""'
      com.microsoft.visualstudio.debuggee.killprogram: C:\remote_debugger\x64\utils\KillProcess.exe
        dotnet.exe
      com.microsoft.visualstudio.debuggee.program: '""C:\Program Files\dotnet\dotnet.exe""'
      com.microsoft.visualstudio.debuggee.workingdirectory: C:\app
    ports:
    - target: 80
    - target: 443
    volumes:
    - C:\Users\nouser\AppData\Roaming\ASP.NET\Https:C:\Users\ContainerUser\AppData\Roaming\ASP.NET\Https:ro
    - C:\Users\nouser\AppData\Roaming\Microsoft\UserSecrets:C:\Users\ContainerUser\AppData\Roaming\Microsoft\UserSecrets:ro
    - C:\Users\nouser\source\repos\WebApplication2\WebApplication2:C:\app:rw
    - C:\Users\nouser\onecoremsvsmon\16.5.0066.0:C:\remote_debugger:ro
    - C:\Users\nouser\source\repos\WebApplication2:C:\src:rw
    - C:\Program Files\dotnet\sdk\NuGetFallbackFolder:c:\.nuget\fallbackpackages:ro
    - C:\Users\nouser\.nuget\packages:c:\.nuget\packages:ro
version: '3.4'
```


## Steps to reproduce the issue

1. Clone the repo - https://github.com/pratiksanglikar/docker-compose-uppercase-error.git
2. Observe in `docker-compose.yml` there are uppercase characters in service name
3. navigate to WebApplication2 directory, and run 
```
docker-compose  -f ""C:\Users\nouser\source\repos\WebApplication2\docker-compose.yml"" -f ""C:\Users\nouser\source\repos\WebApplication2\docker-compose.override.yml"" -f ""C:\Users\nouser\source\repos\WebApplication2\obj\Docker\docker-compose.vs.debug.g.yml"" -p dockercompose14357808182777382152 --no-ansi --verbose build
```
4. Observe that `docker-compose build` command hangs

### Observed result
`docker compose build` hangs.

### Expected result
```
compose.cli.verbose_proxy.proxy_callable: docker build -> <generator object APIClient._stream_helper at 0x00000229FEB0BCA8>
compose.cli.errors.log_api_error: invalid reference format: repository name must be lowercase
```
### Stacktrace / full error message

```
docker-compose  -f ""C:\Users\nouser\source\repos\WebApplication2\docker-compose.yml"" -f ""C:\Users\nouser\source\repos\WebApplication2\docker-compose.override.yml"" -f ""C:\Users\nouser\source\repos\WebApplication2\obj\Docker\docker-compose.vs.debug.g.yml"" -p dockercompose14357808182777382152 --no-ansi --verbose build
compose.config.config.find: Using configuration files: C:\Users\nouser\source\repos\WebApplication2\docker-compose.yml,C:\Users\nouser\source\repos\WebApplication2\docker-compose.override.yml,C:\Users\nouser\source\repos\WebApplication2\obj\Docker\docker-compose.vs.debug.g.yml
docker.utils.config.find_config_file: Trying paths: ['C:\\Users\\nouser\\.docker\\config.json', 'C:\\Users\\nouser\\.dockercfg']
docker.utils.config.find_config_file: Found file at path: C:\Users\nouser\.docker\config.json
docker.auth.load_config: Found 'credsStore' section
urllib3.connectionpool._make_request: http://localhost:None ""GET /v1.30/version HTTP/1.1"" 200 661
compose.cli.command.get_client: docker-compose version 1.24.1, build 4667896b
docker-py version: 3.7.3
CPython version: 3.6.8
OpenSSL version: OpenSSL 1.0.2q  20 Nov 2018
compose.cli.command.get_client: Docker base_url: http+docker://localnpipe
compose.cli.command.get_client: Docker version: Platform={'Name': 'Docker Engine - Community'}, Components=[{'Name': 'Engine', 'Version': '19.03.5', 'Details': {'ApiVersion': '1.40', 'Arch': 'amd64', 'BuildTime': '2019-11-13T07:36:50.000000000+00:00', 'Experimental': 'true', 'GitCommit': '633a0ea', 'GoVersion': 'go1.12.12', 'KernelVersion': '10.0 18362 (18362.1.amd64fre.19h1_release.190318-1202)', 'MinAPIVersion': '1.24', 'Os': 'windows'}}], Version=19.03.5, ApiVersion=1.40, MinAPIVersion=1.24, GitCommit=633a0ea, GoVersion=go1.12.12, Os=windows, Arch=amd64, KernelVersion=10.0 18362 (18362.1.amd64fre.19h1_release.190318-1202), Experimental=True, BuildTime=2019-11-13T07:36:50.000000000+00:00
compose.cli.verbose_proxy.proxy_callable: docker inspect_network <- ('dockercompose14357808182777382152_default')
urllib3.connectionpool._make_request: http://localhost:None ""GET /v1.30/networks/dockercompose14357808182777382152_default HTTP/1.1"" 200 943
compose.cli.verbose_proxy.proxy_callable: docker inspect_network -> {'Attachable': True,
 'ConfigFrom': {'Network': ''},
 'ConfigOnly': False,
 'Containers': {'a0ee74438263197bb257d5ad5d49e9d7d51d147dc851ef66c8df320f92a6dbc8': {'EndpointID': '309885ae7991e0782055d0dcc306211994ddacbd62d8b65d40f545b7247a4861',
                                                                                     'IPv4Address': '172.25.127.211/16',
                                                                                     'IPv6Address': '',
                                                                                     'MacAddress': '00:15:5d:11:7f:c2',
                                                                                     'Name': 'WebApplication2'}},
 'Created': '2019-11-19T12:25:55.9670017-08:00',
 'Driver': 'nat',
...
compose.service.build: Building webapplication2
compose.cli.verbose_proxy.proxy_callable: docker build <- (path='\\\\?\\C:\\Users\\nouser\\source\\repos\\WebApplication2', tag='webapplication2-UPPERCASE:dev', rm=True, forcerm=False, pull=False, nocache=False, dockerfile='WebApplication2\\Dockerfile', cache_from=None, labels={'com.microsoft.created-by': 'visual-studio', 'com.microsoft.visual-studio.project-name': 'WebApplication2'}, buildargs={}, network_mode=None, target='base', shmsize=None, extra_hosts=None, container_limits={'memory': None}, gzip=False, isolation=None, platform=None)
docker.api.build._set_auth_headers: Looking for auth config
docker.auth._resolve_authconfig_credstore: Looking for auth entry for 'webapplication1420190920041237.azurecr.io:443'
docker.auth._resolve_authconfig_credstore: Looking for auth entry for 'webapplication220191008014328.azurecr.io:443'
docker.auth._resolve_authconfig_credstore: Looking for auth entry for 'webapplication320191021113840.azurecr.io:443'
docker.auth._resolve_authconfig_credstore: Looking for auth entry for 'webapplication520191021114425.azurecr.io:443'
docker.auth._resolve_authconfig_credstore: Looking for auth entry for 'workerservice120191021100554.azurecr.io:443'
docker.api.build._set_auth_headers: Sending auth config ('webapplication1420190920041237.azurecr.io:443', 'webapplication220191008014328.azurecr.io:443', 'webapplication320191021113840.azurecr.io:443', 'webapplication520191021114425.azurecr.io:443', 'workerservice120191021100554.azurecr.io:443')
```
## Additional information

OS version: Microsoft Windows 10 Enterprise - 1903
Project: Default ASP.NET Core web project created in Visual Studio.
Nature of error: error occurs in both Visual Studio tools and powershell.
",,,ndeloof,"
--
I just tried to reproduce your issue, with a simplified scenario:

- download https://github.com/pratiksanglikar/docker-compose-uppercase-error/blob/master/WebApplication2/docker-compose.yml
- run `docker-compose build`

Then I get an expected error message:
```
  docker-compose build
Building webapplication2
ERROR: invalid reference format: repository name must be lowercase
```

Could you please confirm you get the same?
--

--
Can you please try using recent 1.25 release ?
In the meantime I'll resurrect my windows box to check this is a windows specific issue.
--

--
You can download from https://github.com/docker/compose/releases/tag/1.25.0
But I don't expect a significant change with 1.25 rc4. Thanks for giving a try.
--
",pratiksanglikar,"
--
Hi @ndeloof ,
I tried to run the simplified command as you suggested. 
The problem is persistent.
Here is the output -->
```
C:\Users\nouser\source\repos\WebApplication2> docker-compose --verbose build
compose.config.config.find: Using configuration files: .\docker-compose.yml,.\docker-compose.override.yml
docker.utils.config.find_config_file: Trying paths: ['C:\\Users\\nouser\\.docker\\config.json', 'C:\\Users\\nouser\\.dockercfg']
docker.utils.config.find_config_file: Found file at path: C:\Users\nouser\.docker\config.json
docker.auth.load_config: Found 'credsStore' section
urllib3.connectionpool._make_request: http://localhost:None ""GET /v1.30/version HTTP/1.1"" 200 661
compose.cli.command.get_client: docker-compose version 1.24.1, build 4667896b
docker-py version: 3.7.3
CPython version: 3.6.8
OpenSSL version: OpenSSL 1.0.2q  20 Nov 2018
compose.cli.command.get_client: Docker base_url: http+docker://localnpipe
compose.cli.command.get_client: Docker version: Platform={'Name': 'Docker Engine - Community'}, Components=[{'Name': 'Engine', 'Version': '19.03.5', 'Details': {'ApiVersion': '1.40', 'Arch': 'amd64', 'BuildTime': '2019-11-13T07:36:50.000000000+00:00', 'Experimental': 'true', 'GitCommit': '633a0ea', 'GoVersion': 'go1.12.12', 'KernelVersion': '10.0 18362 (18362.1.amd64fre.19h1_release.190318-1202)', 'MinAPIVersion': '1.24', 'Os': 'windows'}}], Version=19.03.5, ApiVersion=1.40, MinAPIVersion=1.24, GitCommit=633a0ea, GoVersion=go1.12.12, Os=windows, Arch=amd64, KernelVersion=10.0 18362 (18362.1.amd64fre.19h1_release.190318-1202), Experimental=True, BuildTime=2019-11-13T07:36:50.000000000+00:00
compose.cli.verbose_proxy.proxy_callable: docker inspect_network <- ('webapplication2_default')
urllib3.connectionpool._make_request: http://localhost:None ""GET /v1.30/networks/webapplication2_default HTTP/1.1"" 404 56
compose.service.build: Building webapplication2
compose.cli.verbose_proxy.proxy_callable: docker build <- (path='\\\\?\\C:\\Users\\nouser\\source\\repos\\WebApplication2', tag='webapplication2-UPPERCASE', rm=True, forcerm=False, pull=False, nocache=False, dockerfile='WebApplication2\\Dockerfile', cache_from=None, labels=None, buildargs={}, network_mode=None, target=None, shmsize=None, extra_hosts=None, container_limits={'memory': None}, gzip=False, isolation=None, platform=None)
docker.api.build._set_auth_headers: Looking for auth config
docker.auth._resolve_authconfig_credstore: Looking for auth entry for 'webapplication1420190920041237.azurecr.io:443'
docker.auth._resolve_authconfig_credstore: Looking for auth entry for 'webapplication220191008014328.azurecr.io:443'
docker.auth._resolve_authconfig_credstore: Looking for auth entry for 'webapplication320191021113840.azurecr.io:443'
docker.auth._resolve_authconfig_credstore: Looking for auth entry for 'webapplication520191021114425.azurecr.io:443'
docker.auth._resolve_authconfig_credstore: Looking for auth entry for 'workerservice120191021100554.azurecr.io:443'
docker.api.build._set_auth_headers: Sending auth config ('webapplication1420190920041237.azurecr.io:443', 'webapplication220191008014328.azurecr.io:443', 'webapplication320191021113840.azurecr.io:443', 'webapplication520191021114425.azurecr.io:443', 'workerservice120191021100554.azurecr.io:443')
```
--

--
*Edit - *
If I put the `docker-compose.yml` in an empty folder and try to run `docker-compose --verbose build`
it is giving the correct error - 
```
ERROR: compose.cli.errors.log_api_error: no such image: webapplication2-UPPERCASE: invalid reference format: repository name must be lowercase
```

I can try to dissect the project to see what causes the issue.


> I also tried to execute `docker-compose --verbose build` outside project directory with just the `docker-compose.yml` following is the output -->
> ```
> PS C:\Users\nouser\source\repos> docker-compose --verbose build                                                                                                                                                             compose.config.config.find: Using configuration files: .\..\docker-compose.yml
> docker.utils.config.find_config_file: Trying paths: ['C:\\Users\\nouser\\.docker\\config.json', 'C:\\Users\\nouser\\.dockercfg']
> docker.utils.config.find_config_file: Found file at path: C:\Users\nouser\.docker\config.json
> docker.auth.load_config: Found 'credsStore' section
> urllib3.connectionpool._make_request: http://localhost:None ""GET /v1.30/version HTTP/1.1"" 200 661
> compose.cli.command.get_client: docker-compose version 1.24.1, build 4667896b
> docker-py version: 3.7.3
> CPython version: 3.6.8
> OpenSSL version: OpenSSL 1.0.2q  20 Nov 2018
> compose.cli.command.get_client: Docker base_url: http+docker://localnpipe
> compose.cli.command.get_client: Docker version: Platform={'Name': 'Docker Engine - Community'}, Components=[{'Name': 'Engine', 'Version': '19.03.5', 'Details': {'ApiVersion': '1.40', 'Arch': 'amd64', 'BuildTime': '2019-11-13T07:36:50.000000000+00:00', 'Experimental': 'true', 'GitCommit': '633a0ea', 'GoVersion': 'go1.12.12', 'KernelVersion': '10.0 18362 (18362.1.amd64fre.19h1_release.190318-1202)', 'MinAPIVersion': '1.24', 'Os': 'windows'}}], Version=19.03.5, ApiVersion=1.40, MinAPIVersion=1.24, GitCommit=633a0ea, GoVersion=go1.12.12, Os=windows, Arch=amd64, KernelVersion=10.0 18362 (18362.1.amd64fre.19h1_release.190318-1202), Experimental=True, BuildTime=2019-11-13T07:36:50.000000000+00:00
> compose.cli.verbose_proxy.proxy_callable: docker inspect_network <- ('source_default')
> urllib3.connectionpool._make_request: http://localhost:None ""GET /v1.30/networks/source_default HTTP/1.1"" 404 47
> compose.service.build: Building webapplication2
> compose.cli.verbose_proxy.proxy_callable: docker build <- (path='\\\\?\\C:\\Users\\nouser\\source', tag='webapplication2-UPPERCASE', rm=True, forcerm=False, pull=False, nocache=False, dockerfile='WebApplication2\\Dockerfile', cache_from=None, labels=None, buildargs={}, network_mode=None, target=None, shmsize=None, extra_hosts=None, container_limits={'memory': None}, gzip=False, isolation=None, platform=None)
> Traceback (most recent call last):
>   File ""site-packages\docker\utils\build.py"", line 96, in create_archive
> PermissionError: [Errno 13] Permission denied: '\\\\?\\C:\\Users\\nouser\\source\\repos\\AT-Kube\\src\\.vs\\Containers.Common\\v16\\Server\\sqlite3\\db.lock'
> 
> During handling of the above exception, another exception occurred:
> 
> Traceback (most recent call last):
>   File ""docker-compose"", line 6, in <module>
>   File ""compose\cli\main.py"", line 71, in main
>   File ""compose\cli\main.py"", line 127, in perform_command
>   File ""compose\cli\main.py"", line 287, in build
>   File ""compose\project.py"", line 386, in build
>   File ""compose\project.py"", line 368, in build_service
>   File ""compose\service.py"", line 1084, in build
>   File ""compose\cli\verbose_proxy.py"", line 55, in proxy_callable
>   File ""site-packages\docker\api\build.py"", line 159, in build
>   File ""site-packages\docker\utils\build.py"", line 31, in tar
>   File ""site-packages\docker\utils\build.py"", line 100, in create_archive
> OSError: Can not read file in context: \\?\C:\Users\nouser\source\repos\AT-Kube\src\.vs\Containers.Common\v16\Server\sqlite3\db.lock
> [9444] Failed to execute script docker-compose
> ```
--

--
Sure let me install the latest 1.25 release.
--

--
Latest stable version of Docker Desktop doesn't have latest docker-compose.
So I tried to get the Edge version of Docker Desktop which includes -
```
docker-compose version 1.25.0-rc4, build 8f3c9c58
docker-py version: 4.1.0
CPython version: 3.7.4
OpenSSL version: OpenSSL 1.1.1c  28 May 2019
```

The issue is still persistent.
--

--
Hi @ndeloof ,
Any updates on this?
Any way I can help?
--
",jbasinger,"
--
I'm using an environment variable as an image tag, if that is blank it results in the image name being `somethinglowercase:` emphasis on the `:` at the end there. That also makes things hang in the same way.
--
",mzur,"
--
I use `docker-compose` 1.25.4 and get the following error message on `docker-compose build` with uppercase image names:
```
ERROR: Couldn't connect to Docker daemon at http+docker://localhost - is it running?

If it's at a non-standard location, specify the URL with the DOCKER_HOST environment variable.
```
When the image names are converted to lowercase, the build runs fine. It's the same with 1.26.0-rc3.
--
",daudihusbands,"
--
Probably a separate issue but, this is also an issue if your image names starts with /
Eg if you specify {DOCKER_REGISTRY-}/my-image:{TAG-latest} and your DOCKER_REGISTRY variable doesn't resolve for whatever reason, docker-compose will simply hang
--
",stormmullerentelect,"
--
I had the same issue.

We also use build args to specify the base image. 

Build hangs, when I remove the uppercase chars, it works perfectly.
--
"
7025,OPEN,Enable ssh option as build parameter for buildkit,kind/feature; status/0-triage,2021-02-08 13:29:34 +0000 UTC,bert2002,In progress,,"**Is your feature request related to a problem? Please describe.**
When building a container we need access to other Resources like ssh and dont want to expose a private key in the container. 

**Describe the solution you'd like**
Support of `--ssh` in the build process that already works in buildkit.

**Additional context**
I tried `1.25.0-rc4`, but it does not support `--ssh` option. Tried the same as in bug 6440:

```
export COMPOSE_DOCKER_CLI_BUILD=1
export DOCKER_BUILDKIT=1
docker-compose build --ssh default my_image
```
This would be a major security improvement and save us so much pain.

Thanks,
bert

",,,ndeloof,"
--
tracked internally as https://docker.atlassian.net/browse/COMPOSE-107
--
",sajusat,"
--
Any timeline on this ?
--

--
I adopted this feature early and now I am having a maintenance nightmare.
--

--
@jungwookim I kept the experimental meta tag in all the Dockerfiles and used --ssh option to do the builds. When I use these images I cannot used the --build option when there is a change in the dockerfile. 
--

--
It's been like two years since I am following this option. I have seen talks about should you guys implement it or not...  Someone please say something concrete. 

--
",jufemaiz,"
--
  any news team?
--
",bert2002,"
--
I saw that buildkit made its way into docker-compose, but ssh is not there yet. This feature would really help to make docker-compose an ideal team for large scale deployments and local developments in one tool.
--
",jungwookim,"
--
@sajusat How did you adopt this feature? How's it going?
--
",alechirsch,"
--
Any update on this? We resorted to using shell scripts for building, and then using docker compose to start everything.
--
"
7011,OPEN,Avoid use of __file__,kind/cleanup; status/0-triage,2020-11-22 08:19:39 +0000 UTC,jayvdb,In progress,,"It appears the use of `__file__` here is mostly unnecessary, and can easily be  replaced with `importlib.resources`/`pkgutil`. See indygreg/PyOxidizer#69 for more info about why, but the tl;dr version is `__file__` is an optional attribute and should not be relied upon.

Loading of resources from the runtime package should ideally be done using `importlib.resources` and backport `importlib_resources`, however `pkgutil` could be used to avoid the need for the backport.  Using `pkgutil` doesn't work under PyOxidizer 0.4, however I expect that will be fixed soon.",,,stale,"
--
This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you for your contributions.

--

--
This issue has been automatically marked as not stale anymore due to the recent activity.

--

--
This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you for your contributions.

--

--
This issue has been automatically closed because it had not recent activity during the stale period.

--

--
This issue has been automatically marked as not stale anymore due to the recent activity.

--

--
This issue has been automatically marked as not stale anymore due to the recent activity.

--
",jayvdb,"
--
This is still valid:

The first two are runtime use of `__file__`.
```
git grep __file__
compose/cli/utils.py:    filename = os.path.join(os.path.dirname(compose.__file__), 'GITSHA')
compose/config/validation.py:    return os.path.dirname(os.path.abspath(__file__))
script/release/const.py:REPO_ROOT = os.path.join(os.path.dirname(__file__), '..', '..')
setup.py:    path = os.path.join(os.path.dirname(__file__), *parts)
```
--

--
ping @ndeloof , can you re-open
--
",thaJeztah,"
--
Let me reopen.

Looks like you have a fair understanding of what changes need to be made; were you considering opening a pull request with those changes?
--
",,,,,,
7004,OPEN,Ending slash in container path volume handling is buggy,kind/bug; status/0-triage,2020-11-15 17:54:53 +0000 UTC,kiorky,In progress,,"
## Description of the issue
Ending slash in container path volume handling is buggy when merging configs and duplicate mountpoings paths since 1.24.1.

## Context information (for bug reports)

**Output of `docker-compose version`**
```
>= 1.24.1
```
-----
Consider those two configs:
```yaml
version: ""3.7""
services:
  test:
    image: ubuntu
    volumes:
    - prod:/prod
volumes:
  prod:
```
```yaml
version: ""3.7""
services:
  test:
    volumes:
    - ./dev:/prod/
```
take care to /prod<strong>/</strong>

This will fail with **Output of `docker-compose config`**
```
ERROR: Duplicate mount points: [prod:/prod:rw, /home/kiorky/for-tests/fail3/dev:/prod:rw]
```
-----
But if you remove the **ending slash: ``/``** in the second config:
```yaml
version: ""3.7""
services:
  test:
    volumes:
    - ./dev:/prod
```
It will return the expected result
```yaml
services:
  test:
    image: ubuntu
    volumes:
    - /home/kiorky/for-tests/fail3/dev:/prod:rw
version: '3.7'
volumes:
  prod: {}
```
",,,kiorky,"
--
That was my original issue when i registered #7003 
--

--
@jcsirot it's tied to the late ""duplicate mountpoints"" related MRs :

https://github.com/docker/compose/issues/5948
--

--
( & #6406 )
--

--
the bug is still there.
--

--
not stale
--
",jcsirot,"
--
Hello @kiorky 
Thank you for opening this issue
Indeed docker compose behavior indeed changed between 1.23.1 and 1.24.0. We are going to investigate to understand why.
--

--
It seems that `docker-compose config` with compose 1.23.1 produced a invalid output
```
services:
  test:
    image: ubuntu
    volumes:
    - /home/jcs/for-tests/issue7004/dev:/prod:rw
    - prod:/prod:rw
version: '3.7'
volumes:
  prod: {}
```
--
",stale,"
--
This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you for your contributions.

--

--
This issue has been automatically closed because it had not recent activity during the stale period.

--

--
This issue has been automatically marked as not stale anymore due to the recent activity.

--

--
This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you for your contributions.

--

--
This issue has been automatically marked as not stale anymore due to the recent activity.

--
",,,,,,
7001,OPEN,Support bracket notation for IPv6 port mappings,kind/feature; status/0-triage,2019-11-06 08:53:09 +0000 UTC,chris13524,Opened,,"I think it would be a good idea to support the bracket notation for IPv6 port mappings. That is, you should be able to do this:

```
ports:
  - ""[::1]:80:80""
```

I'm aware you can simply omit the brackets to do this currently, however I think supporting the bracket notation would be a good idea.

I believe this for several reasons:
  - it is [standard](https://tools.ietf.org/html/rfc5952#section-6) to use brackets when writing out IPv6 addresses and port numbers
  - the `docker run` command uses this bracket format for port mappings
  - applications such as web browsers and `curl` use brackets
  - it is easier to parse with the eyes
  - for some (like myself), it is intuitive to write out port mappings using the brackets just to be greeted by this confusing error message:
    ```
    ERROR: The Compose file './docker-compose.yml' is invalid because:
    services.nginx.ports contains an invalid type, it should be a number, or an object
    ```
    I've done this several times and after a few minutes of Googling come across [this](https://github.com/docker/compose/issues/5020) issue which reminds me.",,,jcsirot,"
--
Hello @chris13524 
Thank you for your feature suggestion. We are going to investigate the possibility to integrate it in a future release.
--
",,,,,,,,,,
6997,OPEN,Ability to exlude certain files and subfolders from being mounted/synced.,kind/feature; status/0-triage,2020-07-01 20:14:14 +0000 UTC,zigi05,Opened,,"My app folder on host machine is synced to my docker container in docker compose volumes. I do development inside a docker container and would like to exclude certain files and subfolders from being synced from the container back to the host folder.

For example, inside the app folder in the container I run `npm install` and I don't want *node_modules* folder with millions of files in it to be mapped backed to my host folder from the container folder.

As of today, I have not found a way to exclude certain files and subfolders from the volumes. There's a hacky way to prevent a subfolder from being synced from host to container, but no way to prevent a subfolder from being synced from container to host.",,,jcsirot,"
--
Hello @dmxd5 
Thank you for opening this ticket. We are going to evaluate the possibility to add this feature in a future Compose release.
--
",kindermax,"
--
That would be super cool!
--
",jdiegosierra,"
--
I'm working with AWS Lambdas and have more than 100. Every Lambda has it's own node_modules. Of course I don't want to add every node_modules path to the docker-compose.yml file.
--
",,,,,,
6995,OPEN,Do not autostart specific services,kind/feature; status/0-triage,2020-01-15 12:52:45 +0000 UTC,samrocketman,In progress,,"# Use case

I have container services I use for troubleshooting inside of a docker network.  I like to use, for example,

```
docker-compose run dns-troubleshoot /bin/bash
```
Which starts an interactive container for me inside the network of my service stack for deeper troubleshooting.  Normally, the `dns-troubleshoot` service does not need to be started.

# Recommended implementation

docker-compose already supports `scale`.  Why not auto-skip services which have `scale: 0` defined.  No need for additional options.

Here's [an example](https://github.com/samrocketman/docker-compose-ha-consul-vault-ui/blob/ddb0ff66b0a8658a754f1d8279f5bd371ce88913/docker-compose.yml#L61-L71) of what it could look like in the context of other services.

# Duplicates

https://github.com/docker/compose/issues/1896 but I couldn't comment in there.  I think I have something useful to add so I created an additional issue to share my thoughts.  Unfortunately, I'm not a ""docker collaborator"" so I am excluded from participating in the discussion.",,,jcsirot,"
--
Hello @samrocketman Thank you for opening this ticket. We are going to evaluate the possibility to add this feature in a future Compose release
--
",samrocketman,"
--
Neat, thanks for letting me know.
--
",jasonkenneth,"
--
We have a one-time-setup service that runs some config on the host in the context of a developer downloading the project for the first time. We only want it to run when explicitly requested.
--
",ndeloof,"
--
We could introduce a `disabled` boolean attribute on services, that would be ignored when explicit service name is part of the command. Just my 2 cents
--
",,,,
6977,OPEN,Why is the last one to create a folder when creating a volume?,kind/feature,2019-10-22 03:29:09 +0000 UTC,impactCn,Opened,,"A docker-compose copied from the Internet, if you do not check the volume, it is easy to report an error. But many times, the host only needs an empty file, not a folder.
So, I hope that when the volume is associated, the last path is the file.",,,,,,,,,,,,,,
6975,OPEN,Volume mounted inside another sometimes disappears after file change,kind/bug; status/0-triage,2020-11-11 00:23:58 +0000 UTC,josh-byster,Opened,,"**Description**

Not sure if this is a Compose-specific issue or Moby so I have the linked issue [here](https://github.com/moby/moby/issues/40109) in case it's not Compose-specific.

**Summary**: We mount our source code in a directory in the container, and within that directory, mount on top a named volume which contains data from the built image (`node_modules`). Sometimes this named volume seems to unmount, resulting in an underlying empty directory in the container.

**Background**: Essentially, I have the mount of the `backend` folder to the container source code located at `/var/www/app`. However, since I don't have `node_modules` installed on the host, we have a named volume mounted called `be_modules`. This has the effect of (when it's working) using the installed node_modules in the image, effectively mounting ""on-top"" of the source code in `/var/www/app`.

The key is here in the Docker Compose file, which gets the `node_modules` directory working usually:
```
- ./backend:/var/www/app
- be_modules:/var/www/app/node_modules
```
    
**Issue:** Running `docker-compose up` or `docker-compose run backend sh` (for debugging) shows correctly the `node_modules` retrieved from the image. They all show up just fine, and the date/time on the `node_modules` folder when running `ls` is whenever the volume got created. All is good.

There's an empty `node_modules` directory created on the host, which is normal since it mounted into the container and so the corresponding folder got created on the host. 

However, occasionally (and more frequent on my coworker's machine) we will make a few changes in the source code while our container is up. The changes syncs up to the container (as it should), however `node_modules` then becomes an empty folder in the container! Moreover, the datetime of the directory changes to the time when the image was built (and is the same as the timestamp of the empty directory on the host)! In other words, it's as if the named volume just randomly unmounts for no reason. Doing nothing to the source but restarting `docker-compose down -v` and `docker-compose up` fixes it until it happens again.

**What we tried:** Restarting Docker, removing all images, containers, volumes, and starting a fresh build. 


Why would this be happening? My suspicion is that it's either a Docker / Compose bug since I can't reproduce with the exact same code, or there's some subtlety that I'm missing. I'm almost seems the issue has to do with when a file changes that Docker is re-mounting the entire directory in the container, and this is over-over-writing the `be_modules` mount with that empty directory, since the timestamp between the host empty directory and container empty directory are the same.
It's **not** device specific. 

**Steps to reproduce the issue:**

Can't write an MWE since it doesn't happen always (for me, almost never; my coworker: all the time) and frequency depends on the machine, which makes me suspect that's a bug rather than something else.
 
[Link to docker-compose gist](https://gist.github.com/josh-byster/130661f8b705a3609d736ada9eeadb46)

[Link to dockerfile gist](https://gist.github.com/josh-byster/d0b54222b162b8a9e0a0bd3444ff43ff)

**Additional information you deem important (e.g. issue happens only occasionally):**

Issue seems to happen randomly on my machine along with some of my coworkers. However, on one coworker's machine, this issue happens almost every time they make a change. 

I'm posting here instead of Docker Compose since I think this may be an issue with volume mounting.


*
## Context information (for bug reports)

**Output of `docker-compose version`**
```
docker-compose version 1.24.1, build 4667896b
docker-py version: 3.7.3
CPython version: 3.6.8
OpenSSL version: OpenSSL 1.1.0j  20 Nov 2018
```

**Output of `docker version`**
```
Client: Docker Engine - Community
 Version:           19.03.2
 API version:       1.40
 Go version:        go1.12.8
 Git commit:        6a30dfc
 Built:             Thu Aug 29 05:26:49 2019
 OS/Arch:           darwin/amd64
 Experimental:      false

Server: Docker Engine - Community
 Engine:
  Version:          19.03.2
  API version:      1.40 (minimum version 1.12)
  Go version:       go1.12.8
  Git commit:       6a30dfc
  Built:            Thu Aug 29 05:32:21 2019
  OS/Arch:          linux/amd64
  Experimental:     true
 containerd:
  Version:          v1.2.6
  GitCommit:        894b81a4b802e4eb2a91d1ce216b8817763c29fb
 runc:
  Version:          1.0.0-rc8
  GitCommit:        425e105d5a03fabd737a126ad93d62a9eeede87f
 docker-init:
  Version:          0.18.0
  GitCommit:        fec3683
```

**Output of `docker-compose config`**

```
services:
  backend:
    build:
      context: /Users/joshbyster/Documents/repo_name/backend
    command: npm start
    depends_on:
    - db
    environment:
      PORT: '5000'
    ports:
    - published: 5000
      target: 5000
    volumes:
    - /Users/joshbyster/Documents/repo_name/backend:/var/www/app:rw
    - be_modules:/var/www/app/node_modules:rw
  db:
    image: mongo
    init: true
    logging:
      driver: none
    ports:
    - published: 27017
      target: 27017
    volumes:
    - mongo_data:/data/db:rw
  frontend:
    build:
      context: /Users/joshbyster/Documents/repo_name
/frontend
    command: npm start
    depends_on:
    - backend
    - db
    environment:
      PORT: '3000'
      REACT_APP_API_PORT: '5000'
    ports:
    - published: 3000
      target: 3000
    volumes:
    - /Users/joshbyster/Documents/repo_name/frontend:/var/www/app:rw
    - fe_modules:/var/www/app/node_modules:rw
version: '3.7'
volumes:
  be_modules: {}
  fe_modules: {}
  mongo_data: {}

```


## Steps to reproduce the issue

Please see above

We run the following commands in order to reproduce:
```
docker-compose run backend sh 
ls -al node_modules #shows correct listing of all node_modules
# make some change in a file and save it
ls -al node_modules # empty directory with date from when empty node_modules folder on host was created
```

## Additional information

OS version / distribution, `docker-compose` install method, etc.

Running OS X 10.14.6 but see this issue on Docker with WSL. ",,,jcsirot,"
--
Hello @josh-byster Thank you for the report. We are going to investigate.
--
",marcthayer,"
--
Any updates on this?
--
",georgecrawford,"
--
This exactly describes the problem I'm seeing. Again with docker-compose, with a sub-volume containing my `node_modules`. I'd love this to be looked into and fixed!
--
",tuanalumi,"
--
We have the same issue. Thank @josh-byster for reporting it in this detail.
--
",joshua,"
--
Me and my co-worker have also been experiencing this issue to varying degrees.
--
",Akhil,"
--
Any update on this?
--
"
6968,OPEN,docker-compose rm -v says 'No stopped containers' when that isn't true,kind/bug; status/0-triage,2021-01-28 00:47:35 +0000 UTC,sydneybmunizaga,Opened,,"## Description of the issue

I have containers that are stopped. My `docker ps -a` looks like this...
``` docker ps -a
4efd8ba5b9b3        ************************/************:latest              ""catalina.sh run""        27 minutes ago      Exited (137) 4 minutes ago                                       ci_api_1
92ee9901ceed        mysql:5.7.23                                                ""docker-entrypoint.s""   27 minutes ago      Exited (0) 5 minutes ago                                         ci_database_1
b6fb5f9d9389        mysql:5.7.24                                                ""docker-entrypoint.s""   47 hours ago        Exited (255) 3 hours ago     0.0.0.0:3306->3306/tcp, 33060/tcp   another_db
```


But when I run `docker-compose rm -v` I get a message in the terminal saying `No stopped containers`


**Output of `docker-compose version`**
```
docker-compose version 1.24.1, build 4667896b
docker-py version: 3.7.3
CPython version: 3.6.8
OpenSSL version: OpenSSL 1.1.0j  20 Nov 2018

```
**Output of `docker version`**
```
Client: Docker Engine - Community
 Version:           19.03.2
 API version:       1.40
 Go version:        go1.12.8
 Git commit:        6a30dfc
 Built:             Thu Aug 29 05:26:49 2019
 OS/Arch:           darwin/amd64
 Experimental:      false

Server: Docker Engine - Community
 Engine:
  Version:          19.03.2
  API version:      1.40 (minimum version 1.12)
  Go version:       go1.12.8
  Git commit:       6a30dfc
  Built:            Thu Aug 29 05:32:21 2019
  OS/Arch:          linux/amd64
  Experimental:     false
 containerd:
  Version:          v1.2.6
  GitCommit:        89***************
 runc:
  Version:          1.0.0-rc8
  GitCommit:        42**********************
 docker-init:
  Version:          0.18.0
  GitCommit:        fe****

```
**Output of `docker-compose config`**
(Make sure to add the relevant `-f` and other flags)
```
services:
  api:
    depends_on:
    - database
    environment:
       C********_DATA_DIR: /opt/*******
    image: **************/***********:latest
    network_mode: service:database
    volumes:
    - server-config:/opt/**************
  database:
    environment:
      MYSQL_DATABASE: root
      MYSQL_PASSWORD: pass
      MYSQL_RANDOM_ROOT_PASSWORD: ""yes""
      MYSQL_USER: <name>
    image: mysql:5.7.23
    ports:
    - 8080/tcp
  ui:
    depends_on:
    - api
    - database
    environment:
      C**********_API_ADDRESS: database:8080
    image: *************/***********:latest
    ports:
    - 80/tcp
version: '3.0'
volumes:
  server-config: {}

```
## Steps to reproduce the issue
```
1. Startup a docker container
2. Stop the docker container
3. Run `docker-compose rm -v`
4. See the error for `No stopped containers`
5. Run `docker ps -a` to see that there are containers there with the status of 'Exit', leaving you wondering what happened. 
",,,falcon03,"
--
I am experiencing the same issue; any workaround to cleanup existing containers?
--
",Tloch95,"
--
Are the containers that appear in your `docker ps -a` output specified in your `docker-compose.yml ` file?
--
",carlosmmelo,"
--
Experiencing the same issue here
--

--
> Hi! Can you try please with the latest docker-compose version? I tried to reproduce this case with the latest and seemed to work fine. Unless there is something I missed...

it was user error, I'm running it through my CI, and when project is not specified compose names the project with the directory name...

So specifying the project name the same in different jobs, then it would work because it recognizes the container, etc
--
",aiordache,"
--
Hi! Can you try please with the latest docker-compose version? I tried to reproduce this case with the latest and seemed to work fine. Unless there is something I missed...
--
",kkmoslehpour,"
--
I'm also experiencing the same issue on my side with `docker-compose rm -fsv <service_name>`. Any ideas as to why this is happening ?
--
",,
6958,OPEN,Using `${foo:?Error}` construct is expanded at too early.,kind/bug; status/0-triage,2021-01-04 10:57:00 +0000 UTC,hansbogert,Opened,,"3. When making a bug report, make sure you provide all required information. The easier it is for
   maintainers to reproduce, the faster it'll be fixed.
-->

## using ${foo:?We need foo} construct is expande/triggered too early

When using multiple docker-compose files, e.g., `docker-compose -f docker-compose.yml -f docker-compose.dev.yml` and the former has a 

```
service:
  build:
    args: 
      FOO: ${foo:?Set 'foo' something}
```

 construct, and the latter docker-compose file has for example, 
```
service:
  build:
    args:
      FOO: iamhardcoded
```
Then, using docker-compose errors with:

```
docker-compose config
ERROR: Missing mandatory value for ""build"" option in service ""service"": set 'foo'
```



## Context information (for bug reports)

**Output of `docker-compose version`**
```
docker-compose version 1.22.0, build f46880fe
docker-py version: 3.4.1
CPython version: 3.6.6
OpenSSL version: OpenSSL 1.1.0f  25 May 2017

```

**Output of `docker version`**
```
docker version
Client: Docker Engine - Community
 Version:           19.03.2
 API version:       1.40
 Go version:        go1.12.8
 Git commit:        6a30dfc
 Built:             Thu Aug 29 05:29:11 2019
 OS/Arch:           linux/amd64
 Experimental:      false

Server: Docker Engine - Community
 Engine:
  Version:          19.03.2
  API version:      1.40 (minimum version 1.12)
  Go version:       go1.12.8
  Git commit:       6a30dfc
  Built:            Thu Aug 29 05:27:45 2019
  OS/Arch:          linux/amd64
  Experimental:     false
 containerd:
  Version:          1.2.6
  GitCommit:        894b81a4b802e4eb2a91d1ce216b8817763c29fb
 runc:
  Version:          1.0.0-rc8
  GitCommit:        425e105d5a03fabd737a126ad93d62a9eeede87f
 docker-init:
  Version:          0.18.0
  GitCommit:        fec3683

```

**Output of `docker-compose config`**
(Make sure to add the relevant `-f` and other flags)
```
docker-compose -f docker-compose.yml -f docker-compose.dev.yml config 
ERROR: Missing mandatory value for ""build"" option in service ""service"":  Set FOO !

```


## Steps to reproduce the issue

1. Use https://gist.githubusercontent.com/hansbogert/575eb05444a90e69dad8fb0c742b9626/raw/b8738564518bf7c052e176333f6182e0a91448d2/docker-compose.yml and https://gist.githubusercontent.com/hansbogert/a47b8bde980375af13a3658f0a7b65fe/raw/939da84fa15e910deca30de0aac3a96417e31d0d/docker-compose.dev.yml as docker-compose files
2. run `docker-compose -f docker-compose.yml -f docker-compose.dev.yml config`

### Observed result
```
ERROR: Missing mandatory value for ""build"" option in service ""service"":  Set FOO !

```

### Expected result
```
version: '3.7'
services:
  service:
    build:
      args:
        FOO: iamhardcoded
```

## Additional information

Ubuntu 18.04. 
",,,ndeloof,"
--
I can confirm issue with docker-compose 1.24.1
I'll investigate this issue
--

--
The logic to load multiple compose file https://github.com/docker/compose/blob/master/compose/config/config.py#L386 is to parse them all with Interpolation=True then load config sections merging elements from all yaml sources. By doing so each and every file has to individually be a valid compose yaml file, so the error you encounter.

Changing this logic and evaluating potential impacts is way beyound my Python skills :)
--

--
@thaJeztah the CLI indeed does the same : load and interpolate on a per-file basis https://github.com/docker/cli/blob/master/cli/compose/loader/loader.go#L98
--
",thaJeztah,"
--
We should check if the docker cli has the same problem
--

--
Thinking what the consequences would be to ""lazily"" expand (after merging); from the top of my head, something like the example below could be problematic;

```yaml
networks:
  foo:
    name: ${foo:?Set 'foo' something}
```

```yaml
networks:
  foo:
    external: true
```

Actually; I don't think that should be a problem, as we don't merge properties of the individual networks (last one just overwrites the previous one)  so from that perspective, it should work.

Changing should definitely get some eyes though, because merging can be complicated, and we need to be sure we don't miss some corner-case that we didn't think about
--

--
still an issue afaik, so don't close yet
--

--
Probably still an issue
--
",stale,"
--
This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you for your contributions.

--

--
This issue has been automatically marked as not stale anymore due to the recent activity.

--

--
This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you for your contributions.

--

--
This issue has been automatically marked as not stale anymore due to the recent activity.

--
",carlfischerjba,"
--
A similar situation occurs within a single compose file. If I run a service from that file I get warnings about missing variables in other services even though they have no effect on the service I'm running.

```
version: ""3.5""
services:
  a:
    image: busybox
    environment:
        - FOO=${FOO?Please provide FOO}
  b:
    image: busybox
    environment:
        - BAR=${BAR?Please provide BAR}
```

This should/could work but doesn't.

```
$ FOO=foo docker-compose -f /tmp/test.yml run a
ERROR: Missing mandatory value for ""environment"" option interpolating ['BAR=${BAR?Please provide BAR}'] in service ""b"": Please provide BAR
```

--

--
Somewhat related to #7203 where the request is to provide a switch for disabling validation of files output by `docker-compose config` so that they can contain variables that will be interpolated later.
--
",,,,
6951,OPEN,.env file whit variable with whitespace,kind/question; status/0-triage,2021-01-21 15:56:23 +0000 UTC,ping86,Opened,,"3. When making a bug report, make sure you provide all required information. The easier it is for
   maintainers to reproduce, the faster it'll be fixed.
-->

## Description of the issue

## Context information (for bug reports)

**Output of `docker-compose version`**
```
docker-compose version 1.24.0, build 0aa59064
docker-py version: 3.7.2
CPython version: 3.6.8
OpenSSL version: OpenSSL 1.1.0j  20 Nov 2018
```

**Output of `docker version`**
```
Client:
 Version:           18.09.3
 API version:       1.39
 Go version:        go1.10.8
 Git commit:        774a1f4
 Built:             Thu Feb 28 06:53:11 2019
 OS/Arch:           linux/amd64
 Experimental:      false

Server: Docker Engine - Community
 Engine:
  Version:          18.09.3
  API version:      1.39 (minimum version 1.12)
  Go version:       go1.10.8
  Git commit:       774a1f4
  Built:            Thu Feb 28 05:59:55 2019
  OS/Arch:          linux/amd64
  Experimental:     false

```

**Output of `docker-compose config`**
(Make sure to add the relevant `-f` and other flags)
```
ERROR: In file ./.env: environment variable name 'typesetting industry. Lorem Ipsum has been' may not contains whitespace.
```


## Steps to reproduce the issue

1. Create .env file with the this content:


```
LOREM=""Lorem Ipsum is simply dummy text of the printing and
typesetting industry. Lorem Ipsum has been
""
```
2. Use docker-compose config or docker-compose build commands

### Observed result

This issue occurs in docker-compose 1.24.0

If we rollback to  docker-compose 1.23.2 the issue is fixed:

> sudo curl -L ""https://github.com/docker/compose/releases/download/1.23.2/docker-compose-$(uname -s)-$(uname -m)"" -o /usr/local/bin/docker-compose

> docker-compose build

```
docker-compose build
nginx uses an image, skipping
Building php
....
```


### Expected result

### Stacktrace / full error message

```
ERROR: In file ./.env: environment variable name 'typesetting industry. Lorem Ipsum has been' may not contains whitespace.
``
",,,ndeloof,"
--
I downloaded docker-compose-1.23.2 trying to reproduce your issue with this minimal setup :

docker-compose.yml:
```yml
version: ""3""
services:
    test:
            image: alpine
            command: 'echo hello $FOO !'
```
.env
```
FOO=""bar
zot""
```

docker-compose up, both with 1.23 and 1.24 fail to run such a configuration.
Actually this feature was discussed on https://github.com/docker/compose/issues/3527 without any obvious fix on his way as env file support in docker engine do _not_ support multilines. Please note that using quotes around a value do not wrap a value as it does in plan shell, as bash isn't involved in parsing the .env file.

--
",ve,"
--
I was getting the same error and i did not use export in .env file. I have defined the variable like this and it worked for me
`var:FOO`
--
",Hassanzadeh,"
--
remove whitespace between environments 
`FOO = ""bar`
to
`FOO=""bar`
--
",syedrakib,"
--
I want to set the following contents into a .env file which i will use in my docker-compose

```

ENV=dev
MY_SERVICE_ACCOUNT='{
  ""type"": ""service_account"",
  ""project_id"": ""my-gcp-project"",
  ""private_key_id"": ""d8f6d9c92749"",
  ""private_key"": ""-----BEGIN PRIVATE KEY-----\nMIIEvQIBADANBgkqhkiG9w0BAQEFAASCBKcwgWI8\naewdr8VbO2sRk1AgmYGCu9s=\n-----END PRIVATE KEY-----\n"",
  ""client_email"": ""xyz@my-gcp-project.iam.gserviceaccount.com"",
  ""client_id"": ""740"",
  ""auth_uri"": ""https://acnt.google.com/o/o2auth/auth"",
  ""token_uri"": ""https://o2auth.googleapi.com/token"",
  ""auth_provider_x509_cert_url"": ""https://www.googleapi.com/o2auth/vX/cert"",
  ""client_x509_cert_url"": ""https://www.googleapis.com/robot/v1/metadata/x509/xyz%40my-gcp-project.iam.gserviceaccount.com""
}'
MY_PHRASE=""boo yaa""

```

It contains a JSON key of a GCP IAM Service Account in it.

I want to save that key in an environment variable  called `$MY_SERVICE_ACCOUNT`.

But i am getting a `...may not contain whitespace` error.

How do i bypass this? The Service Account key will certainly have whitespaces and stuff.
--
",sudughonge,"
--
^ Facing the same issue. I have an environment variable that _has_ to have spaces
--
",lil12t,"
--
I've got the same problem, the issue was in CI/CD config, it was SERVICE_NAME:'value' instead of SERVICE_NAME=value.


--
"
6939,OPEN,docker-compose-up fails to fetch remote images,status/0-triage,2020-12-11 14:36:48 +0000 UTC,davidje13,In progress,,"## Description of the issue

If an image used by `docker-compose.yml` is not cached locally, running `docker-compose up` will fail with the errors shown below (appears to be related to credentials).

## Context information (for bug reports)

**Output of `docker-compose version`**
```
docker-compose version 1.24.1, build 4667896b
docker-py version: 3.7.3
CPython version: 3.6.8
OpenSSL version: OpenSSL 1.1.0j  20 Nov 2018
```

**Output of `docker version`**
```
Client: Docker Engine - Community
 Version:           19.03.2
 API version:       1.40
 Go version:        go1.12.8
 Git commit:        6a30dfc
 Built:             Thu Aug 29 05:26:49 2019
 OS/Arch:           darwin/amd64
 Experimental:      false

Server: Docker Engine - Community
 Engine:
  Version:          19.03.2
  API version:      1.40 (minimum version 1.12)
  Go version:       go1.12.8
  Git commit:       6a30dfc
  Built:            Thu Aug 29 05:32:21 2019
  OS/Arch:          linux/amd64
  Experimental:     false
 containerd:
  Version:          v1.2.6
  GitCommit:        894b81a4b802e4eb2a91d1ce216b8817763c29fb
 runc:
  Version:          1.0.0-rc8
  GitCommit:        425e105d5a03fabd737a126ad93d62a9eeede87f
 docker-init:
  Version:          0.18.0
  GitCommit:        fec3683
```

**Output of `docker-compose config`**
```
services:
  anything:
    image: nginx
version: '2.0'
```

(nginx is used as an example here but any docker hub image will do)


## Steps to reproduce the issue

1. Ensure you do not have the configured image locally
2. Run `docker-compose up`

### Observed result

An error (see below)

### Expected result

Image is downloaded

### Stacktrace / full error message

```
Pulling anything (nginx:)...
Traceback (most recent call last):
  File ""site-packages/dockerpycreds/store.py"", line 80, in _execute
  File ""subprocess.py"", line 356, in check_output
  File ""subprocess.py"", line 438, in run
subprocess.CalledProcessError: Command '['/usr/local/bin/docker-credential-desktop', 'get']' returned non-zero exit status 1.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""site-packages/docker/auth.py"", line 264, in _resolve_authconfig_credstore
  File ""site-packages/dockerpycreds/store.py"", line 35, in get
  File ""site-packages/dockerpycreds/store.py"", line 93, in _execute
dockerpycreds.errors.StoreError: Credentials store docker-credential-desktop exited with ""No stored credential for https://index.docker.io/v1/"".

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""docker-compose"", line 6, in <module>
  File ""compose/cli/main.py"", line 71, in main
  File ""compose/cli/main.py"", line 127, in perform_command
  File ""compose/cli/main.py"", line 1085, in up
  File ""compose/cli/main.py"", line 1081, in up
  File ""compose/project.py"", line 527, in up
  File ""compose/service.py"", line 354, in ensure_image_exists
  File ""compose/service.py"", line 1222, in pull
  File ""compose/progress_stream.py"", line 102, in get_digest_from_pull
  File ""compose/service.py"", line 1187, in _do_pull
  File ""site-packages/docker/api/image.py"", line 381, in pull
  File ""site-packages/docker/auth.py"", line 48, in get_config_header
  File ""site-packages/docker/auth.py"", line 322, in resolve_authconfig
  File ""site-packages/docker/auth.py"", line 235, in resolve_authconfig
  File ""site-packages/docker/auth.py"", line 281, in _resolve_authconfig_credstore
docker.errors.DockerException: Credentials store error: StoreError('Credentials store docker-credential-desktop exited with ""No stored credential for https://index.docker.io/v1/"".',)
[3629] Failed to execute script docker-compose
```

## Additional information

I have never signed in to the docker daemon (I do not have an account).

Pulling the image first (i.e. `docker pull nginx`) makes the command succeed.

OS version: macOS 10.14.6",,,ndeloof,"
--
I tried to reproduce on a fresh new docker installation (Linux) and image is pulled as expected. This issue seem to be specific to Docker4Desktop integration.

--
",davidje13,"
--
From the errors produced, it looks like something is assuming everybody will have a docker login, and doesn't support pulling images without a login (even public images). But the stack trace does suggest this is in docker compose itself, rather than the external daemon.

I imagine OS X and Linux have different APIs for their keychains, so that's where I'd suspect the difference lies.
--

--
@claritee are you on mac or linux? (I'd like to know if this is unique to mac as suggested before)
--

--
I did some further digging and reported this to the docker-py repository here: https://github.com/docker/docker-py/issues/2482
--

--
@hzb yes this appears to be limited to macOS. I have tracked it down to a bug in dockerpy-creds, which is throwing the wrong exception when credentials are not found on mac (https://github.com/shin-/dockerpy-creds/issues/13), causing docker-py to mishandle the exception (https://github.com/docker/docker-py/issues/2482), which results in this bug.

btw, logging in may work around this issue, but it should not be required, and is not required on linux.
--

--
Since this issue has been stale-closed I'll add a link to the (very nested) issue which was eventually raised:

https://github.com/docker/docker-credential-helpers/issues/177
--
",claritee,"
--
Running `docker pull nginx` pulled the latest image of nginx, however the issue was resolved for me, by logging in unfortunately. 

I had to login with `docker login` and followed the prompts.
--
",marcelormourao,"
--
I had the same problem right now. I am using mac.

```
Pulling backend (marcelormourao/backend:)...
Traceback (most recent call last):
  File ""site-packages/dockerpycreds/store.py"", line 80, in _execute
  File ""subprocess.py"", line 356, in check_output
  File ""subprocess.py"", line 438, in run
subprocess.CalledProcessError: Command '['/usr/local/bin/docker-credential-desktop', 'get']' returned non-zero exit status 1.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""site-packages/docker/auth.py"", line 264, in _resolve_authconfig_credstore
  File ""site-packages/dockerpycreds/store.py"", line 35, in get
  File ""site-packages/dockerpycreds/store.py"", line 93, in _execute
dockerpycreds.errors.StoreError: Credentials store docker-credential-desktop exited with ""No stored credential for https://index.docker.io/v1/"".

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""docker-compose"", line 6, in <module>
  File ""compose/cli/main.py"", line 71, in main
  File ""compose/cli/main.py"", line 127, in perform_command
  File ""compose/cli/main.py"", line 1085, in up
  File ""compose/cli/main.py"", line 1081, in up
  File ""compose/project.py"", line 527, in up
  File ""compose/service.py"", line 354, in ensure_image_exists
  File ""compose/service.py"", line 1222, in pull
  File ""compose/progress_stream.py"", line 102, in get_digest_from_pull
  File ""compose/service.py"", line 1187, in _do_pull
  File ""site-packages/docker/api/image.py"", line 381, in pull
  File ""site-packages/docker/auth.py"", line 48, in get_config_header
  File ""site-packages/docker/auth.py"", line 322, in resolve_authconfig
  File ""site-packages/docker/auth.py"", line 235, in resolve_authconfig
  File ""site-packages/docker/auth.py"", line 281, in _resolve_authconfig_credstore
docker.errors.DockerException: Credentials store error: StoreError('Credentials store docker-credential-desktop exited with ""No stored credential for https://index.docker.io/v1/"".',)
[5281] Failed to execute script docker-compose
```
--
",hzb,"
--
@davidje13 Which system do you use Docker on? I met this issue on macOS, and I logged in Docker Desktop on macOS, and then the issue is fixed.
--

--
@davidje13 Yes, I am the same as you think, whey does it be required on macOS, but not on Linux.

BTW, If these images are not from the docker hub (index.docker.io), but from other places, such as docker.package.github.com. This problem still occurs, even if you logged in. All you need to do is check the option in Docker Desktop, as shown in red in the following picture.

![issue](https://user-images.githubusercontent.com/535675/71517921-3633a000-28eb-11ea-8612-8de96a113a0e.png)

--
",stale,"
--
This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you for your contributions.

--

--
This issue has been automatically marked as not stale anymore due to the recent activity.

--
"
6935,OPEN,compose breaks network on arm only,area/networking; kind/bug; status/0-triage,2021-01-23 13:46:16 +0000 UTC,qdel,Opened,,"3. When making a bug report, make sure you provide all required information. The easier it is for
   maintainers to reproduce, the faster it'll be fixed.
-->

## Description of the issue

When docker-compose up create a network, docker cannot create other networks.



## Context information (for bug reports)

Output of ""docker-compose version""
```
docker-compose version 1.21.0, build unknown
docker-py version: 3.4.1
CPython version: 3.7.3
OpenSSL version: OpenSSL 1.1.1d  10 Sep 2019
```

Output of ""docker version""
```
Client: Docker Engine - Community
 Version:           19.03.2
 API version:       1.40
 Go version:        go1.12.8
 Git commit:        6a30dfc
 Built:             Thu Aug 29 05:44:44 2019
 OS/Arch:           linux/arm
 Experimental:      false

Server: Docker Engine - Community
 Engine:
  Version:          19.03.2
  API version:      1.40 (minimum version 1.12)
  Go version:       go1.12.8
  Git commit:       6a30dfc
  Built:            Thu Aug 29 05:38:46 2019
  OS/Arch:          linux/arm
  Experimental:     false
 containerd:
  Version:          1.2.6
  GitCommit:        894b81a4b802e4eb2a91d1ce216b8817763c29fb
 runc:
  Version:          1.0.0-rc8
  GitCommit:        425e105d5a03fabd737a126ad93d62a9eeede87f
 docker-init:
  Version:          0.18.0
  GitCommit:        fec3683

```

Output of ""docker-compose config""
```
networks:
  super: {}
services:
  grafana:
    deploy:
      restart_policy:
        condition: on-failure
    image: grafana/grafana
    networks:
      super: null
    ports:
    - 127.0.0.1:3000:3000/tcp
    restart: unless-stopped
    volumes:
    - grafana:/var/lib/grafana:rw
  influxdb:
    deploy:
      restart_policy:
        condition: on-failure
    environment:
      INFLUXDB_UDP_DATABASE: '""udp""'
      INFLUXDB_UDP_ENABLED: ""true""
    image: influxdb
    networks:
      super: null
    ports:
    - 10.89.0.1:8086:8086/tcp
    - 10.89.0.1:8089:8089/udp
    restart: unless-stopped
    volumes:
    - influxdb:/var/lib/influxdb:rw
version: '3.0'
volumes:
  grafana: {}
  influxdb: {}
```


## Steps to reproduce the issue

1. Run docker-compose up
2. run docker network create abc (or docker-compose up another service)
3.  Error response from daemon: Failed to program FILTER chain: iptables failed: iptables --wait -I FORWARD -o br-0a9b0aa29512 -j DOCKER: iptables v1.8.3 (nf_tables):  RULE_INSERT failed (Invalid argument): rule in chain FORWARD
 (exit status 4)

### Observed result

docker-compose seems to break iptables (nftables) config for further docker-compose / docker network commands.

Runned service works correctly.

Without using compose, it is possible to create multiple networks using docker network create without any problem.

### Expected result

Be able to have multiple services / manually created networks.

### Stacktrace / full error message

```
(if applicable)
```

## Additional information

OS version / distribution, `docker-compose` install method, etc.

Tried with docker-compose / docker.io from debian and docker-ce from docker repository.

Scaleway C1 instance (arm)
debian 10, nftables, ufw.

Note that the bug does not reproduce on debian 10, nftables, ufw but amd64 laptop.

Note that docker let quite a lot of dirty config in this case:
- br-XXX interface still exists
- br-XXX iptables config still exists
 ",,,Hugo1380,"
--
Same issue here on Scaleway C2M instance (X86 64bit) Debian 10.
--
",gitl30n,"
--
> debian 10, nftables, ufw.

Use iptables legacy instead of nftables. With iptables legacy it works.


--
",netthier,"
--
This issue still exists with Debian Buster and the newest available docker-compose.
I can confirm that switching to iptables-legacy fixes the issue, but actually fixing the bug in compose would be great.
--
",ScarUY,"
--
> switching to iptables-legacy

I can confirm that on an up to date Debian buster, with lasttest available version of docker and docker compose the solution is to revert to iptables-legacy, for those of you who don't really knew that there was such a thing as iptables-legacy and that since buster debianis using nftables, just follow the instructions from https://wiki.debian.org/nftables the part named ""Switching to the legacy version:Switching to the legacy version""
--
",,,,
6931,OPEN,[Feature Request] Better handling of entropy on VPS,,2020-12-12 19:26:42 +0000 UTC,lonix1,In progress,,"**Problem**
Low entropy on VPSs cause docker-compose to hang for many minutes, for apps to be slow, etc.

Reported many times, including:
- https://github.com/docker/compose/issues/6678
- https://github.com/docker/compose/issues/6552
- https://github.com/docker/compose/issues/6462

*Will probably be reported again many times.*

**Workarounds**
There are two workarounds in those issues and on StackExchange:
- install `haveged` (and [some say](https://security.stackexchange.com/questions/34523/is-it-appropriate-to-use-haveged-as-a-source-of-entropy-on-virtual-machines) it isn't as secure/accurate as widely quoted... worth noting)
- patch `/usr/local/lib/<PYTHON_VERSION>/dist-packages/docker/transport/__init__.py` to [strip out the parts](https://github.com/docker/compose/issues/6552#issuecomment-508124668) that cause the problem

**Solutions**
1. *Please document these workarounds!* It's not a limitation of docker-compose itself, but many people encounter this problem only when using docker-compose. If documented it would avoid lots of wasted time and github issues.

2. The patching approach is ideal for our needs because we don't need that functionality, but it's an ugly hack - *it would be nice to have that as a config option* (i.e. not depend upon python stuff that isn't needed). And that would mean we don't need to remember to patch python on every update.",,,f100024,"
--
Did someone try install `rng-tools`? Seems it helped me.
--

--
I've based on this. https://tails.boum.org/contribute/design/random/

```
HAVEGE reliability
haveged relies on the RDTSC instruction, that apparently is useless in some virtualized environments. Also, the quality of random numbers output by HAVEGE is unclear, and the topic of many discussions.
Further research on this topic is left to be done.
This is why Tails also ships rngd. Still, it is not clear how these two daemons act together.

Hardware RNG trustworthiness and availability
It is not clear how much one can trust a hardware RNG, that is hard, if not impossible, to audit. Also, not all computers include a hardware RNG.
This is why Tails also ships HAVEGE. Still, it is not clear how these two daemons act together.
```

To check if your system have hardware random number generator(RNG). This should return something, otherwise try install `haveged`.
```
  grep -F -e rdseed -e rdrand /proc/cpuinfo
```

Installation:
```
$ sudo apt update && apt install rng-tools
```
In some cases rng-tools returned error:
```
...
Oct 26 04:11:02 ubuntuvps rng-tools[299]: /etc/init.d/rng-tools: Cannot find a hardware RNG device to use.
...
```
Added rng-device and restart daemon.
```
# echo ""HRNGDEVICE=/dev/urandom"" >> /etc/default/rng-tools && systemctl restart rng-tools.
```
--
",lonix1,"
--
@f100024 The conventional advice is to install `haveged`, which worked for me (though the problems mentioned above still apply). How does `rng-tools` differ?
--

--
@l3ender Not sure about mac, but look at the workarounds in the OP... and try `haveged`. (And let us know if it works for you, because this thread is also about creating better docs.)
--
",l3ender,"
--
I seem to be experiencing the same issues on my Mac using Docker Desktop. Is there any workaround?
--
",mmlr,"
--
I've run into this on a VPS and wanted to use jitterentropy-rngd as suggested in the libsodium documentation (https://libsodium.gitbook.io/doc/usage#sodium_init-stalling-on-linux). There indeed was no package for my host system available, so I put it into a container instead. I've made a pull-request for jitterentropy-rngd with which one can just clone the repo and `docker-compose up -d` to have this solved: https://github.com/smuellerDD/jitterentropy-rngd/pull/10
--
",SlavikCA,"
--
Running docker-compose on VPS on Azure.
Ubuntu 20.04

Entropy looks good:
```
root@ub20azure:/home/slavik# cat /proc/sys/kernel/random/entropy_avail
3868
```

`haveged` is installed.

Can't do the python patch, because I don't have files mentioned:
```
root@ub20azure:/home/slavik# ls -l /usr/local/lib/python3.8/dist-packages/
total 0
```
docker-compose build is extremely slow. Other (not build) commands are fast.

Am I looking at the wrong place for python files?
Anything else I can do?
--
",poggdogg,"
--
I noticed that when changing the context to a higher directory that the build times change.  It looks like docker-compose does a recursive search and/or caching of all directories based on the context dir.  IE:
```
root
- dir1 
- dir2
- dir3
```
If all the files are in dir3 (including dockerfile) and we're setting the context as root and pathing to dir3 to build it still takes a much longer time than if we are to change context to dir3. 

This is unfortunate because if we need to copy artifacts from other directories then performance takes a hit or if context dir is dir3 then we can't even copy from outside of context.
--
"
6910,OPEN,docker-compose ps should show port ranges as docker ps does,,2020-09-17 21:02:11 +0000 UTC,neale-bpm,Opened,,"`docker ps` gives a sensible output for ranges `1-5431/tcp, 5433-30000/tcp, 0.0.0.0:5432->5432/tcp` but frustratingly `docker-compose ps` gives `1/tcp, 10/tcp, 100/tcp, 1000/tcp, 10000/tcp, 10001/tcp, 10002/tcp, 10003/tcp, 10004/tcp, 10005/tcp, 10006/tcp, 10007/tcp`.

While large ranges like this are a bit nuts and that can be debated somewhere else, it would be helpful for docker-compose to match docker in the output format for `ps` in this case.",,,stale,"
--
This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you for your contributions.

--

--
This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you for your contributions.

--

--
This issue has been automatically marked as not stale anymore due to the recent activity.

--
",thaJeztah,"
--
.
--
",,,,,,,,
6904,OPEN,[Bug/Security] Wrong volume mounted if only a dash differs in project name.,,2020-09-15 08:08:54 +0000 UTC,Yivan,In progress,,"## Description of the issue

When a stack is up and volume are created with a project name (option `-p` of docker-compose up) having a dash in the name (ex: my-project), it seems docker/docker-compose try to find if a volume prefixed with the project name without a dash exist already (in this exemple: myproject) and if he found one he use it instead creating the volume with dash.

## Context information (for bug reports)

**Seems to affect a large scope of versions**

Seen on : docker-compose version 1.22.0, build f46880fe, on Debian 9 stable
Docker version:
Client:
 Version:           18.09.0
 API version:       1.39
 Go version:        go1.10.4
 Git commit:        4d60db4
 Built:             Wed Nov  7 00:48:46 2018
 OS/Arch:           linux/amd64
 Experimental:      false

Server: Docker Engine - Community
 Engine:
  Version:          18.09.0
  API version:      1.39 (minimum version 1.12)
  Go version:       go1.10.4
  Git commit:       4d60db4
  Built:            Wed Nov  7 00:16:44 2018
  OS/Arch:          linux/amd64
  Experimental:     false


And seen on : docker-compose version 1.24.1, build 4667896b, on Debian 10 stable
Client: Docker Engine - Community
 Version:           19.03.1
 API version:       1.40
 Go version:        go1.12.5
 Git commit:        74b1e89
 Built:             Thu Jul 25 21:21:24 2019
 OS/Arch:           linux/amd64
 Experimental:      false

Server: Docker Engine - Community
 Engine:
  Version:          19.03.1
  API version:      1.40 (minimum version 1.12)
  Go version:       go1.12.5
  Git commit:       74b1e89
  Built:            Thu Jul 25 21:19:56 2019
  OS/Arch:          linux/amd64
  Experimental:     false
 containerd:
  Version:          1.2.6
  GitCommit:        894b81a4b802e4eb2a91d1ce216b8817763c29fb
 runc:
  Version:          1.0.0-rc8
  GitCommit:        425e105d5a03fabd737a126ad93d62a9eeede87f
 docker-init:
  Version:          0.18.0
  GitCommit:        fec3683

**There is no specific configuration of docker or docker-compose, they are native/classic install and use.**

## Steps to reproduce the issue

Create and up a first stack with :
```
  myservicename:
    ...
    volumes:
      - ""myvolume:/mydatas""
````
And start it : `docker-compose -f /path/to/compose/file -p myproject up -d`

Make a second one with :
```
  myservicename:
    ...
    volumes:
      - ""myvolume:/mydatas""
````
And start it : `docker-compose -f /path/to/this/other/compose/file -p my-project up -d`

Note the difference in project name : `myproject` (for the first started) and `my-project` (for the second one started). The started order is important. If it is played in the other order there is no problem.

### Observed result

Inspect the second started service (on my-project) with `docker inspect ...` and you will see that volume are mounted from `myproject_myvolume`. 

### Expected result

It should be `my-project_myvolume`.

### Stacktrace / full error message

No error message, but it messed our multi project stack as volume from another stack was used (just a dash differs in the project name, exactly like the provided exemple).

## Additional information

I think it is a serious problem, as **IT CAN LEADS TO SECURITY PROBLEM** which can be silent, thinking the right container is mounted.

For now, as tempory fix, we post fixe the volume name (myvolume-${projectname}).
",,,stale,"
--
This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you for your contributions.

--

--
This issue has been automatically marked as not stale anymore due to the recent activity.

--

--
This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you for your contributions.

--

--
This issue has been automatically marked as not stale anymore due to the recent activity.

--
",Yivan,"
--
No it should not be staled. This issue is always happening.
Could someone of the docker compose team handle it please ?

Thanks.
Best regards.
--

--
Hello,

Please can someone take this issue under investigation ?

Thanks
--
",,,,,,,,
6902,OPEN,docker-compose config throws traceback if interval is a string without a suitable suffix.,,2020-10-20 16:35:13 +0000 UTC,pmav99,In progress,,"## Description of the issue

docker-compose config throws a traceback if interval is a string without a suitable suffix.

## Context information (for bug reports)

**Output of `docker-compose version`**
```
docker-compose version 1.24.1, build 4667896
docker-py version: 3.7.3
CPython version: 3.6.8
OpenSSL version: OpenSSL 1.1.1  11 Sep 2018
```

**Output of `docker version`**
```
Client: Docker Engine - Community
 Version:           19.03.2
 API version:       1.40
 Go version:        go1.12.8
 Git commit:        6a30dfc
 Built:             Thu Aug 29 05:29:11 2019
 OS/Arch:           linux/amd64
 Experimental:      false

Server: Docker Engine - Community
 Engine:
  Version:          19.03.2
  API version:      1.40 (minimum version 1.12)
  Go version:       go1.12.8
  Git commit:       6a30dfc
  Built:            Thu Aug 29 05:27:45 2019
  OS/Arch:          linux/amd64
  Experimental:     false
 containerd:
  Version:          1.2.6
  GitCommit:        894b81a4b802e4eb2a91d1ce216b8817763c29fb
 runc:
  Version:          1.0.0-rc8
  GitCommit:        425e105d5a03fabd737a126ad93d62a9eeede87f
 docker-init:
  Version:          0.18.0
  GitCommit:        fec3683
```

## Steps to reproduce the issue

1. Create this `docker-compose.yml`
```
---
version: '3.7'
services:
  db:
    image: postgresql
    healthcheck:
      test: [""CMD"", ""/healthcheck.sh""]
      interval: ""10""  # you can also try with e.g. ""10a""
```

2. Run `docker-compose config`

### Observed result

You will see this traceback:

```
Traceback (most recent call last):
  File ""/home/pmav99/.local/bin/docker-compose"", line 10, in <module>
    sys.exit(main())
  File ""/home/pmav99/.local/pipx/venvs/docker-compose/lib/python3.6/site-packages/compose/cli/main.py"", line 71, in main
    command()
  File ""/home/pmav99/.local/pipx/venvs/docker-compose/lib/python3.6/site-packages/compose/cli/main.py"", line 121, in perform_command
    handler(command, command_options)
  File ""/home/pmav99/.local/pipx/venvs/docker-compose/lib/python3.6/site-packages/compose/cli/main.py"", line 367, in config
    print(serialize_config(compose_config, image_digests))
  File ""/home/pmav99/.local/pipx/venvs/docker-compose/lib/python3.6/site-packages/compose/config/serialize.py"", line 98, in serialize_config
    denormalize_config(config, image_digests),
  File ""/home/pmav99/.local/pipx/venvs/docker-compose/lib/python3.6/site-packages/compose/config/serialize.py"", line 60, in denormalize_config
    for service_dict in config.services
  File ""/home/pmav99/.local/pipx/venvs/docker-compose/lib/python3.6/site-packages/compose/config/serialize.py"", line 60, in <listcomp>
    for service_dict in config.services
  File ""/home/pmav99/.local/pipx/venvs/docker-compose/lib/python3.6/site-packages/compose/config/serialize.py"", line 147, in denormalize_service_dict
    service_dict['healthcheck']['interval']
  File ""/home/pmav99/.local/pipx/venvs/docker-compose/lib/python3.6/site-packages/compose/config/serialize.py"", line 116, in serialize_ns_time_value
    tmp = value / stage[0]
TypeError: unsupported operand type(s) for /: 'NoneType' and 'float'
```
### Expected result

Detecting that the healthcheck value is invalid and showing an appropriate error would be nice.
",,,stale,"
--
This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you for your contributions.

--

--
This issue has been automatically marked as not stale anymore due to the recent activity.

--
",pmav99,"
--
This is still an issue on:
```
$ docker-compose version
docker-compose version 1.25.4, build unknown
docker-py version: 4.2.0
CPython version: 3.8.2
OpenSSL version: OpenSSL 1.1.1d  10 Sep 2019
```
--
",EpiqSty,"
--
This is still an issue on:

```
$ docker-compose --version
docker-compose version 1.26.0, build d4451659
$  docker-compose config
Traceback (most recent call last):
  File ""bin/docker-compose"", line 6, in <module>
  File ""compose/cli/main.py"", line 72, in main
  File ""compose/cli/main.py"", line 122, in perform_command
  File ""compose/cli/main.py"", line 354, in config
  File ""compose/config/serialize.py"", line 106, in serialize_config
  File ""compose/config/serialize.py"", line 62, in denormalize_config
  File ""compose/config/serialize.py"", line 62, in <listcomp>
  File ""compose/config/serialize.py"", line 159, in denormalize_service_dict
  File ""compose/config/serialize.py"", line 124, in serialize_ns_time_value
TypeError: unsupported operand type(s) for /: 'NoneType' and 'float'
[13809] Failed to execute script docker-compose
```

--
",,,,,,
6879,OPEN,Unable to build for arm32 and arm64 (1.24.1),,2021-01-06 07:59:11 +0000 UTC,NicolasDorier,In progress,,"The SSH dependency via paramiko broke the build for arm32 and arm64 (for 1.24.1)


You can try to build my repo on https://github.com/btcpayserver/docker-compose-builder :

Dependency:
```bash
docker run --rm --privileged multiarch/qemu-user-static:register --reset
apt install -y qemu qemu-user-static qemu-user binfmt-support
```

Build:
```bash
docker build -t temp -f .\linuxarm32v7.Dockerfile --build-arg DOCKER_COMPOSE_VER=1.24.1 .
```


Error on libsodium tests:
https://circleci.com/gh/btcpayserver/docker-compose-builder/89",,,NicolasDorier,"
--
Posted on PynACL https://github.com/pyca/pynacl/issues/553 with temporary workaround.
--

--
unsolved
--

--
bump
--
",stale,"
--
This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you for your contributions.

--

--
This issue has been automatically marked as not stale anymore due to the recent activity.

--

--
This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you for your contributions.

--

--
This issue has been automatically marked as not stale anymore due to the recent activity.

--
",dvonessen,"
--
I have the same issue here. 
--
",,,,,,
6867,OPEN,docker-compose ps should show uptime,kind/enhancement,2020-12-03 05:49:14 +0000 UTC,bertjwregeer,In progress,,"**Is your feature request related to a problem? Please describe.**

I would like to be able to see when the last time was that a docker container was restarted/updated. Similar to #4577, but my main concern is seeing the uptime of the container.

**Describe the solution you'd like**

```
docker-compose ps
```

shows the time since the container was launched.

**Describe alternatives you've considered**

Right now I use:

```
docker ps -a
``` 

instead, which means I get a sea of output that may not be relevant, especially if I am running multiple docker-compose setups locally.",,,stale,"
--
This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you for your contributions.

--

--
This issue has been automatically marked as not stale anymore due to the recent activity.

--

--
This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you for your contributions.

--

--
This issue has been automatically marked as not stale anymore due to the recent activity.

--
",bertjwregeer,"
--
There's an open pull request for this... but so far no movement on it. It is not a stale request.
--

--
Still not stale, still a good feature request.
--
",mjraadi,"
--
Would love to see this.
--
",,,,,,
6855,OPEN,Feature Request: Init Containers for Docker Compose,,2020-12-09 08:46:33 +0000 UTC,soapergem,Opened,,"**Is your feature request related to a problem? Please describe.**

Kubernetes has a concept called [Init Containers](https://kubernetes.io/docs/concepts/workloads/pods/init-containers/) which currently has no direct parallel in Docker Compose. There are certain applications designed to take advantage of Init Containers which cannot be correctly tested locally using Docker Compose due to this limitation.

**Describe the solution you'd like**

The Docker Compose docs includes an article on [Startup Order for Containers](https://docs.docker.com/compose/startup-order/) but this doesn't capture the essence of this problem. That article stresses, repeatedly, that there is no good way for Docker Compose to determine when a container is truly ""up,"" so dependent applications should be designed with checks. However Init Containers are a totally different animal, as they are designed to start up **and terminate** before the next container runs. Termination is, in fact, very easy to check for and should be thought of as a different use case entirely.

In other words, there should be a solution in Docker Compose to declare that a container is dependent on a special class of ""Init Containers"" which will start up, run, and terminate before launching the rest. All you'd really have to do is add a flag in the configuration - something like `initContainer: true`

**Describe alternatives you've considered**

The only ""alternatives"" aren't really alternatives at all. You can override the default entrypoint / commands of the dependent containers to wait some fixed interval, but this is sloppy guesswork and does not represent good application design. You could write your application code in the dependent containers to check that other containers (with certain names, maybe?) at one time existed and are no longer running... but you see where this is going, no one does this, and indeed no one _should_ try to do this, because it's sloppy, unreliable, and bad design. On the other hand, it would be very easy to check, from a Docker Compose standpoint, that a container has terminated before launching the next.

**Additional context**

An example of an application that makes use of Kubernetes' Init Containers is `vault-env`, by Banzai Cloud. They have an in-depth article on it [here](https://banzaicloud.com/blog/inject-secrets-into-pods-vault/). Essentially, they have an Init Container application which copies itself to a shared volume as a means of injecting secrets from Hashicorp Vault, and then the default entrypoint / command of the dependent container is updated to call the binary in the shared volume. Currently with Docker Compose this is not possible, because it doesn't wait for the first container to finish executing before trying to launch the second, so the application doesn't copy to the shared volume in time. Again, you can hack around this by changing the entrypoint to a long string involving `bash -c sleep 3; /shared-volume/vault-env ...` but this is an absolute mess.

Kubernetes has Init Containers. Docker Compose needs them too!",,,cartermckinnon,"
--
I agree; init containers are an elegant way to achieve much more flexible, reliable lifecycle management for a stack. The alternatives are distasteful.

I would rather write a `docker-compose.yml` than a helm chart, but (in the interest of time) using a local Kubernetes cluster may be a better solution. You can set one up with a checkbox in Docker for Mac, and you'd be able to use all your k8s files instead of having to maintain a `docker-compose.yml`.
--
author:	
association:	none
edited:	false
status:	none
--
Coming from Kubernetes I was just looking for this feature. The company am I working for now does not have a Kubernetes implementation yet. And for now just a Docker installation is fine. But I am missing this feature.
--

--
Coming from Kubernetes I was just looking for this feature. The company am I working for now does not have a Kubernetes implementation yet. And for now just a Docker installation is fine. But I am missing this feature.
--
author:	cartermckinnon
association:	none
edited:	true
status:	none
--
Having had more experience with `initContainers` in production, there are some downsides. Specifically, if an `initContainer` is not successful, how often is it retried? In Kubernetes, the `Pod` enters `CrashLoopBackoff` (exponential backoff). This can cause your stack to be slow to stabilize when the `initContainer` finally succeeds. An Operator is one way to conduct a complex lifecycle without this sort of delay. I'm not sure what an ""operator"" would look like in a bare Docker setup -- a shell script?  
--
",blackandred,"
--
Having had more experience with `initContainers` in production, there are some downsides. Specifically, if an `initContainer` is not successful, how often is it retried? In Kubernetes, the `Pod` enters `CrashLoopBackoff` (exponential backoff). This can cause your stack to be slow to stabilize when the `initContainer` finally succeeds. An Operator is one way to conduct a complex lifecycle without this sort of delay. I'm not sure what an ""operator"" would look like in a bare Docker setup -- a shell script?  
--
author:	blackandred
association:	none
edited:	false
status:	none
--
This feature would be nice to see in compose. It is very helpful, so some kind of ""Maintenance page"" could be easily implemented in place of apps that are not up yet. Often applications do not wait for linked services such as database, cache or other linked application.
--

--
We have a few scenarios where we want to move to init containers.   

- certificate generation
- database provisioning
- common configuration

Right now we use the approach above which is to have a flag that tells the init container to not shutdown in compose environments, but run normal in kubernetes environment.  
--
author:	blackandred
association:	none
edited:	true
status:	none
--
I'm developing a docker (compose based) environment framework/template with features such as service discovery, automatic SSL, rolling updates (zero-downtime deployments) and I also plan to implement startup priority+ init containers. 

I'm preparing a 2.0 version rewritten in Python where I plan to implement init containers within month or two (possibly in 2.1) - **subscribe for releases** :)

https://github.com/riotkit-org/riotkit-harbor/tree/migrate_to_rkd

![harbor](https://user-images.githubusercontent.com/22807686/84422542-7bd7f100-ac1d-11ea-8b60-e25265ccd4a4.png)

--
",AndreasGB,"
--
This feature would be nice to see in compose. It is very helpful, so some kind of ""Maintenance page"" could be easily implemented in place of apps that are not up yet. Often applications do not wait for linked services such as database, cache or other linked application.
--
author:	AndreasGB
association:	none
edited:	false
status:	none
--
I'd also love for this feature to be implemented as well. 

My usecase is generating config files containing per-deployment secrets that two containers expect.
--
",dfcowell,"
--
I'd also love for this feature to be implemented as well. 

My usecase is generating config files containing per-deployment secrets that two containers expect.
--
author:	dfcowell
association:	none
edited:	true
status:	none
--
I worked around this by defining a shared volume that my init container writes to and then sleeps forever, which my dependent containers poll.

```yaml
version: '3.7'
services:

  bootstrap:
    build: ./
    volumes:
      - ./:/app
      - bootstrap:/bootstrap
    command: ./bootstrap.sh

  dependent-1:
    build: ./
    depends_on:
      - bootstrap
    volumes:
      - ./:/app
      - bootstrap:/bootstrap
    command: /app/start.sh dependent-1

  dependent-2:
    build: ./
    depends_on:
      - bootstrap
    volumes:
      - ./:/app
      - bootstrap:/bootstrap
    command: /app/start.sh dependent-2

volumes:
  bootstrap:
```

**bootstrap.sh:**
```bash
#! /bin/ash

if test ! -f ""/bootstrap/bootstrap""; then
  lerna bootstrap

  # This provides an init-contianer-like experience on docker-compose, which
  # doesn't natively support init containers.
  today=$(date +""%Y-%m-%d"")

  echo ""${today}"" > /bootstrap/bootstrap
fi

sleep infinity
```

**start.sh:**
```bash
#! /bin/ash

set -e

until test -f ""/bootstrap/bootstrap""; do
  >&2 echo ""Waiting for bootstrap - sleeping""
  sleep 3
done

cd ""./packages/$1""

yarn start
```
Won't work for all init container use-cases, but it solves a subset of them.
--
",fksimon,"
--
I worked around this by defining a shared volume that my init container writes to and then sleeps forever, which my dependent containers poll.

```yaml
version: '3.7'
services:

  bootstrap:
    build: ./
    volumes:
      - ./:/app
      - bootstrap:/bootstrap
    command: ./bootstrap.sh

  dependent-1:
    build: ./
    depends_on:
      - bootstrap
    volumes:
      - ./:/app
      - bootstrap:/bootstrap
    command: /app/start.sh dependent-1

  dependent-2:
    build: ./
    depends_on:
      - bootstrap
    volumes:
      - ./:/app
      - bootstrap:/bootstrap
    command: /app/start.sh dependent-2

volumes:
  bootstrap:
```

**bootstrap.sh:**
```bash
#! /bin/ash

if test ! -f ""/bootstrap/bootstrap""; then
  lerna bootstrap

  # This provides an init-contianer-like experience on docker-compose, which
  # doesn't natively support init containers.
  today=$(date +""%Y-%m-%d"")

  echo ""${today}"" > /bootstrap/bootstrap
fi

sleep infinity
```

**start.sh:**
```bash
#! /bin/ash

set -e

until test -f ""/bootstrap/bootstrap""; do
  >&2 echo ""Waiting for bootstrap - sleeping""
  sleep 3
done

cd ""./packages/$1""

yarn start
```
Won't work for all init container use-cases, but it solves a subset of them.
--
author:	fksimon
association:	none
edited:	false
status:	none
--
We have a few scenarios where we want to move to init containers.   

- certificate generation
- database provisioning
- common configuration

Right now we use the approach above which is to have a flag that tells the init container to not shutdown in compose environments, but run normal in kubernetes environment.  
--
",stale,"
--
I'm developing a docker (compose based) environment framework/template with features such as service discovery, automatic SSL, rolling updates (zero-downtime deployments) and I also plan to implement startup priority+ init containers. 

I'm preparing a 2.0 version rewritten in Python where I plan to implement init containers within month or two (possibly in 2.1) - **subscribe for releases** :)

https://github.com/riotkit-org/riotkit-harbor/tree/migrate_to_rkd

![harbor](https://user-images.githubusercontent.com/22807686/84422542-7bd7f100-ac1d-11ea-8b60-e25265ccd4a4.png)

--
author:	stale
association:	none
edited:	false
status:	none
--
This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you for your contributions.

--

--
I'm still interested specially for swarm 

--
author:	stale
association:	none
edited:	false
status:	none
--
This issue has been automatically marked as not stale anymore due to the recent activity.

--
"
6851,OPEN,Ability to show only container logs without container name with `docker-compose logs`,kind/feature,2021-02-08 09:28:21 +0000 UTC,serge1peshcoff,In progress,,"-->

**Is your feature request related to a problem? Please describe.**
I have a few of my docker containers logging to stdout with JSON and I want to pass this output to a CLI utility to pretty-print it. For now each log line is prepended with the service name, and I can't find a way to disable it (or there is such flag but it's not documented).

This is how the output looks like:


```
$ docker-compose -f /opt/MyAEGEE/base-docker-compose.yml -f /opt/MyAEGEE/oms-global/docker/docker-compose.yml -f /opt/MyAEGEE/oms-core-elixir/docker/docker-compose.yml -f /opt/MyAEGEE/oms-serviceregistry/docker/docker-compose.yml -f /opt/MyAEGEE/oms-events/docker/docker-compose.yml -f /opt/MyAEGEE/oms-statutory/docker/docker-compose.yml -f /opt/MyAEGEE/oms-frontend/docker/docker-compose.yml -f /opt/MyAEGEE/oms-logo-print/docker/docker-compose.yml -f /opt/MyAEGEE/oms-mailer/docker/docker-compose.yml -f /opt/MyAEGEE/oms-discounts/docker/docker-compose.yml -f /opt/MyAEGEE/alastair/docker/docker-compose.yml logs -f --tail=100 oms-statutory

oms-statutory_1             | 2019-08-14T11:00:23.962Z [debug]: 	Executing (default): SELECT ""event"".*, ""applications"".""id"" AS ""applications.id"", ""applications"".""event_id"" AS ""applications.event_id"", ""applications"".""user_id"" AS ""applications.user_id"", ""applications"".""body_id"" AS ""applications.body_id"", ""applications"".""visa_required"" AS ""applications.visa_required"", ""applications"".""board_comment"" AS ""applications.board_comment"", ""applications"".""answers"" AS ""applications.answers"", ""applications"".""participant_type"" AS ""applications.participant_type"", ""applications"".""participant_order"" AS ""applications.participant_order"", ""applications"".""status"" AS ""applications.status"", ""applications"".""cancelled"" AS ""applications.cancelled"", ""applications"".""paid_fee"" AS ""applications.paid_fee"", ""applications"".""attended"" AS ""applications.attended"", ""applications"".""registered"" AS ""applications.registered"", ""applications"".""departed"" AS ""applications.departed"", ""applications"".""first_name"" AS ""applications.first_name"", ""applications"".""last_name"" AS ""applications.last_name"", ""applications"".""email"" AS ""applications.email"", ""applications"".""gender"" AS ""applications.gender"", ""applications"".""body_name"" AS ""applications.body_name"", ""applications"".""nationality"" AS ""applications.nationality"", ""applications"".""visa_place_of_birth"" AS ""applications.visa_place_of_birth"", ""applications"".""visa_passport_number"" AS ""applications.visa_passport_number"", ""applications"".""visa_passport_issue_date"" AS ""applications.visa_passport_issue_date"", ""applications"".""visa_passport_expiration_date"" AS ""applications.visa_passport_expiration_date"", ""applications"".""visa_passport_issue_authority"" AS ""applications.visa_passport_issue_authority"", ""applications"".""visa_embassy"" AS ""applications.visa_embassy"", ""applications"".""visa_street_and_house"" AS ""applications.visa_street_and_house"", ""applications"".""visa_postal_code"" AS ""applications.visa_postal_code"", ""applications"".""visa_city"" AS ""applications.visa_city"", ""applications"".""visa_country"" AS ""applications.visa_country"", ""applications"".""date_of_birth"" AS ""applications.date_of_birth"", ""applications"".""number_of_events_visited"" AS ""applications.number_of_events_visited"", ""applications"".""meals"" AS ""applications.meals"", ""applications"".""allergies"" AS ""applications.allergies"", ""applications"".""is_on_memberslist"" AS ""applications.is_on_memberslist"", ""applications"".""statutory_id"" AS ""applications.statutory_id"", ""applications"".""created_at"" AS ""applications.created_at"", ""applications"".""updated_at"" AS ""applications.updated_at"", ""image"".""id"" AS ""image.id"", ""image"".""user_id"" AS ""image.user_id"", ""image"".""file_name"" AS ""image.file_name"", ""image"".""file_folder"" AS ""image.file_folder"", ""image"".""created_at"" AS ""image.created_at"", ""image"".""updated_at"" AS ""image.updated_at"" FROM (SELECT ""event"".""id"", ""event"".""name"", ""event"".""starts"", ""event"".""ends"", ""event"".""description"", ""event"".""status"", ""event"".""application_period_starts"", ""event"".""application_period_ends"", ""event"".""board_approve_deadline"", ""event"".""participants_list_publish_deadline"", ""event"".""memberslist_submission_deadline"", ""event"".""body_id"", ""event"".""questions"", ""event"".""fee"", ""event"".""type"", ""event"".""image_id"", ""event"".""url"", ""event"".""created_at"", ""event"".""updated_at"" FROM ""events"" AS ""event"" WHERE ""event"".""url"" ILIKE 'autumn-agora-salerno-2019' LIMIT 1) AS ""event"" LEFT OUTER JOIN ""applications"" AS ""applications"" ON ""event"".""id"" = ""applications"".""event_id"" LEFT OUTER JOIN ""images"" AS ""image"" ON ""event"".""image_id"" = ""image"".""id"";
oms-statutory_1             | 2019-08-14T11:00:24.662Z [info]: 	GET /events/autumn-agora-salerno-2019/applications/stats 200 8334 - 724.043 ms, user couchie with id 93
oms-statutory_1             | 2019-08-14T11:00:28.659Z [debug]: 	Executing (default): SELECT ""event"".""id"", ""event"".""name"", ""event"".""starts"", ""event"".""ends"", ""event"".""description"", ""event"".""status"", ""event"".""application_period_starts"", ""event"".""application_period_ends"", ""event"".""board_approve_deadline"", ""event"".""participants_list_publish_deadline"", ""event"".""memberslist_submission_deadline"", ""event"".""body_id"", ""event"".""questions"", ""event"".""fee"", ""event"".""type"", ""event"".""image_id"", ""event"".""url"", ""event"".""created_at"", ""event"".""updated_at"", ""image"".""id"" AS ""image.id"", ""image"".""user_id"" AS ""image.user_id"", ""image"".""file_name"" AS ""image.file_name"", ""image"".""file_folder"" AS ""image.file_folder"", ""image"".""created_at"" AS ""image.created_at"", ""image"".""updated_at"" AS ""image.updated_at"" FROM ""events"" AS ""event"" LEFT OUTER JOIN ""images"" AS ""image"" ON ""event"".""image_id"" = ""image"".""id"" WHERE ""event"".""status"" = 'published' ORDER BY ""event"".""starts"" DESC LIMIT 1;
oms-statutory_1             | 2019-08-14T11:00:28.709Z [info]: 	GET /events/latest 304  - 74.354 ms, user andreeacezara with id 2171
oms-statutory_1             | 2019-08-14T11:10:46.393Z [debug]: 	Executing (default): SELECT ""event"".""id"", ""event"".""name"", ""event"".""starts"", ""event"".""ends"", ""event"".""description"", ""event"".""status"", ""event"".""application_period_starts"", ""event"".""application_period_ends"", ""event"".""board_approve_deadline"", ""event"".""participants_list_publish_deadline"", ""event"".""memberslist_submission_deadline"", ""event"".""body_id"", ""event"".""questions"", ""event"".""fee"", ""event"".""type"", ""event"".""image_id"", ""event"".""url"", ""event"".""created_at"", ""event"".""updated_at"", ""image"".""id"" AS ""image.id"", ""image"".""user_id"" AS ""image.user_id"", ""image"".""file_name"" AS ""image.file_name"", ""image"".""file_folder"" AS ""image.file_folder"", ""image"".""created_at"" AS ""image.created_at"", ""image"".""updated_at"" AS ""image.updated_at"" FROM ""events"" AS ""event"" LEFT OUTER JOIN ""images"" AS ""image"" ON ""event"".""image_id"" = ""image"".""id"" WHERE ""event"".""status"" = 'published' ORDER BY ""event"".""starts"" DESC LIMIT 1;
oms-statutory_1             | 2019-08-14T11:10:46.426Z [info]: 	GET /events/latest 304  - 63.980 ms, user veysellkoca with id 2670
```

**Describe the solution you'd like**
Some flag to remove it, like `--no-container-names` or something simplier that would disable prepending it.

**Describe alternatives you've considered**
A workaround is to use `cut`, but it's ugly:

```
docker-compose logs -f --tail=100 <service-name> | cut -f2 -d '|'
```

**Additional context**
None.


-----

EDIT: As @ndeloof suggested, this can work:

```
docker-compose  ps -q <service> | xargs -I {} docker logs -f --tail=100 {}
```
",,,mirao,"
--
I would appreciate it for `docker-compose up` as well because console output is too wide when viewing it in Jenkins job results.
--

--
Yes, I can confirm it's [fixed](https://github.com/docker/compose/releases/tag/1.28.0): `docker-compose up --no-log-prefix` doesn't log container name. Tested with docker-compose 1.28.2 on Ubuntu 20.04
--
",brunofin,"
--
+1
--
",ndeloof,"
--
docker compose is designed to manage multiple containers, and as such to distinguish which container a log line is originated from.
If you want to obtain log a single container, you can use the standard `docker` commands, and can obtain container ID running `docker compose ps <service> -q`


--

--
can be even simpler : `docker logs -f $(docker-compose  ps -q <service>)`

I have a few dozen aliases in my .profile for such commands :P
--
",serge1peshcoff,"
--
@ndeloof didn't know about `ps <service> -q` thing, thanks!

I've come up with a easier solution without using `cut`, should be the proper way of solving it:

```
docker-compose  ps -q <service> | xargs -I {} docker logs -f --tail=100 {}
```

I've put `-f --tail=100` as arguments to only display last 100 lines, you can customize it in any way you want.
--
",lgathy,"
--
The suggested alternatives and workarounds are not always applicable, thus I think this would be a reasonable feature to add.

Take [gradle-docker-compose-plugin](https://github.com/avast/gradle-docker-compose-plugin) as an example, you can set it up to capture the logs of each containers into separate files, see: [source](https://github.com/avast/gradle-docker-compose-plugin/blob/87c8e97a8052ec98351f04d74c8c96f6aca8b9c5/src/main/groovy/com/avast/gradle/dockercompose/tasks/ComposeUp.groovy#L137). But, it uses the `docker-compose logs` command, becuase it needs to capture all the settings configured i.e. project name, compose files, etc. Thus, the individual log files still contain the unnecessary prefix in every line.

It would just easy to pass an extra argument [here](https://github.com/avast/gradle-docker-compose-plugin/blob/0ba74fa7a0fb9fbad681ee72794c7c51e5e40555/src/main/groovy/com/avast/gradle/dockercompose/ComposeExecutor.groovy#L114) if this feature would exists. Sure, there are alternatives, such as resolving the container id and use `docker logs` instead. I still think it's better and more flexible to add this flag as well.
--
",simonhir,"
--
Seems like these is a duplicate of #7416 which was already solved and merged or am I wrong?

For the docs there is an open merge request.
--
"
6831,OPEN,Release docker/compose image for armv7 / arm64v8,kind/feature,2021-02-22 17:23:52 +0000 UTC,maruel,Opened,,"**Is your feature request related to a problem? Please describe.**

Using `curl -L ""https://github.com/docker/compose/releases/download/1.24.1/docker-compose-$(uname -s)-$(uname -m)"" > docker-compose`
fails on Raspbian as described in issue #6810.

The root causes are:

- https://github.com/docker/compose/releases only contain releases for amd64 / x64-64.
- https://hub.docker.com/r/docker/compose is not multi-arch enabled.

While issue #6810 was closed, I think this is a genuine feature request since instructions at https://docs.docker.com/compose/install/#install-as-a-container are not clear about which platforms are _officially_ supported to run docker-compose as a container.

Two recent events may now make this worth:

- The new RPi4 has real 1Gbit ethernet. It becomes a real platform for hobbyist with limited linux experience using Raspbian to host images. 
- Docker Hub has real native support for multi-arch images via [manifest v2](https://docs.docker.com/registry/spec/manifest-v2-2/).

Combined with the fact that docker-compose is a *core building block for orchestrating images*, the lack of support on arm v7 (32 bits) and v8 (64 bits) makes the bootstrapping process options more limited than on x86 equivalent and the documentation is not clear about which options work where.

As stated at https://github.com/docker/compose/issues/4733#issuecomment-294021065, there _used_ to be a Dockerfile.armhf. This file was deleted in #6666 by @joakimr-axis since the current one works just fine.

**Describe the solution you'd like**

Officially create armv7 and arm64v8 docker images to https://hub.docker.com/r/docker/compose as part of the release process.

This is essentially a process change, not a code change, since the Dockerfile is known to work on arm already. This would involve at the very least updating [.circleci/config.yml](https://github.com/docker/compose/blob/master/.circleci/config.yml).

**Describe alternatives you've considered**

Installing via `pip` works in the meantime but is trickier to run this process successfully for new comers with limited linux experience, especially that the documentation is misleading about what is supported and what is not. This leads to a poor user experience (UX).",,,webash,"
--
As a new user to Docker, hoping to make my Raspberry Pi 4 the test ground for learning Docker, this stumbling block has been impossible to get past. Every tutorial uses docker-compose and the fact that it seems impossible to obtain easily has wasted hours of my time.

There is no clear reason why this isn't the case. It should at least be called out in the installation documentation in the meantime.

For those trying to understand why it is so hard: there is no official documentation for getting Docker (and compose!) up and running on an RPI. The general Linux guidance doesn't work. There are hundreds of tutorials out there, all of them of varying ages (the older ones being most wrong), all with varying levels of self-described 'easy' steps, most of them involving what can only be best described as hacks. I just wanted a little bit of a home project to learn a new technology. Instead I've wasted my time frustratingly. KISS principles do not appear to have been followed here.
--

--
Python dependencies and the share number of them for `docker-compose` is a crime to install directly on a machine where containers will be used; so I ended up following [these instructions](https://www.berthon.eu/2019/revisiting-getting-docker-compose-on-raspberry-pi-arm-the-easy-way/) for getting a `docker-compose` container spun up on the Raspberry Pi.
--
",nemchik,"
--
@webash I'm sorry to hear you've had troubles installing compose. You should be able to do it pretty easily by installing `python3` and `python3-pip` first and then running `python3 -m pip install -IU docker-compose`.

If you have further issues feel free to reach out via my contact info on my GitHub profile since this isn't really a support thread.

That being said I'm subscribed here hoping to see any kind of movement in this happening. I'd love to he able to run compose from docker on ARM. It works great on x86_64.
--

--
Interestingly those instructions use a Dockerfile from this very repo. I'm pretty sure all we're asking for is an `armhf` tag on docker hub. Maybe a multiarch manifest if the devs are feeling fresh  
--

--
https://hub.docker.com/r/linuxserver/docker-compose

Hopefully this helps anyone waiting for an official response.
--

--
> There are official, up-to-date raspbian builds for docker core ...
> 
> ```
> https://download.docker.com/linux/raspbian/dists/buster/pool/stable/armhf
> ```
> 
> but not for compose? Why is that?

Compose installs via pip, which works fine on arm. This issue it's specifically about the lack of an official docker image built for arm.
--

--
> Last time I checked compose wants python 3, while raspbian's global python is still 2. `apt-get install docker-compose` is still the cleanest compromise, but then we end up with an older version of it. Look, it's not the end of the world, I just can't help feeling the general docker experience on ARM/Raspbian still lags behind what I'm used to on mainstream cpus/distros.

Echoing the Recommended method from https://hub.docker.com/r/linuxserver/docker-compose
```bash
sudo curl -L --fail https://raw.githubusercontent.com/linuxserver/docker-docker-compose/master/run.sh -o /usr/local/bin/docker-compose
sudo chmod +x /usr/local/bin/docker-compose
```
Should work on any linux distro and should work on `x86_64`, `armv7l`/`armhf`, and `aarch64`/`armv8`/`arm64` if you already have docker installed.

Edit:
To be clear this runs compose inside a container and does not require installing python on the host system.
--
",joakimr,"
--
Yes, multiarch would surely be the contemporary way.
--
",Ivan61,"
--
@webash 

I had built it on my Raspberry Pi 3 Model B Rev 1.2 with Raspbian10 (buster) [arm/v7].
You can try to do it on your Raspberry Pi 4.
```
pi@raspberrypi:~ $ git clone https://github.com/docker/compose.git
pi@raspberrypi:~ $ cd compose/
pi@raspberrypi:~/compose $ git checkout -f 1.25.0
pi@raspberrypi:~/compose $ sudo docker build -t dockercompose:1.25.0 .
pi@raspberrypi:~ $ sudo curl -L --fail https://github.com/docker/compose/releases/download/1.25.0/run.sh -o /usr/local/bin/docker-compose
pi@raspberrypi:~ $ sudo chmod +x /usr/local/bin/docker-compose
pi@raspberrypi:~ $ sudo sed -i 's/docker\/compose:$VERSION""/dockercompose:$VERSION""/g' /usr/local/bin/docker-compose
pi@raspberrypi:~ $ sudo docker-compose version
docker-compose version 1.25.0, build unknown
docker-py version: 4.1.0
CPython version: 3.7.4
OpenSSL version: OpenSSL 1.1.1d  10 Sep 2019
```

I have the following images after `docker build`.
```
pi@raspberrypi:~ $ sudo docker images
REPOSITORY          TAG                     IMAGE ID            CREATED              SIZE
dockercompose       1.25.0                  9272a0512c9e        16 seconds ago       56.6MB
<none>              <none>                  d4b17be57ec2        About a minute ago   470MB
<none>              <none>                  a164b2c19a32        31 minutes ago       306MB
python              3.7.4-slim-stretch      c8a29540aa80        2 months ago         112MB
python              3.7.4-alpine3.10        6fcdf3f2e43b        2 months ago         76.6MB
debian              stretch-20190812-slim   9e643d1c5544        4 months ago         41.5MB
docker              18.09.7                 1661b80f3a8a        5 months ago         140MB
alpine              3.10.1                  962e8b19ad7b        5 months ago         3.74MB
```

The executable docker-compose binary file is inside `dockercompose:1.25.0`. `alpine:3.10.1` is the base image of `dockercompose:1.25.0`. The other images are useless anymore. You can delete them.

And don't try to copy it to Raspberry Pi and use it directly. Because it depends on other shared library inside `dockercompose:1.25.0`. 

It takes 40mins to build it on my Raspberry Pi 3. I had uploaded it to my docker-hub. If anyone want to use it on Raspberry Pi 3(arm/v7),  please refer [here](https://github.com/AppTower/docker-compose). 
--
",JonahGroendal,"
--
`sudo apt install docker-compose` works but it installs an older version (currently 1.25.0)
--
",Ghada,"
--
@Ivan61 
> sudo docker-compose version

Unable to find image 'dockercompose:1.25.0' locally
docker: Error response from daemon: pull access denied for dockercompose, repository does not exist or may require 'docker login': denied: requested access to the resource is denied.

--
"
6829,OPEN,An iterator available in docker-compose?,kind/feature,2020-04-09 18:24:20 +0000 UTC,chrislombardo,In progress,,"I am using docker-compose 3.4 healthcheck to test network connectivity between two network segments. I have iperf running in server mode within containers on one host and iperf in client mode within containers on a different host. Here is sample docker-compose healthcheck configuration on the client side:
```
healthcheck:
    test: iperf3 -V --logfile iperf3_client_log -c 172.29.128.8 -p 5200
    interval: 60s
    timeout: 40s
    start_period: 5s
    retries: 1
```
Each client container starts and connects to a different iperf server port (i.e. 5200-5209). This is easy enough if I create each container as a separate service within my compose file and hard code the port, however, that isnt very scalable. Id like to be able to pass healthcheck something like:
```
iterator: 5200-5209
test: iperf3 -V --logfile iperf3_client_log -c 172.29.128.8 -p $iterator
```
and have docker-compose iterate through the port numbers exactly like it does if I specify a port range using the ports configuration option when issuing --scale with my up command.  Please understand that the ""ports"" config option will NOT work for this usecase as I am not mapping external port numbers to a container ... simply choosing the port which iperf will use during it's run.

Same question posted by me in forums.docker: https://forums.docker.com/t/an-iterator-available-in-docker-compose-3-4/79049
Another example of user desire for an iterator:
https://forums.docker.com/t/pass-incremental-variable-to-cmd-for-each-scaled-service-in-docker-compose/16371
I am aware that a similar [request](https://github.com/docker/compose/issues/5189) was turned down in reference to container_name, but I believe I've proven the need for an iterator/incrementor outside of naming a container.",,,jeremyhamm,"
--
@chrislombardo Did you ever find a solution for this?  I need the same functionality.
--

--
@chrislombardo No worries thanks for the response.  I think I will need an out of the box solution to my issue as well
--
",chrislombardo,"
--
@jeremyhamm Sorry, I did not.  I ended up going a different route where the iterator wasn't necessary.
--
",,,,,,,,
6822,OPEN,Network priority ignored for external networks,kind/bug,2021-01-22 01:09:14 +0000 UTC,pytz,In progress,,"Not sure if this is intended behaviour or a bug.

I have a docker-compose file for an OpenVPN container which uses two external networks:

```
networks:
  astnet:
    external: true
    name: astnet
  ovpnnet:
    external: true
    name: ovpnnet
services:
  openvpn:
    ... left out intentionally ...
    networks:
      astnet:
        ipv4_address: 192.168.250.250
      ovpnnet:
        ipv4_address: 192.168.252.2
    ports:
    - 192.168.253.2:1194:1194/udp
    - 192.168.253.2:1195:1194/udp
version: '2.4'
```

The started container uses astnet for the default route:
```
bash-4.3# ip route
default via 192.168.250.1 dev eth0 
10.0.2.0/24 dev tun0 proto kernel scope link src 10.0.2.1 
192.168.3.0/24 via 10.0.2.2 dev tun0 
192.168.250.0/24 dev eth0 proto kernel scope link src 192.168.250.250 
192.168.252.0/24 dev eth1 proto kernel scope link src 192.168.252.2
```

and also in the matching iptables rule:
```
Chain DOCKER (24 references)
target     prot opt source               destination      
ACCEPT     udp  --  anywhere             192.168.250.250      udp dpt:openvpn
```

Now I would like to configure docker to use the ovpnet as default network.
According to https://docs.docker.com/compose/compose-file/compose-file-v2/#priority and Issue #4645 it should be possible by setting a priority like this:

```
      astnet:
        ipv4_address: '192.168.250.250'
        priority: 200
      ovpnnet:
        ipv4_address: '192.168.252.2'
        priority: 300
```
But this doesn't change anything. astnet is still eth0 and has the default route.
I also tried switching the priorities and changing the order of the networks but no success.

## Version informations

docker version:
```
Client: Docker Engine - Community
 Version:           19.03.1
 API version:       1.40
 Go version:        go1.12.5
 Git commit:        74b1e89
 Built:             Thu Jul 25 21:21:05 2019
 OS/Arch:           linux/amd64
 Experimental:      false

Server: Docker Engine - Community
 Engine:
  Version:          19.03.1
  API version:      1.40 (minimum version 1.12)
  Go version:       go1.12.5
  Git commit:       74b1e89
  Built:            Thu Jul 25 21:19:41 2019
  OS/Arch:          linux/amd64
  Experimental:     false
 containerd:
  Version:          1.2.6
  GitCommit:        894b81a4b802e4eb2a91d1ce216b8817763c29fb
 runc:
  Version:          1.0.0-rc8
  GitCommit:        425e105d5a03fabd737a126ad93d62a9eeede87f
 docker-init:
  Version:          0.18.0
  GitCommit:        fec3683
```

docker-compose version:
```
docker-compose version 1.24.1, build 4667896b
docker-py version: 3.7.3
CPython version: 3.6.8
OpenSSL version: OpenSSL 1.1.0j  20 Nov 2018
```",,,pytz,"
--
Here a minimal working example.

First create both networks:
```
docker network create -d bridge --subnet=192.168.101.0/24 a_net
docker network create -d bridge --subnet=192.168.102.0/24 b_net
```
Start the following using `docker-compose up -d`:
```
networks:
  a_net:
    external: true
    name: a_net
  b_net:
    external: true
    name: b_net
services:
  my_service:
    image: alpine:3.7
    container_name: my_service
    networks:
      a_net:
        ipv4_address: 192.168.101.2
        priority: 100
      b_net:
        ipv4_address: 192.168.102.2
        priority: 200
    command: sleep 3600
    ports:
    - 127.0.0.1:1194:1194/udp
    - 127.0.0.1:1195:1194/udp
version: '2.4'
```

Check the output of `docker exec -it my_service ip route`:
```
default via 192.168.101.1 dev eth0 
192.168.101.0/24 dev eth0 scope link  src 192.168.101.2 
192.168.102.0/24 dev eth1 scope link  src 192.168.102.2
```
--

--
I'm not sure if it is a bug.
You are right as the docker-compose reference (https://docs.docker.com/compose/compose-file/compose-file-v2/#priority) just says it indicates the order in which networks should be connected.
But I still don't understand which interface becomes the ""default"" route. My guess would be the first interface (= eth0). So changing the order in which the interfaces get connected to the docker container should influence the eth0, eth1, ... assignment.

But going back to the minimal working example above the priority doesn't seem to matter (note the different priority):

```
networks:
  a_net:
    external: true
    name: a_net
  b_net:
    external: true
    name: b_net
services:
  my_service:
    image: alpine:3.7
    container_name: my_service
    networks:
      a_net:
        ipv4_address: 192.168.101.2
        priority: 100
      b_net:
        ipv4_address: 192.168.102.2
        priority: 200
    command: sleep 3600
    ports:
    - 127.0.0.1:1194:1194/udp
    - 127.0.0.1:1195:1194/udp
version: '2.4'
```
```
# docker exec -it my_service ip route
default via 192.168.101.1 dev eth0 
192.168.101.0/24 dev eth0 scope link  src 192.168.101.2 
192.168.102.0/24 dev eth1 scope link  src 192.168.102.2
```
Changing the priority has no result:
```
networks:
  a_net:
    external: true
    name: a_net
  b_net:
    external: true
    name: b_net
services:
  my_service:
    image: alpine:3.7
    container_name: my_service
    networks:
      a_net:
        ipv4_address: 192.168.101.2
        priority: 200
      b_net:
        ipv4_address: 192.168.102.2
        priority: 100
    command: sleep 3600
    ports:
    - 127.0.0.1:1194:1194/udp
    - 127.0.0.1:1195:1194/udp
version: '2.4'
```
```
# docker exec -it my_service ip route
default via 192.168.101.1 dev eth0 
192.168.101.0/24 dev eth0 scope link  src 192.168.101.2 
192.168.102.0/24 dev eth1 scope link  src 192.168.102.2
```
--
",jcsirot,"
--
Hello @pytz thank you for filling this issue
--
",pcellix,"
--
Hello
I would like to work on this issue
I'm new so I would new info how can I be assigned
--

--
Is it really a bug as it does state regarding routing metric but the priority of connecting 
--
",karthanistyr,"
--
Has this bug been acknowledged? I repeatedly get the wrong interface (network) assigned to the default route in my containers.
--

--
This is still not addressed (or even acknowledged)
@shin- any input?
--
",stale,"
--
This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you for your contributions.

--

--
This issue has been automatically marked as not stale anymore due to the recent activity.

--
",jfellus,"
--
It seems to be the case for interal networks as well, see https://gist.github.com/jfellus/cfee9efc1e8e1baf9d15314f16a46eca to reproduce.
Lexical order of network names seems to always superseed any priorities you set.
To be precise, this has an impact on the order in which your container gets connected to networks, but it is then ignored by docker that keep on allocating ethX based on lexical order of network names
--
"
6817,OPEN,docker-compose overshoots requested scale,kind/bug,2019-07-25 09:40:11 +0000 UTC,remram44,Opened,,"# Description of the issue

If some containers are stopped, docker-compose will create too many.

## Context information (for bug reports)

This happens on my test server (Ubuntu 18.04, docker and docker-compose from apt):

**Output of `docker-compose version`**
```
docker-compose version 1.17.1, build unknown
docker-py version: 2.5.1
CPython version: 2.7.15+
OpenSSL version: OpenSSL 1.1.1  11 Sep 2018
```

**Output of `docker version`**
```
Server: Docker Engine - Community
 Engine:
  Version:          18.09.7
  API version:      1.39 (minimum version 1.12)
  Go version:       go1.10.8
  Git commit:       2d0083d
  Built:            Thu Jun 27 17:23:02 2019
  OS/Arch:          linux/amd64
  Experimental:     false
```

And I reproduced it locally running docker:dind and docker-compose from pip (Ubuntu 18.04):

**Output of `docker-compose version`**
```
docker-compose version 1.24.1, build 4667896
docker-py version: 3.7.3
CPython version: 3.6.9
OpenSSL version: OpenSSL 1.1.0j  20 Nov 2018
```

**Output of `docker version`**
```
Server:
 Version:      19.03.0
 API version:  1.40 (minimum version 1.12)
 Go version:   go1.12.5
 Git commit:   aeac9490dc
 Built:        Wed Jul 17 18:22:15 2019
 OS/Arch:      linux/amd64
 Experimental: false
```

## Steps to reproduce the issue

```
$ cat >docker-compose.yml
version: '3.2'
services:
  query:
    image: busybox
    command: [""sh"", ""-c"", ""sleep 3600""]
^D
$ docker-compose up -d --scale=query=4 query
Creating default_query_1 ... done
Creating default_query_2 ... done
Creating default_query_3 ... done
Creating default_query_4 ... done
$ docker stop default_query_2
default_query_2
$ docker-compose up -d --scale=query=4 query
Starting default_query_2 ... done
Creating default_query_5 ... done
Creating default_query_6 ... done
Creating default_query_7 ... done
$ docker-compose up -d --scale=query=4 query
Stopping and removing default_query_5 ... done
Stopping and removing default_query_6 ... done
Stopping and removing default_query_7 ... done
Starting default_query_1              ... done
Starting default_query_2              ... done
Starting default_query_3              ... done
Starting default_query_4              ... done
```

As you can see it gets it right the second time.

### Observed result

7 containers were running

### Expected result

4 containers run when I request 4",,,ulyssessouza,"
--
Thanks for the report @remram44 !
--
",,,,,,,,,,
6782,OPEN,docker-compose up -d with a volume causes compose.parallel.feed_queue: Pending: set() endless loop,stale,2021-02-21 22:55:08 +0000 UTC,jnewton03,Opened,,"3. When making a bug report, make sure you provide all required information. The easier it is for
   maintainers to reproduce, the faster it'll be fixed.
-->

## Description of the issue
on first boot of system, docker-compose up -d with a volume causes compose.parallel.feed_queue: Pending: set() endless loop.

Subsequent starts work fine.  Also removing the volume will make it work the first time.

## Context information (for bug reports)

**Output of `docker-compose version`**
```
docker-compose version 1.24.0, build 0aa59064
docker-py version: 3.7.2
CPython version: 3.6.8
OpenSSL version: OpenSSL 1.1.0j  20 Nov 2018
```

**Output of `docker version`**
```
docker-compose version 1.24.0, build 0aa59064
docker-py version: 3.7.2
CPython version: 3.6.8
OpenSSL version: OpenSSL 1.1.0j  20 Nov 2018
[centos@ip-172-30-0-179 test-dockerdb-configs]$ docker version
Client:
 Version:           18.09.7
 API version:       1.39
 Go version:        go1.10.8
 Git commit:        2d0083d
 Built:             Thu Jun 27 17:56:06 2019
 OS/Arch:           linux/amd64
 Experimental:      false

Server: Docker Engine - Community
 Engine:
  Version:          18.09.7
  API version:      1.39 (minimum version 1.12)
  Go version:       go1.10.8
  Git commit:       2d0083d
  Built:            Thu Jun 27 17:26:28 2019
  OS/Arch:          linux/amd64
  Experimental:     false
```

**Output of `docker-compose config`**
(Make sure to add the relevant `-f` and other flags)
```
services:
  lbcli-oracle-primary:
    container_name: oracle12c-db1
    image: docker-dev.artifactory.datical.net/datical/oracle-ee:12.2.0.1-ci
    ports:
    - 1521:1521/tcp
    restart: always
    volumes:
    - opt/oracle/product/12.2.0.1
  lbcli-oracle-secondary:
    container_name: oracle12c-db2
    image: docker-dev.artifactory.datical.net/datical/oracle-ee:12.2.0.1-ci
    ports:
    - 1522:1521/tcp
    restart: always
version: '2.1'
```


## Steps to reproduce the issue

1.  Load Centos 7 server with docker-ce and docker-compose latest versions
2. reboot system
3. run above docker-compose --verbose up -d 
4. either remove the volume or just try to re-run the docker-compose up.  It will succeed.

### Observed result
Gets stuck in a compose.parallel.feed_queue: Pending: set() endless loop on the first try.
Removing the volume or just trying a 2nd time resolves the issue.

### Expected result
This should start on the first try.

### Stacktrace / full error message

*FIRST ATTEMPT*

```
compose.config.config.find: Using configuration files: ./docker-compose.yml
docker.utils.config.find_config_file: Trying paths: ['/home/centos/.docker/config.json', '/home/centos/.dockercfg']
docker.utils.config.find_config_file: Found file at path: /home/centos/.docker/config.json
docker.auth.load_config: Found 'auths' section
docker.auth.parse_auth: Found entry (registry='docker-dev.artifactory.datical.net', username='jnewton')
docker.auth.parse_auth: Found entry (registry='docker.artifactory.datical.net', username='jnewton')
urllib3.connectionpool._make_request: http://localhost:None ""GET /v1.24/version HTTP/1.1"" 200 580
compose.cli.command.get_client: docker-compose version 1.24.0, build 0aa59064
docker-py version: 3.7.2
CPython version: 3.6.8
OpenSSL version: OpenSSL 1.1.0j  20 Nov 2018
compose.cli.command.get_client: Docker base_url: http+docker://localhost
compose.cli.command.get_client: Docker version: Platform={'Name': 'Docker Engine - Community'}, Components=[{'Name': 'Engine', 'Version': '18.09.7', 'Details': {'ApiVersion': '1.39', 'Arch': 'amd64', 'BuildTime': '2019-06-27T17:26:28.000000000+00:00', 'Experimental': 'false', 'GitCommit': '2d0083d', 'GoVersion': 'go1.10.8', 'KernelVersion': '3.10.0-957.21.3.el7.x86_64', 'MinAPIVersion': '1.12', 'Os': 'linux'}}], Version=18.09.7, ApiVersion=1.39, MinAPIVersion=1.12, GitCommit=2d0083d, GoVersion=go1.10.8, Os=linux, Arch=amd64, KernelVersion=3.10.0-957.21.3.el7.x86_64, BuildTime=2019-06-27T17:26:28.000000000+00:00
compose.cli.verbose_proxy.proxy_callable: docker inspect_network <- ('testdockerdbconfigs_default')
urllib3.connectionpool._make_request: http://localhost:None ""GET /v1.24/networks/testdockerdbconfigs_default HTTP/1.1"" 404 60
compose.cli.verbose_proxy.proxy_callable: docker info <- ()
urllib3.connectionpool._make_request: http://localhost:None ""GET /v1.24/info HTTP/1.1"" 200 None
compose.cli.verbose_proxy.proxy_callable: docker info -> {'Architecture': 'x86_64',
 'BridgeNfIp6tables': True,
 'BridgeNfIptables': True,
 'CPUSet': True,
 'CPUShares': True,
 'CgroupDriver': 'cgroupfs',
 'ClusterAdvertise': '',
 'ClusterStore': '',
 'ContainerdCommit': {'Expected': '894b81a4b802e4eb2a91d1ce216b8817763c29fb',
                      'ID': '894b81a4b802e4eb2a91d1ce216b8817763c29fb'},
...
compose.cli.verbose_proxy.proxy_callable: docker inspect_network <- ('test-dockerdb-configs_default')
urllib3.connectionpool._make_request: http://localhost:None ""GET /v1.24/networks/test-dockerdb-configs_default HTTP/1.1"" 404 62
compose.network.ensure: Creating network ""test-dockerdb-configs_default"" with the default driver
compose.cli.verbose_proxy.proxy_callable: docker create_network <- (name='test-dockerdb-configs_default', driver=None, options=None, ipam=None, internal=False, enable_ipv6=False, labels={'com.docker.compose.project': 'test-dockerdb-configs', 'com.docker.compose.network': 'default', 'com.docker.compose.version': '1.24.0'}, attachable=True, check_duplicate=True)
urllib3.connectionpool._make_request: http://localhost:None ""POST /v1.24/networks/create HTTP/1.1"" 201 87
compose.cli.verbose_proxy.proxy_callable: docker create_network -> {'Id': 'cf4a3b7b44ea940eb6464ff2c012b383a480c9d8271fb9c25da7834a648b15f4',
 'Warning': ''}
compose.cli.verbose_proxy.proxy_callable: docker containers <- (all=False, filters={'label': ['com.docker.compose.project=test-dockerdb-configs', 'com.docker.compose.oneoff=False']})
urllib3.connectionpool._make_request: http://localhost:None ""GET /v1.24/containers/json?limit=-1&all=0&size=0&trunc_cmd=0&filters=%7B%22label%22%3A+%5B%22com.docker.compose.project%3Dtest-dockerdb-configs%22%2C+%22com.docker.compose.oneoff%3DFalse%22%5D%7D HTTP/1.1"" 200 3
compose.cli.verbose_proxy.proxy_callable: docker containers -> (list with 0 items)
compose.cli.verbose_proxy.proxy_callable: docker containers <- (all=False, filters={'label': ['com.docker.compose.project=testdockerdbconfigs', 'com.docker.compose.oneoff=False']})
urllib3.connectionpool._make_request: http://localhost:None ""GET /v1.24/containers/json?limit=-1&all=0&size=0&trunc_cmd=0&filters=%7B%22label%22%3A+%5B%22com.docker.compose.project%3Dtestdockerdbconfigs%22%2C+%22com.docker.compose.oneoff%3DFalse%22%5D%7D HTTP/1.1"" 200 3
compose.cli.verbose_proxy.proxy_callable: docker containers -> (list with 0 items)
compose.cli.verbose_proxy.proxy_callable: docker containers <- (all=True, filters={'label': ['com.docker.compose.project=test-dockerdb-configs', 'com.docker.compose.service=lbcli-oracle-primary', 'com.docker.compose.oneoff=False']})
urllib3.connectionpool._make_request: http://localhost:None ""GET /v1.24/containers/json?limit=-1&all=1&size=0&trunc_cmd=0&filters=%7B%22label%22%3A+%5B%22com.docker.compose.project%3Dtest-dockerdb-configs%22%2C+%22com.docker.compose.service%3Dlbcli-oracle-primary%22%2C+%22com.docker.compose.oneoff%3DFalse%22%5D%7D HTTP/1.1"" 200 3
compose.cli.verbose_proxy.proxy_callable: docker containers -> (list with 0 items)
compose.cli.verbose_proxy.proxy_callable: docker containers <- (all=True, filters={'label': ['com.docker.compose.project=testdockerdbconfigs', 'com.docker.compose.service=lbcli-oracle-primary', 'com.docker.compose.oneoff=False']})
urllib3.connectionpool._make_request: http://localhost:None ""GET /v1.24/containers/json?limit=-1&all=1&size=0&trunc_cmd=0&filters=%7B%22label%22%3A+%5B%22com.docker.compose.project%3Dtestdockerdbconfigs%22%2C+%22com.docker.compose.service%3Dlbcli-oracle-primary%22%2C+%22com.docker.compose.oneoff%3DFalse%22%5D%7D HTTP/1.1"" 200 3
compose.cli.verbose_proxy.proxy_callable: docker containers -> (list with 0 items)
compose.cli.verbose_proxy.proxy_callable: docker containers <- (all=True, filters={'label': ['com.docker.compose.project=test-dockerdb-configs', 'com.docker.compose.service=lbcli-oracle-secondary', 'com.docker.compose.oneoff=False']})
urllib3.connectionpool._make_request: http://localhost:None ""GET /v1.24/containers/json?limit=-1&all=1&size=0&trunc_cmd=0&filters=%7B%22label%22%3A+%5B%22com.docker.compose.project%3Dtest-dockerdb-configs%22%2C+%22com.docker.compose.service%3Dlbcli-oracle-secondary%22%2C+%22com.docker.compose.oneoff%3DFalse%22%5D%7D HTTP/1.1"" 200 3
compose.cli.verbose_proxy.proxy_callable: docker containers -> (list with 0 items)
compose.cli.verbose_proxy.proxy_callable: docker containers <- (all=True, filters={'label': ['com.docker.compose.project=testdockerdbconfigs', 'com.docker.compose.service=lbcli-oracle-secondary', 'com.docker.compose.oneoff=False']})
urllib3.connectionpool._make_request: http://localhost:None ""GET /v1.24/containers/json?limit=-1&all=1&size=0&trunc_cmd=0&filters=%7B%22label%22%3A+%5B%22com.docker.compose.project%3Dtestdockerdbconfigs%22%2C+%22com.docker.compose.service%3Dlbcli-oracle-secondary%22%2C+%22com.docker.compose.oneoff%3DFalse%22%5D%7D HTTP/1.1"" 200 3
compose.cli.verbose_proxy.proxy_callable: docker containers -> (list with 0 items)
compose.cli.verbose_proxy.proxy_callable: docker inspect_image <- ('docker-dev.artifactory.datical.net/datical/oracle-ee:12.2.0.1-ci')
urllib3.connectionpool._make_request: http://localhost:None ""GET /v1.24/images/docker-dev.artifactory.datical.net/datical/oracle-ee:12.2.0.1-ci/json HTTP/1.1"" 200 None
compose.cli.verbose_proxy.proxy_callable: docker inspect_image -> {'Architecture': 'amd64',
 'Author': '',
 'Comment': '',
 'Config': {'ArgsEscaped': True,
            'AttachStderr': False,
            'AttachStdin': False,
            'AttachStdout': False,
            'Cmd': ['/bin/sh', '-c', 'exec $ORACLE_BASE/$RUN_FILE'],
            'Domainname': '',
            'Entrypoint': None,
...
compose.cli.verbose_proxy.proxy_callable: docker inspect_image <- ('docker-dev.artifactory.datical.net/datical/oracle-ee:12.2.0.1-ci')
urllib3.connectionpool._make_request: http://localhost:None ""GET /v1.24/images/docker-dev.artifactory.datical.net/datical/oracle-ee:12.2.0.1-ci/json HTTP/1.1"" 200 None
compose.cli.verbose_proxy.proxy_callable: docker inspect_image -> {'Architecture': 'amd64',
 'Author': '',
 'Comment': '',
 'Config': {'ArgsEscaped': True,
            'AttachStderr': False,
            'AttachStdin': False,
            'AttachStdout': False,
            'Cmd': ['/bin/sh', '-c', 'exec $ORACLE_BASE/$RUN_FILE'],
            'Domainname': '',
            'Entrypoint': None,
...
compose.cli.verbose_proxy.proxy_callable: docker containers <- (all=True, filters={'label': ['com.docker.compose.project=test-dockerdb-configs', 'com.docker.compose.service=lbcli-oracle-primary', 'com.docker.compose.oneoff=False']})
urllib3.connectionpool._make_request: http://localhost:None ""GET /v1.24/containers/json?limit=-1&all=1&size=0&trunc_cmd=0&filters=%7B%22label%22%3A+%5B%22com.docker.compose.project%3Dtest-dockerdb-configs%22%2C+%22com.docker.compose.service%3Dlbcli-oracle-primary%22%2C+%22com.docker.compose.oneoff%3DFalse%22%5D%7D HTTP/1.1"" 200 3
compose.cli.verbose_proxy.proxy_callable: docker containers -> (list with 0 items)
compose.cli.verbose_proxy.proxy_callable: docker containers <- (all=True, filters={'label': ['com.docker.compose.project=testdockerdbconfigs', 'com.docker.compose.service=lbcli-oracle-primary', 'com.docker.compose.oneoff=False']})
urllib3.connectionpool._make_request: http://localhost:None ""GET /v1.24/containers/json?limit=-1&all=1&size=0&trunc_cmd=0&filters=%7B%22label%22%3A+%5B%22com.docker.compose.project%3Dtestdockerdbconfigs%22%2C+%22com.docker.compose.service%3Dlbcli-oracle-primary%22%2C+%22com.docker.compose.oneoff%3DFalse%22%5D%7D HTTP/1.1"" 200 3
compose.cli.verbose_proxy.proxy_callable: docker containers -> (list with 0 items)
compose.cli.verbose_proxy.proxy_callable: docker containers <- (all=True, filters={'label': ['com.docker.compose.project=test-dockerdb-configs', 'com.docker.compose.service=lbcli-oracle-secondary', 'com.docker.compose.oneoff=False']})
urllib3.connectionpool._make_request: http://localhost:None ""GET /v1.24/containers/json?limit=-1&all=1&size=0&trunc_cmd=0&filters=%7B%22label%22%3A+%5B%22com.docker.compose.project%3Dtest-dockerdb-configs%22%2C+%22com.docker.compose.service%3Dlbcli-oracle-secondary%22%2C+%22com.docker.compose.oneoff%3DFalse%22%5D%7D HTTP/1.1"" 200 3
compose.cli.verbose_proxy.proxy_callable: docker containers -> (list with 0 items)
compose.cli.verbose_proxy.proxy_callable: docker containers <- (all=True, filters={'label': ['com.docker.compose.project=testdockerdbconfigs', 'com.docker.compose.service=lbcli-oracle-secondary', 'com.docker.compose.oneoff=False']})
urllib3.connectionpool._make_request: http://localhost:None ""GET /v1.24/containers/json?limit=-1&all=1&size=0&trunc_cmd=0&filters=%7B%22label%22%3A+%5B%22com.docker.compose.project%3Dtestdockerdbconfigs%22%2C+%22com.docker.compose.service%3Dlbcli-oracle-secondary%22%2C+%22com.docker.compose.oneoff%3DFalse%22%5D%7D HTTP/1.1"" 200 3
compose.cli.verbose_proxy.proxy_callable: docker containers -> (list with 0 items)
compose.parallel.feed_queue: Pending: {<Service: lbcli-oracle-secondary>, <Service: lbcli-oracle-primary>}
compose.parallel.feed_queue: Starting producer thread for <Service: lbcli-oracle-secondary>
compose.cli.verbose_proxy.proxy_callable: docker containers <- (all=True, filters={'label': ['com.docker.compose.project=test-dockerdb-configs', 'com.docker.compose.service=lbcli-oracle-secondary', 'com.docker.compose.oneoff=False']})
compose.parallel.feed_queue: Starting producer thread for <Service: lbcli-oracle-primary>
compose.cli.verbose_proxy.proxy_callable: docker containers <- (all=True, filters={'label': ['com.docker.compose.project=test-dockerdb-configs', 'com.docker.compose.service=lbcli-oracle-primary', 'com.docker.compose.oneoff=False']})
urllib3.connectionpool._make_request: http://localhost:None ""GET /v1.24/containers/json?limit=-1&all=1&size=0&trunc_cmd=0&filters=%7B%22label%22%3A+%5B%22com.docker.compose.project%3Dtest-dockerdb-configs%22%2C+%22com.docker.compose.service%3Dlbcli-oracle-secondary%22%2C+%22com.docker.compose.oneoff%3DFalse%22%5D%7D HTTP/1.1"" 200 3
urllib3.connectionpool._make_request: http://localhost:None ""GET /v1.24/containers/json?limit=-1&all=1&size=0&trunc_cmd=0&filters=%7B%22label%22%3A+%5B%22com.docker.compose.project%3Dtest-dockerdb-configs%22%2C+%22com.docker.compose.service%3Dlbcli-oracle-primary%22%2C+%22com.docker.compose.oneoff%3DFalse%22%5D%7D HTTP/1.1"" 200 3
compose.cli.verbose_proxy.proxy_callable: docker containers -> (list with 0 items)
compose.cli.verbose_proxy.proxy_callable: docker containers -> (list with 0 items)
compose.cli.verbose_proxy.proxy_callable: docker containers <- (all=True, filters={'label': ['com.docker.compose.project=testdockerdbconfigs', 'com.docker.compose.service=lbcli-oracle-secondary', 'com.docker.compose.oneoff=False']})
compose.cli.verbose_proxy.proxy_callable: docker containers <- (all=True, filters={'label': ['com.docker.compose.project=testdockerdbconfigs', 'com.docker.compose.service=lbcli-oracle-primary', 'com.docker.compose.oneoff=False']})
urllib3.connectionpool._make_request: http://localhost:None ""GET /v1.24/containers/json?limit=-1&all=1&size=0&trunc_cmd=0&filters=%7B%22label%22%3A+%5B%22com.docker.compose.project%3Dtestdockerdbconfigs%22%2C+%22com.docker.compose.service%3Dlbcli-oracle-secondary%22%2C+%22com.docker.compose.oneoff%3DFalse%22%5D%7D HTTP/1.1"" 200 3
urllib3.connectionpool._make_request: http://localhost:None ""GET /v1.24/containers/json?limit=-1&all=1&size=0&trunc_cmd=0&filters=%7B%22label%22%3A+%5B%22com.docker.compose.project%3Dtestdockerdbconfigs%22%2C+%22com.docker.compose.service%3Dlbcli-oracle-primary%22%2C+%22com.docker.compose.oneoff%3DFalse%22%5D%7D HTTP/1.1"" 200 3
compose.cli.verbose_proxy.proxy_callable: docker containers -> (list with 0 items)
Creating oracle12c-db2 ...
compose.cli.verbose_proxy.proxy_callable: docker containers -> (list with 0 items)
Creating oracle12c-db1 ...
compose.parallel.feed_queue: Pending: {ServiceName(project='test-dockerdb-configs', service='lbcli-oracle-secondary', number=1)}
compose.parallel.feed_queue: Pending: {ServiceName(project='test-dockerdb-configs', service='lbcli-oracle-primary', number=1)}
compose.parallel.feed_queue: Starting producer thread for ServiceName(project='test-dockerdb-configs', service='lbcli-oracle-secondary', number=1)
compose.parallel.feed_queue: Starting producer thread for ServiceName(project='test-dockerdb-configs', service='lbcli-oracle-primary', number=1)
compose.cli.verbose_proxy.proxy_callable: docker inspect_image <- ('docker-dev.artifactory.datical.net/datical/oracle-ee:12.2.0.1-ci')
compose.cli.verbose_proxy.proxy_callable: docker inspect_image <- ('docker-dev.artifactory.datical.net/datical/oracle-ee:12.2.0.1-ci')
urllib3.connectionpool._make_request: http://localhost:None ""GET /v1.24/images/docker-dev.artifactory.datical.net/datical/oracle-ee:12.2.0.1-ci/json HTTP/1.1"" 200 None
compose.cli.verbose_proxy.proxy_callable: docker inspect_image -> {'Architecture': 'amd64',
 'Author': '',
 'Comment': '',
 'Config': {'ArgsEscaped': True,
            'AttachStderr': False,
            'AttachStdin': False,
            'AttachStdout': False,
            'Cmd': ['/bin/sh', '-c', 'exec $ORACLE_BASE/$RUN_FILE'],
            'Domainname': '',
            'Entrypoint': None,
...
compose.cli.verbose_proxy.proxy_callable: docker inspect_image <- ('docker-dev.artifactory.datical.net/datical/oracle-ee:12.2.0.1-ci')
urllib3.connectionpool._make_request: http://localhost:None ""GET /v1.24/images/docker-dev.artifactory.datical.net/datical/oracle-ee:12.2.0.1-ci/json HTTP/1.1"" 200 None
compose.cli.verbose_proxy.proxy_callable: docker inspect_image -> {'Architecture': 'amd64',
 'Author': '',
 'Comment': '',
 'Config': {'ArgsEscaped': True,
            'AttachStderr': False,
            'AttachStdin': False,
            'AttachStdout': False,
            'Cmd': ['/bin/sh', '-c', 'exec $ORACLE_BASE/$RUN_FILE'],
            'Domainname': '',
            'Entrypoint': None,
...
compose.cli.verbose_proxy.proxy_callable: docker inspect_image <- ('docker-dev.artifactory.datical.net/datical/oracle-ee:12.2.0.1-ci')
urllib3.connectionpool._make_request: http://localhost:None ""GET /v1.24/images/docker-dev.artifactory.datical.net/datical/oracle-ee:12.2.0.1-ci/json HTTP/1.1"" 200 None
compose.cli.verbose_proxy.proxy_callable: docker inspect_image -> {'Architecture': 'amd64',
 'Author': '',
 'Comment': '',
 'Config': {'ArgsEscaped': True,
            'AttachStderr': False,
            'AttachStdin': False,
            'AttachStdout': False,
            'Cmd': ['/bin/sh', '-c', 'exec $ORACLE_BASE/$RUN_FILE'],
            'Domainname': '',
            'Entrypoint': None,
...
compose.service.build_container_labels: Added config hash: b64576715c9f4d2f41e6e41cc3287f4331fcc48eb3c2bb063b603b993e195e1e
compose.cli.verbose_proxy.proxy_callable: docker create_host_config <- (links=[], port_bindings={'1521/tcp': ['1521']}, binds=[], volumes_from=[], privileged=False, network_mode='test-dockerdb-configs_default', devices=None, dns=None, dns_opt=None, dns_search=None, restart_policy={'Name': 'always', 'MaximumRetryCount': 0}, runtime=None, cap_add=None, cap_drop=None, mem_limit=None, mem_reservation=None, memswap_limit=None, ulimits=None, log_config={'Type': '', 'Config': {}}, extra_hosts=None, read_only=None, pid_mode=None, security_opt=None, ipc_mode=None, cgroup_parent=None, cpu_quota=None, shm_size=None, sysctls=None, pids_limit=None, tmpfs=[], oom_kill_disable=None, oom_score_adj=None, mem_swappiness=None, group_add=None, userns_mode=None, init=None, init_path=None, isolation=None, cpu_count=None, cpu_percent=None, nano_cpus=None, volume_driver=None, cpuset_cpus=None, cpu_shares=None, storage_opt=None, blkio_weight=None, blkio_weight_device=None, device_read_bps=None, device_read_iops=None, device_write_bps=None, device_write_iops=None, mounts=None, device_cgroup_rules=None, cpu_period=None, cpu_rt_period=None, cpu_rt_runtime=None)
compose.cli.verbose_proxy.proxy_callable: docker create_host_config -> {'Binds': [],
 'Links': [],
 'LogConfig': {'Config': {}, 'Type': ''},
 'NetworkMode': 'test-dockerdb-configs_default',
 'PortBindings': {'1521/tcp': [{'HostIp': '', 'HostPort': '1521'}]},
 'RestartPolicy': {'MaximumRetryCount': 0, 'Name': 'always'},
 'VolumesFrom': []}
compose.cli.verbose_proxy.proxy_callable: docker create_container <- (image='docker-dev.artifactory.datical.net/datical/oracle-ee:12.2.0.1-ci', ports=[('1521', 'tcp')], volumes={'opt/oracle/product/12.2.0.1': {}}, name='oracle12c-db1', detach=True, environment=[], labels={'com.docker.compose.project': 'test-dockerdb-configs', 'com.docker.compose.service': 'lbcli-oracle-primary', 'com.docker.compose.oneoff': 'False', 'com.docker.compose.container-number': '1', 'com.docker.compose.version': '1.24.0', 'com.docker.compose.config-hash': 'b64576715c9f4d2f41e6e41cc3287f4331fcc48eb3c2bb063b603b993e195e1e'}, host_config={'NetworkMode': 'test-dockerdb-configs_default', 'RestartPolicy': {'Name': 'always', 'MaximumRetryCount': 0}, 'VolumesFrom': [], 'Binds': [], 'PortBindings': {'1521/tcp': [{'HostIp': '', 'HostPort': '1521'}]}, 'Links': [], 'LogConfig': {'Type': '', 'Config': {}}}, networking_config={'EndpointsConfig': {'test-dockerdb-configs_default': {'Aliases': ['lbcli-oracle-primary'], 'IPAMConfig': {}}}})
urllib3.connectionpool._make_request: http://localhost:None ""GET /v1.24/images/docker-dev.artifactory.datical.net/datical/oracle-ee:12.2.0.1-ci/json HTTP/1.1"" 200 None
compose.cli.verbose_proxy.proxy_callable: docker inspect_image -> {'Architecture': 'amd64',
 'Author': '',
 'Comment': '',
 'Config': {'ArgsEscaped': True,
            'AttachStderr': False,
            'AttachStdin': False,
            'AttachStdout': False,
            'Cmd': ['/bin/sh', '-c', 'exec $ORACLE_BASE/$RUN_FILE'],
            'Domainname': '',
            'Entrypoint': None,
...
compose.service.build_container_labels: Added config hash: c71f9e9138dc9820bcd2f30bf48cc9e013cb44542aefd79246e420d19dc69a49
compose.cli.verbose_proxy.proxy_callable: docker create_host_config <- (links=[], port_bindings={'1521/tcp': ['1522']}, binds=[], volumes_from=[], privileged=False, network_mode='test-dockerdb-configs_default', devices=None, dns=None, dns_opt=None, dns_search=None, restart_policy={'Name': 'always', 'MaximumRetryCount': 0}, runtime=None, cap_add=None, cap_drop=None, mem_limit=None, mem_reservation=None, memswap_limit=None, ulimits=None, log_config={'Type': '', 'Config': {}}, extra_hosts=None, read_only=None, pid_mode=None, security_opt=None, ipc_mode=None, cgroup_parent=None, cpu_quota=None, shm_size=None, sysctls=None, pids_limit=None, tmpfs=[], oom_kill_disable=None, oom_score_adj=None, mem_swappiness=None, group_add=None, userns_mode=None, init=None, init_path=None, isolation=None, cpu_count=None, cpu_percent=None, nano_cpus=None, volume_driver=None, cpuset_cpus=None, cpu_shares=None, storage_opt=None, blkio_weight=None, blkio_weight_device=None, device_read_bps=None, device_read_iops=None, device_write_bps=None, device_write_iops=None, mounts=None, device_cgroup_rules=None, cpu_period=None, cpu_rt_period=None, cpu_rt_runtime=None)
compose.cli.verbose_proxy.proxy_callable: docker create_host_config -> {'Binds': [],
 'Links': [],
 'LogConfig': {'Config': {}, 'Type': ''},
 'NetworkMode': 'test-dockerdb-configs_default',
 'PortBindings': {'1521/tcp': [{'HostIp': '', 'HostPort': '1522'}]},
 'RestartPolicy': {'MaximumRetryCount': 0, 'Name': 'always'},
 'VolumesFrom': []}
compose.cli.verbose_proxy.proxy_callable: docker create_container <- (image='docker-dev.artifactory.datical.net/datical/oracle-ee:12.2.0.1-ci', ports=[('1521', 'tcp')], volumes={}, name='oracle12c-db2', detach=True, environment=[], labels={'com.docker.compose.project': 'test-dockerdb-configs', 'com.docker.compose.service': 'lbcli-oracle-secondary', 'com.docker.compose.oneoff': 'False', 'com.docker.compose.container-number': '1', 'com.docker.compose.version': '1.24.0', 'com.docker.compose.config-hash': 'c71f9e9138dc9820bcd2f30bf48cc9e013cb44542aefd79246e420d19dc69a49'}, host_config={'NetworkMode': 'test-dockerdb-configs_default', 'RestartPolicy': {'Name': 'always', 'MaximumRetryCount': 0}, 'VolumesFrom': [], 'Binds': [], 'PortBindings': {'1521/tcp': [{'HostIp': '', 'HostPort': '1522'}]}, 'Links': [], 'LogConfig': {'Type': '', 'Config': {}}}, networking_config={'EndpointsConfig': {'test-dockerdb-configs_default': {'Aliases': ['lbcli-oracle-secondary'], 'IPAMConfig': {}}}})
compose.parallel.feed_queue: Pending: set()
urllib3.connectionpool._make_request: http://localhost:None ""POST /v1.24/containers/create?name=oracle12c-db2 HTTP/1.1"" 201 90
compose.cli.verbose_proxy.proxy_callable: docker create_container -> {'Id': '177b24e282c62affe66cf6bb16df62568be8cbae21fb7190348a1df793b5b710',
 'Warnings': None}
compose.cli.verbose_proxy.proxy_callable: docker inspect_container <- ('177b24e282c62affe66cf6bb16df62568be8cbae21fb7190348a1df793b5b710')
compose.parallel.feed_queue: Pending: set()
compose.parallel.feed_queue: Pending: set()
urllib3.connectionpool._make_request: http://localhost:None ""GET /v1.24/containers/177b24e282c62affe66cf6bb16df62568be8cbae21fb7190348a1df793b5b710/json HTTP/1.1"" 200 None
compose.cli.verbose_proxy.proxy_callable: docker inspect_container -> {'AppArmorProfile': '',
 'Args': ['-c', 'exec $ORACLE_BASE/$RUN_FILE'],
 'Config': {'ArgsEscaped': True,
            'AttachStderr': False,
            'AttachStdin': False,
            'AttachStdout': False,
            'Cmd': ['/bin/sh', '-c', 'exec $ORACLE_BASE/$RUN_FILE'],
            'Domainname': '',
            'Entrypoint': None,
            'Env': ['ORACLE_SID=orcl',
...
compose.cli.verbose_proxy.proxy_callable: docker disconnect_container_from_network <- ('177b24e282c62affe66cf6bb16df62568be8cbae21fb7190348a1df793b5b710', 'test-dockerdb-configs_default')
urllib3.connectionpool._make_request: http://localhost:None ""POST /v1.24/networks/test-dockerdb-configs_default/disconnect HTTP/1.1"" 200 0
compose.cli.verbose_proxy.proxy_callable: docker disconnect_container_from_network -> None
compose.cli.verbose_proxy.proxy_callable: docker connect_container_to_network <- ('177b24e282c62affe66cf6bb16df62568be8cbae21fb7190348a1df793b5b710', 'test-dockerdb-configs_default', aliases=['177b24e282c6', 'lbcli-oracle-secondary'], ipv4_address=None, ipv6_address=None, links=[], link_local_ips=None)
urllib3.connectionpool._make_request: http://localhost:None ""POST /v1.24/networks/test-dockerdb-configs_default/connect HTTP/1.1"" 200 0
compose.cli.verbose_proxy.proxy_callable: docker connect_container_to_network -> None
compose.cli.verbose_proxy.proxy_callable: docker start <- ('177b24e282c62affe66cf6bb16df62568be8cbae21fb7190348a1df793b5b710')
compose.parallel.feed_queue: Pending: set()
compose.parallel.feed_queue: Pending: set()
compose.parallel.feed_queue: Pending: set()
compose.parallel.feed_queue: Pending: set()
compose.parallel.feed_queue: Pending: set()
compose.parallel.feed_queue: Pending: set()
compose.parallel.feed_queue: Pending: set()
compose.parallel.feed_queue: Pending: set()
compose.parallel.feed_queue: Pending: set()
compose.parallel.feed_queue: Pending: set()
compose.parallel.feed_queue: Pending: set()
compose.parallel.feed_queue: Pending: set()
compose.parallel.feed_queue: Pending: set()
compose.parallel.feed_queue: Pending: set()
compose.parallel.feed_queue: Pending: set()
compose.parallel.feed_queue: Pending: set()
compose.parallel.feed_queue: Pending: set()
compose.parallel.feed_queue: Pending: set()
urllib3.connectionpool._make_request: http://localhost:None ""POST /v1.24/containers/177b24e282c62affe66cf6bb16df62568be8cbae21fb7190348a1df793b5b710/start HTTP/1.1"" 204 0
Creating oracle12c-db2 ... done
compose.parallel.parallel_execute_iter: Finished processing: ServiceName(project='test-dockerdb-configs', service='lbcli-oracle-secondary', number=1)
compose.parallel.feed_queue: Pending: set()
compose.parallel.parallel_execute_iter: Finished processing: <Service: lbcli-oracle-secondary>
compose.parallel.feed_queue: Pending: set()
compose.parallel.feed_queue: Pending: set()
compose.parallel.feed_queue: Pending: set()
compose.parallel.feed_queue: Pending: set()
compose.parallel.feed_queue: Pending: set()
compose.parallel.feed_queue: Pending: set()
compose.parallel.feed_queue: Pending: set()
compose.parallel.feed_queue: Pending: set()
compose.parallel.feed_queue: Pending: set()
compose.parallel.feed_queue: Pending: set()
compose.parallel.feed_queue: Pending: set()
compose.parallel.feed_queue: Pending: set()
compose.parallel.feed_queue: Pending: set()
compose.parallel.feed_queue: Pending: set()
compose.parallel.feed_queue: Pending: set()
compose.parallel.feed_queue: Pending: set()
compose.parallel.feed_queue: Pending: set()
compose.parallel.feed_queue: Pending: set()
compose.parallel.feed_queue: Pending: set()
compose.parallel.feed_queue: Pending: set()
compose.parallel.feed_queue: Pending: set()
compose.parallel.feed_queue: Pending: set()
compose.parallel.feed_queue: Pending: set()
compose.parallel.feed_queue: Pending: set()
compose.parallel.feed_queue: Pending: set()
compose.parallel.feed_queue: Pending: set()
compose.parallel.feed_queue: Pending: set()
compose.parallel.feed_queue: Pending: set()
compose.parallel.feed_queue: Pending: set()
compose.parallel.feed_queue: Pending: set()
compose.parallel.feed_queue: Pending: set()
compose.parallel.feed_queue: Pending: set()
compose.parallel.feed_queue: Pending: set()
compose.parallel.feed_queue: Pending: set()
compose.parallel.feed_queue: Pending: set()
compose.parallel.feed_queue: Pending: set()
compose.parallel.feed_queue: Pending: set()
compose.parallel.feed_queue: Pending: set()
compose.parallel.feed_queue: Pending: set()
compose.parallel.feed_queue: Pending: set()
compose.parallel.feed_queue: Pending: set()
compose.parallel.feed_queue: Pending: set()
compose.parallel.feed_queue: Pending: set()
compose.parallel.feed_queue: Pending: set()
compose.parallel.feed_queue: Pending: set()
compose.parallel.feed_queue: Pending: set()
compose.parallel.feed_queue: Pending: set()
compose.parallel.feed_queue: Pending: set()
compose.parallel.feed_queue: Pending: set()
compose.parallel.feed_queue: Pending: set()
compose.parallel.feed_queue: Pending: set()
compose.parallel.feed_queue: Pending: set()
compose.parallel.feed_queue: Pending: set()
compose.parallel.feed_queue: Pending: set()
compose.parallel.feed_queue: Pending: set()
compose.parallel.feed_queue: Pending: set()
compose.parallel.feed_queue: Pending: set()
compose.parallel.feed_queue: Pending: set()
compose.parallel.feed_queue: Pending: set()
compose.parallel.feed_queue: Pending: set()
compose.parallel.feed_queue: Pending: set()
compose.parallel.feed_queue: Pending: set()
compose.parallel.feed_queue: Pending: set()
compose.parallel.feed_queue: Pending: set()
compose.parallel.parallel_execute_iter: Failed: ServiceName(project='test-dockerdb-configs', service='lbcli-oracle-primary', number=1)
compose.parallel.feed_queue: Pending: set()

ERROR: for oracle12c-db1  UnixHTTPConnectionPool(host='localhost', port=None): Read timed out. (read timeout=60)
compose.parallel.parallel_execute_iter: Failed: <Service: lbcli-oracle-primary>
compose.parallel.feed_queue: Pending: set()

ERROR: for lbcli-oracle-primary  UnixHTTPConnectionPool(host='localhost', port=None): Read timed out. (read timeout=60)
compose.cli.errors.log_timeout_error: An HTTP request took too long to complete. Retry with --verbose to obtain debug information.
If you encounter this issue regularly because of slow network conditions, consider setting COMPOSE_HTTP_TIMEOUT to a higher value (current value: 60).
```

*SECOND ATTEMPT*
```
[centos@ip-172-30-0-179 test-dockerdb-configs]$ docker-compose down
Stopping oracle12c-db2 ... done
Removing oracle12c-db1 ... done
Removing oracle12c-db2 ... done
Removing network test-dockerdb-configs_default
[centos@ip-172-30-0-179 test-dockerdb-configs]$ docker-compose --verbose up -d 2>&1 | tee log2
compose.config.config.find: Using configuration files: ./docker-compose.yml
docker.utils.config.find_config_file: Trying paths: ['/home/centos/.docker/config.json', '/home/centos/.dockercfg']
docker.utils.config.find_config_file: Found file at path: /home/centos/.docker/config.json
docker.auth.load_config: Found 'auths' section
docker.auth.parse_auth: Found entry (registry='docker-dev.artifactory.datical.net', username='jnewton')
docker.auth.parse_auth: Found entry (registry='docker.artifactory.datical.net', username='jnewton')
urllib3.connectionpool._make_request: http://localhost:None ""GET /v1.24/version HTTP/1.1"" 200 580
compose.cli.command.get_client: docker-compose version 1.24.0, build 0aa59064
docker-py version: 3.7.2
CPython version: 3.6.8
OpenSSL version: OpenSSL 1.1.0j  20 Nov 2018
compose.cli.command.get_client: Docker base_url: http+docker://localhost
compose.cli.command.get_client: Docker version: Platform={'Name': 'Docker Engine - Community'}, Components=[{'Name': 'Engine', 'Version': '18.09.7', 'Details': {'ApiVersion': '1.39', 'Arch': 'amd64', 'BuildTime': '2019-06-27T17:26:28.000000000+00:00', 'Experimental': 'false', 'GitCommit': '2d0083d', 'GoVersion': 'go1.10.8', 'KernelVersion': '3.10.0-957.21.3.el7.x86_64', 'MinAPIVersion': '1.12', 'Os': 'linux'}}], Version=18.09.7, ApiVersion=1.39, MinAPIVersion=1.12, GitCommit=2d0083d, GoVersion=go1.10.8, Os=linux, Arch=amd64, KernelVersion=3.10.0-957.21.3.el7.x86_64, BuildTime=2019-06-27T17:26:28.000000000+00:00
compose.cli.verbose_proxy.proxy_callable: docker inspect_network <- ('testdockerdbconfigs_default')
urllib3.connectionpool._make_request: http://localhost:None ""GET /v1.24/networks/testdockerdbconfigs_default HTTP/1.1"" 404 60
compose.cli.verbose_proxy.proxy_callable: docker info <- ()
urllib3.connectionpool._make_request: http://localhost:None ""GET /v1.24/info HTTP/1.1"" 200 None
compose.cli.verbose_proxy.proxy_callable: docker info -> {'Architecture': 'x86_64',
 'BridgeNfIp6tables': True,
 'BridgeNfIptables': True,
 'CPUSet': True,
 'CPUShares': True,
 'CgroupDriver': 'cgroupfs',
 'ClusterAdvertise': '',
 'ClusterStore': '',
 'ContainerdCommit': {'Expected': '894b81a4b802e4eb2a91d1ce216b8817763c29fb',
                      'ID': '894b81a4b802e4eb2a91d1ce216b8817763c29fb'},
...
compose.cli.verbose_proxy.proxy_callable: docker inspect_network <- ('test-dockerdb-configs_default')
urllib3.connectionpool._make_request: http://localhost:None ""GET /v1.24/networks/test-dockerdb-configs_default HTTP/1.1"" 404 62
compose.network.ensure: Creating network ""test-dockerdb-configs_default"" with the default driver
compose.cli.verbose_proxy.proxy_callable: docker create_network <- (name='test-dockerdb-configs_default', driver=None, options=None, ipam=None, internal=False, enable_ipv6=False, labels={'com.docker.compose.project': 'test-dockerdb-configs', 'com.docker.compose.network': 'default', 'com.docker.compose.version': '1.24.0'}, attachable=True, check_duplicate=True)
urllib3.connectionpool._make_request: http://localhost:None ""POST /v1.24/networks/create HTTP/1.1"" 201 87
compose.cli.verbose_proxy.proxy_callable: docker create_network -> {'Id': '3d6f2557f4cfbeae40aaba915c2e9dc4a477b89125b78456de77b49e727c847c',
 'Warning': ''}
compose.cli.verbose_proxy.proxy_callable: docker containers <- (all=False, filters={'label': ['com.docker.compose.project=test-dockerdb-configs', 'com.docker.compose.oneoff=False']})
urllib3.connectionpool._make_request: http://localhost:None ""GET /v1.24/containers/json?limit=-1&all=0&size=0&trunc_cmd=0&filters=%7B%22label%22%3A+%5B%22com.docker.compose.project%3Dtest-dockerdb-configs%22%2C+%22com.docker.compose.oneoff%3DFalse%22%5D%7D HTTP/1.1"" 200 3
compose.cli.verbose_proxy.proxy_callable: docker containers -> (list with 0 items)
compose.cli.verbose_proxy.proxy_callable: docker containers <- (all=False, filters={'label': ['com.docker.compose.project=testdockerdbconfigs', 'com.docker.compose.oneoff=False']})
urllib3.connectionpool._make_request: http://localhost:None ""GET /v1.24/containers/json?limit=-1&all=0&size=0&trunc_cmd=0&filters=%7B%22label%22%3A+%5B%22com.docker.compose.project%3Dtestdockerdbconfigs%22%2C+%22com.docker.compose.oneoff%3DFalse%22%5D%7D HTTP/1.1"" 200 3
compose.cli.verbose_proxy.proxy_callable: docker containers -> (list with 0 items)
compose.cli.verbose_proxy.proxy_callable: docker containers <- (all=True, filters={'label': ['com.docker.compose.project=test-dockerdb-configs', 'com.docker.compose.service=lbcli-oracle-primary', 'com.docker.compose.oneoff=False']})
urllib3.connectionpool._make_request: http://localhost:None ""GET /v1.24/containers/json?limit=-1&all=1&size=0&trunc_cmd=0&filters=%7B%22label%22%3A+%5B%22com.docker.compose.project%3Dtest-dockerdb-configs%22%2C+%22com.docker.compose.service%3Dlbcli-oracle-primary%22%2C+%22com.docker.compose.oneoff%3DFalse%22%5D%7D HTTP/1.1"" 200 3
compose.cli.verbose_proxy.proxy_callable: docker containers -> (list with 0 items)
compose.cli.verbose_proxy.proxy_callable: docker containers <- (all=True, filters={'label': ['com.docker.compose.project=testdockerdbconfigs', 'com.docker.compose.service=lbcli-oracle-primary', 'com.docker.compose.oneoff=False']})
urllib3.connectionpool._make_request: http://localhost:None ""GET /v1.24/containers/json?limit=-1&all=1&size=0&trunc_cmd=0&filters=%7B%22label%22%3A+%5B%22com.docker.compose.project%3Dtestdockerdbconfigs%22%2C+%22com.docker.compose.service%3Dlbcli-oracle-primary%22%2C+%22com.docker.compose.oneoff%3DFalse%22%5D%7D HTTP/1.1"" 200 3
compose.cli.verbose_proxy.proxy_callable: docker containers -> (list with 0 items)
compose.cli.verbose_proxy.proxy_callable: docker containers <- (all=True, filters={'label': ['com.docker.compose.project=test-dockerdb-configs', 'com.docker.compose.service=lbcli-oracle-secondary', 'com.docker.compose.oneoff=False']})
urllib3.connectionpool._make_request: http://localhost:None ""GET /v1.24/containers/json?limit=-1&all=1&size=0&trunc_cmd=0&filters=%7B%22label%22%3A+%5B%22com.docker.compose.project%3Dtest-dockerdb-configs%22%2C+%22com.docker.compose.service%3Dlbcli-oracle-secondary%22%2C+%22com.docker.compose.oneoff%3DFalse%22%5D%7D HTTP/1.1"" 200 3
compose.cli.verbose_proxy.proxy_callable: docker containers -> (list with 0 items)
compose.cli.verbose_proxy.proxy_callable: docker containers <- (all=True, filters={'label': ['com.docker.compose.project=testdockerdbconfigs', 'com.docker.compose.service=lbcli-oracle-secondary', 'com.docker.compose.oneoff=False']})
urllib3.connectionpool._make_request: http://localhost:None ""GET /v1.24/containers/json?limit=-1&all=1&size=0&trunc_cmd=0&filters=%7B%22label%22%3A+%5B%22com.docker.compose.project%3Dtestdockerdbconfigs%22%2C+%22com.docker.compose.service%3Dlbcli-oracle-secondary%22%2C+%22com.docker.compose.oneoff%3DFalse%22%5D%7D HTTP/1.1"" 200 3
compose.cli.verbose_proxy.proxy_callable: docker containers -> (list with 0 items)
compose.cli.verbose_proxy.proxy_callable: docker inspect_image <- ('docker-dev.artifactory.datical.net/datical/oracle-ee:12.2.0.1-ci')
urllib3.connectionpool._make_request: http://localhost:None ""GET /v1.24/images/docker-dev.artifactory.datical.net/datical/oracle-ee:12.2.0.1-ci/json HTTP/1.1"" 200 None
compose.cli.verbose_proxy.proxy_callable: docker inspect_image -> {'Architecture': 'amd64',
 'Author': '',
 'Comment': '',
 'Config': {'ArgsEscaped': True,
            'AttachStderr': False,
            'AttachStdin': False,
            'AttachStdout': False,
            'Cmd': ['/bin/sh', '-c', 'exec $ORACLE_BASE/$RUN_FILE'],
            'Domainname': '',
            'Entrypoint': None,
...
compose.cli.verbose_proxy.proxy_callable: docker inspect_image <- ('docker-dev.artifactory.datical.net/datical/oracle-ee:12.2.0.1-ci')
urllib3.connectionpool._make_request: http://localhost:None ""GET /v1.24/images/docker-dev.artifactory.datical.net/datical/oracle-ee:12.2.0.1-ci/json HTTP/1.1"" 200 None
compose.cli.verbose_proxy.proxy_callable: docker inspect_image -> {'Architecture': 'amd64',
 'Author': '',
 'Comment': '',
 'Config': {'ArgsEscaped': True,
            'AttachStderr': False,
            'AttachStdin': False,
            'AttachStdout': False,
            'Cmd': ['/bin/sh', '-c', 'exec $ORACLE_BASE/$RUN_FILE'],
            'Domainname': '',
            'Entrypoint': None,
...
compose.cli.verbose_proxy.proxy_callable: docker containers <- (all=True, filters={'label': ['com.docker.compose.project=test-dockerdb-configs', 'com.docker.compose.service=lbcli-oracle-primary', 'com.docker.compose.oneoff=False']})
urllib3.connectionpool._make_request: http://localhost:None ""GET /v1.24/containers/json?limit=-1&all=1&size=0&trunc_cmd=0&filters=%7B%22label%22%3A+%5B%22com.docker.compose.project%3Dtest-dockerdb-configs%22%2C+%22com.docker.compose.service%3Dlbcli-oracle-primary%22%2C+%22com.docker.compose.oneoff%3DFalse%22%5D%7D HTTP/1.1"" 200 3
compose.cli.verbose_proxy.proxy_callable: docker containers -> (list with 0 items)
compose.cli.verbose_proxy.proxy_callable: docker containers <- (all=True, filters={'label': ['com.docker.compose.project=testdockerdbconfigs', 'com.docker.compose.service=lbcli-oracle-primary', 'com.docker.compose.oneoff=False']})
urllib3.connectionpool._make_request: http://localhost:None ""GET /v1.24/containers/json?limit=-1&all=1&size=0&trunc_cmd=0&filters=%7B%22label%22%3A+%5B%22com.docker.compose.project%3Dtestdockerdbconfigs%22%2C+%22com.docker.compose.service%3Dlbcli-oracle-primary%22%2C+%22com.docker.compose.oneoff%3DFalse%22%5D%7D HTTP/1.1"" 200 3
compose.cli.verbose_proxy.proxy_callable: docker containers -> (list with 0 items)
compose.cli.verbose_proxy.proxy_callable: docker containers <- (all=True, filters={'label': ['com.docker.compose.project=test-dockerdb-configs', 'com.docker.compose.service=lbcli-oracle-secondary', 'com.docker.compose.oneoff=False']})
urllib3.connectionpool._make_request: http://localhost:None ""GET /v1.24/containers/json?limit=-1&all=1&size=0&trunc_cmd=0&filters=%7B%22label%22%3A+%5B%22com.docker.compose.project%3Dtest-dockerdb-configs%22%2C+%22com.docker.compose.service%3Dlbcli-oracle-secondary%22%2C+%22com.docker.compose.oneoff%3DFalse%22%5D%7D HTTP/1.1"" 200 3
compose.cli.verbose_proxy.proxy_callable: docker containers -> (list with 0 items)
compose.cli.verbose_proxy.proxy_callable: docker containers <- (all=True, filters={'label': ['com.docker.compose.project=testdockerdbconfigs', 'com.docker.compose.service=lbcli-oracle-secondary', 'com.docker.compose.oneoff=False']})
urllib3.connectionpool._make_request: http://localhost:None ""GET /v1.24/containers/json?limit=-1&all=1&size=0&trunc_cmd=0&filters=%7B%22label%22%3A+%5B%22com.docker.compose.project%3Dtestdockerdbconfigs%22%2C+%22com.docker.compose.service%3Dlbcli-oracle-secondary%22%2C+%22com.docker.compose.oneoff%3DFalse%22%5D%7D HTTP/1.1"" 200 3
compose.cli.verbose_proxy.proxy_callable: docker containers -> (list with 0 items)
compose.parallel.feed_queue: Pending: {<Service: lbcli-oracle-secondary>, <Service: lbcli-oracle-primary>}
compose.parallel.feed_queue: Starting producer thread for <Service: lbcli-oracle-secondary>
compose.cli.verbose_proxy.proxy_callable: docker containers <- (all=True, filters={'label': ['com.docker.compose.project=test-dockerdb-configs', 'com.docker.compose.service=lbcli-oracle-secondary', 'com.docker.compose.oneoff=False']})
compose.parallel.feed_queue: Starting producer thread for <Service: lbcli-oracle-primary>
urllib3.connectionpool._make_request: http://localhost:None ""GET /v1.24/containers/json?limit=-1&all=1&size=0&trunc_cmd=0&filters=%7B%22label%22%3A+%5B%22com.docker.compose.project%3Dtest-dockerdb-configs%22%2C+%22com.docker.compose.service%3Dlbcli-oracle-secondary%22%2C+%22com.docker.compose.oneoff%3DFalse%22%5D%7D HTTP/1.1"" 200 3
compose.cli.verbose_proxy.proxy_callable: docker containers <- (all=True, filters={'label': ['com.docker.compose.project=test-dockerdb-configs', 'com.docker.compose.service=lbcli-oracle-primary', 'com.docker.compose.oneoff=False']})
compose.cli.verbose_proxy.proxy_callable: docker containers -> (list with 0 items)
compose.cli.verbose_proxy.proxy_callable: docker containers <- (all=True, filters={'label': ['com.docker.compose.project=testdockerdbconfigs', 'com.docker.compose.service=lbcli-oracle-secondary', 'com.docker.compose.oneoff=False']})
urllib3.connectionpool._make_request: http://localhost:None ""GET /v1.24/containers/json?limit=-1&all=1&size=0&trunc_cmd=0&filters=%7B%22label%22%3A+%5B%22com.docker.compose.project%3Dtestdockerdbconfigs%22%2C+%22com.docker.compose.service%3Dlbcli-oracle-secondary%22%2C+%22com.docker.compose.oneoff%3DFalse%22%5D%7D HTTP/1.1"" 200 3
urllib3.connectionpool._make_request: http://localhost:None ""GET /v1.24/containers/json?limit=-1&all=1&size=0&trunc_cmd=0&filters=%7B%22label%22%3A+%5B%22com.docker.compose.project%3Dtest-dockerdb-configs%22%2C+%22com.docker.compose.service%3Dlbcli-oracle-primary%22%2C+%22com.docker.compose.oneoff%3DFalse%22%5D%7D HTTP/1.1"" 200 3
compose.cli.verbose_proxy.proxy_callable: docker containers -> (list with 0 items)
Creating oracle12c-db2 ...
compose.cli.verbose_proxy.proxy_callable: docker containers -> (list with 0 items)
compose.parallel.feed_queue: Pending: {ServiceName(project='test-dockerdb-configs', service='lbcli-oracle-secondary', number=1)}
compose.cli.verbose_proxy.proxy_callable: docker containers <- (all=True, filters={'label': ['com.docker.compose.project=testdockerdbconfigs', 'com.docker.compose.service=lbcli-oracle-primary', 'com.docker.compose.oneoff=False']})
compose.parallel.feed_queue: Starting producer thread for ServiceName(project='test-dockerdb-configs', service='lbcli-oracle-secondary', number=1)
compose.cli.verbose_proxy.proxy_callable: docker inspect_image <- ('docker-dev.artifactory.datical.net/datical/oracle-ee:12.2.0.1-ci')
urllib3.connectionpool._make_request: http://localhost:None ""GET /v1.24/containers/json?limit=-1&all=1&size=0&trunc_cmd=0&filters=%7B%22label%22%3A+%5B%22com.docker.compose.project%3Dtestdockerdbconfigs%22%2C+%22com.docker.compose.service%3Dlbcli-oracle-primary%22%2C+%22com.docker.compose.oneoff%3DFalse%22%5D%7D HTTP/1.1"" 200 3
compose.cli.verbose_proxy.proxy_callable: docker containers -> (list with 0 items)
Creating oracle12c-db1 ...
compose.parallel.feed_queue: Pending: {ServiceName(project='test-dockerdb-configs', service='lbcli-oracle-primary', number=1)}
compose.parallel.feed_queue: Starting producer thread for ServiceName(project='test-dockerdb-configs', service='lbcli-oracle-primary', number=1)
compose.cli.verbose_proxy.proxy_callable: docker inspect_image <- ('docker-dev.artifactory.datical.net/datical/oracle-ee:12.2.0.1-ci')
urllib3.connectionpool._make_request: http://localhost:None ""GET /v1.24/images/docker-dev.artifactory.datical.net/datical/oracle-ee:12.2.0.1-ci/json HTTP/1.1"" 200 None
compose.cli.verbose_proxy.proxy_callable: docker inspect_image -> {'Architecture': 'amd64',
 'Author': '',
 'Comment': '',
 'Config': {'ArgsEscaped': True,
            'AttachStderr': False,
            'AttachStdin': False,
            'AttachStdout': False,
            'Cmd': ['/bin/sh', '-c', 'exec $ORACLE_BASE/$RUN_FILE'],
            'Domainname': '',
            'Entrypoint': None,
...
compose.cli.verbose_proxy.proxy_callable: docker inspect_image <- ('docker-dev.artifactory.datical.net/datical/oracle-ee:12.2.0.1-ci')
urllib3.connectionpool._make_request: http://localhost:None ""GET /v1.24/images/docker-dev.artifactory.datical.net/datical/oracle-ee:12.2.0.1-ci/json HTTP/1.1"" 200 None
compose.cli.verbose_proxy.proxy_callable: docker inspect_image -> {'Architecture': 'amd64',
 'Author': '',
 'Comment': '',
 'Config': {'ArgsEscaped': True,
            'AttachStderr': False,
            'AttachStdin': False,
            'AttachStdout': False,
            'Cmd': ['/bin/sh', '-c', 'exec $ORACLE_BASE/$RUN_FILE'],
            'Domainname': '',
            'Entrypoint': None,
...
compose.service.build_container_labels: Added config hash: c71f9e9138dc9820bcd2f30bf48cc9e013cb44542aefd79246e420d19dc69a49
compose.cli.verbose_proxy.proxy_callable: docker create_host_config <- (links=[], port_bindings={'1521/tcp': ['1522']}, binds=[], volumes_from=[], privileged=False, network_mode='test-dockerdb-configs_default', devices=None, dns=None, dns_opt=None, dns_search=None, restart_policy={'Name': 'always', 'MaximumRetryCount': 0}, runtime=None, cap_add=None, cap_drop=None, mem_limit=None, mem_reservation=None, memswap_limit=None, ulimits=None, log_config={'Type': '', 'Config': {}}, extra_hosts=None, read_only=None, pid_mode=None, security_opt=None, ipc_mode=None, cgroup_parent=None, cpu_quota=None, shm_size=None, sysctls=None, pids_limit=None, tmpfs=[], oom_kill_disable=None, oom_score_adj=None, mem_swappiness=None, group_add=None, userns_mode=None, init=None, init_path=None, isolation=None, cpu_count=None, cpu_percent=None, nano_cpus=None, volume_driver=None, cpuset_cpus=None, cpu_shares=None, storage_opt=None, blkio_weight=None, blkio_weight_device=None, device_read_bps=None, device_read_iops=None, device_write_bps=None, device_write_iops=None, mounts=None, device_cgroup_rules=None, cpu_period=None, cpu_rt_period=None, cpu_rt_runtime=None)
compose.cli.verbose_proxy.proxy_callable: docker create_host_config -> {'Binds': [],
 'Links': [],
 'LogConfig': {'Config': {}, 'Type': ''},
 'NetworkMode': 'test-dockerdb-configs_default',
 'PortBindings': {'1521/tcp': [{'HostIp': '', 'HostPort': '1522'}]},
 'RestartPolicy': {'MaximumRetryCount': 0, 'Name': 'always'},
 'VolumesFrom': []}
compose.cli.verbose_proxy.proxy_callable: docker create_container <- (image='docker-dev.artifactory.datical.net/datical/oracle-ee:12.2.0.1-ci', ports=[('1521', 'tcp')], volumes={}, name='oracle12c-db2', detach=True, environment=[], labels={'com.docker.compose.project': 'test-dockerdb-configs', 'com.docker.compose.service': 'lbcli-oracle-secondary', 'com.docker.compose.oneoff': 'False', 'com.docker.compose.container-number': '1', 'com.docker.compose.version': '1.24.0', 'com.docker.compose.config-hash': 'c71f9e9138dc9820bcd2f30bf48cc9e013cb44542aefd79246e420d19dc69a49'}, host_config={'NetworkMode': 'test-dockerdb-configs_default', 'RestartPolicy': {'Name': 'always', 'MaximumRetryCount': 0}, 'VolumesFrom': [], 'Binds': [], 'PortBindings': {'1521/tcp': [{'HostIp': '', 'HostPort': '1522'}]}, 'Links': [], 'LogConfig': {'Type': '', 'Config': {}}}, networking_config={'EndpointsConfig': {'test-dockerdb-configs_default': {'Aliases': ['lbcli-oracle-secondary'], 'IPAMConfig': {}}}})
urllib3.connectionpool._make_request: http://localhost:None ""GET /v1.24/images/docker-dev.artifactory.datical.net/datical/oracle-ee:12.2.0.1-ci/json HTTP/1.1"" 200 None
compose.cli.verbose_proxy.proxy_callable: docker inspect_image -> {'Architecture': 'amd64',
 'Author': '',
 'Comment': '',
 'Config': {'ArgsEscaped': True,
            'AttachStderr': False,
            'AttachStdin': False,
            'AttachStdout': False,
            'Cmd': ['/bin/sh', '-c', 'exec $ORACLE_BASE/$RUN_FILE'],
            'Domainname': '',
            'Entrypoint': None,
...
compose.cli.verbose_proxy.proxy_callable: docker inspect_image <- ('docker-dev.artifactory.datical.net/datical/oracle-ee:12.2.0.1-ci')
urllib3.connectionpool._make_request: http://localhost:None ""GET /v1.24/images/docker-dev.artifactory.datical.net/datical/oracle-ee:12.2.0.1-ci/json HTTP/1.1"" 200 None
compose.cli.verbose_proxy.proxy_callable: docker inspect_image -> {'Architecture': 'amd64',
 'Author': '',
 'Comment': '',
 'Config': {'ArgsEscaped': True,
            'AttachStderr': False,
            'AttachStdin': False,
            'AttachStdout': False,
            'Cmd': ['/bin/sh', '-c', 'exec $ORACLE_BASE/$RUN_FILE'],
            'Domainname': '',
            'Entrypoint': None,
...
compose.service.build_container_labels: Added config hash: b64576715c9f4d2f41e6e41cc3287f4331fcc48eb3c2bb063b603b993e195e1e
compose.cli.verbose_proxy.proxy_callable: docker create_host_config <- (links=[], port_bindings={'1521/tcp': ['1521']}, binds=[], volumes_from=[], privileged=False, network_mode='test-dockerdb-configs_default', devices=None, dns=None, dns_opt=None, dns_search=None, restart_policy={'Name': 'always', 'MaximumRetryCount': 0}, runtime=None, cap_add=None, cap_drop=None, mem_limit=None, mem_reservation=None, memswap_limit=None, ulimits=None, log_config={'Type': '', 'Config': {}}, extra_hosts=None, read_only=None, pid_mode=None, security_opt=None, ipc_mode=None, cgroup_parent=None, cpu_quota=None, shm_size=None, sysctls=None, pids_limit=None, tmpfs=[], oom_kill_disable=None, oom_score_adj=None, mem_swappiness=None, group_add=None, userns_mode=None, init=None, init_path=None, isolation=None, cpu_count=None, cpu_percent=None, nano_cpus=None, volume_driver=None, cpuset_cpus=None, cpu_shares=None, storage_opt=None, blkio_weight=None, blkio_weight_device=None, device_read_bps=None, device_read_iops=None, device_write_bps=None, device_write_iops=None, mounts=None, device_cgroup_rules=None, cpu_period=None, cpu_rt_period=None, cpu_rt_runtime=None)
compose.cli.verbose_proxy.proxy_callable: docker create_host_config -> {'Binds': [],
 'Links': [],
 'LogConfig': {'Config': {}, 'Type': ''},
 'NetworkMode': 'test-dockerdb-configs_default',
 'PortBindings': {'1521/tcp': [{'HostIp': '', 'HostPort': '1521'}]},
 'RestartPolicy': {'MaximumRetryCount': 0, 'Name': 'always'},
 'VolumesFrom': []}
compose.cli.verbose_proxy.proxy_callable: docker create_container <- (image='docker-dev.artifactory.datical.net/datical/oracle-ee:12.2.0.1-ci', ports=[('1521', 'tcp')], volumes={'opt/oracle/product/12.2.0.1': {}}, name='oracle12c-db1', detach=True, environment=[], labels={'com.docker.compose.project': 'test-dockerdb-configs', 'com.docker.compose.service': 'lbcli-oracle-primary', 'com.docker.compose.oneoff': 'False', 'com.docker.compose.container-number': '1', 'com.docker.compose.version': '1.24.0', 'com.docker.compose.config-hash': 'b64576715c9f4d2f41e6e41cc3287f4331fcc48eb3c2bb063b603b993e195e1e'}, host_config={'NetworkMode': 'test-dockerdb-configs_default', 'RestartPolicy': {'Name': 'always', 'MaximumRetryCount': 0}, 'VolumesFrom': [], 'Binds': [], 'PortBindings': {'1521/tcp': [{'HostIp': '', 'HostPort': '1521'}]}, 'Links': [], 'LogConfig': {'Type': '', 'Config': {}}}, networking_config={'EndpointsConfig': {'test-dockerdb-configs_default': {'Aliases': ['lbcli-oracle-primary'], 'IPAMConfig': {}}}})
urllib3.connectionpool._make_request: http://localhost:None ""POST /v1.24/containers/create?name=oracle12c-db2 HTTP/1.1"" 201 90
compose.cli.verbose_proxy.proxy_callable: docker create_container -> {'Id': '3e1ae80527f7e5b963502054d4780ee145d06b89581db2fa07ee77d4af831886',
 'Warnings': None}
compose.cli.verbose_proxy.proxy_callable: docker inspect_container <- ('3e1ae80527f7e5b963502054d4780ee145d06b89581db2fa07ee77d4af831886')
urllib3.connectionpool._make_request: http://localhost:None ""GET /v1.24/containers/3e1ae80527f7e5b963502054d4780ee145d06b89581db2fa07ee77d4af831886/json HTTP/1.1"" 200 None
compose.cli.verbose_proxy.proxy_callable: docker inspect_container -> {'AppArmorProfile': '',
 'Args': ['-c', 'exec $ORACLE_BASE/$RUN_FILE'],
 'Config': {'ArgsEscaped': True,
            'AttachStderr': False,
            'AttachStdin': False,
            'AttachStdout': False,
            'Cmd': ['/bin/sh', '-c', 'exec $ORACLE_BASE/$RUN_FILE'],
            'Domainname': '',
            'Entrypoint': None,
            'Env': ['ORACLE_SID=orcl',
...
compose.cli.verbose_proxy.proxy_callable: docker disconnect_container_from_network <- ('3e1ae80527f7e5b963502054d4780ee145d06b89581db2fa07ee77d4af831886', 'test-dockerdb-configs_default')
urllib3.connectionpool._make_request: http://localhost:None ""POST /v1.24/networks/test-dockerdb-configs_default/disconnect HTTP/1.1"" 200 0
compose.cli.verbose_proxy.proxy_callable: docker disconnect_container_from_network -> None
compose.cli.verbose_proxy.proxy_callable: docker connect_container_to_network <- ('3e1ae80527f7e5b963502054d4780ee145d06b89581db2fa07ee77d4af831886', 'test-dockerdb-configs_default', aliases=['lbcli-oracle-secondary', '3e1ae80527f7'], ipv4_address=None, ipv6_address=None, links=[], link_local_ips=None)
urllib3.connectionpool._make_request: http://localhost:None ""POST /v1.24/networks/test-dockerdb-configs_default/connect HTTP/1.1"" 200 0
compose.cli.verbose_proxy.proxy_callable: docker connect_container_to_network -> None
compose.cli.verbose_proxy.proxy_callable: docker start <- ('3e1ae80527f7e5b963502054d4780ee145d06b89581db2fa07ee77d4af831886')
compose.parallel.feed_queue: Pending: set()
compose.parallel.feed_queue: Pending: set()
compose.parallel.feed_queue: Pending: set()
compose.parallel.feed_queue: Pending: set()
compose.parallel.feed_queue: Pending: set()
compose.parallel.feed_queue: Pending: set()
compose.parallel.feed_queue: Pending: set()
compose.parallel.feed_queue: Pending: set()
compose.parallel.feed_queue: Pending: set()
compose.parallel.feed_queue: Pending: set()
compose.parallel.feed_queue: Pending: set()
compose.parallel.feed_queue: Pending: set()
compose.parallel.feed_queue: Pending: set()
compose.parallel.feed_queue: Pending: set()
compose.parallel.feed_queue: Pending: set()
compose.parallel.feed_queue: Pending: set()
compose.parallel.feed_queue: Pending: set()
compose.parallel.feed_queue: Pending: set()
compose.parallel.feed_queue: Pending: set()
compose.parallel.feed_queue: Pending: set()
compose.parallel.feed_queue: Pending: set()
compose.parallel.feed_queue: Pending: set()
compose.parallel.feed_queue: Pending: set()
compose.parallel.feed_queue: Pending: set()
urllib3.connectionpool._make_request: http://localhost:None ""POST /v1.24/containers/3e1ae80527f7e5b963502054d4780ee145d06b89581db2fa07ee77d4af831886/start HTTP/1.1"" 204 0
Creating oracle12c-db2 ... done
compose.parallel.parallel_execute_iter: Finished processing: ServiceName(project='test-dockerdb-configs', service='lbcli-oracle-secondary', number=1)
compose.parallel.feed_queue: Pending: set()
compose.parallel.parallel_execute_iter: Finished processing: <Service: lbcli-oracle-secondary>
compose.parallel.feed_queue: Pending: set()
compose.parallel.feed_queue: Pending: set()
compose.parallel.feed_queue: Pending: set()
compose.parallel.feed_queue: Pending: set()
compose.parallel.feed_queue: Pending: set()
compose.parallel.feed_queue: Pending: set()
compose.parallel.feed_queue: Pending: set()
compose.parallel.feed_queue: Pending: set()
compose.parallel.feed_queue: Pending: set()
compose.parallel.feed_queue: Pending: set()
compose.parallel.feed_queue: Pending: set()
compose.parallel.feed_queue: Pending: set()
compose.parallel.feed_queue: Pending: set()
compose.parallel.feed_queue: Pending: set()
compose.parallel.feed_queue: Pending: set()
compose.parallel.feed_queue: Pending: set()
compose.parallel.feed_queue: Pending: set()
compose.parallel.feed_queue: Pending: set()
compose.parallel.feed_queue: Pending: set()
compose.parallel.feed_queue: Pending: set()
compose.parallel.feed_queue: Pending: set()
compose.parallel.feed_queue: Pending: set()
compose.parallel.feed_queue: Pending: set()
compose.parallel.feed_queue: Pending: set()
compose.parallel.feed_queue: Pending: set()
compose.parallel.feed_queue: Pending: set()
compose.parallel.feed_queue: Pending: set()
compose.parallel.feed_queue: Pending: set()
compose.parallel.feed_queue: Pending: set()
compose.parallel.feed_queue: Pending: set()
compose.parallel.feed_queue: Pending: set()
compose.parallel.feed_queue: Pending: set()
compose.parallel.feed_queue: Pending: set()
compose.parallel.feed_queue: Pending: set()
compose.parallel.feed_queue: Pending: set()
compose.parallel.feed_queue: Pending: set()
compose.parallel.feed_queue: Pending: set()
compose.parallel.feed_queue: Pending: set()
compose.parallel.feed_queue: Pending: set()
compose.parallel.feed_queue: Pending: set()
compose.parallel.feed_queue: Pending: set()
compose.parallel.feed_queue: Pending: set()
compose.parallel.feed_queue: Pending: set()
compose.parallel.feed_queue: Pending: set()
compose.parallel.feed_queue: Pending: set()
compose.parallel.feed_queue: Pending: set()
compose.parallel.feed_queue: Pending: set()
compose.parallel.feed_queue: Pending: set()
compose.parallel.feed_queue: Pending: set()
compose.parallel.feed_queue: Pending: set()
compose.parallel.feed_queue: Pending: set()
compose.parallel.feed_queue: Pending: set()
compose.parallel.feed_queue: Pending: set()
compose.parallel.feed_queue: Pending: set()
compose.parallel.feed_queue: Pending: set()
compose.parallel.feed_queue: Pending: set()
compose.parallel.feed_queue: Pending: set()
compose.parallel.feed_queue: Pending: set()
compose.parallel.feed_queue: Pending: set()
compose.parallel.feed_queue: Pending: set()
compose.parallel.feed_queue: Pending: set()
urllib3.connectionpool._make_request: http://localhost:None ""POST /v1.24/containers/create?name=oracle12c-db1 HTTP/1.1"" 201 90
compose.cli.verbose_proxy.proxy_callable: docker create_container -> {'Id': '05b9c60e3244c3003aa0a881f1f03c3ae740625ed3f40425b307392e8bd22674',
 'Warnings': None}
compose.cli.verbose_proxy.proxy_callable: docker inspect_container <- ('05b9c60e3244c3003aa0a881f1f03c3ae740625ed3f40425b307392e8bd22674')
urllib3.connectionpool._make_request: http://localhost:None ""GET /v1.24/containers/05b9c60e3244c3003aa0a881f1f03c3ae740625ed3f40425b307392e8bd22674/json HTTP/1.1"" 200 None
compose.cli.verbose_proxy.proxy_callable: docker inspect_container -> {'AppArmorProfile': '',
 'Args': ['-c', 'exec $ORACLE_BASE/$RUN_FILE'],
 'Config': {'ArgsEscaped': True,
            'AttachStderr': False,
            'AttachStdin': False,
            'AttachStdout': False,
            'Cmd': ['/bin/sh', '-c', 'exec $ORACLE_BASE/$RUN_FILE'],
            'Domainname': '',
            'Entrypoint': None,
            'Env': ['ORACLE_SID=orcl',
...
compose.cli.verbose_proxy.proxy_callable: docker disconnect_container_from_network <- ('05b9c60e3244c3003aa0a881f1f03c3ae740625ed3f40425b307392e8bd22674', 'test-dockerdb-configs_default')
urllib3.connectionpool._make_request: http://localhost:None ""POST /v1.24/networks/test-dockerdb-configs_default/disconnect HTTP/1.1"" 200 0
compose.cli.verbose_proxy.proxy_callable: docker disconnect_container_from_network -> None
compose.cli.verbose_proxy.proxy_callable: docker connect_container_to_network <- ('05b9c60e3244c3003aa0a881f1f03c3ae740625ed3f40425b307392e8bd22674', 'test-dockerdb-configs_default', aliases=['05b9c60e3244', 'lbcli-oracle-primary'], ipv4_address=None, ipv6_address=None, links=[], link_local_ips=None)
urllib3.connectionpool._make_request: http://localhost:None ""POST /v1.24/networks/test-dockerdb-configs_default/connect HTTP/1.1"" 200 0
compose.cli.verbose_proxy.proxy_callable: docker connect_container_to_network -> None
compose.cli.verbose_proxy.proxy_callable: docker start <- ('05b9c60e3244c3003aa0a881f1f03c3ae740625ed3f40425b307392e8bd22674')
compose.parallel.feed_queue: Pending: set()
compose.parallel.feed_queue: Pending: set()
compose.parallel.feed_queue: Pending: set()
compose.parallel.feed_queue: Pending: set()
compose.parallel.feed_queue: Pending: set()
compose.parallel.feed_queue: Pending: set()
compose.parallel.feed_queue: Pending: set()
compose.parallel.feed_queue: Pending: set()
urllib3.connectionpool._make_request: http://localhost:None ""POST /v1.24/containers/05b9c60e3244c3003aa0a881f1f03c3ae740625ed3f40425b307392e8bd22674/start HTTP/1.1"" 204 0
compose.cli.verbose_proxy.proxy_callable: docker start -> None
Creating oracle12c-db1 ... done
compose.parallel.feed_queue: Pending: set()
compose.parallel.parallel_execute_iter: Finished processing: <Service: lbcli-oracle-primary>
compose.parallel.feed_queue: Pending: set()
[centos@ip-172-30-0-179 test-dockerdb-configs]$
```

## Additional information

This fails even when setting a higher COMPOSE_HTTP_TIMEOUT

OS version / distribution, `docker-compose` install method, etc.
CentOS Linux release 7.6.1810 (Core)
docker-ce installed via yum repo
docker-compose installed via curl",,,DonSupreme,"
--
I am also experiencing this issue but on Windows. It happens randomly, which breaks my build process.

`docker-compose version 1.24.1, build 4667896b
docker-py version: 3.7.3
CPython version: 3.6.8
OpenSSL version: OpenSSL 1.0.2q  20 Nov 2018`

`Client: Docker Engine - Community
 Version:           19.03.5
 API version:       1.40
 Go version:        go1.12.12
 Git commit:        633a0ea
 Built:             Wed Nov 13 07:22:37 2019
 OS/Arch:           windows/amd64
 Experimental:      false

Server: Docker Engine - Community
 Engine:
  Version:          19.03.5
  API version:      1.40 (minimum version 1.24)
  Go version:       go1.12.12
  Git commit:       633a0ea
  Built:            Wed Nov 13 07:36:50 2019
  OS/Arch:          windows/amd64
  Experimental:     false`
--
",akshayvijapur,"
--
Any one has solutions for this ? 
--
",cknott,"
--
I'm also running into this issue on MacOS Catalina with the newest version of Docker Desktop (2.2.0.3)
Is there any way to solve this problem?
--

--
Disabling the Packet Filter on my machine (pfctl -d) helped fixing this problem - MacOS Catalina 10.15.6
--
",timpavone1990,"
--
I guess I had the same issue and could resolve it by using the [nocopy](https://docs.docker.com/compose/compose-file/compose-file-v2/#long-syntax) flag.

According to the docs, this will prevent copying existing data in the volume target folder into the volume. But well, if your container depends on that data to start up, the nocopy flag might not really work for you.
--
",momadthenomad,"
--
I'm also experiencing same thing. The funny thing is it started happening today for me and was working fine yesterday.

```
Client: Docker Engine - Community
 Version:           19.03.8
 API version:       1.40
 Go version:        go1.12.17
 Git commit:        afacb8b
 Built:             Wed Mar 11 01:23:10 2020
 OS/Arch:           windows/amd64
 Experimental:      false

Server: Docker Engine - Community
 Engine:
  Version:          19.03.8
  API version:      1.40 (minimum version 1.12)
  Go version:       go1.12.17
  Git commit:       afacb8b
  Built:            Wed Mar 11 01:29:16 2020
  OS/Arch:          linux/amd64
  Experimental:     false
 containerd:
  Version:          v1.2.13
  GitCommit:        7ad184331fa3e55e52b890ea95e65ba581ae3429
 runc:
  Version:          1.0.0-rc10
  GitCommit:        dc9208a3303feef5b3839f4323d9beb36df0a9dd
 docker-init:
  Version:          0.18.0
  GitCommit:        fec3683
```

docker-compose:

```
docker-compose version 1.25.5, build 8a1c60f6
docker-py version: 4.1.0
CPython version: 3.7.4
OpenSSL version: OpenSSL 1.1.1c  28 May 2019
```
--

--
Restarting docker and restarting the computer fixed it for me.
--
",subbumahalingam,"
--
I'm on latest stable version atm 2.3.0.4 (46911). And still facing this issue. Its really annoying and can't get this to work even after restart of docker, host machine.  
--

--
> Disabling the Packet Filter on my machine (pfctl -d) helped fixing this problem - MacOS Catalina 10.15.6

Thanks for your reply. I'm on Catalina as well. And after disabling the packet filter, tried restarting docker and no luck. :(
--
"
6762,OPEN,Feature: Detach after blocking for minimum delay until assumed stable,kind/feature,2020-08-17 19:44:26 +0000 UTC,nhooey,Opened,,"One of the most common problems I encounter when bringing up containers in detached mode is that one of my containers encounters and error and quits, without me knowing about it until I realize much later, and manually check to find a stopped container.

An feature that would help with this problem would be a detached mode that behaves like undetached for a minimum delay until the container is assumed to be stable and continue running indefinitely.

So if you brought up a series of containers with this new option, you would see:
```
$ docker-compose up --detach --attach-for-n-seconds 10 c1 c2 c3
Starting c1 ... done
Starting c2 ... done
Starting c3 ... done
c1        | (Log output showing whatever c1 does...)
c2        | (Log output showing whatever c2 does...)
c3        | (Log output showing whatever c3 does...)
*** Detaching from c1 because it has been running without exit for 10 seconds ***
*** Detaching from c2 because it has been running without exit for 10 seconds ***
*** Detaching from c3 because it has been running without exit for 10 seconds ***
```
And if every container survived the specified timeout, the return code would be zero.

This could also be configured per-container in `docker-compose.yaml`.

What do you think?",,,chris,"
--
Hi @nhooey,

Thanks for the idea. I can see how this would make debugging easier in some cases but I'm not sure this is the best way to solve the problem. We'll mull this over as a team and try to come back with something.
--
",mlanett,"
--
I'd like to see this sort of feature, but have it be in the foreground until health check returns true, then detach.
--
",,,,,,,,
6757,OPEN,Add new label com.docker.compose.projectfolder,kind/feature,2019-06-27 11:23:08 +0000 UTC,thwr,In progress,,"**Is your feature request related to a problem? Please describe.**
I'm planning a project that requires to know the folder of (or complete path to) the `docker-compose.yml` for any compose-controlled container on a host. 

**Describe the solution you'd like**
Ask you guys to add a new built-in label, e.g. `com.docker.compose.projectfolder`

**Describe alternatives you've considered**
This could also be archived by adding a label to every container, e.g. `my_fancy_label=$PWD`. But this is prone to (human) error if not using some orchestration / config management tool like puppet, chef, ansible, salt etc. 

**Additional context**
none, sorry
",,,thwr,"
--
On a second (and third) thought, it makes more sense to me to provide the full path to the compose file itself or a second label  - one for the path, one for the file.

This should help if someone uses an alternate compose file name, like `docker-compose.yaml` or `compose.yml` or whatever else.
--
",chris,"
--
Hi @thwr,

Thank you for the suggestion. While this may make sense when you're working on your local machine, when you're targeting a remote Docker endpoint and have multiple devs working on the same machine it doesn't work.

As such, I don't think that it makes sense to add this to Compose.

**[EDIT]** I see that you proposed what is below in your issue:

You can use environment variables in labels so if you are running `docker-compose up` from your project directory, the following would give you a label with the project directory:

```yaml
version: ""3.7""
services:
        one:
                image: nginx
                labels:
                        - ""com.example.project-dir=${PWD}""
```

```console
$ docker inspect sandbox_one_1
...
            ""Labels"": {
                ""com.example.project-dir"": ""/tmp/sandbox"",
...
```
--
",,,,,,,,
6753,OPEN,want ports long syntax support species IP address like short syntax,kind/feature,2019-12-19 08:17:17 +0000 UTC,Sherlock-Holo,Opened,,"I write a docker-compose.yml and use ports with long syntax to expose services, like
```docker-compose
ports:
      - target: 53
        published: 127.0.0.1:53
        protocol: udp

      - target: 9253
        published: 127.0.0.1:9253
        protocol: tcp
```

when I run `docker-compose config` it will report **Error while attempting to convert service.dns.ports.published to appropriate type: ""127.0.0.1:53"" is not a valid integer**

If long syntax support sepices IP address, it will be great",,,chris,"
--
Hi @Sherlock-Holo,

Thanks for the report. You are right that you currently cannot do this with the long port format. A couple of things raised by @thaJeztah about this:
- It would not work in orchestrated environments (i.e.: Swarm or Kubernetes)
- It would require a new field in the port spec
--
",imfms,"
--
@chris-crone 

The long syntax can use [extension-fields](https://docs.docker.com/compose/compose-file/#extension-fields) directly. 
If long syntax support sepices IP address, it will be great.

```yaml
x-config:
- &publish-port ""127.0.0.1:80""

...
ports:
  - target: 80
    published: *publish-port
```


Although Swarm or Kubernetes don't support, but short syntax was also. It's not a problem~
--
",thaJeztah,"
--
> It would not work in orchestrated environments (i.e.: Swarm or Kubernetes)

There's a tracking issue for features that are not currently supported for swarm-mode / orchestrated environments here: https://github.com/moby/moby/issues/25303

And two issues about supporting `ip-address` when publishing ports (https://github.com/moby/moby/issues/26696, https://github.com/moby/moby/issues/32299)

> It would require a new field in the port spec

Yes, so apart from the above, this would also need some design choices, with things to consider about:

- would it only support ip-addresses, or also (e.g.) interface name (`eth0`) ?
- If both IPv6 and IPv4 is to be supported; a single field or multiple?
- (related to the previous); can it hold a single address, or multiple? (or should the format ""keep it simple"") and require multiple _ports_ to be specified - one for each ip-address for a port-mapping?

Using an extension field (`x-something`) that's only supported by docker compose, and marking it ""experimental"" _could_ be used to explore what works best.
--
",,,,,,
6749,OPEN,Building containers in parallel to speed up performance?,kind/feature,2020-05-28 17:03:13 +0000 UTC,specialtactics,In progress,,"**Is your feature request related to a problem? Please describe.**
No

**Describe the solution you'd like**
When using docker-compose up, and more than 1 container needs to have it's image build/rebuild, it would be fantastic if the building for all containers could be done in parallel rather than sequentially, to speed up the process.

**Describe alternatives you've considered**
None

**Additional context**
Situations where multiple docker containers need to have their image either built for the first time, or rebuilt because of some changes.
",,,chris,"
--
Hi @specialtactics,

Thanks for posting this. Have you taken a look at [`buildx`](https://github.com/docker/buildx)? It's an experimental build tool that can build all service images in a Compose file using BuildKit. It will be released (as experimental) with the 19.03 release.
--

--
@specialtactics Since `docker-compose` is written in Python and the rest of the Docker stack is Go, it's quite difficult to integrate things like `buildx` well. The general plan for `buildx` is for its functionality to land in the `docker build` command when it's stable.
--

--
@giorgiosironi Yes, `--parallel` will make it quicker if you have multiple service images that need building. This will still use the older build system though and not BuildKit.
--
",specialtactics,"
--
Hey @chris-crone - sounds interesting, what will be the relationship between buildx and docker/docker-compose though? I would prefer that docker-compose worked this way by default instead of having to also use some third-party tooling to facilitate this functionality.
--
",giorgiosironi,"
--
Doesn't `docker-compose build --parallel` cover this?
--
",ostrolucky,"
--
Use this to utilize both buildx and --parallel
```
COMPOSE_DOCKER_CLI_BUILD=1 DOCKER_BUILDKIT=1 docker-compose build --parallel
```
--
",julianrutten,"
--
`--parallel` is good but could this be added to `docker-compose up` too? I was quite confused not finding it there even though I was running latest versions. Edit: reasoning: saves a build step in my case, which is a lot cleaner.
--
",k1w1m8,"
--
Using a separate `build` and then `up` is only a partial workaround for this.

This is because the existing separate build and up steps mean we have to wait for _all_ the containers to stop building before starting _any_ containers.

If the `--parallel` option was added to `up`, it would (in theory) be possible to begin starting containers before all the builds were finished. 

This could reduce the overall start time considerably.
--
"
6748,OPEN,Is it possible to let env_file config supports load from url ?,kind/feature,2019-06-28 03:41:22 +0000 UTC,lff0305,In progress,,"For example,
```
web:
  env_file:
    - http://my-config-center/docker/web.env
```
I know there is some way to make it possible now (For example, map a local file to a remote file by some utility), but I think it would be great if it is supported by docker-compose.",,,chris,"
--
Hi @lff0305,

Thanks for your request. Could you please expand on a use case for how you'd use this feature? That will help us think about how to handle the case and prioritise the work.
--
",lff0305,"
--
Hi
The case is here: we have a few docker-compose instances. Now the .env file is put on each server / directory. When there is something to be update, the dev-ops must update each .env file on the servers separately.

So we would like to put the .env files on a web server (GitLab, or SpringCloud Config Server), and then docker-compose can load them from http://git-lab/.../web.env.

More over, with some server (Spring Could Config) for example, the hierarchy is supported. We can extract some common properties to a base env file, and then extend it to create each sub env files for each docker-compose instance.

Thanks.


--
",,,,,,,,
6743,OPEN,Add support for non-service container,kind/feature,2020-10-20 16:08:25 +0000 UTC,kitingChris,In progress,,"Unfortunatelly the discussion in https://github.com/docker/compose/issues/1896 was closed. And since @shin- wrote a long post https://github.com/docker/compose/issues/1896#issuecomment-322285976 about the service philosophy I made some thoughts on that.

I would agreee with your point. Calling it service would then not be the correct term. But as the discussion and the recurring demands of such an feature request show there is a real need to define ""command containers"" as wenn in the docker-compose service.

Having containers that run a single command is not an unfamiliar concept to docker. So why does docker-compose do not help with such containers?

Defining command containers as services is currently still the defacto standard to have them defined somewhere.

So there is a really broad need for the feature defining command containers. Therefore I would ask for a new section in docker-compose files besides ""services"".

Could be called ""commands"".

Docker container could be defined exactly like services there. But they are not started with `docker-compose up` but only by `docker-compose run`.  

Optional command containers are runned with --rm by default (unlike services)
",,,chris,"
--
Hi @kitingChris,

The current scope for the Compose format is to define a list of services and how they interact. This means that one can write a Compose file, deploy it locally with `docker-compose` to develop and test before deploying it to an orchestrated environment (Swarm or Kubernetes) with `docker stack deploy` with little or no changes. Because of this we need to be mindful of what we add to the format and how it translates to orchestrated environments.

At the moment there is no notion of running a container for a single task on Swarm but there is work on Swarmkit to add tasks which would do this, see: https://github.com/docker/swarmkit/issues/2852

We will need to investigate what UI we provide for this and if it makes sense to add something to the Compose format or not.
--
",kitingChris,"
--
@chris-crone thanks for answering :) 
Well I actually need this feature not during deploy with docker-swarm or else in prod environment but in development.

For example: An php-web application requires many One-off Tasks such as composer for installing dependencies, phpunit for running the unit tests or phpstan for the QA tasks. Also php-cli commands running tasks or one-off jobs during development for testing purposes. 

In my current main project I am working with we have the following containers as task containers:
- yarn:
- php-console
- phpunit
- phpstan
- composer

and the following as true services:
- mysql:
- elastic:
- nginx:
- php-fpm:
- redis:

So there is also in docker-compose the high demand for this feature.


Best way in my opinion to solve this would be to define a sibling definition to services calles tasks where you can define all non-service container in exact the same way you define the service containers but during up docker-compose just ignores them. 
During build both should be considered ... 

This may be the easiest solution to solve this issue AND keep the service-philosophy.
--

--
Is there any chance we can get this soon? Because this issue drives me crazy.

When you have a team with mixed OS users and you use overrides to cope with volume issues AND then have to split docker-compose files because you don't want to up non-service container it really gets fuzzy! 

This feature is severely needed! There were several claims and discussions for it in the past so PLEASE!!! 



--

--
Now I have the same issue for a dotnet project. Need to execute a non-service container for database migrations. Still no suitable way to work this out with docker-compose. :( 
--
",enghelewa,"
--
I think it would be great if we can just tag a service to be `on-demand:true` so that docker-compose will not start it up by the `up` command.
--
",AstraLuma,"
--
To add my $.02: I would love support for declaring commands. My use case involves things like initializing a database and other operational tasks. My current preference is to run those commands in one of the containers I already declared (since they have the context needed to do it).

I currently do this by adding executables in the container and doing things like `docker-composes exec web /init-db`. This isn't complex, but I would still like to be able to declare this in my compose file, for the same reasons you might write them out in a Makefile:
* Discoverability
* Executable documentation
* It's just convenient
--
",,,,
6741,OPEN,Feature Request: option to disable reading from .env,kind/feature,2020-11-29 17:26:41 +0000 UTC,jonmchan,In progress,,"Similar/repeat request to #4642. New/different reason now though. Related to https://github.com/docker/compose/issues/6511.

Other systems use the exact same file `.env` for parsing and processing environment variables. With the release of 1.24.0, the feature where `Compose will no longer accept whitespace in variable names sourced from environment files. This matches the Docker CLI behavior.` breaks compatibility with other .env utilities. Although my setup does not use the variables in .env for docker-compose, docker-compose now fails because the .env file does not meet docker-compose's format.

I either have to make the .env file fit docker-compose's format or remove the file.

I propose that you can specify an option to ignore the `.env` file or specify a different `.env` file (such as `.docker.env`) in the `docker-compose.yml` file so that we can work around projects that are already using the `.env` file for something else.

",,,chris,"
--
Hi @jonmchan,

Thanks for your report. I would prefer to keep issues in the same place so that we can track them. Could you please add this as a comment to the relevant issue?

I'll close this as a duplicate.
--

--
Thanks for clarifying @jonmchan I'll reopen this.
--
",jonmchan,"
--
hi @chris-crone , this isn't a duplicate. This is a feature request to disable reading `.env` file. #4642 issue was closed and it's rational for implementing that feature has already been addressed, so it didn't seem appropriate to reopen that issue.  #6511 is just rational to why we need this feature, but it is not dependent or directly related. 

I think evaluating this feature request independently - ""can we have a config option to disable interpreting `.env` file?"" - would be the proper approach to addressing this feature request.
--

--
I started looking into the details for implementing such a feature - the `--env-file` is the only option to change the `.env` file location. The docker-compose.yml file is not loaded until after the environment file is read. If we were to implement a feature where the `.env` location could be changed from docker-compose.yml, we would have to read the docker-compose.yml to peak for the parameter beforehand resulting in either 2 reads to docker-compose.yml or changing the order of loading (which may not be good because the env file needs to be set before reading docker-compose.yml). I think reading docker-compose.yml 2 times would be acceptable, thoughts? 
--

--
Everyone please comment on PR https://github.com/docker/compose/pull/6850. I don't think it properly addresses this issue, but I would love to get everyone else's feedback. Thanks!
--
",alecgibson,"
--
Definitely in favour of being able to disable `.env` from the `docker-compose.yml`. I just updated Docker to the latest stable release, and it's broken my development environment because we have a `.env` file lurking that was never intended for Docker consumption.
--
",joshchernoff,"
--
.env is such a standard outside of docker, allowing docker to dictate to me how I should be using it and given I'm not even using it to configure docker itself I feel its a complete overreach by docker. 

Thank you for this feature, I hope it gets merged soon.  
--
",rofrano,"
--
Docker just broke my development environment too. :( As a Python developer I use `autoenv` extensively so all of my `.env` files start with:

```
if [ -d ""venv"" ]; then
  deactivate > /dev/null 2>&1
  source venv/bin/activate
fi

export FLASK_APP=service:app
... blah, blah, blach, etc.
```

This allows me to simply `cd` into a folder and have that Python virtual environment immediately activated. 

We need a way to disable this behavior or at a minimum have it give a warning and keep going because my `.env` file is not meant for docker consumption.
--
",lawrencejones,"
--
This is massively frustrating team! `.env` is used by so many applications and now all the docker tooling breaks whenever it tries reading what other tools consider to support full bash syntax.

The change will have made these tools unusable in people's dev environments :(
--
"
6736,OPEN,Hooks to run scripts on host before starting any containers,kind/feature; status/0-triage,2021-02-01 16:28:00 +0000 UTC,Jamie-,Opened,,"This is clearly a common problem lots of people have been facing (even since 2014, #468), there's pile of closed issues for similar functionality to be added before and they have been closed, I believe, entirely un-reasonably.

Please see #1341 for a very concise argument as to why this functionality is useful, and judging by the **reactions to most of the comments**, it is quite a popular feature the community would like added.

Now it's over 2 years since #1341 was closed I believe hook-like functionality should be reconsidered.

## Is your feature request related to a problem? Please describe.
There are many examples in #1341 already but I'll add my most recent use case for this.

I have a number of containers that are spun up, using compose, for development which require a shared data directory. I also need to access that directory on my host. Inside each of my containers a Python program is started as a specific user (as to mimic production as accurately as possible). Currently I mount this volume on each of my containers in docker-compose like so:
```
volumes:
  - ""/tmp/data-var:/var/data""
```
However `/tmp/data-var` doesn't exist on my host (this is a shared development project), so it's created by docker for me, as root. Therefore my Python programs, running as non-root, cannot write to it.

Before `docker-compose up` starts any containers, I'd like to call something like `mkdir /tmp/data-var && chown +w /tmp/data-var`. Then on `docker-compose down` after all containers are destroyed I'd like to remove the temp data directory `rm -rf /tmp/data-var`.

I understand this _could_ be accomplished in other ways, please see the alternatives section below as to why these suck.

## Describe the solution you'd like
I'd like to have two bash scripts, say `pre-up.sh` and `post-down.sh` and add them to be called via docker-compose with something like the following in my `docker-compose.yml`
```
version: ""3""
pre-up: ""./pre-up.sh""
post-down: ""./post-down.sh""
services:
  service1:
    build: .
    volumes:
      - ""/tmp/data-var:/var/data""
```
Other possible hooks people might find useful:
* `post-up`: Called after containers have all started
* `post-stop`: Called after containers have been stopped (either with ^C or docker-compose stop)
* `pre-down`: Called before destroying containers and networks (with `docker-compose down`)
* etc.

When calling these, compose should block at the specified point until the script has returned with an exit code of 0, and itself stop with a non-zero exit code if the script exits with a non-zero code.

## Describe alternatives you've considered
There are alternatives for _my example_ use case, and equally good reasons they're a bad fit. 

### 1. Calling a script on container start
I could have an `ENTRYPOINT [""start.sh""]` which sets the correct permissions on the directory, then my Python run command be specified via `CMD [""python"", ...]` and have `start.sh` finally call `exec ""$@""`. However this is a waste as the first container to get started, and every container restart after would do the same thing, it only needs to be done once before any containers start.

Equally, it wouldn't solve my `post-down: ""./post-down.sh""` use case.

### 2. Wrapping it up in a different script
I could write a wrapper script that calls `docker-compose up`, as that's been suggested many times in other issues. Come on... we're all using compose because it's concise, neat, tidy and simple to use. Everything is specified in one place which makes it easy for beginners to understand and read what's going on. Compose itself is essentially a standard when using docker with multiple containers.

### 3. Compose events
Though my understanding of events is lacking, due to how complex it is for what I really want to do. This is a poor way to achieve the goal I described, just like many other issues that were raised, then all pointed to #1510 (compose events). Events are reactive, this needs to be proactive, but more importantly, **events do not block**, and for many people, like me, blocking is essential.
",,,phedders,"
--
Good luck... with kubernetes. Docker inc doesnt care.
--
",ndeloof,"
--
Volume permission is very common issue with docker, and as long as you use bind mounts you even tell the engine ""I'm in charge for this one, just expose inside container"" and get into obvious permission issues. Using named volumes, which are created with owner set to the first container to use them, would help solve this issue.

What you describe as a proposed solution is pretty comparable to Kubernetes [init containers](https://kubernetes.io/fr/docs/concepts/workloads/pods/init-containers/), this is something we should consider for a future version of docker-compose. Main constraint is that compoes file format is not only used by docker-compose so such a move will require some coordination with `docker stack` command 
 and compose-on-kubernetes.
cc @chris-crone 
--
",jdiegosierra,"
--
Would be nice to run different scripts before start any services, in my case I need create some folders and depends of the service I want to start.
--

--
@TomaszGasior I mean I have to create folders into my host. And they dependeds of the service. As far I understand how entrypoint.sh works, it is for run some commands into de container right?


--

--
@TomaszGasior Yeah I know :D But is not my case...

My case is I'm sharing the folder of a project with the container except the dist folder. I want the container has its own dist folder and my host project its own dist folder in order to develop using docker or without it. So in my docker-compose I have this:
```
volumes:
  - ../../frontend:/opt/app
  - ../../frontend/dist
  - /opt/app/dist <-here is the problem
```
Also in my docker image I have this:

```
RUN groupadd appuser
RUN useradd -r -u 1001 -g appuser appuser
... build stuff
RUN chown appuser:appuser /opt/app -R
```
Into my container the dist folder has the appuser permissions and its builded files so its okey for me. The problem is outside the container. docker.-compose has created a folder called dist with root permissions so if i want to build my project in my host i cant because permissions. However if I create dist folder in my host with appuser permissions before start docker-compose all works as I want and dist folder in my host is empty with appuser permissions so I can build my project also in my host and it doesnt conflict with the dist folder into the container.
--

--
Is not exactly what I need. I need to create a empty folder in my host called dist with appuser permissions before start the service in order to docker-compose doesnt create a dist folder with root permissions.

btw, I appreciate your help :)
--
",TomaszGasior,"
--
@jdiegosierra Can't you just do this in entrypoint script?
--

--
@jdiegosierra If you need to create directories inside directories shared between host and container, you can create them inside container's entrypoint by wrapping original entrypoint into  your own.
--

--
> docker-compose has created a folder called dist with root permissions so if i want to build my project in my host i cant because permissions

As I understand, what you need is to create directory from inside of container's entrypoint but with permissions like it would be created from your host. If there is any directory inside your container with permissions from your host, you may want to use `stat` and `chown`.

Let's see my example. I have PHP application. composer, PHP package manager, creates `vendor` directory with all app dependencies. I want to run it from container entrypoint but with permissions like it would be ran from my host. Check it out: https://github.com/TomaszGasior/RadioLista-v3/blob/bf5692d3d767afcfa7c1ccf46109c4f653c85b1c/container/php-fpm/entrypoint.sh#L8

Basically what I am doing here is I ran composer command with permissions (user and group) the same as parent folder has. You may take some inspiration from this. For example, you may create folder with `mkdir`, then change its permissions by `chown` to permissions of different directory of your project which is created on your host  you can get them using `stat`. 
--

--
> Is not exactly what I need. I need to create a empty folder in my host called dist with appuser permissions before start the service in order to docker-compose doesnt create a dist folder with root permissions.

Or you may let docker create that folder *with* root permissions and then inside your entrypoint just fix that wrong permissions using method which I described. :) It's possible if you have any other directory created in host by your host user, available inside container. Just `stat` the second one and `chown` first one. Your host user don't have to exist inside your container  `chown` will accept non-existing user/group ID returned by `stat`.

Something like: `chown $(stat -c '%u:%g' /from-host) /in-container`.  
`/from-host`  directory created by your user in host OS, `/in-container`  directory created by dockerd with wrong permission. 
--
",Ibsardar,"
--
> @jdiegosierra If you need to create directories inside directories shared between host and container, you can create them inside container's entrypoint by wrapping original entrypoint into your own.

Just a side thought - why should I research what is the `ENTRYPOINT` of the original image in order to prepend/append my own set of runtime commands? Shouldn't it be easier? Something like:

```` Dockerfile
BEFORE_ENTRYPOINT echo ""before""
AFTER_ENTRYPOINT echo ""after
````

So if the original `ENTRYPOINT` is:
```` Dockerfile
ENTRYPOINT echo ""original""
````

Then the next container that uses this container would have the following value for `ENTRYPOINT`:
```` sh
echo ""before""
echo ""original""
echo ""after""
````
--
",,
6735,OPEN,Expose use_network_aliases flag through compose config file,,2020-11-22 22:46:00 +0000 UTC,mwgamble,In progress,,"**Is your feature request related to a problem? Please describe.**
We have several projects where one service is designed to connect to a common network in addition to their default network. One project (which runs Adminer, the DB management tool), also connects to this common network with both of its services (nginx and PHP). All of the other projects run services with the same names (`nginx` and `php`).

The issue arises when `nginx` in one of the non-adminer projects tries to talk to its `php` service. There are `php` services on its default network, and on the common network. In a lot of cases, it ends up talking to the wrong `php` container.

**Describe the solution you'd like**
Based on what I've found from reading the compose source code, there is a `use_network_aliases` flag in the `start_container` method of the main `Service` class. When this flag is set to `False`, compose doesn't add any aliases (including the default service name alias) for that service. Unfortunately, there doesn't appear to be any way to control this flag from a compose config file.

So, the ideal solution would be to allow control of this flag on a per-network basis. We still want the Adminer `php` service to be advertised as such within the Adminer project's default network, but we don't have any need for it to be advertised as `php` on the common network.

**Describe alternatives you've considered**
As it's unlikely that this feature will be added in the immediate future, we're probably going to have to press ahead with a different solution whereby we define custom aliases for all services on the default network only, and then update our images to use those aliases instead of the service name alias.
",,,stale,"
--
This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you for your contributions.

--

--
This issue has been automatically marked as not stale anymore due to the recent activity.

--

--
This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you for your contributions.

--

--
This issue has been automatically marked as not stale anymore due to the recent activity.

--

--
This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you for your contributions.

--

--
This issue has been automatically marked as not stale anymore due to the recent activity.

--
",mwgamble,"
--
I'm not sure why this has been marked as stale when there hasn't even been so much as an acknowledgement from the maintainers.
--

--
Still no acknowledgement from the maintainers. Definitely still an issue, definitely not resolved, definitely not stale.
--

--
Still waiting for an acknowledgement from the maintainers.
--
",,,,,,,,
6684,OPEN,Feature Request: present environment variable COMPOSER_OPTS,kind/feature,2019-08-20 14:48:04 +0000 UTC,sgohl,Opened,,"Sometimes we're in the need for multiple docker-compose.yml files, while trying to simplify the daily usage of less experienced users, which leads me to the wish of being able to define multiple docker-compose.yml just like `COMPOSE_FILE`, but as an extension to that, append more command-line options to an environment variable, which docker-compose will read and inject at the `[options]` position (see usage):

```Usage:
  docker-compose [-f <arg>...] [options] [COMMAND] [ARGS...]
```
.env
```
COMPOSE_OPTS=""-f docker-compose.yml -f service-override.yml""
```

So every user can adjust the optional used compose.ymls where we can extend predeclared services, besides other options which are available on the cli.

This feature request comes as a workaround for not being able to extend nor include whole compose.ymls (considering network configuration), because just extending services is not enough. 

As an alternative, converting `COMPOSE_FILE` what is a string, to being a list, we just could simply define multiple files this way and it would not break any existing users, because the list just would 
 hold one entry:

```
COMPOSE_FILE=""/www/docker-compose.yml /www/another-compose.yml""
```

This would (in terms of a workaround) satisfy also the requirements to being able to really override services, as far as I've experienced in my test. Because, docker-compose.override.yml 1) not really works as expected and 2) you can not have multiple.",,,jcsirot,"
--
Hello @port22 Thank you for the feature suggestion. We are going to evaluate it but note that any Pull Request implementing this feature would also be greatly appreciated.
--
",,,,,,,,,,
6658,OPEN,[Feature Request] Use variables within env file,,2020-09-30 13:58:55 +0000 UTC,lonix1,In progress,,"**Is your feature request related to a problem? Please describe.**
No

**Describe the solution you'd like**
Use of variables within env file

**Additional context**
Often it's useful to be able to combine multiple variables in the env file. This makes the compose file much simpler and neater.

An example (from [here](https://github.com/docker/compose/issues/4878)) is:

````
HOME_DIR=/home/user
DOCKER_DIR=""${HOME_DIR}/docker""
FOO_DIR=""${HOME_DIR}/foo""
````

or

````
SERVICE=connection-foo-bar-baz-somehash
CONNECTION_FOO=http://${SERVICE}.foo.com/80/api/v1/service/
CONNECTION_BAR=http://${SERVICE}.bar.com/80/api/v1/service/
````",,,funkyfuture,"
--
but your titles says ""environment variable"" which `HOME_DIR` is not in the context of the host. so, the issue title is misleading.
--
",lonix1,"
--
@funkyfuture Please edit the title as you think. I'm unsure how best to describe it - variables / variable expansion / nested expansion?
--
",Alfro,"
--
+1 to this feature. :)
--
",razielanarki,"
--
+1 for feature request
--
",snowmoonsoftware,"
--
This would be useful for teams that develop on both Windows, Mac / Linux.

Here is what I'd like to be able to do to support my teams

```
# Set the name of your aws profile. If you haven't named your profile, use Default.
# though you really should name the profile for the enviroment its used with.
AWS_PROFILE=waters-saas

# use these lines for linux/macos
MSFT_USERSECRETS=~/.microsoft/usersecrets
ASPNET_HTTPS_CERTS=~/.aspnet/https
AWS_CREDENTIALS=~/.aws/credentials

# use these lines for Windows
#MSFT_USERSECRETS=${APPDATA}/Microsoft/UserSecrets
#ASPNET_HTTPS_CERTS=${APPDATA}/ASP.NET/Https
#AWS_CREDENTIALS=${UserProfile}/.aws/credentials
```
These variables are used in a docker-compose file to add volumes:
```
   volumes:
      - ${MSFT_USERSECRETS}:/root/.microsoft/usersecrets:ro
      - ${ASPNET_HTTPS_CERTS}:/root/.aspnet/https:ro
      - ${AWS_CREDENTIALS}:/root/.aws/credentials:ro
```
--
",roanosullivan,"
--
+1 for feature request
--
"
6611,OPEN,Proposal: add Docker save and load commands,area/cli; kind/feature,2019-09-17 14:08:58 +0000 UTC,ebuildy,In progress,,"**Is your feature request related to a problem? Please describe.**
Docker can save and load image as tar archive, docker-compose not.

**Describe the solution you'd like**
a simple ``docker-compose save > compose.tar``.

**Describe alternatives you've considered**
Parsing ``docker-compose.yml`` file to get image list, then run manually ``docker save``:

```
docker save -o docker-images.tar $(docker-compose config | awk '{if ($1 == ""image:"") print $2;}' ORS="" "")
```

",,,ijc,"
--
Thanks for the suggestion, this sounds like a reasonable enhancement, I think we'd be happy to take a look at a PR implementing this.
--

--
I woudn't say completely trivial, but at the easier end of the spectrum I reckon.
--
",ebuildy,"
--
Thanks you, do you thing this is an easy one? I could spend some time on it if yes.
--
",Ryllau,"
--
I was wondering if this has been implemented yet?
--
",,,,,,
6569,OPEN,Support IPAM gateway in version 3.x,kind/enhancement; status/0-triage,2020-10-31 10:58:15 +0000 UTC,rvernica,Opened,,"**Is your feature request related to a problem? Please describe.**

See #6555 

**Describe the solution you'd like**

The [documentation](https://docs.docker.com/compose/compose-file/#ipam) page sis it all:

> Note: Additional IPAM configurations, such as gateway, are only honored for version 2 at the moment.

I would be nice to have a more complete support of IPAM/network in the compose file for version `3.x`.

**Describe alternatives you've considered**

I've considered downgrading to version `2.x` but it seems a step backward.",,,cjsimon,"
--
Also see https://github.com/docker/compose/issues/4474
--
",bastiao,"
--
Any possible alternatives with v3?
This is weird because the default gateway is set as X.Y.Z.1. 
--
",stale,"
--
This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you for your contributions.

--

--
This issue has been automatically marked as not stale anymore due to the recent activity.

--
",kewur,"
--
just stumbled upon this. official ecs documentation were using gateway so I had to revert back to version 2. 

https://aws.amazon.com/blogs/compute/a-guide-to-locally-testing-containers-with-amazon-ecs-local-endpoints-and-docker-compose/
--
",smgoller,"
--
Would definitely like to be using version 3 files. What needs to be done to make this supported?
--
",EricHripko,"
--
Releases [1.27.0+](https://github.com/docker/compose/releases) have merged v2/v3 file formats, so you should be able to use `ipam` anywhere now.
--

--
Yep - I don't think the docs have been updated to reflect the changes introduced by _1.27.0+_ yet.
--

--
_1.27.0+_ drops the requirement for `version` attribute (so you don't even have to specify it any more). This indeed means that you can mix any 3.0+ features with any 2.0+ features  
--
"
6554,OPEN,up to create a subset of services,kind/feature,2019-03-11 15:58:50 +0000 UTC,GiovanniPaoloGibilisco,Opened,,"Managing complex docker-compose files with multiple services and dependencies sometime I would like to start only a subset of them. Currently I issue commands like: 
`docker-compose up -d elasticsearch logstasg kibana database serviceA serviceB...`
or 
`docker-compose up -d; docker-compose stop prometheus serviceB .... `

Working by addition is I need a few services or subtraction if I need more. 

I think it would be useful to be able to specify in the compose file some sort of profile (e.g. minimal, full, databases, logging..) and let docker-compose spawn those services (and related dependencies) that share the profile. 
Probably using labels for this is a more general way of handling this kind of situations. 


What I have in mind is something like:

`docker-compose up -d --profile minimal`
then all services with label profile containing minimal would be created. In such a scenario the label profile should contain a list of values more than a single one. 

A more general solution would be: 
`docker-compose up -d --labels profile=minimal`
so that users are free to use labels as they like and the compose just expose a filter on services to start. 

",,,ulyssessouza,"
--
Hello @GiovanniPaoloGibilisco. 
What you can do is separating the services in different files and using multiple `-f` flags to combine them.
For example:
With 2 files:
```
$ cat docker-compose1.yml
version: '2'
services:
    first:
        image: nginx
    second:
        image: nginx
$ cat docker-compose2.yml
version: '2'
services:
    third:
        image: nginx
    fourth:
        image: nginx
```

This opens the possibility of starting all with:
```
$ docker-compose -f docker-compose1.yml -f docker-compose2.yml up -d
```

And to stop just the third and fourth, this can be done by:
```
$ docker-compose -f docker-compose2.yml stop
```

Like this, you can define your groups using different files.
Please, let me know if that covers your use case.
--
",,,,,,,,,,
6533,OPEN,Compose treats empty labels different than stack deploy,format/v3; kind/bug,2020-09-16 13:51:54 +0000 UTC,thaJeztah,In progress,,"3. When making a bug report, make sure you provide all required information. The easier it is for
   maintainers to reproduce, the faster it'll be fixed.
-->

## Description of the issue

Docker Compose treats empty labels as `null` value, instead of an empty string, whereas `docker stack deploy` treats the same as empty string (default value for labels);


## Context information (for bug reports)

**Output of `docker-compose version`**

```
docker-compose version 1.24.0-rc1, build 0f3d4dda
docker-py version: 3.7.0
CPython version: 3.6.6
OpenSSL version: OpenSSL 1.1.0h  27 Mar 2018
```

**Output of `docker version`**

```
Client: Docker Engine - Community
 Version:           18.09.1
 API version:       1.39
 Go version:        go1.10.6
 Git commit:        4c52b90
 Built:             Wed Jan  9 19:33:12 2019
 OS/Arch:           darwin/amd64
 Experimental:      true

Server: Docker Engine - Community
 Engine:
  Version:          18.09.1
  API version:      1.39 (minimum version 1.12)
  Go version:       go1.10.6
  Git commit:       4c52b90
  Built:            Wed Jan  9 19:41:49 2019
  OS/Arch:          linux/amd64
  Experimental:     true
```

**Output of `docker-compose config`**

```
ERROR: The Compose file './docker-compose.yml' is invalid because:
services.web.deploy.labels.one contains null, which is an invalid type, it should be a string
services.web.labels.one contains null, which is an invalid type, it should be a string
```


## Steps to reproduce the issue

Create a docker-compose.yml;

```yaml
version: ""3.4""
services:
  web:
    image: ""nginx:alpine""
    deploy:
      labels:
        one:
        two: """"
        three: ""three""
```

Deploy the project with `docker-compose`:

```bash
docker-compose up
ERROR: The Compose file './docker-compose.yml' is invalid because:
services.web.deploy.labels.one contains null, which is an invalid type, it should be a string
services.web.labels.one contains null, which is an invalid type, it should be a string
```

Deploy the same project through `docker stack deploy`:

```bash
docker stack deploy -c docker-compose.yml labels
Creating network labels_default
Creating service labels_web
```

Verify that the service was created successfully and has the labels set (output formatted with `jq` for readability);

```bash
docker service inspect labels_web --format '{{json .Spec.Labels}}'
{
  ""com.docker.stack.image"": ""nginx:alpine"",
  ""com.docker.stack.namespace"": ""labels"",
  ""one"": """",
  ""three"": ""three"",
  ""two"": """"
}
```

Verify that the service's container was created successfully and has the labels set

```bash
docker container inspect $(docker service ps labels_web --no-trunc --format '{{.Name}}.{{.ID}}') --format '{{json .Config.Labels}}'

{
  ""com.docker.stack.namespace"": ""labels"",
  ""com.docker.swarm.node.id"": ""y9gtufi5v9lih2fd3sx236oi5"",
  ""com.docker.swarm.service.id"": ""xvdcpdr56iemdg23ssoppmfho"",
  ""com.docker.swarm.service.name"": ""labels_web"",
  ""com.docker.swarm.task"": """",
  ""com.docker.swarm.task.id"": ""0ekknzh03es82tdpz8cctqhfd"",
  ""com.docker.swarm.task.name"": ""labels_web.1.0ekknzh03es82tdpz8cctqhfd"",
  ""maintainer"": ""NGINX Docker Maintainers <docker-maint@nginx.com>"",
  ""one"": """",
  ""three"": ""three"",
  ""two"": """"
}
```


### Observed result

The compose file is marked invalid

### Expected result

Docker Compose using `""""` (empty string) as default for labels


",,,thaJeztah,"
--
ping @ulyssessouza @chris-crone PTAL
--

--
.
--

--
.
--
",stale,"
--
This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you for your contributions.

--

--
This issue has been automatically marked as not stale anymore due to the recent activity.

--

--
This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you for your contributions.

--

--
This issue has been automatically marked as not stale anymore due to the recent activity.

--
",,,,,,,,
6527,OPEN,`logs` encoding is incorrect,,2020-12-01 12:13:32 +0000 UTC,ofek,In progress,,"## Description of the issue

`docker-compose logs` outputs as a Windows-specific encoding while `docker logs` properly outputs as `utf-8`

```
ofek.lev@OZONE C:\Users\ofek.lev\Desktop\code\integrations-core\riakcs\tests\compose
$ python
Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)] on win32
Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.
>>> import subprocess
>>> import sys
>>> print(sys.getdefaultencoding())
utf-8
>>> for line in subprocess.run('docker logs 9f3b1d3828a3', stdout=subprocess.PIPE).stdout.splitlines()[:2]: print(line)
...
b""Update data permissions in case it's mounted as volume\xe2\x80\xa6 OK!""
b'Starting Riak\xe2\x80\xa6 OK!'
>>> for line in subprocess.run('docker-compose logs --no-color', stdout=subprocess.PIPE).stdout.splitlines()[:3]: print(line)
...
b'Attaching to dd-test-riakcs'
b""dd-test-riakcs    | Update data permissions in case it's mounted as volume\x85 OK!""
b'dd-test-riakcs    | Starting Riak\x85 OK!'
>>> for line in subprocess.run('docker-compose logs --no-color', stdout=subprocess.PIPE, encoding='cp1252').stdout.splitlines()[:3]: print(line.encode())
...
b'Attaching to dd-test-riakcs'
b""dd-test-riakcs    | Update data permissions in case it's mounted as volume\xe2\x80\xa6 OK!""
b'dd-test-riakcs    | Starting Riak\xe2\x80\xa6 OK!'
```

## Context information (for bug reports)

**Output of `docker-compose version`**
```
docker-compose version 1.23.2, build 1110ad01
docker-py version: 3.6.0
CPython version: 3.6.6
OpenSSL version: OpenSSL 1.0.2o  27 Mar 2018
```

**Output of `docker version`**
```
Client: Docker Engine - Community
 Version:           18.09.2
 API version:       1.39
 Go version:        go1.10.8
 Git commit:        6247962
 Built:             Sun Feb 10 04:12:31 2019
 OS/Arch:           windows/amd64
 Experimental:      false

Server: Docker Engine - Community
 Engine:
  Version:          18.09.2
  API version:      1.39 (minimum version 1.12)
  Go version:       go1.10.6
  Git commit:       6247962
  Built:            Sun Feb 10 04:13:06 2019
  OS/Arch:          linux/amd64
  Experimental:     false
 Kubernetes:
  Version:          v1.10.11
  StackAPI:         v1beta2
```

**Output of `docker-compose config`**
```
services:
  dd-test-riakcs:
    container_name: dd-test-riakcs
    environment:
      RIACK_CS_BUCKET: foo
    image: ianbytchek/riak-cs
    ports:
    - published: 8080
      target: 8080
version: '3.5'
```

### Observed result

encoding (after much debugging to render `ellipsis` properly) is `cp1252`

### Expected result

encoding should be `utf-8`

## Additional information

Windows 10 pro, `docker-compose` installed via pip

cc @shin- 
",,,ofek,"
--
@shin- Do you why this may be happening, or of any workarounds for now?
--

--
Any update on this?
--

--
Still an issue
--
",andrewmed,"
--
I have the same issue with ""docker-compose logs"" when running docker-compose as a container
--
",stale,"
--
This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you for your contributions.

--

--
This issue has been automatically marked as not stale anymore due to the recent activity.

--
",0h41,"
--
Still an issue on compose v1.25.2
--
",Billy,"
--
I'm also experiencing this - compose v1.25.4 on OSX
--
",robermorales,"
--
+1
--
"
6522,OPEN,Implement condition or wait command to start service when other stop,format/v3; kind/feature; status/0-triage,2020-06-08 04:28:43 +0000 UTC,kenorb,In progress,,"**Is your feature request related to a problem? Please describe.**

Currently there is no reliable method to wait another service to exit. You can use `depends_on`, however it doesn't wait for the service to finish.
 
**Describe the solution you'd like**


The `docker` command have the following `wait` command:
```
$ docker wait --help

Usage:	docker wait CONTAINER [CONTAINER...]

Block until one or more containers stop, then print their exit codes
```
which can be used.

I believe introduction some `wait` command along with `depends_on` can solve the problem.

Another method is to implement negation to `service_healthy`, e.g.

```
service1:
    depends_on:
      service2:
        condition: !service_healthy
```
or `service_not_healthy` or `service_stopped` (as opposed to `service_started`)?

I think the better way is to extend `condition` with extra values which can make it possible.

But I've read [docs page](https://docs.docker.com/compose/compose-file/#depends_on) and it reads that ""Version 3 no longer supports the condition form of `depends_on`"", so I'm confused.

**Describe alternatives you've considered**

```
version: '3'
services:
  main:
    image: bash
    depends_on:
     - test01
     - test02
    command: bash -c ""sleep 2 && until ! ping -qc1 test01 && ! ping -qc1 test02; do sleep 1; done &>/dev/null""
    networks:
      intra:
        ipv4_address: 172.10.0.254
  test01:
    image: bash
    hostname: test01
    command: bash -c ""ip route && sleep 10""
    networks:
      intra:
        ipv4_address: 172.10.0.11
  test02:
    image: bash
    hostname: test02
    command: bash -c ""ip route && sleep 20""
    networks:
      intra:
        ipv4_address: 172.10.0.12
networks:
  intra:
    driver: bridge
    ipam:
      config:
      - subnet: 172.10.0.0/24
```

**Additional context**

Related posts:
- [Docker Compose wait for container X before starting Y](https://stackoverflow.com/q/31746182/55075)
- [How to start service when not healthy?](https://stackoverflow.com/q/54660990/55075)",,,stale,"
--
This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you for your contributions.

--

--
This issue has been automatically marked as not stale anymore due to the recent activity.

--
",kenorb,"
--
This issue has been automatically marked as active because it has recent activity.
--
",mirr254,"
--
Any development on this?
--
",iloveicedgreentea,"
--
They have repeatedly said they will not implement this. No idea why as its one of the most requested features... but oh well. condition: service_healthy was removed. You can use version 2.1 or something like wait-for-it.
--
",peters95,"
--
+1 for service_stopped condition
--
",,
6510,OPEN,Add support for docker --squash,kind/feature,2020-10-31 12:23:21 +0000 UTC,kiorky,Opened,,"Reopening of #4235, feel free to close and reopen the other.


**Is your feature request related to a problem? Please describe.**
squash is often needed to handle base image builds, see https://github.com/moby/moby/issues/38657 and the long list of --squash related bugs on moby tracker. A lot of us rely on it.

It would be nice to have a supported toggle in compose to enable the flag.
",,,mskoenz,"
--
I mention my comment in #4235 here too, since this is an open issue. At least to my search, many propose to just use multistage builds to compensate for the lack of squash, but the issue is that it does not seem possible to inherit CMD/ENTRYPOINT/USER/WORKDIR from the parent image we are multistage-""squashing"" (or I did not find the way to do it). A docker-compose build --squash option would be extremely helpful to make e.g. gitlab CI pipelines more efficient since pulling only a few layers seems to be faster due to less validation (and also the output is less cluttered with many hundered lines of docker pull output).

As a naive proposal:
```
...
    my_service:
        build:
            - squash: true #or 1 or whatever is the best yml const
```

Thx for all your work, docker-compose is awesome!

--
",,,,,,,,,,
6470,OPEN,Add bind mount exclusion to prevent overwriting generated files with local files,kind/feature,2019-01-21 17:50:57 +0000 UTC,steevehook,Opened,,"It's always annoying when I want to create a bind mount in order to synchronize `local` source code I'm editing, with `code from docker container` and all of the generated files.

Whether it's `vendor` directory or a `binary file` which eventually is used as an `ENTRYPOINT` or `CMD` they are getting removed when the bind mount is done.  And since these `files/directories` are not available on `local machine` to avoid copying different binaries for different OS & ARCH inside linux container, docker removes them inside container as well when binding the source from local with the one from container

A solution to this might be to to do the bind mount first then use the snapshot fs which was created when the image was build, which will first bind mount the sources then allow the scripts which generate the binaries/directories to execute without being removed

Another solution would be to indicate in the volumes section some sort of exclude list when binding mount for the first time, somethings that would look like this:

```yaml
volumes:
      - .:/usr/app:
          exclude:
            - fileA
            - fileB
            - dirA/
```

As a workaround to avoid this situation with volumes instead of running the generated binary in `CMD or ENTRYPOINT` we run some sort of `shell script` which generates again the binary and then executes the binary and now the `CMD/ENTRYPOINT` is `referencing` the `shell script`.
However would be a nice option with for initial bind mount some files which we choose would not be overwritten/removed in order to sync with local source code


docker-compose.yaml

```yaml
version: ""3.7""

services:
  redis:
    image: redis
    restart: always
    volumes:
      - redis-data:/data
    networks:
      - visits
    command: redis-server --appendonly yes
  visits-app:
    build: .
    restart: always
    ports:
      - ""8080:8080""
    volumes:
      - ./:/usr/app
    networks:
      - visits
    

    # if this custom command is missing then we get an error that there is no node_modules
    # but in Dockerfile we indeed genereated node_modules by running npm install
    command: sh /usr/app/init.sh

networks:
  visits:

volumes:
  redis-data:
```

init.sh

```bash
npm install
npm start
```

Dockerfile

```Dockerfile
FROM node:alpine

ENV PORT 8080

EXPOSE $PORT

WORKDIR /usr/app

COPY ./package.json ./
RUN npm install
COPY . .

CMD npm start
```

Thank you for the awesome project and let me know if such a feature is a valid one and does not come against docker philosophy or if you need any help in implementing it

",,,ulyssessouza,"
--
Thanks for the suggestion @steevehook !

One thing you can do is restructuring your source tree so that you can mount (in docker-compose.yml:18) just important part which is, lets say a `src` folder. Leading to something like `./:/usr/app/src` in the volume mounting line.

I think implementing volume exclusions could lead to awkward corner cases. 

If the mounting is for a performance issue then, looking at your `Dockerfile`, if you use `buildkit` your image layers should be cached until the `RUN npm install`.

--
",,,,,,,,,,
6443,OPEN,Allow running up without binding on ports.,,2019-01-16 14:53:22 +0000 UTC,pauldraper,Opened,,"**Is your feature request related to a problem? Please describe.**

Sometimes, I need to run multiple stacks for testing in parallel.

However, containers fail to launch if published ports conflict.

**Describe the solution you'd like**

I'd like `docker-compose up` to be able to run without publish ports. A `--service-ports=false` option.

**Describe alternatives you've considered**

I've considered using docker run, however it has other differences that make it not work, like not giving it a hostname on the network.

I've considered using `extends`, but that doesn't work with `depends_on` (https://github.com/docker/compose/issues/3220).

I've considered using YAML anchors but that still more verbose that I'd prefer for something as simple as choosing whether to publish ports or not.

I've considered removing ports with a override file, but that can't be done https://github.com/docker/compose/issues/3729

I've considered adding ports with a `docker-compose.override.yml` but I prefer that to be reserved for per-user edits, and I prefer to keep vanilla docker-compose working well.

**Additional context**

`docker-compose run` already has the `--service-ports` flag.",,,ulyssessouza,"
--
I would consider using [docker-app](https://github.com/docker/app).
More specifically, `docker-app render --set` option so you can replace fixed port by a variable, then you just have to run each of your stacks with different values.
--
",,,,,,,,,,
6438,OPEN,Tag based filtering,kind/feature,2019-01-22 09:38:43 +0000 UTC,willis7,Opened,,"-->

**Is your feature request related to a problem? Please describe.**
Yes. I want the ability to run combinations of containers in different situations. The examples below give some context.

**Describe the solution you'd like**
This is borrowed from Ansible:

> If you have a large playbook, it may become useful to be able to run only a specific part of it rather than running everything in the playbook. Ansible supports a tags: attribute for this reason.
When you execute a playbook, you can filter tasks based on tags in two ways:
> * On the command line, with the --tags or --skip-tags options
> * In Ansible configuration settings, with the TAGS_RUN and TAGS_SKIP options


```yaml
web:
  image: example/my_web_app:latest
  links:
    - db
    - cache
    - messaging
  tags:
    - test
    - dev

db:
  image: postgres:latest
  tags:
    - test
    - dev

cache:
  image: redis:latest
  tags:
    - cache

messaging:
  image: rabbitmq:latest
```

_Example 1_
`docker-compose -f docker-compose.yml --tags test --tags cache up -d`
In this example, `web`, `db` and `cache` will run, but not `messaging`.

_Example 2_
`docker-compose -f docker-compose.yml --skip-tags cache up -d`
In this example, `web`, `db` and `messaging` will run, but not `cache`.

_Example 3_
`docker-compose -f docker-compose.yml up -d`
Everything will run in this example.

**Describe alternatives you've considered**
https://docs.docker.com/compose/extends/#example-use-case

The above link provides an example of `extends` which is really neat, and to some extends achieves the same, but also comes with the tax of managing many files.  Having the information in one place is a lot more desirable for most engineers.

**Additional context**
Naiively, I think this could be an easy change. There is some dependency on the user ""getting it right"", but documentation will help here.

There will be subtleties with features such as `links` and how they are handled if flags are set. I also don't know the project well enough to say if this would be easy to integrate extends.

If this is something the team thinks is valuable, I would be happy to attempt this with some direction.
",,,,,,,,,,,,,,
6414,OPEN,Add --net to docker-compose run,area/run; kind/feature,2019-02-25 09:59:50 +0000 UTC,Yajo,In progress,,"-->

**Is your feature request related to a problem? Please describe.**
I use private networks for test and devel environments, where I want to inhibit external network connections except for some specific whitelisted hosts, by using the technique and image explained [here](https://github.com/Tecnativa/docker-whitelist#example).

It works safely and pretty well for those environments, but sometimes I still need to run some network-enabled commands, and there's no straight-forward solution.

**Describe the solution you'd like**
I'd love to be able to bind the container to networks when booting a new one with `run`, something like:

```bash
docker-compose run --rm --net public service command-that-requires-network-access
```

**Describe alternatives you've considered**
One is to define a specific `docker-compose.yml` file that is used only for those purposes, where the specific service is attached to the public network, although it is uncomfortable to maintain all of that code for such a specific and unusual task.

I end up doing:

1. `docker-compose down` to destroy networks
1. Edit `docker-compose.yml` and add the container I'm going to run to the public network.
1. `docker-compose run --rm service command-that-requires-network-access`
1. When finished, repeat step 1 and undo step 2",,,shin,"
--
Thanks for the suggestion @Yajo 

I think this has merit. There's some technical wrinkles we'd need to iron, e.g. does it add to the list of networks in the service definition or replace them entirely? Should you be able to specify options like aliases or IP address, and what would that look like on the CLI? 

FWIW, the way I'd work around this with current Compose would be to write a `public-networks.yml` file with just the additional network definition for each service, and run with `-f docker-compose.yml -f public-networks.yml` when needed. It's minimal maintenance and probably less tedious than the process you describe.
--
",Yajo,"
--
Usually those kind of flags append to the current defined list. For instance, `-v /host:/guest` adds a new volume to the list of already-defined volumes, so I guess that for consistency, it should be an added network. You could name the flag `--net-add`, just in case you want to be explicit and leave room for possible future enhancements.

Maybe that flag can support either just a name, or a json/yaml input with all details. Example:

```sh
# Just add container to network, with defaults
docker-compose run --net-add public service command-that-requires-network-access
# Allow extra configuration
docker-compose run --net-add '{""name"": ""public"", ""aliases"": [""a"",""b""]}' service command-that-requires-network-access
```

Just some ideas :blush: 
--

--
I'm thinking in annother idea: Just `--net public`.

It should add `public` to the list of networks, and in such case, a public network should exist in the `docker-compose.yml` file, so you can define it there with all of its configurations, and the `run` command only attaches the container to that additional network.
--
",,,,,,,,
6408,OPEN,Add `verify` command,area/events; kind/feature; kind/question,2018-12-13 19:53:11 +0000 UTC,trajano,In progress,,"-->

**Is your feature request related to a problem? Please describe.**

For CI, it would be good to verify that the docker-compose would work correctly.

**Describe the solution you'd like**

When I do `docker-compose verify` it does the same thing as `docker-compose up` and waits for the `healthcheck` to pass for all the services.  Once it passes, it runs `docker-compose down` to tear down the app.

Some other parameters to consider are:

* `--build` force a build even if it is not needed
* `--limit=60s` time limit before giving up on health checks to pass
* `--keep-up` keeps the services up after verifying.  This allows more complex integration tests to be executed after the healthchecks are up.

**Describe alternatives you've considered**

We create a separate test application that waits for the stack to come up and run our tests.

",,,shin,"
--
Thanks for the suggestion @trajano !

The way I look at it, this seems like a very specific scenario you want to introduce as a mainline command. I'd assume users would have wildly differing expectations of what a `verify` command would do and how it should behave, and as a result, I don't think it would be wise for us to attempt to introduce a solution to ""application checking"" that would only ever satisfy a small portion of our users. It also seems a bit out of scope for Compose. 

Note that the [`docker-compose events`](https://docs.docker.com/compose/reference/events/) command will inform you once a service becomes healthy, which can help you write a script or a program to do what you describe.
--
",trajano,"
--
NP we already have the ""tests"" for the Java apps using testcontainers.  However, for something simple I'd rather avoid all the harness that is needed.

But I'd rather see if there's any interest on this from other members before we just close it much like https://github.com/json-schema-org/json-schema-spec/issues/396 generated a lot of interest.
--
",,,,,,,,
6358,OPEN,Support for docker build --secret for build-time docker secrets.,area/build; kind/feature; status/0-triage,2020-05-22 08:24:26 +0000 UTC,mikhail-khodorovskiy,Opened,,"-->

**Is your feature request related to a problem? Please describe.**
https://medium.com/@tonistiigi/build-secrets-and-ssh-forwarding-in-docker-18-09-ae8161d066 described how to provide secret mounts available at build times.

> docker build --secret id=mysite.key,src=path/to/mysite.key .

Can be referenced during docker build:

> RUN --mount=type=secret,id=mysite.key,required <command-to-run>

docker compose build command: https://docs.docker.com/compose/compose-file/#build currently has no support for the secrets section

**Describe the solution you'd like**
build command should allow referencing the secrets defined in the same docker-compose file

**Describe alternatives you've considered**
The alternatives is to use secret-containing file contents as build arguments.  The solution is cumbersome since the secret has to be splatted so it can become available for Dockerfile commands which may cause it to become part of a docker layer, i.e it may leak the secret value.

**Additional context**
Add any other context or screenshots about the feature request here.
",,,ciaranmcnulty,"
--
This would be really useful - right now we're doing a `docker build` using the new option and matching the image name to the one that compose will generate, as part of a shell wrapper.

Native support would be great.
--

--
As a future-proofing measure it might be interesting to have a key that allows arbitrary CLI flags to be passed to `build`?

```
services:
  foo:
    build:
      context: .
      dockerfile: Dockerfile
      target: secure
      flags: '--secret id=mysite.key,src=path/to/mysite.key'
```
--

--
@yinzara flags attribute was to address next time this happens - a specific syntax for secrets would be best

We should also support:

```
services:
  foo:
    build:
        # ...
        ssh: default
```

--
",yinzara,"
--
Agree! SUPER useful especially in a setting where you're building artifacts that have to access private repositories of some sort. Nearly impossible to do without this.

While I would support the idea of a 'flags' attribute, I think because of the specifics of this feature, a real language element would be better.  Maybe make a separate feature request specifically for this.

```
services:
  foo:
    build:
      context: .
      dockerfile: Dockerfile
      target: secure
      secrets:
        -  id: mysite.key
           src: path/to/mysite.key
```

or possibly assuming there will never be other attributes to the command:
```
services:
  foo:
    build:
      context: .
      dockerfile: Dockerfile
      target: secure
      secrets:
        'mysite.key': path/to/mysite.key
```
--
",Legogris,"
--
Just supporting `--ssh` for `docker-compose run` would be great.
--
",chris,"
--
Thanks for the suggestion! This requires that we support BuildKit in the Python SDK, see the issue [here](https://github.com/docker/docker-py/issues/2230).
--

--
@mattsrobot There is now a PR to add BuildKit support to Docker Compose (see: https://github.com/docker/compose/pull/6865).

The approach of the PR is to exec out to the Docker CLI for build so we could pass flags there.
--
",mattsrobot,"
--
Has this ticket moved on, is there a way to use ssh secrets in docker compose?
--
",Teyras,"
--
@chris-crone I'm trying to do that, but I don't see how I could pass flags to the CLI from `docker-compose.yml`. Am I missing something?
--
"
6264,OPEN,Top-level/standalone image build specification,area/build; area/config; kind/feature; kind/question,2018-10-13 18:20:35 +0000 UTC,DrPyser,In progress,,"3. When making a bug report, make sure you provide all required information. The easier it is for
   maintainers to reproduce, the faster it'll be fixed.
-->

## Description of the issue

Is there any plan for/existing discussions around the idea of supporting a top-level `build` or `images` section to declare images to be built, independently of their use in any service?

Use cases might include:
* Specifying build options and ensuring the build of base images required by services
* Avoiding redundancy in service definitions when multiple services use the same image. This can currently be addressed by using a separate service block(with a dummy command override) to define the image build, and having other services using that image require that ""build"" service and specify only the image name. This is a non-ideal workaround.
* Using docker-compose simply as a tool for defining and orchestrating the build of docker images.

On that last use case, considering that `docker stack` seems to be going to replace docker-compose for the deployment and management of ""services"", but leaves out the problem of building the necessary images(specifying all options through a declarative configuration, along with build orchestration) to other tools, docker-compose could stay very useful as such a tool. In that optic, the orchestration and configuration of image builds would be done separately and independently from the orchestration and configuration of services, so it makes sense that they could be also specified separately and independently.

Thanks for your consideration.",,,shin,"
--
Thanks for the suggestion @DrPyser ! Please note that our stance has generally been to keep image/build management out of Compose, and focus primarily on running applications. See e.g. https://github.com/docker/compose/issues/6148#issuecomment-414469013 , https://github.com/docker/compose/issues/6093#issuecomment-406375210

As a result, it's unlikely such a feature would make it into the Compose format as currently designed. It may however be implemented in an external tool that supports a Compose-based workflow. In particular, using [extension fields](https://docs.docker.com/compose/compose-file/#extension-fields) would allow such top-level declarations to exist in a way that would allow these files to still be compatible with `docker-compose` and `docker stack` if desired.
--
",DrPyser,"
--
I see, thanks for the info. Do you have any suggestion for production-ready, open source tools that would be well suited for the use case of docker build management? 
--
",,,,,,,,
6180,OPEN,bridge DNS does not work when referencing a service alias as dns,area/networking; kind/question,2020-09-26 14:51:12 +0000 UTC,samrocketman,In progress,,"## Description of the issue

Referencing the `dns` key in YAML does not work when the value is a service alias of another container in the `docker-compose.yml` file.

Sample compose file.

```yaml
networks:
  internal:
     driver: bridge
services:
  dnsmasq:
    # ... some container configuration which should be reachable from the DNS host ""dnsmasq""
    networks:
      - internal
  my-service:
    # NOTE: setting DNS to docker-compose service alias does not work
    dns: dnsmasq
    networks:
      - internal
```

## Context information (for bug reports)

```
$ docker-compose version
docker-compose version 1.22.0, build f46880fe
docker-py version: 3.4.1
CPython version: 3.6.6
OpenSSL version: OpenSSL 1.1.0f  25 May 2017
```

```
$ docker version
Client:
 Version:           18.06.1-ce
 API version:       1.38
 Go version:        go1.10.3
 Git commit:        e68fc7a
 Built:             Tue Aug 21 17:24:56 2018
 OS/Arch:           linux/amd64
 Experimental:      false

Server:
 Engine:
  Version:          18.06.1-ce
  API version:      1.38 (minimum version 1.12)
  Go version:       go1.10.3
  Git commit:       e68fc7a
  Built:            Tue Aug 21 17:23:21 2018
  OS/Arch:          linux/amd64
  Experimental:     false
```

Broken config
https://github.com/samrocketman/docker-compose-ha-consul-vault-ui/blob/03ba4d1c5875e3b1c10d85425316ffa7d064ca74/docker-compose.yml


## Steps to reproduce the issue

1. `docker-compose run dns-troubleshoot`
2. `dig example.com`
3. `dig @dnsmasq example.com`

### Observed result

`dig example.com` fails with the following message:

```
/ # dig example.com
; <<>> DiG 9.10.4-P3 <<>> example.com
;; global options: +cmd
;; connection timed out; no servers could be reached

/ # cat /etc/resolv.conf
nameserver 127.0.0.11
options ndots:0
```

However, `dig @dnsmasq example.com` succeeds.

```
/ # dig @dnsmasq example.com

; <<>> DiG 9.10.4-P3 <<>> @dnsmasq example.com
; (1 server found)
;; global options: +cmd
;; Got answer:
;; ->>HEADER<<- opcode: QUERY, status: NOERROR, id: 4516
;; flags: qr rd ra; QUERY: 1, ANSWER: 1, AUTHORITY: 0, ADDITIONAL: 1

;; OPT PSEUDOSECTION:
; EDNS: version: 0, flags:; udp: 4096
;; QUESTION SECTION:
;example.com.			IN	A

;; ANSWER SECTION:
example.com.		4335	IN	A	93.184.216.34

;; Query time: 0 msec
;; SERVER: 172.19.0.2#53(172.19.0.2)
;; WHEN: Wed Sep 12 04:53:29 UTC 2018
;; MSG SIZE  rcvd: 56
```

### Expected result

I expect both `dig example.com` and `dig @dnsmasq example.com` to work the same way.

## Additional information

I installed `docker-compose` by downloading the go binary from GitHub releases and adding it to a location available in my `$PATH`.",,,samrocketman,"
--
It is desirable to use a custom dnsmasq container so that I can use consul DNS across all of my containers.  Example, here I look up DNS using consul DNS.

```
/ # dig @dnsmasq consul.service.consul

; <<>> DiG 9.10.4-P3 <<>> @dnsmasq consul.service.consul
; (1 server found)
;; global options: +cmd
;; Got answer:
;; ->>HEADER<<- opcode: QUERY, status: NOERROR, id: 1598
;; flags: qr aa rd ra; QUERY: 1, ANSWER: 3, AUTHORITY: 0, ADDITIONAL: 4

;; OPT PSEUDOSECTION:
; EDNS: version: 0, flags:; udp: 4096
;; QUESTION SECTION:
;consul.service.consul.		IN	A

;; ANSWER SECTION:
consul.service.consul.	0	IN	A	172.16.238.5
consul.service.consul.	0	IN	A	172.16.238.3
consul.service.consul.	0	IN	A	172.16.238.4

;; ADDITIONAL SECTION:
consul.service.consul.	0	IN	TXT	""consul-network-segment=""
consul.service.consul.	0	IN	TXT	""consul-network-segment=""
consul.service.consul.	0	IN	TXT	""consul-network-segment=""

;; Query time: 0 msec
;; SERVER: 172.16.238.2#53(172.16.238.2)
;; WHEN: Wed Sep 12 05:05:22 UTC 2018
;; MSG SIZE  rcvd: 206
```
--
, id: 1598
;; flags: qr aa rd ra; QUERY: 1, ANSWER: 3, AUTHORITY: 0, ADDITIONAL: 4

;; OPT PSEUDOSECTION:
; EDNS: version: 0, flags:; udp: 4096
;; QUESTION SECTION:
;consul.service.consul.		IN	A

;; ANSWER SECTION:
consul.service.consul.	0	IN	A	172.16.238.5
consul.service.consul.	0	IN	A	172.16.238.3
consul.service.consul.	0	IN	A	172.16.238.4

;; ADDITIONAL SECTION:
consul.service.consul.	0	IN	TXT	""consul-network-segment=""
consul.service.consul.	0	IN	TXT	""consul-network-segment=""
consul.service.consul.	0	IN	TXT	""consul-network-segment=""

;; Query time: 0 msec
;; SERVER: 172.16.238.2#53(172.16.238.2)
;; WHEN: Wed Sep 12 05:05:22 UTC 2018
;; MSG SIZE  rcvd: 206
```
--
author:	samrocketman
association:	none
edited:	false
status:	none
--
The only fix currently is to statically set the DNS and not use the `docker-compose` service name in the `dns` YAML key.

ref: https://github.com/samrocketman/docker-compose-ha-consul-vault-ui/commit/3b5f422dbf386056d1a11ba9e45de05a98a9487f

That is to say, the bug still exists but there's currently a workaround until it is fixed.
--

--
Hi @samrocketman 

As far as I can tell, the issue you're reporting is a Docker networking issue, not a Compose issue. If you concur, please open an issue on the [moby/moby](https://github.com/moby/moby/issues) tracker where it can more readily be addressed.
--
author:	samrocketman
association:	none
edited:	true
status:	none
--
I don't understand if it's a docker networking issue.  I've only seen docker-compose service aliases used in docker-compose as hostnames.  So I assumed it was this project.

I can copy my issue to moby/moby if that's what you think is appropriate.  I don't have the expertise to determine which project is appropriate to address the root cause of this issue.

Please let me know.
--

--
This is because a DNS server should be specified by IP-address, so using a name won't work (unless some step was added to resolve the IP based on the name, and use that).

There's a tracking issue for that in the cli repository; https://github.com/docker/cli/issues/385 (I think there's also one in the Moby repository, but I'd have to search for that)
--
author:	samrocketman
association:	none
edited:	true
status:	none
--
I understand that /etc/resolve.conf only takes IPs in Linux (and why that is).  My hope is that *docker-compose would resolve the DNS IP* from the compose service under the hood and do the right thing with it to expose the DNS automatically.

FWIW I have a workaround but its not ideal because I need to statically set the network and IP.

- set network https://github.com/samrocketman/docker-compose-ha-consul-vault-ui/blob/a91f37e57066cd8d662e7c614f9cc47279c194d2/docker-compose.yml#L5-L11
- set DNS server IP so that other containers can use it https://github.com/samrocketman/docker-compose-ha-consul-vault-ui/blob/a91f37e57066cd8d662e7c614f9cc47279c194d2/docker-compose.yml#L66-L68
- other containers configured to use the DNS https://github.com/samrocketman/docker-compose-ha-consul-vault-ui/blob/a91f37e57066cd8d662e7c614f9cc47279c194d2/docker-compose.yml#L100-L102

In case someone finds it useful.
--

--
This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you for your contributions.

--
author:	samrocketman
association:	none
edited:	false
status:	none
--
This is still desirable so should not be stale IMO.
--

--
This issue has been automatically marked as not stale anymore due to the recent activity.

--
author:	samrocketman
association:	none
edited:	false
status:	none
--
This is still desirable so should not be stale IMO.
--

--
This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you for your contributions.

--
author:	samrocketman
association:	none
edited:	false
status:	none
--
This is still desirable so should not be stale IMO.
--

--
This issue has been automatically marked as not stale anymore due to the recent activity.

--
author:	samrocketman
association:	none
edited:	true
status:	none
--
@shin- can we remove the `kind/question` label?  This is not a question.  It is a docker-compose enhancement request originally reported as a bug since it made intuitive sense. Considering most things can be referenced by service name in the compose file it made sense you should be able to do the same in the DNS field and have docker-compose translate that to the service IP.

I feel like `kind/question` makes this issue not an obvious feature request so it has been overlooked for 2 years.

# Why this is a docker-compose issue

docker-compose has some glue logic which makes using docker easy.  For example, if you reference a service name `foo` there is no such reference in the docker daemon.  docker-compose translates foo into a docker container (or group of docker containers) in dockerd backend.

The syntax exposed by docker-compose should support **docker-compose services** in the same way that the docker-compose syntax supports **docker-compose services** in other fields.  To put another way, the brief syntax in docker-compose translates into API calls on the dockerd backend.  This translation should occur for the service name in the DNS field.
--
",shin,"
--
The only fix currently is to statically set the DNS and not use the `docker-compose` service name in the `dns` YAML key.

ref: https://github.com/samrocketman/docker-compose-ha-consul-vault-ui/commit/3b5f422dbf386056d1a11ba9e45de05a98a9487f

That is to say, the bug still exists but there's currently a workaround until it is fixed.
--
author:	shin-
association:	contributor
edited:	false
status:	none
--
Hi @samrocketman 

As far as I can tell, the issue you're reporting is a Docker networking issue, not a Compose issue. If you concur, please open an issue on the [moby/moby](https://github.com/moby/moby/issues) tracker where it can more readily be addressed.
--
",chizou,"
--
I don't understand if it's a docker networking issue.  I've only seen docker-compose service aliases used in docker-compose as hostnames.  So I assumed it was this project.

I can copy my issue to moby/moby if that's what you think is appropriate.  I don't have the expertise to determine which project is appropriate to address the root cause of this issue.

Please let me know.
--
author:	chizou
association:	none
edited:	false
status:	none
--
I'd like to see this issue get resolved as well. Is there an update on whether this is actually a docker-compose issue or does a new issue need to be filed with Docker? If it does need to be filed with moby/moby, can someone with an understanding of why it's a moby/moby issue expand upon it so we can file it correctly? Thanks.
--

--
I understand that /etc/resolve.conf only takes IPs in Linux (and why that is).  My hope is that *docker-compose would resolve the DNS IP* from the compose service under the hood and do the right thing with it to expose the DNS automatically.

FWIW I have a workaround but its not ideal because I need to statically set the network and IP.

- set network https://github.com/samrocketman/docker-compose-ha-consul-vault-ui/blob/a91f37e57066cd8d662e7c614f9cc47279c194d2/docker-compose.yml#L5-L11
- set DNS server IP so that other containers can use it https://github.com/samrocketman/docker-compose-ha-consul-vault-ui/blob/a91f37e57066cd8d662e7c614f9cc47279c194d2/docker-compose.yml#L66-L68
- other containers configured to use the DNS https://github.com/samrocketman/docker-compose-ha-consul-vault-ui/blob/a91f37e57066cd8d662e7c614f9cc47279c194d2/docker-compose.yml#L100-L102

In case someone finds it useful.
--
author:	chizou
association:	none
edited:	false
status:	none
--
> My hope is that docker-compose would resolve the DNS IP from the compose service under the hood and do the right thing with it to expose the DNS automatically.

This is exactly what I'd like to see as well. Hardcoding IP addresses for this specific purpose is less than ideal. 
--
",thaJeztah,"
--
I'd like to see this issue get resolved as well. Is there an update on whether this is actually a docker-compose issue or does a new issue need to be filed with Docker? If it does need to be filed with moby/moby, can someone with an understanding of why it's a moby/moby issue expand upon it so we can file it correctly? Thanks.
--
author:	thaJeztah
association:	member
edited:	false
status:	none
--
This is because a DNS server should be specified by IP-address, so using a name won't work (unless some step was added to resolve the IP based on the name, and use that).

There's a tracking issue for that in the cli repository; https://github.com/docker/cli/issues/385 (I think there's also one in the Moby repository, but I'd have to search for that)
--
",Veitor,"
--
> My hope is that docker-compose would resolve the DNS IP from the compose service under the hood and do the right thing with it to expose the DNS automatically.

This is exactly what I'd like to see as well. Hardcoding IP addresses for this specific purpose is less than ideal. 
--
author:	Veitor
association:	none
edited:	true
status:	none
--
I had the same problem.

And I thought about another solution. This solution is only available for nginx container:
```nginx
version: '3'
services:
  openresty:
    image: openresty/openresty:1.13.6.2-alpine
    volumes:
      - ./nginx.conf:/usr/local/openresty/nginx/conf/nginx.conf
    ports:
      - 80:80
    dns:
      - 127.0.0.1
    links:
      - dns-server
  dns-server:
    image: jpillora/dnsmasq
    cap_add:
      - NET_ADMIN
    ports:
      - 53:53/tcp
      - 8080:8080
```

`nginx.conf` has such a code snippet:
```nginx
stream {
    upstream dns {
        server dns-server:53;
    }

    server{
        listen 53 udp;
        proxy_connect_timeout 1s;
        proxy_pass dns;
    }
}
```


--
",stale,"
--
I had the same problem.

And I thought about another solution. This solution is only available for nginx container:
```nginx
version: '3'
services:
  openresty:
    image: openresty/openresty:1.13.6.2-alpine
    volumes:
      - ./nginx.conf:/usr/local/openresty/nginx/conf/nginx.conf
    ports:
      - 80:80
    dns:
      - 127.0.0.1
    links:
      - dns-server
  dns-server:
    image: jpillora/dnsmasq
    cap_add:
      - NET_ADMIN
    ports:
      - 53:53/tcp
      - 8080:8080
```

`nginx.conf` has such a code snippet:
```nginx
stream {
    upstream dns {
        server dns-server:53;
    }

    server{
        listen 53 udp;
        proxy_connect_timeout 1s;
        proxy_pass dns;
    }
}
```


--
author:	stale
association:	none
edited:	false
status:	none
--
This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you for your contributions.

--

--
This is still desirable so should not be stale IMO.
--
author:	stale
association:	none
edited:	false
status:	none
--
This issue has been automatically marked as not stale anymore due to the recent activity.

--

--
Same issue. I expect this behaviour as well.
--
author:	stale
association:	none
edited:	false
status:	none
--
This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you for your contributions.

--

--
This is still desirable so should not be stale IMO.
--
author:	stale
association:	none
edited:	false
status:	none
--
This issue has been automatically marked as not stale anymore due to the recent activity.

--
"
6159,OPEN,Add labels in docker-compose up,area/up; kind/feature,2020-09-14 13:59:39 +0000 UTC,xlf12,In progress,,"Currently all CLI (docker or docker-compose) commands have the possibility to overwrite via the switch `-l` or `--label` the labels of the services/containers to run or volumes/networks to create.  The `docker-compose up` does not have such an option. 

See for example [Add labels in docker-compose run #4937](https://github.com/docker/compose/issues/4937) where such an option was added for `docker-compose run`

## One Use case
If we start a docker-compose stack on a swarm multiple times, then different labels can be used to identify the started services/containers. 
Adding the labels at command line level would free us from knowing any insights of what we started and free us from changing the compose file. 
We can for example run several docker-compose stacks multiple times in a CI test scenario. On an error situation we can simply enforce by filtering by labels that what ever had been tested (container, services, volumes, networks, etc.) is removed from the swarm.

## Version
```
docker-compose version 1.22.0, build f46880fe
docker-py version: 3.4.1
CPython version: 3.6.6
OpenSSL version: OpenSSL 1.0.2o  27 Mar 2018
```",,,jewertow,"
--
I would be very happy if I could take care of it, but I need information from the maintainer, if anyone is already working on it. And if you want, give me some hints. 
--
",bkanuka,"
--
@jewertow It may be helpful to look at this MR: https://github.com/docker/compose/pull/5397  which implemented the label for `docker-compose run`.

In the meantime, and as a workaround, you can pass a label using an environment variable and variable substitution in the docker-compose file.
--
",xlf12,"
--
Well, yeah, fine. I didn't think to do it that way. It's a workaround. Although the command-line version would be nice, as it doesn't force us to write our composed files for specific use cases. 
--
",emmm,"
--
Is there really no way to assign a label using docker-compose? Came here looking how to do it since I have some filters on labels that I would like to assign to a docker-compose stack. Would really like this functionality. 
--
",cristianrgreco,"
--
Just hit this issue in 2020, could this year get any worse? My use case is I want to be able to automatically clean up resources created by a given docker-compose. To achieve this I want to tag all resources (containers/volumes/networks) with a given label so I can track and remove them later, something like `docker-compose -l custom=true up` would be great
--
",,
6026,OPEN,Feature Request: Provide --quiet option to 'up' command,area/up; kind/feature,2021-02-11 15:33:59 +0000 UTC,ulope,Opened,,"## Description of the issue

There is currently no way to prevent the `up` command from producing extraneous (i.e. 'meta' messages, not produced by the service being run) output.
Supposedly `--log-level` can be used to suppress unwanted output but unfortunately, this has no effect on `up` (it looks like there are quite a few uses of `print()` in the cli layer which of course isn't affected by log levels). 

Example:

```
~$ docker-compose --log-level CRITICAL up service
Starting someproject_service_1 ... done
Attaching to someproject_service_1
someproject_service_1 exited with code 0
```

### Observed result

`up` always produces 'meta'-output.

### Expected result

To have an option of preventing `up` from generating meta output.

## Additional information

```
docker-compose version 1.21.2, build a133471
docker-py version: 3.3.0
CPython version: 3.6.5
OpenSSL version: OpenSSL 1.1.0g  2 Nov 2017
```",,,BEllis,"
--
With this PR, you can to do,
```bash
docker-compose --log-level ERROR up -q -d
```

--
",bibendi,"
--
What is the state of this issue?
--

--
Looks like the Parallel ""logger"" doesn't respect logging level
https://github.com/docker/compose/blob/40b0ce3e5d196dd8cbc8b692be45d2a761e867b1/compose/cli/main.py#L130-L142
--
",wsw70,"
--
using `--log-level ERROR` disables actual output from the command:

```
root@srv ~# docker-compose -f /etc/docker/docker-compose.yaml  --compatibility up -d jackett
WARNING: The Docker Engine you're using is running in swarm mode.

Compose does not use swarm mode to deploy services to multiple nodes in a swarm. All containers will be scheduled on the current node.

To deploy your application across the swarm, use `docker stack deploy`.

WARNING: Found orphan containers (hass, lightswitch) for this project. If you removed or renamed this service in your compose file, you can run this command with the --remove-orphans flag to clean it up.
jackett is up-to-date

root@srv ~# docker-compose -f /etc/docker/docker-compose.yaml --log-level ERROR --compatibility up -d jackett
root@srv ~#
```

The warnings were correctly silenced but the output (`jackett is up-to-date`) was also discarded.
--
",bemeyert,"
--
My `docker-compose` is not silenced:
```
$ docker-compose --version
docker-compose version 1.24.1, build unknown

$ docker-compose --log-level ERROR up --detach --quiet-pull 1>/dev/null
Creating curl_es_1     ... done
Creating curl_api_1    ... done
Creating curl_netcat_1 ... done

$ docker-compose --log-level ERROR down -v 1>/dev/null
Stopping curl_netcat_1 ... done
Stopping curl_es_1     ... done
Stopping curl_api_1    ... done
Removing curl_netcat_1 ... done
Removing curl_es_1     ... done
Removing curl_api_1    ... done
```
This makes the output of tests hard to handle and read. Is there any way this can be fixed? That would be great. Thx
--
",Vanav,"
--
`restart` command can't output only errors too:
```
# docker-compose --log-level CRITICAL --no-ansi -f test-compose.yml restart test-service > /dev/null
Restarting compose_test-service_1 ... 
Restarting compose_test-service_1 ... done
```
--
",lifenautjoe,"
--
Any update on this? :-(
--
"
5842,OPEN,docker-compose fails with invalid volume specification,,2020-12-10 20:40:56 +0000 UTC,uglydawg,In progress,,"## Description of the issue
docker-compose fails with invalid volume specification

## Context information (for bug reports)
Output of ""docker-compose version""
PS C:\temp> docker-compose --version
docker-compose version 1.20.1, build 5d8c71b2

Output of ""docker version""
PS C:\temp> docker --version
Docker version 18.03.0-ce, build 0520e24

Output of ""docker-compose config""
PS C:\temp> docker-compose config
networks:
  default:
    external: true
    name: nat
services:
  test:
    image: microsoft/windowsservercore
    volumes:
    - /c/temp:/data:rw
version: '3.6'


## Steps to reproduce the issue
PS C:\temp> docker-compose -f c:\temp\docker-compose.yml up --build
Creating temp_test_1 ... error

ERROR: for temp_test_1 Cannot create container for service test: invalid volume specification: '/c/temp:/data:rw'

ERROR: for test Cannot create container for service test: invalid volume specification: '/c/temp:/data:rw'
ERROR: Encountered errors while bringing up the project.

### Observed result
Expected to build image with volume mapped.

### Expected result
Error: invalid volume specification

### Stacktrace / full error message
[18:26:01.536][WindowsDaemon  ][Info   ] debug: FIXME: Got an API for which error does not match any expected type!!!: invalid volume specification: '/c/temp:/data:rw'
github.com/docker/docker/volume.errInvalidSpec
	/go/src/github.com/docker/docker/volume/volume.go:230
github.com/docker/docker/volume.windowsSplitRawSpec
	/go/src/github.com/docker/docker/volume/windows_parser.go:87
github.com/docker/docker/volume.(*windowsParser).parseMountRaw
	/go/src/github.com/docker/docker/volume/windows_parser.go:305
github.com/docker/docker/volume.(*windowsParser).ParseMountRaw
	/go/src/github.com/docker/docker/volume/windows_parser.go:301
github.com/docker/docker/daemon.(*Daemon).registerMountPoints
	/go/src/github.com/docker/docker/daemon/volumes.go:146
github.com/docker/docker/daemon.(*Daemon).setHostConfig
	/go/src/github.com/docker/docker/daemon/container.go:215
github.com/docker/docker/daemon.(*Daemon).create
	/go/src/github.com/docker/docker/daemon/create.go:173
github.com/docker/docker/daemon.(*Daemon).containerCreate
	/go/src/github.com/docker/docker/daemon/create.go:75
github.com/docker/docker/daemon.(*Daemon).ContainerCreate
	/go/src/github.com/docker/docker/daemon/create.go:34
github.com/docker/docker/api/server/router/container.(*containerRouter).postContainersCreate
	/go/src/github.com/docker/docker/api/server/router/container/container_routes.go:468
github.com/docker/docker/api/server/router/container.(*containerRouter).(github.com/docker/docker/api/server/router/container.postContainersCreate)-fm
	/go/src/github.com/docker/docker/api/server/router/container/container.go:47
github.com/docker/docker/api/server/middleware.ExperimentalMiddleware.WrapHandler.func1
	/go/src/github.com/docker/docker/api/server/middleware/experimental.go:27
github.com/docker/docker/api/server/middleware.VersionMiddleware.WrapHandler.func1
	/go/src/github.com/docker/docker/api/server/middleware/version.go:62
github.com/docker/docker/pkg/authorization.(*Middleware).WrapHandler.func1
	/go/src/github.com/docker/docker/pkg/authorization/middleware.go:59
github.com/docker/docker/api/server/middleware.DebugRequestMiddleware.func1
	/go/src/github.com/docker/docker/api/server/middleware/debug.go:53
github.com/docker/docker/api/server.(*Server).makeHTTPHandler.func1
	/go/src/github.com/docker/docker/api/server/server.go:137
net/http.HandlerFunc.ServeHTTP
	/usr/local/go/src/net/http/server.go:1918
github.com/docker/docker/vendor/github.com/gorilla/mux.(*Router).ServeHTTP
	/go/src/github.com/docker/docker/vendor/github.com/gorilla/mux/mux.go:103
github.com/docker/docker/api/server.(*routerSwapper).ServeHTTP
	/go/src/github.com/docker/docker/api/server/router_swapper.go:29
net/http.serverHandler.ServeHTTP
	/usr/local/go/src/net/http/server.go:2619
net/http.(*conn).serve
	/usr/local/go/src/net/http/server.go:1801
runtime.goexit
	/usr/local/go/src/runtime/asm_amd64.s:2337 [module=api error_type=*errors.fundamental](if applicable)
```

## Additional information

OS version / distribution, `docker-compose` install method, etc.
Windows 10 Pro
Installed with Docker for Windows",,,shin,"
--
You probably need to unset COMPOSE_CONVERT_WINDOWS_PATHS in your environment
--

--
Oh, sorry, did you actually write your mount like this? `/c/temp:/data:rw`
If so, you need to rewrite it correctly: `C:\temp:/data:rw`
--
",uglydawg,"
--
I don't see COMPOSE_CONVERT_WINDOWS_PATHS set anywhere. I manually set it to 0 and it still fails.
--

--
I have tried just about every possible combination. The volume mapping works correctly when using just docker. 
--
",keskarshreesh,"
--
I'm facing the same issue for docker-compose up

--
",kaushikdasroy,"
--
any solution to this, facing same issue
--
",talamus,"
--
Same problem here, OS is Win10 and software is the newest version.

I think this is something that used to work when Docker for Windows had the ""Shared Drives"" setup screen: ![d4w-shared-drives](https://user-images.githubusercontent.com/1710153/42376731-ee8e441e-8128-11e8-996b-4c3ba0cd3f49.png)
That setup screen does not exist anymore.

Anyhow, ""docker run"" works fine with volumes. It is the ""docker-compose up"" that breaks down with ""invalid volume specification"" error.
--

--
Okay, so it seems to work after all, kind of.
I am using Windows containers, and they are bit different in every possible way...

If I create a volume in Dockerfile:
```
FROM microsoft/nanoserver
SHELL [""powershell.exe"", ""-Command""]
VOLUME C:/volume
```

And then use it in docker-compose.yaml:
```
version: ""3""
services:
  localnano:
    build: .
    volumes:
      - testvolume:C:/volume
volumes:
  testvolume:
```

The files do start to appear in here:
```
PS> ls (docker volume inspect composer_testvolume --format '{{.Mountpoint}}')
```
BUT I cannot change the location freely, because of this:
https://github.com/sixeyed/docker-windows-kb/blob/master/1.13/limitations/volumes/driver-opts-not-supported.md

(I think it would really help if someone would re-write the docker-compose tutorial to be Windows compliant, or create a separate ""Windows Errata"" to list all the tiny differences...)

(And it would be really nice if `docker-compose` would say something like ""the Windows platform does not support volume options"" instead of ""invalid volume specification""...)
--
",usbook,"
--
today I encountered the same problem today and it took a long time to solve him.I am loading Docker for Windows.First convert docker to switch to linux containers, then set the volume in the settings, then vs re-add docker support, it will be solved

--
"
5730,OPEN,"add --timestamps option for ""up"" command",area/cli; area/up; kind/feature,2020-12-18 03:06:30 +0000 UTC,ggmod,Opened,,"It would be great to have a `--timestamps` option for the ""up"" command, similarly to how the ""logs"" command handles it, displaying the timestamp for each line of log message. I've found the ""up"" command's output to be much more practical than the ""logs"" command for monitoring the app during development, and also for streaming the aggregated logs of the latest run into a file, but unfortunately the timestamps are missing.",,,shin,"
--
Thanks for the suggestion ; I think it's something we can consider.
--
",mraxus,"
--
Is this still on the agenda for the near future?
Would love to have this feature as it makes for a nice work flow, like @ggmod explained :)
--
",jamesgoodhouse,"
--
Just thought I'd bump this as it seems like a great feature.
--
",MadDamDam,"
--
Would be especially useful for docker-compose run.
If used with --rm logs are not available after the run so i often use it with output redirection.
OP's suggestion will allow to easily get timestamps on the output.
--
",stephan,"
--
Still useful. Please implement. It's a nice little summer project ;)
--
",urig,"
--
@shin- I'd love to try and get this done if it's open to first time contributors. I've tried finding where the `--timestamps` option is parsed for the `logs` command but didn't succeed. Can someone point me in the right direction? TX
--
"
5613,OPEN,Docker Compose does not support defining port ranges in long form.,area/config; format/v3; kind/question,2020-12-16 18:01:30 +0000 UTC,estenrye,In progress,,"# Issue
docker-compose file format does not support a method of declaring port ranges in the long form syntax defined here: https://docs.docker.com/compose/compose-file/#long-syntax-1

# Steps to Reproduce
## docker-compose.yml:
```yaml
version: '3.4'
services:
  helloWorld:
    image: hello-world
    ports:
      - target: 9900-9999
        published: 9900-9999
        protocol: tcp
        mode: host
```
## command executed:
`docker-compose -f ./docker-compose.yml config`
`docker-comopse -f ./docker-compose.yml up -d`

# Expected Output:
```
PS D:\issue> docker-compose -f ./docker-compose.yml config
services:
  helloWorld:
    image: hello-world
    ports:
      - target: 9900-9999
        published: 9900-9999
        protocol: tcp
        mode: host
version: '3.4'
PS D:\issue> docker-compose -f ./docker-compose.yml up -d
<ContainerId>
```

# Actual Output:
```
PS D:\issue> docker-compose -f ./docker-compose.yml config
Traceback (most recent call last):
  File ""docker-compose"", line 6, in <module>
  File ""compose\cli\main.py"", line 71, in main
  File ""compose\cli\main.py"", line 118, in perform_command
  File ""compose\cli\main.py"", line 304, in config
  File ""compose\cli\command.py"", line 47, in get_config_from_options
  File ""compose\config\config.py"", line 375, in load
  File ""compose\config\config.py"", line 506, in process_config_file
  File ""compose\config\config.py"", line 497, in interpolate_config_section
  File ""compose\config\interpolation.py"", line 44, in interpolate_environment_variables
  File ""compose\config\interpolation.py"", line 44, in <genexpr>
  File ""compose\config\interpolation.py"", line 39, in process_item
  File ""compose\config\interpolation.py"", line 39, in <genexpr>
  File ""compose\config\interpolation.py"", line 54, in interpolate_value
  File ""compose\config\interpolation.py"", line 77, in recursive_interpolate
  File ""compose\config\interpolation.py"", line 74, in recursive_interpolate
  File ""compose\config\interpolation.py"", line 74, in <genexpr>
  File ""compose\config\interpolation.py"", line 70, in recursive_interpolate
  File ""compose\config\interpolation.py"", line 184, in convert
  File ""compose\config\interpolation.py"", line 141, in to_int
ValueError: invalid literal for int() with base 0: '9900-9999'
Failed to execute script docker-compose
PS D:\issue> docker-compose -f ./docker-compose.yml up -d
Traceback (most recent call last):
  File ""docker-compose"", line 6, in <module>
  File ""compose\cli\main.py"", line 71, in main
  File ""compose\cli\main.py"", line 121, in perform_command
  File ""compose\cli\command.py"", line 37, in project_from_options
  File ""compose\cli\command.py"", line 91, in get_project
  File ""compose\config\config.py"", line 375, in load
  File ""compose\config\config.py"", line 506, in process_config_file
  File ""compose\config\config.py"", line 497, in interpolate_config_section
  File ""compose\config\interpolation.py"", line 44, in interpolate_environment_variables
  File ""compose\config\interpolation.py"", line 44, in <genexpr>
  File ""compose\config\interpolation.py"", line 39, in process_item
  File ""compose\config\interpolation.py"", line 39, in <genexpr>
  File ""compose\config\interpolation.py"", line 54, in interpolate_value
  File ""compose\config\interpolation.py"", line 77, in recursive_interpolate
  File ""compose\config\interpolation.py"", line 74, in recursive_interpolate
  File ""compose\config\interpolation.py"", line 74, in <genexpr>
  File ""compose\config\interpolation.py"", line 70, in recursive_interpolate
  File ""compose\config\interpolation.py"", line 184, in convert
  File ""compose\config\interpolation.py"", line 141, in to_int
ValueError: invalid literal for int() with base 0: '9900-9999'
Failed to execute script docker-compose
```

# Docker Version
```
PS D:\issue> docker version
Client:
 Version:       17.12.0-ce
 API version:   1.35
 Go version:    go1.9.2
 Git commit:    c97c6d6
 Built: Wed Dec 27 20:05:22 2017
 OS/Arch:       windows/amd64

Server:
 Engine:
  Version:      17.12.0-ce
  API version:  1.35 (minimum version 1.24)
  Go version:   go1.9.2
  Git commit:   c97c6d6
  Built:        Wed Dec 27 20:15:52 2017
  OS/Arch:      windows/amd64
  Experimental: true
```

# Docker-Compose Version
```
D:\issue> docker-compose version
docker-compose version 1.18.0, build 8dd22a96
docker-py version: 2.6.1
CPython version: 2.7.14
OpenSSL version: OpenSSL 1.0.2k  26 Jan 2017
```

# Observations
- docker-compose only accepts a single port in long form syntax.
- docker currently appears to only support a single port in long form syntax.  See https://github.com/moby/moby/issues/32551
```
PS D:\issue> docker run -p mode=host,target=9900-9999,published=9900-9999,protocol=tcp -d hello-world
C:\Program Files\Docker\Docker\Resources\bin\docker.exe: Invalid containerPort: mode=host,target=9900-9999,published=9900-9999,protocol=tcp.
See 'C:\Program Files\Docker\Docker\Resources\bin\docker.exe run --help'.
```

# Impacts
- Customers with needs to define a large range of port bindings must declare each port individually if they need to use the long form syntax.  This is burdensome and I would prefer to see parity between the long and short form syntax.

# Workaround
- Customers who do not need to use the long form syntax can use the short form syntax to declare a range of ports.
- Customers who must use the long form syntax, to control which protocol is used or to bind the ports on the ingress network when deploying to swarm, need to declare each port individually in their compose files.

",,,shin,"
--
The error message should be improved in the next release.

As for actually supporting port ranges, the v3 format would need to be updated first - these changes happen at the [docker/cli](https://github.com/docker/cli) level, then get ported to `docker-compose`. Please open an issue there.
--

--
> It also does not support not stating which port published should be used.

Actually, you can do that by not stating which port to publish, e.g.

```yaml
version: '3.5'
services:
  foo:
    image: busybox
    ports:
      - target: 9900
        protocol: udp
```
--
",estenrye,"
--
@shin- got it, will do
--

--
@christopher-coffin This feature request can't be completed until the CLI supports the functionality.

If you go Thumbs Up this issue, it might get some traction?
https://github.com/docker/cli/issues/839
--
",MetalArend,"
--
It also does not support not stating which port published should be used. It would be useful to be able to say `published: *`.
--

--
I found out what I did wrong: using `mode: host` without a published port does not show the port on portainer service overview. Did not mean to hijack the topic.
--
",christopher,"
--
I'm running into this issue as well. Are there any updates on this?
--
",hugmoro,"
--
> This feature request can't be completed until the CLI supports the functionality.

[I think the CLI does support it now](https://github.com/docker/cli/issues/839#issuecomment-500136821)


--

--
It'd be a bit sad to see this issue closed for inactivity, so here's a comment reasserting that [the CLI supports the necessary syntax](https://github.com/docker/cli/issues/839#issuecomment-500136821), the upstream issue should be closed to clarify this.
--
",stale,"
--
This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you for your contributions.

--

--
This issue has been automatically marked as not stale anymore due to the recent activity.

--
"
5523,OPEN,docker-compose copy file or directory to container,kind/feature; status/0-triage,2021-02-06 03:49:35 +0000 UTC,,Opened,,"we miss a possibility to copy a file or directory using docker-compose. I find this really useful.
Please check many **+1** in premature closed https://github.com/docker/compose/issues/2105",,,shin,"
--
What's the usecase? Most of the suggested usage I've seen were antipatterns.
--
author:	
association:	none
edited:	false
status:	none
--
You can see some of many usecases clicking at link provided. As you can see many of subscribers consider it as really useful feature instead of ""antipattern""
--
author:	
association:	none
edited:	false
status:	none
--
ooops, now I see ""something"" happened to issue #2105 as there are no comments at all anymore...
Perhaps I provided wrong link...
--
author:	
association:	none
edited:	false
status:	none
--
so, I find really useful to copy some configuration/initialization files to container. As example some *.sql stuff for db containers, some html/js/css content for apache/nginx containers or even jar file for java container. This will make it available/runnable ""globally"" not only on machine where it was composed as in case of mounting volume(s). Mainly this will be some combination of host-local and container-contained files. In fact any container can be considered useless without any configuration or initialization

this is correct link: https://github.com/docker/compose/issues/1664
--

--
ooops, now I see ""something"" happened to issue #2105 as there are no comments at all anymore...
Perhaps I provided wrong link...
--
author:	
association:	none
edited:	false
status:	none
--
so, I find really useful to copy some configuration/initialization files to container. As example some *.sql stuff for db containers, some html/js/css content for apache/nginx containers or even jar file for java container. This will make it available/runnable ""globally"" not only on machine where it was composed as in case of mounting volume(s). Mainly this will be some combination of host-local and container-contained files. In fact any container can be considered useless without any configuration or initialization

this is correct link: https://github.com/docker/compose/issues/1664
--
author:	ukbe-aurea
association:	none
edited:	false
status:	none
--
+1
--
author:	shin-
association:	contributor
edited:	false
status:	none
--
> This will make it available/runnable ""globally"" not only on machine where it was composed as in case of mounting volume(s)

The problem with this is that it is incredibly short-sighted (hence the term ""anti-pattern""), as it will force you to repeat the operation every time the containers to be recreated. Not to mention the fact that it scales very poorly (what if you have 10 containers? 20? 100?)

The actual solution to your issue is to include those necessary files in your build (Dockerfile) and rebuild when an update is needed.
--
author:	
association:	none
edited:	false
status:	none
--
of course, if it is composed including all ""shared"" content into container, scaling 10-20-100- containers would be much easier. Everything you need is to pull it from repository and mount(yes, in this case mount) only node-specific config. And even more, you don't need run docker-compose on each node.
Sure we can use docker-compose in combination with build: & Dockerfile, however things  become little more complex and yaml configuration in docker-compose is much more ""elegant"" :o)
--

--
@harpratap you are right, but the drawback is that /folder_in_container must not exist or must be empty or else it will be overwritten.  If you have a bash script as your entry point, you could circumvent this by symlinking your files into the originally intended directory after you create a volume at /some_empty_location

+1 for having a COPY functionality.  Our use case is for rapidly standing up local development environments and copying in configs for the dev settings.
--
author:	djelroy
association:	none
edited:	false
status:	none
--
+1 for COPY. This would really be a helpful feature.

Use case: in swarm mode, I have a service using mysql image. I need to copy my initialization scripst in /docker-entrypoint-initdb.d/ so that MySQL can execute them.

Though it is possible to create an image on top of mysql, copy the files and use it or connect to the mysql 
 task in swarm and then manually run the scripts, it's kinda unnecessary in my opinion.
--
author:	AnishAnil
association:	none
edited:	false
status:	none
--
+1 for COPY/ADD, 

Use Case:
 Fluentd requires the configuration files to be moved into the container during run time. These config files are created on the run time by our Jenkins Engine and without a COPY/ADD in docker compose it simply fails.

--
author:	jpz
association:	none
edited:	false
status:	none
--
Suppose one has a shared config file across a number of docker machines, with their Dockerfiles in respective subdirectories under the docker-compose directory.  How do you copy that shared config into each image?  I can't symbolically link to `../` from the Dockerfile context without getting `COPY failed: Forbidden path outside the build context` 

In this instance when running docker-compose build, I'd like to copy the config files from the docker-compose context prior to running the docker build steps.

I'm happy if someone can suggest a clean workaround of course.
--
author:	shin-
association:	contributor
edited:	false
status:	none
--
Please don't comment with just +1 - it's a waste of everyone's time. If you have additional information to provide, please do so ; otherwise, just add a thumbs up to the original issue.


--

--
My use case is simple. I don't want volumes nor do I want to roll my own image. I just want to put a simple defensive copy of a config file in a container after it's created and before it's started.
--
author:	
association:	none
edited:	false
status:	none
--
is this still a issue?
I have a django application with a very long settings file. For me it would be just way easier to create a docker image and copy a single configuration file to each container. 
Passing all the settings as ENV is for me the antipattern. Takes a lot of code, is difficult to maintain and could be solved with a single copy command.
--
author:	jadon1979
association:	none
edited:	false
status:	none
--
I opened #6643 and would love feedback on how it would be considered an anti-pattern.  Especially, in an environment where numerous configuration files  could have a need to be added/modified on-the-fly.  
--
author:	Glideh
association:	none
edited:	true
status:	none
--
@shin- 
> The problem with this is that it is incredibly short-sighted (hence the term ""anti-pattern""), as it will force you to repeat the operation every time the containers to be recreated. Not to mention the fact that it scales very poorly (what if you have 10 containers? 20? 100?)

How does work `docker-compose exec` with multiple containers ?

```
    --index=index     index of the container if there are multiple
                      instances of a service [default: 1]
```

 Shouldn't we try to get the same behavior with `cp` ?

IMHO `exec` is as much ephemeral as `cp` would be. But I always consider it ""development"" commands anyway, development environments must be ephemeral shouldn't they ?
--
author:	crazycodr
association:	none
edited:	false
status:	none
--
I hadn't seen the comment about a lot of devs here saying that they are short-sighted by trying too quickly fix this by requesting this feature. I think this is a little harsh and condescending. If there is one thing i've learned from my years of development it is the following:

> It's not what your software does, it's what the user does with it that counts

Obviously, i understand that you have a role to prevent things from going crazy, but it's not because someone uses a tool incorrectly based on your vision that everyone will start to do it that way and all hell will break loose. 

All of the special cases i've seen here are very appropriate most of the time. And, most of these special cases shouldn't and wouldn't happen on production system, they are, for example, like my case that i explained a while ago, to customize a development environment and run special files in a container that cannot use a volume mapping. Most examples say clearly they don't want to bake in schemas, data, or config files and cannot use volume mapping so i don't see why this is so much aof an inconvenience as too use the term ""Short-Sighted"".

I think you should carefully weight your words when saying things like that...
--
author:	shin-
association:	contributor
edited:	false
status:	none
--
1. I really don't need a lecture on what I am allowed to say or write. I'm sorry that ""short-sighted"" offends you. It's still accurate to say that these things belong in the Dockerfile by design.
2. I'm not a maintainer anymore. Please stop @-ing me on things I no longer have any control over.
--

--
This has gone off the rails... 'anti-pattern' without explanation turns 'anti-pattern' into a very broad definition that is impossible to argue against.  There is also no clear direction on which side the 'anti-pattern' sits on; docker or docker-compose.

A clear definition of the anti-pattern responses would be fantastic and much appreciated.  

The community is going to continue to grow so an established set of definitions needs to exist.
--
author:	rhuanbarreto
association:	none
edited:	true
status:	none
--
I want to use it to copy artifacts generated by a jenkins pipeline running on a docker compose stack. And then, the container name can be random, so I can't use `docker cp`.

Today I must use 

`docker cp $(docker-compose -f docker-compose.development.ci.yml ps -q test):/app/tests_output ./tests_output`
--
author:	abhinavgurung
association:	none
edited:	false
status:	none
--
> Is this different from `volumes: - ./folder_on_host/ :/folder_in_container/` ?
> I am able to copy files from host to container (equivalent of COPY) this way in my compose file

I am trying to do same. I have a folder with a csv file and I would like to supply it to logstash.
how can I do that. or which folder in container?
at the moment I have something this:
./path/to/storage:/usr/share/logstash/data:ro

Any suggestions would be helpful

--
author:	isapir
association:	none
edited:	false
status:	none
--
@shin- This ticket is now 1.5 years old.  When 160 people tell you you're wrong - you probably are.  

What else do you need to convince you that this should be implemented?
--
author:	sfuerte
association:	none
edited:	false
status:	none
--
@isapir, the companies that don't listen to their customers, tend to go out of the business rather soon. So I guess we should see some production-ready docker alternatives in the near future. 
--
author:	shin-
association:	contributor
edited:	false
status:	none
--
> @shin- This ticket is now 1.5 years old. When 160 people tell you you're wrong - you probably are.

      

[Also,](https://github.com/docker/compose/issues/5523#issuecomment-484951785)

> I'm not a maintainer anymore. Please stop @-ing me on things I no longer have any control over.

--

--
@shin- This ticket is now 1.5 years old.  When 160 people tell you you're wrong - you probably are.  

What else do you need to convince you that this should be implemented?
--
author:	sfuerte
association:	none
edited:	false
status:	none
--
@isapir, the companies that don't listen to their customers, tend to go out of the business rather soon. So I guess we should see some production-ready docker alternatives in the near future. 
--
author:	shin-
association:	contributor
edited:	false
status:	none
--
> @shin- This ticket is now 1.5 years old. When 160 people tell you you're wrong - you probably are.

      

[Also,](https://github.com/docker/compose/issues/5523#issuecomment-484951785)

> I'm not a maintainer anymore. Please stop @-ing me on things I no longer have any control over.

--
author:	isapir
association:	none
edited:	false
status:	none
--
@sfuerte There is a little project named Kubernetes that has already replaced Docker-Compose.  I wonder if that would have happened had the attitude towards user feedback been more positive.
--
author:	robclancy
association:	none
edited:	false
status:	none
--
We need a buzzword to counter their buzzwords. It's all they can deal with. 

This feature would totally be `pro-pattern`. That should do it. The difference is that even though I made that stupid thing up there is many comments in this issue showing the advantages of this in ways that are clearly common use cases. And there isn't a single instance of an `anti-pattern`.

@shin- you get tagged in this because you started this bullshit antipattern crap with no basis in reality. So stop crying about something that you caused.
--
author:	shin-
association:	contributor
edited:	false
status:	none
--
k have fun
--
",ukbe,"
--
You can see some of many usecases clicking at link provided. As you can see many of subscribers consider it as really useful feature instead of ""antipattern""
--
author:	
association:	none
edited:	false
status:	none
--
ooops, now I see ""something"" happened to issue #2105 as there are no comments at all anymore...
Perhaps I provided wrong link...
--
author:	
association:	none
edited:	false
status:	none
--
so, I find really useful to copy some configuration/initialization files to container. As example some *.sql stuff for db containers, some html/js/css content for apache/nginx containers or even jar file for java container. This will make it available/runnable ""globally"" not only on machine where it was composed as in case of mounting volume(s). Mainly this will be some combination of host-local and container-contained files. In fact any container can be considered useless without any configuration or initialization

this is correct link: https://github.com/docker/compose/issues/1664
--
author:	ukbe-aurea
association:	none
edited:	false
status:	none
--
+1
--
",dkinzer,"
--
so, I find really useful to copy some configuration/initialization files to container. As example some *.sql stuff for db containers, some html/js/css content for apache/nginx containers or even jar file for java container. This will make it available/runnable ""globally"" not only on machine where it was composed as in case of mounting volume(s). Mainly this will be some combination of host-local and container-contained files. In fact any container can be considered useless without any configuration or initialization

this is correct link: https://github.com/docker/compose/issues/1664
--
author:	ukbe-aurea
association:	none
edited:	false
status:	none
--
+1
--
author:	shin-
association:	contributor
edited:	false
status:	none
--
> This will make it available/runnable ""globally"" not only on machine where it was composed as in case of mounting volume(s)

The problem with this is that it is incredibly short-sighted (hence the term ""anti-pattern""), as it will force you to repeat the operation every time the containers to be recreated. Not to mention the fact that it scales very poorly (what if you have 10 containers? 20? 100?)

The actual solution to your issue is to include those necessary files in your build (Dockerfile) and rebuild when an update is needed.
--
author:	
association:	none
edited:	false
status:	none
--
of course, if it is composed including all ""shared"" content into container, scaling 10-20-100- containers would be much easier. Everything you need is to pull it from repository and mount(yes, in this case mount) only node-specific config. And even more, you don't need run docker-compose on each node.
Sure we can use docker-compose in combination with build: & Dockerfile, however things  become little more complex and yaml configuration in docker-compose is much more ""elegant"" :o)
--
author:	dkinzer
association:	none
edited:	false
status:	none
--
I'm running into an issue where copy would come in handy (at least as an override).  I mostly develop on mac so I almost never see an issue with commands running as root in the container and exporting to a mounted volume.  However, recently using the same workflow on a CentOs has caused some major pain because files owned by the root user are being added to the host via the mounted volume.  I would like in these cases to just be able to copy the host files to the container instead of mounting them.

The related issue: #1532

## update
I think in my case I can get away with using COPY in the Dockerfile and having multiple docker-compose files one of which uses a volume mount.
--
",srghma,"
--
+1
--
author:	shin-
association:	contributor
edited:	false
status:	none
--
> This will make it available/runnable ""globally"" not only on machine where it was composed as in case of mounting volume(s)

The problem with this is that it is incredibly short-sighted (hence the term ""anti-pattern""), as it will force you to repeat the operation every time the containers to be recreated. Not to mention the fact that it scales very poorly (what if you have 10 containers? 20? 100?)

The actual solution to your issue is to include those necessary files in your build (Dockerfile) and rebuild when an update is needed.
--
author:	
association:	none
edited:	false
status:	none
--
of course, if it is composed including all ""shared"" content into container, scaling 10-20-100- containers would be much easier. Everything you need is to pull it from repository and mount(yes, in this case mount) only node-specific config. And even more, you don't need run docker-compose on each node.
Sure we can use docker-compose in combination with build: & Dockerfile, however things  become little more complex and yaml configuration in docker-compose is much more ""elegant"" :o)
--
author:	dkinzer
association:	none
edited:	false
status:	none
--
I'm running into an issue where copy would come in handy (at least as an override).  I mostly develop on mac so I almost never see an issue with commands running as root in the container and exporting to a mounted volume.  However, recently using the same workflow on a CentOs has caused some major pain because files owned by the root user are being added to the host via the mounted volume.  I would like in these cases to just be able to copy the host files to the container instead of mounting them.

The related issue: #1532

## update
I think in my case I can get away with using COPY in the Dockerfile and having multiple docker-compose files one of which uses a volume mount.
--
author:	srghma
association:	none
edited:	false
status:	none
--
Use-case:
 I want to use directory from read-only file system inside container. Application creates new files in that directory, but because filesystem is read only this cause errors.

I can't use rw volume, because filesystem is read only.
I can't use ro volume, because effect will be the same.

It would be awesome to make writes that are persists only when container runs. I can make wrapper (https://stackoverflow.com/questions/36362233/can-a-dockerfile-extend-another-one) to only `COPY` files, but making this in compose, similar to `volume`, would be better
--
",nrdmn,"
--
> This will make it available/runnable ""globally"" not only on machine where it was composed as in case of mounting volume(s)

The problem with this is that it is incredibly short-sighted (hence the term ""anti-pattern""), as it will force you to repeat the operation every time the containers to be recreated. Not to mention the fact that it scales very poorly (what if you have 10 containers? 20? 100?)

The actual solution to your issue is to include those necessary files in your build (Dockerfile) and rebuild when an update is needed.
--
author:	
association:	none
edited:	false
status:	none
--
of course, if it is composed including all ""shared"" content into container, scaling 10-20-100- containers would be much easier. Everything you need is to pull it from repository and mount(yes, in this case mount) only node-specific config. And even more, you don't need run docker-compose on each node.
Sure we can use docker-compose in combination with build: & Dockerfile, however things  become little more complex and yaml configuration in docker-compose is much more ""elegant"" :o)
--
author:	dkinzer
association:	none
edited:	false
status:	none
--
I'm running into an issue where copy would come in handy (at least as an override).  I mostly develop on mac so I almost never see an issue with commands running as root in the container and exporting to a mounted volume.  However, recently using the same workflow on a CentOs has caused some major pain because files owned by the root user are being added to the host via the mounted volume.  I would like in these cases to just be able to copy the host files to the container instead of mounting them.

The related issue: #1532

## update
I think in my case I can get away with using COPY in the Dockerfile and having multiple docker-compose files one of which uses a volume mount.
--
author:	srghma
association:	none
edited:	false
status:	none
--
Use-case:
 I want to use directory from read-only file system inside container. Application creates new files in that directory, but because filesystem is read only this cause errors.

I can't use rw volume, because filesystem is read only.
I can't use ro volume, because effect will be the same.

It would be awesome to make writes that are persists only when container runs. I can make wrapper (https://stackoverflow.com/questions/36362233/can-a-dockerfile-extend-another-one) to only `COPY` files, but making this in compose, similar to `volume`, would be better
--
author:	nrdmn
association:	none
edited:	false
status:	none
--
Use case: starting multiple docker containers simultaneously from .gitlab-ci.yml which need to write into the git repository's directory.

If the process inside a container fails or if the ci job is cancelled before the container has cleaned up after itself, the remaining files can't be deleted by gitlab-runner due to lack of permissions. Now I could copy the files within the container out of the volume into another directory, but that would be an antipattern, wouldn't it?
--

--
I created a quick gist for this. It assumes the docker compose service is named `phpfpm`, however you can change this to whatever you wish. feel free to modify.
https://gist.github.com/markoshust/15efb29aa5eebf8adae402af18b2e674
--
author:	sfuerte
association:	none
edited:	false
status:	none
--
COPY/ADD would definitely be a welcome feature. 

A usecase: running a Graylog instance in Docker for Dev purposes. In order to launch an input automatically, a JSON spec has to be put in /usr/share/graylog/data/contentpacks
With the COPY/ADD feature, it'll be as easy as single line in YML. 

In order to get it working now (on Oct 16, 2018), need to mount a volume to that point AND copying the original content of that folder to the persistent volume. Which is quiet inconvenient. 
--
author:	crazycodr
association:	none
edited:	true
status:	none
--
I would benefit from that, i have a set of tools that import a database seed into a container and then i run the devtools database importer based on that file. I don't want to have to do:

```bash
docker cp ""${seed_file}"" $(docker-compose ps -q devtools):/tmp/seed_file
```
to be able to import my seed. And no, i will not compile my dev images with a fixed schema, this goes against web development pattern at the very least. Containers should be for app portability, not data.

It would make way more sense to do:

```bash
docker-compose cp ""${seed_file}"" devtools:/tmp/seed_file
```
All in all, it is just a short-hand that basically does the same thing, but it looks better to leverage `docker-compose` everywhere than to mix stuff...
--
author:	funkyfuture
association:	contributor
edited:	false
status:	none
--
1) this seems to be a duplicate of #3593
2) i agree with @shin- that the elaborated use-cases are following an anti-pattern
3) but wrapping up Docker's `cp` command makes sense, imo
--
author:	nrdmn
association:	none
edited:	false
status:	none
--
@funkyfuture If you think that these use-cases follow an antipattern, then please suggest a solution that does not.
--
",harpratap,"
--
of course, if it is composed including all ""shared"" content into container, scaling 10-20-100- containers would be much easier. Everything you need is to pull it from repository and mount(yes, in this case mount) only node-specific config. And even more, you don't need run docker-compose on each node.
Sure we can use docker-compose in combination with build: & Dockerfile, however things  become little more complex and yaml configuration in docker-compose is much more ""elegant"" :o)
--
author:	dkinzer
association:	none
edited:	false
status:	none
--
I'm running into an issue where copy would come in handy (at least as an override).  I mostly develop on mac so I almost never see an issue with commands running as root in the container and exporting to a mounted volume.  However, recently using the same workflow on a CentOs has caused some major pain because files owned by the root user are being added to the host via the mounted volume.  I would like in these cases to just be able to copy the host files to the container instead of mounting them.

The related issue: #1532

## update
I think in my case I can get away with using COPY in the Dockerfile and having multiple docker-compose files one of which uses a volume mount.
--
author:	srghma
association:	none
edited:	false
status:	none
--
Use-case:
 I want to use directory from read-only file system inside container. Application creates new files in that directory, but because filesystem is read only this cause errors.

I can't use rw volume, because filesystem is read only.
I can't use ro volume, because effect will be the same.

It would be awesome to make writes that are persists only when container runs. I can make wrapper (https://stackoverflow.com/questions/36362233/can-a-dockerfile-extend-another-one) to only `COPY` files, but making this in compose, similar to `volume`, would be better
--
author:	nrdmn
association:	none
edited:	false
status:	none
--
Use case: starting multiple docker containers simultaneously from .gitlab-ci.yml which need to write into the git repository's directory.

If the process inside a container fails or if the ci job is cancelled before the container has cleaned up after itself, the remaining files can't be deleted by gitlab-runner due to lack of permissions. Now I could copy the files within the container out of the volume into another directory, but that would be an antipattern, wouldn't it?
--
author:	harpratap
association:	none
edited:	false
status:	none
--
Is this different from `volumes: - ./folder_on_host/ :/folder_in_container/` ? 
I am able to copy files from host to container (equivalent of COPY) this way in my compose file
--
"
5477,OPEN,add env_blueprint_file feature,area/config; kind/feature,2019-05-22 14:58:08 +0000 UTC,Bamieh,Opened,,"Hello,

There is a nice feature in the [dotenv npm package](https://www.npmjs.com/package/dotenv) which is the option to provide a blueprint for the `.env` file. the purpose of the blueprint is to validate missing environment variables in the .env file before running, providing a catch net to catch missing env variables before spinning the component.

Possible Implementations:

```
services:
  service-name:
    env_file:
      - ./.env
    env_blueprint_file:
      - ./.env.blueprint
```
or

```
services:
  service-name:
    env_file:
      - "".env:.env.blueprint""
```
also auto detecting the blueprint of the env file is a possiblity (by trying to fetch `env_file_name.blueprint`).

Cheers!",,,,,,,,,,,,,,
5388,OPEN,"Support the ""consistency"" option in long syntax format for volumes",area/volumes; kind/feature; kind/parity,2019-04-17 15:45:18 +0000 UTC,lmakarov,In progress,,"I did not find an example for the [consistency](https://docs.docker.com/engine/admin/volumes/bind-mounts/#configure-mount-consistency-for-macos) option used with the **long syntax format** in [Compose file version 3 reference](https://docs.docker.com/compose/compose-file/#long-syntax-3) docs.

Looks like it is not yet supported.

```
$ docker-compose --version
docker-compose version 1.17.1, build 6d101fb
```

**Short syntax**

```yaml
version: ""3.3""

services:
  web:
    image: nginx
    volumes:
      - ${PROJECT_ROOT}:/var/www:rw,cached
```

```
$ docker-compose config
services:
  web:
    image: nginx
    volumes:
    - /Users/leonid/Work/Labs/docksal/demo:/var/www:rw,cached
version: '3.3'
```

```
$ docker inspect demo_web_1
...
        ""Mounts"": [
            {
                ""Type"": ""bind"",
                ""Source"": ""/Users/leonid/Work/Labs/docksal/demo"",
                ""Destination"": ""/var/www"",
                ""Mode"": ""rw,cached"",
                ""RW"": true,
                ""Propagation"": ""rprivate""
            }
        ],
...
```

> `""Mode"": ""rw,cached""`

```
$ /Applications/Docker.app/Contents/MacOS/com.docker.osxfs state
Exported directories:
 - /Users to /Users (nodes_/Users table size: 8)
 - /Volumes to /Volumes (nodes_/Volumes table size: 0)
 - /private to /private (nodes_/private table size: 0)
 - /tmp to /tmp (nodes_/private/tmp table size: 0)
Container-mounted directories:
 - /Users/leonid/Work/Labs/docksal/demo into 5b47358f24a178ceb11543109c0ad467181f783430a7e7fae620bdb87641f87f (state=cached)
```

> `(state=cached)`

**Long syntax**

```yaml
version: ""3.3""

services:
  web:
    image: nginx
    volumes:
      - type: bind
        source: ${PROJECT_ROOT}
        target: /var/www
        read_only: false
        consistency: cached
```

```
$ docker-compose config
services:
  web:
    image: nginx
    volumes:
    - /Users/leonid/Work/Labs/docksal/demo:/var/www:rw
version: '3.3'
```

```
        ""Mounts"": [
            {
                ""Type"": ""bind"",
                ""Source"": ""/Users/leonid/Work/Labs/docksal/demo"",
                ""Destination"": ""/var/www"",
                ""Mode"": ""rw"",
                ""RW"": true,
                ""Propagation"": ""rprivate""
            }
        ],
```

> `""Mode"": ""rw"",`

```
$ /Applications/Docker.app/Contents/MacOS/com.docker.osxfs state
Exported directories:
 - /Users to /Users (nodes_/Users table size: 8)
 - /Volumes to /Volumes (nodes_/Volumes table size: 0)
 - /private to /private (nodes_/private table size: 0)
 - /tmp to /tmp (nodes_/private/tmp table size: 0)
Container-mounted directories:
 - /Users/leonid/Work/Labs/docksal/demo into ad5c57007849125a4ccdc4fcda6964a42eeddab9084b00a5a2cea8361942e132 (state=default)
```

> `(state=default)`
",,,shin,"
--
cc @dnephin 
--
",kbluescode,"
--
@lmakarov - it doesn't support `consistency`, but it does support the `propagation` method via the driver config of a given volume. As of 1.16 this worked fine, but I'm running into issues in 1.18.

Example:
```
services:

  service1:
    image: alpine:3.4
    volumes:
      - type: bind
        bind:
          propagation: cached
        source: ./folder_to_mount
        target: /app
```

This is in version '3.3' of a compose file
--

--
@lmakarov - As of 1.16 this worked fine for all my coworkers, but it could just be that compose never complained before. I understand that as of the current options in 1.18, this isn't valid. I implemented this before a bunch of those docs surfaced.
--

--
Porting my compose files back to short-form syntax now due to this issue
--
",lmakarov,"
--
@kbluescode there is no `cached` option for `propagation`.
https://docs.docker.com/engine/admin/volumes/bind-mounts/#configure-bind-propagation
--
",andytson,"
--
note, this is blocking the use of tmpfs volumes when using another bind volume with consistency setting is really needed for performance issues (DfM osxfs)

(edit) It seems tmpfs: is available as an alternative though
--
",fuel,"
--
I'm not sure this is a bug in docker-compose, but rather a side effect of how docker works internally.

My experimentation with the docker-cli is as follows

Short Form:
```
docker container create -v `pwd`:/app:cached alpine ls /app
docker inspect df88a08da88e445b29252de52104e5de89ad0eae86f81d28db85e146aff20a90
(extract from higher up)
""Binds"": [
    ""/tmp:/app:cached""
],
(extract from lower down)
""Mounts"": [
    {
        ""Type"": ""bind"",
        ""Source"": ""/tmp"",
        ""Destination"": ""/app"",
        ""Mode"": ""cached"",
        ""RW"": true,
        ""Propagation"": ""rprivate""
    }
],
```

Long Form
```
docker container create --mount ""type=bind,source=`pwd`,destination=/app,consistency=cached"" alpine ls /app
docker inspect 3484b05ba7f509bfd56ef6bbb1cfa2a3f8fe3ddb89bb5414bf035d9a8096014c
(extract from higher up)
""Mounts"": [
    {
        ""Type"": ""bind"",
        ""Source"": ""/tmp"",
        ""Target"": ""/app"",
        ""Consistency"": ""cached""
    }
],

(extract from lower in the output)
""Mounts"": [
    {
        ""Type"": ""bind"",
        ""Source"": ""/tmp"",
        ""Destination"": ""/app"",
        ""Mode"": """",
        ""RW"": true,
        ""Propagation"": ""rprivate""
    }
],
```

My experimentation confirmed that docker-compose does the same difference between long form and short form.

As far as I can tell, docker internally is doing what is desired by the original reporter.

@lmakarov do you have another way to show the consistency is flag is not being respected?
If so, this might be better reported as a bug in the engine itself in how it's translating the host_config to the actual mount.
--
",mdcrawford,"
--
Same problem on 2.3.  Similar to what @fuel-wlightning mentioned, it seems Docker Compose does support a consistency field when you're using it in docker-compose.yml, but once you check the actual Mode field in `.Mounts` it no longer lists `delegated`, although it's specified in the HostConfig.  I'm attaching the docker-compose.yml and the output of `docker inspect` using the old and the new syntax.

The other thing that's weird is that with the old syntax, the mount is described in HostConfig.Binds, whereas for the new syntax, it's listed under HostConfig.Mounts.  I wonder if that difference affects how things get passed down to the Docker engine.

Docker Compose:

```
version: '2.3'
services:

  nginx:
    image: nginx:latest
    init: true
    volumes:
      - type: bind
        source: /Users/michael.crawford/test/test-docker-compose/test
        target: /test
        consistency: delegated

  nginx2:
    image: nginx:latest
    init: true
    volumes:
      - ""/Users/michael.crawford/test/test-docker-compose/test:/test:delegated""
```

[new_syntax.txt](https://github.com/docker/compose/files/3090421/new_syntax.txt)
[old_syntax.txt](https://github.com/docker/compose/files/3090422/old_syntax.txt)


--
"
5288,OPEN,Feature Request: list all local images with docker-compose; even without containers,,2021-01-31 00:59:39 +0000 UTC,slavik57,In progress,,"Currently `docker-compose images` lists only images with created containers.
```
> docker-compose images --help
List images used by the created containers.
Usage: images [options] [SERVICE...]

Options:
-q     Only display IDs
```

I need a way to list all images on local machine relevant to `docker-compose` file even if they don't have containers.

I found a workaround with these steps:
```
> docker-compose create
> docker-compose images
> docker-compose rm
```

I feel there should be a way of doing it with one command. Adding a flag to `images` would be nice, something like `-a` meaning `list all images`

Some info:
```
> docker version
Client:
 Version:      17.05.0-ce
 API version:  1.29
 Go version:   go1.7.5
 Git commit:   89658be
 Built:        Thu May  4 22:06:25 2017
 OS/Arch:      linux/amd64

Server:
 Version:      17.05.0-ce
 API version:  1.29 (minimum version 1.12)
 Go version:   go1.7.5
 Git commit:   89658be
 Built:        Thu May  4 22:06:25 2017
 OS/Arch:      linux/amd64
 Experimental: false
```

```
> docker-compose version
docker-compose version 1.15.0, build e12f3b9
docker-py version: 2.5.1
CPython version: 2.7.5
OpenSSL version: OpenSSL 1.0.1e-fips 11 Feb 2013
```",,,florianeichin,"
--
If I'm getting the source code right, `docker-compose images `is not returning images but containers. Is that as planned or is it more kind of a bug? 
--

--
@shin-  yes I did, but you getting the containers and the corresponding images, that I think is also true if I'm looking into the source code, where you get the information out of the ""container.py"". So therefore it's not simply possible to get the images, that are not associated to a container, no?
--
",shin,"
--
@florianeichin That's a bit of a wild assumption. Have you tried running the command?
--
",cosmopetrich,"
--
I think what's being requested is a way to determine which image compose would use for a particular service without needing to run that service first.

This could be useful in CI where compose is used to provide the arguments to `docker-compose build` and there's a need to operate on a particular image even if its container hasn't been brought up.

```sh
# This will return no output
docker-compose build
docker-compose images

# This will return a list of containers and images
docker-compose build
docker-compose up -d
docker-compose images
```

A workaround is to parse the output of `docker-compose config`, which will print the image name with any variables expanded. If there are multiple services defined then you can use [yq](https://github.com/kislyuk/yq) to select a specific one.

```sh
docker-compose config | yq -r .services.${service}.image
```
  
--
",joshua,"
--
```
# This will return no output
docker-compose build
docker-compose images
# Why!?
```

I would really like for this to list the images built, I don't understand why the `docker-compose up -d` is required to make them visible.
--
",jhrabi,"
--
Is this being looked at all? There hasn't been an update in over 18 months.
--
",AndrewRayCode,"
--
What I enjoy about docker-compose is how nice it makes working with project specific docker, and doing things like prefixing container names with the current directory. I can get docker-compose to list images for _running containers_, but if i'm not running anything, I'd still like to see the images. Especially since docker-compose is adding the concept of a ""service"" and abstracting away some handling of images, it would make sense to me that docker-compose would list images for a service even if it's not running.

In my case I wanted to try out a little test app then remove images after to clear up space. I'm not sure how to accomplish this with docker-compose other than running all the services, _then_ doing `docker-compose images` or `docker-compose ps`, and manually removing the image tags.
--
"
5124,OPEN,Sequential restart when using `docker-compose up` with scale,area/scale; kind/feature,2019-11-16 08:43:10 +0000 UTC,corradio,In progress,,"Hello,

It seems to me that when scale is > 1, and a new image is being pulled, using `docker-compose up` restarts all containers in parallel rather than sequentially.
Doing a cascading restart would ensure zero downtime.

Am I correct in my analysis?

Thank you,

Olivier",,,shin,"
--
Both are valid strategies depending on your use-case, but you're right that we don't currently offer an automated way to do zero-downtime deployments. In the meantime, you may want to take a look at https://github.com/docker/compose/issues/1786#issuecomment-294434786 which outlines how to do so manually.
--

--
> With previous versions of docker/docker-compose, it seems like containers were restarted sequentially. Did anything change?

Unless you're looking at versions from 2 years ago, that wasn't the case.
--
",corradio,"
--
Hi @shin- , 
Unfortunately your method won't work as I have more than 1 container in production.
With previous versions of docker/docker-compose, it seems like containers were restarted sequentially. Did anything change?
It would be nice to be able to control the start strategy in docker-compose (sequential vs parallel)
--

--
I was indeed working with a very old version (due to CI constraints).
Any idea if it's possible to add the feature I'm requesting? I'm up for contributing if needed.
--
",domq,"
--
Replying to the [original question](https://github.com/docker/compose/issues/5124#issue-251914680), it is still not possible to do sequential restarts. *However*, you can prevent `docker-compose up --scale` from restarting existing containers using [the `--no-recreate` flag](https://docs.docker.com/compose/reference/up/). This is enough to do zero-downtime restarts if you use only run one serving instance (by momentarily scaling to two, then deleting the oldest container).
--
",,,,,,
5102,OPEN,Configure merge behavior for configuration keys,area/config; kind/epic; kind/feature,2017-08-12 01:05:42 +0000 UTC,shin-,Opened,,"Some use cases require extends / overrides to completely overwrite the base config for a given key instead of merging both together.

### Issues requesting or requiring this feature: 
- #3648 (build)
- #4973 (ports)
- #4019
- ...

### Steps

- Figure out universal, non-breaking syntax for this feature
- Figure out desirable behaviors (current default behavior, overwrite are the current requested ones. Is there a use-case for giving priority to keys defined in base vs override?)
- Figure out implementation - currently merging behavior is done somewhat differently for each key, according to what makes the most sense as a default. This might make implementation of a generic solution challenging.",,,,,,,,,,,,,,
4980,OPEN,Add --json option and send progress for non-TTY,area/logs; kind/feature,2019-05-22 14:35:59 +0000 UTC,aaronbeall,In progress,,"I've been working on a NodeJS project that invokes `docker-compose` as a child process. The issue I ran into is that progress events [are only output if `isatty=true`](https://github.com/docker/compose/blob/master/compose/progress_stream.py#L12). I might be able to get the output using `pty.js` but the output will be hard to read... what I really want is the event as JSON.

So this request is to add a `--json` option that will format `stdout` as JSON, and include the download progress events.",,,tonivj5,"
--
I'm interested too!  
--

--
Yeah, I think something like that would be awesome!  
--
",jnovack,"
--
Do you mean you would like the following events printed to the stdout so you can parse them? (I'm making up a structure without coffee, forgive me.)

```
{ event: ""download"", hash: ""019300c8a437"", completion: 100, status: ""Already exists"" }
{ event: ""download"", hash: ""52a47bc43268"", completion: 0, status: ""Pulling fs layer"" }
{ event: ""download"", hash: ""52a47bc43268"", completion: 3, status: ""Downloading"", progress: 4.523, total: 14.82 }
{ event: ""download"", hash: ""52a47bc43268"", completion: 100, status: ""Download complete"" }
{ event: ""build"", task: ""Recreating dockercomposetest_nginx_1"", status: ""in progress"" }
{ event: ""build"", task: ""Recreating dockercomposetest_nginx_1"", status: ""complete"" }
```

--
",aaronbeall,"
--
Yes, exactly!On Jul 20, 2017 8:43 AM, ""Justin J. Novack"" <notifications@github.com> wrote:Do you mean you would like the following events printed to the stdout so you can parse them? (I'm making up a structure without coffee, forgive me.)
{ event: { type: download, hash: 019300c8a437, completion: 100, status: ""Already exists"" } }
{ event: { type: download, hash: 52a47bc43268, completion: 0, status: ""Pulling fs layer"" } }
{ event: { type: download, hash: 52a47bc43268, completion: 3, status: ""Downloading"", detail: { downloaded: 4.523, total: 14.82 } } }
{ event: { type: download, hash: 52a47bc43268, completion: 100, status: ""Download complete"" } }


You are receiving this because you authored the thread.Reply to this email directly, view it on GitHub, or mute the thread.
--
",,,,,,
4787,OPEN,Docker Compose not using trusted conent during pull,kind/feature,2021-01-11 09:26:31 +0000 UTC,brian-bason,Opened,,"We have been using content trust (notary) to sign our images when building and sending them to a third party repository.

We make use of docker compose to pull in all the required images that need to go on a particular device but we noticed that compose is not making use of notary to confirm that the images being pulled down have a tag record in the notary server thus marking it a trusted content.

We need to make sure that the images stored at the third party site have not be compromised from the day we uploaded them to the time they are deployed in production. Why doesn't docker compose respect the environment variables DOCKER_CONTENT_TRUST and DOCKER_CONTENT_TRUST_SERVER when running the pull command like the docker client does?

This seems to be a bug and therefore request to get it fixed please, thanks.",,,shin,"
--
Content trust is implemented client-side in the Docker CLI. Since `docker-compose` is an entirely different code-base, we do not have a matching implementation of that feature at this time.

For the time being, you might want to pull images using the `docker` CLI before running `docker-compose up`.
--
",brian,"
--
This is a bit of a limitation. We have a number of images that need to go into production machines and we find it useful to make use of compose to manage the set of images that are to be deployed on a particular box.

Is this in the pipeline of getting done or still not on the radar? We have assumed that since docker compose is part of the ecosystem of Docker that the same feature for trusted content would have been implemented.
--
",MatthewVance,"
--
It's also worth noting pulling the Docker compose image (docker/compose:1.15.0) with content trust enabled fails because the compose image itself has not been signed. 

```
docker pull --disable-content-trust=false docker/compose:1.15.0
Error: remote trust data does not exist for docker.io/docker/compose: notary.docker.io does not have trust data for docker.io/docker/compose 
```

--
",peterthomassen,"
--
You might want to take a look at [trusted-compose](https://github.com/sse-secure-systems/trusted-compose).

It is a wrapper that uses `docker pull` with DCT to pull verified images, then propagates them to a local registry (which can be a ephemeral container without persistent storage), and then makes sure that docker-compose only uses these verified and locally stored images. The tool requires prefixing each image name with an environment variable so that the magic can be injected.
--

--
@ddelange As explained in the [previous post](https://github.com/docker/compose/issues/4787#issuecomment-573129692), trusted-compose is a wrapper around docker-compose; it pulls images, verifies signatures, and pushes them to a local registry. It then has to make sure that docker-compose will only used the verified images from the local registry. That's what the env variable prefix is needed for.

The reason for this approach is so that certain race conditions can be avoided. For details, see [this article on trusted-compose](https://medium.com/sse-blog/bringing-content-trust-into-the-world-of-docker-compose-12836b3537d).
--
",ddelange,"
--
> Content trust is implemented client-side in the Docker CLI. Since `docker-compose` is an entirely different code-base, we do not have a matching implementation of that feature at this time.
> 
> For the time being, you might want to pull images using the `docker` CLI before running `docker-compose up`.

@shin- is there a specific reasoning behind skipping this essential feature in compose? Who can we tag here for a second opinion? :)

As for your suggestion, grepping the docker image tags from the `docker-compose.yml` before each `up` seems a bit cumbersome, but I guess the best alternative without resorting to 3rd party software.

> The tool requires prefixing each image name with an environment variable so that the magic can be injected.

@peterthomassen could you elaborate on this reasoning?
--
",,
4579,OPEN,Using scale number to adjust mounted volumes?,kind/feature,2020-02-22 10:43:40 +0000 UTC,Sushisource,Opened,,"I have a situation where I need to create many instances of a docker container, and they should have mounts that enable them to persist their data to different locations, so they aren't all running into each other. The containers are all worker agents for some non-docker-controlled server.

Essentially I need to be able to do something like this:
    
    services:
        agent:
            volumes:
                - /mnt/dat/agent_${DOCKER_SCALE_NUM}:/data/agent

I found a few references when googling around to something like this, but all of them seemed to have a resolution along the lines of ""you don't really want to do this"" or ""here's some other way to solve your problem that doesn't involve doing this"".

I doesn't need to be a sequential number or anything like that - I just need some way to get unique mount points for each one.

Is there an existing way to do this? If not, is anything planned?

Thanks!",,,manniche,"
--
I have the same use-case, in which I would like to have a variable number of elasticsearch containers, and have each of them write to their own volume, have their own distinct internal name, expose on distinct ports, etc. E.g. a docker-compose definition such as 

```
  es:
    build: ./es/
    restart: unless-stopped
    environment:
      - node.name=es${DOCKER_SCALE_NUM}
      - ""ES_JAVA_OPTS=-Xms512m -Xmx512m""
    ulimits:
      memlock:
        soft: -1
        hard: -1
      nofile:
        soft: 65536
        hard: 65536
    volumes:
      - es_${DOCKER_SCALE_NUM}:/usr/share/elasticsearch/data
    ports:
      - ${DOCKER_SCALE_NUM+CONSTANT}:9200
    networks:
      - elastic
```
which when running `docker-compose up --scale , I would expect to get 5 containers, 5 volumes with distinct names, 5 different expose ports (starting from some $CONSTANT, e.g. 9199 to make the first container hit the expected 9200 expose port or similar) and a single network they all connect to.
--
",ruimoliveira,"
--
no response yet and no workaround either?
--
",,,,,,,,
4577,OPEN,docker-compose ps show configuration update status,kind/feature,2019-05-22 13:50:46 +0000 UTC,deadbeef84,Opened,,"It would be really nice if `docker-compose ps` would show _configuration update status_, ie what would happen when running `docker-compose up -d`.

I'm guessing there's about 4 states:
- up to date
- image updated
- service configuration updated
- dependencies updated (not sure about this one)

An example output would be:
```
        Name                      Command               State     Configuration               x                 Ports
----------------------------------------------------------------------------------------------------------------------------------------
demo_couchdb_1         tini -- /docker-entrypoint ...   Up        up to date                  4369/tcp, 0.0.0.0:5984->5984/tcp, 9100/tcp
demo_elasticsearch_1   /docker-entrypoint.sh elas ...   Up        needs update (service)      0.0.0.0:9200->9200/tcp, 9300/tcp
demo_loadbalancer_1    /usr/local/openresty/bin/o ...   Up        needs update (image)        0.0.0.0:443->443/tcp, 0.0.0.0:80->80/tcp
demo_portainer_1       /portainer                       Up        needs update (dependency)   0.0.0.0:9000->9000/tcp
```

Does this make sense?",,,,,,,,,,,,,,
4548,OPEN,docker-compose run fails for running network_mode=host services,,2021-01-14 07:27:12 +0000 UTC,SpComb,Opened,,"For a `network_mode: host` service,

```yaml
version: '2'
services:
  redis:
    image: redis
    network_mode: host
```

```
$ docker-compose version
docker-compose version 1.11.1, build 7c5d5e4
docker-py version: 2.0.2
CPython version: 2.7.13
OpenSSL version: OpenSSL 1.0.1t  3 May 2016
$ hostname
localhost
$ docker-compose run --rm redis hostname
localhost
```

The `docker-compose run` command fails if the service is running:

```
$ docker-compose up -d redis
Starting composetest_redis_1
$ docker-compose run --rm redis hostname
ERROR: Cannot create container for service redis: Conflicting options: host type networking can't be used with links. This would result in undefined behavior
$ docker-compose stop redis         
Stopping composetest_redis_1 ... done
$ docker-compose run --rm redis hostname
localhost
```

It looks like `docker-compose --verbose run` tries to do some `--link` trickery against the running container, but this is not compatible with the `--net host`:

```

compose.cli.verbose_proxy.proxy_callable: docker create_host_config -> {'Binds': [],
 'Links': ['composetest_redis_1:composetest_redis_1',
           'composetest_redis_1:redis',
           'composetest_redis_1:redis_1'],
 'LogConfig': {'Config': {}, 'Type': u''},
 'NetworkMode': 'host',
 'PortBindings': {},
 'VolumesFrom': []}

ERROR: compose.cli.main.main: Cannot create container for service redis: Conflicting options: host type networking can't be used with links. This would result in undefined behavior
```

Possibly related:  #2480",,,sivabudh,"
--
I'm also running into the exact same problem. Here are my versions:

```
docker-compose version 1.11.2, build dfed245
Docker version 17.03.1-ce, build c6d412e
```

and here's the gist of my `docker-compose.yml` file: 

(some part redacted)

```
version: '3'

services:

  backend:
    container_name: backend
    build:
      context: .
      dockerfile: DockerfileBackend
    image: 123456.ecr.some-region.amazonaws.com/some-repo:latest
    environment:
      - DATABASE_URL=postgres://postgres:P@ssw0rd@localhost:5432/some_db
    volumes:
      - ./frontend_assets/static_files:/code/static_files
    command: gunicorn --bind 0.0.0.0:8000 --workers 3 --worker-class gevent app.config.wsgi:application --log-level=INFO
    ports:
      - ""8000:8000""
    network_mode: ""host""

  frontend:
    container_name: frontend
    build:
      context: .
      dockerfile: DockerfileFrontend
    image: 123456.dkr.ecr.some-region.amazonaws.com/frontend-repo:latest
    volumes:
      - ./frontend_assets:/code/frontend_assets
```

With this `docker-compose.yml`, the error will happen when the `backend` container is already running **and** we attempt to execute another `docker run` command related to `backend`.

Here's a concrete example. Assuming that **`backend`** is already running, this is the behavior:

```
# When running `frontend` container, there's no problem
docker-compose run frontend cp -rf /code/static_files/ /code/frontend_assets/
# But once you run the `backend` container while there's already one running...
docker-compose run backend python manage.py collectstatic --noinput
```
You will immediately see this error:
```
ERROR: Cannot create container for service backend: Conflicting options: host type networking can't be used with links. This would result in undefined behavior
```

-------------------------
## Workaround

There's a workaround for this issue that works for me, which is to do a `docker-compose down` prior to doing `docker-compose run backend`. Eg, this is what I do now:

```
docker-compose down
docker-compose run frontend cp -rf /code/static_files/ /code/frontend_assets/
# No problem. We are happy! ^_^
docker-compose run backend python manage.py collectstatic --noinput
```


--

--
Agreed with @usmanm on his comments. Fortunately, my app update takes roughly 6 seconds, and we are lucky that our apps can have daily maintenance window.
--
author:	
association:	none
edited:	false
status:	none
--
This is still relevant :+1: 
--
",usmanm,"
--
Running into the same issue. There should be a way to bypass the automatic linking that compose is trying to do. The workaround that @sivabudh describes isn't really ideal if the command being run in the second step takes a non-trivial amount of time.
--
",damouse,"
--
This is still relevant :+1: 
--
author:	damouse
association:	none
edited:	false
status:	none
--
Same issue. 
--
",tomholub,"
--
Same issue. 
--
author:	tomholub
association:	none
edited:	false
status:	none
--
Encountered here too
--
",rhoerbe,"
--
Encountered here too
--
author:	rhoerbe
association:	none
edited:	false
status:	none
--
Same issue
--

--
Same issue
--
author:	rhoerbe
association:	none
edited:	false
status:	none
--
likewise
--

--
likewise
--
author:	rhoerbe
association:	none
edited:	false
status:	none
--
The reason turned out to be a misleading error message in my case. An instance of the container was in restart mode, and docker compose got confused (I have not links, but network_mode=host)
--

--
This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you for your contributions.

--
author:	rhoerbe
association:	none
edited:	false
status:	none
--
The problem does not go away by doing nothing, then flagging it as stale, and finally closing the ticket. Bugs need to be fixed, not managed
--
",thomas,"
--
The reason turned out to be a misleading error message in my case. An instance of the container was in restart mode, and docker compose got confused (I have not links, but network_mode=host)
--
author:	thomas-profitt
association:	none
edited:	false
status:	none
--
This is still reproducible in docker-compose version 1.22.0, build f46880f.

`docker-compose run some-container any-command`, where `some-container` is any container that's got `network_mode: host` and is currently `Restarting` or `Up`.
--
"
4249,OPEN,Allow an environment variable to be used for an array field (e.g. devices:),area/config; kind/feature,2020-11-20 23:56:49 +0000 UTC,jamshid,Opened,,"Not sure what the syntax would be exactly, but I would like to supply an optional and variable set of devices to an docker-compose.yml service. 

Seems more flexible if the variable is a string and literally substituted, but maybe shell array variables should be used instead.

```
DEVICES=   # empty set, as a string
DEVICES=()   # or, empty set, as an array?
DEVICES='""/dev/sdb:/dev/sdb"", ""/dev/sdc:/dev/sdc""'   # as a string
DEVICES=(""/dev/sdb:/dev/sdb"" ""/dev/sdc:/dev/sdc"")   # or as an array?
```

```
foo:
   devices: [ ${DEVICES} ]   # not sure of the best syntax
   image: ...
```

It would be great if this syntax allowed ""appending"" to an existing hard-coded array.

```
foo:
   volumes: [ ""/var/foo"", ${EXTRA_VOLUMES} ]   # not sure of the best syntax
   image: ...
```

Without this feature, I can't use docker-compose directly and instead have to do unnatural things with yml substitution scripts and ""docker-compose -f -"".

PS: I don't know what's up with docker-compose and Swarm ""services"" on your roadmap. IMO Compose and the yml service definitions are a really nice way to define both simple and complicated environments.",,,dustinschultz,"
--
Relevant Stackoverflow question: https://stackoverflow.com/questions/50919605/docker-compose-variable-substitution-interpolation-with-list-map-or-array-va
--
",nevmerzhitsky,"
--
Please, implement this. Tuning networks list via orchestration of compose/swarm configs is really terrible.
--
",WaterYue,"
--
how about the new version, is the new version resolved array environment variable issue ?  @dustinlacewell Do you know if there have new solution about this?
--
",,,,,,
4246,OPEN,Outgoing network firewall configuration,kind/feature,2016-12-14 22:14:34 +0000 UTC,jrmoserbaltimore,Opened,,"As an addendum to Docker issue https://github.com/docker/docker/issues/29407

In the event the above feature is implemented, corresponding update to `docker-compose` should provide a `firewall` section:

```
wordpress:
  image: wordpress:fpm
  firewall:
    outgoing:
      - "":state:established,related:accept""
      - ""dns.example.com:udp:53:accept""
      - ""!10.0.0.0/8:tcp:80,443,21:accept""
      - ""::reject""
```

",,,,,,,,,,,,,,
4241,OPEN,Feature request: add support for starting container from checkpoint,kind/enhancement; status/0-triage,2020-10-06 14:11:00 +0000 UTC,tswift242,Opened,,"Checkpoint/restore support was merged into Docker in https://github.com/docker/docker/pull/22049, and will be released in Docker 1.13. Thus, add support for starting a container from a checkpoint in a compose file.",,,ImVexed,"
--
Suppose it's time for a bump! Any work being done on this?
--
",stale,"
--
This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you for your contributions.

--

--
This issue has been automatically marked as not stale anymore due to the recent activity.

--

--
This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you for your contributions.

--

--
This issue has been automatically marked as not stale anymore due to the recent activity.

--

--
This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you for your contributions.

--

--
This issue has been automatically marked as not stale anymore due to the recent activity.

--
",edurenye,"
--
I guess it will not happen until the feature does not leave the state of 'experimental' so we should put some pressure there. https://docs.docker.com/engine/reference/commandline/checkpoint
--

--
Any progress on this?
Another related resource: https://criu.org/Docker
--
",ndeloof,"
--
Internally tracked as https://docker.atlassian.net/browse/COMPOSE-93
--
",unixfox,"
--
Still interested
--
",,
4176,OPEN,Filter services by labels (Feature),area/cli; kind/feature,2016-11-23 02:22:51 +0000 UTC,brunocascio,Opened,,"Hi,

I think about filtering services by labels, for example:

`docker-compose config --services --filter 'label=somelabel'`

In shell scripts it would be awesome!",,,shin,"
--
Thanks for the suggestion!
--
",,,,,,,,,,
4133,OPEN,Add --exclude to docker-compose up,kind/feature,2020-10-20 09:18:08 +0000 UTC,philtay,In progress,,I have a Compose file with 10 services. I want to start only 8 of them. I can do `docker-compose up srv1 srv2 srv3 srv4 srv5 srv6 srv7 srv8` but it would be better to do `docker-compose up --exclude srv9 srv10`. Useful syntactic sugar IMO.,,,johnharris85,"
--
Is it common that you'd want to start a regular subset? If so then perhaps using `extends` would help the use case. Compose is meant to model an application / common set of container deployments. Not sure how common wanting to start a project that is missing a couple of containers would be (although happy to be enlightened!).

--
",philtay,"
--
Judging by the fact that Compose already supports starting a subset, I would say that it's common enough. Many other commands, not only `up`, also allow to specify the services by name. The current syntax makes it easy to specify a limited subset of the services (2 or 3) as opposed to a larger one.

--
",pmzajaczkowski,"
--
For my team it's very common to start all services apart of particular one. That's the case where you are developing some microservices and want to run all of them on your machine (using docker-compose) apart of that single one that you are currently developing and running from your IDE (for example in the debug mode). So that's :+1: from me for --exclude. But that --exclude should also override dependencies - if I don't want to start something it should never start :)
--
",yohanliyanage,"
--
I'm facing the same situation as @pmzajaczkowski. Having this feature is quite useful when testing microservices locally. 
--
",DemianTinkiel,"
--
+1 on suggestion. Definitely useful for my team
--
",echo,"
--
+1
--
"
4096,OPEN,Proposal: exec shortcuts,area/run; kind/feature,2019-05-22 09:26:38 +0000 UTC,mathroc,Opened,,"I'd like to propose a new feature to simplify using `docker-compose exec`.

In some case it could be an alternative #1896

docker-compose.yml example:

```yml
version: ""2""
services:
  my_service:
    image: my/service
shortcuts:
  backup:
    service: my_service
    entrypoint: rsync /some/thing
    command: ssh://some.where/
    privileged: true|false
    user: <username>
```

and usage:

```bash
docker-compose sc backup
docker-compose sc backup ssh://some.where.else/
```

or maybe (if `@backup` is not a valid service name)

```bash
docker-compose exec @backup
docker-compose exec @backup ssh://some.where.else/
```",,,shin,"
--
Thanks for the suggestion!

We will have to take another good look at #1896 sooner or later, so any feedback is welcome there as well.

--
",glensc,"
--
I like the issue number here :D

--
",vipseixas,"
--
+1
Very useful idea.

--
",,,,,,
4047,OPEN,docker-compose terminates if build directory is missing,,2020-11-10 07:27:20 +0000 UTC,hholst80,In progress,,"Summary:

`docker-compose` seems to pre-check that all build directories exists before running any commands. Even for commands where the build directory is not needed, like `docker-compose ps` or `docker-compose run ...`

Command:

```
docker-compose ps
```

Result:

```
ERROR: build path /omnicoder either does not exist, is not accessible, or is not a valid URL.
```

Expected result:

```
        Name                       Command               State              Ports
---------------------------------------------------------------------------------------------
api-server_1   npm start                        Up      3000/tcp
cron_1         /usr/sbin/crond -f -d 8 -c ...   Up
disbatcher_1   /usr/bin/tini -- python -m ...   Up
mongodb_1      /entrypoint.sh mongod            Up      27017/tcp
nginx_1        nginx -g daemon off;             Up      0.0.0.0:443->443/tcp, 80/tcp
```
",,,trodrigues,"
--
Just ran into this issue myself, in a situation where someone was trying to run a service and getting an error about a directory not existing.

The file in question defines multiple services. One of these services can run just this application (a REST API) and another one can run this application, and also build and run an image for an UI which talks to this API.

The person in question wanted only the API so they ran the service which starts only the API. But because there is a definition for that other service which runs both API and UI in the same file, and because this person didn't have the directory where the UI is built from, they got an error, preventing them from running their desired service.
--
",jhagege,"
--
+1 
--
",CodeCorrupt,"
--
I'm currently running into this issue with Jenkins deployment. I use the  `docker-compos build` command to build the images locally, then push them to the registry. From there I go to the production server and want to `dockere-compose rm -sf && docker-compose up` copying over only the compose file and I get this error.

I'm getting around the issue by simply creating an empty directory. but it's a rather clunky work around.
--
",afeilulu,"
--
+1
--
",hedleyroos,"
--
Docker compose is very useful for non-developers to quickly get an env up and running (eg. to demo) but this issue means you have to distribute a few files and not just a docker-compose.yml. It would be a very useful fix.
--
",italktocomputers,"
--
I can confirm this issue is present in docker-compose version 1.23.2, build 1110ad0.
--
"
3927,OPEN,UnixHTTPConnectionPool(host='localhost'; port=None): Read timed out. (read timeout=60),,2021-02-18 00:17:15 +0000 UTC,bodazhao,In progress,,"Hi since yesterday I've been running into this error while doing `docker-compose up`

**Full Error Message**

```
Device-Tracker $ docker-compose up
Creating device-tracker-db
Creating device-tracker

ERROR: for web  UnixHTTPConnectionPool(host='localhost', port=None): Read timed out. (read timeout=60)
Traceback (most recent call last):
  File ""<string>"", line 3, in <module>
  File ""compose/cli/main.py"", line 61, in main
  File ""compose/cli/main.py"", line 113, in perform_command
  File ""contextlib.py"", line 35, in __exit__
  File ""compose/cli/errors.py"", line 56, in handle_connection_errors
TypeError: log_timeout_error() takes exactly 1 argument (0 given)
docker-compose returned -1
```

**Docker Version**
Docker for Mac: 1.12.0-a (Build 11213)
**Machine info**
MacBook Air (13-inch, Early 2015)
Processor: 1.6 GHz i5
Memory: 4GB 1600 MHz DDR3
macOS: Version 10.11.6 (Build 15G1004)

**Attempts**
- Everything still works on colleagues' machine, they are using MacBook Pro 
- Increased Docker CPU from 2 to 3, and 2GB RAM to 3GB, still error
- Removed All Docker containers & images, and rebuild everything, still error
",,,bodazhao,"
--
tried this

```
export DOCKER_CLIENT_TIMEOUT=120
export COMPOSE_HTTP_TIMEOUT=120
```

and it seems to fix the issue for now

**Other solutions people mentioned in this thread:**

* Restart Docker
* Increase Docker CPU & memory
--
",shin,"
--
Does it happen if you turn off your WiFi? Could be related to https://github.com/docker/docker-py/issues/1076.

Another theory, if your service has `tty: True` enabled, could be #3106 

--
",gvilarino,"
--
I'm seeing exactly the same problem with latest beta for Mac. Same error if I run `docker-compose create`

Could this be related to having one very large layer in the image? (a very lengthy `npm install` operation that takes about a minute to be flattened into a layer when docker builds the image)

--

--
From different attempts at working around this, I found something that might shed some light on a possible fix:

At first my scenario looked a bit like this:

``` yaml
app:
  build: .
  volumes:
    - ${PWD}:/usr/src
    - /usr/src/node_modules
```

My mounted path included many directories with big, static files that I didn't really need mounted in terms of code reloading. So i ended up swapping for something like this:

``` yaml
app:
  build: .
  volumes:
    - ${PWD}:/usr/src
    - /usr/src/static  # large files in a long dir structure
    - /usr/src/node_modules
```

This left out of the runtime mounting all my big static files, which made the service start **way** faster.

What I understand from this is: the more files you mount, especially the larger they are (images in the MBs instead of source files in the Bs/KBs), loading times go up by a lot.

Hope this helps

--

--
@cherrot I wouldn't say I'm extremely proficient in the subject, but I believe this has to do with the storage driver used by Docker and how it works internally for keeping layers in order. Use `docker info` to see what storage driver your daemon is using (probably `aufs`, which is the slowest) and depending on your host OS, you may change it so something else (`overlay` being a better choice, if supported). There are faster alternatives like [LCFS](https://github.com/portworx/lcfs) but they aren't commercially supported by Docker so you'd be on your own there.
--
",60days,"
--
We are also seeing this issue using a docker compose file with 6 containers [docker-compose version 1.8.1, build 878cff1] on both windows and mac [Version 1.12.2-rc1-beta27 (build: 12496)
179c18cae7]

Increasing resources available to docker seems to reduce the chance of it happening (as does extending the timeout vars) , but its never eliminated. 

We also have some large-ish layers (240MB is the largest, the main package install command) and we are binding to a host directory with 120MB of files across a couple of containers.

--
",WayneYe,"
--
+1
I am seeing this timeout issue every single week, usually after an idle weekend, while I was trying to connect to me containers, it timed out...
I have to terminate the running docker proc and restart it to work around....
--
",ALibrada,"
--
+1 
It happens to me every time I try to restart the containers because they are not responding anymore after a day. I'm not sure if my case has to do with the mounting since I am trying to stop the containers.
--
"
3909,OPEN,abort-on-container-exit not working if a service is given,kind/question,2021-01-22 00:46:52 +0000 UTC,fchennouf,In progress,,"Hi everybody,

Is it normal that abort-on-container-exit option of the up command is not working if a service is given for example: docker-compose up --abort-on-container-exit web doesn't stop the db service if the web service stops, whereas docker-compose up --abort-on-container-exit stops it

version: '2'

services:

```
db:
      image: postgres:9.3

web:
      build: ./
      links:
              - db
```

Client:
 Version:      1.12.1
 API version:  1.24
 Go version:   go1.6.3
 Git commit:   23cf638
 Built:        Thu Aug 18 05:22:43 2016
 OS/Arch:      linux/amd64

Server:
 Version:      1.12.1
 API version:  1.24
 Go version:   go1.6.3
 Git commit:   23cf638
 Built:        Thu Aug 18 05:22:43 2016
 OS/Arch:      linux/amd64

docker-compose version 1.8.0, build f3628c7
docker-py version: 1.9.0
CPython version: 2.7.9
OpenSSL version: OpenSSL 1.0.1e 11 Feb 2013
",,,shin,"
--
Hi!

I believe that is the expected behavior, yes. The command you're running `docker-compose up [...] web` is explicit about handling the `web` service, and not any other - having it stop the `db` service, which as far as compose is concerned is running independently, would seem very counter-intuitive to me. Is there a specific reason why you need to do things that way?

--
",fchennouf,"
--
Hi Shin,
Thanks for the answer. In my view  --abort-on-container-exit should work as long as linked containers are started. If I give a service like web in param, by default linked services are also started and I think that  --abort-on-container-exit should by default stopped these services. What I wanna do is to put two diffrent configurations of a service in the compose file (web1 and web2 for example), and i can precise one of the service if i want to separately start it with its linked containers.

--
",MicahZoltu,"
--
We also are running into problems with this.  We are using `docker-compose` for integration testing and so we do `docker-compose up ... test app_under_test`.  This will allow us to see the console output for `app_under_test` and `test` but it won't show us the massive spam of output from our dependencies like MySQL, Zookeeper, Kafka, etc. which in almost all cases we don't care about, isn't under our control, and is very noisy.

However, after the `test` container exits only the `app_under_test` also exits, which leaves all of the dependencies running indefinitely even though they are no longer used.  They just sit there consuming resources and (in some cases) bound to ports.

@shin- Can you help me understand the scenario under which you believe the current behavior is correct?  To me, a `docker-compose` collection is a single contiguous unit.  Presumably they would all come and go together in most cases.  Is that not how you use `docker-compose`?  Is that not how `docker-compose` is intended to be used?

--

--
@GraemeF Assuming you have your dependencies setup correctly in `docker-compose.yml`, then you can just do `docker-compose up integration-tests --abort-on-container-exit` and I _believe_ that will do what you want and only terminate the docker-compose execution if `integration-tests` service exits.  If any of the things that `integration-tests` depends on exits, I _think_ it will keep running.
--

--
Hmm, I just tested this again and I am witnessing the same behavior, the dependency containers are not exited when the primary container is with `--abort-on-container-exit`.  However, if I don't specify a service (e.g., just `docker-compose up --abort-on-container-exit`) then all of the containers exit.  Maybe I'm just mis-remembering how this used to work?   
--

--
I believe this should remain open.  While it does seem low priority, I believe the current behavior is quite counter intuitive and arguably wrong.
--
",ronin1,"
--
We actually have the same need for our integration test in CI. We only care about our application container (where we have the app). Sometimes the tests are run directly on the application container, sometimes we run it on a separate test container and if the test pass or fail, we would like to tear down all containers.  Is there an easy way to do this with docker-compose?
--
",markbirbeck,"
--
I see what you are getting at @shin-, that when you explicitly start a service you aren't saying anything about the other services in the `docker-compose.yml` file, and so it might be counterintuitive to change the state of any services that Docker Compose didn't start.

But it also seems counterintuitive to _not_ stop any services that were started as a consequence of using `depends_on`. It completely threw me that secondary containers weren't being shut down once integration tests were complete.

Any thoughts on that aspect?
--
",amithgeorge,"
--
Any updates on this? Same use-case. Same issue. 
--
"
3896,OPEN,Docker-compose up exiting with code 0,,2020-08-30 11:05:23 +0000 UTC,karneaud,In progress,,"## expected behaviour

start container and expose container bash
## actual behaviour

starts up the container then exits the container shutting down the container
## software/ hardware specs

Virtual box 5.0.24
Docker 1.2.11
Docker-compose version 1.8.0
OSX Yosemite
## issue description

I'm trying to run a container using docker-compose via docker-compose.yml files but the process seems to start up the container and exits with a code 0 when running the command `docker-compose -f docker-compose.yml -f docker-compose-dev.yml up` . I really need to run some bash commands and live the container up and running
here is my docker-compose.yml

```
services:
  ngcracealong-rsync:
    # command: [""watch"",""-n3"",""ls -la""]
    command: 'bash'
    # entrypoint: '/bin/bash'
    # entrypoint: ""lein with-profile dev do start-dev""
    container_name: 'docker-clojurescript'
    environment:
      - TERM=xterm
      - COMPOSE_HTTP_TIMEOUT=200
      - DEBUG=true
    expose:
      - ""3000""
      - ""9000""
    image: rand/docker-clojurescript
    ports:
      - ""3000:3000""
      - ""9000:9000""
    working_dir: '/data'
    read_only: false
    privileged: true
    # tty: true
    # command: ""/bin/bash ls -la""
version: '2'
```

in a docker-compose-dev.yml

```
services:
  ngcracealong-rsync:
    volumes:
      - ngcracealong-rsync-sync:/data:rw
version: '2'
volumes:
  ngcracealong-rsync-sync:
    external: true
```

trying to execute a command like '/bin/bash ls -l' leads to some erroneous errors like 'commands not found' I can only assume that the commands are running before volumes are   setup

a --verbose output yields

>  compose.config.config.find: Using configuration files: ./docker-compose.yml,./docker-compose-dev.yml
> docker.auth.auth.load_config: File doesn't exist
> compose.cli.command.get_client: docker-compose version 1.8.0, build unknown
> docker-py version: 1.9.0
> CPython version: 2.7.10
> OpenSSL version: OpenSSL 0.9.8zh 14 Jan 2016
> compose.cli.command.get_client: Docker base_url: https://192.168.99.103:2376
> compose.cli.command.get_client: Docker version: KernelVersion=4.4.17-boot2docker, Os=linux, BuildTime=2016-08-18T17:52:38.255390991+00:00, ApiVersion=1.24, Version=1.12.1, GitCommit=23cf638, Arch=amd64, GoVersion=go1.6.3
> compose.cli.verbose_proxy.proxy_callable: docker info <- ()
> compose.cli.verbose_proxy.proxy_callable: docker info -> {u'Architecture': u'x86_64',
>  u'BridgeNfIp6tables': True,
>  u'BridgeNfIptables': True,
>  u'CPUSet': True,
>  u'CPUShares': True,
>  u'CgroupDriver': u'cgroupfs',
>  u'ClusterAdvertise': u'',
>  u'ClusterStore': u'',
>  u'Containers': 4,
>  u'ContainersPaused': 0,
> ...
> compose.cli.verbose_proxy.proxy_callable: docker inspect_network <- (u'ngcracealongdocker_default')
> compose.cli.verbose_proxy.proxy_callable: docker inspect_network -> {u'Containers': {},
>  u'Driver': u'bridge',
>  u'EnableIPv6': False,
>  u'IPAM': {u'Config': [{u'Gateway': u'172.18.0.1',
>                         u'Subnet': u'172.18.0.0/16'}],
>            u'Driver': u'default',
>            u'Options': None},
>  u'Id': u'bce4ac5ee716ed4b0b2b184632fd2a83423b78120fe51b9788d9b59ca248d669',
>  u'Internal': False,
>  u'Labels': {},
> ...
> compose.cli.verbose_proxy.proxy_callable: docker inspect_volume <- ('ngcracealong-rsync-sync')
> compose.cli.verbose_proxy.proxy_callable: docker inspect_volume -> {u'Driver': u'local',
>  u'Labels': None,
>  u'Mountpoint': u'/mnt/sda1/var/lib/docker/volumes/ngcracealong-rsync-sync/_data',
>  u'Name': u'ngcracealong-rsync-sync',
>  u'Scope': u'local'}
> compose.volume.initialize: Volume ngcracealong-rsync-sync declared as external. No new volume will be created.
> compose.cli.verbose_proxy.proxy_callable: docker containers <- (all=False, filters={u'label': [u'com.docker.compose.project=ngcracealongdocker', u'com.docker.compose.oneoff=False']})
> compose.cli.verbose_proxy.proxy_callable: docker containers -> (list with 0 items)
> compose.cli.verbose_proxy.proxy_callable: docker containers <- (all=True, filters={u'label': [u'com.docker.compose.project=ngcracealongdocker', u'com.docker.compose.service=ngcracealong-rsync', u'com.docker.compose.oneoff=False']})
> compose.cli.verbose_proxy.proxy_callable: docker containers -> (list with 1 items)
> compose.cli.verbose_proxy.proxy_callable: docker inspect_container <- (u'dfbae0eb3e7589786a8d9bf71bbe8a01cc22088cc88a4d0fa2b06fbccb29742d')
> compose.cli.verbose_proxy.proxy_callable: docker inspect_container -> {u'AppArmorProfile': u'',
>  u'Args': [u'with-profile', u'dev', u'do', u'start-dev'],
>  u'Config': {u'AttachStderr': False,
>              u'AttachStdin': False,
>              u'AttachStdout': False,
>              u'Cmd': None,
>              u'Domainname': u'',
>              u'Entrypoint': [u'lein',
>                              u'with-profile',
>                              u'dev',
> ...
> compose.cli.verbose_proxy.proxy_callable: docker inspect_image <- ('rand/docker-clojurescript')
> compose.cli.verbose_proxy.proxy_callable: docker inspect_image -> {u'Architecture': u'amd64',
>  u'Author': u'Rand Fitzpatrick rand.fitzpatrick@gmail.com',
>  u'Comment': u'',
>  u'Config': {u'AttachStderr': False,
>              u'AttachStdin': False,
>              u'AttachStdout': False,
>              u'Cmd': [u'bash'],
>              u'Domainname': u'',
>              u'Entrypoint': None,
>              u'Env': [u'PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin',
> ...
> compose.cli.verbose_proxy.proxy_callable: docker containers <- (all=True, filters={u'label': [u'com.docker.compose.project=ngcracealongdocker', u'com.docker.compose.service=ngcracealong-rsync', u'com.docker.compose.oneoff=False']})
> compose.cli.verbose_proxy.proxy_callable: docker containers -> (list with 1 items)
> compose.cli.verbose_proxy.proxy_callable: docker inspect_image <- ('rand/docker-clojurescript')
> compose.cli.verbose_proxy.proxy_callable: docker inspect_image -> {u'Architecture': u'amd64',
>  u'Author': u'Rand Fitzpatrick rand.fitzpatrick@gmail.com',
>  u'Comment': u'',
>  u'Config': {u'AttachStderr': False,
>              u'AttachStdin': False,
>              u'AttachStdout': False,
>              u'Cmd': [u'bash'],
>              u'Domainname': u'',
>              u'Entrypoint': None,
>              u'Env': [u'PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin',
> ...
> compose.cli.verbose_proxy.proxy_callable: docker inspect_container <- (u'dfbae0eb3e7589786a8d9bf71bbe8a01cc22088cc88a4d0fa2b06fbccb29742d')
> compose.cli.verbose_proxy.proxy_callable: docker inspect_container -> {u'AppArmorProfile': u'',
>  u'Args': [u'with-profile', u'dev', u'do', u'start-dev'],
>  u'Config': {u'AttachStderr': False,
>              u'AttachStdin': False,
>              u'AttachStdout': False,
>              u'Cmd': None,
>              u'Domainname': u'',
>              u'Entrypoint': [u'lein',
>                              u'with-profile',
>                              u'dev',
> ...
> compose.parallel.feed_queue: Pending: set([<Service: ngcracealong-rsync>])
> compose.parallel.feed_queue: Starting producer thread for <Service: ngcracealong-rsync>
> compose.service.start_container_if_stopped: Starting docker-clojurescript
> compose.cli.verbose_proxy.proxy_callable: docker attach <- (u'dfbae0eb3e7589786a8d9bf71bbe8a01cc22088cc88a4d0fa2b06fbccb29742d', stream=True, stderr=True, stdout=True)
> compose.cli.verbose_proxy.proxy_callable: docker attach -> <generator object _multiplexed_response_stream_helper at 0x1015b8730>
> compose.cli.verbose_proxy.proxy_callable: docker start <- (u'dfbae0eb3e7589786a8d9bf71bbe8a01cc22088cc88a4d0fa2b06fbccb29742d')
> compose.parallel.feed_queue: Pending: set([])
> compose.cli.verbose_proxy.proxy_callable: docker start -> None
> compose.parallel.parallel_execute_iter: Finished processing: <Service: ngcracealong-rsync>
> compose.parallel.feed_queue: Pending: set([])
> Attaching to docker-clojurescript
> compose.cli.verbose_proxy.proxy_callable: docker events <- (decode=True, filters={u'label': [u'com.docker.compose.project=ngcracealongdocker', u'com.docker.compose.oneoff=False']})
> compose.cli.verbose_proxy.proxy_callable: docker events -> <generator object _stream_helper at 0x1015b8780>
> docker-clojurescript  | 'start-dev' is not a task. See 'lein help'.
> docker-clojurescript  | Error encountered performing task 'do' with profile(s): 'dev'
> docker-clojurescript  | Task not found
> compose.cli.verbose_proxy.proxy_callable: docker wait <- (u'dfbae0eb3e7589786a8d9bf71bbe8a01cc22088cc88a4d0fa2b06fbccb29742d')
> compose.cli.verbose_proxy.proxy_callable: docker inspect_container <- (u'dfbae0eb3e7589786a8d9bf71bbe8a01cc22088cc88a4d0fa2b06fbccb29742d')
> compose.cli.verbose_proxy.proxy_callable: docker inspect_container -> {u'AppArmorProfile': u'',
>  u'Args': [u'with-profile', u'dev', u'do', u'start-dev'],
>  u'Config': {u'AttachStderr': False,
>              u'AttachStdin': False,
>              u'AttachStdout': False,
>              u'Cmd': None,
>              u'Domainname': u'',
>              u'Entrypoint': [u'lein',
>                              u'with-profile',
>                              u'dev',

Can someone help me figure ut what is going wrong here? 
",,,shin,"
--
I would uncomment `tty: true`, and run `COMPOSE_HTTP_TIMEOUT=8000 ocker-compose -f docker-compose.yml -f docker-compose-dev.yml up`

--

--
`tty`? It has not been removed from the spec. There's an issue with HTTP timeouts, as pointed out in #3633, which is why I suggested to work around it using `COMPOSE_HTTP_TIMEOUT=8000` (or more if you need a longer session).

--

--
I'm sorry to hear you're having a frustrating experience :( Do you mind clarifying what the issue you're running into is?

--

--
I must admit I am not familiar with how `docker-sync` works, but I was able to run a long-lived container using the following config:

docker-compose.yml

``` yaml
services:
  ngcracealong-rsync:
    entrypoint: ['bash']
    container_name: 'docker-clojurescript'
    environment:
      - DEBUG=true
    expose:
      - ""3000""
      - ""9000""
    image: rand/docker-clojurescript
    ports:
      - ""3000:3000""
      - ""9000:9000""
    working_dir: '/data'
    read_only: false
    privileged: true
    tty: true
version: '2'
```

docker-compose-dev.yml

``` yaml
services:
  ngcracealong-rsync:
    volumes:
      - ngcracealong-rsync-sync:/data:rw
version: '2'
volumes:
  ngcracealong-rsync-sync:
    external: true
```

And running `docker-compose -f docker-compose.yml -f docker-compose-dev.yml up` seems to start properly. Do you see any significant difference with your current setup that could account for the differences?

--
",karneaud,"
--
@shin- read on another issue that this was removed from the spec.....is this option still available? users had issues using it as it caused the containers to hang

--

--
@shin- well I tried your solution and no dice. Must say this has been a frustrating week debugging this docker tooling framework rather than working on my own project ....sigh

--

--
simple. I'm using `docker-sync` framework to start and sync a container and access its shell to run some commands but as stated in the issue....it seems to ""exit"" upon creation not sure why it is doing this. 

--

--
other than I'm running on an external drive and trying to mount a volume from my host file system no..... I'm not familiar with docker-compose but if i were to use `docker run` everything would work as expected. So I'm not sure why docker compose is acting this way....I'm using docker-sync because their process seems to speed things up with respect to syncing files in developing on the fly....

From the looks of things thought Vagrant is looking pretty awesome right about now

--

--
@zuernBernhard `tty:true` hangs
--
",zuernBernhard,"
--
tty: true was key :)
--
",cpapidas,"
--
i have the same problem

--

--
@karneaud  I already use it. The problem is that I use vagrant with docker.  When docker use volume and vagrant use share folder then the container stops immediately.  
--
",ehongyu,"
--
`tty: true` doesn't work for me
--
",flik,"
--

I have the same issue: here is my docker-compoe file:

```
version: '3'

services:
    xdev:
      build:
        context: .
        dockerfile: ./docker/development/Dockerfile
      container_name: xdev
      expose:
        - ""80""
        - ""443""
      ports:
        - ""80:80""
        - ""443:443""
      tty: true
      volumes:
        - .:/var/www/html
      #depends_on:
      #  - oracledb
    
    oracledb:
      image: wnameless/oracle-xe-11g
      expose:
        - ""1521""
      ports:
        - ""1521:1521""
```

$docker-compose up 
Recreating xdev ... 
Recreating xdev ... done
Attaching to xdev_oracledb_1, xdev
xdev        | => Xdebug is already configured
xdev        | => Starting Apache ...
oracledb_1  | Starting Oracle Net Listener.
oracledb_1  | Starting Oracle Database 11g Express Edition instance.
oracledb_1  | 
oracledb_1  | /usr/sbin/startup.sh: ignoring /docker-entrypoint-initdb.d/*
oracledb_1  | 
oracledb_1  | Starting Oracle Net Listener.
oracledb_1  | Starting Oracle Database 11g Express Edition instance.
oracledb_1  | 
oracledb_1  | /usr/sbin/startup.sh: ignoring /docker-entrypoint-initdb.d/*
oracledb_1  | 
xdev exited with code 0
--

--
I have the same issue but then found the error. 
 I was writing some wrong command in Docker file.

So need to investigate the issue you need to comment your commands and check with rebuild. It will show you the issue. 
--
"
3874,OPEN,When using multiple docker-compose.yml files from different directories; local paths are not followed correctly.,kind/enhancement; status/0-triage,2020-08-21 11:54:28 +0000 UTC,brocoli,Opened,,"Consider the following command, working from `~/myproj/`:

`docker-compose -f docker-compose.yml -f somesubmodule/docker-compose.yml up`

Suppose `somesubmodule/docker-compose.yml` contains the following

```
services:
  myservice:
    build:
      context: ./myservice
```

`docker-compose up` fails because it will try to build `myservice` from `~/myproj/myservice/docker-compose.yml` instead of `~/myproj/myservice/somesubmodule/docker-compose.yml`.

The error message is something like: `ERROR: build path ~/myproj/myservice/ either does not exist, is not accessible, or is not a valid URL.`

This happened with docker-compose version 1.8.0-rc1, build 9bf6bc6, installed from Homebrew on my Mac OS X Yosemite version 10.10.5

Note that simply running `docker-compose -f somesubmodule/docker-compose.yml up` works fine, it's probably a glitch due to merging yml files and losing locality. Relative paths should be expanded before merging instead.
",,,lhm,"
--
I'm having the same problem. It makes pulling together the docker-compose configs from multiple projects somewhat difficult. It appears as if only the first context is being used when combining multiple files:

```
$ pwd
/tmp/dc

$ tree
.
 p1
  Dockerfile
  docker-compose.yml
 p2
     Dockerfile
     docker-compose.yml

2 directories, 4 files

$ cat p1/docker-compose.yml 
version: '2'
services:
  p1:
    build:
      context: .
    command: echo 'hello from p1'

$ cat p2/docker-compose.yml 
version: '2'
services:
  p2:
    build:
      context: .
    command: echo 'hello from p2'

$ docker-compose -f p1/docker-compose.yml -f p2/docker-compose.yml config
networks: {}
services:
  p1:
    build:
      context: /private/tmp/dc/p1
    command: echo 'hello from p1'
  p2:
    build:
      context: /private/tmp/dc/p1
    command: echo 'hello from p2'
version: '2.0'
volumes: {}

$ docker-compose -v
docker-compose version 1.10.0, build 4bd6f1a
```

In the example above I'd expect that the build context of p2 be `/private/tmp/dc/p2`

I made a repo for it here: https://github.com/lhm/docker-compose-contexts-issue
--
",MrHash,"
--
Is there any workaround for this problem?
--
",dpnova,"
--
FWIW I have created an empty compose config at the root of my project:
```
version: ""3""
```
Then make sure it's included all the time:

`docker-compose -f ./docker-compose.yml -f ./somewhereelse/docker-compose.yml -f ./1/2/3/docker-compose.yml up`

In doing this, you then use the same relative path for volumes and context in all the other compose configs through the project.

I'm going to create a command line wrapper for my team so they don't have to think about it too much.
--

--
You need to keep in mind that when you do a `build` compose sends stuff to the docker daemon, it's then outside of the context of compose. You should run compose with the verbose flag to see what the paths in your `build` section are being translated to when being sent to the docker daemon.
--
",bgiorgini,"
--
It didn't work for me adding the emtpy docker-compose.yml file in the root. Still the other 2 compose files get mixed up with the paths, taking the first relative path for all the other images to build.
Anyone else found another solution for this?

With the same sample files I got this:
```
  /tmp docker-compose -f docker-compose.yml -f ./p1/docker-compose.yml -f ./p2/docker-compose.yml config
services:
  p1:
    build:
      context: /private/tmp/p1
    command: echo 'hello from p1'
  p2:
    build:
      context: /private/tmp/p1
    command: echo 'hello from p2'
version: '2.0'

  /tmp docker-compose version
docker-compose version 1.14.0, build c7bdf9e
docker-py version: 2.3.0
CPython version: 2.7.12
OpenSSL version: OpenSSL 1.0.2j  26 Sep 2016
  /tmp docker version
Client:
 Version:      17.06.1-ce
 API version:  1.30
 Go version:   go1.8.3
 Git commit:   874a737
 Built:        Thu Aug 17 22:53:38 2017
 OS/Arch:      darwin/amd64

Server:
 Version:      17.06.1-ce
 API version:  1.30 (minimum version 1.12)
 Go version:   go1.8.3
 Git commit:   874a737
 Built:        Thu Aug 17 22:54:55 2017
 OS/Arch:      linux/amd64
 Experimental: true
```
--
",joeyhub,"
--
I think there is a lot of confusion here with people wanting different things.

I want the behaviour described in the original ticket which should be possible to fix with a stub docker-compose file. some people don't want that behaviour. I have lots of compose files in subdirectory where I want the path to always be treated as from the root path for the project directory. There are limits on volume (not supporting relative) and I have some limits on symlink usage.

However with version 2 at least this doesn't appear to work (docker-compose.yml in base directory). It seems that the path is now enforced as being relative to the specific file loaded at least for build paths.

This is something where it would be great to give the user more control. It's currently inconsistent and hard to find appropriate documentation on.

For example with version 2, including a base configuration works for setting a new base path for extends.file but not for build.context. Except on investigation it turns out that it is working except that extends doesn't take the path from the first configuration file used.

I'm really pulling my hair out with this because it does all kinds of strange things automatically taking control over the user rather than giving the user control and visibility. It's not only this but things like not being able to extend VOLUME in the Dockerfiles and finding myself doing things like putting in dummy services just to build and tag an image. I find myself working around these tools more than working with them.

At least with extends gone (ironically a work around to have it work the other way around) I suppose that inconsistency is not an issue any more, however it would be nice to be able to specify the base directory rather via argument rather than having a dummy file for it.
--

--
ZimbiX, docker compose I believe just wraps docker and some of those strings in the configuration will go all the way down through to the shell command.

That means that for volume you might be able to get away with something like:

    volume: ""${STANDARD_ENVVAR}/path:/container/mountpoint""
--
",fabriziocucci,"
--
I've found [this](https://docs.docker.com/compose/extends/#understanding-multiple-compose-files) link particularly clear when it comes to using multiple compose files.

I'm not sure whether the page has been published recently or whether the behavior described matches the current implementation but it _kind of_ makes sense.

Specifically:

> Understanding multiple Compose files
> ...
> When you use multiple configuration files, you must make sure all paths in the files are relative to the base Compose file (the first Compose file specified with -f). This is required because override files need not be valid Compose files. Override files can contain small fragments of configuration. Tracking which fragment of a service is relative to which path is difficult and confusing, so to keep paths easier to understand, all paths must be defined relative to the base file.

Although, I don't particularly agree that this should be _the only way_ of handling relative paths and I can try to elaborate a little bit more by providing a simple example.

Suppose you have the following:
```
my-project
|
|----> service-a (git submodule)
|          |
|          -----> docker-compose.yml
|
|----> service-b (git submodule)
|          |
|          -----> docker-compose.yml
|
 -----> docker-compose.yml
```
where:
1. `service-a` requires MongoDB to be stand up by itself, so its `docker-compose.yaml` should be a valid compose file, i.e. I should be able to `cd service-a && docker-compose up`, so paths should be relative to the `service-a` folder;
2. `service-b` requires Neo4j to be stand up by itself, so its `docker-compose.yaml` should be a valid compose file, i.e. I should be able to `cd service-b && docker-compose up`, so paths should be relative to the `service-b` folder;
3. the `docker-compose.yml` in `my-project` adds other services that should be used in combination with the docker compose files of `service-a` and `service-b`, i.e. I should be able to `cd my-project && docker-compose -f docker-compose.yml -f service-a/docker-compose.yml -f service-b/docker-compose.yml up`. In order for this to work, paths in the `docker-compose.yml` of `service-a` and `service-b` should be relative to `my-project`.

So it appears that you need to either settle for 1 and 2 **or** 3, but not all of them (unless you introduce some duplication). Maybe a simple solution would be to treat paths as relative to the `docker-compose.yml` file where they appear.

Is there a ""nice"" workaround to currently handle this scenario?
--
"
3849,OPEN,docker-compose .env file not support dynamic values,kind/feature,2020-08-03 01:25:38 +0000 UTC,nevergone,Opened,,"It's work:
CURRENT_UID=1000

It's not work:
(other command result)
CURRENT_UID=$(id -u)

(previous defined environment variable)
CURRENT_UID=$UID
",,,ilinum,"
--
I would be interested in tackling this issue :)
Is this something that would be useful?
--
",adiabuk,"
--
Has there been any progress with this?  I would definitely find it useful
--
",dmitry,"
--
As I know it's still not possible in the latest compose versions.
--
",SvenDowideit,"
--
I'm interested in this for use with vault - but at some point, this would mean it needs to be able to have an interactive ""enter username and password"" 
--
",,,,
3729,OPEN,allow removing something in docker-compose.override.yml,,2021-02-10 19:59:03 +0000 UTC,stefanfoulis,Opened,,"My usecase is that the base `docker-compose.yml` maps a certain port in the `ports` section. In my `docker-compose.override.yml` I'd like to change that port since I already have a different service running there on my host.
As far as I understand the current implementation it is only possible to add stuff, override extends the other file.
As far as I can tell there is no way to remove an entry. And I can't think of an obvious syntax for it.
",,,aanand,"
--
Correct. Best practice is to not include anything in `docker-compose.yml` that you might not want to have in another environment.

--
",nkovacs,"
--
My problem with your suggestion is that docker-compose.override.yml might not exist (it's an optional file the developer can create locally). I only want to use docker-compose.override.yml to locally customize ports, like this:

docker-compose.yml:

```
version: '2'
services:
    web:
        ports:
            - 80
            - 443
        ...
```

docker-compose.override.yml:

```
version: '2'
services:
    web:
        ports:
            - 32080:80
            - 32443:443
```

This isn't a big deal because this will only result in 80 being exposed twice, once as a random port and once as 32080. I think it would make sense in this case to only expose it as 32080 automatically (without having to specify anything in the override to remove the original config value)

--
",tomekit,"
--
Facing the same problem. I've got one specific host which shouldn't start the one of the docker containers for given service. Yeah, maybe my `docker-composer.yml` approach is not the best, but I can see the need of removing something.
--
",paunin,"
--
Did anyone get script to remove ports from docker-compose file ? :) 

--

--
Alright, there is no solution so far, so I got a simple port-remover 
https://github.com/paunin/docker-compose-v2-ports-remover

In general I dont think docker-compose should allow to do it, as then logic of merging many files is gonna be complex... 
--
",bluemoehre,"
--
This was already solved here https://github.com/docker/compose/pull/3939
--
",jedie,"
--
It's also not possible to removed a service, isn't it?
--
"
3715,OPEN,driver_opts should support the same commands as docker volume create --opt,,2020-10-05 08:52:29 +0000 UTC,DJviolin,In progress,,"I have the following `docker-compose.yml`:

``` yaml
version: '2'

services:
  app:
    build: ./app
    container_name: myapp
    volumes:
      #- ""../app:/root/www/myapp:rw""
      - myapp:/root/www/myapp:rw

volumes:
  myapp:
    #driver: local
    driver_opts:
      o: uid=500,gid=500
      device: ../app
```

I have a hard time to figure out how to attach a named volume from the host machine to the container. I following this resource: https://docs.docker.com/engine/reference/commandline/volume_create/

This throws the following error:

``` shell
ERROR: for app  no such device
ERROR: Encountered errors while bringing up the project.
```

Thank You for your help!

``` shell
core@core-1 ~ $ docker -v
Docker version 1.11.2, build 4a6e2b1
core@core-1 ~ $ docker-compose -v
docker-compose version 1.8.0-rc1, build 9bf6bc6
```
",,,cpuguy83,"
--
@DJviolin The driver opts you are specifying here are not going to work. You can't create a bind mount like this, and you can't change uid/gid's on bind mounts, unfortunately.

--

--
@DJviolin driver_opts should work (I've not tried to use them with compose) for volumes... just not with these options.

--

--
@mferrier `proto` is not a supported opt, you would need `o` with a csv list, just like `mount -o`
e.g.
```yaml
volumes:
  app_volume:
  driver_opts:
    type: nfs
    device: /export/path
    o: proto=tcp,addr=1.2.3.4
--

--
@denhams This is because the options you've supplied are not valid.
Specifically: `o: 10.172.48.39,rw` should be something like `o: addr=10.172.48.39,rw` and `device` needs to be `device: :/var/whus/images`... this is just due to how the nfs kernel module parses this.

~~Also not really related since `version: '2'` is not supported by docker, only compose.~~
[ EDIT] sorry, thought this was on another issue that looks similar.
--
",DJviolin,"
--
So the `driver_opts` mentoined here is not work at all in `volumes`, just only in `networks`?

https://docs.docker.com/compose/compose-file/#/driver-opts

It is also specified for `networks` config:

https://docs.docker.com/compose/compose-file/#/driver-opts-1

I thought `driver_opts` implementing the `docker volume` command?

https://docs.docker.com/engine/reference/commandline/volume_create/#/driver-specific-options

So what you are saying I still need to use host volume mount in the good old-fashioned way?

``` yaml
    volumes:
      - ""../app:/root/www/myapp:rw""
```

--
",xeor,"
--
Should this work now? I just tried a volume like this in my compose-file:

```
volumes:
  servicename:
    driver: local
    driver_opts:
      type: ""nfs""
      o: ""addr=10.1.2.3,rw""
      device: "":/data/servicename""
```

but it gives me an error;

```

ERROR: for servicename  Cannot create container for service servicename: no such file or directory
ERROR: Encountered errors while bringing up the project.
```

Should this work now?

```
Client:
 Version:      1.12.2-rc1
 API version:  1.23
 Go version:   go1.6.3
 Git commit:   45bed2c
 Built:        Tue Sep 27 23:38:15 2016
 OS/Arch:      darwin/amd64
 Experimental: true

Server:
 Version:      1.12.1
 API version:  1.24
 Go version:   go1.6.3
 Git commit:   23cf638
 Built:
 OS/Arch:      linux/amd64

docker-compose version 1.8.1, build 878cff1
docker-py version: 1.10.3
CPython version: 2.7.9
OpenSSL version: OpenSSL 1.0.2h  3 May 2016
```

--

--
Should docker-compose using `volumes` do exactly the same as `docker volume create` in this case?

I'm getting this error:
```sh
$ docker-compose up
Starting backup_borg_1

ERROR: for borg  Cannot start service borg: invalid argument
ERROR: Encountered errors while bringing up the project.
```

Using a `docker-compose` like this, for testing:
```yml
version: '2'

services:
  borg:
    image: alpine
    command: sleep 10000
    volumes:
      - backupdata:/data

volumes:
   backupdata:
     driver_opts:
       type: nfs
       device: :/docker/backup
       o: addr=10.1.2.3,rw
```

However, creating the volume manually and mounting it with a normal `docker run` works.
```
docker volume create --driver local --opt type=nfs --opt o=addr=10.1.2.3,rw --opt device=:/docker/backup --name backupdata
```
Including a `docker-compose` like this after the creation of the volume;

```yml
volumes:
  backupdata:
    external: true
```

Using docker and docker-compose on osx. dockerd is on `CentOS 7`
`docker-compose version 1.9.0, build 2585387`

```
Client:
 Version:      1.13.0-rc2
 API version:  1.24
 Go version:   go1.7.3
 Git commit:   1f9b3ef
 Built:        Wed Nov 23 17:40:58 2016
 OS/Arch:      darwin/amd64

Server:
 Version:             1.12.3
 API version:         1.24
 Minimum API version:
 Go version:          go1.6.3
 Git commit:          6b644ec
 Built:
 OS/Arch:             linux/amd64
 Experimental:        false
```

Should this have worked? Or does docker-compose behave differently? Bug? How can I provide more info?

If I look at the container docker-compose creates (if I look at `docker-compose --verbose up` output), the `docker inspect` > `mounts` stanza looks the same as the container that works.
--

--
@cpuguy83: your suggestions is what I am trying, see previous comment. I have the same problem as well
--
",mferrier,"
--
I'm trying to do the same thing and wondering if it's actually not possible to pass the same `--opt` style options to the volume definition in docker-compose or what?

Is there a list of the accepted `driver_opts` for volume definitions? The docker-compose volume [docs](https://docs.docker.com/compose/compose-file/) refer to the `docker volume create` [docs](https://docs.docker.com/engine/reference/commandline/volume_create/) which refer to the `mount` [docs](http://man7.org/linux/man-pages/man8/mount.8.html), but clearly not all the same options that can be passed to `docker volume create` work with volume `driver_opts` in docker-compose. 

e.g. with 
```
volumes:
  app_volume:
    driver: local
    driver_opts:
      type: nfs
      proto: tcp
```

`ERROR: create format_app_volume: invalid option key: ""proto""`

Is the only option to create the volume with `docker volume create` and then use `external` ?
--

--
I also tried all the suggestions here with no luck. I was trying to get it working for sharing source for local development, so if it helps anyone else, I eventually got it working by:
1. Going back to Docker Machine (from Docker for Mac)
1. Using [docker-machine-nfs](https://github.com/adlogix/docker-machine-nfs) to automatically share the directory to the docker machine, which in turn automatically shares its nfs mounts with any containers run on it, including those from the host OS.
--
",dschu,"
--
I'm currently experiencing the same error as @xeor and don't know how to solve this. 
--
",denhams,"
--
I'm also seeing the same problem:

```
version: '2'

services:
  apache:
    build:
      context: .
      dockerfile: ./docker/Dockerfile-debug
    volumes:
      - ./:/var/www/app
      - ./docker/apache/app.conf:/etc/httpd/conf.d/app.conf
      - image_store:/var/www/betslip/shared/storage/images
volumes:
    image_store:
        driver_opts:
            type: nfs
            o: 10.172.48.39,rw
            device: /var/whus/images
```
This gives:

ERROR: for apache  Cannot start service apache: invalid argument
ERROR: Encountered errors while bringing up the project.

--
"
3660,OPEN,Docker compose pull doesn't respect local images,kind/question,2021-02-23 17:10:21 +0000 UTC,antony,In progress,,"During my searches I've seen this issue raised and closed a few times, but even using the latest build of docker-compose, this still doesn't behave the way I understand that it is expected to.

Scenario:
We're building a composed environment for our CI tests to run. We grab a database image, an api image, and a _local_ copy of the image containing application we are trying to test (it has been built in a previous CI step, and tagged with the build hash provided by our CI environment (CIRCLE_SHA1)

docker-compose.yml

``` yaml
api:
  image: mycompany/api

undertest:
  image: mycompany/undertest:${CIRCLE_SHA1}

db:
  image: mycompany/db
```

The commands we run then are as follows:

``` bash
docker-compose pull # Because we definitely want the latest db, and api for a true test.
docker-compose up # compose the environment
```

Actual Result:
No matter what I do, docker compose always tries to pull my CIRCLE_SHA1 tagged version from  docker hub. it doesn't exist there, I never want to push it (until it passes tests and is re-tagged as :latest and/or :release 

I have a unique tag CIRCLE_SHA1 which only exists inside the build environment, meaning no confusion for docker-compose when it tries to pull, and yet, it seems to try to fetch it anyway, and fail even though that exact tag exists locally.

Expected Result:
I'd expect the fact that there is no remote build tagged with CIRCLE_SHA1 to cause docker-compose to use the local copy it finds. I need to do pull, because I want everything else to be the latest.

I'd suggest that if there is confusion where `image:` refers to a remote repository, then perhaps we could use `local:` instead, to reference a local image?
",,,decoomanj,"
--
I'm facing similar issues. I use the --ignore-pull-failures option when I do a docker-compose pull. This basically ignores ALL errors. It is ok as a workaround. We do the same thing in our pipeline. I pull other production-images and start my freshly build release-candidate container locally. When the tests are ok, it's uploaded.

--
",johnharris85,"
--
I don't see this is a issue / bug with current functionality. `pull` is doing exactly that, how would it know in your original compose file that 2 images should be pulled remotely but one should be grabbed locally (seeing as they all probably exist locally right, you just want to 'refresh' the other two?).

Perhaps a --filter option to pull? So something like:

```
docker-compose.yml
version: '2'
services:
  api:
    image: mycompany/api
    labels:
      - ""refresh""
  undertest:
    image: mycompany/undertest:${CIRCLE_SHA1}
  db:
    image: mycompany/db
    labels:
      - ""refresh""
```

Then:

 `docker-compose pull --filter ""label=refresh""`

@aanand @dnephin thoughts?

--

--
Both of those options seem kind of sub-optimal. 

It's not really a 'failure' to ignore, more of a separate use case. 

The second option means you're having to declare some behavior / state outside of the compose file. I.e. I have all of this automated but then want to change which images are pulled and which aren't, I probably want that to be reflected in my compose file as a single-point-of-truth, but I have to edit the pull command instead.

--
",dnephin,"
--
`--ignore-pull-failures` was added for this very reason. 

You could also do `docker-compose pull db api` to only pull the ones you wanted.

--

--
> The second option means you're having to declare some behavior outside of the compose file. 

Yes, and in this case I think that's correct. The behaviour that is external to the Compose file is not the behaviour of a container, but part of your project dev workflow. Compose is not a project workflow tool. It's a tool for orchestrating containers.

The Compose file should really only include configuration for those containers. How to pull an image is not container configuration, it's part of the workflow, and currently all of those options are commands and flags. I think this is an important distinction. Trying to mix both would make the Compose file very confusing.

 The equivalent of `--prefer-local` is to just never run `docker pull` in the first place. Any missing images will be pulled before trying to run the container.

--
",antony,"
--
I'd agree with @johnharris85 on `--ignore-pull-failures` not feeling like the option to use. Something like `--prefer-local` would work - but I'd still probably prefer a concrete `local: my-org/my-image:tag` to make for a clearer intent.

I didn't know you could pull specific images, so thanks for that @dnephin - the downside being, this would move knowledge about the composure of my stack outside the compose file, whereas for me a compose file is a one-stop encapsulation of my architecture.

--
",JashaadGaines,"
--
Problem: `docker-compose -f docker-compose.yml up` -> doesn't look locally for the image at all. 
I agree @johnharris85 - These options are suboptimal. Docker is sort of acting like a dependency manager or at least one dependency resolver. It pulls images from a specified/default repo then/and only then, commences it's docker process. In the same way gradle, ant, maven, gulp, npm, etc. pull dependencies and define processes the user can run. The standard has been set for Dependency Mgr/Resolvers, look locally first (sometimes cache or something), then pull from repo. I'm trying to think of a really pressing reason why docker would want to force you to look at the repo first. Just like @antony & @decoomanj I don't want to push any images that don't even satisfy our lowest level of quality threshold: unit tests. Not to mention any other test suite. 

Suggestion: 
rancher-compose offers a --pull option to insure you're getting the latest image from the repo. It would be great if docker-compose looked for images locally first then to the repo. And if necessary there can be a --pull option to force docker to only search for images in the repo.  
--
",martindariocernadas,"
--
Any clues how to avoid this issue?
--
"
3608,OPEN,Undefined default build arg is sent as empty string to docker build; instead of not sent,area/config; kind/enhancement,2020-09-30 15:05:20 +0000 UTC,thomas-riccardi,Opened,,"In issue #3281 `compose < 1.8.0-rc1` incorrectly sent undefined default build args as `'None'` string to `docker build`, it was fixed by PR #3449 (included in `compose 1.8.0-rc1`) by sending an empty string instead to `docker build`.

I think it would be better to just not send the undefined build args to `docker build`, so that the default value for the build arg defined in `Dockerfile` would apply.
# Scenario:
## Files

`Dockerfile`:

```
FROM ubuntu:14.04

ARG FOO=1
RUN echo ""-${FOO}-""

CMD /bin/bash
```

`docker-compose.yml`:

```
version: '2'

services:
  test:
    build:
      context: .
      args:
        - FOO
```
## Execution:

```
$ ./docker-compose-1.8.0-rc1 --verbose config
networks: {}
services:
  test:
    build:
      args:
        FOO: ''
      context: /home/riccardi/git/ses-docker/test-default-build-arg
version: '2.0'
volumes: {}

```

```
$ ./docker-compose-1.8.0-rc1 --verbose build
compose.config.config.find: Using configuration files: ./docker-compose.yml
docker.auth.auth.load_config: Found 'auths' section
docker.auth.auth.parse_auth: Found entry (registry=u'docker-registry-stag.systran.net:5000', username=u'systran')
compose.cli.command.get_client: docker-compose version 1.8.0-rc1, build 9bf6bc6
docker-py version: 1.8.1
CPython version: 2.7.9
OpenSSL version: OpenSSL 1.0.1e 11 Feb 2013
compose.cli.command.get_client: Docker base_url: http+docker://localunixsocket
compose.cli.command.get_client: Docker version: KernelVersion=4.4.0-21-generic, Os=linux, BuildTime=2016-04-26T23:30:23.291099901+00:00, ApiVersion=1.23, Version=1.11.1, GitCommit=5604cbe, Arch=amd64, GoVersion=go1.5.4
compose.service.build: Building test
compose.cli.verbose_proxy.proxy_callable: docker build <- (pull=False, stream=True, nocache=False, tag=u'testdefaultbuildarg_test', buildargs={u'FOO': ''}, rm=True, forcerm=False, path='/home/riccardi/git/ses-docker/test-default-build-arg', dockerfile=None)
docker.api.build._set_auth_headers: Looking for auth config
docker.api.build._set_auth_headers: Sending auth config (u'docker-registry-stag.systran.net:5000')
compose.cli.verbose_proxy.proxy_callable: docker build -> <generator object _stream_helper at 0x7f8a18739b40>
Step 1 : FROM ubuntu:14.04
 ---> 8f1bd21bd25c
Step 2 : ARG FOO=1
 ---> Using cache
 ---> a8c68a88ef6d
Step 3 : RUN echo ""-${FOO}-""
 ---> Running in c03d7e477353
--
 ---> 17f6ac07ea06
Removing intermediate container c03d7e477353
Step 4 : CMD /bin/bash
 ---> Running in 47164716758d
 ---> 5ef78af6532b
Removing intermediate container 47164716758d
Successfully built 5ef78af6532b
compose.cli.verbose_proxy.proxy_callable: docker close <- ()
compose.cli.verbose_proxy.proxy_callable: docker close -> None
```
# Issue
## Expected result:

prints `-1-`.
## Actual result:

prints `--`.
## `<1.8.0-rc1` result:

prints `-None-`.
# Details

`compose 1.8.0-rc1` behavior is better than previous `compose` versions: it could be accepted as a correct behavior.
However, I believe the behavior could be improved further by expecting `-1-` as result, not `--`: if docker compose has no value for the build arg, then it should let `docker build` apply its own default value that comes from the `Dockerfile`.

Changing from `--` to `-1-` is a breaking change, so I suggest to release it in 1.8.0 if this behavior is accepted.

Without this feature, I have to duplicate the default value both in `Dockerfile` and in `.env` read by `docker-compose` (or just in `.env`, but in this case the `Dockerfile` cannot be used alone, without `docker-compose`), and I think the best place for the default value is in the `Dockerfile` only.
",,,thomas,"
--
@aanand any thoughts ?

--

--
> If we change the behaviour as you suggest, it's impossible to override a build arg's default value with an empty value. i.e. if the Dockerfile contains FOO=1, I can't override that with FOO=.

`FOO=` and `FOO` are not the same thing, if you want to override `ARG FOO=1` from the `Dockerfile`  with empty string, you can either put `args: [ FOO= ]` in the `docker-compose.yml`, or in the `.env`, so I don't see any issue here.

However, your 3rd point is valid: indeed, docker engine treats `--build-arg FOO` as `--build-arg FOO=` if `FOO` is not defined in the `docker build` process environment.

I understand your point about keeping the same behavior on both `engine` and `compose`.
I'll open an issue in docker engine for that.

I'd like to point out that this docker engine feature is not documented anywhere (neither in https://docs.docker.com/engine/reference/commandline/build/, nor in https://docs.docker.com/engine/reference/builder/).
I suggest to not document it for compose either so it'll be easier to change the behavior without it being considered as a breaking change.

Thanks

PS: maybe this issue can be closed for now; I'm not sure what procedure to follow in this case.

--

--
@agilgur5 I like your `docker-compose build myservice --build-arg MYBUILDARG=argggg` idea! You probably should open a new issue for that.

--

--
bash-style Inline defaults also has the drawback that the default value must be duplicated on each usage of the variable.
--

--
This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you for your contributions.

--
author:	thomas-riccardi
association:	none
edited:	false
status:	none
--
Let's create activity here to keep the issue open, because I assume the issue is still there if no compose developer talked about it here, and we have recent documented workarounds...

--
",aanand,"
--
Sorry about the delay - been catching up post-DockerCon.

So here's the tradeoff:
1. If we leave the behaviour as it is in master, it's impossible to write a Compose file where the argument's value can be _optionally_ overridden by the environment or `.env` file, unless you repeat the default value in the Compose file.
2. If we change the behaviour as you suggest, it's impossible to override a build arg's default value with an empty value. i.e. if the Dockerfile contains `FOO=1`, I can't override that with `FOO=`.

It's a difficult call, but I think what sways it is the analogous behaviour of `docker build --build-arg`. From manual testing, I think the behaviour in master mirrors that of `docker build --build-arg`, and should therefore not be changed. Here's an example:

``` console
$ cat Dockerfile
FROM alpine
ARG FOO=1
RUN [""sh"", ""-c"", ""echo '>>>' FOO=$FOO '<<<'""]

$ docker build --no-cache .
Sending build context to Docker daemon 3.072 kB
Step 1 : FROM alpine
 ---> 4e38e38c8ce0
Step 2 : ARG FOO=1
 ---> Running in 71f0b88d767c
 ---> 0a5b70556553
Removing intermediate container 71f0b88d767c
Step 3 : RUN sh -c echo '>>>' FOO=$FOO '<<<'
 ---> Running in fa5ec958c69b
>>> FOO=1 <<<
 ---> c9e8ee8d0593
Removing intermediate container fa5ec958c69b
Successfully built c9e8ee8d0593

$ docker build --build-arg FOO --no-cache .
Sending build context to Docker daemon 3.072 kB
Step 1 : FROM alpine
 ---> 4e38e38c8ce0
Step 2 : ARG FOO=1
 ---> Running in 8a4c80867daa
 ---> 68a4c7db60b9
Removing intermediate container 8a4c80867daa
Step 3 : RUN sh -c echo '>>>' FOO=$FOO '<<<'
 ---> Running in fff6482af7a4
>>> FOO= <<<
 ---> d2e4fdee15fb
Removing intermediate container fff6482af7a4
Successfully built d2e4fdee15fb
```

As you can see, specifying an empty value for `FOO` does indeed override the default set in the Dockerfile. As much as possible, in cases like these we try to stick to mirroring the behaviour of the `docker client`. I can hear a case for the alternate behaviour being better, but if it's going to change in Compose, it should change in Engine first.

--

--
We can leave this open for the purposes of discussion and to track the Engine issue - please link to it from here once you've created it. Thanks!

--
",agilgur5,"
--
Similarly ran into this problem and agree with the proposal by @triccardi-systran.
I'd also like to mention that without using a `.env` file, the optional override is _impossible_. I often use Compose from a subdirectory, and as `.env` is read from the current working directory (https://docs.docker.com/compose/env-file/), it effectively prevents me from using the subdirectory feature as such (unless I have a `.env` file defined in every subdirectory...). The only solution in my case ends up having to use `MYBUILDARG=thedefault docker-compose build ...` for all `build` commands :/

I also think Compose should support passing the build args as arguments to `docker-compose build`, i.e. just like `docker-compose run` now supports the `-e` option (to mirror `docker`), `docker-compose build` could support the `--build-arg` option as well. For my use case at least, this would eliminate the need to even use an unset option in `args`, as instead of

```
args:
  - MYBUILDARG
```

I could then use `docker-compose build myservice --build-arg MYBUILDARG=argggg`

--

--
Still agree with all the above comments, but just wanted to note that as of v1.9 and the 2.1 file format, Compose supports bash-style inline defaults, which means optional build args without a `.env` file _are_ possible now. As @triccardi-systran noted though, you have to duplicate the default value in `Dockerfile` to be in `docker-compose.yml` as well, due to this bug and no support for `--build-arg` (#3790), which is quite annoying and prone to mistakes.


With inline defaults it looks likes this:
```
build:
  args:
    - SOMEBUILDARG=$SOMEBUILDARG:-thedefault
```
--

--
Indeed, that's why I wrote:
> As @triccardi-systran noted though, you have to duplicate the default value in Dockerfile to be in docker-compose.yml as well, due to this bug and no support for --build-arg (#3790), which is quite annoying and prone to mistakes.

Just that with inline defaults you don't need a `.env` file anymore
--
",electrofelix,"
--
I've encountered this impacting use of proxy related variables, and part of the it is that the behaviour between args and environment is not consistent.

Reading https://docs.docker.com/compose/compose-file/#/args and https://docs.docker.com/compose/compose-file/#/environment, one would expect the same behaviour from both.

Given a service defined as follows:
```
services:
  jenkins:
    image: jenkins:latest
    build:
      context: ./jenkins
      args:
        - HTTP_PROXY
        - HTTPS_PROXY
        - NO_PROXY
        - http_proxy
        - https_proxy
        - no_proxy
    environment:
      - HTTP_PROXY
      - HTTPS_PROXY
      - NO_PROXY
      - http_proxy
      - https_proxy
      - no_proxy
      - JAVA_OPTS=-Djenkins.install.runSetupWizard=false
      - JENKINS_OPTS=--prefix=/jenkins
```
If you happen to only have http_proxy & https_proxy defined but not HTTP_PROXY & HTTPS_PROXY defined what you will see during the build is that HTTP_PROXY and HTTPS_PROXY are set to '', which causes anything checking the environment for these variables to assume that their existance means no proxy is defined, rather than moving onto checking the lowercase versions as well.

This can cause all sorts of opaque issues building with docker-compose behind proxies because the behaviour for the environment versions of these is different. I've discovered that apk will not check for http_proxy if it finds HTTP_PROXY set to an empty string.

You could argue the software should check for both variations, however given the difference in behavour when dealing with environment settings, such as if you have an image built, and using the same unset/set variables listed above, and run `docker-compose run -u root jenkins env` you will not see HTTP_PROXY or HTTPS_PROXY appearing in the output.

This is because for environment:
```
    environment:
        - SOMEVAR
```
SOMEVAR is considered optional, and is only picked up from the environment of the user if defined.

It seems like it would be much better to have the behaviour of args and environment consistent, and since environment has been around for longer, I would suggest that following it's behaviour rather than changing environment to follow the newer behaviour of args will have less of an impact.


Perhaps it would be better if instead of having:
```
    build:
        args:
            - SOMEVAR
```
pass through a variable as being empty, require that someone provide '=', with nothing after it to indicate that it's intended to override with an empty value.

This would match the existing behaviour for environment, and avoid surprising behaviour.

### Override SOMEVAR in Dockerfile only if defined in user environment:
```
    build:
        args:
            - SOMEVAR
```
OR
```
    build:
        args:
            SOMEVAR:
```

### Override SOMEVAR in Dockerfile with blank value
```
    build:
        args:
            - SOMEVAR=
```
or
```
    build:
        args:
            SOMEVAR: """"
```
### Override SOMEVAR in Dockerfile with different value
```
    build:
        args:
            - SOMEVAR=my_value
```
or
```
    build:
        args:
            SOMEVAR: my_value
```

This seems to give the flexibility needed to be able to override with blank values, while also retaining the ability to pass through certain env variables only if set.
--

--
This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you for your contributions.

--
author:	electrofelix
association:	none
edited:	false
status:	none
--
AFAIK the problem still exists and is why I've had to avoid docker compose for building of images due to the inconsistency
--
",schurig,"
--
Something like this would be amazing:

```yaml
# docker-compose.yml
services:
  app:
    build:
      context: .
      args:
        - NODE_VERSION=${cat .node-version}
```

```Dockerfile
# Dockerfile
FROM node:${NODE_VERSION}
```
  
--
author:	
association:	none
edited:	false
status:	none
--
My workaround example:
```yml
# docker-compose.yml
services:
  app:
    build:
      args:
        CONTAINERPILOT_VERSION: ""${CONTAINERPILOT_VERSION:-}""
```

```
# Dockerfile
ARG CONTAINERPILOT_VERSION
ENV CONTAINERPILOT_VERSION=${CONTAINERPILOT_VERSION:-""3.8.0""}
```

with this implementation I need to define default version only in Dockerfile, and my docker-compose file is proxying ARG from optional env var
--
",stale,"
--
My workaround example:
```yml
# docker-compose.yml
services:
  app:
    build:
      args:
        CONTAINERPILOT_VERSION: ""${CONTAINERPILOT_VERSION:-}""
```

```
# Dockerfile
ARG CONTAINERPILOT_VERSION
ENV CONTAINERPILOT_VERSION=${CONTAINERPILOT_VERSION:-""3.8.0""}
```

with this implementation I need to define default version only in Dockerfile, and my docker-compose file is proxying ARG from optional env var
--
author:	stale
association:	none
edited:	false
status:	none
--
This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you for your contributions.

--

--
Let's create activity here to keep the issue open, because I assume the issue is still there if no compose developer talked about it here, and we have recent documented workarounds...

--
author:	stale
association:	none
edited:	false
status:	none
--
This issue has been automatically marked as not stale anymore due to the recent activity.

--

--
This issue does not have a true workaround. The workarounds presented do not solve the core issue as requested by @thomas-riccardi :

- having a default for ARGs being defined in Dockerfile only (which would be the apt place as it allows one to use Dockerfiles without compose and keep defaults behavior consistent)
- not having to specify these defaults in multiple places in order to achieve the above

The workaround given by @idetoile ***does not work for ARGs***. They still behave as when this issue was first open, regardless of having been able to use bash inline defaults.

Furthermore, use of bash inline defaults are documented ***nowhere***, apart from being nonchalantly glossed over in the section on Scope for ARGs in Dockerfile reference, so this particular issue is the documentation for the matter, which also adds to the frustration.

Anyway,

Given compose file:

```yaml
version: '3'

services: 
    test:
        build:
            context: .
            args:
                FOO: ${FOO:-}
```

and Dockerfile:

```
FROM alpine
ARG FOO=${FOO:-2}
RUN echo ""-- $FOO --""
```

Issuing `docker build --build-arg FOO --no-cache .`

Results in the relevant lines being:

    Step 3/3 : RUN echo ""-- $FOO --""
     ---> Running in 48cd1eaaaf2c
    -- 2 --

Whereas running `docker-compose build` results in:

    Step 3/3 : RUN echo ""-- $FOO --""
     ---> Running in 935f9a469215
    --  --

Which means that the 2017 merge of PR to @thomas-riccardi issue in docker upstream solved this issue in docker itself, but compose still does something wrong when passing the argument. 
--
author:	stale
association:	none
edited:	false
status:	none
--
This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you for your contributions.

--

--
AFAIK the problem still exists and is why I've had to avoid docker compose for building of images due to the inconsistency
--
author:	stale
association:	none
edited:	false
status:	none
--
This issue has been automatically marked as not stale anymore due to the recent activity.

--
"
3593,OPEN,Support `cp' sub command,area/cli; kind/feature; status/0-triage,2020-09-30 00:34:04 +0000 UTC,arnisoph,In progress,,"For now, `docker-compose cp` is missing. :)

```
$ docker-compose -v
docker-compose version 1.7.1, build 0a9ab35
```

```
$ docker-compose -h
Define and run multi-container applications with Docker.

Usage:
  docker-compose [-f <arg>...] [options] [COMMAND] [ARGS...]
  docker-compose -h|--help

Options:
  -f, --file FILE             Specify an alternate compose file (default: docker-compose.yml)
  -p, --project-name NAME     Specify an alternate project name (default: directory name)
  --verbose                   Show more output
  -v, --version               Print version and exit
  -H, --host HOST             Daemon socket to connect to

  --tls                       Use TLS; implied by --tlsverify
  --tlscacert CA_PATH         Trust certs signed only by this CA
  --tlscert CLIENT_CERT_PATH  Path to TLS certificate file
  --tlskey TLS_KEY_PATH       Path to TLS key file
  --tlsverify                 Use TLS and verify the remote
  --skip-hostname-check       Don't check the daemon's hostname against the name specified
                              in the client certificate (for example if your docker host
                              is an IP address)

Commands:
  build              Build or rebuild services
  config             Validate and view the compose file
  create             Create services
  down               Stop and remove containers, networks, images, and volumes
  events             Receive real time events from containers
  exec               Execute a command in a running container
  help               Get help on a command
  kill               Kill containers
  logs               View output from containers
  pause              Pause services
  port               Print the public port for a port binding
  ps                 List containers
  pull               Pulls service images
  restart            Restart services
  rm                 Remove stopped containers
  run                Run a one-off command
  scale              Set number of containers for a service
  start              Start services
  stop               Stop services
  unpause            Unpause services
  up                 Create and start containers
  version            Show the Docker-Compose version information
```
",,,ocramz,"
--
@bechtoldt What should `cp` do?

--
",ain,"
--
`docker-compose cp <container> <path> <local path>`, e.g.

```
$ docker-compose cp db /var/lib/postgresql ~/Downloads/database_backup
```

--

--
@bechtoldt @ocramz I also filed #3609 earlier, would offer great value when working with data across containers.

--

--
Currently not. I'm using `docker cp` still. Somewhat inconvenient since you always need to know the ID or the name of the container.
--
",arnisoph,"
--
@ocramz ^

--
",ColinHebert,"
--
That would be an awesome feature.

On top of that a support of `copy` in the configuration file (#1664) would be perfect

--
",29e7e280,"
--
+1 for this feature. need copy some files into running container

--
",dorgan,"
--
+1.... having to build a container to get a large file or 2 updates is a pain.

--
"
3541,OPEN,compose control network domain name,kind/feature; status/0-triage,2019-10-22 05:50:26 +0000 UTC,dwaite,In progress,,"When I create a ""foo.com"" network with docker-compose, the network appears to be changed and to be dynamic.

The containers themselves talk to each other with TLS, and do hostname validation. So, the DNS resolution for my network has to have the services be addressed in the form of ""foo.bar.com"".

Today I'm handling this by having docker-compose attach to an externally created network so that I can control the FQDN. Is there another way to accomplish this?
",,,shin,"
--
Are you looking for [`aliases`](https://docs.docker.com/compose/compose-file/#aliases)?

--

--
They're always fully qualified.

--

--
This should work, unless I'm misunderstanding the use case.

```
version: ""2""
networks:
  bar.com:
services:
  foo:
    networks:
      bar.com:
        aliases:
          - foo.bar.com
```

--
",dwaite,"
--
Are aliases within a domain, or can they be FQDNs?

--

--
I believe my issue is that for:

``` xml
version: ""2""
networks:
  bar.com:
services:
  foo:
    networks:
      bar.com:
```

a FQDN is created based on the service label (not dynamic container name) and the dynamic network name (not network label). So my service isn't reachable as `foo.bar.com`, but something like `foo.folder_bar.com`.

Would it be worth opening an issue that there should be a default alias created of `foo.bar.com`?

--

--
Yes, it does. I'm wondering if I should open an issue that that particular alias should be automatic under compose - today without specifying an alias, your service will wind up with a DNS name in the form of foo.foldername_bar.com 

--
",WolfgangFahl,"
--
This report is more than a year old and for me falls in to the category of useability issues. The workaround above is non intuitive and most awkward. Setting the fqdn foo.bar.com directly would IMHO be most sensible.
--

--
Again automatically closed with no fix. The need is still there - how do you no that it's not?
--

--
How about teaching the bot not to close issues that have a certain comment content /number of upvotes or the like?
--
",stale,"
--
This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you for your contributions.

--

--
This issue has been automatically closed because it had not recent activity during the stale period.

--

--
This issue has been automatically marked as not stale anymore due to the recent activity.

--

--
This issue has been automatically marked as not stale anymore due to the recent activity.

--
",glours,"
--
We added the bot to do some automatic cleanup & get more visibility on what's really matter or not.
There's currently too much issues open, some for years, and it can be difficult to prioritize what to do.

When the bot mark an issue as stale, you only have to add a comment to remove this status.

I reopen the issue
--
",,
3513,OPEN,pull requires valid build path,area/build; area/config; kind/question,2020-09-21 07:58:29 +0000 UTC,tanmayambre,In progress,,"```
docker-compose version
docker-compose version 1.7.0, build 0d7bf73
docker-py version: 1.8.0
CPython version: 2.7.9
OpenSSL version: OpenSSL 1.0.1e 11 Feb 2013

```

I have a docker-compose file 

```
version: '2'
services:
    xyzservice:
    image: xxx-image
    container_name: xxx_container
    build:
      context: ./somecontext
      dockerfile: Dockerfile.xxx
    networks:
      - some-network

```

When I want to build the image using `docker-compose build`, I understand that the **_Dockerfile.xxx**_ is absolutely required.

But if I just want to pull the image using `docker-compose pull` why is the **Dockerfile.xxx** required?

I get the following error on pull command

```
ERROR: build path ./somecontext either does not exist, is not accessible, or is not a valid URL.
```
",,,shin,"
--
You don't need the `build` section if you're just going to pull the image. Your compose file should be

``` yaml
version: '2'
services:
    xyzservice:
    image: xxx-image
    container_name: xxx_container
    networks:
      - some-network

```

--
",tanmayambre,"
--
Thanks,
My scenario is the developer requires the buildpath to build & push the container while if someone wants to just run the container without build just pulling mage using same compose file.

--
",fvanderbiest,"
--
This issue is annoying for our [use case](https://github.com/georchestra/georchestra/blob/16.12/docs/docker.md) where the compose file is used both to build and run the app. Valid build paths should **not** be required to run `docker-compose pull` IMO.
--
",Elyytscha,"
--
this is annoying, just saying
--

--
its not stale its still annoying
--

--
yep its fixed with 1.27.0, thanks alot! could be closed now i think
--
",zypA13510,"
--
Are you sure this is `kind/question`? @docker/maintainer

As noted by @**fvanderbiest** and other people, there are valid use cases where pulling without building is required. Could you please consider this as an enhancement?
--
",yamac,"
--
This is seriously annoying and makes no sense. Could you please implement this?
--
"
3480,OPEN,Releases; code should be digitally signed,area/packaging; kind/enhancement; status/0-triage,2021-02-10 17:13:38 +0000 UTC,sanmai-NL,Opened,,"Apparently the releases, e.g. the latest [1.7.1](/docker/compose/releases/tag/1.7.1), are not being signed, neither the Git tags nor the artifacts (executables). This reduces the confidence users can have in the integrity of your release process.
",,,TotallyPro,"
--
This issue clearly deserves a higher significance, not feature but requirement!
Anyone security conscious will, and should, have serious questions about credibility when missing...
--
",damianb,"
--
Having no way to verify a binary as being official via a cryptographic signature (e.g. GPG) and then having instructions for users to install by using sudo, curl altogether blindly is a blatant disregard for best practices for software distribution.

At minimum, please start signing *release binaries*.  No way can I or many others pull in docker-compose from a random URI (HTTPS or not) without some way of verifying who built the binary in the first place.
--

--
Issue still persists - please disable stale bot suspense of issue until issue is remediated.
--
",stale,"
--
This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you for your contributions.

--

--
This issue has been automatically marked as not stale anymore due to the recent activity.

--

--
This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you for your contributions.

--

--
This issue has been automatically marked as not stale anymore due to the recent activity.

--

--
This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you for your contributions.

--

--
This issue has been automatically marked as not stale anymore due to the recent activity.

--
",sanmai,"
--
Activity.
--

--
The only lack of activity is on the part of Docker, Inc.
--
",ndeloof,"
--
Internally tracked as https://docker.atlassian.net/browse/COMPOSE-92
cc @jcsirot 
--
",janoking,"
--
hello ?
--
"
3476,OPEN,Allow mixing of the default bridge with other networks,area/networking,2021-02-14 16:22:53 +0000 UTC,far-blue,Opened,,"In the V2 config it is not possible to define a custom network for a composed group of containers and then have a limited number of those containers also exposed on the default bridge. This is because the default bridge doesn't support network aliases.

It would be very helpful if compose knew how to handle this situation. Or, I guess, alternatively, maybe docker itself needs an option to disable legacy mode on the default bridge.
",,,leyyinad,"
--
This would be absolutely helpful with nginx-proxy, see here:
https://github.com/jwilder/nginx-proxy/issues/487#issuecomment-230093806

--
",pdeveltere,"
--
+1 for allowing containers to be exposed on the default bridge
--
",Creased,"
--
**EDIT:** Finally, I was able to solve the following issue using a custom docker network (e.g., `front`). For the moment, since we can't to do so using the default bridge because of the legacy mode, you can follow steps described [here](http://git.bmoine.fr/chl-docker) with such [this project](http://git.bmoine.fr/chl-docker-webdev-env)...

<hr>

Hi, just wondering if there is any updates about this issue?

TL;DR: Trying to set up a front network stack over a custom bridge (pre-existing bridge) along with an internal network (public and private network at the same time) without using port-mapping or IPTables, but bridges.

I'm trying to set up such this [project](http://git.bmoine.fr/chl-docker-webdev-env), here is a try:

```yaml
version: '3.0'
networks:
    back:
        driver: bridge
        driver_opts:
            com.docker.network.bridge.enable_ip_masquerade: ""false""
            com.docker.network.internal: ""true""
        internal: true
        ipam:
            driver: default
            config:
                - subnet: 10.1.0.0/24
    front:
        external:
            name: bridge
services:
    db:
        image: mariadb:latest
        container_name: db
        environment:
            MYSQL_DATABASE: app
            MYSQL_PASSWORD: app-admin
            MYSQL_ROOT_PASSWORD: root
            MYSQL_USER: admin-app
        ports:
            - 3306:3306/tcp
        # network_mode: bridge
        networks:
            - back
        restart: always
        volumes:
            - ${ROOT}/conf/mysql/my.cnf:/etc/mysql/conf.d/my.cnf:ro
            - dbdata:/var/lib/mysql:rw
    http:
        build: build/nginx
        container_name: http
        links:
            - php
        ports:
            - 80:80/tcp
            - 443:443/tcp
        # network_mode: bridge
        networks:
            - front
        restart: always
        volumes:
            - ${ROOT}/conf/nginx/nginx.conf:/etc/nginx/nginx.conf:ro
            - ${ROOT}/conf/nginx/conf.d:/etc/nginx/conf.d:ro
            - ${ROOT}/data/www/webroot:/usr/share/nginx/webroot:ro
            - ${ROOT}/data/www/lab:/usr/share/nginx/lab:ro
            - ${ROOT}/data/www/vendor:/usr/share/nginx/vendor:ro
            - ${ROOT}/data/www/static:/usr/share/nginx/static:ro
            - ${ROOT}/log/nginx:/usr/share/nginx/log:rw
    php:
        build: build/php-fpm
        container_name: php
        links:
            - db
        privileged: true
        # network_mode: bridge
        networks:
            - front
            - back
        restart: always
        command: php-fpm --allow-to-run-as-root
        volumes:
            - ${ROOT}/conf/php-fpm/www.conf:/etc/php5/fpm/pool.d/www.conf:ro
            - ${ROOT}/conf/php/php.ini:/usr/local/etc/php/php.ini:ro
            - ${ROOT}/data/www/webroot:/usr/share/nginx/webroot:ro
            - ${ROOT}/data/www/lab:/usr/share/nginx/lab:ro
            - ${ROOT}/data/www/vendor:/usr/share/nginx/vendor:rw
volumes:
    dbdata:
        driver: local
```

I've set up a custom bridge (`/etc/network/interfaces`):

```
# Loopback NIC
auto lo
iface lo inet loopback

# Ethernet NIC
auto eth0
allow-hotplug eth0
iface eth0 inet manual

auto br0
iface br0 inet static
    bridge_ports eth0
    address 172.16.57.148
    netmask 255.255.0.0
    gateway 172.16.10.1
    dns-search miletrie.lan
    dns-nameservers 172.16.57.146 172.16.10.32 172.16.10.33
```

And, configured my dockerd to use it instead of the default docker0 bridge:

```bash
systemctl stop docker.service docker.socket
ip link set dev docker0 down
brctl delbr docker0
cat <<-'EOF' >/etc/default/docker
##
# Location of Docker binary (especially for development testing)
#
DOCKERD=""/usr/bin/dockerd""

##
# General daemon startup options
# https://docs.docker.com/engine/reference/commandline/docker/
#
DOCKER_OPTS=""--ip=0.0.0.0 \
             --ipv6=false \
             --ip-masq=false \
             --ip-forward=false \
             --iptables=false \
             --userland-proxy=false \
             --icc=true \
             --bridge=br0 \
             --fixed-cidr=172.16.57.224/28 \
             --dns=172.16.10.32 \
             --dns=172.16.10.33 \
             --dns-search=miletrie.chl""

EOF
cat <<-'EOF' >/etc/systemd/system/docker.service.d/exec.conf
[Service]
EnvironmentFile=-/etc/default/docker
ExecStart=
ExecStart=/usr/bin/dockerd $DOCKER_OPTS

EOF
systemctl daemon-reload
systemctl restart docker.service docker.socket
```

Complete steps are described [here](http://git.bmoine.fr/chl-docker).

Now, when I try to set up the project:

```bash
docker-compose pull
docker-compose build
docker-compose up -d
```

It returns the following error:

```bash
ERROR: for php  Network-scoped alias is supported only for containers in user defined networks
ERROR: Encountered errors while bringing up the project.
```

Please let me know if you need more information!

Looking forward to hearing from you!
--
",Qix,"
--
Almost a year and a half and no word on this error message? It's so incredibly vague and this issue is the top result for it.

Can we get some information here?
--

--
The stale bot is the worst thing to happen to GitHub.
--
",liudonghua123,"
--
> This would be absolutely helpful with nginx-proxy, see here:
> [jwilder/nginx-proxy#487 (comment)](https://github.com/jwilder/nginx-proxy/issues/487#issuecomment-230093806)

I have the same problem, and I also posted a question in https://stackoverflow.com/questions/57782423/how-to-make-a-docker-compose-service-to-use-multiple-network, but still got little help.
--
",khimaros,"
--
This would be very helpful for gradual migration to user defined networks.

@Creased -- you mentioned you had found a workaround. The link provided seems to no longer work -- could you describe the steps here?
--

--
This is still relevant.
--
"
2999,OPEN,docker-compose host-ip value should defaults to the --ip value of docker daemon,area/config; kind/bug,2021-02-10 09:30:26 +0000 UTC,bbinet,Opened,,"If we don't specify host ip address when declaring the ports in the compose file, like:

```
ports:
  - ""8000:8000""
```

docker-compose will assume the host ip address to use is `0.0.0.0`, but if we run the docker daemon with the `--ip=<default-ip>` option, it should use `<default-ip>` instead.

See in the [docker daemon documentation](https://docs.docker.com/engine/reference/commandline/daemon/):
`--ip=0.0.0.0                           Default IP when binding container ports`

The `--ip=<default-ip>` option is correctly taken into account when running a container directly with `docker run`, but when I want to run it through `docker-compose`, it does not work and we have to force host ip value for all services in the docker-compose.yml file like:

```
ports:
  - ""10.0.0.1:8000:8000""
```
",,,dnephin,"
--
Seems strange, because we just pass these values on to the API, and I would have expected the engine to handle it, but maybe it's actually the docker-cli which is doing the work here. If that's the case, the correct fix might be to have the engine do it instead of the client.

Needs more investigation.

--
",dato,"
--
As far as I can see, when a version 2 YAML definition does not specify what networking to use, docker-compose creates a `projectname_default` network instead of using the default bridge.

These `projectname_default` networks do not have _host_binding_ipv4_ set, even if the daemon was started with e.g. `--ip=192.168.17.1`:

```
# Default bridge network
$ docker network inspect bridge  |  grep host_binding_ipv4
    ""com.docker.network.bridge.host_binding_ipv4"": ""192.168.17.1"", 

# docker-compose-created example_default (see YAML below)
$ docker network inspect example_default | grep host_binding_ipv4 || echo not present
not present
```

_example_default_ was created by docker-compose for a very simple file:

``` yaml
version: ""2""

services:
  test:
    image: busybox
    command: sleep 60

    ports:
      - ""7560:8080""
```

One simple workaround is to specify `network_mode: default` in services defined in docker-compose.yml.

--
",papey,"
--
`network_mode: default` is not a workaround. You just destroy projects isolation when using this default mode.
--
",jabenninghoff,"
--
I found a better workaround for this issue: create a new network bound to a specific IP, and instruct compose to use the external network:
`docker network create -o ""com.docker.network.bridge.host_binding_ipv4""=""192.168.17.1"" bridge2`

Use the following `docker-compose.yml`:
```
version: ""3""
services:
  test:
    image: busybox
    command: sleep 60

    ports:
      - ""7560:8080""
    networks:
      - bridge2

networks:
  bridge2:
    external: true
```
I use compose v3, this may also work on v2.

This also avoids the need to change the docker daemon settings.
--
",SteveEasley,"
--
An alternate approach not requiring any special networks, or hard coded IP addresses:

docker_compose.yml
```
version: '3'
services:
  web:
   image: nginx
   ports:
     - ""${MY_DOCKER_IP:-127.0.0.1}:8080:80""
```

By default, this will start the container so its not viewable externally (bound to 127.0.0.1).

If you want to expose it externally just run `export MY_DOCKER_IP=0.0.0.0` then restart your container with `docker-compose up -d --force-recreate`.
--

--
@arthurhenrique 0.0.0.0 is the default value. The point of this issue is how NOT to bind 0.0.0.0 (all interfaces).
--
",arthurhenrique,"
--
Changed to:
```yml
ports:
    - ""0.0.0.0:8080:8080""
``` 
and it's works. 

@SteveEasley , Do you see some problem with that alteration?
--
"
2957,OPEN,Define host volumes in the `volumes` section of the Compose file,area/config; kind/enhancement; stale,2021-02-18 04:11:35 +0000 UTC,bigfoot90,In progress,,"It seems that there is not the possibility to mount a host directory using the `volumes` section using the versrion 2

I would propose an configuration example

``` yaml
volumes:
    data:
        driver: host
        driver_opts:
            source: /host/directory
```

My use case:
**docker-compose.yml**

``` yaml
services:
    nginx:
        # ...
        volumes:
            - data:/var/www

    php:
        # ...
        volumes:
            - data:/var/www

    symfony:
        # ...
        volumes:
            - data:/var/www

volumes:
    data:
        driver: host
        driver_opts:
            source: /tmp/data
```

Override **docker-compose.prod.yml**

``` yaml
volumes:
    data:
        driver: host
        driver_opts:
            source: /home/prod/data
```
",,,dnephin,"
--
`host` is not a driver type, host volumes are treated differently.

I believe the only way to do this is to inline the path in the service: 

```
nginx:
  ...
  volumes:
    - /tmp/data:/var/www
```

--

--
It is possible, but at this time it's not a high priority, we can keep the issue open to track it, and see if there is other interest in this feature.

--
",bigfoot90,"
--
Thank you for your responce.

`host` was for example only, you can implement this differently.

Is there any chance for having having such feature in the next release?
It would be good to be able to overwrite only the volume configuration instead of configure different volumes for each service.

--
",nicodmf,"
--
i'm interessing
--
",x007007007,"
--
i'm interesting 
--
",glorquet,"
--
+1
--
",tomfotherby,"
--
Did you try using `driver_opts` in the volumes definition? This worked for me:

```
services:
  php:
    volumes:
      - app_sourcecode:/var/www

volumes:
  app_sourcecode:
    driver_opts:
      type: none
      device: $PWD
      o: bind
```

This was with docker-compose `1.11.2` and docker `17.03.0-ce` with Ubuntu 16.10 as the host OS. There does seem to be a bug with folder ownership being reset to `root` though - ref: https://github.com/docker/compose/issues/3270.

--

--
> Replace $PWD with your preferred host directory (absolute path) and it should work.

For me, on Linux, it works using literally `$PWD` but yes, if you can hardcode the absolute path that might be more stable because I found some inconsistencies on using either `$PWD` or `./` or other relative paths depending on whether on Mac or Linux.
--
"
2945,OPEN,compose checks that the build context folders exist even when not needed,status/0-triage,2020-10-05 08:53:22 +0000 UTC,chaseajen,Opened,,"In a docker-compose file where both `build` and `image` are specified, running `docker-compose up` will check that the build `context` folders exist, even if `docker-compose pull` is run first and the build contexts are not needed to run the services.

This seems like an unnecessary validation step, requiring empty build context folders that are not actually used.
",,,dnephin,"
--
This is heavily related to #1973, I think we could just include it there.

--
",afirth,"
--
It appears this also affects cases where only one service is required. e.g `docker-compose up service1` checks that all build targets for all defined services are available, even if service1 is standalone.
--

--
somebody gives me a compose file. I want to use just one service. `docker-compose up service1` checks that all build targets for all defined services are available, even if service1 is standalone. Doesn't work. Just from memory since nobody has actioned this in 4 years. On the K8s :train2: now so /unsubscribe but thanks for all the fish.
--
",MartinMuzatko,"
--
I have the same problem with when I want to build or `pull` or `build` just **one** service. It requires me to create empty folders for **all the services**.
--

--
No this is not stale. Still happening
--

--
This is still an issue for us.
We have to maintain at least two compose files. One for building, one for starting. unifying that would be great.
--
",stale,"
--
This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you for your contributions.

--

--
This issue has been automatically marked as not stale anymore due to the recent activity.

--

--
This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you for your contributions.

--

--
This issue has been automatically marked as not stale anymore due to the recent activity.

--

--
This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you for your contributions.

--

--
This issue has been automatically marked as not stale anymore due to the recent activity.

--
",ndeloof,"
--
@MartinMuzatko  Can you please explain why you have your compose file to define a `build` section for a service while you don't have a matching context path and Dockerfile ? Support for pulling by image tag is just a shortcut to avoid (potentially long) builds while the build result is already available as a local or published image.
--
",,
2925,OPEN,Service can't be reached by defined hostname,area/networking; kind/enhancement,2021-01-22 22:11:30 +0000 UTC,brunoborges,In progress,,"Given the following docker-compose.yml file:

```
version: '2'

networks: 
  mynet:
    driver: bridge

services:

  master:
    image: busybox
    command: top
    hostname: amasterservice
    networks: 
      - mynet

  slave: 
    image: busybox
    command: top
    networks:
      - mynet
```

The following ping fails:

```
$ docker exec -ti test_slave_1 ping amasterservice
ping: bad address 'amasterservice'
```
",,,brunoborges,"
--
Adding **depends_on** (in slave to master) does not fix the problem.

--

--
Hi @jake-low, I think question is why isn't **hostname** defined under aliases. What is the reasoning behind this decision? 

--

--
As a Docker Composer user, I expect that whenever I set a hostname to a service, that hostname should resolve to _any_ instance of that service. Same should apply for the service name.

If these things should not work the same way, and a user should only rely on service name, then hostname definition should not be allowed in the compose file. It just creates confusion.

--

--
If goal of Docker Compose is to make it easier for users to deploy a composition of services using Docker images and containers, then the file definition should be crystal clear. 

When a user defines a hostname to a service, it will expect that hostname to be resolvable from other services, specially when these services participate in the same network (as per my [example](https://github.com/docker/compose/issues/2925#issue-133811897)).

Since a service can have multiple instances, it is just logical that when I define a hostname to a service, that hostname resolves to multiple instances (thus using the new DNS feature in latest version).

If nothing of these can be implemented today, or should not be implemented at all, then it is a matter of clarifying the documentation to state either:
1. **hostname** should have restriction like **container_name** where one service instance only will exist.
2. **hostname** should not be allowed in the compose file because there is no value added to that rather creating confusion in users' mind.

--

--
> We should probably add a warning to the docs about using hostname. I think it is rarely useful.

I think it should not be allowed at all.

--

--
> That is not backwards compatible, and while it is ""rarely"" useful, there are still cases where it is useful in its current form, so removing it completely is not really an option.

Then the feature should work as expected by users using Compose for the first time, by adding that information to the list of alises.

Could you please be more specific where, although rare, the current form is useful?

--

--
> IMHO this feature does work ""as expected"" because it works the same way it does in Docker engine. Running a container with the --hostname argument does one thing: sets the hostname. Aliases are defined by the user (with the caveat I mentioned earlier).

Not really. With overlay network, the hostname set in a container is reachable by another container. So I disagree that it works as ""expected"". In fact, what users expect (and think about new users), is that when a hostname is set, specially in the case of Docker Compose, that hostname can be used by other containers.

--

--
@jake-low indeed, thanks for checking. I missed that I was setting --name too on my shell scripts. 

--

--
Still doesn't work...
--
",jake,"
--
Looking at `docker inspect test_master_1`, I see two aliases:

```
...
""Aliases"": [
    ""master"",
    ""268ef7e1e5""
],
...
```

The first comes from the service name, and the second is the container's short ID. I think that by default Compose doesn't create aliases based on hostnames.

May I ask what you're trying to accomplish? Why can't the hostname also be ""master"", and why does the slave need to ping the master by hostname rather than by service name?

--

--
My guess would be because `hostname` isn't guaranteed to be unique, and aliases are required to be. How would Compose handle this situation?

```
version: '2'
services:
  foo:
    image: busybox
    command: top
    hostname: notunique
  bar: 
    image: busybox
    command: top
    hostname: notunique
  test:
    image: busybox
    command: ping notunique
```

Service name and container ID are both guaranteed to be unique -- service because YAML doesn't allow multiple keys with the same name, and container ID because Docker uses a unique hash automatically.

--

--
This may be a decision better left to the Engine team, as there's currently an incongruity there that needs to be solved.

When you run a container with `docker run`, no alias gets created for it. However, if you give it a `--name`, both its hostname (a random SHA) and its container name are resolvable.

It's strange that, even though Docker gives every container a unique ID and nickname, neither is by default DNS-resolvable (based on my tests; someone feel free to correct me).

--

--
That's a tall order. DNS load balancing is crude and has many unusual failure cases due to DNS's hierarchical organization and client caching behaviour [[1]](https://en.wikipedia.org/wiki/Round-robin_DNS#Drawbacks). This is why application-level (so-called Layer 7) load balancing schemes have become popular [[2]](https://www.nginx.com/resources/glossary/layer-7-load-balancing/).

Tutum provides DNS-level load balancing (mapped to services, not hostnames), as seen [here](https://support.tutum.co/support/solutions/articles/5000050235-load-balancing-a-web-service) (last paragraph), but as the rest of the article discusses, this feature is recommended for use as a second-level load balancer. Primary load balancing duties have been assigned to a purpose-built container.

--

--
> That is not backwards compatible, and while it is ""rarely"" useful, there are still cases where it is useful in its current form, so removing it completely is not really an option.

Agreed; I use it in a couple of cases where legacy applications expect to be able to resolve themselves by their own hostname (in these cases matching `hostname` to the service name in the composition).

I've also used it in Kerberos environments, when the hostname on a host needs to be set to an FQDN (not necessarily unique) so that services running there can use their service principals to authenticate themselves.

IMHO this feature does work ""as expected"" because it works the same way it does in Docker engine. Running a container with the `--hostname` argument does one thing: sets the hostname. Aliases are defined by the user (with the caveat I mentioned earlier).

--

--
> With overlay network, the hostname set in a container is reachable by another container.

That's not true.

```
$ docker run -d --hostname testing --net my_overlay_network alpine sleep 300
12e9d172d1964c2ad843f3bb4b61556eb75c0680ec95d8559fe77e617cf1371b
$ docker run --rm --net my_overlay_network alpine ping testing
ping: bad address 'testing'
```

What you're saying is true if you set the `--name` of the container, not the `--hostname`.

```
$ docker run -d --name testing --net my_overlay_network alpine sleep 300
ac8ec87ec8c2893588a8d271401deb07ca934d3d5590e6726ea17cea5166876e
$ docker run --rm --net my_overlay_network alpine ping testing
PING testing (10.0.9.3): 56 data bytes
64 bytes from 10.0.9.3: seq=0 ttl=64 time=0.525 ms
64 bytes from 10.0.9.3: seq=1 ttl=64 time=0.495 ms
64 bytes from 10.0.9.3: seq=2 ttl=64 time=0.590 ms
^C
--- testing ping statistics ---
3 packets transmitted, 3 packets received, 0% packet loss
round-trip min/avg/max = 0.495/0.536/0.590 ms
```

Proof that this is a swarm, and an overlay network:

```
$ docker network inspect my_overlay_network
[
    {
        ""Name"": ""my_overlay_network"",
        ""Id"": ""102259bd950d46e3d3b1694f09708dc3833d4cda80a525cde1fbd081ce5bbabd"",
        ""Scope"": ""global"",
        ""Driver"": ""overlay"",
        ""IPAM"": {
            ""Driver"": ""default"",
            ""Options"": null,
            ""Config"": [
                {
                    ""Subnet"": ""10.0.9.0/24""
                }
            ]
        },
        ""Containers"": {
            ""1c1609f004bff373d2c26dd269d37411214bfb05c73607620bab286621585d27"": {
                ""Name"": ""testing"",
                ""EndpointID"": ""c2c5b645e36b52952f7744d02030b3e06e1637a781be55a93ab2eebb63849429"",
                ""MacAddress"": ""02:42:0a:00:09:02"",
                ""IPv4Address"": ""10.0.9.2/24"",
                ""IPv6Address"": """"
            }
        },
        ""Options"": {}
    }
]
$ docker info
Containers: 5
 Running: 4
 Paused: 0
 Stopped: 1
Images: 4
Role: primary
Strategy: spread
Filters: health, port, dependency, affinity, constraint
Nodes: 2
 mhs-demo0: 192.168.99.102:2376
   Status: Healthy
   Containers: 3
   Reserved CPUs: 0 / 1
   Reserved Memory: 0 B / 1.021 GiB
   Labels: executiondriver=native-0.2, kernelversion=4.1.17-boot2docker, operatingsystem=Boot2Docker 1.10.1 (TCL 6.4.1); master : b03e158 - Thu Feb 11 22:34:01 UTC 2016, provider=virtualbox, storagedriver=aufs
   Error: (none)
   UpdatedAt: 2016-02-17T01:32:30Z
 mhs-demo1: 192.168.99.103:2376
   Status: Healthy
   Containers: 2
   Reserved CPUs: 0 / 1
   Reserved Memory: 0 B / 1.021 GiB
   Labels: executiondriver=native-0.2, kernelversion=4.1.17-boot2docker, operatingsystem=Boot2Docker 1.10.1 (TCL 6.4.1); master : b03e158 - Thu Feb 11 22:34:01 UTC 2016, provider=virtualbox, storagedriver=aufs
   Error: (none)
   UpdatedAt: 2016-02-17T01:32:04Z
Plugins: 
 Volume: 
 Network: 
Kernel Version: 4.1.17-boot2docker
Operating System: linux
Architecture: amd64
CPUs: 2
Total Memory: 2.043 GiB
Name: mhs-demo0
```

--
",dnephin,"
--
There was some discussion early on about using `hostname` instead of `container_name` as the default name used by docker, but that didn't happen (I'm not sure why).

We add aliases for service name and short id to be backwards compatible and handle the common use cases.  We're also adding support for your own net-aliases in #2829

As far as I know, it's not all that uncommon for the internal hostname to be unresolvable from the outside. 

We could probably make it another alias, but I'm not sure how we'd deal with conflicts with the service names.

--

--
We should probably add a warning to the docs about using `hostname`. I think it is rarely useful.

--

--
That is not backwards compatible, and while it is ""rarely"" useful, there are still cases where it is useful in its current form, so removing it completely is not really an option.

--
",hacknaked,"
--
Any update on this issue?

--
",mafrosis,"
--
It's long been an annoyance for me that compose only creates the DNS container name aliases when using `docker-compose up`, and not when using `docker-compose run`.

The `--name` trick solves it, but it feels like this shouldn't be necessary.
--
",Ocramius,"
--
 > compose only creates the DNS container name aliases when using `docker-compose up`, and not when using `docker-compose run`.

This burnt almost 2 days of development on my end (with very cryptic failures).

Do you by chance know if `docker-compose exec` is also affected?
--
"
2545,OPEN,Proposal: support for args_file,area/config; kind/feature; status/0-triage,2019-10-17 09:54:22 +0000 UTC,mbontemps,Opened,,"#### Motivation for this proposal
- build args have been introduced in Docker 1.9.0.
- #2163 proposes a new `build:` section in your Compose service
- builds args can be used to provide secret tokens (ssh key to clone a repository, github token...) during the build phase. These tokens should however not appear in your `docker-compose.yml` file but rather in a separate file.
#### Proposal

Introduce a `args_file:` section working the same way that `env_file:` works - but in the build phase.
#### Proposed documentation
##### args_file

Add build arguments from a file. Can be a single value or a list.

If you have specified a Compose file with `docker-compose -f FILE`, paths in `args_file` are relative to the directory that file is in.

Environment variables specified in `args` override these values.

``` yaml
build:
 args_file: .args

build:
  args_file:
    - ./common.env
    - ./apps/web.env
    - /opt/secrets.env
```

Compose expects each line in an env file to be in `VAR=VAL` format. Lines beginning with `#` (i.e. comments) are ignored, as are blank lines.

``` ini
# Set the secret token necessary to clone the dependencies
SECRET_TOKEN=yNxbjX
```
",,,aanand,"
--
Makes sense to me.

--
",marcellodesales,"
--
:+1: 

--

--
@thaJeztah Is this planned for the next release?

--
",thaJeztah,"
--
Nice idea

I'm not sure we should use `/opt/secrets.env` as an example in our documentation, given that we discourage people to use build-time args for secrets (the args are included in the history of an image, so would be visible to others)

--
",daef,"
--
i'd really love args_file, i kinda expected it to be there - but i am disappoint now i've found it just got proposed

--
",schmunk42,"
--
> These tokens should however not appear in your docker-compose.yml file

A workaround is to use a `.env` file and ENV variables (compose 1.7+ AFAIR)

```
version: '2'
services:
  php:
    build:
      dockerfile: Dockerfile-7.0-fpm
      context: .
      args:
        - GITHUB_API_TOKEN=${GITHUB_API_TOKEN}
    image: local/dmstr/php-yii2
    environment:
      - GITHUB_API_TOKEN=${GITHUB_API_TOKEN}
```

--

--
@yangm97 Did you try with a recent docker-compose version? Can you set build args in docker-compose (without variables)?
--

--
These have to be in your `.env` file

```
NATIVE=${NATIVE}
ROCKS=${ROCKS}
```

Double check it with `docker-compose config`

<img width=""704"" alt=""bildschirmfoto 2017-02-14 um 18 36 07"" src=""https://cloud.githubusercontent.com/assets/649031/22941128/91919028-f2e4-11e6-8dc1-14c383fbf245.png"">

--

--
> Do I need to explicitly set these variables on .env or it should work when I set these using the .deps file?

Yes, it has to be in `.env` - which is the default for `docker-compose`. I've written about this in the [docs for our application framework](https://github.com/dmstr/phd5-docs/blob/master/guide/development/configuration.md#hierarchy--scopes). I won't recommend using `.env` as an application environment file, btw.

It's a bit confusing, because `docker-compose` has ""hijacked"" this filename, when a lot of people were already using it for applications. I'd call it ""control-environment"" file now.
--
",yangm97,"
--
@schmunk42 that workaround didnt work for me.
--

--
docker-compose version 1.9.0, build 2585387

Setting args on docker-compose.yml work fine.

```
  bot:
    build:
      args:
        - LUA=5.2 # this works
        - NATIVE=${NATIVE} # these don't
        - ROCKS=${ROCKS}
      context: .
    command: $BOT
    depends_on:
      - db
      - redis
    env_file:
      - .deps
      - .env
    environment:
      - NATIVE=${NATIVE}
      - ROCKS=${ROCKS}
      - REDIS_HOST=redis
      - DB_HOST=db
    privileged: true
    restart: always
```
--

--
So far, the only ways I got to read build time arguments from a file were:

1. Source the args file on host and then run docker-compose with build args;
2. Copy the args file on the Dockerfile and then source the file using the RUN command.
--

--
> These have to be in your `.env` file

I have multiple env files:

```
    env_file:
      - .deps
      - .env
```

Do I need to explicitly set these variables on `.env` or it should work when I set these using the `.deps` file?

My .deps file looks like this:

```
LUA=5.2

NATIVE=""libreadline-dev libssl-dev lua$LUA luarocks liblua$LUA-dev curl libcurl4-gnutls-dev figlet deborphan git make unzip""
ROCKS=""luasec luasocket redis-lua lua-term serpent dkjson Lua-cURL lanes luautf8
```

--
"
2369,OPEN,docker-compose ps enhancements,area/cli; kind/feature,2019-09-03 14:11:13 +0000 UTC,dnephin,Opened,,"This issue is to aggregate all the requests for enhancements to `ps`.  
- include the swarm node name (#2366)
- some way to disable wrapping of lines, either with a flag, or default to no wrapping when the terminal is not a tty (#1414)
- machine readable output, as json (#1992)
- container ip address (#1038)
- include the short container id (#1414)
- support additional fields (#1414)

We need to find a way to support all of this without making the default unnecessarily verbose.  I think we should be keeping the default fairly close to what we have now.

One option is to add a bunch of flags to include new columns.
",,,lmesz,"
--
Hello,

Thanks to gather the PRs and issues around PS.
I think the default should be as it is, but give an oportunity the user to customize the columns would be great. E.g.: docker ps:

##          Name                        Command               State                          Ports                         

dockermaster_etcd_1       /etcd                            Up      0.0.0.0:2379->2379/tcp, 2380/tcp, 4001/tcp, 7001/tcp
dockermaster_etcd_2       /etcd                            Up      0.0.0.0:2380->2379/tcp, 2380/tcp, 4001/tcp, 7001/tcp

docker ps --columns name
dockermaster_etcd_1
dockermaster_etcd_2

And docker ps --help should show the available columns. And ps shouldn't rely on tty at all IMHO, cause for example when user process the output from script there's no such a thing like tty. 
The ""machine readable output, as json"" would be also great. With --json should drop the ps output like a simple json array as you suggested the original PR.

--
",achekulaev,"
--
I wanted to bring up another notice. Currently `ps` returns container **name** as a first column

```
# docker-compose ps
     Name                    Command                State     Ports 
-------------------------------------------------------------------
fusion114_cli_1   /opt/startup.sh /bin/sh -c ...   Exit 137         
fusion114_db_1    /entrypoint.sh mysqld            Exit 128         
fusion114_web_1   /opt/startup.sh apache2 -D ...   Exit 0   
```

However that value is useless for any other docker-compose command as docker-compose can not work with container names but only works with services. 

```
# docker-compose ps fusion114_cli_1
No such service: fusion114_cli_1
```

```
# docker-compose ps cli
     Name                    Command                State     Ports 
-------------------------------------------------------------------
fusion114_cli_1   /opt/startup.sh /bin/sh -c ...   Exit 137   
```

It makes sense to drop Name column and introduce Service Name or Service column instead.

```
# docker-compose ps
Service                    Command                State     Ports 
-------------------------------------------------------------------
cli         /opt/startup.sh /bin/sh -c ...   Exit 137         
db          /entrypoint.sh mysqld            Exit 128         
web         /opt/startup.sh apache2 -D ...   Exit 0   
```

--
",tflori,"
--
especially a `docker-compose --columns ""name, state""` will be very intresting for me. I'm running some containers that have a lot of ports (hardware/mailserver for example) and I just want to check if everything is up but it's hard to follow the lines when some containers have more than one line..
--
",znerd,"
--
Feature parity, and output format parity, across `docker ps` and `docker-compose ps` would be very nice.

E.g.:
- `docker ps` supports **filtering** (with the `-f`/`-filter` option), while `docker-compose ps` does not
- `docker ps` supports **formatting** (with the `--format` option), while `docker-compose ps` does not
- `docker-ps` just returns one line with column names and then the info, while `docker-compose ps` includes a **horizontal line** in the output
- etc.
--
",reitzig,"
--
@achekulaev Only if you want to `docker cp` you'll need the container name.
--
",,
2294,OPEN,1.5 - Make COMPOSE_PROJECT_NAME accessible to environment,area/networking; kind/enhancement,2021-02-23 19:04:19 +0000 UTC,mbontemps,In progress,,"Given that: 
- [containers join the network under their container name](https://github.com/docker/compose/issues/2248) - at least for now
- container names depends on the project name

I think we need a quick basic solution for 1.5 to allow docker-compose with `--x-networking` enabled to **work on a project independently from the project name**. 

The reasoning: project names are variable (they can be different for two users depending on their directory, or can be changed in the CLI).  
So without forcing the project name, when we up a project, we have no way yet to predict the network name - and worse, no way to predict the hostnames of the other containers in the project.
## Proposed solution

I understand that nice solutions are planned for 1.6, but in the mean time I think we need a solution doable for 1.5. I suggest to set and make the environment variable `COMPOSE_PROJECT_NAME` available.

This way we can actually predict at which hostname other containers will be accessible in the current network. Something like `${COMPOSE_PROJECT_NAME}_redis_1`.
## Example
### What you do now

``` yaml
mysql:
    image: my-mysql

www:
    image: my-www
    environment:
        DB_HOST: hello_mysql_1
```

``` bash
~/Sites/hello$ docker-compose --x-networking up

~/Sites/hello$ docker-compose --x-networking --project-name staging up
# hello_mysql_1: Unknown host

~/Sites/dev$ docker-compose --x-networking up
# hello_mysql_1: Unknown host
```
### Proposal

The proposal is to make that possible:

``` yaml
mysql:
    image: my-mysql

www:
    image: my-www
    environment:
        DB_HOST: ${COMPOSE_PROJECT_NAME}_mysql_1
```

``` bash
~/Sites/hello$ docker-compose --x-networking up

~/Sites/hello$ docker-compose --x-networking --project-name staging up
# DB_HOST will be set to staging_mysql_1

~/Sites/dev$ docker-compose --x-networking up
# DB_HOST will be set to dev_mysql_1
```
",,,dnephin,"
--
Good news, this works already!

https://github.com/docker/compose/blob/master/docs/reference/overview.md#compose_project_name
https://github.com/docker/compose/blob/master/docs/compose-file.md#variable-substitution

Edit: that is, it works assuming you've set an explicit project name using the environment. 

--

--
I'm hesitant to add something like that because it's likely only going to be necessary for 1 release. In the next release we should support aliases (so you won't need the project name), and we'd like to do #745 to persist the name.

It feels a bit like another hidden thing that may confuse users, although I can't think of a scenario right now where it would actually break something.

If it's a major issue, we could add it in a bug fix release.

--

--
`COMPOSE_PROJECT_NAME={unique string} docker-compose up` is not really all that much different from `docker-compose up --project-name={unique string}`.

--
",mbontemps,"
--
Thanks for the answer!

Indeed, it _can_ work if I set a project name manually but does _not_ work with the default usage so you can not rely on it.

In my case with:

``` yaml
mysql:
    image: my-mysql

www:
    image: my-www
    environment:
        DB_HOST: ${COMPOSE_PROJECT_NAME}_mysql_1
```

The 1d and 3d usecase do not work:

``` bash
~/Sites/hello$ docker-compose --x-networking up
~/Sites/dev$ docker-compose --x-networking up
```

As by default the `COMPOSE_PROJECT_NAME` variable is not set.

And we cannot assume a default value for it (as it depends on the dirname) so that leaves the problem unsolved.

What do you think about setting this variable with the value which will actually be used by compose under the hood as (sanitized) project name?

--

--
Well IMO there are 2 things at play here:
1. This point is not actually related to networking. To be honest, after reading the doc I kinda expected `COMPOSE_PROJECT_NAME` to be accessible in all cases. Why wouldn't it be? Doesn't this feel more coherent than making it accessible _only if set manually in the CLI_? The current behavior seemed confusing to me until I read the source code. 
2. That being said, using this feature in networking to do what I want to do is indeed going to be useful only for 1 release, you're right.

But to me it is necessary as right now, I'm struggling to find _any_ way to solve my problem in docker-compose with networking: running 2 times the same project with the same docker-compose on the same docker engine but with different networks. Think master + development branches for example.

So I would argue that given that it makes the environment variables behave more coherently and it does not seem to hurt, temporarily solving my scenario is just a bonus. :)

--
",pwaller,"
--
I'm just hitting this exact situation. I have a configuration identical in spirit. I _really don't_ want to have to configure anything except the project name, since our integration tests spin up many `compose up`'s at a time, and they need to not conflict. I don't want to have to teach my CI to run anything other than `docker compose up --project-name={unique string}`.

--
",thaJeztah,"
--
Also note this proposal in docker, that will allow setting aliases on containers so that they can be reached on the network, independent of the container name; https://github.com/docker/docker/issues/18699

--
",CircleCode,"
--
> `COMPOSE_PROJECT_NAME={unique string} docker-compose up` is not really all that much different from `docker-compose up --project-name={unique string}`

in linux this is effectively not that much, but in windows, it is much more complicated.
Since one may have to build cross platforms compose files, this feature still remains blocking

--

--
@nottrobin wouldn't [environment file](https://docs.docker.com/compose/env-file/) solve your case?

--

--
for example, you could add a `.env` file into your project folder, defining an explicit PROJECT_NAME
Then you do not need anymore to guess it since it is well known.

--

--
@nottrobin On the first glance, I agree with you.
Actually, I faced exactly the same problem in another way.

Why the decision has been took to automatically computing a project name is IMHO a bad question (and I do not even have an answer, I suppose this is a decision that made sense at the moment it has been decided). The fact is that it is now this way, and I found that the .env file is much better than `COMPOSE_PROJECT_NAME` or `--project-name` in the way it is explicit and persistent in the project since it is defined by a file of the project. For my needs, it was enough to rely on it rather than letting composer choose a project name.

Actually, I act as if

> [compose] never have chosen [a project name] in the first place and instead ask you to specify one every time

## 

Edit: Sorry if this sounds abrupt, it was not my intention, I'm just a little bit tired

--

--
@nottrobin 
Sorry if I wasn't able to help more.
BTW, remember I am in no way member of compose development team, nor affiliated to them, so maybe someone with better skills will be able to help you more.

--
",nottrobin,"
--
It would be incredibly helpful to me to be able to somehow determine the project-name that `docker-compose` assigns by default. It's not simply the folder name, 'cos it removes, at least, hyphens.

Is there any simple way for me to get the auto-assigned project name, without overriding it manually?

My problem is that, after I do 

``` bash
docker-compose build web
```

I end up with a docker image called `{project-name}_web`. If I then want to clean up the system to leave it exactly as it was before, there's no way that I'm aware of to ask `docker-compose` to delete that built image. So I have to delete it manually with `docker rmi -f {project-name}_web`, but this is very difficult to script reliably because I don't know what the `{project-name}` is.

--

--
@CircleCode How? I can of course specify the `COMPOSE_PROJECT_NAME` variable, but that's precisely what I don't want to do. I want to let `docker-compose` pick the project name, and also know what it is.

--

--
@CircleCode Thanks for responding.

I was always aware I could specify a project name, either through `COMPOSE_PROJECT_NAME` or through the `--project-name` option, but this is what I'm trying to avoid. `docker-compose` already has a mechanism for picking a project name for a given project folder, which is the functionality I want, so it seems silly for me to implement it again just so I know what it is.

Given that `docker-compose` is taking it upon itself to create a hopefully unique, human-readable project name by default, it seems entirely sensible to me that it would offer to tell you what that project name is - especially given that it does a less-than-perfect job of cleaning up after itself. Otherwise I feel like it should never have chosen one in the first place and instead ask you to specify one every time.

--

--
@CircleCode Yes all that makes sense(and doesn't sound too abrupt). The problem I'm facing is that I'm currently trying to write tools for developers to run on their machines. The tools may be used on any project, and those projects may also be forked many different times (in different folders) on a developer's machine, and run simultaneously.

Therefore defining a single `COMPOSE_PROJECT_NAME` is out of the question, and even having one per project isn't great, because as I say I want to enable running a project multiple times in parallel. However, when developers run multiple versions of a project, they are almost always from directories with different names (`~/projects/my-project/`, `~/projects/my-project-2/` etc.), and so the default `docker-compose` project naming mechanism works rather well.

But given everything you've said, it sounds like the only way forward for me is to re-implement a way of picking a project name which is unique enough for my needs, and always override the default.

--
"
2235,OPEN,Provide RPM and DEB packages for compose,area/packaging; status/0-triage,2021-02-23 23:10:14 +0000 UTC,dnephin,In progress,,"Not everyone likes to install binaries (#1288).

It might be good to provide a system package for compose. We should use https://github.com/spotify/dh-virtualenv for the debian package and look into a similar approach for the rpm.
",,,jacek99,"
--
I would recommend to just work with the respective Debian and Fedora/CentOS communities and get that rolled into the default system repositories.'

Just my $0.02

--
",atrauzzi,"
--
That ends up being less than optimal for a project that's moving as quickly as compose.  You'll just end up with a pile of people coming in reporting that new features aren't working.

Better to have a PPA so that you can do updates outside of the distro release cycle.

--

--
@alexanderadam That's a good way to get outdated bug reports.  A PPA makes much more sense for a target that moves as quickly as docker+compose.

Indeed that's why people prefer to use the docker PPA.  What's in the ubuntu/debian repos just doesn't keep pace.

--

--
Good enough! :)

--
",dnephin,"
--
It sounds like there is a deb for it (https://packages.debian.org/sid/docker-compose) but it's already a few versions behind.

--

--
And a fedora package https://admin.fedoraproject.org/pkgdb/package/docker-compose/

--

--
Hosting the packages is the easy part. Most of the work here is making sure the package works for older versions of distros.

--
",voltagex,"
--
Couldn't this be done in the same way as https://docs.docker.com/installation/ubuntulinux/ and https://docs.docker.com/installation/fedora/? i.e. host on *.docker.org

--
",athyuttamre,"
--
Would you consider doing this once development pace has stabilized?

--
",StefanScherer,"
--
What about putting the docker-compose binary that is also available at the GH release into DEB/RPM?
No python/virtualenv required on the target machine.

Creating such a package with [fpm](https://github.com/jordansissel/fpm) should be very easy. We've done similar things at work (sorry private repos) and put some integration tests behind the build to test the DEB/RPM package at CircleCI within debian/centos Docker containers.

If there is interest in such things I can check if we can open source that parts as an example.

--
"
2057,OPEN,Add command to list project status,kind/feature,2018-10-24 15:18:28 +0000 UTC,,Opened,,"With release 1.4.0 I have found no way to use `docker-compose` command to check if project is up and running (correct me if I'm wrong).

The closest is `docker-compose ps` whose output lacks information about stopped/not created containers. I guess it could be used for status querying with issue #1061 impemented, but we would still need to parse textual output to determine project status.

A `docker-compose status` that checks if project is up and running and returns proper zero/non-zero exit code would be very usefull for scripting `docker-compose` and integrating it with other tools.
",,,dnephin,"
--
The problem with using container status as a healthcheck is that it's not a good measure of the health of a service.  The container may be running, but there are lots of possible (and likely) scenarios where your application in the container is not running correctly (ex: it could be listening on the wrong port (or otherwise misconfiguration). It could be spewing errors to a log and not actually doing any work.)

If you need the health of a service, it really needs to query the application itself.

There's been some discussion about how healthchecks should work in other issues, but I don't think that checking container status is sufficient.

I think #1061 is still important to implement, but I'm not sure if a `status` subcommand is the right approach.

--
author:	
association:	none
edited:	false
status:	none
--
Let me start from back. I too think that #1061 is important and should not be rolled up into this issue. I mentioned it only because I would be able to use it to work around my issue.

You say that I need query application to check for service health and I agree with you completely. The `status` subcommand as I proposed it is not sufficient for it. But my intention was not to check application health, only if it is running or not.

Think LSB init scripts and their `status` command. It does not know about service health either, but it is very uncomplicated mechanism that allows rudimentatry monitoring and automation (start if stopped). The `docker-compose` lacks even this rudimentary ability now.

What I've tried to do was implement simple LSB init script that would start and stop `docker-compose` project. But how do I check if all projects containers are running? The only way I found is `docker ps` and knowing which containers should run. And thats pretty hard to automate.

Status with proper health checks would be nice, but simple LSB init script like `status` seem like good, inexpensive start.

--
",nvllsvm,"
--
Let me start from back. I too think that #1061 is important and should not be rolled up into this issue. I mentioned it only because I would be able to use it to work around my issue.

You say that I need query application to check for service health and I agree with you completely. The `status` subcommand as I proposed it is not sufficient for it. But my intention was not to check application health, only if it is running or not.

Think LSB init scripts and their `status` command. It does not know about service health either, but it is very uncomplicated mechanism that allows rudimentatry monitoring and automation (start if stopped). The `docker-compose` lacks even this rudimentary ability now.

What I've tried to do was implement simple LSB init script that would start and stop `docker-compose` project. But how do I check if all projects containers are running? The only way I found is `docker ps` and knowing which containers should run. And thats pretty hard to automate.

Status with proper health checks would be nice, but simple LSB init script like `status` seem like good, inexpensive start.

--
author:	nvllsvm
association:	contributor
edited:	false
status:	none
--
I've been using some shell to check if any containers with health checks are not ""healthy"". If anyone one health check is not ""healthy"", the command exits with a code of 1.

```
FORMAT='{{ if .State.Health }}{{ if ne .State.Health.Status ""healthy""}}1{{ end }}{{ end }}'
exit $(docker inspect -f ""$FORMAT"" $(docker-compose ps -q ""$@"") | sort -n | tail -n 1)
```

It's clearly not a pretty solution to my problem so having this in Docker Compose (or per-container in Docker CLI) would be useful. The biggest unknown is what the API would like.
--
",,,,,,,,
1910,OPEN,Stable Compose / Swarm integration,kind/epic; swarm,2015-11-23 18:55:11 +0000 UTC,bfirsh,In progress,,"It should be possible to point Compose at Swarm and have it run any Compose app that runs on a single Engine.

This is also being tracked on Swarm's side here: https://github.com/docker/swarm/issues/1156
### Sub-issues
- [ ] Run the Compose test suite against a Swarm cluster
- [x] https://github.com/docker/swarm/issues/1244
- [x] https://github.com/docker/compose/issues/1913
- [ ] https://github.com/docker/compose/issues/1528
- [ ] #2131
- [x] https://github.com/docker/swarm/issues/1257
- [ ] #2169
- [x] https://github.com/docker/swarm/issues/1293
- [x] https://github.com/docker/swarm/issues/1316
",,,dnephin,"
--
Related issues: #1913, #1528

I think step 1 here might be ""run the compose test suite against a swarm cluster"".

--

--
#1090 is related, but might already be fixed

--

--
This is blocked on https://github.com/docker/swarm/issues/1244

--

--
Possible #2374

--

--
I've created a new swarm label: https://github.com/docker/compose/labels/swarm to track related issues, instead of having to come update the checklist in this issue.

--
",bfirsh,"
--
:+1: thanks

--
",,,,,,,,
1516,OPEN,Proposal: Stop using sequential container numbers,area/scale; kind/feature,2018-11-15 01:57:40 +0000 UTC,aanand,Opened,,"Sequential container numbers (`myapp_web_1`, `myapp_web_2`) are problematic.
1. They're costly to maintain: we have to query the names of all containers for a service to determine what the next number should be. As apps get bigger, this is going to get worse.
2. They're error-prone: if a Swarm node with `myapp_web_LASTNUM` goes down at the same time as Compose is querying the cluster, it will incorrectly think `LASTNUM` is the next number we should use. Once the node comes up, there'll be a clash of container names.
3. They make it impossible to do multiple `docker-compose run`s in parallel.

As such, I think we should start using random suffixes. This may well break some scripts that rely on container names, but now that we're using labels to track containers, we should be explicit about making _no guarantees_ about container names.
",,,villlem,"
--
For scripts is useful ps command with -q option. If there is option for get my only one container there would be no need for some explicit naming.

--
",SBoudrias,"
--
I just wondered what were the plans for this feature? Is it planned soon?

--
",dnephin,"
--
Hey Simon!

We aren't doing anything about this in the 1.5 release (which will be out soon), but I think we may look to implement something in the 1.6 release which will be a few months away.

--

--
The project name is required to support [isolated environments](https://docs.docker.com/compose/overview/#multiple-isolated-environments-on-a-single-host).

--
",murphyke,"
--
+1  I want to run parallel copies of a container in a data processing pipeline.  If there were a `--container-name=NAME` CLI flag, I would be in business, but random suffixes would work also.

--
",ibizaman,"
--
Another use case where this would be useful is if the prefix - the directory of the `docker-compose.yml` - is the same and the same service name is used.

For example, having two apps with the following structure:

```
myapp/
    doc/
    src/
        docker-compose.yml
myapp2/
    doc/
    src/
        docker-compose.yml
```

and assuming they both use a `mysql` service, this will result in two identically named services `src_mysql_1`.

A not so great solution would be to use the complete `$PWD` as a prefix.
But in fact, why do we even need to name the machines in the first place? This is not a troll question. :)

**EDIT**: I just found out about the --projectname command line option which solves my particular problem. Although the question about why should we even give a name still stands.

--
",caiofbpa,"
--
:+1:

--
"
1234,OPEN,Proposal: Support for affinity filter in Docker Swarm,area/up; kind/feature; swarm,2015-11-23 18:48:10 +0000 UTC,denverdino,In progress,,"Swarm provide the container affinity to control the placement of container with the environment variables as following

E.g. 

```
affinity:container==[<container_name>|<regexp>]
affinity:container!=[<container_name>|<regexp>]
affinity:container==~[<container_name>|<regexp>]
affinity:container!=~[<container_name>|<regexp>]
```

The challenge to use the affinity in the Compose template are
1. The container name is generated with service name and project name. It is not easy to write above filter easily. 

Propose to use bellow way to describe the container affinity for specific service. And it will be converted to the ""affinity:container"" when create/recreate the container

```
affinity:service==<service_name>
affinity:service!=<service_name>
affinity:service==~<service_name>
affinity:service!=~<service_name>
```

E.g. the following compose template to deploy the containers of ""web"" and ""test"" service in different hosts.

```
web:
  image: nginx
  ports:
    - 80
test:
  image: nginx
  ports:
    - 80
  environment:
    - affinity:service!=~web
```
1. The implied affinity relationship between service should be considered.

E.g. for above sample, if we recreate the container for ""web"" service. It will be better to consider the affinity filer of ""test"". Otherwise, the new container may break the expectation for the placement.

So if service ""A"" has the affinity condition with ""B"", the ""B"" should have the same affinity condition with ""A""
",,,dnephin,"
--
Instead of rewriting `service` to `container`, we should use http://docs.docker.com/swarm/scheduler/filter/#label-affinity

Every service has a label, so we can set an affinity based on the service label.  That way it will work with scale (setting container affinity would not work with scale because some containers would be created after others).

--
",denverdino,"
--
@dnephin Daniel, using the label filter will be great from the implementation point of view. 

The challenge is it is required to match both the ""com.docker.compose.project"" and also ""com.docker.compose.service"" labels. but those labels are set by docker-compose internally and user don't know the value of ""com.docker.compose.project"" before deployment. 

So, my suggestion is to generate the proper label filtering for the ""affinity:service"" during the deployment time.

Your thought? Thanks

--
",,,,,,,,
1209,OPEN,Add support for pointing to tarball contexts in the 'build' parameter.,area/build; kind/enhancement,2020-09-14 13:58:01 +0000 UTC,moysesb,In progress,,"Since the docker client used by compose (docker-py) supports receiving externally generated tarballs as a parameter for its build() method, this alternative should be available in the project configuration file. i.e.:

> service:
> 
> > build: path/to/tarball.tar.gz

The  contents within the compressed file should pass the same level of validation as the currently supported directory paths (for example, 'there must be a Dockerfile at the root inside the tar archive'). Aside from that, the general idea is that the archive is some kind of externally validated artifact, auto-generated by a continuous integration stack, so there should be no need for parsing .dockerignore. 

If this sounds like a good idea I can start working on a PR (I already have an working prototype).
",,,dnephin,"
--
It seems reasonable to me that `build:` would support tarballs as well

--
",aanand,"
--
Seems like this change belongs in docker-py.

--

--
OK, I'd mistakenly believed the docker client would smartly determine whether the argument passed to it was a directory or a tarball, but it looks like they go different routes (stdin for tarball or single Dockerfile vs. argument for directory).

In that case, I think it's fine for that logic to live in Compose: we should check whether the path passed to `build` is a directory or a regular file, and in the latter case pass `fileobj=open(self.options['build'], 'rb')`, as you say.

--
",moysesb,"
--
@aanand I think it belongs in both compose and docker-py, actually. It would certainly be possible to just change docker-py so that it automatically detects when the context being passed is already compressed (instead of relying on the combination-of-parameters logic that it uses today). My grip with this approach would be that it involves moving validation and conditional behavior too far down to the library level. 

As a principle there's always value in keeping validation and detection of user intent as close as possible to surface code and not deep in libraries. Libraries should provide a set of tailored, focused operations that each do one thing with as little conditional logic as possible, specially with regard to the input parameters (they certainly need a lot of conditional logic to deal with failures on the underlying resource level and such). That arrangement makes it easier both to fail early and to optimize for efficiency where relevant. 

So, if docker-py is changed the right way it would not solve this particular problem, because the right way would be to have docker-py offer a more fine grained interface for its `build()` operation, one call for tarballs, one for Dockerfile, one for directory path - and then have the calling code decide upfront which one to use, instead of having just one interface that knows how to deal with whatever the calling code decides to pass on.

So, either both compose and docker-py could be changed in tandem (the 'right way', probably unrealistic, I don't know) or compose could be changed first, to call docker-py's build method with the right combination of arguments when the `build:` parameter points to a tarball. That would solve the more visible half of the problem, i.e, the user facing half.

As it's currently implemented, compose implicitly assumes the value of `build:` to be a directory path, since the value is passed ""as is"" to docker-py with the combination of parameters that docker-py happens to use to infer a directory path value.

In services.py:

``` python
def build(self, no_cache=False):
   log.info('Building %s...' % self.name)
""""""
 - Here it should be determined what kind of resource self.options['build'] points to.
  - If it's a tarball, the call to self.client.build should look something like:
    build_output = self.client.build(
        fileobj=open(self.options['build'], 'rb'),
        custom_context=True,
        encoding='gzip',
        tag=self.full_name,
        stream=True,
        rm=True,
        nocache=no_cache,
    )
  - If it's a directory, use the already existing call:
""""""
build_output = self.client.build(
    self.options['build'],
    tag=self.full_name,
    stream=True,
    rm=True,
    nocache=no_cache,
)
```

Then, when docker-py is improved to move away from the combination-of-parameters approach, the implementation in `compose` could become less crufty than what's necessary now without losing the ability to fail early, etc.

--

--
Would it be ok to add backports.lzma as a requirement? Python2's tarfile module doesn't support lzma compression natively. Since the docker daemon accepts xz I think compose should support it too.

--

--
@smebberson I have a working implementation of this feature in the PR referenced above.

My scenario is more or less the same as yours. We have a staging directory with a bunch of maven generated tar archives with Dockerfiles inside them. When someone finishes a project build, the archive is shipped to this staging area. New uploads are detected by an `inotify-wait` script of some contraption, which then calls `docker-compose` to rebuild and restart the corresponding image. 

--
",dreamcat4,"
--
@aanand If build command could accept tarball as a regular arg, then it would benefit other compose tools too. When I look in the source code of `docker build` and it already has the necessary checking functions etc.

We just have to peek the input file, and check if `if archive.IsArchive(magic)` then set the variable `context` to be `context = ioutil.NopCloser(but)`. _IMHO It does not seem to be too difficult._

Existing tarball handling (the stdin):

https://github.com/docker/docker/blob/master/api/client/build.go#L74-90

Where to add new tarball handling (as regular argument):

https://github.com/docker/docker/blob/master/api/client/build.go#L94-95

Where the `context` variable gets sent to docker daemon:

https://github.com/docker/docker/blob/master/api/client/build.go#L206-214

--

--
Oh right I also seem to have forgotten that compose actually doesn't use the CLI client, but directly calls the API instead. (where in the API, tarball is always sent across the same way).

--
",smebberson,"
--
In two different projects, we have a custom build scripts to achieve a couple of things...

In one project we use `tar` to build a tarball (concatenating a few directories, and removing a few others) and pass this to `docker build`. In another project, we remove a directory from the context in which `docker build` is run so that we don't have to remove this directory as part of the build process (it's a `node_modules` directory), then run `docker build` and then move the directory back for development purposes. Having written that, we could use `tar` in both instances which would be better.

I was going to open a new ticket to discuss support for pre and post build scripts, so that you could alter the build directory as required before and after a build. But I thought I'd chime in here instead... having the ability to point to a tarball would suffice I suppose. The ability to run a pre-build script would be fantastic to generate the tarball, but you could get around this by a custom script that generates a tarball and then executes `docker-compose build`.

--
",stale,"
--
This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you for your contributions.

--

--
This issue has been automatically marked as not stale anymore due to the recent activity.

--

--
This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you for your contributions.

--

--
This issue has been automatically marked as not stale anymore due to the recent activity.

--
"
1203,OPEN,docker-compose dry run,kind/enhancement,2021-02-22 12:28:06 +0000 UTC,,Opened,,"Would like insight to what docker-compose generates/executes
",,,aanand,"
--
Agreed - for the time being, you can use `docker-compose --verbose` to see what it's doing.

--
",paurullan,"
--
This would be incredibly useful for debugging purposes.

--
",jmkgreen,"
--
So `config` just said my file was fine yet `up` told me a service was linked to a service not described.

Does `config` need to be improved or is `dry-run` intended for this? Gut tells me the former...

--
",dnephin,"
--
`config` should catch these errors, we don't currently for `links` (however we do for `depends_on`).

I created #2933

--
",ekristen,"
--
+1 this would be a great feature

--
",atrauzzi,"
--
Something like this would be extremely helpful in debugging situations like https://github.com/docker/compose/issues/3259.

Currently `--verbose` isn't showing me any information about volumes/bind-mounts.

--
"
1197,OPEN,Feature Request: docker-compose stats,kind/feature,2019-10-20 15:19:04 +0000 UTC,awsmsrc,Opened,,"Is it too much cross over/out of scope to implement the stats option in compose

docker-compose stats service_name --index=n

??
",,,thaJeztah,"
--
Nice idea, perhaps even `docker-compose stats` to show stats of all containers of the project.

Not sure if Docker allready supports filtering (ie, specifying a _list_ of containers to get stats for). I'll check, otherwise will create a feature request upstream.

--

--
Checked; the [stats API](https://docs.docker.com/reference/api/docker_remote_api_v1.17/#get-container-stats-based-on-resource-usage) actually is _per container_, so that should be possible, by making an API call for each container.

Would be nice though, if docker offered an endpoint to achieve that (e.g. `GET /stats?filter=....`)

--
",baptistedonaux,"
--
+1

--
",mattes,"
--
+1

--
",mclate,"
--
+1

--
",junxy,"
--
+1

--
",GeorgeTaveras1231,"
--
+1

--
"
963,OPEN,Don't build the same thing twice,area/build; kind/feature,2020-04-14 12:17:41 +0000 UTC,kojiromike,Opened,,"Even though Docker caches layers and the second build is fast, it's not necessary for Compose to build the same thing twice. As far as I can tell, if two services in the yaml have exactly the same string, you can be sure they will be exactly the same build:

```
21:02 ~/docker/test $ cat fig.yml 
svc1:
    build: oog
svc2:
    build: oog
21:02 ~/docker/test $ fig build
Building svc2...
 ---> e72ac664f4f0
Successfully built e72ac664f4f0
Building svc1...
 ---> e72ac664f4f0
Successfully built e72ac664f4f0
```

Naturally, the image built is the same for both services.

There's also the question of the race condition if someone edits the Dockerfile while fig is already building. This is a bit contrived, but does work:

```
$ cat fig.yml
svc1:
    build: oog
svc2:
    build: oog
$ diff oog/Dockerfile[12]
3c3
<  && echo hi

---
>  && echo bye
$ ( cd oog;ln -sf Dockerfile{1,} ); fig build --no-cache & ( cd oog;sleep 2;ln -sf Dockerfile{2,} ); fg
[1] 1374
Building svc2...
 ---> e72ac664f4f0
Step 1 : RUN sleep 5  && echo hi
 ---> Running in dd0c813779ec
fig build --no-cache
hi
 ---> 9f1aed6d839c
Removing intermediate container dd0c813779ec
Successfully built 9f1aed6d839c
Building svc1...
 ---> e72ac664f4f0
Step 1 : RUN sleep 5  && echo bye
 ---> Running in 3c7d54f6145a
bye
 ---> 02ece1cf8f17
Removing intermediate container 3c7d54f6145a
Successfully built 02ece1cf8f17
```

Contrived or not, if it didn't attempt to run the same build twice, it wouldn't have divergent images.
",,,bonndan,"
--
+1

--
",pikeas,"
--
+1

--
",hectorj,"
--
+1

--
",mark,"
--
+1

--
",tristan0x,"
--
+1

--
",eidge,"
--
+1

--
"
745,OPEN,Proposal: make project-name persistent.,kind/feature; status/0-triage,2021-02-18 07:25:18 +0000 UTC,thaJeztah,In progress,,"By default, Compose bases the project name on basename of the directory compose
commands are run from. The project name can be overridden either by 
passing a `-p / --project-name` option for each command or setting the
`COMPOSE_PROJECT_NAME` environment variable.

Using the `--project-name` option for _each_ command is error-prone and for-
getting to pass the option when doing (for example) `docker-compose up`, will result in 
_another_ instance of the project being created under a different name or even
containers of a different project being replaced.

Using the `COMPOSE_PROJECT_NAME` environment variable is not useful when dealing
with multiple projects and can cause similar problems.
### Proposal: make project-name persistent

To solve these problems, compose will save the name of a project to a file in the 
build-context when the project is first started / built.

If a project-file is found, compose automatically uses the project-name from that 
file and throw an exception if the user is trying to override the project-name 
using the `--project-name` option.
### File location

To allow further expansion of options, compose creates a hidden `.docker-compose` directory
in the ""root"" directory of the build-context. Inside that directory, a 
`project-name` file is created, containing just the name of the project;

```
tree -a
.
 .docker-compose
  project-name
 docker-compose.yml
```
### Request for comment

There are a couple of things left to be discussed;
- Should the configuration-file be created _automatically_ or should this
  be an explicit action by the user (e.g. `docker-compose init --project-name=foobar`)
- Should a command be added to _remove_ the configuration file(s)? (e.g. 
  `docker-compose destroy`)
- Compose allows specifying an alternative compose-file (`--file`) should the
  project-name also be applied to those? Should each compose-file get its own
  configuration?

And, in a wider scope;
- Is the project-_name_ actually important? If not, compose could create a _random_ 
  project-name and store that inside the configuration. This would greatly reduce 
  the risk of conflicting names with other projects running on the same server.

edit: renamed Fig to Compose
",,,bfirsh,"
--
The project name isn't important. I like the idea of a random project name. Even better  could we generate a hash of the path to fig.yml and use that?

--
",dnephin,"
--
I actually think the project name is pretty important. If you want to be able to do anything with the images in a CI pipeline, you need to know the project name to be able to retag them as something else.

Being able to override project name from an environment variables makes it easy to keep these unique, and predictable. I think no matter what happens, we need to support the override from environment variables.

I do like the idea of making the project name configurable from a file. I think a similar discussion happened in (#45). Having the project name in`.fig/project-name` seems like it will lead to a lot of really small files.  I think it would be easier to just put it into the `fig.yml` itself (like it is suggested in #45, and one of the docker compose proposals).

What are the advantages of putting it in a separate directory and file?

--

--
> Curious; how do you handle managing multiple projects? 

I usually run `fig` from `python-tox`, which lets me set the environment, so I'm never really setting it in my shell.  I also tend to use tmux, so I have a different shells for every project.

> I think both options can be complementary

Cool, I agree. 

I don't know if I'm sold on `.fig/instance-name` vs say `.fig-instance.yml` that could contain any instance specific overrides, but I think this is more of a minor point.

--

--
> it's important to be able to have control over the images being produced, e.g. myapp:build12345, or also names of the containers?

I guess image is the really important one, but being able to ensure that container names don't conflict is also really important on shared hosts. I see this proposal actually aims to deal with that issue as well.

But I do think that predictable names for containers are still important. I can think of a couple tasks where it's important for external systems (not just fig) to be able to identify a container by name:
- cleanup scripts to remove old containers, being able to identify what project created a container
- debugging/inspecting containers

Both of these are pretty easy right now because I already know what the container name will be.  If I have to lookup a name it's somewhat more involved.

> Even have been thinking that fig could keep track of containers by ID in a local storage inside the .fig directory

It is true this could be a performance gain, but I worry this is the wrong approach.  Adding any persistent state to fig introduces the possibility of lots of bugs (that come along with state).  I would much rather see this being handled by a labeling system in dockerd.  If fig is able to just label containers and then query for all containers with that label , it keeps all the state in a single place (dockerd). I know there was talk of this at some point, I'm not sure if it's on the roadmap.

> Any thoughts on ""implicitly"" creating the 'project-name' file or ""explicitly"" via fig init?

I guess implicitly would be more backwards compatible.  I would like to avoid a `fig init` unless absolutely necessary. Instead of using the basedir, I could see it implicitly creating a project name of `<basename>-<4 digit random id>`

--

--
Originally I wanted the name in the `docker-compose.yml`, but after thinking about it more, I really like the idea of a separate file.

A separate file give you the option to keep it out of version control if you want (for cases where you want each user to be able to have a different project name).

With the new networking support there is feature request to be able to configure the network name as well (it defaults to the project name). So with a separate config file we could include things like default network name, default scale etc.  All the meta-configuration that isn't part of the application definition, but is still relevant to running the composition.

--

--
Some ideas for semi-related information we may want to store either in the same file, or same directory:
- network name (users may want a network name different from the project name. We've already had one request for that.)
- client api version
- docker host
- default scale value

Now that we support multiple compose files, it might also be interesting to include the paths to the compose files to use as config.

--

--
That sounds like a good one as well (added)

--

--
https://github.com/docker/compose/issues/745#issuecomment-182296139 sounds right. The environment variable would take precedence over the value in the compose file, which acts as a default (assuming the project name belongs in the compose file).

Something to consider, what happens when you use multiple compose files that each define a project name?

I don't think it should be an error, that would force files to be either ""primary"" or ""extras"", which is not the case right now. Any file can be used in isolation or in combination with others.

Maybe a warning is reasonable, or maybe we just ignore it completely (since the value can be ignored by setting an option or environment variable as well).

--

--
`COMPOSE_FILE=one.yml:two.yml` is how to set multiple files. So just include the override file in `$COMPOSE_FILE`

--

--
`export COMPOSE_PROJECT_NAME=somethingnew`
--

--
It's not clear to me why the project name matters. No part of the config file should rely on any specific project name.

The only important quality of the project name is that it doesn't conflict with the name of any other project, which is actually an argument **against** putting it in the `docker-compose.yml` file. A developer on a project will often use a different directory name for each project, so the default is often correct for most use cases.

When the default isn't correct there is a way for the developer to override it (`-p`, or `COMPOSE_PROJECT_NAME`), which can either be aliases or put into the `.env` file.

I'm not against a project file that would define the project name, I'd just like to understand why this feature is so critical for some.  If it's because the Compose file requires a specific project name, I see that as a separate problem that should be addressed differently,



--

--
So to summarize, the use cases seem to be when the default isn't appropriate. There are already ways to override the default, but those could be error prone and not obvious to early adopters.

Cases where the default isn't appropriate are:
* multiple compose files in the same directory (already requires you to specify `-f` to run them)
* using the same directory name for all projects (I guess this also requires you to specify `-f`, possible workaround is to use a unique directory name).


--

--
I don't think that fixes the problem for everyone. The naming of the `.env` file feels like a different issue to me.

I think the crux of the problem is this:

The original design of `docker-compose up` was to be a single (short) command you could run to get services running. This is what developers expect from it. However that behaviour can't be achieved for some users (in [these cases](https://github.com/docker/compose/issues/745#issuecomment-282825234)).

There are plenty of ways to work around the problem, but none that seem to work for everyone.

I think the order of precedence (from highest to lowest) needs to be something like this:
1. `--project-name` (always overrides)
2. `COMPOSE_PROJECT_NAME` environment variable
3. A default defined by the user, separate from any versioned file
4. A default defined by the project, that can be checked in
5. The directory name (the default when nothing is specified)

(3) could be achieved with a `.docker/project-name` file (as proposed in the OP)
(4) could be achieved with a field in the `docker-compose.yml` file

It's unfortunate that there needs to be so many different ways to set the project name.
--

--
To clarify some of the confusion

> You could do that already

Previously you could set a project name using an environment variable. The new environment variable is not a name, it's a toggle which enabled a feature which lets you set a project name in the compose file.

> I'm assuming you mean globally in all of your shells that you spawn on your computer. If you do that, then you could get unwanted behaviour in completely unrelated projects. 

If you mean ""other projects"" as-in, ""something that is not compose could read this and break"" I think that is not realistic. There are plenty of environment variables set in every shell. The environment variable is properly namespaced as ""COMPOSE_X_"".

If you mean ""other compose projects"" then I think you are actually making an argument for why this variable is necessary. If the feature were enabled by default then anyone relying on the current default behaviour would break. 

If it's neither of those, please do clarify.

> It will also cause confusion when a developer pulls a project from version control and forgets to set the environment variable.

If a project only works with a specific project name then I think there are other problems. There should never be a case where a project only works with a single name.

I see this as another argument for not putting the project name in the Compose file. If the project name is in the compose file then any two project could use the same name, causing a conflict, which would break both projects. The name should really be set by the developer who is aware of what other project names are already in use.
--

--
I am a fan of ""4 project.rc"" although I would probably use something like `docker-project.yaml` instead of a different format. This is exactly what the original issue describes. As far as I'm concerned any discussion about putting the project name in the compose file should be in a separate issue.

> All I need is a way to commit my project name to source control. 

This is still a point I don't understand. There should be no reason to require a single hard coded project name. If there is external tooling that expects a consistent name, why is that tooling not setting a project name before it calls `docker-compose` ?

`my_project_network_on_my_localhost` seems wrong to me. Why do you need the project name in an external network? It doesn't need to match the compose project name.
--
",thaJeztah,"
--
The reason for putting it in a separate file has a number of reasons, I'll try to explains my thinking behind this;
- To preserve the name that was used to _start_ the project (i.e., `--project-name=foobar`), which can be different from the automatic project-name.
- Having multiple instances or _versions_ of a project running on the same server, without them conflicting each other
- Or, in short, the `.fig/project-name` holds the name of _that instance_ of the project.

Perhaps the file should be called `instance-name` or similar.

> I do like the idea of making the project name configurable from a file

Although _possible_ to do this with this proposal (by manually creating the `project-name` file), my primary use case was to have _fig_ create the file in order to save the name that was used.

> will lead to a lot of really small files. 

True, the alternative is to skip the `.fig` directory, however, if additional things are needed in future, extra file(s) can be added without cluttering the root of your project. Git does it similar and I think it's a clean approach.

> I think it would be easier to just put it into the fig.yml

I think both options can be complementary; use the name from `fig.yml` as the default if the name is not overridden by a flag or env-variable. Put the name that is actually used to _start_ the project inside the `.fig/project-name`

> Being able to override project name from an environment variables makes it easy to keep these unique, and predictable. I think no matter what happens, we need to support the override from environment variables.

Curious; how do you handle managing multiple projects? I.e. `cd project-a && fig ps` then `cd project-b fig <something>`?

Thanks for your feedback!

--

--
Thinking of the project-name; If I understand your situation correctly, it's important to be able to have control over the _images_ being produced, e.g. `myapp:build12345`, or also names of the _containers_? Just to get a ""feel"" for your situation.

My thoughts behind ""random"" project-names was that, as long as Fig is able to locate the containers for a project, nice-looking names aren't important. If I, as a user, can access a services' container via its service-name (e.g. `fig stop web`), the name of the actual container doesn't matter.

Even have been thinking that fig could keep track of containers by ID in a local storage inside the `.fig` directory (which could be a performance gain on machines with a lot of running containers). But that's really something for a separate issue.

Any thoughts on ""implicitly"" creating the 'project-name' file or ""explicitly"" via `fig init`? Perhaps if I have some time during the coming holidays I can experiment a bit (never coded anything in Python, so it will be _really_ experimental :)) 

--

--
@frank-dspeed thanks for adding your use-case. If I understand correctly, you _start_ your containers with fig, but _""manage""_ them directly via Docker after that, making use of the naming convention that Fig uses?

Perhaps this is of interest to you as well: https://github.com/docker/docker/pull/9882 - having meta-data would offer more ways to identify containers, not only their name.

--

--
> I think managing the unambiguity of the project name shouldn't be fig's responsibility.

I'm not so sure; Fig ""silently"" overwriting another projects' containers because if happened to be in a directory with the same name is sometimes nasty.

> when i understood your proposal correctly, the generation of a random name would render the FIG_PROJECT_VARIABLE and the --project-name-option useless. which is handy for 'templating' services.

Following the discussion above, I think something like this would work
- If `--project-name` is provided, use that (and write/update the `.project-name`? Not sure)
- No `--project-name` is provided, but `FIG_PROJECT_NAME` is, use `FIG_PROJECT_NAME` (and write/update to `.project-name`?)
- None of the above, but `.project-name` is set, use `.project-name`
- None of the above; create a _random_ name and write it to `.project-name`

--

--
@dnephin sgtm

@mikehaertl I used a `.docker-compose` folder in my example, but a file could work as well, depending on how much information we want to store

--

--
@mikehaertl just renamed them from `.fig` to `.docker-compose` ;-)

--

--
> client api version

possibly `docker_host` ?

--
",frank,"
--
i can only say if fig starts generating random names now i will switch away from it because i run 1000+ containers on a single host and when i cant identify them by name any more its nothing for me.

--

--
ah yes i did such proposals a lot for example simply adding new filds and that but i ended in that case with simply adding a ENV and then i have that as costum fild i can parse it :dart: 

--
",funkyfuture,"
--
I think managing the unambiguity of the project name shouldn't be fig's responsibility.

when i understood your proposal correctly, the generation of a random name would render the `FIG_PROJECT_VARIABLE` and the `--project-name`-option useless. which is handy for 'templating' services.

--

--
from someone's perspective who uses fig in scripts that take care of a name and pass it to fig, storing a name in the project (which is in my case rather a template) location makes no sense.

and still, i sensed it very intuitive that the directory name is used in the name of the resulting containers when i just ran `fig up`.
and let say, you look at `docker ps -a`, that won't be very helpful if it's filled up with random names.

would an option `--random-name` help in your situation?
beside that i think the ability to prepend some `[a-zA-Z0-9_].*` to reflect some namespacing would be useful for broader deployments.

--
",jderusse,"
--
What's about using the fig.yml to store such informations ?

```
schema-version: 1.1
project_name: foo
containers:
  web:
    build: .
   command: python app.py
    links:
     - db
    ports:
     - ""8000:8000""
  db:
    image: postgres
```

And to keep BC, in compose/project.py::from_config

```
@classmethod
    def from_config(cls, name, config, client):
        if 'schema-version' not in config:
            config = {
                'schema-version': '1.0',
                'containers': config
            }
        dicts = []
        for service_name, service in list(config.containers.items()):
            if not isinstance(service, dict):
                raise ConfigurationError('Service ""%s"" doesn\'t have any configuration options. All top level keys in your docker-compose.yml must map to a dictionary of configuration options.' % service_name)
            service['name'] = service_name
            dicts.append(service)
        return cls.from_dicts(name, dicts, client)
```

--

--
what's about introdusing a new property `container_name_pattern` with the default value `%(project_name)s_%(service_name)s_%(instance_number)s` to keep BC
this parameter lets us free to change it to `hardcodedproject_%(service_name)s_%(instance_number)s` and definitively fix this issue

--

--
an elegant solution could be to use placeholder in the `container_name` property (and other dynamic naming like volume, network, ...)
```yaml
services:
  my_service:
    container_name: {project_name}_{service_name}_{instance_number} # default value
```

with such configuration, one could use
```yaml
services:
  my_service:
    container_name: fixedprojectname_{service_name}_{instance_number}
```


edit: this is not a perfect solution, as it'll conflict for people who use 2 distinguished project within the same folder name
--
"
318,OPEN,feature: including external docker-compose.yml,kind/enhancement; status/0-triage,2020-10-19 11:18:52 +0000 UTC,dnephin,In progress,,"### The Problem

I'd like to use fig for acceptance testing of services

In the case of a single service with a single level of dependencies this is easy (ex: a webapp with a database). As soon as the dependency tree grows to depth > 1, it gets more complicated (ex: service-a requires service-b which requires a database). Currently I'd have to specify the service dependency tree in each `fig.yml`.  This is not ideal because as the tree grows, we end up with a lot of duplication, and having to update a few different `fig.yml`'s in different projects when a service adds/changes a dependency is not great.
### Proposed Solution

Support an `include` section in the `fig.yml` which contains url/paths to other `fig.yml` files. These files would be included in a `Project` so that the top-level `fig.yaml` can refer to them using `<proejct>_<service>`.
#### Example config

``` yaml
include:
    # link using http
    servicea:
        http: http://localhost:8080/projects/servicea/fig.yml
    # local paths
    serviceb:
        path: ../projects/serviceb/fig.yml

webapp:
    ...
    links:
        - servicea_webapp
        - serviceb_webapp
```
",,,dnephin,"
--
I'm looking to implement this features myself, but I would like to upstream it eventually, so I'm interested to see how you feel about this idea.

I've looked over the code, and it seems to be relatively easy to make this work.

Some unresolved issues are:
- including services which use `image` should be easy enough, but services with `build` would need to ensure that the naming remains consistent, and that the service was already built (and possibly pushed to a registry). See next two issues
- in the case of remote repos, the config may need to support a repo name as well (as part of the includes section).
- project naming. Instead of using the file path/directory for a project, it uses the key from the parent  yaml config (the file with the include section). This poses a problem if the names don't match.  I was considering adding a `project_name` key to the config to keep these consistent (this is not really critical)

For fetching the external configs. I was going to use `requests` since it's already a dependency, but I was also considering supporting git as another method, possibly using [dulwich](https://github.com/jelmer/dulwich)

--

--
I have a working prototype with a single integration test in https://github.com/dnephin/fig/compare/include_remote_config

It still needs some cleanup and more tests, but I thought I'd link to the current progress.

--

--
Cool, glad you are interested! I haven't had much time to finish this off yet.  I still plan on doing it, but it might still be a week or two out. I've been thinking it actually probably requires #457 to deal with including any services that use `build` instead of `image` (because you wont be able to build them without the whole project).

The idea would be to use one of the tags as the image, and assume the other project has properly pushed the images and they are available to be pulled (or already cached locally).

--

--
I haven't thought much about using it with locally available `fig.yml`. In that kind of setup would you have different services in subdirectories and you want to include them so that each individual one is smaller?

I think defaulting to use the `build` if no tags are provided is probably reasonable. It might need to do something with relative paths (append the path given in the `include` section to any build paths in the included `fig.yml`).

--

--
https://github.com/dnephin/fig/compare/include_remote_config is mostly ready. There are two TODOs to resolve:
- convert remote `build` services to use the first `tag`
- support reading `hdfs` and `s3` urls for remotes (currently supports http/https, and local files)

--

--
@rseymour Thanks for trying it out!

I wonder if `fig up --no-recreate` will accomplish this?

--

--
PR is up at #758 is anyone is interesting in giving some feedback

--

--
I agree, I think they're trying to solve the same problem

--

--
I've implemented this as an external pre-processing tool at https://github.com/dnephin/compose-addons#dcao-include

If anyone is interested, please check out the docs. Any feedback can be contributed by opening an issue on that repo (and would be appreciated). 

--

--
The branch is so old now I don't think it will merge.

I would suggest giving  https://github.com/dnephin/compose-addons#dcao-include a try. It's a pre-processing step, but you still use `docker-compose` for the orchestration.  I've used `compose-addons` for a few repos and it's worked for me.

If the issue is a lack of a binary install, please do open an issue on the github for that project and I can help you out.

--

--
I build some things external to Compose in  https://github.com/dnephin/compose-addons that act as pre/post processors for a Compose file. They probably need to be updated for the v2 format.

--

--
We have not made any progress integrating the ideas into Compose

--
",bfirsh,"
--
Nice!

--
",suzaku,"
--
@dnephin @bfirsh  +1 for the new feature.

I'm looking for a way to reuse `fig.yml` from another project,
before something like `include` is available,
I'll have to fallback to using copy/paste/edit ;(

--
",pirelenito,"
--
That is awesome! I'd love to get this feature as well. Any updates on merging this on master @dnephin ?

--

--
Nice!

For a remote or standalone fig.yml file your solution of using tags seems pretty reasonable.

What are your thoughts if the fig.yml file is available locally inside its own project (meaning everything would be there)? Could the build be triggered? It seems to make sense.

--
",ThomasSteinbach,"
--
+1 - absolutely nescessary feature

It should be possible, to extend the imports. For instance a service included should get 'volumes_from' a data volume container.

Thus you can configure smaller orchestrations close to the services (e.g. gitlabService=gitlab+redis+postgres) and combine those smaller orchestration to a bigger one (whole orchestration = gitlabService + liferayService + jenkinsService). In the final fig.yml you can connect the imports to each other.

--
",rudibatt,"
--
+1 for more reusable configuration

--
"
229,OPEN,Switch to using hyphens as a separator in hostnames,,2021-02-10 18:35:06 +0000 UTC,kung-foo,Opened,,"The hostname format used by fig creates names that are not strictly valid. 

Current pseudo-code:

``` python
name = '_'.join([project, container, instance_num])
```

This generates names like `cluster_hadoop_1`. Underscores are not valid (though in practice _most_ components are tolerant of this). 

Valid names should match `[a-zA-Z0-9\-]+`.

I came across this error when trying to test out some hadoop/hdfs containers and hadoop bailed with an exception saying that `hdfs://flume_hadoop_1/` was not valid URI (even though it was in `/etc/hosts` and `ping flume_hadoop_1` worked just fine).

See: http://en.wikipedia.org/wiki/Hostname#Restrictions_on_valid_host_names

Changing this to dashes is easy, but it would break existing configurations that depend on hard coded container names.
",,,kung,"
--
also see: https://github.com/dotcloud/docker/issues/5418

--
",danburkert,"
--
This is causing pain for me as well, in pretty much the exact same scenario (the hostname being parsed by Java's standard library URI parser).  Is this a fig issue, or should it be fixed in docker?

--
",aanand,"
--
Frustratingly, underscores are invalid in hostnames, and dashes are invalid in shell variable names. So if you can't name a Docker link without either breaking one of those or smushing everything together (e.g. `hadoop1`). Not ideal.

However, looks like https://github.com/docker/docker/pull/6270 might fix this by sanitising environment variable names, in which case Fig can switch to dashes and everything will hopefully work:

``` yaml
web:
  links:
    - hadoop
```

``` bash
$ fig run web cat /etc/hosts
...
172.17.0.42 hadoop-1
...

$ fig run web env
...
HADOOP_1_PORT=tcp://172.17.0.42:5432
HADOOP_1_PORT_5432_TCP=tcp://172.17.0.42:5432
HADOOP_1_PORT_5432_TCP_ADDR=172.17.0.42
...
```

--

--
https://github.com/orchardup/fig/pull/349 is also relevant.

--

--
@zeeraw that would be out of fig's scope - a job for docker itself.

--

--
@susu Why is this a showstopper? The problem of underscores in hostnames is easily worked around, either with link aliases or by changing service names.

--

--
> spark somehow extracts the underscored hostname of docker container (projectname_container_1.default_network), and try to use it

However it's doing that, that's the wrong thing to do. Is this an image you're using from the Hub, or did you build it yourself?

Switching back to version 1 is not a future-proof solution.

--
",nubs,"
--
Technically speaking, I don't believe that hyphens in shell variable names are strictly forbidden.  You just can't access them in the normal way:

``` sh
$ env foo-bar=baz bash
$ printenv foo-bar
baz
```

--
",bfirsh,"
--
:+1: switching to hyphens

--

--
We can do this now that https://github.com/docker/docker/issues/5418 has been fixed, right?

--
",zeeraw,"
--
What about writing both hyphenated and underscored to the hosts file for now?

--
"
184,OPEN,Watch code and automatically rebuild when something changes,kind/enhancement; status/0-triage,2021-01-31 17:20:39 +0000 UTC,bfirsh,In progress,,"Compose could watch your code and automatically kick off builds when something changes. This would mean:
- Code can be reloaded automatically regardless of language. This would also make code reloading work on compiled languages if that was part of the build process!
- Volumes are no longer needed in development
- Production server can be used in development (e.g. gunicorn can be used to serve Django apps in development)

It could either be an option to `up` (`docker-compose up --watch`), an option in the config file specifying directories to watch/ignore, or perhaps a separate command (`docker-compose watch`).

Thanks to @samalba for the suggestion!
",,,samalba,"
--
:+1: 

--
",marksteve,"
--
:+1:

--
",sherzberg,"
--
+1. If this is to be part of _fig up_, how about an opt in flag?

``` yaml
web:
  watch: 
   - *.py
   - *.css
   - *.coffee
```

--
",cameron,"
--
:thumbsup: 

Where this gets documented, it's probably worth noting the following pattern that helps avoiding unnecessary package manager (pip/npm/bower/et al) action:

```
# adding your language deps before adding the rest of your source....
ADD requirements.txt /requirements.txt
RUN pip install -r requirements.txt

# ... will prevent changes to source incurring a re-install of language deps
ADD . /src
```

--
",KyleAMathews,"
--
:100: 

--
",luebken,"
--
+1

--
"
