Summary,Issue key,Issue id,Issue Type,Status,Project key,Project name,Project type,Project lead,Project description,Project url,Priority,Resolution,Assignee,Reporter,Creator,Created,Updated,Last Viewed,Resolved,Affects Version/s,Affects Version/s,Affects Version/s,Affects Version/s,Fix Version/s,Component/s,Component/s,Component/s,Component/s,Votes,Labels,Labels,Labels,Labels,Labels,Description,Environment,Work Ratio,Security Level,Outward issue link (Backports),Outward issue link (Backports),Outward issue link (Backports),Outward issue link (Backports),Outward issue link (Depends),Outward issue link (Depends),Outward issue link (Depends),Outward issue link (Duplicate),Outward issue link (Related),Outward issue link (Related),Outward issue link (Related),Outward issue link (Related),Outward issue link (Related),Outward issue link (Related),Outward issue link (Related),Outward issue link (Related),Outward issue link (Related),Outward issue link (Related),Outward issue link (Related),Outward issue link (Related),Outward issue link (Related),Outward issue link (Related),Outward issue link (Related),Outward issue link (Related),Outward issue link (Related),Attachment,Attachment,Attachment,Custom field (# Replies),Custom field (# of Sprints),Custom field (Account),Custom field (Actual Story Points),Custom field (Additional Product Details/Requests),Alert Assignee,Alert Assignee simplified,Custom field (Atlas Org Link),Auto-Close,Auto-Close simplified,Average Wait Time (AWT),Average Wait Time (AWT) simplified,Custom field (Backport Approved By),Custom field (Backport Requested),Custom field (Backport Requested),Custom field (Backport Requested),Custom field (Backport Requested),Custom field (Backwards Compatibility),Custom field (Baseline end date),Custom field (Baseline start date),Custom field (Branch),Custom field (Case),Custom field (Case),Custom field (Case),Custom field (Case),Custom field (Case),Custom field (Case),Custom field (Case),Custom field (Case),Custom field (Case),Custom field (Case),Custom field (Case),Custom field (Case),Custom field (Case),Custom field (Case),Custom field (Case),Custom field (Case),Custom field (Case),Custom field (Case),Custom field (Case),Custom field (Case),Custom field (Case),Custom field (Case),Custom field (Case),Custom field (Case),Custom field (Case),Custom field (Case),Custom field (Case),Custom field (Case),Custom field (Case),Custom field (Case),Custom field (Case),Custom field (Change completion date),Custom field (Change reason),Custom field (Change risk),Custom field (Change start date),Custom field (Change type),Close After 3 Days,Close After 3 Days simplified,Custom field (Cloud-Dev Target),Custom field (Concerns around backporting this change?),Custom field (Contractor Request Type-Link Jira Proc Tickets),Critical issues resolved in 24 hours,Critical issues resolved in 24 hours simplified,Customer Request Type,Custom field (Date of 1st Reply),Custom field (Days since reply),Custom field (Dependencies),Custom field (Desktop Hardware Specifications),Custom field (Docs Owner),Custom field (Downstream Changes Summary),Custom field (Downstream Team Attention),Custom field (Email Send Date),Custom field (Engineering Lead),Custom field (Epic Link),Escalation SLA,Escalation SLA simplified,Custom field (Estimated Time to Complete),Custom field (External Case Link),Custom field (External issue ID),Custom field (External issue ID),Custom field (Feature Flag),First Response Time (FRT),First Response Time (FRT) simplified,Custom field (From Email Address),Custom field (GitHub#),Custom field (Github URL),Custom field (Impact),Custom field (Investigation reason),Custom field (Is it a regression?),Custom field (Issue Type Filters Security (managed by plugin)),Custom field (Jump ID),Custom field (Last Commenter),Custom field (Last Workflow Status),Custom field (Last comment by Customer),Custom field (Last commenter),Custom field (Last public comment date),Custom field (Linked BF Score),Custom field (Nessus Affected Hosts),Custom field (Nessus CVE),Custom field (Nessus CVSS),Custom field (Nessus Plugin ID),Custom field (Nessus See Also),Custom field (Netsuite Invoice #),Custom field (Old_Backport),Custom field (Operating System),Custom field (Operational categorization),Custom field (Original story points),Custom field (Other Notes),Custom field (Parent Link),Custom field (Participants),Custom field (Participants),Custom field (Participants),Custom field (Participants),Custom field (Participants),Custom field (Participants),Custom field (Participants),Custom field (Participants),Custom field (Participants),Custom field (Participants),Custom field (Participants),Custom field (Participants),Custom field (Participants),Custom field (Participants),Custom field (Participants),Custom field (Participants),Custom field (Participants),Custom field (Participants),Custom field (Participants),Custom field (Participants),Custom field (Participants),Custom field (Participants),Custom field (Participants),Custom field (Participants),Custom field (Participants),Custom field (Participants),Custom field (Participants),Custom field (Participants),Custom field (Participants),Custom field (Participants),Custom field (Participants),Custom field (Participants),Custom field (Participants),Custom field (Participants),Custom field (Participants),Custom field (Participants),Custom field (Participants),Custom field (Participants),Custom field (Participants),Custom field (Participants),Custom field (Participants),Custom field (Participants),Custom field (Participants),Custom field (Participants),Custom field (Participants),Pending Business Approval,Pending Business Approval simplified,Custom field (Pending reason),Custom field (Phase I),Custom field (Phase II),Custom field (Phase III),Custom field (Photo URL),Custom field (Planned End),Custom field (Planned Start),Custom field (Police Report #),Custom field (Private notes),Custom field (Product Design),Custom field (Product Manager),Custom field (Product Marketing Manager),Custom field (Product Rank),Custom field (Product categorization),Custom field (Program Manager),Custom field (Progress),Custom field (Published),Question SLA,Question SLA simplified,Custom field (Rank),Custom field (Rank (Obsolete)),Custom field (Reason for requested due date),Custom field (Request participants),Custom field (Requested Completion - Planned Completion),Custom field (Requires additional work before releasing the ticket?),Researching,Researching simplified,Custom field (Root cause),Satisfaction score (out of 5),Custom field (Should it be included in release notes?),Custom field (Solution),Custom field (Source),Sprint,Sprint,Sprint,Sprint,Sprint,Sprint,Sprint,Stalled,Stalled simplified,Custom field (Story Points),Custom field (TS Initiative Status),Custom field (Talk duration),Custom field (Target end),Custom field (Target start),Custom field (Team),Custom field (Teams Impacted),Custom field (Teams Impacted),Custom field (Teams Impacted),Custom field (Tests Written),Custom field (Theme),Time to Business Approval Request,Time to Business Approval Request simplified,Time to Closed,Time to Closed simplified,Time to Netsuite Entry,Time to Netsuite Entry simplified,Time to Resolved,Time to Resolved simplified,Time to Security Review,Time to Security Review simplified,Time to approve normal change,Time to approve normal change simplified,Time to close after resolution,Time to close after resolution simplified,Time to closed,Time to closed simplified,Time to first response,Time to first response simplified,Time to regional response,Time to regional response simplified,Time to resolution,Time to resolution simplified,Time waiting for support,Time waiting for support simplified,Custom field (To Delete - End date),Custom field (To Delete - Start date),Custom field (Triage Assignee),Custom field (Triage Assignee),Triaged,Triaged simplified,Custom field (Type Of Work (TSTOOLS)),Custom field (Urgency),Custom field (User Summary),Custom field (User Summary Box required?),Custom field (Versioned API Impact Summary),Waiting for Approval,Waiting for Approval simplified,Waiting for BIZSYS,Waiting for BIZSYS simplified,Waiting for Employee,Waiting for Employee simplified,Waiting for IT,Waiting for IT simplified,Waiting for Reporter (Test),Waiting for Reporter (Test) simplified,Waiting for User Input,Waiting for User Input simplified,Waiting for Vendor,Waiting for Vendor simplified,Custom field (Workaround),Custom field (Zoom ID),Custom field (serverRank),Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment,Comment
Index covered binary prefix search,SERVER-9925,78916,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Critical - P2,,backlog-query-optimization,nicholas.tang,nicholas.tang,Jun 13 2013 02:23:30 PM UTC,Nov 14 2020 06:44:47 PM UTC,Feb 17 2021 11:14:55 AM UTC,,,,,,Backlog,Indexing,Querying,,,1,,,,,,We need a way to do a binary prefix search on an existing field that's covered by an index so it can happen quickly in RAM.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,3.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2013-06-14 15:59:20.0,223776000,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,craig.homa(craig.homa),Wed Jan 15 05:32:54 UTC 2014,,,,,,,,,,,,,,asya(asya),backlog-query-optimization(JIRAUSER1257108),eliot(eliot),nicholas.tang(nicholas.tang@10gen.com),yfinkelstein(yfinkelstein),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i04fi7:",,,,,,,"0|i00ttj:",6419,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i1i1db:","Jul 03 2013 04:14:15 AM UTC;asya;This already works in current version. 

{code}
> db.bincov.find()
{ ""_id"" : BinData(5,""1295AB3E"") }
{ ""_id"" : BinData(5,""389AAB3E"") }
{ ""_id"" : BinData(5,""A56AAB3E"") }
{ ""_id"" : BinData(5,""12900000"") }
{ ""_id"" : BinData(5,""38FFFFFF"") }
{ ""_id"" : BinData(5,""38FFFF00"") }
{ ""_id"" : BinData(5,""1290FFFF"") }
{ ""_id"" : BinData(5,""00000000"") }
{ ""_id"" : BinData(5,""11111111"") }
{ ""_id"" : BinData(5,""AAAAAAAA"") }
{ ""_id"" : BinData(5,""AAAA0000"") }
{ ""_id"" : BinData(5,""0000AAAA"") }
{ ""_id"" : BinData(5,""FFFFAAAA"") }
{ ""_id"" : BinData(5,""MD5HHXWW"") }
{ ""_id"" : BinData(5,""MD512X16"") }
{ ""_id"" : BinData(5,""MD520X24"") }
{ ""_id"" : BinData(5,""MD536X40"") }
{ ""_id"" : BinData(5,""MD812X16"") }
{ ""_id"" : BinData(5,""MD120X24"") }
{ ""_id"" : BinData(5,""MD220X24"") }
> > db.bincov.find({$or : [ {_id: {$gt:BinData(5,""MD5AAAAA""), $lt:BinData(5,""MD599999"")} } , {_id: {$gt:BinData(5,""MD8AAAAA""), $lt:BinData(5,""MD899999"")}}, {_id: {$gt:BinData(5,""MD1AAAAA""), $lt:BinData(5,""MD199999"")} } ]  },{_id:1}).explain()
{
	""clauses"" : [
		{
			""cursor"" : ""BtreeCursor _id_"",
			""isMultiKey"" : false,
			""n"" : 4,
			""nscannedObjects"" : 0,
			""nscanned"" : 4,
			""nscannedObjectsAllPlans"" : 0,
			""nscannedAllPlans"" : 4,
			""scanAndOrder"" : false,
			""indexOnly"" : true,
			""nYields"" : 0,
			""nChunkSkips"" : 0,
			""millis"" : 0,
			""indexBounds"" : {
				""_id"" : [
					[
						BinData(5,""MD5AAAAA""),
						BinData(5,""MD599999"")
					]
				]
			}
		},
		{
			""cursor"" : ""BtreeCursor _id_"",
			""isMultiKey"" : false,
			""n"" : 1,
			""nscannedObjects"" : 0,
			""nscanned"" : 1,
			""nscannedObjectsAllPlans"" : 0,
			""nscannedAllPlans"" : 1,
			""scanAndOrder"" : false,
			""indexOnly"" : true,
			""nYields"" : 0,
			""nChunkSkips"" : 0,
			""millis"" : 0,
			""indexBounds"" : {
				""_id"" : [
					[
						BinData(5,""MD8AAAAA""),
						BinData(5,""MD899999"")
					]
				]
			}
		},
		{
			""cursor"" : ""BtreeCursor _id_"",
			""isMultiKey"" : false,
			""n"" : 1,
			""nscannedObjects"" : 0,
			""nscanned"" : 1,
			""nscannedObjectsAllPlans"" : 0,
			""nscannedAllPlans"" : 1,
			""scanAndOrder"" : false,
			""indexOnly"" : true,
			""nYields"" : 0,
			""nChunkSkips"" : 0,
			""millis"" : 0,
			""indexBounds"" : {
				""_id"" : [
					[
						BinData(5,""MD1AAAAA""),
						BinData(5,""MD199999"")
					]
				]
			}
		}
	],
	""n"" : 6,
	""nscannedObjects"" : 0,
	""nscanned"" : 6,
	""nscannedObjectsAllPlans"" : 0,
	""nscannedAllPlans"" : 6,
	""millis"" : 1,
	""server"" : ""asyasmacbook.local:24444""
}
{code}

Is the issue that $in can't be used and it has to be an $or operator?  There is a separate ticket for making $or as performant as $or but this ticket is specifically about covered index queryability which seems to work.
","Jul 05 2013 08:47:57 PM UTC;yfinkelstein;Yes, the performance of this query is very poor at the moment. If indeed $or will be as performant as $in that could be an acceptable solution. Please note that if the following would be supported

{code}
db.bincov.find({_id: {$in: [{$prefix: BinData(5,""MD5_1"")}, {$prefix: BinData(5,""MD5_1"")}, ...]}}
{code}

it would more more concise and readable.

What I also asked in relaed ticket is for the ability to specify limit for each $prefix term match.

Example:
{code}
db.bincov.find({_id: {$in: [{$prefix: {$value: BinData(5,""MD5_1""}, $limit: 1)}, {$prefix: {$value: BinData(5,""MD5_1""), $limit: 1}}, ...]}}
{code}

This would return at most one document with _id having a binary prefix MD5_1, at most one document with _id having a binary prefix MD5_2, etc. Without the $limit feature the query would first return all documents  with _id having a binary prefix MD5_1. If the number of them is high and exceed the limit on the cursor we would have a logical problem of how to resume the query on the same cursor.

Again, the syntax is just schematic and is meant only to help express the point. How you folks end up expressing it is not important as long as the same capabilities are supported.

Does it make sense?
Yuri



 
","Jan 15 2014 05:32:54 AM UTC;eliot;To do for binary, need to change sort order of bindata",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
ReshardingDonorService instances to load metrics state upon instantiation,SERVER-53913,1595524,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,lamont.nelson,lamont.nelson,lamont.nelson,Jan 20 2021 05:04:09 PM UTC,Feb 17 2021 12:32:11 AM UTC,Feb 17 2021 11:15:15 AM UTC,,,,,,5.0 Required,,,,,0,PM-234-T-autocommits,,,,,Should instantiate ReshardingMetrics object with the persisted data.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,1.0,,,,,,,,,,,,,,,,Fully Compatible,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2332800,,,,,,,,PM-234,,,,,,,,,,,,,,,,,,,,true,lamont.nelson(lamont.nelson),2021-01-20 17:04:09.0,,,,,,,,,,,,,,lamont.nelson(lamont.nelson),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i7ejj3:",,,,,,,"0|i78bjz:",9223372036854775807,,,,,,,,,,,,Sharding 2021-04-05,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i7ehmn:",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Test that transactions and retryable writes are able to complete within gReshardingMinimumOperationDurationMillis when the transaction needs to retry.,SERVER-54452,1619848,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-server-sharding,lamont.nelson,lamont.nelson,Feb 10 2021 07:06:22 PM UTC,Feb 17 2021 12:07:12 AM UTC,Feb 17 2021 11:15:15 AM UTC,,,,,,5.0 Desired,Sharding,,,,0,PM-234-T-autocommits,,,,,SERVER-53918 introduced a pause for up to gReshardingMinimumOperationDurationMillis to allow retryable writes the time to complete if they need to be retried. This ticket is a placeholder to add a jstest for this scenario.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,Fully Compatible,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,518400,,,,,,,,PM-234,,,,,,,,,,,,,,,,,,,,true,lamont.nelson(lamont.nelson),2021-02-10 19:06:22.0,,,,,,,,,,,,,,backlog-server-sharding(backlog-server-sharding),lamont.nelson(lamont.nelson),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i7ipcv:",,,,,,,"0|i7cbsv:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i7ingf:",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Aggregate the donor approxBytesToCopy and approxDocumentsToCopy values and report to recipients,SERVER-53908,1595473,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,amirsaman.memaripour,lamont.nelson,lamont.nelson,Jan 20 2021 04:34:14 PM UTC,Feb 17 2021 12:04:14 AM UTC,Feb 17 2021 11:15:15 AM UTC,,,,,,5.0 Required,,,,,0,PM-234-T-autocommits,,,,,Should add the aggregated value in config collection document where minFetchTimestamp is stored.,,,,,,,,SERVER-53907,,,,,,,,,,,,,,,,,,,,,,,,1.0,1.0,,,,,,,,,,,,,,,,Fully Compatible,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,40522,<s><a href='https://jira.mongodb.org/browse/SERVER-53907'>SERVER-53907</a></s>,,,,,,,PM-234,,,,,,,,,,,,,,,,,,,,true,lamont.nelson(lamont.nelson),Tue Feb 16 23:59:53 UTC 2021,,,,,,,,,,,,,,amirsaman.memaripour(amirsaman.memaripour),lamont.nelson(lamont.nelson),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i7ej7r:",,,,,,,"0|i78bbb:",9223372036854775807,,,,,,,,,,,,Sharding 2021-02-22,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i7ehbb:","Feb 16 2021 11:59:53 PM UTC;lamont.nelson;Note that we had decided to do the calculation based on the number of recipients in this ticket since the coordinator has this information readily available. The value reported by each donor in SERVER-53907 is the true value reported by $collStats.storageStats for that process.

This is referring to this part of the spec:
{noformat}
The initial value for the approxDocumentsToCopy and approxBytesToCopy metrics are calculated as follows.
approxDocumentsToCopy = 
[sum of $collStats.storageStats.count across all donor shards] / [# recipient shards]
approxBytesToCopy = 
[sum of $collStats.storageStats.size across all donor shards] / [# recipient shards]
{noformat}
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Resharding metrics output from the currentOp command should be reset when a new operation is started,SERVER-54229,1609755,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-server-sharding,lamont.nelson,lamont.nelson,Feb 03 2021 03:36:51 AM UTC,Feb 16 2021 11:06:35 PM UTC,Feb 17 2021 11:15:15 AM UTC,,,,,,5.0 Required,,,,,0,PM-234-T-autocommits,,,,,"The following metrics should be reset when a new resharding operation is started:

{noformat}
    totalOperationTimeElapsedMillis: int64
    remainingOperationTimeEstimatedMillis: int64

    approxDocumentsToCopy: int64
    documentsCopied: int64
    approxBytesToCopy: int64
    bytesCopied: int64
    totalCopyTimeElapsedMillis: int64

    oplogEntriesFetched: int64
    oplogEntriesApplied: int64
    totalApplyTimeElapsedMillis: int64

    countWritesDuringCriticalSection: int64
    totalCriticalSectionTimeElapsedMillis: int64

    // Note that 0 corresponds to kUnused for these enum values and therefore
    // won’t be ambiguous when reset.
    coordinatorState: int32
    donorState: int32
    recipientState: int32
{noformat}

",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,4.0,,,,,,,,,,,,,,,,,Fully Compatible,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2021-02-03 19:50:34.0,43756,,,,,,,,PM-234,,,,,,,,,,,,,,,,,,,,true,lamont.nelson(lamont.nelson),Tue Feb 16 23:05:59 UTC 2021,,,,,,,,,,,,,,backlog-server-sharding(backlog-server-sharding),bruce.lucas(bruce.lucas@10gen.com),lamont.nelson(lamont.nelson),max.hirschhorn(max.hirschhorn@10gen.com),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i7gza7:",,,,,,,"0|i7ao53:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i7gxdr:","Feb 03 2021 07:50:34 PM UTC;bruce.lucas;Generally serverStatus metrics that represent cumulative counters or cumulative elapsed time are expected by downstream tooling to be cumulative since the server started, so I'm not sure I would expect those to be reset. Are there any other instances of cumulative server counters that get reset, for comparison?","Feb 03 2021 08:07:58 PM UTC;max.hirschhorn;Hi [~bruce.lucas], we're having resharding report metrics for the actively running operation in serverStatus as part of the ""shardingStatistics.resharding"" section (see SERVER-52773). This is because we want to capture these metrics in FTDC. The idea behind resetting them when a new resharding operation is started is to avoid reporting per-collection metrics in serverStatus because that leads to expensive schema changes in FTDC.

SERVER-52730 will enforce that there can be at most one resharding operation active in the whole cluster. That restriction is why we can treat the ""global"" metrics as being for a single collection and single resharding operation.

I believe there's some prior art with lastCommittedTransaction for not tracking global measurements in serverStatus and FTDC.

Do you feel it would be more clear to split ""shardingStatistics.resharding"" into ""shardingStatistics.resharding"" and ""shardingStatistics.resharding.lastOp"" (or some similar name)?","Feb 08 2021 03:34:44 PM UTC;bruce.lucas;Normally we take the derivative of cumulative counters for display and report in units like ""document / s"", ""bytes / s"", etc. This allows to easily see if an operation is active and to correlate its performance with other metrics like cpu, disk, WT operations, etc. when doing performance analysis. When a cumulative counter like that is reset it results in an artificial large negative spike that is misleading and interferes with things like taking averages.

Understood about not having per-collection metrics (and that's good), but I don't see the connection between that and resetting the metrics. What are you interested in seeing that wouldn't be possible if the metrics aren't reset?

The lastCommittedTransaction metric isn't an example of what I was asking about as it's not a cumulative metric. We actually recently eliminated it from FTDC (SERVER-53609, for reasons described there but not relevant to this question) and were ok with that because ""last x"" type metrics generally have limited diagnostic value - they may get overwritten by the next event before they're even seen for an event of interest, and generally the last of some particular observable is not generally more interesting than all the previous ones.

I'd be reluctant to inflate FTDC with a ""cumulative"" and a ""last op""version of the same counters. If the most recent occurrence truly is of some special interest, the log file might be a better place to get that information. Logging this information on completion of a resharding operation would ensure that the information is available for all operations, including the most recent as of any particular time.","Feb 16 2021 11:05:59 PM UTC;lamont.nelson;Based on our conversation last week, I created SERVER-54483 to report process lifetime totals in the server status command. I'm modifying the description of this ticket to reset the count in the current op command.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Increment countWritesDuringCriticalSection,SERVER-53911,1595519,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-server-sharding,lamont.nelson,lamont.nelson,Jan 20 2021 04:56:55 PM UTC,Feb 16 2021 10:11:34 PM UTC,Feb 17 2021 11:15:15 AM UTC,,,,,,5.0 Required,,,,,0,PM-234-T-autocommits,,,,,Should increment the relevant statistic in ReshardingMetrics repository.,,,,,,,,,,,,SERVER-53258,,,,,,,,,,,,,,,,,,,,0.0,1.0,,,,,,,,,,,,,,,,Fully Compatible,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2332800,,,,,,,,PM-234,,,,,,,,,,,,,,,,,,,,true,max.hirschhorn(max.hirschhorn@10gen.com),2021-01-20 16:56:55.0,,,,,,,,,,,,,,backlog-server-sharding(backlog-server-sharding),lamont.nelson(lamont.nelson),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i7ejhz:",,,,,,,"0|i78bi7:",9223372036854775807,,,,,,,,,,,,Sharding 2021-03-22,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i7ehlj:",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Periodically obtain remainingOperationTimeEstimatedMillis estimates from recipients for use by the ReshardingCoordinator,SERVER-53920,1595550,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,amirsaman.memaripour,lamont.nelson,lamont.nelson,Jan 20 2021 05:36:51 PM UTC,Feb 16 2021 08:07:04 PM UTC,Feb 17 2021 11:15:15 AM UTC,,,,,,5.0 Required,,,,,0,PM-234-T-autocommits,,,,,"Add a remainingReshardingOperationTimeMillisThreshold server parameter to control when the coordinator should engage the critical section (default value of 2s)
Should contact each recipient to gather statistics.
Should continuously monitor while a ReshardingCoordinator service instance exists.
Should stop monitoring when the coordinator instance exits or we reach the critical section of the coordinator.
Should provide ability to determine if all recipients report they can finish within the remainingReshardingOperationTimeMillisThreshold.
Engage critical section once all recipients report they can finish within remainingOperationTimeMillisThreshold.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,1.0,,,,,,,,,,,,,,,,Fully Compatible,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2332800,,,,,,,,PM-234,,,,,,,,,,,,,,,,,,,,true,amirsaman.memaripour(amirsaman.memaripour),2021-01-20 17:36:51.0,,,,,,,,,,,,,,amirsaman.memaripour(amirsaman.memaripour),lamont.nelson(lamont.nelson),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i7ejov:",,,,,,,"0|i78bp3:",9223372036854775807,,,,,,,,,,,,Sharding 2021-03-22,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i7ehsf:",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Increment oplogEntriesFetched and oplogEntriesApplied in ReshardingOplogFetcher and ReshardingOplogApplier,SERVER-53910,1595502,New Feature,In Code Review,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,billy.donahue,lamont.nelson,lamont.nelson,Jan 20 2021 04:44:50 PM UTC,Feb 16 2021 07:57:01 PM UTC,Feb 17 2021 11:15:15 AM UTC,,,,,,5.0 Required,,,,,0,PM-234-T-autocommits,,,,,"Should increment the relevant statistic in ReshardingMetrics repository.

https://github.com/mongodb/mongo/blob/master/src/mongo/db/s/resharding/resharding_oplog_fetcher.h#L51

[src/mongo/db/s/resharding/resharding_oplog_fetcher.h:51|https://github.com/mongodb/mongo/blob/7ddbf0f51f09d436fd52a216cb5d606c3d2521bc/src/mongo/db/s/resharding/resharding_oplog_fetcher.h#L51]",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,1.0,1.0,,,,,,,,,,,,,,,,Fully Compatible,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2021-01-26 17:00:38.0,1814400,,,,,,,,PM-234,,,,,,,,,,,,,,,,,,,,true,billy.donahue(billy.donahue),Tue Jan 26 17:00:38 UTC 2021,,,,,,,,,,,,,,billy.donahue(billy.donahue),lamont.nelson(lamont.nelson),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i7eje7:",,,,,,,"0|i78bin:",9223372036854775807,,,,,,,,,,,,Sharding 2021-02-22,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i7ehhr:","Jan 26 2021 05:00:38 PM UTC;billy.donahue;Need to figure out a test for this, but here's the start of it.
https://mongodbcr.appspot.com/756330003/",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Add section on cancelation to the architecture guide,SERVER-50661,1458187,New Feature,In Code Review,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,george.wangensteen,matthew.saltz,matthew.saltz,Aug 31 2020 08:54:00 PM UTC,Feb 16 2021 07:56:46 PM UTC,Feb 17 2021 11:15:15 AM UTC,,,,,,5.0 Required,Internal Code,,,,0,,,,,,"This should include:
* How to write a service which handles cancelation using CancelationTokens
* How to use CancelationSources to cancel work
* How to create cancelation hierarchies
* How tokens integrate with futures",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2021-02-16 19:56:46.0,14601600,,,,,,,,PM-1423,,,,,,,,,,,,,,,,,,,,true,george.wangensteen(george.wangensteen),2020-08-31 20:54:00.0,,,,,,,,,,,,,,george.wangensteen(george.wangensteen),matthew.saltz(matthew.saltz),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i6r1f3:",,,,,,,"0|i6z09b:",9223372036854775807,,,,,,,,,,,,Service Arch 2021-02-22,,,,,,,,,3.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i6qzin:",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Enforce reshardingCriticalSectionTimeout parameter,SERVER-53923,1595563,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-server-sharding,lamont.nelson,lamont.nelson,Jan 20 2021 05:45:53 PM UTC,Feb 16 2021 04:56:39 PM UTC,Feb 17 2021 11:15:15 AM UTC,,,,,,5.0 Required,,,,,0,PM-234-T-autocommits,,,,,"- Add a server parameter for an upper limit on how long to wait to hear back from recipient shards reaching strict consistency after engaging the critical section. This is to bound the amount of write unavailability in case the estimated time remaining turns out to be inaccurate. Default value isn’t decided but should be around 5-10 seconds.
- Should abort the resharding operation if the timeout is reached before reaching strict consistency after engaging the critical section.",,,,,,,,SERVER-53258,,,,SERVER-53922,,,,,,,,,,,,,,,,,,,,0.0,1.0,,,,,,,,,,,,,,,,Fully Compatible,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2332800,<a href='https://jira.mongodb.org/browse/SERVER-53258'>SERVER-53258</a>,,,,,,,PM-234,,,,,,,,,,,,,,,,,,,,true,lamont.nelson(lamont.nelson),2021-01-20 17:45:53.0,,,,,,,,,,,,,,backlog-server-sharding(backlog-server-sharding),lamont.nelson(lamont.nelson),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i7ejrr:",,,,,,,"0|i78brr:",9223372036854775807,,,,,,,,,,,,Sharding 2021-03-08,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i7ehvb:",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Download debug symbols in resmoke hang analyzer,SERVER-54086,1602677,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,siran.wang,robert.guo,robert.guo,Jan 27 2021 10:10:24 PM UTC,Feb 16 2021 04:35:09 PM UTC,Feb 17 2021 11:15:15 AM UTC,,,,,,Backlog,Testing Infrastructure,,,,0,tig-hanganalyzer,,,,,"Currently we spend about 6 min wall clock time in every Evergreen build waiting for debug symbols to be archived and blocking execution of all JS tasks.

The archives are only used if the task fails, which is relatively rare. We should therefore conditionally wait for debug symbols only when a resmoke task fails or times out.

Impl sketch:
 # Update multiversion setup to support downloading from patch builds
 ## When resmoke tries to run the hang analyzer, it should first check if the debug symbols are available and if not, retry downloading the debug symbols for up to 15 minutes since resmoke is first started. This only needs to be done if resmoke is running in Evergreen and it detects running mongod, mongos, or mongo processes. Some tests are run through resmoke but don't depend on compile or debug symbols.
 ## The resmoke start time needs to be persisted to disk like what Genny does since the hang analyzer is called on a separate resmoke instance.",,,,,,,,,,,,SERVER-54297,,,,,,,,,,,,,,,,,,,,1.0,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2021-02-16 16:30:41.0,67474,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,brooke.miller(brooke.miller),Tue Feb 16 16:30:41 UTC 2021,,,,,,,,,,,,,,brooke.miller(brooke.miller),robert.guo(robert.guo),siran.wang(JIRAUSER1258629),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i7frmf:",,,,,,,"0|i79i1z:",9223372036854775807,,,,,,,,,,,,STM 2021-03-08,,,,,,,,,3.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i7fppz:","Feb 16 2021 04:30:41 PM UTC;brooke.miller;The original first task included (move the [{{dist-test-debug}} target|https://github.com/mongodb/mongo/blob/1f4b281907b264bd9d40a6ad6d3b6b9ae785cd90/etc/evergreen.yml#L3412] to a separate task that's part of the [{{compile_TG}}|https://github.com/mongodb/mongo/blob/1f4b281907b264bd9d40a6ad6d3b6b9ae785cd90/etc/evergreen.yml#L8417] but done after {{compile}}. The JS tasks [depend on compile|https://github.com/mongodb/mongo/blob/1f4b281907b264bd9d40a6ad6d3b6b9ae785cd90/etc/evergreen.yml#L50] only, not remaining tasks) was completed by Drew in SERVER-54297.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Convert find and aggregate commands' output to IDL,SERVER-51622,1515163,New Feature,In Code Review,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,arun.banala,arun.banala,arun.banala,Oct 15 2020 09:57:20 AM UTC,Feb 16 2021 02:01:21 PM UTC,Feb 17 2021 11:15:15 AM UTC,,,,,,Backlog,,,,,0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,3.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,10800000,,,,,,,,PM-1846,,,,,,,,,,,,,,,,,,,,true,jesse(jesse),2020-10-15 09:57:20.0,,,,,,,,,,,,,,arun.banala(arun.banala),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i70scv:",,,,,,,"0|i00shr:",9223372036854775807,,,,,,,,,,,,Query 2021-01-11,Query 2021-01-25,Query Execution 2021-02-22,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i70qgf:",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
MongoDB Enterprise dependencies meta-package,SERVER-18975,210665,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-server-build,andrew.davidson,andrew.davidson,Jun 15 2015 04:00:29 PM UTC,Feb 14 2021 03:34:30 AM UTC,Feb 17 2021 11:15:15 AM UTC,,,,,,Needs Further Definition,Packaging,,,,0,build-planning,,,,,"It should be possible to ensure platform-appropriate Enterprise dependencies are installed without requiring installation of the MongoDB Enterprise software.

An Enterprise dependencies meta-package will make it easier to utilize the Enterprise build tar.gz installation files to store and run MongoDB binaries in a flexible manner.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2015-06-15 19:37:21.0,179107200,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,ian.whalen(ian@10gen.com),2015-06-15 16:00:29.0,,,,,,,,,,,,,,andrew.davidson(andrew.davidson@10gen.com),backlog-server-build(backlog-server-build),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i02sdj:",,,,,,,"0|i00nmu:zzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzi",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i02siv:",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Add ability to mock Streamable RSM topology description state,SERVER-54290,1612205,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,renctan,lamont.nelson,lamont.nelson,Feb 04 2021 03:43:53 PM UTC,Feb 12 2021 04:05:27 PM UTC,Feb 17 2021 11:15:15 AM UTC,,,,,,5.0 Required,,,,,0,sharding-remove-scanning-rsm,sharding-wfbf-day,,,,"In order to support running in unit tests we need the ability to 1) manually install a topology description into the rsm, and 2) enable a 'test mode' where the rsm does not try to schedule new monitoring code from the ping monitor or server discovery monitor.

",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,1.0,1.0,,,,,,,,,,,,,,,,Fully Compatible,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,1036800,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,ratika.gandhi(ratika.gandhi),Thu Feb 04 15:50:24 UTC 2021,,,,,,,,,,,,,,lamont.nelson(lamont.nelson),renctan(renctan),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i7he9b:",,,,,,,"0|i790fb:",9223372036854775807,,,,,,,,,,,,Sharding 2021-02-22,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i7hccv:","Feb 04 2021 03:50:24 PM UTC;lamont.nelson;This class will allow creating server descriptions: https://github.com/mongodb/mongo/blob/master/src/mongo/client/sdam/server_description_builder.h#L40 for the mocked topology description. We should consider adding a higher level interface to create a usable topology description with a few lines of code.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Specify a microarchitecture minimum for x86_64 builds,SERVER-54407,1616651,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-server-devplatform,acm,acm,Feb 08 2021 08:22:41 PM UTC,Feb 12 2021 02:17:32 PM UTC,Feb 17 2021 11:15:15 AM UTC,,,,,,5.0 Required,Build,,,,0,,,,,,"For all other architectures than x86_64, we have a known microarchitecture minimum. We should select one for x86_64 and set it at build time.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,1.0,,,,,,,,,,,,,,,,Major Change,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,691200,,,,"After this change MongoDB will only run on Intel systems offering a Sandybridge (https://en.wikipedia.org/wiki/List_of_Intel_CPU_microarchitectures) or newer microarchitecture. Attempting to start server binaries on systems not offering that level of hardware support will result in an immediate hard operating-system level crash (e.g. no MongoDB diagnostic will be provided).

Note that we have similar minima already in place for power, s390x, and ARM systems, so this is just bringing x86_64 up to par.
",Needed,,,PM-1328,,,,,,,,,,,,,,,,,,,,true,backlog-server-pm(backlog-server-pm),2021-02-08 20:22:41.0,,,,,,,,,,,,,,acm(acm),backlog-server-devplatform(backlog-server-devplatform),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i7i5lj:",,,,,,,"0|i7amlj:",9223372036854775807,,,,,,,,,,,,Dev Platform 2021-03-08,,,,,,,,,,,,,,,Cloud,Docs,Triage and Release,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i7i3p3:",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
resharding metrics for serverStatus should report cumulative totals for the process,SERVER-54483,1621995,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-server-sharding,lamont.nelson,lamont.nelson,Feb 12 2021 01:40:13 AM UTC,Feb 12 2021 01:41:50 AM UTC,Feb 17 2021 11:15:15 AM UTC,,,,,,5.0 Required,,,,,0,PM-234-T-autocommits,,,,,We want serverStatus to report information for all resharding operations run over the lifetime of the server process.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,Fully Compatible,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,432000,,,,,,,,PM-234,,,,,,,,,,,,,,,,,,,,true,lamont.nelson(lamont.nelson),2021-02-12 01:40:13.0,,,,,,,,,,,,,,backlog-server-sharding(backlog-server-sharding),lamont.nelson(lamont.nelson),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i7j2kv:",,,,,,,"0|i7colj:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i7j0of:",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Enable mongodb deployment through windows command line package manager ,SERVER-17143,181873,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-server-build,eitan.klein,eitan.klein,Feb 01 2015 03:54:53 AM UTC,Feb 12 2021 12:07:12 AM UTC,Feb 17 2021 11:15:15 AM UTC,,3.0.0-rc7,,,,Backlog,Packaging,,,,0,build-later,,,,,"Windows 10 introduce command line package manager (similar to Linux),

I think we would like to enable mongodb deployment through this channel.

See more details:
http://blogs.technet.com/b/windowsserver/archive/2014/04/03/windows-management-framework-v5-preview.aspx
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,190771200,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,ian.whalen(ian@10gen.com),2015-02-01 03:54:53.0,,,,,,,,,,,,,,backlog-server-build(backlog-server-build),eitan.klein(eitan.klein),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i032dr:",,,,,,,"0|i00nmu:zzzzzzzzzzzzzzzzzz",159797,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i0ujun:",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
background consistency checking (patrol reads),SERVER-10997,92364,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-server-execution,duraid.madina@10gen.com,duraid.madina@10gen.com,Oct 02 2013 06:26:41 AM UTC,Feb 11 2021 11:44:22 PM UTC,Feb 17 2021 11:15:15 AM UTC,,,,,,Backlog,Storage,,,,4,,,,,,"We could detect bit rot/flakey hardware by running background consistency checks of documents and indexes across replica sets.
",,,,,,,,,,,,CS-9589,SUPPORT-663,CS-8383,CS-8608,CS-8490,CS-8088,CS-7713,CS-8275,CS-7898,CS-8090,CS-8260,CS-8134,CS-7999,CS-7534,CS-9416,SUPPORT-681,SUPPORT-736,,,,0.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2016-11-01 13:58:43.0,232848000,,,,,,,,PM-855,,,,,,,,,,,,,,,,,,,,true,ian.whalen(ian@10gen.com),2013-10-02 06:26:41.0,,,,,,,,No,,,,,,backlog-server-execution(backlog-server-execution),duraid.madina@10gen.com(duraid.madina@10gen.com),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i0436f:",,,,,,,"0|i00cgv:",5032,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i17fdr:",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Provide a way to disable compile bypass from the command line or config files,SERVER-50087,1425950,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,david.bradford,acm,acm,Aug 01 2020 02:50:46 PM UTC,Feb 11 2021 10:10:31 PM UTC,Feb 17 2021 11:15:15 AM UTC,,,,,,Backlog,,,,,0,,,,,,"I never want the compile bypass feature to kick in on my patch builds. About every second or third patch build I do, I get erroneous results because of it. I end up needing to make synthetic commits to place comments in files that I know will disable it to work around, and then I need to remember to revert those changes before I send my work to the commit queue.

I'd like evergreen to provide a way that I can, using an option to the {{evergreen}} command line tool, or better a configuration file setting, ensure that compile bypass is never applied to my patches.
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2020-08-10 14:26:16.0,17193600,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,david.bradford(david.bradford),2020-08-01 14:50:46.0,,,,,,,,,,,,,,acm(acm),david.bradford(david.bradford),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i6liiv:",,,,,,,"0|i013wn:",9223372036854775807,,,,,,,,,,,,DAG 2021-05-17,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i6lgmf:",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Provide network metrics for egress connections,SERVER-51832,1524347,New Feature,Needs Scheduling,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-server-servicearch,amirsaman.memaripour,amirsaman.memaripour,Oct 23 2020 10:07:39 PM UTC,Feb 11 2021 10:02:29 PM UTC,Feb 17 2021 11:15:15 AM UTC,,,,,,,Diagnostics,,,,0,sa-groomed,,,,,"The metrics under {{serverStatus.network}} only account for the network traffic of ingress connections (see SERVER-6227). Extending the metrics to also include egress connections, those established by a mongo process, would help diagnostics and monitoring. This ticket requires the following:
 * Defining new metrics (e.g., {{egress.physicalBytesOut}} and {{egress.physicalBytesIn}}) for egress traffic.
 * Separating egress and ingress metrics in serverStatus.
 * Creating a ticket to update the documentation for network metrics in serverStatus.",,,,,,,,,,,,SERVER-6227,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,5002K00000ms5pdQAA,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,10022400,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,ratika.gandhi(ratika.gandhi),2020-10-23 22:07:39.0,,,,,,,,,,,,,,amirsaman.memaripour(amirsaman.memaripour),backlog-server-servicearch(backlog-server-servicearch),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i72cu7:",,,,,,,"0|i6wogf:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i72axr:",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Create a Futures-compatible Stream/Channel abstraction,SERVER-51765,1519737,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-server-servicearch,matthew.saltz,matthew.saltz,Oct 20 2020 03:34:25 PM UTC,Feb 11 2021 10:00:49 PM UTC,Feb 17 2021 11:15:15 AM UTC,,,,,,Backlog,Internal Code,,,,0,servicearch-wfbf-day,,,,,"This ticket is to implement a producer-consumer queue with asynchronous blocking on an empty queue.

Fairly often, we have found cases in sharding where it would be helpful to have a blocking producer-consumer queue, but need it to be used in a context where it's not acceptable to block a thread. This creates the need for ungainly workarounds. We should come up with an abstraction (probably based on futures) that handles this.

Example idea (rough sketch):
{code:cpp}template <typename T>
class Stream {
public:
    // Pulls message from stream. Alternate name pop/receive
    ExecutorFuture<T> getNext();
    // Alternate names push/send
    void emplace(T t);
   // Shuts down the stream, interrupts waiter with an error code on the future
    void close();
};

// Usage
Stream<Message> stream(executor);

// Consumer:
AsyncTry([stream]{
        return stream.getNext().then([] (Message m) {
            // Handle message
        });
    }).until([](Status s) { 
        return s == ErrorCodes::StreamClosed /* or some existing error code */ 
    }).on(executor);

// Producer:
stream.emplace(Message{});
{code}
Things to consider:
 * Should it support more than one consumer? I think single producer, single consumer is probably fine for most cases.
 * Should we support a max size for streams, in which case emplacing a message could block as well?
 * Is futures really the best way to do this? It looks cute, but it might make more sense to just set a single callback on the stream that gets called whenever something is added.
 * Are there cases where we want to just call a callback every time something is added to the stream, rather than executing them sequentially?

I think whether we call this a stream or a channel depends on the above considerations.

*Acceptance Criteria:* 

Design a class for Create a Futures-compatible Stream/Channel abstraction by answering the questions above. ",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,10281600,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,ratika.gandhi(ratika.gandhi),2020-10-20 15:34:25.0,,,,,,,,,,,,,,backlog-server-servicearch(backlog-server-servicearch),matthew.saltz(matthew.saltz),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i71kef:",,,,,,,"0|i05n4v:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,5.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i71ihz:",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Integrate CancelationTokens with Future types,SERVER-53587,1581404,New Feature,In Code Review,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,matthew.saltz,matthew.saltz,matthew.saltz,Jan 05 2021 06:42:01 PM UTC,Feb 11 2021 08:30:24 PM UTC,Feb 17 2021 11:15:15 AM UTC,,,,,,5.0 Required,Internal Code,,,,0,,,,,,"This ticket is to do the following functionality:
 * Add ability to do asynchronous, interruptible waits on a future using
 CancelationTokens
 * Add ability to do synchronous, interruptible waits on a future using
 CancelationTokens
 * Add ability to cancel a future chain using CancelationTokens

Depending on SERVER-50659, we may break this into several tickets",,,,,,,,SERVER-50659,,,,,,,,,,,,,,,,,,,,,,,,1.0,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,1209600,<s><a href='https://jira.mongodb.org/browse/SERVER-50659'>SERVER-50659</a></s>,,,,,,,PM-1423,,,,,,,,,,,,,,,,,,,,true,matthew.saltz(matthew.saltz),Tue Feb 02 21:55:57 UTC 2021,,,,,,,,,,,,,,matthew.saltz(matthew.saltz),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i7c4en:",,,,,,,"0|i6z0an:",9223372036854775807,,,,,,,,,,,,Service Arch 2021-02-22,,,,,,,,,4.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i7c2i7:","Feb 02 2021 09:55:57 PM UTC;matthew.saltz;This ticket will encompass creating a single free function withCancelation(FutureT, CancelationToken). See SERVER-50659 for more details and usage. As such I'm decreasing the story points.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
SortedDataInterface to support creating indexes where the RecordId is a binary string,SERVER-53990,1598051,New Feature,In Code Review,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,louis.williams,gregory.wlodarek,gregory.wlodarek,Jan 22 2021 09:01:43 PM UTC,Feb 11 2021 07:39:36 PM UTC,Feb 17 2021 11:15:15 AM UTC,,,,,,5.0 Required,Indexing,Storage,,,0,,,,,,"Index tables have an index key -> RecordId (int64_t) layout today. They will need to support the index key -> RecordId (ObjectId) layout so that time-series collections can create secondary indexes.

Determine the type via the durable catalog metadata. ",,,,,,,,SERVER-53984,SERVER-53986,SERVER-53989,,,,,,,,,,,,,,,,,,,,,,0.0,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2021-02-03 23:02:37.0,2160000,"<s><a href='https://jira.mongodb.org/browse/SERVER-53984'>SERVER-53984</a></s>, <s><a href='https://jira.mongodb.org/browse/SERVER-53986'>SERVER-53986</a></s>, <s><a href='https://jira.mongodb.org/browse/SERVER-53989'>SERVER-53989</a></s>",,,,,,,PM-288,,,,,,,,,,,,,,,,,,,,true,louis.williams(louis.williams),2021-01-22 21:01:43.0,8.0,,,,,,,,,,,,,gregory.wlodarek(gregory.wlodarek),louis.williams(louis.williams),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i7ez47:",,,,,,,"0|i78q9b:",9223372036854775807,,,,,,,,,,,,Execution Team 2021-02-08,Execution Team 2021-02-22,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i7ex7r:",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Working set estimation WT,SERVER-21448,239243,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,brian.lane,alex.komyagin,alex.komyagin,Nov 13 2015 03:33:39 PM UTC,Feb 11 2021 03:13:12 AM UTC,Feb 17 2021 11:15:15 AM UTC,,,,,,Backlog,WiredTiger,,,,0,,,,,,"WT has its own cache, and we can put some clever accounting to compute a meaningful working set estimation. Such accounting can be expensive but it doesn't need to be performed all the time, so this feature can be turned on/off with a switch.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2015-11-13 23:52:26.0,166060800,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,brian.lane(brian.lane),2015-11-13 15:33:39.0,,,,,,,,,,,,,,alex.komyagin(alex.komyagin@10gen.com),brian.lane(brian.lane),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i02e1r:",,,,,,,"0|i01ikn:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i0xlov:",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Generalize CollectionScan node so it can perform bounded scans over time series bucket collections,SERVER-54008,1599102,New Feature,In Progress,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,louis.williams,gregory.wlodarek,gregory.wlodarek,Jan 25 2021 05:20:42 AM UTC,Feb 10 2021 09:05:27 PM UTC,Feb 17 2021 11:15:16 AM UTC,,,,,,5.0 Required,Indexing,Querying,,,0,,,,,,Modify the query system to perform bounded collection scans over _id ranges given a start and end key. Allow the CollectionScan stage to perform bounded collection scans over {{_id}} ranges given a start and end key. This will allow {{$gt(e)}} and {{$lt(e)}} range queries by {{_id}} to go directly to the record store. An additional option to delete records in these ranges is necessary for TTL deletions.,,,,,,,,SERVER-53989,,,,SERVER-54409,,,,,,,,,,,,,,,,,,,,0.0,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,1987200,<s><a href='https://jira.mongodb.org/browse/SERVER-53989'>SERVER-53989</a></s>,,,,,,,PM-288,,,,,,,,,,,,,,,,,,,,true,louis.williams(louis.williams),2021-01-25 05:20:42.0,,,,,,,,,,,,,,gregory.wlodarek(gregory.wlodarek),louis.williams(louis.williams),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i7f5lj:",,,,,,,"0|i78wv3:",9223372036854775807,,,,,,,,,,,,Execution Team 2021-02-22,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i7f3p3:",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Allow to use $not like $or,SERVER-1454,12498,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-query-optimization,lanwin,lanwin,Jul 21 2010 07:56:47 AM UTC,Feb 10 2021 09:03:11 PM UTC,Feb 17 2021 11:15:16 AM UTC,,,,,,Backlog,Querying,,,,15,,,,,,"In our MongoDB-CSharp driver we convert code expressions like that to documents queries.

{code}
!(Address.IsDefault && Adress.Name==""foo"")
{code}

The problem here is that the ! operator reverses the meaning of both equality checks. This scenario would be much easier to accomplish when we could use the $not operator like the $or operator. 

Example:

{code}
{ $not : [ 
    { ""Address.IsDefault"" : true },
    { ""Address.Name"" : ""foo"" }
] }
{code}

I think also that this is more the way the users expect to use the $not operator.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,8.0,,,,,,,,,,,,,,,,,,,,,5002K00000scPPFQA2,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2010-07-21 12:11:27.0,604800,,,,,,,,PM-2151,,,,,,,,,,,,,,,,,,,,true,,Tue Feb 09 22:00:46 UTC 2021,,,,,,,,No,,,,,,asya(asya),backlog-query-optimization(JIRAUSER1257108),charlie.swanson(charlie.swanson),eliot(eliot),meugen(meugen),nehresma(nehresma),rstam(rstam),lanwin(lanwin),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i078h3:",,,,,,,"0|i00tvr:",6239,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i1iubb:","Jul 21 2010 10:35:59 AM UTC;lanwin;I would really like to know if you consider adding this or not soon.","Jul 21 2010 12:11:27 PM UTC;eliot;When we prioritize this will depend on # of votes primarily. ","Dec 30 2010 03:34:45 PM UTC;nehresma;I have a situation where expanded $not support would be very useful.  We have a query builder to let the user build complex expressions that are then translated into a MongoDB query and executed.","Apr 07 2015 02:14:28 PM UTC;rstam;I think $not should take a single argument, otherwise it can be rather ambiguous what it means (does De Morgan's Law apply or not?).

The example in the description could be represented unambiguously as:

{code}
{ $not : 
    { $and : [
        { ""Address.IsDefault"" : true },
        { ""Address.Name"" : ""foo"" }
    ] } 
}
{code}
","Dec 17 2015 06:32:35 AM UTC;meugen;it will be a very good feature!
For example: i take conditions from admins, in wich case they dont see documents. And witout this feature i create in aggreagte.project() FOR ALL DOCUMENTS computed fields with false to prohibited fields and THEN match all documents for computed field == true. 
It works very slowly!   (

PS in my example i need to ADD ALL FIELDS in project! Automotically it imposible and i use ""fields: ""$$ROOT"""", then i need to exclude this new level (named ""fields"").... This is unnormal way! (","Dec 17 2015 06:53:14 AM UTC;meugen;To Robert Stam: 
Yes. Transformation should support the law of de Morgan . Which is not ambiguous because it law )

For MongoDB-developers, I think, the ambiguity or complexity would not be at all. Since they will only take those objects that do not fall under a set of conditions shown in $ not: {}.","Apr 15 2016 08:32:38 PM UTC;asya;Equivalent of top level $not that already works now would be \{$nor: [ \{ original-query \} ] \}
","Feb 09 2021 10:00:46 PM UTC;charlie.swanson;I'm nominating this as quick win because I have no reason to suspect it's all that hard and it would simplify some of the language building efforts on the drivers side.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Enforce minimumReshardingDuration,SERVER-53918,1595542,New Feature,In Code Review,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,amirsaman.memaripour,lamont.nelson,lamont.nelson,Jan 20 2021 05:24:25 PM UTC,Feb 10 2021 07:06:46 PM UTC,Feb 17 2021 11:15:16 AM UTC,,,,,,5.0 Required,,,,,0,PM-234-T-autocommits,,,,,"Add server parameter minimumReshardingDurationMillis to control the minimum duration of resharding operations.
Should allow transactions and retryable writes started after the current resharding operation to complete within the period defined by minimumReshardingDurationMillis.",,,,,,,,,,,,SERVER-53917,SERVER-54452,,,,,,,,,,,,,,,,,,,0.0,2.0,,,,,,,,,,,,,,,,Fully Compatible,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2021-02-10 02:14:12.0,2332800,,,,,,,,PM-234,,,,,,,,,,,,,,,,,,,,true,lamont.nelson(lamont.nelson),2021-01-20 17:24:25.0,,,,,,,,,,,,,,amirsaman.memaripour(amirsaman.memaripour),lamont.nelson(lamont.nelson),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i7ejn3:",,,,,,,"0|i78bnr:",9223372036854775807,,,,,,,,,,,,Sharding 2021-01-25,Sharding 2021-02-22,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i7ehqn:",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
libdeps graph linter: Unnecessary LIBDEPS Edges,SERVER-52581,1531950,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,daniel.moody,daniel.moody,daniel.moody,Nov 03 2020 03:20:34 AM UTC,Feb 10 2021 06:11:59 PM UTC,Feb 17 2021 11:15:16 AM UTC,,,,,,5.0 Desired,,,,,0,,,,,,"from the document:
{quote}Declaring a library dependency that you don’t actually need currently has no visible consequences. Somewhat obviously, the tree still links.

 

Unnecessary private edges are almost entirely harmless, except perhap for some tiny overhead of including the symbols exported from the library among the candidate symbols during linking. 

 

However, unnecessary public library edges are actively harmful. If library A declares a public library dependency on B when it doesn’t need to, then every library that picks up, directly or transitively, a dependency on A will also pick up a dependency on B and all of B’s transitively exported dependencies. Suddenly everything that uses A can get away without declaring proper dependencies for things from B and its transitive includes.

 

Unfortunately, resolving these sorts of errors is extremely difficult. In theory it looks like it would be straightforward: if A does not make direct use of any symbols from B, and if the interface to A does not induce a dependency on B to users of A, then B is an unnecessary dependency in A. This simple rule breaks down entirely, however, in the presence of static initializers: even though B may not satisfy any symbolic references in A (or A’s users), it may be necessary for B to be present in the image anytime A is present so that B’s initializers can configure state that A depends on.

 

Without a mechanism to identify and validate the initializer dependency graph threaded through the library dependency graph, it is impossible to ever safely remove an edge from the graph. After removing such an edge, the graph may link, and the process may start up (especially if the initializer is a C++ initializer and not a MONGO_INITIALIZER, but then fail at runtime since an entire but rarely used subsystem (ldap?) is no longer properly configured.

 

We currently have no technology that allows us to identify and validate the correctness of the link graph with respect to initializers. Further discussion on this topic will be deferred to the end of this section.

 

Due to the technical complexity of this problem, it seems advisable to address it near to the end of the project, if a resolution to the initializer problem is identified. Without a solution, this result is disappointing, as it means we cannot reduce the total number of direct edges declared in the graph.
{quote}",,,,,,,,SERVER-52578,,,,,,,,,,,,,,,,,,,,,,,,0.0,3.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,9158400,<a href='https://jira.mongodb.org/browse/SERVER-52578'>SERVER-52578</a>,,,,,,,PM-1112,,,,,,,,,,,,,,,,,,,,true,april.schoffer(april.schoffer),2020-11-03 03:20:34.0,,,,,,,,,,,,,,daniel.moody(JIRAUSER1253549),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i73nq7:",,,,,,,"0|i007h3:",9223372036854775807,,,,,,,,,,,,Dev Platform 2021-01-25,Dev Platform 2021-02-08,Dev Platform 2021-02-22,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i73ltr:",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Integrate CancelationTokens with ExecutorFutures,SERVER-53326,1565512,New Feature,In Code Review,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,george.wangensteen,matthew.saltz,matthew.saltz,Dec 10 2020 06:37:04 PM UTC,Feb 10 2021 05:53:58 PM UTC,Feb 17 2021 11:15:16 AM UTC,,,,,,,Internal Code,,,,0,,,,,,"The current thought is to add a parameter to the ExecutorFuture constructor and to .thenRunOn taking a CancelationToken, and refuse to schedule new continuations once the token is canceled, similar to executor shutdown. We could also consider making OutOfLineExecutor support cancelation so that we could cancel already scheduled tasks, but that isn't strictly necessary and would be more work.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2021-02-10 17:53:58.0,5875200,,,,,,,,PM-1423,,,,,,,,,,,,,,,,,,,,true,george.wangensteen(george.wangensteen),2020-12-10 18:37:04.0,,,,,,,,,,,,,,george.wangensteen(george.wangensteen),matthew.saltz(matthew.saltz),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i79eef:",,,,,,,"0|i6z09j:",9223372036854775807,,,,,,,,,,,,Service Arch 2021-02-22,,,,,,,,,4.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i79chz:",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Create a new macro for suppressing TSAN errors,SERVER-51053,1480258,New Feature,Backlog,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-server-devplatform,gregory.wlodarek,gregory.wlodarek,Sep 18 2020 05:54:40 PM UTC,Feb 10 2021 05:29:32 PM UTC,Feb 17 2021 11:15:16 AM UTC,,,,,,,Usability,,,,0,,,,,,"To suppress the TSAN sanitizer today is quite wordy:
{code:java}#if defined(__has_feature)
#if __has_feature(thread_sanitizer)
    __attribute__((no_sanitize(""thread"")))
#endif
#endif
{code}
Instead, if we had a macro, such as *MONGO_NO_TSAN* it would make this easier for future uses.",,,,,,,,,,,,SERVER-50924,SERVER-49956,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,13046400,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,april.schoffer(april.schoffer),2020-09-18 17:54:40.0,,,,,,,,,,,,,,backlog-server-devplatform(backlog-server-devplatform),gregory.wlodarek(gregory.wlodarek),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i6ut1z:",,,,,,,"0|i3f1cf:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i6ur5j:",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
connect libdep visualization service to graph collection service,SERVER-52577,1531790,New Feature,Backlog,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-server-devplatform,daniel.moody,daniel.moody,Nov 02 2020 09:53:00 PM UTC,Feb 10 2021 05:29:30 PM UTC,Feb 17 2021 11:15:16 AM UTC,,,,,,,,,,,0,,,,,,"After the libdeps visualization service has been created for local files, implement the ability to connect to a specific collection service UI.

 

This ticket should also implement some basic UI to be able to select a specific commit to view and re-render the graph from the commit from the graph collection service.",,,,,,,,SERVER-52573,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,9158400,<a href='https://jira.mongodb.org/browse/SERVER-52573'>SERVER-52573</a>,,,,,,,PM-1112,,,,,,,,,,,,,,,,,,,,true,april.schoffer(april.schoffer),2020-11-02 21:53:00.0,,,,,,,,,,,,,,backlog-server-devplatform(backlog-server-devplatform),daniel.moody(JIRAUSER1253549),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i73mqn:",,,,,,,"0|i01n2f:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i73ku7:",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Add support for producing .deb's from component/role matrix,SERVER-41662,799172,New Feature,Backlog,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-server-devplatform,acm,acm,Jun 12 2019 06:30:43 PM UTC,Feb 10 2021 05:29:26 PM UTC,Feb 17 2021 11:15:16 AM UTC,,,,,,,Build,,,,0,,,,,,Each non-empty component/role combination should produce meaningful .deb packages.,,,,,,,,SERVER-9668,,,,,,,,,,,,,,,,,,,,,,,,1.0,1.0,,,,,,,,,,,,,,,,Fully Compatible,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2019-10-04 17:17:42.0,43286400,<s><a href='https://jira.mongodb.org/browse/SERVER-9668'>SERVER-9668</a></s>,,,,,,,PM-1614,,,,,,,,,,,,,,,,,,,,true,april.schoffer(april.schoffer),Fri Oct 04 17:17:42 UTC 2019,,,,,,,,,,,,,,acm(acm),backlog-server-devplatform(backlog-server-devplatform),mathew.robinson(mathew.robinson),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i3nlpb:",,,,,,,"0|i02flj:",9223372036854775807,,,,,,,,,,,,Dev Tools 2019-07-01,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i3njt3:","Oct 04 2019 05:17:42 PM UTC;mathew.robinson;Moving out of Hygienic Builds to the Generative Packaging epic",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Add git tool to scons,SERVER-18367,202739,New Feature,Backlog,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-server-devplatform,jonathan.reams,jonathan.reams,May 07 2015 03:52:36 PM UTC,Feb 10 2021 05:29:21 PM UTC,Feb 17 2021 11:15:16 AM UTC,,,,,,,Build,,,,0,,,,,,Right now scons calls out to the utils module to get information about git. We should replace that with a scons tool.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,182476800,,,,,,,,PM-345,,,,,,,,,,,,,,,,,,,,true,april.schoffer(april.schoffer),2015-05-07 15:52:36.0,,,,,,,,,,,,,,backlog-server-devplatform(backlog-server-devplatform),jonathan.reams(jonathan.reams@10gen.com),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i02vqv:",,,,,,,"0|i05miv:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i0y76n:",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Evaluate feasibility of enabling -fno-semantic-interposition,SERVER-49323,1402771,New Feature,Backlog,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-server-devplatform,acm,acm,Jul 07 2020 01:08:44 PM UTC,Feb 10 2021 05:29:19 PM UTC,Feb 17 2021 11:15:16 AM UTC,,,,,,,Build,,,,0,,,,,,"The {{-fno-semantic-interposition}} flag significantly improves startup time for dynamically linked binaries by disabling support for symbol interposition (e.g. {{LD_PRELOAD}}. We should evaluate whether we think the loss of {{LD_PRELOAD}} functionality is justified by the performance gains. If we decide against doing so, we should consider building with {{-fsemantic-interposition}}, since clang defaults to {{-fno-semantic-interposition}} despite it generating binaries that are technically not in alignment with the ELF standard.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,Fully Compatible,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,19353600,,,,,,,,PM-1328,,,,,,,,,,,,,,,,,,,,true,april.schoffer(april.schoffer),2020-07-07 13:08:44.0,,,,,,,,,,,,,,acm(acm),backlog-server-devplatform(backlog-server-devplatform),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i6hjtb:",,,,,,,"0|i02fgn:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i6hhwv:",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Consider adding lzma to third party,SERVER-51675,1515956,New Feature,Backlog,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-server-devplatform,daniel.moody,daniel.moody,Oct 15 2020 07:00:45 PM UTC,Feb 10 2021 05:29:10 PM UTC,Feb 17 2021 11:15:16 AM UTC,,,,,,,,,,,0,,,,,,"Currently libunwind will only use system installed lzma.

We may want to include building lzma in third party, as this will possibly allow us to standardize a version for which we test against, and remove a required dependency that is needed to be install by a given platform's package manager or similar.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2021-01-05 16:18:54.0,3628800,,,,,,,,PM-1690,,,,,,,,,,,,,,,,,,,,true,april.schoffer(april.schoffer),Tue Jan 05 16:18:54 UTC 2021,,,,,,,,,,,,,,acm(acm),backlog-server-devplatform(backlog-server-devplatform),daniel.moody(JIRAUSER1253549),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i70x93:",,,,,,,"0|i02pu7:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i70vcn:","Jan 05 2021 04:18:54 PM UTC;acm;I can't really entirely justify my unease since this request models existing practice, but this idea makes me uneasy. I think, in general, we should attempt to vendor as few libraries as possible. Good reasons for vendoring include that we cannot deliver required functionality across all platforms without vendoring (think boost), or that persisted data has a hard dependency on a specific version (think icu), or that we require local modifications to make the package work for us (several). The compression libraries don't generally fall into any of these categories. In many cases I think we would be better off using the system version, as long as it was of a sufficient API/ABI rev to meet our programmatic needs. Any package we vendor becomes another for which we need to track and perform updates, backport those, deal with CVEs, etc. I wonder if the right way to go here is to actually go the other way and start making more use of system packages. Should we instead use the system {{libunwind}} if found to be a sufficient version, and which is probably configured correctly to use lzma if it is available on the system? The point about additional dependencies is true, but mitigated for all cases where users install via a package management system. Hopefully that is an increasingly large subset of our users.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Enable dynamic linking build for Windows,SERVER-27509,340712,New Feature,Backlog,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-server-devplatform,acm,acm,Dec 22 2016 09:05:56 PM UTC,Feb 10 2021 05:29:10 PM UTC,Feb 17 2021 11:15:16 AM UTC,,,,,,,Build,,,,0,,,,,,"After all library types and symbols have been annotated per SERVER-27508, it would be possible to add a dynamic linking build for Windows. Our current dynamic linking builds run twice as fast as the static builds. Achieving the same gains for Windows development would be extremely beneficial.",,,,,,,,SERVER-27508,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,Fully Compatible,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,131068800,<a href='https://jira.mongodb.org/browse/SERVER-27508'>SERVER-27508</a>,,,,,,,PM-1922,,,,,,,,,,,,,,,,,,,,true,april.schoffer(april.schoffer),2016-12-22 21:05:56.0,,,,,,,,,,,,,,acm(acm),backlog-server-devplatform(backlog-server-devplatform),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i1hxq7:",,,,,,,"0|i03nnz:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i0mq1b:",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
libdeps graph linter: Initializer Linting,SERVER-52584,1531954,New Feature,Backlog,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-server-devplatform,daniel.moody,daniel.moody,Nov 03 2020 03:31:48 AM UTC,Feb 10 2021 05:29:03 PM UTC,Feb 17 2021 11:15:16 AM UTC,,,,,,,,,,,0,,,,,,"from the document:
{quote}While all of the above transformations are appealing, it was noted that there was one that we simply can’t achieve safely: removing edges.

 

We frequently have nodes in the graph that exist only for their side effects, where they are linked so that static initializers will run and have side effects (like command registration). If we ever want to be able to remove edges, we need to be able to validate that removing those edges does not break the initializer graph. Is such a thing possible? Can it be done statically? Must we run code?

 

Here is a somewhat disorganized list of potential solutions to part of the problem:

 
 * Can we ban C++ static initializers that reach outside of the current library and require the use of mongo initializers? That would greatly reduce the scope of the problem, but raises another of identifying all such initializers. Many C++ static initializers are simply innocent strings. How can we find the ones that have spooky action at a distance? Can the linker help somehow, maybe with a linker plugin? If a C++ initializer implementation contains references to unresolved symbols that are provided by one its library dependencies?


 * We could operate under the assumption that the initializer graph is currently correct. Then we could write a program which dlopen’d each program and shared library and invoked the mongo initializer entry point in a special mode which dumped all the executed initializers and their DAG. If removing an edge caused any change in the initializer graph realized by any target, we could flag the libdep removal as invalid.



Other ideas are most welcome.
{quote}",,,,,,,,SERVER-52578,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,9158400,<a href='https://jira.mongodb.org/browse/SERVER-52578'>SERVER-52578</a>,,,,,,,PM-1112,,,,,,,,,,,,,,,,,,,,true,april.schoffer(april.schoffer),2020-11-03 03:31:48.0,,,,,,,,,,,,,,backlog-server-devplatform(backlog-server-devplatform),daniel.moody(JIRAUSER1253549),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i73nr3:",,,,,,,"0|i01n3b:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i73lun:",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
add Dockerfile into Mongodb server code tree,SERVER-18408,203238,New Feature,Backlog,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-server-devplatform,jackyh,jackyh,May 11 2015 08:28:14 AM UTC,Feb 10 2021 05:28:56 PM UTC,Feb 17 2021 11:15:16 AM UTC,,,,,,,Build,,,,0,platforms-re-triaged,,,,,"Since docker is a very popular platform as to PaaS, it should be benefit for mongodb to release it's source code with Dockerfile(and the scripts to build docker image if there's any). Here, I would like to raise this idea to include it into our source tree:
1) I suggest to have a dir named Docker with Dockerfile and other related scripts under it. This dir will just be put under the root dir (the same level with debian or rpm dir)
2) The Dockerfile should build docker image based on the latest development code
3) The Dockerfile should be able to build docker image for most important platforms including X86, Power and others.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,5.0,,,,,,,,,,,,,,,,,,,,,500A000000UabrfIAB,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2015-05-11 15:27:53.0,182131200,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,april.schoffer(april.schoffer),Tue May 12 08:03:58 UTC 2015,,,,,,,,,,,,,,backlog-server-devplatform(backlog-server-devplatform),ernie.hershey(ernie.hershey@10gen.com),jackyh(jackyh),ramon.fernandez(ramon.fernandez),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i02viv:",,,,,,,"0|i3f1an:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i0y6xj:","May 11 2015 08:41:17 AM UTC;jackyh;I'm Jack He from IBM, now working on the dockerization of Mongodb. Since I dont know how to assign bug on JIRA, maybe admin can help to assign this one to me.","May 11 2015 03:27:53 PM UTC;ramon.fernandez;[~jackyh], we can't assign a ticket to external contributors, but if you're interested in contributing a Dockerfile please take a look at the [contributor's guide|https://www.mongodb.org/about/contributors/], specially the [Getting Started section|https://www.mongodb.org/about/contributors/getting-started/]: you can fork the MongoDB repository and submit a pull request against it with your proposed changes.

Please let us know if you have any questions about the process. We can keep this ticket open to host any discussion necessary.

Regards,
Ramón.","May 11 2015 09:52:00 PM UTC;ernie.hershey;For reference, some decent semi-official docker mongodb info from Docker. 
https://docs.docker.com/examples/mongodb/
https://github.com/docker-library/mongo/tree/c9a1b066a0f35f679c2f8e1854a21e025867d938
","May 12 2015 08:01:59 AM UTC;jackyh;Ramon, yes, I roughly went over these guilds, will fork the repo of mongodb and start. Seems it's common to all projects that host on github. Also, I joined the mongodb-dev google group:)

-jack","May 12 2015 08:03:58 AM UTC;jackyh;Ernie, right, they already did something that I can refer to.

-jack",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Create SCons coverage tool,SERVER-49877,1420526,New Feature,Backlog,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-server-devplatform,daniel.moody,daniel.moody,Jul 24 2020 07:05:30 PM UTC,Feb 10 2021 05:28:45 PM UTC,Feb 17 2021 11:15:16 AM UTC,,,,,,,,,,,0,coverage,,,,,"The tool should be loaded into the base environment if the --gcov option is supplied.

It should add the specific flags for clang and gcc for turning on coverage file generation.

It should add an emitter on associated builders adding the coverage output files as additional targets.

It should add an additional builder which will take in those outputed coverage files and generate a coverage report.
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,17884800,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,april.schoffer(april.schoffer),2020-07-24 19:05:30.0,,,,,,,,,,,,,,backlog-server-devplatform(backlog-server-devplatform),daniel.moody(JIRAUSER1253549),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i6kl2f:",,,,,,,"0|i05rgf:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i6kj5z:",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
libdeps graph linter: Missing LIBDEPS Edges,SERVER-52579,1531802,New Feature,Backlog,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-server-devplatform,daniel.moody,daniel.moody,Nov 02 2020 10:06:17 PM UTC,Feb 10 2021 05:28:45 PM UTC,Feb 17 2021 11:15:16 AM UTC,,,,,,,,,,,0,,,,,,"Implement the graph linter employing the command line tool, graph collection service and graph visualization tool where applicable. Description from the technical design doc:
{quote}If the graph links, can any LIBDEPS edges actually be missing? In one sense, the answer is no. The fact that all nodes in the dependency graph link is fairly compelling evidence that every link target has at least the required libraries on its link line.

 

However, the situation may be more fragile than it appears. If link target A makes direct use of symbols from library Z but does not declare its own dependency on Z, it must be linking successfully because one or more of A’s other dependencies has transitively promulgated Z to A’s link line by itself declaring a public dependency on Z. If those Z exporting dependencies were to later reduce Z from a public to a private library dependency, A would no longer see Z on its link line and would suddenly fail to link.

 

Therefore, A should be flagged as having a missing dependency on Z if:

 
 * A uses (has undefined references to) symbols exported from library Z.
 * A does not directly declare a dependency on library Z.
 * Z should in fact be a private dependency in all exporters of Z reachable from A.

 

This is a fairly stringent set of requirements, but it is not impossible. Especially if we intend to start moving more libraries to private (an explicit goal of the linter) this situation is likely to become increasingly relevant.

 

Another situation where A could be flagged as having a missing library dependency on Z would be if A did not declare a public dependency on Z, but use of the interface to library A by a client node C ought to induce C to have a dependency edge on Z because use of A results in unresolved symbols provided by Z. Again, C might link in practice because C achieves, either directly or transitively, a dependency on Z via its other dependencies. Again, this is fragile because if C’s dependencies change such that they cease to transitively export Z to C, C will suddenly fail to link. If Library A induces a Z dependency on users of its interface but does not declare any dependency on Z, then Z should be flagged as missing (and as needing to be public) from A.

 

There may be other cases like the above, these are intended to be illustrative not exhaustive. Overall, adding libdeps flagged as missing is a relatively safe operation. Adding edges to the graph that are already being satisfied through back channels is unlikely to break things. 

 

Finally, note that the mechanics of detecting this class of errors overlaps heavily with that of identifying public nodes that should be private and vice versa. This check should be implemented after those checks are implemented.
{quote}",,,,,,,,SERVER-52578,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,9158400,<a href='https://jira.mongodb.org/browse/SERVER-52578'>SERVER-52578</a>,,,,,,,PM-1112,,,,,,,,,,,,,,,,,,,,true,april.schoffer(april.schoffer),2020-11-02 22:06:17.0,,,,,,,,,,,,,,backlog-server-devplatform(backlog-server-devplatform),daniel.moody(JIRAUSER1253549),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i73mtb:",,,,,,,"0|i01n2v:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i73kwv:",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
integrate libabigail data into libdeps generate-libdeps-graph target,SERVER-52578,1531797,New Feature,Backlog,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-server-devplatform,daniel.moody,daniel.moody,Nov 02 2020 10:03:52 PM UTC,Feb 10 2021 05:28:40 PM UTC,Feb 17 2021 11:15:16 AM UTC,,,,,,,,,,,0,,,,,,"Integrating source file and symbol dependency info from libabigail into the libdeps graph will open up a lot of possibilities for linting and graph queries. This particular integration may cause the time required to generate the graph to blow up, and we may want a separate target which adds the symbol dependency info if requested.",,,,,,,,SERVER-52566,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,9158400,<s><a href='https://jira.mongodb.org/browse/SERVER-52566'>SERVER-52566</a></s>,,,,,,,PM-1112,,,,,,,,,,,,,,,,,,,,true,april.schoffer(april.schoffer),2020-11-02 22:03:52.0,,,,,,,,,,,,,,backlog-server-devplatform(backlog-server-devplatform),daniel.moody(JIRAUSER1253549),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i73ms7:",,,,,,,"0|i01n2n:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i73kvr:",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
create the libdeps graph collection service,SERVER-52573,1531712,New Feature,Backlog,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-server-devplatform,daniel.moody,daniel.moody,Nov 02 2020 08:17:43 PM UTC,Feb 10 2021 05:28:38 PM UTC,Feb 17 2021 11:15:16 AM UTC,,,,,,,,,,,0,,,,,,"From the document: 
{quote}The graph collection service is a web service to which new instances of graph data can be pushed and persisted. A permanent instance of the collection service will be maintained, such that an evergreen task can send new graph instances to it for every commit. The collection service will then be able to answer queries about the state of the graph at any given time.

 

The graph collection service will also serve an instance of the visualization tools that are pointed at its stored data, allowing visualization of the state of the graph at any given time, or over time.

 

The command line tools, when pointed at the graph collection service, will gain the ability to answer temporal queries, such as:
 * Over what range of commits does node X exist?
 * In what commits did the node or edge count increase or decrease?
 * By how much did a given commit change the node or edge counts?
 * In what commit did node X first become dependent on node Y?
 * In what commit did node X cease to be dependent on node Y?
 * Provide a time series representation of the node or edge counts over a given range.

 

The graph collection service should be implemented in Python and will presumably use MongoDB for its data storage, unless another data store is called for due to friction between the graph-y nature of the data and MongoDB’s capabilities.

 

The graph collection service code should be committed to the server repository so that it is easy to run a local instance.
{quote}
This ticket is for writing the basic implementation of such a service and committing that service into the repo. The scope of this ticket assumes the service can be started, data can be pushed to it and persisted, and the basic query is functional and answers through a web interface (REST?): 
 * Over what range of commits does node X exist?

The format the data stored in the database should be conducive to further more advanced queries.",,,,,,,,SERVER-52566,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,9158400,<s><a href='https://jira.mongodb.org/browse/SERVER-52566'>SERVER-52566</a></s>,,,,,,,PM-1112,,,,,,,,,,,,,,,,,,,,true,april.schoffer(april.schoffer),2020-11-02 20:17:43.0,,,,,,,,,,,,,,backlog-server-devplatform(backlog-server-devplatform),daniel.moody(JIRAUSER1253549),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i73m9b:",,,,,,,"0|i01n1r:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i73kcv:",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Refactor SCons directory variable names,SERVER-42170,853219,New Feature,Backlog,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-server-devplatform,mathew.robinson,mathew.robinson,Jul 11 2019 06:17:27 PM UTC,Feb 10 2021 05:28:37 PM UTC,Feb 17 2021 11:15:16 AM UTC,,,,,,,Build,,,,0,,,,,,"Currently we have $BUILD_DIR which is actually the VariantDir, and $BUILD_ROOT which is the argument to --build-dir. We also have $INSTALL_DIR but a flag called --prefix. Finally, we are going to be adding a new --dest-dir flag and it needs a new associated variable.

We should normalize these as follows:

* Rename $BUILD_DIR to $VARIANT_DIR
* Rename $BUILD_ROOT to $BUILD_DIR

",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,50630400,,,,,,,,PM-345,,,,,,,,,,,,,,,,,,,,true,april.schoffer(april.schoffer),2019-07-11 18:17:27.0,,,,,,,,,,,,,,backlog-server-devplatform(backlog-server-devplatform),mathew.robinson(mathew.robinson),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i3wq4n:",,,,,,,"0|i05mhj:",9223372036854775807,,,,,,,,,,,,Dev Tools 2019-09-09,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i3wo8f:",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
libdeps graph linter: private that should be public,SERVER-52582,1531952,New Feature,Backlog,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-server-devplatform,daniel.moody,daniel.moody,Nov 03 2020 03:22:19 AM UTC,Feb 10 2021 05:28:28 PM UTC,Feb 17 2021 11:15:16 AM UTC,,,,,,,,,,,0,,,,,,"from the document:
{quote}This is actually one of the simpler ones. If A declares a private dependency on Z, but use of A’s interface by a client C induces a dependency on symbols from Z, then A’s declaration of the Z dependency should be promoted from private to public. Such a transformation is always safe: no edges are removed, and no other nodes will have their current dependency set reduced.

 

There is a subtle angle to this one (of course!): it is possible that use of A’s interface induces symbol dependencies on Z in C not because of the direct use of Z in A’s interface, but because A induces the use of symbols from B, and use of those symbols from B induces the use of symbols from Z. If all of the induced uses of Z in consumers of the A interface can be explained away by other should-be-public dependencies of A (like B), then it makes no difference if Z is public or private in A: B will need to be public in A, and Z will need to be public in B. In such situations, it seems best that if A really does make direct use of Z internally, that it be declared a private library dependency despite the fact that B will drive it through A as public to A’s clients. Otherwise, if B later changed such that it no longer induced a Z dependency on clients of A’s interface, Z would suddenly become flagged as public-should-be-private in A.

 

Given that the transformation suggested by the linter is safe and the conditions reasonably easy to understand, it is probably a good candidate for implementation early in the project.
{quote}",,,,,,,,SERVER-52578,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,9158400,<a href='https://jira.mongodb.org/browse/SERVER-52578'>SERVER-52578</a>,,,,,,,PM-1112,,,,,,,,,,,,,,,,,,,,true,april.schoffer(april.schoffer),2020-11-03 03:22:19.0,,,,,,,,,,,,,,backlog-server-devplatform(backlog-server-devplatform),daniel.moody(JIRAUSER1253549),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i73nqn:",,,,,,,"0|i01n33:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i73lu7:",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
create the lint-libdeps-graph target,SERVER-52572,1531702,New Feature,Backlog,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-server-devplatform,daniel.moody,daniel.moody,Nov 02 2020 08:05:47 PM UTC,Feb 10 2021 05:28:28 PM UTC,Feb 17 2021 11:15:16 AM UTC,,,,,,,,,,,0,,,,,,"This target should run the libdeps graph command line tool to output various issues found from a prescribed list of lint rules. output file of this target should be somewhat of a report, describing a lint errors found from a prescribed list of linters to run, and other various graph information.

 

The format of this report is yet to be decided but should be a format that supports programmable interface such as XML or JSON, such that other tools, or the libdeps graph command line tool itself can read it and output the info in a pretty-print or easily extract bits of target info.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,9158400,,,,,,,,PM-1112,,,,,,,,,,,,,,,,,,,,true,april.schoffer(april.schoffer),2020-11-02 20:05:47.0,,,,,,,,,,,,,,backlog-server-devplatform(backlog-server-devplatform),daniel.moody(JIRAUSER1253549),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i73m73:",,,,,,,"0|i01n1j:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i73kan:",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Add support for producing RPMs from component/role matrix,SERVER-41661,799171,New Feature,Backlog,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-server-devplatform,acm,acm,Jun 12 2019 06:29:52 PM UTC,Feb 10 2021 05:28:24 PM UTC,Feb 17 2021 11:15:16 AM UTC,,,,,,,Build,,,,0,,,,,,Each non-empty role/component combination should produce meaningful RPMs.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,Fully Compatible,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2019-10-04 17:17:48.0,43286400,,,,,,,,PM-1614,,,,,,,,,,,,,,,,,,,,true,april.schoffer(april.schoffer),Fri Oct 04 17:17:48 UTC 2019,,,,,,,,,,,,,,acm(acm),backlog-server-devplatform(backlog-server-devplatform),mathew.robinson(mathew.robinson),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i3nlp3:",,,,,,,"0|i02fn3:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i3njsv:","Oct 04 2019 05:17:48 PM UTC;mathew.robinson;Moving out of Hygienic Builds to the Generative Packaging epic",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Evaluate feasibility of enabling -fvisibility-inlines-hidden,SERVER-49322,1402768,New Feature,Backlog,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-server-devplatform,acm,acm,Jul 07 2020 01:05:37 PM UTC,Feb 10 2021 05:28:22 PM UTC,Feb 17 2021 11:15:16 AM UTC,,,,,,,Build,,,,0,,,,,,"Building with {{-fvisibility-inlines-hidden}} results in a significantly faster startup time for a dynamically linked build. It also results in a smaller text segment. However, it is not entirely without consequence: it can mean that the address of inline functions cannot be compared across DSOs. We should undertake to understand whether the consequences are acceptable in light of the performance impact. 

See https://gcc.gnu.org/wiki/Visibility for more details.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,Fully Compatible,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,19353600,,,,,,,,PM-1328,,,,,,,,,,,,,,,,,,,,true,april.schoffer(april.schoffer),2020-07-07 13:05:37.0,,,,,,,,,,,,,,acm(acm),backlog-server-devplatform(backlog-server-devplatform),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i6hjsn:",,,,,,,"0|i02fgf:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i6hhw7:",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
libdeps graph command line tool: symbol dependencies,SERVER-52570,1531697,New Feature,Backlog,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-server-devplatform,daniel.moody,daniel.moody,Nov 02 2020 08:00:34 PM UTC,Feb 10 2021 05:28:17 PM UTC,Feb 17 2021 11:15:16 AM UTC,,,,,,,,,,,0,,,,,,"The command line tool should support the query through option:
 * What symbols defined in node X are used by node Y?

This will require that symbol information is being generated into the libdeps graph file generated from the generate-libdeps-graph and that info may require the build to integrate such tools such as libabigail to discover such symbol dependency information.

 ",,,,,,,,SERVER-52567,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,9158400,<s><a href='https://jira.mongodb.org/browse/SERVER-52567'>SERVER-52567</a></s>,,,,,,,PM-1112,,,,,,,,,,,,,,,,,,,,true,april.schoffer(april.schoffer),2020-11-02 20:00:34.0,,,,,,,,,,,,,,backlog-server-devplatform(backlog-server-devplatform),daniel.moody(JIRAUSER1253549),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i73m5z:",,,,,,,"0|i01n1b:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i73k9j:",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Implement improved build module system,SERVER-17756,192283,New Feature,Backlog,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-server-devplatform,acm,acm,Mar 26 2015 07:03:15 PM UTC,Feb 10 2021 05:28:17 PM UTC,Feb 17 2021 11:15:16 AM UTC,,,,,,,Build,,,,1,,,,,,"The current module system does not provide an API by which a module can express things like the addition of new options or variables to scons, and does not provide a simple way to integrate additional configure checks or environment modifications.

Additionally, the top level SConstructs use of modules is fairly limited.

A better module system should be developed that allows options, variables, configure checks to be pushed down into each loaded module. Additionally, the top level SConstruct should be updated so that it acts, essentially, as a builder of modules.

Once this is done, we should write module definitions for src/mongo and src/third_party and push down much of the logic in the top level SConstruct into those modules.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,1.0,,,,,,,,,,,,,,,,Fully Compatible,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,186105600,,,,,,,,PM-345,,,,,,,,,,,,,,,,,,,,true,april.schoffer(april.schoffer),2015-03-26 19:03:15.0,,,,,,,,,,,,,,acm(acm),backlog-server-devplatform(backlog-server-devplatform),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i02z0v:",,,,,,,"0|i05mgn:",9223372036854775807,,,,,,,,,,,,Platform 2 04/24/15,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i0yb6n:",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Provide packages with AVX2 architecture,SERVER-18417,203404,New Feature,Backlog,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-server-devplatform,sallgeud,sallgeud,May 11 2015 08:05:07 PM UTC,Feb 10 2021 05:28:12 PM UTC,Feb 17 2021 11:15:16 AM UTC,,,,,,,Build,Packaging,Performance,,1,build-later,,,,,"The Haswell architecture has a new AVX2 instruction set that's supported by more current versions of gcc and visual-studio compilers. In-memory databases are known to benefit substantially from the incorporation of these instruction sets. 

It would be great to have linux and windows packages with these already compiled. Notably aptitude and windows packages.

https://software.intel.com/en-us/articles/how-intel-avx2-improves-performance-on-server-applications",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2020-06-20 04:46:42.0,20563200,,,,,,,,PM-1328,,,,,,,,,,,,,,,,,,,,true,april.schoffer(april.schoffer),Tue Jun 23 15:00:03 UTC 2020,,,,,,,,,,,,,,acm(acm),backlog-server-devplatform(backlog-server-devplatform),sallgeud(sallgeud),corporate.piyush@gmail.com(corporate.piyush@gmail.com),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i02vgv:",,,,,,,"0|i02fh3:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i02yx3:","Jun 20 2020 04:46:42 AM UTC;corporate.piyush@gmail.com;Looks like this issue is out of attention. Please re-consider this issue.

 

It will help tremendously for querying larger dataset through aggregation pipeline or otherwise.   

 

Or Is there a way to compile the mongodb source code to include this feature and let compiler do the deep autovectorization of the code ?","Jun 23 2020 03:00:03 PM UTC;acm;[~corporate.piyush@gmail.com] - This ticket is currently slotted into a project that is approved, but not yet moving forward due to higher priority work. We do hope to get to it in the near future. While it is certainly possible to build the source code with flags that would enable this, I cannot recommend doing so as it will be difficult to ensure correctness without extensive regression testing.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Add support for producing MSIs from component/role matrix,SERVER-41660,799168,New Feature,Backlog,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-server-devplatform,acm,acm,Jun 12 2019 06:28:56 PM UTC,Feb 10 2021 05:28:10 PM UTC,Feb 17 2021 11:15:16 AM UTC,,,,,,,Build,,,,0,,,,,,"Given a build and a set of component and role assignments for files, we should be able to produce one or more MSIs that allow installation of (perhaps selectable) subsets of the build.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,Fully Compatible,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2019-10-04 17:17:54.0,43286400,,,,,,,,PM-1614,,,,,,,,,,,,,,,,,,,,true,april.schoffer(april.schoffer),Fri Oct 04 17:17:54 UTC 2019,,,,,,,,,,,,,,acm(acm),backlog-server-devplatform(backlog-server-devplatform),mathew.robinson(mathew.robinson),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i3nlon:",,,,,,,"0|i02flr:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i3njsf:","Oct 04 2019 05:17:54 PM UTC;mathew.robinson;Moving out of Hygienic Builds to the Generative Packaging epic",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Add support for auto-installation and role tagging of soname and dev symlinks for versioned shared libraries,SERVER-41665,799185,New Feature,Backlog,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-server-devplatform,acm,acm,Jun 12 2019 06:47:54 PM UTC,Feb 10 2021 05:28:04 PM UTC,Feb 17 2021 11:15:16 AM UTC,,,,,,,Build,,,,0,,,,,,"When installing versioned shared libraries, the library should get installed to the runtime component and the relevant directory along with its SONAME symlink, but the developer symlink should go to the dev role instead.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,Fully Compatible,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2019-10-04 17:27:01.0,42854400,,,,,,,,PM-1922,,,,,,,,,,,,,,,,,,,,true,april.schoffer(april.schoffer),Wed Oct 09 15:57:25 UTC 2019,,,,,,,,,,,,,,acm(acm),backlog-server-devplatform(backlog-server-devplatform),mathew.robinson(mathew.robinson),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i3nls7:",,,,,,,"0|i03no7:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i3njvz:","Oct 04 2019 05:27:01 PM UTC;mathew.robinson;[~acm] same as SERVER-41970 this should go into the ""Dynamic Builds by Default"" epic if we have one.","Oct 09 2019 03:57:25 PM UTC;acm;[~mathew.robinson] - Yes, moved. Thanks.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
connect the libdeps graph command line tool to libdeps graph web service,SERVER-52575,1531721,New Feature,Backlog,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-server-devplatform,daniel.moody,daniel.moody,Nov 02 2020 08:26:19 PM UTC,Feb 10 2021 05:27:54 PM UTC,Feb 17 2021 11:15:16 AM UTC,,,,,,,,,,,0,,,,,,"The command line tools performs queries on the libdeps graph file but does not have data to perform temporal queries on how the graph has changed across commits.

 

This ticket is to add the interface such that the command line tool can be pointed at a running web service and perform temporal queries through the web service.

 

This ticket should also allow such a service to be started if there is none to point to and data files from a directory to be automatically added to perform said temporal queries. ",,,,,,,,SERVER-52567,SERVER-52573,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,9158400,"<s><a href='https://jira.mongodb.org/browse/SERVER-52567'>SERVER-52567</a></s>, <a href='https://jira.mongodb.org/browse/SERVER-52573'>SERVER-52573</a>",,,,,,,PM-1112,,,,,,,,,,,,,,,,,,,,true,april.schoffer(april.schoffer),2020-11-02 20:26:19.0,,,,,,,,,,,,,,backlog-server-devplatform(backlog-server-devplatform),daniel.moody(JIRAUSER1253549),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i73mbb:",,,,,,,"0|i01n27:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i73kev:",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Add support for ""allocator=jemalloc""",SERVER-39325,681477,New Feature,Backlog,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-server-devplatform,michael.cahill,michael.cahill,Feb 01 2019 02:15:47 AM UTC,Feb 10 2021 05:27:51 PM UTC,Feb 17 2021 11:15:16 AM UTC,,,,,,,Build,,,,1,,,,,,"For some MongoDB use cases, jemalloc has some advantages over tcmalloc.  In particular, some users have reported that performance is more predictable (avoiding some of the long stalls experienced with tcmalloc).

Please consider adding build-time support for jemalloc.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2019-02-01 15:16:07.0,64540800,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,april.schoffer(april.schoffer),2019-02-01 02:15:47.0,,,,,,,,,,,,,,backlog-server-devplatform(backlog-server-devplatform),michael.cahill(michael.cahill),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i33rzb:",,,,,,,"0|i3f1bj:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i33q33:",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
libdeps graph command line tool: optimizing node mergers,SERVER-52569,1531688,New Feature,Backlog,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-server-devplatform,daniel.moody,daniel.moody,Nov 02 2020 07:56:36 PM UTC,Feb 10 2021 05:27:47 PM UTC,Feb 17 2021 11:15:16 AM UTC,,,,,,,,,,,0,,,,,,"The libdeps graph command line tool should be able to give a list of all nodes which have indegree of 1 and are possible candidates of merging with the depender to reduce the number of nodes in the graph.

 

There is vagueness around what other constraints (besides indegree of 1) need to be fulfilled before a merge of two nodes can be done. This ticket should be updated to reflect those other constraints once the vagueness is resolved.",,,,,,,,SERVER-52567,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,9158400,<s><a href='https://jira.mongodb.org/browse/SERVER-52567'>SERVER-52567</a></s>,,,,,,,PM-1112,,,,,,,,,,,,,,,,,,,,true,april.schoffer(april.schoffer),2020-11-02 19:56:36.0,,,,,,,,,,,,,,backlog-server-devplatform(backlog-server-devplatform),daniel.moody(JIRAUSER1253549),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i73m3z:",,,,,,,"0|i01n13:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i73k7j:",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
libdeps graph collection service basic quiries,SERVER-52574,1531715,New Feature,Backlog,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-server-devplatform,daniel.moody,daniel.moody,Nov 02 2020 08:21:14 PM UTC,Feb 10 2021 05:27:45 PM UTC,Feb 17 2021 11:15:16 AM UTC,,,,,,,,,,,0,,,,,,"The libdeps graph collection service should be updated to answer these queries through a web interface (REST?)
 * In what commits did the node or edge count increase or decrease?
 * By how much did a given commit change the node or edge counts?
 * In what commit did node X first become dependent on node Y?
 * In what commit did node X cease to be dependent on node Y?
 * Provide a time series representation of the node or edge counts over a given range.",,,,,,,,SERVER-52573,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,9158400,<a href='https://jira.mongodb.org/browse/SERVER-52573'>SERVER-52573</a>,,,,,,,PM-1112,,,,,,,,,,,,,,,,,,,,true,april.schoffer(april.schoffer),2020-11-02 20:21:14.0,,,,,,,,,,,,,,backlog-server-devplatform(backlog-server-devplatform),daniel.moody(JIRAUSER1253549),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i73m9z:",,,,,,,"0|i01n1z:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i73kdj:",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Implement a snapshot manager for ephemeralForTest,SERVER-49792,1416477,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-server-execution,gregory.wlodarek,gregory.wlodarek,Jul 22 2020 05:00:47 AM UTC,Feb 10 2021 05:00:13 PM UTC,Feb 17 2021 11:15:16 AM UTC,,,,,,Backlog,Storage,,,,0,,,,,,"To allow the RecoveryUnit to open a snapshot on the *kMajorityCommitted* and *kLastApplied* ReadSource's, we need to implement a [snapshot manager|https://github.com/mongodb/mongo/blob/master/src/mongo/db/storage/snapshot_manager.h] for ephemeralForTest.

The replication subsystem hooks into the snapshot manager of the storage engine to update the majority committed and last applied timestamps on the fly.

This should end up looking similar to [WiredTiger's snapshot manager|https://github.com/mongodb/mongo/blob/master/src/mongo/db/storage/wiredtiger/wiredtiger_snapshot_manager.h] implementation.

 

This ticket should also implement the *kNoOverlap* ReadSource in ephemeralForTest's RecoveryUnit. The no overlap timestamp is the minimum of the 'all durable' and 'last applied' timestamps.

Enable [SnapshotManagerTests|https://github.com/mongodb/mongo/blob/master/src/mongo/db/storage/kv/kv_engine_timestamps_test.cpp] for ephemeralForTest",,,,,,,,SERVER-49553,,,,,,,,,,,,,,,,,,,,,,,,1.0,1.0,,,,,,,,,,,,,,,,Fully Compatible,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2020-08-07 19:19:05.0,9590400,<s><a href='https://jira.mongodb.org/browse/SERVER-49553'>SERVER-49553</a></s>,,,,,,,,,,,,,,,,,,,,,,,,,,,true,bynn.lee(JIRAUSER1253412),Wed Oct 28 19:01:29 UTC 2020,,,,,,,,,,,,,,backlog-server-execution(backlog-server-execution),gregory.wlodarek(gregory.wlodarek),louis.williams(louis.williams),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i6jw2v:",,,,,,,"0|i00dpj:",9223372036854775807,,,,,,,,,,,,Execution Team 2020-08-10,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i6ju6f:","Oct 28 2020 07:01:29 PM UTC;louis.williams;Moving back to backlog because we encountered some bugs in EFT that mean certain tests don't pass. Specifically, EFT mocks commit timestamps, and it is not possible to commit multiple transactions at the same commit timestamp. This has the consequence that reading at a timestamp has incorrect behavior.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Enable pushdown of config.cache.chunks $lookup through $sort,SERVER-53638,1583451,New Feature,In Progress,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,charlie.swanson,charlie.swanson,charlie.swanson,Jan 07 2021 08:47:09 PM UTC,Feb 09 2021 10:01:05 PM UTC,Feb 17 2021 11:15:16 AM UTC,,,,,,Backlog,Aggregation Framework,,,,0,query-work-resharding,,,,,"As part of a resharding operation we issue a pipeline with a $sort followed by a $lookup on config.cache.chunks. For efficiency and resumability, we need each shard to provide things in a sorted order and also perform the $lookup. Today this doesn't work because the $sort forces a split of a sharded pipeline and does not push the $lookup into the shards part. For this particular $lookup, we know it is safe to run it in parallel, so we should be able to push it into the shards pipeline.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,1.0,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2021-01-14 17:05:16.0,3456000,,,,,,,,PM-234,,,,,,,,,,,,,,,,,,,,true,charlie.swanson(charlie.swanson),Thu Jan 07 20:49:05 UTC 2021,,,,,,,,,,,,,,charlie.swanson(charlie.swanson),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i7ch1j:",,,,,,,"0|i7960f:",9223372036854775807,,,,,,,,,,,,Query Optimization 2021-02-22,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i7cf53:","Jan 07 2021 08:49:05 PM UTC;charlie.swanson;Anyone who picks this up: be aware of some similar discussion of tradeoffs in [SERVER-26442|https://www.google.com/url?q=https://jira.mongodb.org/browse/SERVER-26442&sa=D&ust=1610055519939000&usg=AOvVaw0FvEjInjKrTKHCv8KIQnPW]. As always, we should try to avoid making things worse with this optimization.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"x.509 certificate authentication requires O,OU to differ between client and server",SERVER-14655,148431,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-server-security,mark.helmstetter,mark.helmstetter,Jul 22 2014 07:45:00 PM UTC,Feb 09 2021 09:24:45 PM UTC,Feb 17 2021 11:15:16 AM UTC,,2.6.3,,,,Backlog,Security,,,,6,platforms-re-triaged,,,,,"For x.509 certificate authentication, MongoDB server will consider a certificate with identical subject name properties, a member of the cluster and not a client. For some organizations it may not be possible to obtain certificates meeting this requirement.",,,,,,,,,,,,HELP-5168,,,,,,,,,,,,,,,,,,,,3.0,1.0,,,,,,,,,,,,,,,,,,,,500A000000YTYPeIAP,5002K00000kDPxGQAW,5002K00000ocekNQAQ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2014-07-22 22:16:35.0,3542400,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,ben.caimano(ben.caimano),Wed Jan 06 16:12:36 UTC 2021,,,,,,,,,,,,,,backlog-server-security(backlog-server-security),mark.helmstetter(mark.helmstetter@10gen.com),mattmail4543@yahoo.com(mattmail4543@yahoo.com),simon.levesque@morganstanley.com(simon.levesque@morganstanley.com),spencer.jackson(spencer.jackson@10gen.com),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i03gcv:",,,,,,,"0|i053ev:",3852,,,,,,,,,,,,Security 2020-08-10,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i0yxgn:","Feb 18 2020 07:37:17 PM UTC;simon.levesque@morganstanley.com;Hi,

I would consider that a ""bug"" ; not a ""new feature"" since when using keyfile that doesn't make sense at all.

Also, it is ""Major"" since 2014. How can we get some traction on it? We depend on that fix to be able to use some vendor products that do not work with kerberos.

thanks

 ","Aug 11 2020 02:14:22 PM UTC;spencer.jackson;Here's a quick summary of our understanding of and plans for this ticket.

Clusters configured for intracluster X509 authentication validate whether incoming client connections are originating from fellow cluster members by comparing the peer's certificate's subject name against its own certificate's. Clients with certificates corresponding to the cluster are granted internal cluster privileges. These authentication attempts do not require the server to make a disk access. This implies that it would be unsafe to create an unprivileged user whose name would be considered a cluster member: anyone authenticating as it would be granted full internal privileges regardless of its defined on-disk privileges. To prevent this issue from arising, createUser has a guardrail which prevents it from making users with these names.

Clusters using keyFile intracluster authentication would be immune from this conflation. However, we support upgrading a cluster from using keyFile intracluster authentication to using X509. Any users created under the old regimen could suddenly gain many powerful privileges after an upgrade. So, createUser's guardrail remains engaged in keyFile mode.

There could be multiple solutions for this request. One could involve a general rework to how cluster identities are provisioned, one could be to relax the guardrail for consumers of keyFile authentication.

There seems to be enough appetite for a relaxation. I believe that this relaxation should be opt-in via a setParameter, and that we should document the risks of using this mode and that the users' collection should be audited before upgrading to intracluster X509 authentication. I believe that we should re-open and perform this work under SERVER-45938, which was more precisely along these lines. We'll keep this ticket open in order to retain longer discussion about provisioning of cluster identity.","Jan 06 2021 04:12:36 PM UTC;mattmail4543@yahoo.com;I have the 4.2.11 version installed and set parameter enforceUserClusterSeparation : false in the mongod.conf which allows me to add an external user with the same  O/OU/DC as the server. When I try to login as that external user I get ""The provided certificate can only be used for cluster authentication, not client authentication. """,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Implement $dateTrunc in DocumentSource execution,SERVER-54390,1616229,New Feature,In Progress,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,mindaugas.malinauskas,mindaugas.malinauskas,mindaugas.malinauskas,Feb 08 2021 04:20:47 PM UTC,Feb 09 2021 06:29:04 PM UTC,Feb 17 2021 11:15:16 AM UTC,,,,,,5.0 Required,,,,,0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,691200,,,,,,,,PM-1933,,,,,,,,,,,,,,,,,,,,true,mindaugas.malinauskas(JIRAUSER1252520),2021-02-08 16:20:47.0,,,,,,,,,,,,,,mindaugas.malinauskas(JIRAUSER1252520),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i7i2yv:",,,,,,,"0|i7bpfz:",9223372036854775807,,,,,,,,,,,,Query Execution 2021-02-22,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i7i12f:",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Implement validateDBMetadata command,SERVER-52874,1542959,New Feature,In Code Review,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,arun.banala,arun.banala,arun.banala,Nov 16 2020 11:58:37 AM UTC,Feb 09 2021 06:14:26 PM UTC,Feb 17 2021 11:15:16 AM UTC,,,,,,Backlog,,,,,0,,,,,,,,,,,,,,SERVER-51653,,,,,,,,,,,,,,,,,,,,,,,,0.0,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,7948800,<s><a href='https://jira.mongodb.org/browse/SERVER-51653'>SERVER-51653</a></s>,,,,,,,PM-1846,,,,,,,,,,,,,,,,,,,,true,arun.banala(arun.banala),2020-11-16 11:58:37.0,,,,,,,,,,,,,,arun.banala(arun.banala),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i75j87:",,,,,,,"0|i6zpyn:",9223372036854775807,,,,,,,,,,,,Query 2021-01-25,Query Execution 2021-02-22,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i75hbr:",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Support including postBatchResumeToken in cursor response for non-change streams aggregations,SERVER-53534,1578201,New Feature,In Code Review,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,mindaugas.malinauskas,max.hirschhorn,max.hirschhorn,Dec 29 2020 02:01:57 PM UTC,Feb 09 2021 06:08:54 PM UTC,Feb 17 2021 11:15:16 AM UTC,,,,,,Backlog,Aggregation Framework,,,,0,PM-234-M2,PM-234-T-oplog-fetch,query-work-resharding,,,"The changes from [7d915a6|https://github.com/mongodb/mongo/commit/7d915a65b286e535397a5d79bf2109512003bda9] as part of SERVER-49895 made it so including {{\{$_requestReshardingResumeToken: true\}}} in the aggregation request would cause a {{\{postBatchResumeToken: \{ts: <latestOplogEntryTimestamp>\}\}}} to be included in the cursor response. However, the plumbing was only done in CollectionScan and therefore only applies when the pipeline can be entirely optimized away. [{{PlanExecutorPipeline::\_latestOplogTimestamp}} is only updated when {{PlanExecutorPipeline::_isChangeStream == true}}|https://github.com/mongodb/mongo/blob/72565dc7c6909fd6f96f5625a9d28c64efed8c9e/src/mongo/db/pipeline/plan_executor_pipeline.cpp#L130]. This makes including {{\{$_requestReshardingResumeToken: true\}}} not useful when running more complex aggregations such as the one resharding is using to fetch donor shard's oplog entries.

h6. Steps to reproduce

{noformat}
python buildscripts/resmoke.py run --suite=sharding jstests/sharding/resharding_oplog_sync_agg_resume_token.js
{noformat}

{code:diff}
diff --git a/jstests/sharding/resharding_oplog_sync_agg_resume_token.js b/jstests/sharding/resharding_oplog_sync_agg_resume_token.js
index 047a01abc8..3dbeb5d4d3 100644
--- a/jstests/sharding/resharding_oplog_sync_agg_resume_token.js
+++ b/jstests/sharding/resharding_oplog_sync_agg_resume_token.js
@@ -28,7 +28,9 @@ const localDb = rst.getPrimary().getDB(""local"");
 jsTest.log(""Run aggregation pipeline on oplog with $_requestReshardingResumeToken set"");
 const resEnabled = localDb.runCommand({
     aggregate: ""oplog.rs"",
-    pipeline: [{$match: {ts: {$gte: Timestamp(0, 0)}}}],
+    // The $addFields prevents the pipeline from being optimized away as a simple plan executor.
+    // This is necessary to force the pipeline to be evaluated using PlanExecutorPipeline.
+    pipeline: [{$match: {ts: {$gte: Timestamp(0, 0)}}}, {$addFields: {extra: {$literal: ""hi""}}}],
     $_requestReshardingResumeToken: true,
     cursor: {batchSize: 1}
 });
{code}",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2021-02-09 18:08:53.0,4233600,,,,,,,,PM-234,,,,,,,,,,,,,,,,,,,,true,mindaugas.malinauskas(JIRAUSER1252520),2020-12-29 14:01:57.0,,,,,,,,,,,,,,max.hirschhorn(max.hirschhorn@10gen.com),mindaugas.malinauskas(JIRAUSER1252520),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i7bkmv:",,,,,,,"0|i75h93:",9223372036854775807,,,,,,,,,,,,Query Execution 2021-02-22,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i7biqf:",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
implement libdeps graph command line tool advanced queries,SERVER-52568,1531683,New Feature,In Code Review,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,daniel.moody,daniel.moody,daniel.moody,Nov 02 2020 07:52:43 PM UTC,Feb 09 2021 03:18:48 PM UTC,Feb 17 2021 11:15:16 AM UTC,,,,,,Backlog,,,,,0,,,,,,"implement options to allow the tool to perform and return the values for these queries:
 * What are all paths by which node X depends on node Y?
 * Is there a single edge which if removed disconnects node X from node Y?
 * What are the weightiest public edges (e.g. add the most transitive edges)",,,,,,,,SERVER-52567,,,,,,,,,,,,,,,,,,,,,,,,0.0,4.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,9158400,<s><a href='https://jira.mongodb.org/browse/SERVER-52567'>SERVER-52567</a></s>,,,,,,,PM-1112,,,,,,,,,,,,,,,,,,,,true,acm(acm),2020-11-02 19:52:43.0,,,,,,,,,,,,,,daniel.moody(JIRAUSER1253549),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i73m2v:",,,,,,,"0|i007hj:",9223372036854775807,,,,,,,,,,,,Dev Platform 2021-01-11,Dev Platform 2021-01-25,Dev Platform 2021-02-08,Dev Platform 2021-02-22,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i73k6f:",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
create libdeps graph visualization web service,SERVER-52576,1531787,New Feature,In Code Review,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,daniel.moody,daniel.moody,daniel.moody,Nov 02 2020 09:47:37 PM UTC,Feb 09 2021 03:18:47 PM UTC,Feb 17 2021 11:15:16 AM UTC,,,,,,Backlog,,,,,0,,,,,,"from the document: 
{quote}The project will provide web browser based visualization tools that can interactively query, filter, and render the graph data in various useful ways, using either local state (flat files generated by graph data) or data held by an instance of the graph collection service. The service backend will be implemented in python using standard python web service frameworks, and the visualization layer will be developed using Javascript and modern web frameworks and data visualization frameworks like D3.

 

It should be turnkey to run a local instance of the web service and any backing data services. Launching an instance of the graph collection service in a container may be one potential approach to this problem, although there are potential downsides to this approach on non-linux platforms. As with the graph collection service, the sources and static content for the visualization service should be checked into the community repo to enable simple local execution.
{quote}
A python webservice should be used to run the visualization service in the browser. This webserive should employ  [JSnetworkx|http://jsnetworkx.org/index.html] which is a javascript library port of pythons networkx, which uses D3 for the graph visualizations.

 

The scope of this ticket should include getting the visualization web service running, and visualizing a local graphml file generated from the generate-libdeps-graph target. Connecting to a graph graph collection webservice and visualizing data from that source will be in later tickets. Also any other advanced UI will be reserved for later tickets.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,5.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,9158400,,,,,,,,PM-1112,,,,,,,,,,,,,,,,,,,,true,acm(acm),2020-11-02 21:47:37.0,,,,,,,,,,,,,,daniel.moody(JIRAUSER1253549),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i73mpz:",,,,,,,"0|i007hb:",9223372036854775807,,,,,,,,,,,,Dev Platform 2020-12-28,Dev Platform 2021-01-11,Dev Platform 2021-01-25,Dev Platform 2021-02-08,Dev Platform 2021-02-22,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i73ktj:",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Support --install-action for Ninja builds,SERVER-48203,1350582,New Feature,In Code Review,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,daniel.moody,ryan.egesdahl,ryan.egesdahl,May 13 2020 09:24:34 PM UTC,Feb 09 2021 03:17:55 PM UTC,Feb 17 2021 11:15:16 AM UTC,,,,,,5.0 Desired,Build,,,,0,,,,,,"We [recently|https://mongodbcr.appspot.com/583630003/] added a workaround for compile_ninja so it sets install-action=default to work around the fact that non-default actions do not work with Ninja. The reason: Ninja has no idea what an install-action even is because that's up in the SCons layer. This workaround is mildly hackish, and it would be a better idea to fix the Ninja generator to implement the SCons install-action.",,,,,,,,,,,,SERVER-54232,,,,,,,,,,,,,,,,,,,,6.0,3.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2020-09-13 15:16:36.0,1123200,,,,,,,,PM-2101,,,,,,,,,,,,,,,,,,,,false,acm(acm),Wed Feb 03 16:02:06 UTC 2021,,,,,,,,,,,,,,acm(acm),daniel.moody(JIRAUSER1253549),milkie(milkie),redbeard0531(redbeard0531),ryan.egesdahl(ryan.egesdahl),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i68xmn:",,,,,,,"0|i007ef:",9223372036854775807,,,,,,,,,,,,Dev Platform 2021-01-25,Dev Platform 2021-02-08,Dev Platform 2021-02-22,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i68vq7:","Sep 13 2020 03:16:36 PM UTC;milkie;I see that SERVER-25534 is marked as a duplicate of this ticket - but is that a mistake?  The descriptions of the work for the two tickets are very different, and they are describing two different problems to be solved.","Sep 14 2020 03:50:57 AM UTC;ryan.egesdahl;[~milkie] The work in SERVER-25534 is obsoleted by the work in this ticket. We can already do {{\--install-action=hardlink}} with SCons builds, which is functionally similar to the work described in SERVER-25534, except that it is applicable to all filesystems including btrfs. The work in this ticket involves applying that work to Ninja builds as well.","Sep 14 2020 12:50:41 PM UTC;milkie;Understood - thank you!","Feb 03 2021 03:47:40 PM UTC;redbeard0531;This is actually different from SERVER-25534 in the same way that reflink is different from a hardlink. A reflink is semantically an independent copy that just happens to share the underlying blocks using copy-on-write semantics in the file system. A hardlink is semantically shared because changes via one path show up via accesses to the other path. It is always safe to replace a copy with a reflink (if it is supported by the filesystem), but it is risky to replace it with a hardlink.","Feb 03 2021 03:53:17 PM UTC;acm;[~redbeard0531] - The point of this ticket is to make the configurability that we have at the SCons level apply at the Ninja level as well. Therefore, it does support what you want because you will be able to inform Ninja of whether you want copies, hardlinks, reflinks, {{install}}, or anything else. I think everyone understands the difference between a hardlink and a reflink.
","Feb 03 2021 04:02:06 PM UTC;redbeard0531;My comment was in reply to [~ryan.egesdahl]'s above, explaining why this ticket doesn't actually cover the behavior requested in SERVER-25534. That was a request to just Do The Right Thing on filesystems that support reflinks, rather than about adding configurability.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Perform TTL deletions on clustered indexes,SERVER-54007,1599101,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,louis.williams,gregory.wlodarek,gregory.wlodarek,Jan 25 2021 05:18:06 AM UTC,Feb 08 2021 07:03:33 PM UTC,Feb 17 2021 11:15:16 AM UTC,,,,,,5.0 Required,Indexing,,,,0,,,,,,"The TTL monitor only works on index specifications with the {{expireAfterSeconds}} option present. Because collections with clustered indexes do not have an {{_id}} index entry, the TTL monitor will skip them. The TTL monitor will have to be updated to handle clustered indexes. The TTL monitor only performs deletions on ranged index scans.  The TTL monitor should perform deletions using ranged collection scans on collections with clustered indexes.",,,,,,,,SERVER-53984,SERVER-54008,,,,,,,,,,,,,,,,,,,,,,,1.0,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2021-02-01 18:22:56.0,1296000,"<s><a href='https://jira.mongodb.org/browse/SERVER-53984'>SERVER-53984</a></s>, <a href='https://jira.mongodb.org/browse/SERVER-54008'>SERVER-54008</a>",,,,,,,PM-288,,,,,,,,,,,,,,,,,,,,true,louis.williams(louis.williams),Mon Feb 01 18:22:56 UTC 2021,,,,,,,,,,,,,,gregory.wlodarek(gregory.wlodarek),louis.williams(louis.williams),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i7f5lb:",,,,,,,"0|i78wvj:",9223372036854775807,,,,,,,,,,,,Execution Team 2021-02-22,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i7f3ov:","Feb 01 2021 06:22:56 PM UTC;louis.williams;Delete the default control.min.time TTL index.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Make variadic whenAny implementation,SERVER-53558,1580199,New Feature,In Code Review,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,tyler.seip,matthew.saltz,matthew.saltz,Jan 04 2021 05:55:35 PM UTC,Feb 08 2021 05:12:05 PM UTC,Feb 17 2021 11:15:16 AM UTC,,,,,,,Internal Code,,,,0,servicearch-wfbf-day,,,,,"[whenAny|https://github.com/mongodb/mongo/blob/801219cbc992f929abb0135d7425bedeb7587297/src/mongo/util/future_util.h#L515] is a function that takes in a vector of futures and returns a future that is resolved as soon as one of its inputs resolves. Because it takes a vector, users sometimes have to first construct a vector prior to using the function, which causes additional lines of code and also can be a hassle since the vector will likely contain ExecutorFutures, which are not copyable and so an initializer list cannot be used for vector construction (and leads to complicated compiler errors). 

So currently you have to write something like:
{code:cpp}
// Does not compile:
// auto futures = {std::move(deadlineReachedFuture), std::move(someOtherFuture)};
// Does not compile for same reason:
//whenAny({std::move(deadlineReachedFuture), std::move(someOtherFuture)}).thenRunOn(executor).then(...);

std::vector<ExecutorFuture<void>> futures;
futures.emplace_back(std::move(deadlineReachedFuture));
futures.emplace_back(std::move(someOtherFuture));
whenAny(futures).thenRunOn(executor).then(...);
{code} 

I think it would be worth making a variadic version of whenAny, so that you could instead do:
{code:cpp}
whenAny(std::move(deadlineReachedFuture), std::move(someOtherFuture))
    .thenRunOn(executor)
    .then(...);
{code}

Since a two-future usage of whenAny seems like it will be a common case (especially with deadlines), we could also choose to just have a single special case that just takes two parameters. I think if we chose the latter, however, it might make sense to make it something different entirely and have it support different input types for the different futures.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,3715200,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,ratika.gandhi(ratika.gandhi),2021-01-04 17:55:35.0,,,,,,,,,,,,,,matthew.saltz(matthew.saltz),tyler.seip(JIRAUSER1257743),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i7bwyv:",,,,,,,"0|i7ankf:",9223372036854775807,,,,,,,,,,,,Service Arch 2021-02-08,Service Arch 2021-02-22,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i7bv2f:",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Provide highlighting of results from full text search,SERVER-13532,130285,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-query-execution,christkv,christkv,Apr 09 2014 09:04:48 PM UTC,Feb 08 2021 04:40:36 PM UTC,Feb 17 2021 11:15:17 AM UTC,,,,,,features we're not sure of,Text Search,,,,7,,,,,,"Currently there is no way to know what text in a document matched the query. 2.4 did include the field queryDebugString but that is also gone in 2.6. I think it's worthwhile to look at how elastic search provides this functionality.

http://www.elasticsearch.org/guide/en/elasticsearch/reference/current/search-request-highlighting.html

The motivation is any search view that contains documents (think pubmed or other scientific search engines)

This should preferably be an option",,,,,,,,,,,,FREE-76448,FREE-80323,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2021-02-08 16:40:36.0,691200,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,g.raviteja@gmail.com(JIRAUSER1258641),Mon Feb 08 16:40:36 UTC 2021,,,,,,,,No,,,,,,backlog-query-execution(JIRAUSER1257109),christkv(christkv),g.raviteja@gmail.com(JIRAUSER1258641),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i02jkv:",,,,,,,"0|i0105j:",111693,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i00vm7:","Feb 08 2021 04:40:36 PM UTC;g.raviteja@gmail.com;Until there is official solution, a solution that may work work, is to use projection condition.

Projection could look something like this (assuming documents containing field1, field2, both of which are added to text index):

 


{code:java}
{
 ""field1"": 1,
 ""is_field1_matched"": {""$gt"": [{""$size"": { ""$setIntersection"": [ <your search string split into array>, { ""$split"": [ { ""$toLower"": ""$field1"" }, "" "" ] } ] }}, 0]},
 ""field2"": 1, 
 ""is_field2_matched"": {""$gt"": [{""$size"": { ""$setIntersection"": [ <your search string split into array>, { ""$split"": [ { ""$toLower"": ""$field2"" }, "" "" ] } ] }}, 0]},
 ""score"": {""$meta"": ""textScore""}
}{code}
 

This projection filter only applies on documents after main query filter is applied. So, performance should be fine. 

One could also remove [stop words|https://github.com/mongodb/mongo/blob/0e3b3ca8480ddddf5d0105d11a94bd4698335312/src/mongo/db/fts/stop_words_english.txt] from <your search string split into array> (depending on your text index language), so that the result more accurately matches what the text index has done. ",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
libdeps analyzer: create evergreen build task,SERVER-53531,1577888,New Feature,In Code Review,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,daniel.moody,daniel.moody,daniel.moody,Dec 28 2020 05:03:05 PM UTC,Feb 08 2021 04:24:56 PM UTC,Feb 17 2021 11:15:17 AM UTC,,,,,,5.0 Desired,,,,,0,,,,,,"Create an evergreen build task to run the generate-libdeps-graph target, and then run the gacli.py command line tool. It may be useful to output the result of gacli to a file which is uploaded to the AWS bucket.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,4.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,4320000,,,,,,,,PM-1112,,,,,,,,,,,,,,,,,,,,true,april.schoffer(april.schoffer),2020-12-28 17:03:05.0,,,,,,,,,,,,,,daniel.moody(JIRAUSER1253549),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i7bipb:",,,,,,,"0|i007fj:",9223372036854775807,,,,,,,,,,,,Dev Platform 2021-01-11,Dev Platform 2021-01-25,Dev Platform 2021-02-08,Dev Platform 2021-02-22,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i7bgsv:",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Implement $dateTrunc in SBE,SERVER-54391,1616231,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,mindaugas.malinauskas,mindaugas.malinauskas,mindaugas.malinauskas,Feb 08 2021 04:21:21 PM UTC,Feb 08 2021 04:22:40 PM UTC,Feb 17 2021 11:15:17 AM UTC,,,,,,5.0 Required,,,,,0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,691200,,,,,,,,PM-1933,,,,,,,,,,,,,,,,,,,,true,mindaugas.malinauskas(JIRAUSER1252520),2021-02-08 16:21:21.0,,,,,,,,,,,,,,mindaugas.malinauskas(JIRAUSER1252520),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i7i2zb:",,,,,,,"0|i7bpgf:",9223372036854775807,,,,,,,,,,,,Query Execution 2021-02-22,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i7i12v:",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Need a command that lists all connections to/from a given mongos or mongod,SERVER-26705,325409,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-server-servicearch,andrew.young,andrew.young,Oct 19 2016 10:42:28 PM UTC,Feb 08 2021 01:27:42 PM UTC,Feb 17 2021 11:15:17 AM UTC,,,,,,Backlog,Networking,,,,11,service_architecture,,,,,"The currentOp(true) command does not always return a list of all open connections to and from a given mongos or mongod.  This is especially true on a mongos where the command instead calls currentOp() on the primary nodes of each shard and merges the results together.

I need a reliable way to determine what connections are currently open to and from a given mongos or mongod server.  This list should correspond to the connection count from db.serverStatus().connections.",,,,,,,,PM-1050,,,,SERVER-5261,SERVER-18470,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,500A000000VmLhcIAF,500A000000VE63LIAT,5002K00000d14sTQAQ,5002K00000gfDfVQAU,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2018-08-15 22:18:35.0,67564800,<s><a href='https://jira.mongodb.org/browse/PM-1050'>PM-1050</a></s>,,,,,,,PM-1236,,,,,,,,,,,,,,,,,,,,true,nicholas.cottrell(nicholas.cottrell),Fri Dec 28 00:22:21 UTC 2018,,,,,,,,,,,,,,andrew.young(andrew.young),backlog-server-servicearch(backlog-server-servicearch),greg.mckeon(greg.mckeon),kjmd75(kjmd75),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i01i53:",,,,,,,"0|i04rin:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i0wkq7:","Aug 16 2018 08:02:12 PM UTC;greg.mckeon;Since investigating, we've determined that this ticket is more than a change to the existing behavior of currentOp and will have user facing changes.  Removing from Quick Wins and moving to track this as an epic for scheduling at our next quarterly planning.","Dec 28 2018 12:22:21 AM UTC;kjmd75;Couldn't you add a new call (totalOps or connectionInfo or creativeNameHere) instead of changing currentOp?  I assume that's the biggest delay in delivering this...the impact to existing users.  My need is slightly different than the requestor, but I definitely see his point.  My need is to be able to show the total connections from a specific client host.  So a group by on clients with the connection counts.  This is very helpful when you have a single client spamming connections into your mongod.  This is pretty trivial with other database platforms, I'm actually quite shocked there isn't already a solution for this outside of parsing log messages.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Replicate capped collection deletes explicitly,SERVER-16049,168240,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,gregory.wlodarek,milkie,milkie,Nov 10 2014 05:15:59 PM UTC,Feb 05 2021 04:04:48 PM UTC,Feb 17 2021 11:15:17 AM UTC,,,,,,5.0 Required,Replication,,,,0,,,,,,Rather than letting them be implicit in the capped collection logic when you insert documents at the front.,,,,,,,,,,,,SERVER-30256,SERVER-21512,PM-223,,,,,,,,,,,,,,,,,,1.0,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2016-07-11 23:13:45.0,9072000,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,gregory.wlodarek(gregory.wlodarek),Wed Nov 04 03:38:16 UTC 2020,7.0,,,,,,,,,,,,,daniel.gottlieb(daniel.gottlieb@10gen.com),milkie(milkie),gregory.wlodarek(gregory.wlodarek),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i038nb:",,,,,,,"0|i00cqn:",147115,,,,,,,,,,,,Execution Team 2021-02-08,Execution Team 2021-02-22,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i0ymx3:","Nov 04 2020 03:38:16 AM UTC;daniel.gottlieb;I reflagged this for scheduling. I believe the only reasons to do implicit deletion for capped collections was due to MMAP (where capped collections were effectively circular buffers).",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Expose an absolute dirty size to the eviction configuration parameters,SERVER-38815,664785,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,dianna.hohensee,dmitry.agranat,dmitry.agranat,Jan 03 2019 10:24:26 AM UTC,Feb 05 2021 04:02:44 PM UTC,Feb 17 2021 11:15:17 AM UTC,,,,,,Backlog,WiredTiger,,,,3,,,,,,,,,,BACKPORT-6265,BACKPORT-6266,BACKPORT-6267,BACKPORT-6268,,,,,WT-3632,HELP-8455,,,,,,,,,,,,,,,,,,,1.0,5.0,,,,,,,,,,,,v3.6,v4.0,v4.2,v4.4,,,,,5002K00000lka58QAA,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2020-05-27 21:05:41.0,22896000,,,,,,,,PM-1869,,,,,,,,,,,,,,,,,,,,true,dianna.hohensee(dianna.hohensee),Wed May 27 21:05:41 UTC 2020,,,,,,,,,,,,,,dianna.hohensee(dianna.hohensee),dmitry.agranat(dmitry.agranat),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i30x0n:",,,,,,,"0|i72ofb:",9223372036854775807,,,,,,,,,,,,Storage Engines 2019-01-28,Execution Team 2020-05-04,Execution Team 2020-05-18,Execution Team 2020-06-01,Execution Team 2021-03-08,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i30v4f:","May 27 2020 09:05:41 PM UTC;dianna.hohensee;So WT's solution in WT-3632 appears to have been to sort of overload all of the eviction settings. 0 to 100 values are considered percentages of cache; while >100 settings are consider an absolute size.

We do not pass eviction settings through MongoDB today. We won't change that. I will add a new MongoDB server parameter just for absolute dirty cache size.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Backup/Restore of individual databases/collections with FS backups,SERVER-23573,277927,New Feature,In Progress,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,michael.gargiulo,alex.komyagin,alex.komyagin,Apr 06 2016 05:10:16 PM UTC,Feb 05 2021 03:52:34 PM UTC,Feb 17 2021 11:15:17 AM UTC,,,,,,Backlog,Usability,WiredTiger,,,10,,,,,,"For big deployments where mongodump/mongorestore approach is not feasible and backups are taken at FS level, we need way to restore individual databases and/or collections to the original system and to some other, new system. This feature is critical for success of those users who have multi-TB multi-tenant clusters and only want to restore a part of it.

With MMAP you could do the per-db backup/restore when directoryPerDb is used, but we no longer have the ability to use that approach in WT as WT metadata files are global for all namespaces. It will segfault if some *.wt files are not present.

However, with WT we have the advantage of individual files per namespace, so it should be possible to extract them and their metadata from an existing dbpath. Perhaps we will need a separate tool for that.",,,,,,,,,,,,SERVER-19043,HELP-2063,CS-33303,PM-1875,,,,,,,,,,,,,,,,,11.0,4.0,,,,,,,,,,,,,,,,,,,,5002K00000ej89qQAA,5002K00000hwy60QAA,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2016-04-12 09:07:12.0,3628800,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,connie.chen(connie.chen),Tue Jan 05 19:28:16 UTC 2021,,,,,,,,,,,,,,alex.komyagin(alex.komyagin@10gen.com),chris.kuethe@gmail.com(chris.kuethe@gmail.com),kmanchev@epo.org(kmanchev@epo.org),michael.gargiulo(michael.gargiulo),paul.reed(paul.reed),paul.reed@gprxdata.com(paul.reed@gprxdata.com),ramon.fernandez(ramon.fernandez),logwriter(logwriter),rodrigo@logwriter.net(rodrigo@logwriter.net),yliu01(yliu01),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i020dz:",,,,,,,"0|i72ohz:",9223372036854775807,,,,,,,,,,,,Execution Team 2021-01-11,Execution Team 2021-01-25,Execution Team 2021-02-08,Execution Team 2021-02-22,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i0x7l3:","Apr 12 2016 09:07:12 AM UTC;ramon.fernandez;I'm linking SERVER-19043, since I think the functionality described there could be used to implement this ticket.","Aug 25 2016 01:17:48 PM UTC;yliu01;I am facing the same issue now. the backup strategy seems the same for WT with system snapshot. But can't restore the individual DB by copying individual folder. Even there is configuration folder per DB. 

It's critical for us too. 

Thanks,
Mei","Oct 11 2016 01:59:35 AM UTC;logwriter;I just got trapped by this issue. 

I was trying to implement a backup/restore strategy that requires a per-db restore, but because of WiredTiger global metadata I wasn't able to deploy it. 

It would be really useful if we could be able to restore per-db from a snapshot.

For a multi-tenant deployment this feature is extremely important. 

All the best,

Rodrigo","Nov 26 2016 09:30:37 AM UTC;kmanchev@epo.org;We face the same issue as well , we have 4TB databases in WT(snappy) same cluster , and there is multiple changes in one of them which is ~500GB , with the mmapv1 it was easy just to backup/restore  the file system folder snapshot  inside dbPath , now with WT we need to backup/restore full fs snapshot of all the 4TB considering the rest of databases are not changing often.

Moreover  using mongodump/mongorestore on huge snappy/zlib WT compressed databases it just takes too much time as the mongodump is uncompressed and sending/receiving data to the mongod is just times slower than filesystem snapshot ...

I guess splitting the metadata in dbPath in separate files for every database folder inside dbPath shall not be such difficult task for the dev team considering the database wt-files are already separated in the folders?

Cheers,
Kiko
","Jun 16 2017 05:00:52 AM UTC;chris.kuethe@gmail.com;I would very much like to see this happen.","Jul 04 2018 05:01:33 PM UTC;paul.reed;+*Now MMAPv is being deprecated.*+ 

Can we have this feature please or SERVER_1903. I would truly love to move to WiredTiger, but cannot without folder level backup/restores.

Also - I worry about how to restore in the case of a catalog/meta file corruption - which I have seen several posts about with complicated salvage operations required to bring even a small database back in.

 

Please please please prioritize this.

 

 

 ","Oct 02 2019 07:40:11 PM UTC;paul.reed@gprxdata.com;Another year goes by, and another time I plead for this ticket to be given some airtime.

Is there any movement forward with a solution which would work, and thus allow me to move to the latest version.

 ","Oct 08 2019 06:56:52 PM UTC;rodrigo@logwriter.net;I share your pain Paul Reed. Looking forward to seeing this feature implemented within Wiredtiger. 

I understand it would involve some changes in the way WiredTiger deals with metadata, but from my perspective, it could be done.","Dec 10 2020 08:47:27 PM UTC;paul.reed@gprxdata.com;Hoooooorrrraaaayyyyyyyyyyyy

:):):):):):):):):):):):):):):):):):):):):):):):):):):):):):):)

Finally I will be able to move to WT and refactor out all the old work arounds. I am sooooo happy about this, only took 5 years !!!

Any insight into how this will materialize itself ?

 ","Jan 05 2021 03:56:42 PM UTC;michael.gargiulo;[~paul.reed@gprxdata.com] This feature, in some capacity, full import/export of live collection files, will be available in the next major release of MongoDB in 2021.

However, at this time, this feature will not be generally available in Community or Enterprise Advanced, but will only be available for internal use in our SaaS offering. 

We are exploring other work that will have selective import/export capabilities, as fully requested in this ticket, along with how to release this for general use. ","Jan 05 2021 07:28:16 PM UTC;paul.reed@gprxdata.com;Please release this in community version. ",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Allow TTLMonitor to use existing indexes starting with Date field,SERVER-13938,136375,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,bynn.lee,alonho,alonho,May 14 2014 08:47:26 AM UTC,Feb 05 2021 03:16:22 PM UTC,Feb 17 2021 11:15:17 AM UTC,,2.4.10,,,,Backlog,Storage,,,,1,TTLMonitor,,,,,"If the composite index starts with the Date field, the TTLMonitor's queries would be as fast and will not require an extra index.

We have lots of time-series data with composite indexes starting with Date, we're forced to create the TTL index although it's used solely by the TTLMonitor.",,,,,,,,,,,,SERVER-9305,PM-223,,,,,,,,,,,,,,,,,,,0.0,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2014-06-23 16:29:11.0,213494400,,,,,,,,PM-1869,,,,,,,,,,,,,,,,,,,,true,gregory.noma(gregory.noma),2014-05-14 08:47:26.0,,,,,,,,No,,,,,,alonho(alonho),bynn.lee(JIRAUSER1253412),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i03k7j:",,,,,,,"0|i00cs7:",117350,,,,,,,,,,,,Execution Team 2021-03-08,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i0z28n:",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Allow to check if a point is within ellipse on sphere,SERVER-47217,1299428,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,kateryna.kamenieva,kateryna.kamenieva,kateryna.kamenieva,Apr 01 2020 12:56:49 AM UTC,Feb 05 2021 01:35:04 PM UTC,Feb 17 2021 11:15:17 AM UTC,,4.5 Desired,,,,Backlog,Geo,,,,0,qexec-team,,,,,"The use case from astronomical research team at CalTech: identify if the coordinates of the object (point) fall within the galaxy (boundaries are described as ellipse).
 Currently ellipse is not supported natively, so the workaround is to store parameters of ellipses (not as geo data), use $geoWithin to perform search within much larger circle area and process data further in the code, which produces a lot of overhead.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,1.0,4.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2020-04-05 19:01:37.0,27388800,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,ana.meza(JIRAUSER1257467),Sun Apr 05 19:01:37 UTC 2020,,,,,,,,,,,,,,kateryna.kamenieva(kateryna.kamenieva),pawel.terlecki(pawel.terlecki),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i60dsf:",,,,,,,"0|i72vfj:",9223372036854775807,,,,,,,,,,,,Query 2020-11-30,Query 2021-01-11,Query 2021-01-25,Query Execution 2021-02-22,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i60bvz:","Apr 05 2020 07:01:37 PM UTC;pawel.terlecki;I believe they could encode their second filter as a UDF in 4.4 or even using $where in 4.2. I am curious if that would improve performance or quite the opposite.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
remove dependency on scanning replica set monitor in dbclient_rs_test,SERVER-54291,1612311,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-server-sharding,lamont.nelson,lamont.nelson,Feb 04 2021 04:19:51 PM UTC,Feb 04 2021 10:43:19 PM UTC,Feb 17 2021 11:15:17 AM UTC,,,,,,5.0 Required,,,,,0,sharding-remove-scanning-rsm,sharding-wfbf-day,,,,,,,,,,,,SERVER-54290,,,,SERVER-52899,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,Fully Compatible,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,1036800,<a href='https://jira.mongodb.org/browse/SERVER-54290'>SERVER-54290</a>,,,,,,,,,,,,,,,,,,,,,,,,,,,true,ratika.gandhi(ratika.gandhi),2021-02-04 16:19:51.0,,,,,,,,,,,,,,backlog-server-sharding(backlog-server-sharding),lamont.nelson(lamont.nelson),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i7hewv:",,,,,,,"0|i7b22v:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i7hd0f:",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
remove dependency on scanning replica set monitor in  tenant_migration_recipient_service_test,SERVER-54292,1612328,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-server-sharding,lamont.nelson,lamont.nelson,Feb 04 2021 04:23:50 PM UTC,Feb 04 2021 10:43:11 PM UTC,Feb 17 2021 11:15:17 AM UTC,,,,,,5.0 Required,,,,,0,sharding-remove-scanning-rsm,sharding-wfbf-day,,,,,,,,,,,,SERVER-54290,,,,SERVER-52899,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,Fully Compatible,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,1036800,<a href='https://jira.mongodb.org/browse/SERVER-54290'>SERVER-54290</a>,,,,,,,,,,,,,,,,,,,,,,,,,,,true,ratika.gandhi(ratika.gandhi),2021-02-04 16:23:50.0,,,,,,,,,,,,,,backlog-server-sharding(backlog-server-sharding),lamont.nelson(lamont.nelson),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i7hf0n:",,,,,,,"0|i7b25j:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i7hd47:",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
USDT unittest python tester,SERVER-41850,809788,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-server-servicearch,nathan.brown,nathan.brown,Jun 20 2019 10:36:06 PM UTC,Feb 04 2021 10:34:55 PM UTC,Feb 17 2021 11:15:17 AM UTC,,,,,,Backlog,,,,,0,devtools-to-servicearch,,,,,"In order to ensure USDT probes are being passed the right parameters, test eBPF programs will have to read out data from them and perform tests. This is related to  SERVER-41834. This ticket will coordinate with the testing harness that ticket generates to obtain information about which probes to attach to, and what values to expect out of them. The python tester will generate eBPF programs and attach them to the probes it is told and perform assertions on the type of data it reads out.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,4.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,52444800,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,ratika.gandhi(ratika.gandhi),2019-06-20 22:36:06.0,,,,,,,,,,,,,,backlog-server-servicearch(backlog-server-servicearch),nathan.brown(nathan.brown),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i3pd73:",,,,,,,"0|i02ukv:",9223372036854775807,,,,,,,,,,,,Dev Tools 2019-07-01,Dev Tools 2019-07-15,Dev Tools 2019-07-29,Dev Tools 2019-08-12,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i3pbav:",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Migrate to std::optional,SERVER-26542,322313,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-server-servicearch,acm,acm,Oct 09 2016 08:25:17 PM UTC,Feb 04 2021 10:28:03 PM UTC,Feb 17 2021 11:15:17 AM UTC,,,,,,Backlog,Portability,,,,0,devtools-to-servicearch,,,,,"Originally this ticket was about using std::optional where possible, and boost::optional elsewhere. The idea of this polyfill was we could avoid including the boost headers in many places if the system provides a std::optional (from std::experimental or similar). After some investigation, the ticket is now about *replacing* our use of boost::optional with std::optional entirely.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,5.0,,,,,,,,,,,,,,,,,Fully Compatible,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2019-06-24 20:54:13.0,7776000,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,ratika.gandhi(ratika.gandhi),Wed Nov 18 17:49:21 UTC 2020,,,,,,,,,,,,,,jesse(jesse),acm(acm),backlog-server-servicearch(backlog-server-servicearch),billy.donahue(billy.donahue),jason.carey(jason.carey),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i01iyf:",,,,,,,"0|i01lhz:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i0wm5r:","Jun 24 2019 08:54:13 PM UTC;jesse;[Bartek has a list of boost/std::optional differences|https://www.bfilipek.com/2018/05/using-optional.html#migration-from-boostoptional], I think these two matter to us:

* boost::optional has get_ptr() but std::optional doesn't. We use get_ptr in about 39 places which would have to be replaced.
* A disengaged boost::optional equals boost::none, but a disengaged std::optional equals std::nullopt. We use boost::none in about 1772 places. We'd have to typedef our own stdx::nullopt as either std::nullopt or boost::none depending on which is available.","Jun 25 2019 01:51:53 PM UTC;acm;[~jesse] - To be honest that doesn't sound that bad since most would be an easy search and replace. If we are going to do it I think we probably wouldn't even polyfill, just cut straight over to std::optional. I guess the other question is what if anything we gain by switching over. I'd expect [~redbeard0531], [~adam.martin@mongodb.com] and [~jason.carey] may have opinions. My feeling is that we are getting along just fine with {{boost::optional}}. On the other hand if something coming in C++20 makes deeper connection with {{std::optional}} we could end up with an annoying impedance mismatch if we were still on {{boost::optional}} when we got there.","Jun 25 2019 04:56:13 PM UTC;jason.carey;deduction guides (like those on std::optional) might also be nice.

I think I agree with [~acm].   I'm in the camp of: ""using std types is a nice, but this looks like a wide change that delivers relatively little value"".  I'm not too worried that we're going to run into bad implementations of std::optional (like we have for variant), it's just a lot of motion for a world that's basically where we are today.

In terms of future integration with the language, I'm not aware of anything that's currently returning an optional in the standard lib.  The only area I see work kicking around is in support for <=> for optional.  But I'd assume that's something that would make it's way to boost (with the same semantics) if/when that lands

 ","Jun 29 2019 01:30:01 PM UTC;acm;I propose we remove this from the C++17 epic, retitle it to ""Migrate to std::optional"", and take it out of the sprint. The re-titled ticket can live on the backlog until we decide that a sufficient motivation has emerged to make the switch over to {{std::optional}}.","Nov 18 2020 05:49:21 PM UTC;billy.donahue;There are significantly more significant differences between boost::optional and std::optional than the previously mentioned {{get_ptr}} and {{boost::none}}.

The hardest one is that boost::optional_io.hpp provides an {{operator<<}} for {{optional<T>}}. This is not sfinae-friendly and will static-assert at you if you try to call it. A boost::optional<T> always appears to be streamable whether T is really streamable or not. This ALREADY screws up detection traits for streamability in frameworks like fmtlib, logv2, StatusWith, or unittest asserts, which all have to handle boost::optional as a special case.

    https://github.com/boostorg/optional/blob/develop/include/boost/optional/optional.hpp#L1594
In those places we are trying to do a structurally recursive traits check for a property like streamability and they need to each be rewritten to correctly identify and define a convention for std::optional streaming (easiest is to just reuse the boost/optional_io.hpp output format). There's a generic pluggable-policy-based solution to problems of this type that I think would make an interesting project for reuse across our stringification, logging, and BSON libraries and greatly offload their complexity and redundancy. Kind of a SAX-like descent protocol. Then we can stop reinventing this wheel.

I've prototyped making the custom changes to each of the places where we do structurally recursive visitation for streamability here: https://github.com/mongodb/mongo/compare/master...BillyDonahue:boost_optional_io_wean?expand=1
This gets us completely out of the optional_io.hpp business.

The most common operations on an optional are has_value() and value(). These would have to be identified and renamed from boost's is_initialized() and get(), respectively. Here's a tool to do that.
https://github.com/BillyDonahue/llvm-project/compare/master...BillyDonahue:boost-optional-migration?expand=1
We can also change these to {{operator*}} and {{operator->}} and {{explicit operator bool}} expressions which would yield code that works in EITHER boost::optional or std::optional.

There are a few uses of {{boost::optional<T&>}}, which isn't supported in std::optional. All uses in our codebase seem to be unnecessary cleverness that can be trivially replaced with {{T*}} without change of semantics.

There are conditional constructors in boost::optional that std::optional doesn't have. They take a (bool,T&&) kind of signature, constructing an empty optional if the bool is false. These are easily rewritten and there aren't that many of them. Maybe 10 or 20.

Boost::optional has some monadic operations like value_or which std::optional has. Others like map and flat_map are missing from std::optional but we have only a couple of uses that can spell it out with explicit lambdas.

There's a difference between boost::optional::value_or and boost::optional::get_value_or, which is deprecated because it returns a reference that's often dangling. We should scrub our code of get_value_or anyway, but this migration would make the scrub mandatory.

The get_ptr problem isn't so bad. All call sites in practice can be replaced with a ternary {{(opt?&*opt:nullptr)}}. At most calls of {{get_ptr}} (there are not that many), we already tested the opt's bool value and can just replace {{opt.get_ptr()}} with {{&*opt}}.

More trivial things:

Obviously we'd have to rewrite the #include lines.

Replace all the declarations of:
    boost::optional to std::optional
    boost::none to std::nullopt
    boost::none_t to std::nullopt_t
    boost::in_place to std::in_place
    boost::in_place_t to std::in_place_t

IDL would need some minor surgery to make it emit std::optional compatible code. That was pretty easy to do.

",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Create a withTimeout helper function for Futures,SERVER-54033,1600033,New Feature,Needs Scheduling,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-server-servicearch,tyler.seip,tyler.seip,Jan 25 2021 08:46:02 PM UTC,Feb 04 2021 07:58:07 PM UTC,Feb 17 2021 11:15:17 AM UTC,,,,,,,Internal Code,,,,0,servicearch-wfbf-day,,,,,"[whenAny|https://github.com/mongodb/mongo/blob/801219cbc992f929abb0135d7425bedeb7587297/src/mongo/util/future_util.h#L515] is a function that takes in a vector of futures and returns a future that is resolved as soon as one of its inputs resolves. This function is currently used to create futures with [timeouts|http://example.com/]. Since we anticipate this functionality being used quite often, create a free function which allows timeouts to be declared on Futures easily.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,1900800,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,ratika.gandhi(ratika.gandhi),2021-01-25 20:46:02.0,,,,,,,,,,,,,,backlog-server-servicearch(backlog-server-servicearch),tyler.seip(JIRAUSER1257743),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i7fbcf:",,,,,,,"0|i792mn:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i7f9fz:",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Increment bytesCopied and documentsCopied in ReshardingCollectionCloner,SERVER-53909,1595498,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,billy.donahue,lamont.nelson,lamont.nelson,Jan 20 2021 04:41:31 PM UTC,Feb 04 2021 07:16:30 PM UTC,Feb 17 2021 11:15:17 AM UTC,,,,,,5.0 Required,,,,,0,PM-234-T-autocommits,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,1.0,,,,,,,,,,,,,,,,Fully Compatible,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2332800,,,,,,,,PM-234,,,,,,,,,,,,,,,,,,,,true,ratika.gandhi(ratika.gandhi),2021-01-20 16:41:31.0,,,,,,,,,,,,,,billy.donahue(billy.donahue),lamont.nelson(lamont.nelson),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i7ejdb:",,,,,,,"0|i78bif:",9223372036854775807,,,,,,,,,,,,Sharding 2021-02-22,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i7ehgv:",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Add cancelation support to WaitForMajorityService using CancelationTokens,SERVER-50656,1458179,New Feature,Blocked,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,george.wangensteen,matthew.saltz,matthew.saltz,Aug 31 2020 08:47:35 PM UTC,Feb 04 2021 07:14:52 PM UTC,Feb 17 2021 11:15:17 AM UTC,,,,,,5.0 Required,Internal Code,,,,0,,,,,,"[waitUntilMajority|https://github.com/mongodb/mongo/blob/f0893e135f9c0dcc68e5189756dc3299674cfb35/src/mongo/db/repl/wait_for_majority_service.h#L64-L67] should accept a CancelationToken. When the token is canceled, it should remove the appropriate OpTime from [this map|https://github.com/mongodb/mongo/blob/f0893e135f9c0dcc68e5189756dc3299674cfb35/src/mongo/db/repl/wait_for_majority_service.h#L80] and the request's future must be signalled, but only if this was the only request pointing to that OpTime. This may require us to change from using SharedPromise to instead use something like a multimap with multiple promises/futures per OpTime.",,,,,,,,,,,,SERVER-54155,,,,,,,,,,,,,,,,,,,,2.0,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2020-12-02 16:34:56.0,1036800,,,,,,,,PM-1423,,,,,,,,,,,,,,,,,,,,true,ratika.gandhi(ratika.gandhi),Thu Feb 04 17:45:37 UTC 2021,,,,,,,,,,,,,,george.wangensteen(george.wangensteen),xgen-internal-githook(xgen-internal-githook),matthew.saltz(matthew.saltz),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i6r1db:",,,,,,,"0|i6z08v:",9223372036854775807,,,,,,,,,,,,Service arch 2020-12-28,Service Arch 2021-03-08,,,,,,,,3.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i6qzgv:","Feb 04 2021 07:10:22 AM UTC;xgen-internal-githook;Author:{'name': 'George Wangensteen', 'email': 'george.wangensteen@mongodb.com', 'username': 'gewa24'}
Message: SERVER-50656 Add cancellation support to WaitForMajorityService
Branch: master
https://github.com/mongodb/mongo/commit/da77452821c355346d873a6b31160c101adc60de","Feb 04 2021 05:45:37 PM UTC;xgen-internal-githook;Author:{'name': 'George Wangensteen', 'email': 'george.wangensteen@mongodb.com', 'username': 'gewa24'}
Message: Revert ""SERVER-50656 Add cancellation support to WaitForMajorityService""

This reverts commit da77452821c355346d873a6b31160c101adc60de.
Branch: master
https://github.com/mongodb/mongo/commit/3b4c40b136da419512bf6501655473db552efb11",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Make version of Shard::runCommand that returns a future,SERVER-50342,1444487,New Feature,In Progress,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,matthew.saltz,matthew.saltz,matthew.saltz,Aug 17 2020 07:41:33 PM UTC,Feb 04 2021 07:11:51 PM UTC,Feb 17 2021 11:15:17 AM UTC,,,,,,5.0 Required,Internal Code,,,,0,,,,,,"The current Shard::runCommand function is blocking, which means that clients who need to contact a shard in an asynchronous fashion are required to implement retry logic on their own. It would be good to have an asynchronous version of runCommand that appropriately handles retry logic. The implementation may be a free function rather than part of the Shard interface if it is more convenient.",,,,,,,,SERVER-50658,SERVER-51298,,,SERVER-50371,,,,,,,,,,,,,,,,,,,,0.0,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,15811200,"<s><a href='https://jira.mongodb.org/browse/SERVER-50658'>SERVER-50658</a></s>, <s><a href='https://jira.mongodb.org/browse/SERVER-51298'>SERVER-51298</a></s>",,,,,,,,,,,,,,,,,,,,,,,,,,,true,ratika.gandhi(ratika.gandhi),2020-08-17 19:41:33.0,,,,,,,,,,,,,,matthew.saltz(matthew.saltz),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i6ooxr:",,,,,,,"0|i6z0af:",9223372036854775807,,,,,,,,,,,,Service Arch 2021-02-22,,,,,,,,,5.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i6on1b:",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Add CancelationTokens to scheduleExhaustCommand APIs in TaskExecutor,SERVER-51283,1497844,New Feature,In Code Review,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,tyler.seip,matthew.saltz,matthew.saltz,Oct 01 2020 05:29:04 PM UTC,Feb 04 2021 07:10:33 PM UTC,Feb 17 2021 11:15:17 AM UTC,,,,,,Backlog,Internal Code,,,,0,,,,,,"This ticket is to add CancelationToken-accepting/future-returning versions of [these two functions|https://github.com/mongodb/mongo/blob/a854b05058f37d1d9e2cad987854fa44978d051c/src/mongo/executor/task_executor.h#L295-L303]. Adding CancelationTokens is straightforward, but since the callback is called multiple times, it's not as straightforward to make them return futures which are signaled when they are done, which is why this ticket is separate from SERVER-50658",,,,,,,,,,,,SERVER-52954,,,,,,,,,,,,,,,,,,,,2.0,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2021-02-04 17:50:07.0,4838400,,,,,,,,PM-1423,,,,,,,,,,,,,,,,,,,,true,ratika.gandhi(ratika.gandhi),Tue Dec 22 21:32:08 UTC 2020,,,,,,,,,,,,,,matthew.saltz(matthew.saltz),tyler.seip(JIRAUSER1257743),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i6xtin:",,,,,,,"0|i6z09z:",9223372036854775807,,,,,,,,,,,,Service Arch 2021-02-22,,,,,,,,,3.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i6xrm7:","Nov 19 2020 08:50:48 PM UTC;matthew.saltz;It's unclear whether this is needed or how difficult it will be. There might be a need for a large-scale refactoring for exhaust in order fo this to be possible in which case we might want to not do it. I also don't think we'll add many new uses of these functions but I'm not sure.","Dec 22 2020 09:32:08 PM UTC;matthew.saltz;After investigation, I think it won't be so bad. Mostly I think we just need to signal the returned future when the [moreToCome|https://github.com/mongodb/mongo/blob/251feeb575e30136547175a8d3eed20e023ea39b/src/mongo/executor/remote_command_response.h#L77] flag is set to false on a response. So the returned future will be resolved when the whole exhaust command has finished, and the CancelationToken will be used to cancel the entire exhaust command (not an individual callback).",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Add ability to opt out of collation for a specific operator or $lookup sub-pipeline,SERVER-53637,1583434,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-query-execution,charlie.swanson,charlie.swanson,Jan 07 2021 08:19:48 PM UTC,Feb 04 2021 05:05:09 PM UTC,Feb 17 2021 11:15:17 AM UTC,,,,,,Backlog,Aggregation Framework,,,,0,query-work-resharding,,,,,"As part of the resharding effort we need to run a pipeline with the collection's default collation, but then use the simple collation for a specific comparison concerning the chunk boundaries.

This ticket tracks the work to add that ability. Note this is different and narrower than SERVER-25954, since we need this relatively soon and it is believed that SERVER-25954 is a pretty substantial engineering effort. ",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,3456000,,,,,,,,PM-234,,,,,,,,,,,,,,,,,,,,true,ana.meza(JIRAUSER1257467),2021-01-07 20:19:48.0,,,,,,,,,,,,,,backlog-query-execution(JIRAUSER1257109),charlie.swanson(charlie.swanson),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i7cgxr:",,,,,,,"0|i76cev:",9223372036854775807,,,,,,,,,,,,Query Execution 2021-03-08,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i7cf1b:",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
New mechanism to force closure of connections when reaching maxIncomingConnections,SERVER-53342,1567279,New Feature,Needs Verification,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-server-servicearch,nicholas.cottrell,nicholas.cottrell,Dec 14 2020 12:43:46 PM UTC,Feb 02 2021 05:08:07 PM UTC,Feb 17 2021 11:15:17 AM UTC,,,,,,,Networking,,,,0,,,,,,"In some cases, a misbehaving client could open up thousands of connections in a short burst, causing a node to reach {{maxIncomingConnections}} and preventing both legitimate client operations and internal health ping and monitoring connections from being established.

I'd like to see a new server-side mechanism that kicks in when {{maxIncomingConnections}} is reached, somewhat analogous to a JVM garbage collector. This would identify stalled (or unused) connections and quickly force them closed, relieving connection pressure and allowing normal operations.

This would be necessary on both {{mongos}} instances as well as all {{mongod}} processes. ",,,,,,,,,,,,PRODUCT-544,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,5002K00000r4r8SQAQ,5002K00000saWneQAE,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,5529600,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,,2020-12-14 12:43:46.0,,,,,,,,,,,,,,backlog-server-servicearch(backlog-server-servicearch),nicholas.cottrell(nicholas.cottrell),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i79pav:",,,,,,,"0|i73oc7:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i79nef:",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Turn on GCP Atlas clusters on GCP for sys-perf,SERVER-37434,613255,New Feature,Backlog,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-server-perf,april.schoffer,april.schoffer,Oct 03 2018 01:28:14 AM UTC,Feb 01 2021 05:12:41 PM UTC,Feb 17 2021 11:15:17 AM UTC,,,,,,Backlog,Performance,,,,0,sys-perf-atlas-followup,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2018-10-03 02:35:00.0,74908800,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,april.schoffer(april.schoffer),Thu Oct 04 09:52:05 UTC 2018,,,,,,,,,,,,,,april.schoffer(april.schoffer),backlog-server-perf(backlog-server-perf),henrik.ingo(henrik.ingo@10gen.com),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i2s48n:",,,,,,,"0|i73qqf:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i2s2cf:","Oct 04 2018 09:52:05 AM UTC;henrik.ingo;This capture work for a terraform tf file to deploy a single workload client host on Azure, but not the sys-perf MongoDB clusters. Note that the current plan is that Atlas tests will only be scheduled manually from the Evergreen UI, so none of them will run ""regularly"" such as daily. (In practice it is up to the cloud team as to what and when to test, such as before they want to deploy something to prod.)",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Add wire protocol compression performance test to sysperf performance tests,SERVER-25489,307365,New Feature,Backlog,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-server-perf,justin.cohler,justin.cohler,Aug 08 2016 08:24:02 PM UTC,Feb 01 2021 05:12:39 PM UTC,Feb 17 2021 11:15:17 AM UTC,,,,,,Backlog,Performance,,,,0,investigation,pperf,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,1.0,4.0,,,,,,,,,,,,,,,,Fully Compatible,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2016-08-13 01:38:56.0,142473600,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,april.schoffer(april.schoffer),Sat Aug 13 01:38:56 UTC 2016,,,,,,,,,,,,,,acm(acm),backlog-server-perf(backlog-server-perf),justin.cohler(justin.cohler),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i01p0f:",,,,,,,"0|i76i8n:",9223372036854775807,,,,,,,,,,,,Platforms 2016-08-26,Platforms 2016-09-19,Platforms 2016-10-10,Platforms 2016-10-31,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Not Needed,,,,,,,,,,,,,,,,,,,"0|i0wu93:","Aug 13 2016 01:38:56 AM UTC;acm;I'm taking this out of the epic, since it isn't gating for this feature to considered complete.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Turn on Azure Atlas cluster in Azure,SERVER-37433,613254,New Feature,Backlog,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-server-perf,april.schoffer,april.schoffer,Oct 03 2018 01:27:15 AM UTC,Feb 01 2021 05:12:14 PM UTC,Feb 17 2021 11:15:17 AM UTC,,,,,,Backlog,Performance,,,,0,sys-perf-atlas-followup,,,,,Turn on Azure Atlas cluster in Azure,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,74995200,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,april.schoffer(april.schoffer),2018-10-03 01:27:15.0,,,,,,,,,,,,,,april.schoffer(april.schoffer),backlog-server-perf(backlog-server-perf),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i2s48f:",,,,,,,"0|i73qq7:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i2s2c7:",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Expose more granular stats about TTL deletions,SERVER-45111,1050717,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-query-execution,ivan.grigolon,ivan.grigolon,Dec 12 2019 08:58:33 PM UTC,Jan 30 2021 12:21:26 AM UTC,Feb 17 2021 11:15:17 AM UTC,,,,,,Backlog,Indexing,,,,1,,,,,,"With the value {{serverstatus.metrics.ttl.deletedDocuments}} we can know the total number of documents deleted from collections with a ttl index (in other words we combine all the documents deleted by every TTL index in one value)

We should introduce metrics on ""per TTL index"" so that we can differentiate how many document are deleted by each TTL index.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,3.0,,,,,,,,,,,,,,,,,,,,,5002K00000iQ9DhQAK,5002K00000sajpyQAA,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2019-12-13 14:18:49.0,37065600,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,,Mon Dec 16 08:07:09 UTC 2019,,,,,,,,,,,,,,backlog-query-execution(JIRAUSER1257109),bruce.lucas(bruce.lucas@10gen.com),carl.champain(carl.champain),dayo.lasode@yodel.co.uk(dayo.lasode@yodel.co.uk),ivan.grigolon(ivan.grigolon),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i4u8t3:",,,,,,,"0|i00zcn:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i4u6wv:","Dec 13 2019 02:18:49 PM UTC;carl.champain;[~ivan.grigolon],

Passing this ticket along to the Query team.","Dec 13 2019 09:02:58 PM UTC;bruce.lucas;As far as I know we don't currently have any per-namespace information in serverStatus. This could potentially be a very large number of fields, which could be a problem for ftdc. Maybe this information would be more at home in collStats. If it is put into serverStatus, it would be good to make it optional and excluded from ftdc.","Dec 16 2019 08:07:09 AM UTC;dayo.lasode@yodel.co.uk;This will be a useful metric at the document level to help review document turnover ",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Add a mode to resmoke to bisect changes,SERVER-53951,1596849,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-server-stm,robert.guo,robert.guo,Jan 21 2021 06:21:36 PM UTC,Jan 29 2021 09:49:31 PM UTC,Feb 17 2021 11:15:17 AM UTC,,,,,,Backlog,Testing Infrastructure,,,,0,,,,,,"Add a {{resmoke bisect}} sub-command that wraps around {{git bisect}}. It'll compile the Server and run resmoke with a repeat of 100 to capture flakiness tests under git-bisect.

We need users to be able to configure the compile and resmoke commands based on git commits. Something like the following:

{code:yaml}
- startGitVersion: xyz
   setupCommand: source ./script-to-setup-venv-and-install-pip-dependencies
   compileCommand: scons ijk
   resmokeCommand: resmoke.py abc
- startGitVersion: xyz
   compileCommand: scons ijk
   resmokeCommand: resmoke.py abc
{code}

- We will need to make a template of the config YAML with global changes to resmoke and compile steps, e.g. {{resmoke.py -> resmoke.py run}}. 
- The script will need to be tested on Ubuntu 1804 (which is the majority of virtual workstations). We'll make a best-effort to ensure it works cross platform by avoid using platform-specific code where possible. ",,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Jan 29 2021 09:48:20 PM UTC;charlie.swanson;bisect.sh;https://jira.mongodb.org/secure/attachment/297846/bisect.sh",,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2021-01-21 19:52:13.0,1555200,,,,,,,,PM-2157,,,,,,,,,,,,,,,,,,,,true,charlie.swanson(charlie.swanson),Fri Jan 29 21:49:31 UTC 2021,,,,,,,,,,,,,,backlog-server-stm(backlog-server-stm),charlie.swanson(charlie.swanson),robert.guo(robert.guo),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i7erpb:",,,,,,,"0|i78jlb:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i7epsv:","Jan 29 2021 09:49:31 PM UTC;charlie.swanson;Hi all. I just found my bisect script I have written and used recently. I uploaded it here. I think I used it to track down a change between 4.2 and 4.4 branches somewhere. It's pretty ugly and complex, but I think it serves well to illustrate some of the problems we run into when trying to run git bisect. In my case the 'resmoke.ini' file changed and caused issues, as did the name of the build targets and the build target install directories.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Query/Write USDT (User-level Statically Defined Tracing) tracepoints,SERVER-35145,547558,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-server-servicearch,ricardo.lorenzo,ricardo.lorenzo,May 22 2018 02:42:19 PM UTC,Jan 29 2021 07:42:19 PM UTC,Feb 17 2021 11:15:17 AM UTC,,,,,,Backlog,Diagnostics,Querying,Storage,,1,service-architecture-dev-tools-triaged,,,,,"This ticket is a continuation of SERVER-33394 and is intended to define some example initial tracing points for queries and write operations as discussed in the previously mentioned ticket.

The following is the list of example tracing points to insert into the application:
 * Lock acquired (lock type, operation)
 * Lock released (lock type, operation) 
 * Thread start (thread name) 
 * Thread wait (IPC related)
 * Thread end (thread name) 
 * Query stage start (readConcern, query shape, stage, database, collection)
 * Query stage end (readConcern, query shape, stage, database, collection)
 * Query saveState (query shape, stage, database, collection)
 * Query restoreStage (query shape, stage, database, collection)
 * Query parse start
 * Query parse end
  * Query plan cached (query shape, database, collection)

 * WiredTiger table key read
 * WiredTiger table value read
 * WiredTiger cursor created
 * WiredTiger cursor search start
 * WiredTiger cursor search end
 * WiredTiger cursor next start
 * WiredTiger cursor next end
 * WiredTiger cursor prev start
 * WiredTiger cursor prev end
 * WiredTiger cursor insert start
 * WiredTiger cursor insert end
 * WiredTiger cursor update start
 * WiredTiger cursor update end
 * WiredTiger cursor remove start
 * WiredTiger cursor remove end
 * WiredTiger cache hit
 * WiredTiger cache miss

 * WiredTiger block checksuming start (file, offset, size)
 * WiredTiger block checksuming end (file, offset, size)
 * WiredTiger block read start (file, offset, size)
 * WiredTiger block read ends (file, offset, size)

 * WiredTiger checkpoint start
 * WiredTiger checkpoint end
 * WiredTiger journal file write start (file)
 * WiredTiger journal file write end (file)

 * Write operation start (type, writeConcern)
 * Write operation end (type, writeConcern)
 * Write operation waiting for replication start (type, writeConcern)
 * Write operation waiting for replication ends (type, writeConcern)",,,,,,,,,,,,SERVER-33394,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,86486400,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,ratika.gandhi(ratika.gandhi),2018-05-22 14:42:19.0,,,,,,,,,,,,,,backlog-server-servicearch(backlog-server-servicearch),ricardo.lorenzo(ricardo.lorenzo),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i2h153:",,,,,,,"0|i03esv:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i2gz8v:",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Support OpenTracing in MongoD and MongoS,SERVER-41106,766353,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-server-servicearch,john.festa,john.festa,May 13 2019 01:47:14 PM UTC,Jan 29 2021 07:40:27 PM UTC,Feb 17 2021 11:15:17 AM UTC,,,,,,Backlog,Internal Code,,,,1,move-sa,service-architecture-dev-tools-triaged,,,,"I'm working with a customer who is requesting OpenTracing support in the Mongo Go Driver as well as the core server (mongod, mongos). The customer is looking to collect metrics, many of which are collected in the diagnostics folder, but correlated with individual requests. 

I see there was a previously created Jira to add OpenTracing to the Go Driver which was resolved ""wont fix"" with an indication the functionality can be built on top of the command monitoring API. https://jira.mongodb.org/browse/GODRIVER-739

Please let us know if OpenTracing support is something that can be considered for acceptance into the engineering stream and if not, an alternative mechanism to achieve some of the same benefits.

Reference:

[https://opentracing.io|https://opentracing.io/]

 ",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2019-05-13 14:20:53.0,10972800,,,,,,,,PM-1514,,,,,,,,,,,,,,,,,,,,true,ratika.gandhi(ratika.gandhi),Mon Oct 12 22:19:13 UTC 2020,,,,,,,,,,,,,,backlog-server-servicearch(backlog-server-servicearch),bartle(bartle),john.festa(john.festa),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i3i7wf:",,,,,,,"0|i05qyv:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i3i607:","Oct 12 2020 10:19:13 PM UTC;bartle;I'd also be interesting in seeing support for this.  If we can agree upon a framework/proposal we could look into doing the work to get it supported.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Allow clients to add context to oplog,SERVER-47313,1302868,New Feature,Investigating,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,evin.roesle,vasi@stripe.com,vasi@stripe.com,Apr 02 2020 11:39:02 PM UTC,Jan 28 2021 06:30:26 PM UTC,Feb 17 2021 11:15:17 AM UTC,,4.2.5,,,,,Write Ops,,,,0,,,,,,"When a document is mutated, it would be very handy to be able to audit what caused the mutation to happen. However, the oplog doesn't currently include much client context.

Ideally, clients could add some context, eg:

{code}
db.runCommand({
  insert: mycoll,
  documents: [{_id: ""myid""}],
  oplogContext: {""some"": ""document}
})
{code}

And then this context could appear in the oplog:

{code}
{
  ""ts"": Timestamp(1585854690, 1),
  ""t"": NumberLong(1),
  ...
  ""context"": {""some"": ""document}
}
{code}

",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,3.0,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2020-04-03 14:45:08.0,1641600,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,vasi@stripe.com(vasi@stripe.com),Thu Jan 28 18:30:26 UTC 2021,,,,,,,,,,,,,,carl.champain(carl.champain),vasi@stripe.com(vasi@stripe.com),evin.roesle(evin.roesle),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i60z0n:",,,,,,,"0|i5x0zb:",9223372036854775807,,,,,,,,,,,,Repl 2020-04-20,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i60x47:","Apr 03 2020 02:45:08 PM UTC;carl.champain;Hi [~vasi@stripe.com],

Thank you for the report.
We're assigning this ticket to the appropriate team to be evaluated against our currently planned work. Updates will be posted on this ticket as they happen.

 Kind regards,
 Carl
  ","Apr 09 2020 11:29:59 PM UTC;vasi@stripe.com;We're working on rolling out a patch against 3.6 locally, we'd be happy to share privately for now (and publicly once we do more testing and make sure it's safe).","Jan 28 2021 06:30:26 PM UTC;vasi@stripe.com;Here's a patch we've been running for a bit against 3.6.9: https://github.com/vasi/mongo/commit/234089669bb3f779f926549850a8311939a70718 . We also have one against 4.0, it's similar.

Is this something Mongo upstream is interested in?",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
POC Evergreen task documentation,SERVER-54002,1598707,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-server-stm,robert.guo,robert.guo,Jan 24 2021 02:38:36 AM UTC,Jan 26 2021 04:08:53 PM UTC,Feb 17 2021 11:15:17 AM UTC,,,,,,5.0 Desired,Testing Infrastructure,,,,0,,,,,,"Add a YAML configuration to resmokeconfig with {{evergreen task name: documentation}} key value pairs. Resmoke will print out the documentation for its {{task_name}} when a task_name is passed in through the command line and when documentation is available.  

Since generated tasks have arbitrary suffixes, we should remove any pure numerical suffixes in the task name after the last underscore. (e.g. ""_123"" should be removed, but ""_abc"" should not)",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,3.0,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2021-01-25 15:52:16.0,1814400,,,,,,,,PM-2157,,,,,,,,,,,,,,,,,,,,true,brooke.miller(brooke.miller),Tue Jan 26 16:04:42 UTC 2021,,,,,,,,,,,,,,backlog-server-stm(backlog-server-stm),charlie.swanson(charlie.swanson),robert.guo(robert.guo),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i7f35r:",,,,,,,"0|i78uif:",9223372036854775807,,,,,,,,,,,,STM 2021-04-19,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i7f19b:","Jan 25 2021 03:52:16 PM UTC;charlie.swanson;[~robert.guo] I'm curious about this ticket and idea. Do you have any more details or can you point me to where the request came from?","Jan 25 2021 04:49:12 PM UTC;robert.guo;Both are great ideas! I'll file a DAG ticket for the BFG/BF addition.

For the build-level doc, it might be misleading to add the description to the ticket as the BF is arbitrarily chosen and could be on any build variant. Given the relatively few number of build variants compared with tasks, maybe we can create a separate document with all the ""unique"" build variants?","Jan 26 2021 04:04:42 PM UTC;charlie.swanson;I'm not sure I follow your last point... Is it that any given BF can affect multiple variants? I hear that and I don't think the explanation would be as useful there. But isn't it also true that a BF can be multiple suites? e.g. something like an invariant. Seems like a worthwhile problem to think about in either case.

We obviously don't want to overwhelm people with a wall of text, but I think having this available in cases where it's a single variant or single suite would be very valuable.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Allow majority read concern for replication for backup node use-case,SERVER-39001,672483,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-server-repl,bartle,bartle,Jan 15 2019 04:41:02 AM UTC,Jan 26 2021 03:09:46 PM UTC,Feb 17 2021 11:15:17 AM UTC,,,,,,Backlog,,,,,0,,,,,,"One common configuration is to have a non-voting, hidden backup node.  One would then take e.g. hourly filesystem or EBS snapshots of the node.  One potential issue with this approach is that it's possible that a backup snapshot might wind up with data that is rolled back, e.g. if the primary fails at the same time a s apshot is taken.  One approach to address this is to use delayed replication of e.g. 5 min, and hope that is sufficient to avoid observing the rollback (I'm not sure of the oplog is fixed up during a rollback or not, so perhaps this isn't actually sufficient).  Instead, a more robust solution would be to allow the backup node's replication thread/query to use read concern majority.  Presumably this would require that you set the node to priority 0/hidden, the same restrictions on delayed replication.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,4.0,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2019-01-15 22:36:43.0,25920000,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,steven.vannelli(steven.vannelli),Thu Apr 23 05:51:04 UTC 2020,,,,,,,,,,,,,,alyson.cabral(alyson.cabral),backlog-server-repl(backlog-server-repl),daniel.hatcher(daniel.hatcher),bartle(bartle),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i328in:",,,,,,,"0|i35jtb:",9223372036854775807,,,,,,,,,,,,Repl 2019-02-25,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i326mf:","Jan 15 2019 10:36:43 PM UTC;daniel.hatcher;Hello David,

Thank you for your report. I have assigned this ticket to our Replication team to take a look.

Danny","Feb 05 2020 04:59:46 PM UTC;alyson.cabral;[~bartle] Hey Bartle, is this a case where you're using backups for compliance? I just want to clarify that once a backup is restored to a node, that node will undergo rollback if necessary. ","Feb 05 2020 08:01:16 PM UTC;bartle;We'd typically either run a mongod standalone against the snapshot (e.g. to pull historic data, or to validate something in our ETL pipeline), or would bring up a replset with each member running against the snapshot.  I don't think we'd ever restore a single node in an existing replset off of a snapshot, though, which I agree would trigger a rollback if necessary.","Apr 23 2020 05:51:04 AM UTC;bartle;Another place where this could be useful is to recover from poisoned oplog entries that cause all secondaries to crash loop.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
ReshardingRecipientService instances to load metrics state upon instantiation,SERVER-53912,1595523,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-server-sharding,lamont.nelson,lamont.nelson,Jan 20 2021 05:00:27 PM UTC,Jan 25 2021 06:56:45 PM UTC,Feb 17 2021 11:15:17 AM UTC,,,,,,5.0 Required,,,,,0,PM-234-T-autocommits,,,,,Should instantiate ReshardingMetrics object with the persisted metrics.,,,,,,,,SERVER-53915,,,,,,,,,,,,,,,,,,,,,,,,1.0,1.0,,,,,,,,,,,,,,,,Fully Compatible,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2332800,<a href='https://jira.mongodb.org/browse/SERVER-53915'>SERVER-53915</a>,,,,,,,PM-234,,,,,,,,,,,,,,,,,,,,true,lamont.nelson(lamont.nelson),Thu Jan 21 01:41:51 UTC 2021,,,,,,,,,,,,,,backlog-server-sharding(backlog-server-sharding),lamont.nelson(lamont.nelson),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i7ejiv:",,,,,,,"0|i78bjr:",9223372036854775807,,,,,,,,,,,,Sharding 2021-04-19,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i7ehmf:","Jan 21 2021 01:41:51 AM UTC;lamont.nelson;SERVER-53915 persists the recipient metrics.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
ReshardingRecipientService metrics should be periodically persisted,SERVER-53915,1595534,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-server-sharding,lamont.nelson,lamont.nelson,Jan 20 2021 05:11:14 PM UTC,Jan 25 2021 06:56:05 PM UTC,Feb 17 2021 11:15:17 AM UTC,,,,,,5.0 Required,,,,,0,PM-234-T-autocommits,,,,,"Only the oplog applier metrics need to be tracked specially. The others are tracked on per-collection basis.

oplog applier:
https://github.com/mongodb/mongo/blob/06b4a33530bfd58fab55e1fdda506b51f75f1ec5/src/mongo/db/s/resharding/resharding_oplog_applier.h#L56

current progress update code:
https://github.com/mongodb/mongo/blob/6308db5c83a3e95f4532c63df8b635b8090036ae/src/mongo/db/s/resharding/resharding_oplog_applier.cpp#L470
",,,,,,,,SERVER-53910,,,,,,,,,,,,,,,,,,,,,,,,1.0,1.0,,,,,,,,,,,,,,,,Fully Compatible,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2332800,<a href='https://jira.mongodb.org/browse/SERVER-53910'>SERVER-53910</a>,,,,,,,PM-234,,,,,,,,,,,,,,,,,,,,true,ratika.gandhi(ratika.gandhi),Wed Jan 20 22:38:50 UTC 2021,,,,,,,,,,,,,,backlog-server-sharding(backlog-server-sharding),lamont.nelson(lamont.nelson),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i7ejlb:",,,,,,,"0|i78blz:",9223372036854775807,,,,,,,,,,,,Sharding 2021-04-19,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i7ehov:","Jan 20 2021 10:38:50 PM UTC;lamont.nelson;One test case that was discussed: 
- start resharding operation
- Perform N inserts while the operation is ongoing
- assert.soon those inserts are accounted for in the metrics",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Create commitReshardCollection command,SERVER-53916,1595540,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-server-sharding,lamont.nelson,lamont.nelson,Jan 20 2021 05:16:06 PM UTC,Jan 25 2021 06:45:00 PM UTC,Feb 17 2021 11:15:17 AM UTC,,,,,,5.0 Required,,,,,0,PM-234-T-autocommits,,,,,"Should return error if the specified resharding operation does not exist or has completed already.
Should enter the critical section of the resharding operation if not already reached.
Should durably record decision to commit the resharding operation if not already done.
Should ensure the original colleciton is removed and the temporary collection assumes the original's name upon success.

The commit flow is already implemented for resharding. This ticket is about introducing a new promise/future pair that the [ReshardingCoordianator|https://github.com/mongodb/mongo/blob/master/src/mongo/db/s/resharding/resharding_coordinator_service.h#L74] waits on and is fulfilled by the commitReshardCollection command.

We should consider adding a server parameter to preserve the existing ""reshardin commits as quickly as possible"" style of behavior to avoid impacting existing tests.",,,,,,,,SERVER-53918,SERVER-53923,,,,,,,,,,,,,,,,,,,,,,,0.0,1.0,,,,,,,,,,,,,,,,Fully Compatible,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2332800,"<a href='https://jira.mongodb.org/browse/SERVER-53918'>SERVER-53918</a>, <a href='https://jira.mongodb.org/browse/SERVER-53923'>SERVER-53923</a>",,,,,,,PM-234,,,,,,,,,,,,,,,,,,,,true,lamont.nelson(lamont.nelson),2021-01-20 17:16:06.0,,,,,,,,,,,,,,backlog-server-sharding(backlog-server-sharding),lamont.nelson(lamont.nelson),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i7ejmn:",,,,,,,"0|i78bnb:",9223372036854775807,,,,,,,,,,,,Sharding 2021-03-22,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i7ehq7:",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Limit resource usage for certain users,SERVER-15072,155290,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-server-servicearch,jon.rangel,jon.rangel,Aug 28 2014 12:52:58 PM UTC,Jan 22 2021 08:03:25 PM UTC,Feb 17 2021 11:15:17 AM UTC,,,,,,Needs Further Definition,Admin,Concurrency,Querying,Security,14,,,,,,"In some special cases (such as debugging a prod issue) users would like to provision read-only access for different participants in these kind of scenarios (developers, architects and so on).
Additionally, it is desired to to prevent those users from affecting the performance of the production application, or at least limit the performance impact of any interaction these users may have with the database.

We should consider adding a mechanism to limit the resource usage for a set of users.  For example:
- Limit the number/rate of operations that can be executed.
- Limit the execution time of operations (kind of like an automatic $maxTimeMS that is enforced for these users).
- Define different execution priorities for different users.
- Allow access only to secondaries for investigation; don't allow queries to be run on the primary.",,,,,,,,,,,SERVER-3807,CS-14627,CS-27596,PRODUCT-110,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,500A000000YfprPIAR,500A000000YSt0NIAT,5002K00000cxju3QAA,5002K00000ekC8CQAU,5002K00000hRkp5QAC,5002K00000kF9h5QAC,5002K00000oc2xqQAA,5002K00000pD5fOQAS,5002K00000pEsrBQAS,5002K00000plQgdQAE,5002K00000r4MzhQAE,5002K00000s2L9tQAE,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2014-09-02 16:01:13.0,79747200,,,,,,,,PM-1109,,,,,,,,,,,,,,,,,,,,true,,Wed Aug 08 17:17:49 UTC 2018,,,,,,,,,,,,,,backlog-server-servicearch(backlog-server-servicearch),benjamin.ogden(benjamin.ogden),jon.rangel(jon.rangel@10gen.com),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i03e53:",,,,,,,"0|i05n9z:",3845,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i0yu5z:","Aug 08 2018 05:17:49 PM UTC;benjamin.ogden;One way to partly address limiting resource usage for certain users could be to strictly enforce workload isolation to specific hosts. This could be achieved by mapping roles to tagged replica members, perhaps by expanding the authenticationRestrictions in a role/user document. When using readPreferenceTags to direct workload to some secondaries, the concern is that some users may (eventually will) omit the read preference / tag from their connection string and accidentally affect the application with longer running analytics queries.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
decode usdt parameters in eBPF,SERVER-41709,800837,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-server-servicearch,gabriel.russell,gabriel.russell,Jun 13 2019 06:28:00 PM UTC,Jan 22 2021 11:13:26 AM UTC,Feb 17 2021 11:15:17 AM UTC,,,,,,Backlog,,,,,0,,,,,,Explorer what the limits of decoding the usdt parameters in ebpf programs. Try to produce some reusable code for doing so. If this turns out to be mostly impossibly then document that here.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2021-01-22 11:13:26.0,53049600,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,josef.ahmad(josef.ahmad),2019-06-13 18:28:00.0,,,,,,,,,,,,,,backlog-server-servicearch(backlog-server-servicearch),gabriel.russell(gabriel.russell),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i3nvyn:",,,,,,,"0|i03esf:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i3nu2f:",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
decode usdt parameters in application ,SERVER-41710,800858,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-server-servicearch,gabriel.russell,gabriel.russell,Jun 13 2019 06:33:50 PM UTC,Jan 22 2021 11:09:11 AM UTC,Feb 17 2021 11:15:17 AM UTC,,,,,,Backlog,,,,,0,,,,,,"Assuming that a tracing tool is written in BCC, explore what parameter decoding can occur. Can we pass and decode bson easily. What about c++ objects. Produce some reusable component.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2021-01-22 11:09:11.0,53049600,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,josef.ahmad(josef.ahmad),2019-06-13 18:33:50.0,,,,,,,,,,,,,,backlog-server-servicearch(backlog-server-servicearch),gabriel.russell(gabriel.russell),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i3nw3b:",,,,,,,"0|i03esn:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i3nu73:",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
ReshardingCoordinator instances to load metrics state upon instantiation,SERVER-53914,1595529,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-server-sharding,lamont.nelson,lamont.nelson,Jan 20 2021 05:07:36 PM UTC,Jan 20 2021 11:49:13 PM UTC,Feb 17 2021 11:15:17 AM UTC,,,,,,5.0 Required,,,,,0,PM-234-T-autocommits,,,,,Should instantiate ReshardingMetrics object with the persisted data,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,1.0,,,,,,,,,,,,,,,,Fully Compatible,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2332800,,,,,,,,PM-234,,,,,,,,,,,,,,,,,,,,true,max.hirschhorn(max.hirschhorn@10gen.com),2021-01-20 17:07:36.0,,,,,,,,,,,,,,backlog-server-sharding(backlog-server-sharding),lamont.nelson(lamont.nelson),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i7ejk7:",,,,,,,"0|i78bl3:",9223372036854775807,,,,,,,,,,,,Sharding 2021-04-05,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i7ehnr:",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Ability to rename databases,SERVER-701,11424,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,brian.lane,ejones,ejones,Mar 04 2010 06:13:20 PM UTC,Jan 19 2021 01:16:46 PM UTC,Feb 17 2021 11:15:17 AM UTC,,,,,,Backlog,Usability,,,,211,,,,,,"{panel:title=Issue Status as of Apr 9, 2015|borderColor=#cccccc|titleBGColor=#6cb33f|bgColor=#eeeeee}
*[UPDATE Sep 10, 2019]*  
The ""copydb"" command is deprecated, please use these two commands instead: 
     1. [mongodump|https://docs.mongodb.com/manual/reference/program/mongodump/] (to back up data) 
     2. [mongorestore|https://docs.mongodb.com/manual/reference/program/mongorestore/] (to recover data from mongodump into a new namespace)

*---------------------- *

We are aware of how painful and long it is to rename a database in MongoDB. Unfortunately, this is not an simple feature for us to implement due to the way that database metadata is stored in the original (default) storage engine. In MMAPv1 files, the namespace (e.g.: dbName.collection) that describes every single collection and index includes the database name, so to rename a set of database files, every single namespace string would have to be rewritten. This impacts:
 - the .ns file
 - every single numbered file for the collection
 - the namespace for every index
 - internal unique names of each collection and index
 - contents of system.namespaces and system.indexes (or their equivalents in the future)
 - other locations I may be missing

This is just to accomplish a rename of a single database in a *standalone* mongod instance. For replica sets the above would need to be done on every replica node, plus on each node every single oplog entry that refers this database would have to be somehow invalidated or rewritten, and then if it's a sharded cluster, one also needs to add these changes to every shard if the DB is sharded, plus the config servers have all the shard metadata in terms of namespaces with their full names.

There would be absolutely no way to do this on a live system.

To do it offline, it would require re-writing every single database file to accommodate the new name, and at that point it would be as slow as the current ""copydb"" command.

Asya Kamsky,
MongoDB Product Team
{panel}

h6. Original description
Having the ability to rename databases would be nice.  That would allow things like cloning a database with straight file copies plus a rename (to avoid having to wait on index builds when using db.copyDatabase).",,,,,,,,,,,,CS-13336,CS-16425,,,,,,,,,,,,,,,,,,,44.0,,,,,,,,,,,,,,,,,,,,,500A000000UaSEwIAN,500A000000bBhlIIAS,5002K00000e7EIeQAM,5002K00000e9jhyQAA,5002K00000eikcfQAA,5002K00000huZsWQAU,5002K00000hueVmQAI,5002K00000kFW3ZQAW,5002K00000nDqe2QAC,5002K00000od8aLQAQ,5002K00000odmJDQAY,5002K00000pG7vZQAS,5002K00000s1lnRQAQ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2011-08-24 17:17:12.0,45532800,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,,Mon Sep 09 07:04:54 UTC 2019,,,,,,,,No,,,,,,zugwalt(zugwalt),alecyu(alecyu),mobafill(mobafill),amey.potnis@gmail.com(amey.potnis@gmail.com),farquaad(farquaad),andrey.hohutkin@gmail.com(andrey.hohutkin@gmail.com),anupk(anupk),asya(asya),bjornharvold(bjornharvold),bkonash(bkonash),brian.lane(brian.lane),ctonhaeuser(ctonhaeuser),dandv(dandv),amcgregor(amcgregor),djvw@redscreen.co.za(djvw@redscreen.co.za),airs0urce(airs0urce),crudson(crudson),ejones(ejones),gavinaiken(gavinaiken),jakiao(jakiao),guillermo85(guillermo85),ifor(ifor),diversario(diversario),brezniczky@gmail.com(brezniczky@gmail.com),jlyonsmith(jlyonsmith),pumpkin(pumpkin),justin@idle-games.com(justin@idle-games.com),kmehta(kmehta),legel(legel),maciej.gajewski(maciej.gajewski),m.korbakov@nimble.com(m.korbakov@nimble.com),nwerneck(nwerneck),reda(reda),rgpublic(rgpublic),rob_colella@volusion.com(rob_colella@volusion.com),sherryummen(sherryummen),sunnybg(sunnybg),hu.sesselmann@dsfishlabs.com(hu.sesselmann@dsfishlabs.com),hedefalk(hedefalk),kreig(kreig),ygbr(ygbr),,,,,,,,,,,,,,,,,,,"0|i07gd3:",,,,,,,"0|i03hov:",6061,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Completed,,,,,,,,,,,,,,,,,,,"0|i012xz:","Aug 24 2011 05:17:12 PM UTC;crudson;We get replacement datasets periodically and it would be helpful to just rename a db to some archived name, and keep using the original db name (without the fuss of copy/export/import and configuration management of db names).","Sep 26 2011 10:08:09 PM UTC;m.korbakov@nimble.com;Any plans for including it into coming releases? Having it solved would help us migrating to sharded MongoDB cluster.","Nov 20 2011 08:37:53 AM UTC;bjornharvold;I'd like to see this feature supported as well.","Jan 24 2012 02:05:21 PM UTC;ctonhaeuser;+1 for being able to rename databases.
Database names play a huge role in our application, so being able to rename them easily would be a killer feature.
Also, I don't really understand why a seemingly simple feature like this hasn't been implemented long ago, after all, this ticket is almost two years old now.","Jul 11 2012 12:57:46 PM UTC;gavinaiken;This would definitely give some flexibility in moving data around quickly as systems grow. Example use case - in EC2 (and many raid systems) you can take a quick snapshot of a running mongo db and create a new disk vol on another server almost immediately. So if you want to move a big collection onto its own server with almost no downtime, you do the snapshot procedure, drop the collection from the original server/db and drop all the other unwanted collections from the copied snapshotted db on the new server. It would be good to then rename the db on the new server as a final step to avoid confusion, and to avoid having to copy the data out and in again which could take hours. Otherwise you have the same db name on 2 different servers but with different collections in each.","Jul 17 2012 03:49:30 PM UTC;pumpkin;Another +1 for this new feature.
cloning the database every time we need to rename it is becoming a hassle.","Aug 02 2012 02:20:45 PM UTC;reda;this a medium priority requirement, i think it's an essential feature.","Sep 24 2012 09:30:59 PM UTC;jakiao;+1 for this feature as well.  It's confusing to think it isn't already supported and is only a minor priority issue.","Oct 29 2012 09:30:09 AM UTC;maciej.gajewski;+1","Feb 28 2013 10:53:38 AM UTC;ifor;+1 Getting the name right first time - isn't Agile","Apr 04 2013 06:07:40 PM UTC;bkonash;+1","Apr 27 2013 08:26:12 PM UTC;anupk;+1","May 10 2013 03:54:49 PM UTC;amey.potnis@gmail.com;+1","May 31 2013 06:53:24 PM UTC;justin@idle-games.com;+1

I'll add that the ability to do this while the server is down would be sufficient for my needs. I would think/hope that this should be as simple as renaming the files on the filesystem and updating some kind of internal metadata. A workaround or hack until the online in-server feature is finished would be acceptable.

I have already implemented all sorts of what I see as hacks when restoring a sharded cluster. I have to manually update all sorts of metadata in the config db to make a restored cluster work, even without renaming databases.","May 31 2013 07:37:45 PM UTC;kmehta;+1 Please add this feature! I get a monthly dataset and was hoping to slide my datasets to preserve historical data. I'm shocked this isn't supported. We really need this. Thanks.","Aug 19 2013 12:32:08 AM UTC;zugwalt;Renaming would be great for large databases","Sep 07 2013 08:58:17 AM UTC;hedefalk;+1","Oct 09 2013 07:13:37 PM UTC;nwerneck;I would like not just renaming, but also creating an ""alias"" would be nice. So for example we can have multiple dumps from some database with different names (their dates), but then have an alias that points to the most recent of them...","Nov 26 2013 03:29:16 PM UTC;diversario;How come that in the shell I can say {{db.rename('newname')}} and it works but I cannot do the same in the mongo shell script?","Nov 26 2013 03:41:44 PM UTC;rgpublic;@Ilya: According to this (http://stackoverflow.com/questions/15303409/how-to-rename-a-database-using-mongomapper-in-ruby) the db.rename Funktion is only a shell-specific wrapper for copyDatabase/dropDatabase. A real ""rename"" like proposed in this JIRA ticket doesn't exist yet.","Mar 07 2014 10:48:05 AM UTC;dandv;Adding my voice to this. I would much rather have a ""rename"" function, than having to wait for db.copyDatabase() to complete on my 2TB database.

Not to mention that you might not have enough disk space for two copies of your database, or you might needlessly pay for it.","Mar 12 2014 04:51:55 AM UTC;djvw@redscreen.co.za;Very good point @Dan_Dascalescu. I would hate to see what our maintenance guys think when you copy that much data in a production environment.","Jun 19 2014 08:58:40 AM UTC;kreig;Please implement this feature. It would save a lot of time not only for production environment. It takes realy a lot of time to restore databse from production backup, devs would be much happier with such handy command.","Oct 10 2014 10:54:12 AM UTC;sherryummen;so with my vote we have 150 votes; could this feature be considered in near future please. Or atleast an efficient workaround, rather we always copy everything? I am using C# Driver where _server.CopyDatabase() is also Obselete.","Nov 12 2014 04:09:57 PM UTC;rob_colella@volusion.com;Please add this feature as it is critical and should be standard in an enterprise environment. ","Nov 27 2014 08:25:07 AM UTC;alecyu;I've needed this features.
thanks","Dec 08 2014 11:59:05 PM UTC;guillermo85;Please add this feature, a future database server must rename his databases. Thanks!","Dec 18 2014 04:24:46 PM UTC;jlyonsmith;Hello!  Anybody in there...?  Pretty please?","Jan 19 2015 11:25:45 AM UTC;mobafill;Upvoted. I need to rename two databases right now, due to early project mistakes that now causing terms confusion. And seems like there is no easy way to do that. ","Feb 16 2015 03:46:19 PM UTC;sunnybg;How many votes are enough for this to be considered?","Mar 02 2015 09:47:23 AM UTC;andrey.hohutkin@gmail.com;It is urgent feature. Extremely needed for DB maintenance.","Mar 02 2015 10:13:43 AM UTC;mobafill;I'm writing again here (already upvoted) to confirm that we still need this. I've managed to rename one problematic database and it was a real pain to do that. I will not dare to do this on the second one as it's few terabytes large and it will take ages. 
A way to easily rename databases regardless of it's size is urgently required.

Philosophy of NoSQL in general and MongoDB particularly is about moving quickly without thorough long-term planning, allowing early mistakes and allowing to easily fix them later when you know what your architecture actually is. Not being able to easily fix database naming is not only a nuisance and a bugger, it's a major system inconsistency and goes across Mongo's ""Flexible Data Model"" mission statement. Being unable to rename database is not a flexible data model.
","Mar 10 2015 04:50:32 PM UTC;legel;Pretty ridiculous that a simple functionality like this is not provided...","Apr 06 2015 09:54:24 PM UTC;farquaad;Seriously this is classified as minor feature?!!! I am currently evaluating MongoDB for one of my clients, and, in all fairness, cannot recommend it as mature product with such basic functionality missing.","Apr 06 2015 10:19:45 PM UTC;alecyu;My manager is asking to moving out from mongo because of this (the major reason)","Apr 09 2015 03:05:33 PM UTC;asya;Folks,

We are aware of how painful and long it is to rename a database in MongoDB. Unfortunately, this is not an simple feature for us to implement due to the way that database metadata is stored in the original (default) storage engine. In MMAPv1 files, the namespace (e.g.: dbName.collection) that describes every single collection and index includes the database name, so to rename a set of database files, every single namespace string would have to be rewritten. This impacts:

- the .ns file
- every single numbered file for the collection
- the namespace for every index
- internal unique names of each collection and index
- contents of system.namespaces and system.indexes (or their equivalents in the future)
- other locations I may be missing

This is just to accomplish a rename of a single database in a *standalone* mongod instance. For replica sets the above would need to be done on every replica node, plus on each node every single oplog entry that refers this database would have to be somehow invalidated or rewritten, and then if it's a sharded cluster, one also needs to add these changes to every shard if the DB is sharded, plus the config servers have all the shard metadata in terms of namespaces with their full names.

There would be absolutely no way to do this on a live system. 

To do it offline, it would require re-writing every single database file to accommodate the new name, and at that point it would be as slow as the current ""copydb"" command.

Asya Kamsky,
MongoDB Product Team
","Apr 09 2015 03:20:54 PM UTC;mobafill;Hi Asya, 

thanks for detailed answer. 

That's unfortunate but understandable, however, what about WiredTiger storage?

Regards
Alex.","Apr 09 2015 03:46:48 PM UTC;asya;Hi Alex,

WredTiger storage engine fortunately keeps the metadata only in limited number of places.   However, we support (and encourage) migration between storage engines via the replica set, by being able to run different storage engines on different nodes.  We basically make a promise that any operation you perform on the primary will be able to replicate successfully to the other members.

Having said that, we are considering the future and what the implications of supporting a command that would not work on all the storage engines would be.  As you might imagine, we have to be extremely careful around this, so as not to break things unexpectedly.   In addition, we are very hesitant to add support for any commands which work on some configurations and don't on others (for example, we really want to make sure that we never add new commands that only work ""unsharded"" and then break when you move to a sharded cluster).

Asya
","Mar 10 2016 05:41:43 PM UTC;hu.sesselmann@dsfishlabs.com;Almost a year has passed - are there any news on this topic? :)","Oct 30 2017 08:43:08 PM UTC;ygbr;Any news on this for wiredtiger on MongoDB 3.4+ ?","Jul 20 2018 06:12:38 AM UTC;brezniczky@gmail.com;Again (and again) a year gone - any news perhaps?","Mar 08 2019 01:09:22 AM UTC;airs0urce;It takes a long time to move collection by collection in new database. Would be good to get ability to rename DB without copying all the data around.","Sep 05 2019 05:15:44 PM UTC;amcgregor;The initial recommendation in the absence of the ability to rename (for technical reasons which are _entirely solvable with a {{for}} loop_…) to use {{copyDatabase}} is problematic. Given {{copyDatabase}} has been hard-deprecated. (_Hard_ as in: *it no longer works*, even with a warning; it fails with an assertion error.)

What's particularly worse is that while the assertion provides a link to the relevant change log, [that change log|https://docs.mongodb.com/manual/release-notes/4.0-compatibility/#copydb-and-clone-commands] makes a recommendation that it does not follow through with an example. Use {{mongodump}} and {{mongorestore}}! I'd love to. How? Given I have BSON files exported to directory-per-db *and* {{--gzip --archive}} backups, and attempting to use the \{-d} option to target an alternate database issues:
{quote}the --db and --collection args should only be used when restoring from a BSON file. Other uses are deprecated and will not exist in the future; use --nsInclude instead
{quote}
C'mon, now. That suggestion / recommendation is outlandish when I'm not attempting to filter which database or collections are restored, I'm only trying to specify the destination database to populate.  (This message _might_ make sense during {{mongodump}}, where you probably are trying to filter, but not on restore.)  Which, after deeper investigation, should utilize {{nsFrom}} and {{nsTo}}, no? Thus the change log should point developers at the [mongorestore reference ""recipe"" for ""Change Collections' Namespaces during Restore""|https://docs.mongodb.com/manual/reference/program/mongorestore/#example-complex-wildcard-usage], specifically.  Or, even better, provide a concrete equivalent example to the old process.","Sep 09 2019 07:04:54 AM UTC;brian.lane;Hi [~amcgregor],

Thanks for the feedback.    I have created DOCS-13024 based on your comment.

Feel free to comment on DOCS-13024 in case I may have missed anything.

-Brian",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
allowing audit log to be send to a log management server instead of a file on the host,SERVER-42506,880038,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-server-security,jennifer.huang,jennifer.huang,Jul 30 2019 05:31:33 PM UTC,Jan 15 2021 10:32:24 AM UTC,Feb 17 2021 11:15:17 AM UTC,,,,,,4.3 Desired,Logging,Security,,,1,,,,,,"It'll be nice to be able to send the audit log or MongoD log to a server before it's written to a file on the localhost.

*Motivation*
Some customers are concerned about when the MongoD or MongoS process writing the audit log to a file, someone has access to the Linux user as the MongoD or MongoS process i.e all their DBAs can edit or delete the file.
So theoretically they can do something malicious then delete or amend the audit log to hide the fact that something bad have been done. 

*Ideal outcome*
In the --auditDestination option allowing people to specify hostname and port of the log management server, and maybe another two options --auditLogUser and --auditLogPassword if the server needs authentication.

Thanks
Jen",,,,,,,,,,,,SERVER-2957,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,5002K00000hukr8QAA,5002K00000ej078QAA,5002K00000s1POPQA2,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2019-08-02 14:59:37.0,48729600,,,,,,,,PM-1591,,,,,,,,,,,,,,,,,,,,true,,Fri Aug 02 14:59:37 UTC 2019,,,,,,,,,,,,,,backlog-server-security(backlog-server-security),jennifer.huang(jennifer.huang),nicholas.cottrell(nicholas.cottrell),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i41awn:",,,,,,,"0|i43hlj:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i4190f:","Aug 02 2019 02:59:37 PM UTC;nicholas.cottrell;Slightly relevant to this case/customer is SERVER-2957. I understand that despite the initial description mentioning ""remote syslog"" that the final implementation only supports a local syslog destination. It would be good if normal (non-audit) logs could also be sent directly to a remote log server.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Ability to customize collection compression level,SERVER-45690,1107978,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-server-storage-engines,platon.work@gmail.com,platon.work@gmail.com,Jan 22 2020 12:07:34 AM UTC,Jan 13 2021 11:12:08 PM UTC,Feb 17 2021 11:15:17 AM UTC,,4.2.2,,,,Backlog,,,,,2,,,,,,"At the moment, this setting is mentioned in the WiredTiger documentation: [http://source.wiredtiger.com/mongodb-4.0/compression.html]


But it cannot be applied in real practice:
{code:java}
coll_obj = db.create_collection(""test"", storageEngine={'wiredTiger': {'configString': 'block_compressor=zstd,compression_level=22'}})
{code}
{code:java}
Traceback (most recent call last):
 File ""/home/platon/_0_Диссертация/00_Скрипты/000_ld-tools-master/backend/create_intgen_db.py"", line 184, in <module>
 create_intgen_db(client)
 File ""/home/platon/_0_Диссертация/00_Скрипты/000_ld-tools-master/backend/create_intgen_db.py"", line 141, in create_intgen_db
 'block_compressor=zstd,compression_level=22'}})
 File ""/home/platon/miniconda3/lib/python3.7/site-packages/pymongo/database.py"", line 411, in create_collection
 read_concern, session=s, **kwargs)
 File ""/home/platon/miniconda3/lib/python3.7/site-packages/pymongo/collection.py"", line 184, in __init__
 self.__create(kwargs, collation, session)
 File ""/home/platon/miniconda3/lib/python3.7/site-packages/pymongo/collection.py"", line 264, in __create
 collation=collation, session=session)
 File ""/home/platon/miniconda3/lib/python3.7/site-packages/pymongo/collection.py"", line 250, in _command
 user_fields=user_fields)
 File ""/home/platon/miniconda3/lib/python3.7/site-packages/pymongo/pool.py"", line 613, in command
 user_fields=user_fields)
 File ""/home/platon/miniconda3/lib/python3.7/site-packages/pymongo/network.py"", line 167, in command
 parse_write_concern_error=parse_write_concern_error)
 File ""/home/platon/miniconda3/lib/python3.7/site-packages/pymongo/helpers.py"", line 159, in _check_command_response
 raise OperationFailure(msg % errmsg, code, response)
pymongo.errors.OperationFailure: 22: Invalid argument. [1579647776:829331][874:0x7f0f8cb3e700], wiredtiger_config_validate: config_check_search, 65: unknown configuration key: 'compression_level': Invalid argument.{code}",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,3.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2020-01-24 20:31:37.0,19785600,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,connie.chen(connie.chen),Thu Jul 02 22:21:20 UTC 2020,,,,,,,,,,,,,,backlog-server-storage-engines(backlog-server-storage-engines),carl.champain(carl.champain),oliver@sensortower.com(oliver@sensortower.com),platon.work@gmail.com(platon.work@gmail.com),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i53zhj:",,,,,,,"0|i01kyf:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i53xl3:","Jan 24 2020 08:31:37 PM UTC;carl.champain;Hi [~platon.work@gmail.com],

Thank you for the report.
I was able to successfully recreate the same error. I'm passing this ticket along to the appropriate team for further investigation.

Kind regards,
Carl
 ","Jul 02 2020 09:54:37 PM UTC;oliver@sensortower.com;+1 here!  According to [https://github.com/facebook/zstd] , zstd is now 38% faster than snappy at similar compression ratio.  We would love to be able to replace snappy with zstd if we're able to configure the compression ratio","Jul 02 2020 10:21:20 PM UTC;oliver@sensortower.com;Looks like [https://github.com/wiredtiger/wiredtiger/blob/7dfd9391862bc9a6d84868c4dc51689c45a3aacf/src/config/config_def.c] doesn't have ""compression_level""",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
User-Parameterized Views,SERVER-10789,90095,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-query-optimization,schwerin,schwerin,Sep 16 2013 06:35:53 PM UTC,Jan 09 2021 01:59:44 AM UTC,Feb 17 2021 11:15:17 AM UTC,,,,,,Backlog,Usability,,,,5,,,,,,"Supposing SERVER-10787 and maybe SERVER-10788, it would be nice to define a view whose contents are dependent on properties of the authenticated user searching it.",,,,,,,,,,,,PM-750,,,,,,,,,,,,,,,,,,,,7.0,,,,,,,,,,,,,,,,,,,,,500A000000ZMu0dIAD,5002K00000d6GocQAE,5002K00000d5iU1QAI,5002K00000plp8IQAQ,5002K00000s0YmgQAE,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2018-08-30 12:11:00.0,33609600,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,,Fri Jan 24 19:16:58 UTC 2020,,,,,,,,No,,,,,,schwerin(schwerin),asya(asya),backlog-query-optimization(JIRAUSER1257108),brunorenzo(brunorenzo),kateryna.kamenieva(kateryna.kamenieva),sgaylord@facilitron.com(sgaylord@facilitron.com),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i045mf:",,,,,,,"0|i00zfj:",4471,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i13xon:","Aug 30 2018 12:11:00 PM UTC;brunorenzo;Hi Andy,

You mean any given input parameter? If yes, that's exactly what I'm looking for as well.

Example:

A very simple aggregate to group information given a number of last days:
{code:javascript}db.collection.aggregate([
    {$match: {created: {$gte: new Date((new Date().getTime() - (30 * 86400000)))}}},
    {$group: {_id: ""$country"", totalDocs: {$sum: 1}}
]){code}
In this case, I would like to create a view that can receive as input parameter the number of days, so that I don't need to hard-code ""30"" in the $match.","Jan 02 2019 07:49:58 PM UTC;sgaylord@facilitron.com;We would like something like this as well. 

We would like to create the view but pass in the matching characteristics at run time, but currently that match is placed at the end of the pipeline. 

We have two collections and we want to pull data from one or the other for a specific entry passed in at runtime, so the view needs to be on the entire collection and then pass the match the specific entity at runtime.  This causes the view to do a COLLSCAN when called.","Jan 03 2019 12:41:50 AM UTC;asya;[~sgaylord@facilitron.com] aggregation pipeline has the ability to reorder stages to optimize the query plan it's able to use.

Does your view involve $group (or similar) stage where you only want a subset of the results?
","Jan 03 2019 04:36:11 PM UTC;sgaylord@facilitron.com;Yes, we do have a group in the view.  Let me give you more details of our use case.  We have three collections, collection one has the parent document and collection two and three have child documents.  I need to see the count of the documents in collection two and if that is zero I need the documents from collection three, so I created a view that looks at collection two and groups them for each parent document and then looks at collection three for those parents that do not have any child documents in collection two and then do a $project to get the appropriate array of documents from collection two or collection three. 

Then when I call an aggregate on the view or use it in a $lookup, I pass in the _id of the parent document I am looking for.  But it looks like the view takes the $match I pass in the aggregate or $lookup and places it after the view pipeline so I get a collscan.  Does that help define the use case?  ","Jan 04 2019 04:12:10 PM UTC;asya;[~sgaylord@facilitron.com] I think what you are describing is being tracked by SERVER-34741 and it's not necessarily related to this ticket (though views that took parameters could be a workaround for this use case).
","Jan 04 2019 04:18:36 PM UTC;asya;[~sgaylord@facilitron.com] if the view you created is not sharded you can run the aggregation in it with $out to create a collection with the results and then do a selective $lookup from that collection (using an indexed field to join).
","Jan 24 2020 07:16:58 PM UTC;kateryna.kamenieva;Adding this request to backlog for prioritization.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Support more granular collation specification,SERVER-25954,313857,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-query-execution,jeff.yemin,jeff.yemin,Sep 02 2016 09:07:55 PM UTC,Jan 07 2021 08:22:36 PM UTC,Feb 17 2021 11:15:17 AM UTC,,3.4.0,,,,Backlog,Querying,,,,0,,,,,,"Additional use cases for collation would be enabled if it could be specified at a more granular level than per-operation.  Some examples:

* A compound index or sort criteria with different collations for each key
* A query filter with different collations per operator
* An aggregation pipeline with different collations per stage (e.g. a case-insensitive collation for a $match and a case-sensitive one for a subsequent $sort) 
* A read-only view with different collations for the view itself, a view that it depends on, and an operation on the view  (this would be enabled by allowing a collation per aggregation stage)",,,,,,,,,,,,SERVER-53637,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2016-09-13 19:16:35.0,139708800,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,charlie.swanson(charlie.swanson),Tue Sep 13 19:16:35 UTC 2016,,,,,,,,,,,,,,asya(asya),backlog-query-execution(JIRAUSER1257109),jeff.yemin(jeff.yemin),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i01m6v:",,,,,,,"0|i00wnr:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i0rztb:","Sep 13 2016 07:16:35 PM UTC;asya;All of these except the last bullet are reasonable requests.

The last bullet seems to enable some security leaks.
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Allow indexing of several arrays,SERVER-826,11613,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-query-optimization,chx,chx,Mar 24 2010 03:29:26 PM UTC,Jan 05 2021 05:49:25 PM UTC,Feb 17 2021 11:15:18 AM UTC,,,,,,Backlog,Indexing,,,,9,,,,,,"While I understand the N^2 complexity of parallel arrays maybe something could be done? Like, allow a limitation of just how how many items will be indexed from an array? While in theory an array can be any number of element in reality we might know that a certain array will be small.",,,,,,,,,,,,HELP-6181,,,,,,,,,,,,,,,,,,,,3.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2011-07-01 12:06:53.0,284774400,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,eric.sedor(eric.sedor),Wed Feb 08 23:11:49 UTC 2012,,,,,,,,No,,,,,,backlog-query-optimization(JIRAUSER1257108),chx(chx),remonvv(remonvv),trayburn(trayburn),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i07f3j:",,,,,,,"0|i00ykf:",6637,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i0u38v:","Mar 24 2010 03:30:57 PM UTC;chx;Actually, due to uniformity, Drupal stores 1-element arrays often. Maybe just make an exception for 1-element arrays? That would be tremendous help.","Jul 01 2011 12:06:53 PM UTC;remonvv;I do not think there should be any limitation put in place on grounds of ""idiot proofing"". There are quite a few use cases where an index on multiple small arrays makes sense.","Feb 08 2012 11:11:49 PM UTC;trayburn;This is a major impact to a project I'm working on right now, we use arrays in many places, and our Web UI suffers from speed issues due to this limitation.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
document level access control,SERVER-648,11338,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-server-security,mwaschkowski,mwaschkowski,Feb 19 2010 10:49:47 AM UTC,Jan 05 2021 03:56:43 PM UTC,Feb 17 2021 11:15:18 AM UTC,,1.3.2,,,,Backlog,Security,,,,24,,,,,,"Access control to the documents in the system would be very helpful. What is done on my current project is to implement an interface that is called during all database operations and returns a boolean to indicate whether or not the document should be included in the result set. We have added some attributes/fields to the document to specify who should be able to access it, and we run through some business rules (ie. admin vs normal user, group belonged to etc.) to determine access. 

The backend that we use currently provided the hook for us via the java interface for us to implement, and it is simple and effective. I can't see an application layer where munging of the queries or doing sub queries to be as clean or error free.",,,,,,,,,,,,SERVER-1105,FREE-127451,,,,,,,,,,,,,,,,,,,8.0,,,,,,,,,,,,,,,,,,,,,5002K00000rzy1uQAA,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2011-10-04 17:04:02.0,60566400,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,,Mon Mar 18 11:30:36 UTC 2019,,,,,,,,No,,,,,,backlog-server-security(backlog-server-security),gianfranco(gianfranco),mwaschkowski(mwaschkowski),matthew.rummel6@gmail.com(matthew.rummel6@gmail.com),mloll(mloll),nestor.urquiza@gmail.com(nestor.urquiza@gmail.com),nevi_me(nevi_me),russellc92(russellc92),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i07gwn:",,,,,,,"0|i05o3z:",6341,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i1ivin:","Feb 19 2010 11:12:05 AM UTC;mwaschkowski;In summary, AC is a global type restriction, and should be treated as such at the database level, which is the gatekeeper of the data.

can also see discussion here:
http://groups.google.com/group/mongodb-user/browse_thread/thread/72fc46873b5be14e
","Oct 04 2011 05:04:02 PM UTC;nestor.urquiza@gmail.com;I totally agree. Managing ACL in Service or any other layer ends up pretty soon in a mess. In the JPA world we have a project like jpasecurity which is a wrapper on top of the JPA provider that intercepts all queries and apply rules defined either in XML or with annotations.

I think something like that should be included as part of MongoDB.

I vote then for this feature.

Best regards,
-Nestor","Apr 05 2013 03:44:09 PM UTC;mloll;I have been working on a proof of concept for this on and off for the past month.  I take an approach similar to how Accumulo handles column visibility - arbitrary boolean expressions like 'manager && engineer' indicate access restrictions on a document (its label if you are familiar with Oracle's label security).  Clients send a list of their rights (['manager', 'engineer', 'readable']) which are then used to prune out documents which may satisfy the query predicate but don't satisfy the access restriction.  If I can get it up on github I'll post a link, but it is not something that is really ready for prime time.

Mike","Oct 17 2013 08:07:53 PM UTC;nevi_me;I think this is solved by SERVER-1105. Maybe we should get the MongoDB team and the community to spend 1-2 days going through open issues that might have been resolved over time. I'm personally tired of those people who blog about how MongoDB is focusing on benchmarks and unsafe writes blah blah, and they go point out very old issues that haven't been, or won't be resolved/worked on.

Would also give MongoDB perspective on how things are going :)","Oct 19 2013 01:57:29 PM UTC;gianfranco;Neville, the SERVER ticket you mention talks about *collection* access level control, not *document*.
That is, each document can possibly have different authorisations (read, write) to different users","Oct 19 2013 02:10:01 PM UTC;nevi_me;Ah, I didn't notice that part. Thanks



","May 24 2017 04:02:26 AM UTC;matthew.rummel6@gmail.com;A few thoughts on implementing document label security:

- User's should have a security token or belong to a group that has a security token. This token defines what documents a user is allowed to access.
- A security token is a representation of all the security groups to which the user belongs.
- A given user's token should be compared with the at the document and subdocument level (and potentially at the filed level)  in each document automatically when a crud operation is performed. Only those documents/subdocuments/fields that a user has access to will be affected by the operation. 
- The framework must allow for security groups to inherit the permissions of other security groups. For instance, if a document is tagged with the ""HR"" security group and ""HR"" is not inherited by any other defined security groups, then only users with the ""HR"" group will be able to perform CRUD operations on the document/subdocument/field.  However, If the ""Executive"" group inherits the ""HR"" group, then user's with either the ""Executive"" or ""HR"" security groups will be able to perform CRUD on the data.
- The evaluation of a document's security label rules should allow for 'AND' and 'OR' operations, such as ""User is in security group A and B"" or ""User is in group A or B or C"".
- A user's security token and a data security label should allow for various compartments to be used in the evaluation, such as ""Department Context: ""User is in department security group A or B, Function Context: User is in functional group B or C"".
- Document level access control should be able to be enabled or disabled at the collection level. Some collections should enforce access control while others do not.
- Both top level and embedded documents should be able to have their own access control label.  If an embedded document has a more restrictive access control than it's parent and a user does not have the permissions necessary to perform a crud operation at the embedded access level, the embedded document should be omitted from the operation.
- A user should be able to run a CRUD operation that is more restrictive than their permissions allow. For instance, if a user has security groups ""Accounting"" and ""Engineering""  wants to perform a find operation on documents that have the ""Engineering"" document label, he or she should be able to do so.","Mar 18 2019 11:30:36 AM UTC;russellc92;I was wondering how this would be implemented and whether it would be similar to how access control is performed at the [collection level|https://docs.mongodb.com/manual/core/collection-level-access-control] (That being: via the use of [user-defined roles|[https://docs.mongodb.com/manual/core/security-user-defined-roles/#user-defined-roles]]).

Here “By creating a role with privileges that are scoped to a specific collection in a particular database, administrators can provision users with roles that grant privileges on a collection level”. For example, the following privilege definition for a user role allows the find action on the “myCollection” collection:

 
{code:java}
“{ resource: { db: ""myDatabase"", collection: ""myCollection"" },  actions: [ ""find"" ] }”.
{code}
 

I think this method could be difficult for Documents. Collections are named and therefore actions can be mapped to collection names (“find” on myCollection). Documents does not have such a naming system by default. (AKA - I can’t see here how to map specific documents to perhaps a user-defined role)

Therefore, would the implementation differ and perhaps revolve around a tagging system as shown in “[Implement Field Level Redaction|[https://docs.mongodb.com/manual/tutorial/implement-field-level-redaction/]]”? Such an approach would be similar to what @Matthew Rummel has described above in the sense that a user has a token and documents would have tags containing matching token(s), giving the user access to that document (correct me if my interpretation is wrong here)

 

 

 ",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Add option for automatically building compiledb with all targets,SERVER-52792,1539513,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-server-devplatform,daniel.moody,daniel.moody,Nov 11 2020 09:32:04 PM UTC,Jan 04 2021 09:16:29 PM UTC,Feb 17 2021 11:15:18 AM UTC,,,,,,5.0 Desired,,,,,0,,,,,,"A feature was requested so that compiledb can automatically be include with all targets, primarily for the purpose of ninja, so that the compiledb target does not need to always be specified at the command line when specifying targets.

This may be something like --auto-compiledb. One possible way to easily accomplish this (although some may consider it hacky) is to add the compiledb target on to the COMMAND_LINE_TARGETS global that scons uses to record targets requested at the command line.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2021-01-04 21:16:29.0,3715200,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,acm(acm),Mon Jan 04 21:16:29 UTC 2021,,,,,,,,,,,,,,acm(acm),backlog-server-devplatform(backlog-server-devplatform),daniel.moody(JIRAUSER1253549),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i74ybr:",,,,,,,"0|i0193j:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i74wfb:","Jan 04 2021 09:16:29 PM UTC;acm;I don't think adding it to {{COMMAND_LINE_TARGETS}} would work, though, because it wouldn't have any impact for Ninja builds, which appears to be where this is primarily desired. I think to make it work with Ninja you would need to make ""everything"" (for some value of everything) depend on the compiledb target, so that no matter what target you built it would need to build the compiledb first. Should that dependency extend all the way down to requesting the direct compilation of a specific TU, which though rare is a legitimate use case? If so, it would maybe even be circular, I'm not sure. Overall, I'm pretty lukewarm in the idea, to be honest. We've had bad experiences with these sort of ""wire up dependencies everywhere"" efforts, and it doesn't seem like that much savings to need to type something like {{--auto-compiledb}} every build rather than just including the compilation database as a target.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
libdeps visualizer: create edge list,SERVER-53532,1577892,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-server-devplatform,daniel.moody,daniel.moody,Dec 28 2020 05:11:27 PM UTC,Jan 04 2021 07:54:59 PM UTC,Feb 17 2021 11:15:18 AM UTC,,,,,,5.0 Desired,,,,,0,,,,,,"The visualizer as of writing this ticket has a node list which lists all nodes in the graph (~900 currently), but for the edge list we may not want to list all edges in the edge list because there are close to 90K edges.

 

We may want the edge list to reflect edges only from the currently selected nodes. So for a user workflow that would be they first must select nodes to select an edge. Once the edge is selected it will be highlighted in the visual graph and appear as a collapsable item in the selected info tab, providing more information about that specific edge.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,4320000,,,,,,,,PM-1112,,,,,,,,,,,,,,,,,,,,true,acm(acm),2020-12-28 17:11:27.0,,,,,,,,,,,,,,backlog-server-devplatform(backlog-server-devplatform),daniel.moody(JIRAUSER1253549),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i7biq7:",,,,,,,"0|i018yn:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i7bgtr:",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
libdeps visualizer: implement commit list textfields,SERVER-53529,1577879,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-server-devplatform,daniel.moody,daniel.moody,Dec 28 2020 04:50:55 PM UTC,Jan 04 2021 07:54:55 PM UTC,Feb 17 2021 11:15:18 AM UTC,,,,,,5.0 Desired,,,,,0,,,,,,"The libdeps visualizer has a draggable list of commits that allow you to select a given graph tied to that commit. If there are a large number of possible commits in this list, it can be hard and cumbersome to find a given commit.

 

There are three placeholder textfields which will be used to allow for navigation through the commit list. The first is ""Jump to"" or ""Scroll To"" which should make the list scroll to the the commit typed in the test field if it exists.

 

The other buttons are for limiting the range of commits in the list. There will be a From and To text field where a desired commit is typed in and the the list will be updated to reflect the start and end commit. This allows for better performance for really large lists. (10000+) and also easier navigation when dragging the list around when working in a certain time. One possible design feature for these text fields is that if + or - sign is the first character typed in, then it will do some relative trimming. For example if +10 is type in the beginning commit field, it will move the current beginning commit up 10 commits.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,4320000,,,,,,,,PM-1112,,,,,,,,,,,,,,,,,,,,true,acm(acm),2020-12-28 16:50:55.0,,,,,,,,,,,,,,backlog-server-devplatform(backlog-server-devplatform),daniel.moody(JIRAUSER1253549),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i7binb:",,,,,,,"0|i018yf:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i7bgqv:",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
libdeps graph linter: public deps efficiency threshold,SERVER-53494,1576409,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-server-devplatform,daniel.moody,daniel.moody,Dec 22 2020 10:21:33 PM UTC,Jan 04 2021 07:53:32 PM UTC,Feb 17 2021 11:15:18 AM UTC,,,,,,5.0 Desired,,,,,0,,,,,,"The transitive tree of edges created by a public libdeps declaration may be added to many link lines but not actually used.

A given public libdep can be given an efficiency percentage calculated by (the number of transitive edges that really need the link)/(the number of edges in that transitive tree).

 

First we should implement a query so that for a given node, you can print the efficiency of all direct public libdeps on that node. 

 

We should then also implement a linter which checks all direct public libdeps edges efficiency percentages, and if a percentage is below a given threshold it is reported. It may be that it is desirable that a node which has, say for example a %2 percent efficiency and is actually needed in only two link lines, but is transitively added to 100 link lines, would instead just use two LIBDEPS_PRIVATE links where needed.

 

 

 ",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,4838400,,,,,,,,PM-1112,,,,,,,,,,,,,,,,,,,,true,acm(acm),2020-12-22 22:21:33.0,,,,,,,,,,,,,,backlog-server-devplatform(backlog-server-devplatform),daniel.moody(JIRAUSER1253549),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i7b9kn:",,,,,,,"0|i018xz:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i7b7o7:",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Add USDT probes to command dispatch,SERVER-41692,800423,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-server-servicearch,gabriel.russell,gabriel.russell,Jun 13 2019 03:41:30 PM UTC,Jan 04 2021 01:31:40 AM UTC,Feb 17 2021 11:15:18 AM UTC,,,,,,Backlog,,,,,0,,,,,,Add USDT probes to command dispatch. Include some parameters. Write tests that the probes function and that the parameters are readable.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,4.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2019-07-29 17:50:39.0,53049600,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,ratika.gandhi(ratika.gandhi),2019-06-13 15:41:30.0,,,,,,,,,,,,,,backlog-server-servicearch(backlog-server-servicearch),gabriel.russell(gabriel.russell),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i3nten:",,,,,,,"0|i02ulb:",9223372036854775807,,,,,,,,,,,,Dev Tools 2019-07-01,Dev Tools 2019-07-15,Dev Tools 2019-07-29,Dev Tools 2019-08-12,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i3nrif:",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Build command dispatch reporting tool,SERVER-41711,800889,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-server-servicearch,gabriel.russell,gabriel.russell,Jun 13 2019 06:39:27 PM UTC,Jan 04 2021 01:31:35 AM UTC,Feb 17 2021 11:15:18 AM UTC,,,,,,Backlog,,,,,0,,,,,,Utilizing SERVER-41692 and SERVER-41709 and SERVER-41710 produce a reporting tool that reports on command dispatch,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,3.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,53049600,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,ratika.gandhi(ratika.gandhi),2019-06-13 18:39:27.0,,,,,,,,,,,,,,backlog-server-servicearch(backlog-server-servicearch),gabriel.russell(gabriel.russell),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i3nwa7:",,,,,,,"0|i02ulj:",9223372036854775807,,,,,,,,,,,,Dev Tools 2019-07-15,Dev Tools 2019-07-29,Dev Tools 2019-08-12,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i3nudz:",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Build data storage engine reporting tool,SERVER-41713,800947,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-server-servicearch,gabriel.russell,gabriel.russell,Jun 13 2019 06:51:15 PM UTC,Jan 04 2021 01:31:19 AM UTC,Feb 17 2021 11:15:18 AM UTC,,,,,,Backlog,,,,,0,,,,,,Utilizing SERVER-41693 and SERVER-41709 and SERVER-41710 produce a reporting tool that reports on data storage entry,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,3.0,,,,,,,,,,,,,,,,Fully Compatible,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2019-08-08 17:17:52.0,53049600,,,,,Not Needed,,,,,,,,,,,,,,,,,,,,,,,true,ratika.gandhi(ratika.gandhi),2019-06-13 18:51:15.0,,,,,,,,,,,,,,backlog-server-servicearch(backlog-server-servicearch),gabriel.russell(gabriel.russell),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i3nwn3:",,,,,,,"0|i02ujz:",9223372036854775807,,,,,,,,,,,,Dev Tools 2019-07-15,Dev Tools 2019-07-29,Dev Tools 2019-08-12,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i3nuqv:",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Add USDT probes to storage engine entry,SERVER-41703,800787,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-server-servicearch,gabriel.russell,gabriel.russell,Jun 13 2019 06:17:27 PM UTC,Jan 04 2021 01:31:14 AM UTC,Feb 17 2021 11:15:18 AM UTC,,,,,,Backlog,,,,,0,,,,,,"Add USDT probes to storage engine entry.
 Include some parameters.
 Write tests that the probes function and that the parameters are readable.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,3.0,,,,,,,,,,,,,,,,Fully Compatible,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2019-08-08 17:17:40.0,53049600,,,,,Not Needed,,,,,,,,,,,,,,,,,,,,,,,true,ratika.gandhi(ratika.gandhi),2019-06-13 18:17:27.0,,,,,,,,,,,,,,backlog-server-servicearch(backlog-server-servicearch),gabriel.russell(gabriel.russell),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i3nvnj:",,,,,,,"0|i02uzb:",9223372036854775807,,,,,,,,,,,,Dev Tools 2019-07-15,Dev Tools 2019-07-29,Dev Tools 2019-08-12,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i3ntrb:",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Add SCons Alias info map for help text,SERVER-51299,1498181,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-server-devplatform,daniel.moody,daniel.moody,Oct 01 2020 09:48:26 PM UTC,Dec 31 2020 08:11:52 PM UTC,Feb 17 2021 11:15:18 AM UTC,,,,,,5.0 Desired,,,,,0,,,,,,"There are many common Alias targets which build sets of targets which would be standard targets a user would generally use. It would be nice if a description of some of the more common Alias and major targets were added to the help text.

 

This is easily accomplished by making a static file that has the Alias with there descriptions that is read and printed when the help text is printed or manually added the common aliases to the help text.


If there was someway to quickly do this dynamically that may also be useful so that the definitions do not go stale. ",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,Fully Compatible,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,11923200,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,acm(acm),2020-10-01 21:48:26.0,,,,,,,,,,,,,,backlog-server-devplatform(backlog-server-devplatform),daniel.moody(JIRAUSER1253549),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i6xvlj:",,,,,,,"0|i0192v:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i6xtp3:",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Ability for a replica set node to only have a subset of the databases or collections?,SERVER-1559,12648,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,evin.roesle,william.shulman@gmail.com,william.shulman@gmail.com,Aug 03 2010 06:15:19 PM UTC,Dec 29 2020 05:12:41 PM UTC,Feb 17 2021 11:15:18 AM UTC,,,,,,Backlog,Replication,,,,40,,,,,,It would be very useful to activate replication of a server only on selected databases. I guess this would be a generalization of the --only option for mongod. Furthermore it would be great if the set of database names were configurable via local.sources (or equiv) vs. just via a command line option. This way changes can be made without restarting the database.,,,,,,,,,,,,SERVER-9780,FREE-39102,FREE-40242,CS-29648,CS-30096,,,,,,,,,,,,,,,,7.0,,,,,,,,,,,,,,,,,,,,,500A000000VE569IAD,500A000000WV1d1IAD,500A000000Y51BpIAJ,500A000000Zfxg8IAB,500A000000ZeAfzIAF,500A000000aukqGIAQ,500A000000bUI7mIAG,500A000000byGJtIAM,500A000000cS3gqIAC,5002K00000dG6gwQAC,5002K00000dHJFQQA4,5002K00000dbP38QAE,5002K00000fLnloQAC,5002K00000hQdSkQAK,5002K00000hSFb3QAG,5002K00000hSGG2QAO,5002K00000htH1mQAE,5002K00000hweTBQAY,5002K00000iObVKQA0,5002K00000kDZDHQA4,5002K00000iyTdMQAU,5002K00000kEM20QAG,5002K00000kFjQaQAK,5002K00000kFuIpQAK,500A000000X2bB2IAJ,5002K00000mr6GBQAY,5002K00000mtAD6QAM,5002K00000nmKYVQA2,5002K00000nnw53QAA,5002K00000plTaSQAU,5002K00000rzLjkQAE,,,,,,,,,,,,,,2010-09-15 22:18:44.0,14601600,,,,,,,,PM-1148,,,,,,,,,,,,,,,,,,,,true,,Mon Aug 31 13:32:06 UTC 2020,,,,,,,,No,,,,,,tibwiz(tibwiz),alyson.cabral(alyson.cabral),evin.roesle(evin.roesle),joe.enzminger(joe.enzminger),jstad(jstad),kevin.pulo(kevin.pulo@10gen.com),mzs(mzs),william.shulman@gmail.com(william.shulman@gmail.com),yuriy.safris@gmail.com(yuriy.safris@gmail.com),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i07793:",,,,,,,"0|i0c2j3:",6620,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i1cixz:","Sep 15 2010 10:18:44 PM UTC;jstad;This is the same feature requested here: http://jira.mongodb.org/browse/SERVER-1799
","Apr 22 2016 12:10:50 AM UTC;kevin.pulo;To make this ticket easier to search for, this feature is also sometimes referred to as ""Filtered replication"".","Apr 10 2019 07:37:11 PM UTC;joe.enzminger;Would it be possible to get some commentary from Mongo on why this feature request has no action for nine years?  It may be that it isn't a common use case, but in our usage of Mongo since 2009 this comes up all the time when looking at reporting, event sourcing, and backup architectures.  MongoDB Ops Manager has had this capability for backups for quite some time.

 

 ","May 29 2019 06:56:58 AM UTC;tibwiz;Are there any updates on this feature request? This is one of the useful scenarios where we want to replicate only portion of the data to a disaster recovery site. In the absence of this, its forced to run separate instances where the locally significant data is written to one instance(s) and globally significant data is written to another instance, which is replicated to a disaster recovery site.","May 29 2019 02:23:25 PM UTC;alyson.cabral;We've invested time building some of this functionality in a MongoDB tool called [mongomirror|https://docs.atlas.mongodb.com/reference/mongomirror/]. This tool has solved some of our most pressing use cases around active migrations. 

In fact, in the upcoming release of mongomirror, users will be able to sync a subset of dbs and collections between MongoDB clusters.  While mongomirror is specifically built to support MongoDB Atlas, it can be used between any two clusters using SSL.  Set up can be a bit tricky, but once auth is in place, you can simply spin up mongomirror to manage db- and collection-level mirroring between any two Mongo clusters. 

Now, to bring this functionality to a wider audience and a wider range of use cases, there is significant work to be done around operationalization. [~seth.payne], the product manager for mongomirror, and I are actively drawing up a plan for how to get us there. This will take time, and thank you for your patience. 

As we are in the requirements gathering phase for this area, can you expand some more on what you mean by partially replicating to a DR site? What is the workflow where this helps in a disaster? Why is it beneficial to only replicate a subset of the data? Do the clusters need to be entirely independent replica sets? If you're open to it, I'd love to schedule a call to talk through some of these questions. 

Aly Cabral
Product Manager, Core Server ","May 29 2019 03:12:47 PM UTC;mzs;We have some databases that are large, infrequently updated, maybe even infrequently used, and periodic snapshots within the region are sufficient. The regular replica set behaviour is more redundancy than we need for these databases, and slows down the resync process if we have to add or rebuild a replica.

We have other databases that are small, frequently updated or used, where we want to minimize the RPO and RTO, and the regular replica set behaviour works well.

And we have still other databases that are large _and_ frequently updated, but might be experimental, and once in a while the oplog blows out while running a job with lots of inserts.

Having a mix of these databases in the same cluster would be useful for simplifying application configuration. A few ideas of how this might look:
 # mark a database (on creation?) as not replicated, such that its operations are never replicated to secondaries;
 # turn off replication for an existing database;
 # remove a database from secondary nodes of the replica set without removing it from the primary;
 # take a previously non-replicated database and replicate it (!!)

The most useful would be #1, the others are just decoration to avoid mongodump/restore.","Aug 31 2020 01:32:06 PM UTC;yuriy.safris@gmail.com;Hi 

Can you clarify what it means: ""it can be used between any two clusters using SSL. Set up can be a bit tricky""

How to configure authentication for the destination, which is an on-premise MongoDB ReplicaSet?

 
{code:java}
net:   
  ssl:     
    mode: allowSSL  
    allowInvalidCertificates: true  
    allowInvalidHostnames: true  
    allowConnectionsWithoutCertificates: true     
    PEMKeyFile: /etc/ssl/mongodb.pem
{code}",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
$true or $truthValue query operator,SERVER-4486,26545,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-query-optimization,redbeard0531,redbeard0531,Dec 13 2011 10:29:18 PM UTC,Dec 15 2020 04:33:54 AM UTC,Feb 17 2021 11:15:18 AM UTC,,,,,,Backlog,Querying,,,,0,,,,,,"db.foo.remove({temporary: {$truthValue: true}})

Probably should share semantics (but not name) with BSONElement::trueValue() where 0, false, null, undefined, and missing are false and everything else is true. Alternatively we may want to treat empty Strings, Objects, and Arrays as false like python.

This can be approximated with an $in/$nin query, but I think it would be nice to have a proper query operator.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2020-12-15 04:33:54.0,5529600,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,david.percy(david.percy),Tue Dec 15 04:33:54 UTC 2020,,,,,,,,No,,,,,,backlog-query-optimization(JIRAUSER1257108),david.percy(david.percy),redbeard0531(redbeard0531),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i068g7:",,,,,,,"0|i00u33:",6275,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i1i1m7:","Dec 15 2020 04:33:54 AM UTC;david.percy;I think $expr is a pretty natural way to write this:
{code}
db.foo.remove({ $expr: ""$temporary"" })
{code}

Although it looks like we don't generate index bounds for it.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
aggregation:  support windowing operation on pipelines,SERVER-4437,26052,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-query-optimization,pasette,cwestin,Dec 06 2011 12:56:10 AM UTC,Dec 15 2020 04:27:12 AM UTC,Feb 17 2021 11:15:18 AM UTC,,,,,,Backlog,Aggregation Framework,,,,10,,,,,,"postgres supports a windowing capability that allows for calculations within a window of visible data; this is for streaming data.

It's easy to imagine supporting something like a $window pipeline operator, which specifies how many documents to include in the window.  Within, aggregate expressions can reference documents within the window using some kind of indexing.  This can be used to calculate things like moving averages, e.g., have a window of 5 items, and create a computed field that is (doc[0] + doc[-1] + doc[-2] + doc[-3] + doc[-4])/5, or something like that.
",,,,,,,,,,,,FREE-30500,FREE-37662,FREE-57356,SERVER-29339,SERVER-29161,PM-1834,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,Fully Compatible,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2011-12-14 14:56:29.0,108777600,,,,,,,,PM-1834,,,,,,,,,,,,,,,,,,,,true,david.percy(david.percy),Wed Sep 06 21:25:38 UTC 2017,,,,,,,,No,,,,,,asya(asya),backlog-query-optimization(JIRAUSER1257108),cwestin(cwestin),pasette(dan@10gen.com),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i0692n:",,,,,,,"0|i00u2f:",5999,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i01dxb:","Dec 14 2011 02:56:29 PM UTC;cwestin;References from a postgres user:

As mentioned, SQL Windows Functions might be a useful design from which to draw further feature inspiration, as it is likely compatible with your ""pipeline"" approach.  I am using these on PostgreSQL and find the best documentation there.  There was [PGCon] presentation slides from 2009 giving a feature introduction and some implementation details, as well as the standard PostgreSQL docs: [PG0] intro and [PG1] functions. 

The feature allows a PARTITION to be defined with similar options to GROUP BY, but then rather than collapsing to a single row for each group, preserves the original set of rows and allows access to functions of the PARTITION.  For example, I make heavy use of the rank() function for a server side scoring algorithm.  

[PGCon]: http://www.pgcon.org/2009/schedule/events/128.en.html
[PG0]: http://www.postgresql.org/docs/9.1/static/tutorial-window.html 
[PG1]: http://www.postgresql.org/docs/9.1/static/functions-window.html
","Sep 06 2017 09:25:38 PM UTC;asya;More current links to description of group by windowing/rollup/cube functions:

- https://www.postgresql.org/docs/current/static/tutorial-window.html
- https://oracle-base.com/articles/misc/rollup-cube-grouping-functions-and-grouping-sets
- https://www.red-gate.com/simple-talk/sql/t-sql-programming/window-functions-in-sql/

",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Ability to access previous document in $group aggregation,SERVER-29161,383037,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-query-optimization,arg20,arg20,May 12 2017 04:38:19 PM UTC,Dec 15 2020 04:03:32 AM UTC,Feb 17 2021 11:15:18 AM UTC,,3.5.6,,,,Backlog,Aggregation Framework,,,,7,expression,,,,,"When performing an aggregation query in mongodb, it would sometimes be useful to reference the previous document. As we have the `$$ROOT` variable, perhaps we could have `$$PREVIOUS` or some other meaningful name that let's us do document to document calculations.

A possible use case would be calculating time passed in between documents more easily, and calculating deltas between documents. 

",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,10.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2017-05-16 15:15:56.0,36633600,,,,,,,,PM-1834,,,,,,,,,,,,,,,,,,,,true,david.percy(david.percy),Fri Dec 20 22:26:24 UTC 2019,,,,,,,,,,,,,,asya(asya),backlog-query-optimization(JIRAUSER1257108),brett.gray(brett.gray),charlie.swanson(charlie.swanson),arg20(arg20),tyeager@real.com(tyeager@real.com),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i1p6dz:",,,,,,,"0|i00x1j:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i0t81z:","May 16 2017 03:16:59 PM UTC;asya;[~arg20] can you give a brief description of your use case?  What calculation/processing you are currently trying to do, etc?
","May 17 2017 01:15:22 AM UTC;arg20;Asya. One of the use cases is for IoT projects my company is developing for a big client. Most of this data is sensor measurements across time. At some point the volume of the data became too large and we moved to storing only changes in the measurements. So instead of storing things like temperature value every 5 seconds, we store only deltas in the temperature. 

Since we are dealing with changes, sometimes we want to know calculations based on these deltas. So in each document I'm forced to store the current value and the previous value so I can compare them. Sometimes I need to know if the temperature increased with respect to the last one, and I can't determine this at the moment in which I store this or I'd store it pre-calculated already. Other times I need to perform conditional logic based on whether a previous distance reading was greater/less than the current reading in a $group operation.

It boils down to the fact that when you're storing deltas to some piece of information, often to reconstruct it, when you $group you need to perform delta-to-delta calculations. If I had access to the `previous` document, it would be trivial to do this, but for now each document stores its data, plus a bulk of data from the previous one.

I think in general this would enable the aggregation framework to achieve a new level of complexity in the algorithms you can write, specially when the volume of the data is so large that it becomes convenient to store only changes to the data.","May 17 2017 02:29:07 PM UTC;charlie.swanson;I think [this stack overflow question|http://stackoverflow.com/questions/43560777/mongodb-aggregation-query-to-subtract-and-grouping-of-cumulative-value/43594156#43594156] is related, I had to do some crazy stuff to reference the previous values.
","May 17 2017 02:50:43 PM UTC;arg20;Yeah, in my particular case, the size of our collection makes it almost impossible for us to create an array, unwind etc. That's clever though. I think the big picture is that when you are grouping, you often need a bit of context to process a given document, having access to the previous value makes it easier to perform conditional computations.","May 17 2017 06:19:19 PM UTC;asya;My question was due to having some solutions similar to the one [~charlie.swanson] linked to.  In general, such computations are done for a particular time period, right?  So pushing all deltas for each ""device"" to an array should be pretty doable. Though I'm guessing you don't mean deltas but rather storing only values that have changed since previous reading?

The issue with providing ""$$PREVIOUS"" is that if the previous document was somehow transformed during the processing, so should this be the document before it was ""processed"" or after?  Comparing elements in the array is simple enough (another example is [here|http://www.kamsky.org/stupid-tricks-with-mongodb/how-to-do-intra-array-comparisons] but it's less clear to me that providing $$PREVIOUS would make the resultant pipeline easier to understand.

We will discuss this request during our next planning cycle, thanks for the suggestion!
","Jul 04 2017 02:22:57 PM UTC;arg20;{code}
My question was due to having some solutions similar to the one Charlie Swanson linked to. In general, such computations are done for a particular time period, right? So pushing all deltas for each ""device"" to an array should be pretty doable. Though I'm guessing you don't mean deltas but rather storing only values that have changed since previous reading?
{code}

Yeah, in some cases we store values that have only changed since the previous reading, in other case we are particularly interested in storing deltas directly. However, I think with the rise of IoT applications (and my company is particularly invested in this), the need to store sensor data or data from devices that produce a really large volume of information is growing, and pushing deltas for each device might become expensive/convoluted. Our aggregation queries are complex enough at the moment unfortunately and they take their fair amount of seconds to execute.

{code:java}
The issue with providing ""$$PREVIOUS"" is that if the previous document was somehow transformed during the processing, so should this be the document before it was ""processed"" or after?
{code}

Please excuse my ignorance here, I do not know how the `$group` stage works under the hood so this request is honestly coming from my lack of knowledge. What I meant was that I want `$$PREVIOUS` (or more suitable name), to point to the previous `$ROOT` processed for that group. So that, if my group is `_id: ""$deviceId""`, when I'm processing the second document for that `group`, `$$PREVIOUS` will be a reference to the first document, and so on. so that I can do something like ""$$PREVIOUS.temperature - $$ROOT.temperature"".

Does that make sense? Thanks","Jul 05 2017 02:28:23 PM UTC;asya;bq. when I'm processing the second document for that `group`, `$$PREVIOUS` will be a reference to the first document, and so on. so that I can do something like ""$$PREVIOUS.temperature - $$ROOT.temperature"".

Okay, I think I understand the example.  I do think the linked ticket, SERVER-29339 would allow something similar, by allowing saving/accumulating previous value(s).   We will need to figure out which syntax would allow for more readable (and/or more performant) implementation.
","Jan 17 2018 08:10:13 PM UTC;asya;It's conceivable that this would be a useful expression in any stage (i.e. $project/$addFields).
","Dec 05 2019 12:15:18 AM UTC;brett.gray;[~asya] I have a customer that could also use the suggested {{$$PREVIOUS}} to assist in calculate\ing variance of products created compared to the previous week.","Dec 20 2019 10:26:24 PM UTC;tyeager@real.com;We want to coalesce image recognition events that have a start and end time.  If the gap between the start time of the $$CURRENT event and the end of the $$PREVIOUS event is less than some duration, we would group the documents into a new event.   ",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Refactor NetworkInterfaceTL using CancelationTokens,SERVER-50655,1458178,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-server-servicearch,matthew.saltz,matthew.saltz,Aug 31 2020 08:47:13 PM UTC,Dec 10 2020 10:51:02 PM UTC,Feb 17 2021 11:15:18 AM UTC,,,,,,5.0 Required,Internal Code,,,,0,,,,,,Use CancelationTokens to clean up the cancelation of work inside the NetworkInterfaceTL implementation,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,14601600,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,ratika.gandhi(ratika.gandhi),2020-08-31 20:47:13.0,,,,,,,,,,,,,,backlog-server-servicearch(backlog-server-servicearch),matthew.saltz(matthew.saltz),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i6r1d3:",,,,,,,"0|i6sbaf:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,7.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i6qzgn:",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Mongo shell javascript sharding admin functions not available in drivers,SERVER-16340,171524,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-server-sharding,joanna.cheng,joanna.cheng,Nov 27 2014 05:09:15 AM UTC,Dec 09 2020 09:01:51 PM UTC,Feb 17 2021 11:15:18 AM UTC,,,,,,Backlog,Admin,Sharding,,,1,balancer,,,,,"The following sharding mongo shell functions are implemented in client-side JS, and rely on the current layout of the config database and the collections within
{code}
sh.disableBalancing
sh.enableBalancing
sh.getBalancerHost
sh.getBalancerState
sh.isBalancerRunning
sh.removeShardTag
sh.setBalancerState
sh.startBalancer
sh.stopBalancer
sh.waitForBalancer
sh.waitForBalancerOff
sh.waitForDLock
sh.waitForPingChange
{code}

If a customer wants to configure their sharded cluster outside of the shell (i.e. through a driver), they need to re-implement the above in their language of choice. 

This unnecessarily exposes internal sharding implementation details to clients, which is an inappropriately fragile API for users to be dealing with.  Any such client-side re-implementation of these functions is therefore brittle in the face of future changes to the sharding implementation (and upgrading across such changes would need to be very carefully managed).

The situation is similar to SERVER-14378, where querying system.indexes and system.namespaces were replaced with the listIndexes/listCollections commands, for similar reasons.  It would be useful if there was also an API (at some level) to allow users to dynamically manage sharded environments via drivers.",,,,,,,,,,,,SERVER-6357,SERVER-6348,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,500A000000UaUM3IAN,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2015-01-10 17:54:51.0,196473600,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,jorge.imperial(jorge.imperial),Thu Nov 27 05:33:56 UTC 2014,,,,,,,,,,,,,,backlog-server-sharding(backlog-server-sharding),joanna.cheng(joanna.cheng@10gen.com),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i03707:",,,,,,,"0|i0bxvr:",150184,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i0ykz3:","Nov 27 2014 05:33:56 AM UTC;joanna.cheng;Some of the sharding related shell admin functions are already covered in other tickets
* {{sh.status()}}, which is (partially) covered in SERVER-6348
* {{sh.addShardTag}} / {{sh.addTagRange}}, which is covered in SERVER-6357",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Add Genny and YCSB workload to the sharding maintenance events build variant,SERVER-52910,1544090,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-server-stm,robert.guo,robert.guo,Nov 17 2020 03:08:29 PM UTC,Dec 08 2020 07:49:20 PM UTC,Feb 17 2021 11:15:18 AM UTC,,,,,,Backlog,Performance,,,,0,sharded-maintenance-workloads,,,,,"Add all existing Genny and YCSB maintenance workloads to a new Sharded maintenance build variant. See linked tickets for more info.

Note that we don't need to add Linkbench workloads as their output is not fine-grained enough for maintenance events",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,7862400,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,brooke.miller(brooke.miller),2020-11-17 15:08:29.0,,,,,,,,,,,,,,backlog-server-stm(backlog-server-stm),robert.guo(robert.guo),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i75q73:",,,,,,,"0|i6zvw7:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i75oan:",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Expose reshardDoneCatchUp no-op oplog entry as change event,SERVER-50637,1456415,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-server-sharding,max.hirschhorn,max.hirschhorn,Aug 29 2020 12:18:10 AM UTC,Dec 08 2020 06:39:19 PM UTC,Feb 17 2021 11:15:18 AM UTC,,,,,,5.0 Required,Sharding,,,,0,PM-234-M3,PM-234-O-unspecialized,PM-234-T-change-streams,query-work-resharding,,"[Convert the repl::OpTypeEnum::kNoop entry|https://github.com/mongodb/mongo/blob/7b0f4781f878fc7c231c2a1ed7fc20fd9ca1a1e6/src/mongo/db/pipeline/document_source_change_stream_transform.cpp#L324] into a change event of the form:

{code:javascript}
{
    operationType: ""reshardDoneCatchUp"",
    reshardingUUID: <reshardingUUID>,
}
{code}",,,,,,,,SERVER-50636,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,14860800,<a href='https://jira.mongodb.org/browse/SERVER-50636'>SERVER-50636</a>,,,,,,,PM-234,,,,,,,,,,,,,,,,,,,,true,max.hirschhorn(max.hirschhorn@10gen.com),2020-08-29 00:18:10.0,,,,,,,,,,,,,,backlog-server-sharding(backlog-server-sharding),max.hirschhorn(max.hirschhorn@10gen.com),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i6qqif:",,,,,,,"0|i6lh73:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i6qolz:",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Expose reshardBegin no-op oplog entry as change event,SERVER-50522,1451639,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-server-sharding,max.hirschhorn,max.hirschhorn,Aug 25 2020 02:47:03 PM UTC,Dec 08 2020 06:39:06 PM UTC,Feb 17 2021 11:15:18 AM UTC,,,,,,5.0 Required,Aggregation Framework,Sharding,,,0,PM-234-M3,PM-234-O-unspecialized,PM-234-T-change-streams,query-work-resharding,,"[Convert the repl::OpTypeEnum::kNoop entry|https://github.com/mongodb/mongo/blob/9cabe0e4bff7542955494cbec756fcf1560f88aa/src/mongo/db/pipeline/document_source_change_stream_transform.cpp#L324] into a change event of the form:

{code:javascript}
{
    operationType: ""reshardBegin"",
    reshardingUUID: <reshardingUUID>,
}
{code}",,,,,,,,SERVER-50521,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,15120000,<a href='https://jira.mongodb.org/browse/SERVER-50521'>SERVER-50521</a>,,,,,,,PM-234,,,,,,,,,,,,,,,,,,,,true,max.hirschhorn(max.hirschhorn@10gen.com),2020-08-25 14:47:03.0,,,,,,,,,,,,,,backlog-server-sharding(backlog-server-sharding),max.hirschhorn(max.hirschhorn@10gen.com),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i6px1r:",,,,,,,"0|i6kpgv:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i6pv5b:",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Support opening single-collection change stream on a system collection,SERVER-50523,1451640,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-server-sharding,max.hirschhorn,max.hirschhorn,Aug 25 2020 02:47:20 PM UTC,Dec 08 2020 06:39:01 PM UTC,Feb 17 2021 11:15:18 AM UTC,,,,,,5.0 Required,Aggregation Framework,Sharding,,,0,PM-234-M3,PM-234-O-unspecialized,PM-234-T-change-streams,query-work-resharding,,"Add allowToRunOnSystemNS parameter to the aggregate command for creating a change streams cursor. DocumentSourceChangeStream::assertIsLegalSpecification() should be [changed to not reject the request|https://github.com/mongodb/mongo/blob/9cabe0e4bff7542955494cbec756fcf1560f88aa/src/mongo/db/pipeline/document_source_change_stream.cpp#L554-L558] when allowToRunOnSystemNS:true is specified.

[Whole-database and whole-cluster change streams must still not see change events on system collections|https://github.com/mongodb/mongo/blob/9cabe0e4bff7542955494cbec756fcf1560f88aa/src/mongo/db/pipeline/document_source_change_stream.cpp#L230-L237].",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,15120000,,,,,,,,PM-234,,,,,,,,,,,,,,,,,,,,true,max.hirschhorn(max.hirschhorn@10gen.com),2020-08-25 14:47:20.0,,,,,,,,,,,,,,backlog-server-sharding(backlog-server-sharding),max.hirschhorn(max.hirschhorn@10gen.com),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i6px1z:",,,,,,,"0|i6kph3:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i6pv5j:",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Add a tool to inspect the resume token of a change stream,SERVER-32283,471334,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-query-execution,charlie.swanson,charlie.swanson,Dec 12 2017 07:48:00 PM UTC,Dec 08 2020 02:25:19 AM UTC,Feb 17 2021 11:15:18 AM UTC,,,,,,Backlog,Aggregation Framework,,,,3,,,,,,"For diagnostic or scripting purposes, it might be useful to inspect the values of the different pieces of a resume token:
* The collection's UUID
* The timestamp of the change
* The document key for the changed document

Cases this has come up include:
* Writing performance tests for change streams, wanting to inspect the cluster time of each change.
* Debugging a test failure during development on SERVER-31447.

A good way to expose this information might be through an aggregation expression.",,,,,,,,,,,,SERVER-34181,SERVER-34313,,,,,,,,,,,,,,,,,,,4.0,,,,,,,,,,,,,,,,,,,,,500A000000bRKD7IAO,5002K00000e9iu3QAA,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2017-12-12 20:13:33.0,83894400,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,dmitry.ryabtsev(dmitry.ryabtsev),Thu Jun 21 17:15:19 UTC 2018,,,,,,,,,,,,,,backlog-query-execution(JIRAUSER1257109),charlie.swanson(charlie.swanson),onlyhemant2410(onlyhemant2410),tess.avitabile(tess.avitabile),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i24393:",,,,,,,"0|i00tq7:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i241cv:","Dec 12 2017 07:48:21 PM UTC;charlie.swanson;[~tess.avitabile] I recall you were interested in this as well, do you remember what for? Debugging a BF?","Dec 12 2017 08:13:33 PM UTC;tess.avitabile;Yes, I think that was why I wanted it.","Jun 20 2018 10:58:03 PM UTC;onlyhemant2410;I am in dire need of this feature, need to know the timestamp to calculate the lag in processing the chagestream events. We are an update-heavy operation and currently, there is no way to identify if we are lagging behind.","Jun 21 2018 05:15:19 PM UTC;charlie.swanson;[~onlyhemant2410], note that in version 4.0 each change stream document will include a ""clusterTime"" field with the timestamp. See SERVER-34181. We plan to ship version 4.0 this summer, as detailed [here|https://www.mongodb.com/press/mongodb-announces-multi-document-acid-transactions-in-release-40]. There is a release candidate available [here|https://groups.google.com/d/msg/mongodb-user/TVXE1JiQ4sw/8jSt1Q94BAAJ].",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Gather and expose ""chunk-level"" statistics",SERVER-41215,770968,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-server-sharding,shakir.sadikali,shakir.sadikali,May 17 2019 05:49:29 PM UTC,Dec 07 2020 04:08:47 PM UTC,Feb 17 2021 11:15:18 AM UTC,,,,,,Backlog,Sharding,,,,4,,,,,,"I'd like to propose (what I believe to be) a light-weight solution for tracking chunk utilization. The mongos already tracks where queries should be routed for DML and find commands.  

Could we track insert, updates, deletes, finds, commands, no-ops against the chunk ranges they are sent to? And, possibly the aggregate total # of documents returned against those chunks?

If we could track these numbers in memory on the mongos we could then get a sense of what chunks are ""hot"". In the case of a balanced-by-data-size and balanced-by-number-of-chunks system, if we observe an imbalance in load as defined by query volume, we could then easily identify those chunks that are hot and take surgical action to move some or all of them manually. ",,,,,,,,,,,,TSEXP-381,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,5002K00000e6yoZQAQ,5002K00000fG7VmQAK,5002K00000gl1E5QAI,5002K00000huFPAQA2,5002K00000r4JFUQA2,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2019-05-17 17:53:20.0,55382400,,,,,,,,PM-631,,,,,,,,,,,,,,,,,,,,true,,Fri May 17 17:53:20 UTC 2019,,,,,,,,,,,,,,backlog-server-sharding(backlog-server-sharding),kaloian.manassiev(kaloian.manassiev),shakir.sadikali(shakir.sadikali),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i3j0dz:",,,,,,,"0|i3lkvj:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i3iyhr:","May 17 2019 05:53:20 PM UTC;kaloian.manassiev;Starting with mongodb 4.2, these statistics are tracked on the mongod, which gives a more accurate picture of the utilization. We are trying to move away from mongos tracking anything, because of their ephemeral nature (they are stateless so they can come and go).",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Support text index on entire subdocument,SERVER-53076,1552042,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-query-optimization,david.percy,david.percy,Nov 25 2020 03:27:53 PM UTC,Dec 01 2020 07:19:34 PM UTC,Feb 17 2021 11:15:18 AM UTC,,,,,,Backlog,,,,,0,,,,,,"Text indexes can apply to specific fields, or the entire document:
{code}
db.c.createIndex({ a: 'text' })
{code}
{code}
db.c.createIndex({ '$**': 'text' })
{code}

The second case is called a [wildcard text index|https://docs.mongodb.com/manual/core/index-text/index.html#wildcard-text-indexes], not to be confused with [wildcard indexes|https://docs.mongodb.com/manual/core/index-wildcard/index.html].

Wildcard indexes can apply to the whole document, or a subdocument:
{code}
db.c.createIndex({ '$**': 1 })
{code}
{code}
db.c.createIndex({ 'a.$**': 1 })
{code}


To complete the analogy, we should support creating a text index on an entire subdocument:
{code}
db.c.createIndex({ 'a.$**': 'text' })
{code}",,,,,,,,,,,,HELP-19936,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,7171200,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,craig.homa(craig.homa),2020-11-25 15:27:53.0,,,,,,,,,,,,,,backlog-query-optimization(JIRAUSER1257108),david.percy(david.percy),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i7739r:",,,,,,,"0|i716q7:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i771db:",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Startup warning when rollback files exist,SERVER-49314,1401432,New Feature,Investigating,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,evin.roesle,nicholas.cottrell,nicholas.cottrell,Jul 03 2020 03:13:06 PM UTC,Dec 01 2020 03:49:11 PM UTC,Feb 17 2021 11:15:18 AM UTC,,,,,,,,,,,0,,,,,,"While rollback events will be logged when they happen, it might be missed on a complex, busy cluster. In order for the existence of {{rollback}} files to be detected easily by existing tools, we should report their presence as a startup warning.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,5002K00000nopDXQAY,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2020-07-07 18:55:28.0,19353600,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,steven.vannelli(steven.vannelli),Tue Jul 07 18:55:28 UTC 2020,,,,,,,,,,,,,,evin.roesle(evin.roesle),jonathan.streets(jonathan.streets),nicholas.cottrell(nicholas.cottrell),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i6hbjr:",,,,,,,"0|i6cg2n:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i6h9nb:","Jul 07 2020 06:55:28 PM UTC;jonathan.streets;[~evin.roesle] do you have any advice on this one ? thanks. jon.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Adding NULL sort order configuration when using sort() queries,SERVER-24310,290068,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-query-optimization,pavel.duchovny,pavel.duchovny,May 29 2016 07:50:59 AM UTC,Nov 28 2020 10:55:29 PM UTC,Feb 17 2021 11:15:18 AM UTC,,,,,,Backlog,Querying,,,,18,storch,,,,,"At the moment, the NULL order fetching is decided upon the sort query type ({{DESC}},{{ASC}}).

If the query is done on field {{X}} in a {{DESC}} order the NULLs of field {{X}} will be presented last, while in an {{ASC}} order the NULLs of field {{X}} will be presented first. I saw many requests on having the ability to decide the fetch positions of the NULLs in the ordered field. 

Can it be added as an optional flag to the query syntax with a default behavior?",,,,,,,,,,,,CS-30519,,,,,,,,,,,,,,,,,,,,5.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2016-05-31 03:22:17.0,6912000,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,smetkice@gmail.com(JIRAUSER1257790),Sat Nov 28 22:55:29 UTC 2020,,,,,,,,,,,,,,asya(asya),backlog-query-optimization(JIRAUSER1257108),jim@complion.com(jim@complion.com),mamt84(mamt84),pavel.duchovny(pavel.duchovny),smetkice@gmail.com(JIRAUSER1257790),WayneUong(wayneuong),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i01w8n:",,,,,,,"0|i00wg7:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i0x2dj:","May 31 2016 03:22:17 AM UTC;asya;This would be analogous to SQL syntax:  ""ORDER BY fieldname NULLS FIRST"" (or LAST).","Dec 12 2017 04:34:48 PM UTC;jim@complion.com;Very important for my company for sorting values to the bottom alphabetically.","May 22 2018 08:18:38 PM UTC;WayneUong;Is there an ETA for this feature? This is so crucial for good UX/UI.","Nov 06 2018 04:29:44 PM UTC;mamt84;+1 Very useful.","Nov 28 2020 10:55:29 PM UTC;smetkice@gmail.com;Is there any update on this? Like previously mentioned, this would be super helpful for good UX. Currently, we have to hack around it.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Geo-spatial $lookup,SERVER-47218,1299439,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-query-execution,kateryna.kamenieva,kateryna.kamenieva,Apr 01 2020 01:21:34 AM UTC,Nov 24 2020 06:26:20 PM UTC,Feb 17 2021 11:15:18 AM UTC,,4.5 Desired,,,,Backlog,Geo,,,,1,qopt-team,,,,,"The use case from astronomical research team at CalTech:
 using aggregation pipeline, check what objects other data catalogs contain for the same position in the sky. (Now they are matching 4 million objects across 30 catalogs, and the number of catalogs is going to grow). The position can be described as a circle on sphere in both collections. Need to identify if there is an intersection of those circles.",,,,,,,,,,,,SERVER-34766,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2020-04-07 16:04:57.0,27216000,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,craig.homa(craig.homa),Tue Apr 07 16:04:57 UTC 2020,,,,,,,,,,,,,,asya(asya),backlog-query-execution(JIRAUSER1257109),kateryna.kamenieva(kateryna.kamenieva),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i60duv:",,,,,,,"0|i6odfz:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i60byf:","Apr 07 2020 04:04:57 PM UTC;asya;I think this is maybe a duplicate of SERVER-34766

 ",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Add support for Chinese language to full text search index,SERVER-52871,1542550,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-query-execution,mitar,mitar,Nov 15 2020 04:46:55 AM UTC,Nov 24 2020 04:54:34 PM UTC,Feb 17 2021 11:15:18 AM UTC,,,,,,Backlog,Text Search,,,,0,,,,,,I would like to ask that full text search index also support Chinese language.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,3.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2020-11-17 23:04:50.0,7776000,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,ana.meza(JIRAUSER1257467),Wed Nov 18 21:14:00 UTC 2020,,,,,,,,,,,,,,backlog-query-execution(JIRAUSER1257109),charlie.swanson(charlie.swanson),david.storch(david.storch),edwin.zhou(JIRAUSER1257066),mitar(mitar),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i75gpb:",,,,,,,"0|i6znlb:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i75esv:","Nov 17 2020 11:04:50 PM UTC;edwin.zhou;Hi [~mitar],

There was prior support for full text search on Chinese with Rosette Linguistics Platform (RLP), but it was removed in SERVER-37069 since the software is no longer supported by Basis Technologies.

I can assign this ticket to the appropriate team to be evaluated against our currently planned work. Updates will be posted on this ticket as they happen.

Kind regards,
Edwin","Nov 18 2020 03:54:40 PM UTC;david.storch;[~james.wahlin] [~charlie.swanson] while we are on the subject of clarifying team charters -- would you say that this ticket belongs to the QE team or the QO team? I will move it to the QE backlog in the meantime.","Nov 18 2020 09:14:00 PM UTC;charlie.swanson;[~david.storch] I think QE is a pretty good home. ",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Add ""errorMessage"" field to failCommand failpoint and ability to toggle error code",SERVER-51196,1493559,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-query-execution,kevin.albertson,kevin.albertson,Sep 28 2020 06:57:55 PM UTC,Nov 23 2020 09:16:02 PM UTC,Feb 17 2021 11:15:18 AM UTC,,,,,,Backlog,,,,,0,sa-groomed,,,,,"Error handling in drivers currently relies on message substring checks for ""not master"" and ""node is recovering"". It is used to help determine whether an error is a server state change error [per SDAM|https://github.com/mongodb/specifications/blob/master/source/server-discovery-and-monitoring/server-discovery-and-monitoring.rst#not-master-and-node-is-recovering], or if it is a retryable read / write error. We intend to remove those checks in DRIVERS-1152, but we are unable to test it with our existing SDAM integration test runner. The test runner uses the failCommand failpoint to simulate errors. But failCommand responses have a fixed errmsg: ""Failing command due to 'failCommand' failpoint"", so we cannot check the substring matching behavior.

If possible, could the failCommand arguments have an additional errorMessage field to overwrite or append to the returned errmsg? Here is an example API proposal:
{code}db.adminCommand({
    configureFailPoint: ""failCommand"",
    mode: ""alwaysOn"",
    data: {failCommands: [""find""], errorMessage: ""node is recovering"", errorCode: 123}
});
// Returns {ok: 0, code: 123, errmsg: ""node is recovering"" }
db.runCommand({find: ""collection""});
db.adminCommand({configureFailPoint: ""failCommand"", mode: ""off""}); 
{code}

Secondly, drivers error handling checks for the presence of an error code. Older MongoDB servers may not return an error code in all cases. Would it be possible to make {{errorCode}} optional so we can test the omission of an error code?",,,,,,,,,,,,DRIVERS-1152,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2020-11-23 21:16:02.0,12182400,,,,,,,,PM-2032,,,,,,,,,,,,,,,,,,,,true,ratika.gandhi(ratika.gandhi),2020-09-28 18:57:55.0,,,,,,,,,,,,,,backlog-query-execution(JIRAUSER1257109),kevin.albertson(kevin.albertson),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i6x32n:",,,,,,,"0|i6rlxz:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i6x167:",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Define a  configuration file expansion mechanism compatible with Ops Manager credentialstool,SERVER-43348,929567,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-server-security,spencer.jackson,spencer.jackson,Sep 16 2019 04:05:50 PM UTC,Nov 23 2020 07:23:08 PM UTC,Feb 17 2021 11:15:18 AM UTC,,Backlog,,,,Backlog,Admin,Security,,,0,,,,,,"We currently allow users to define commands which acquire sensitive configuration material, like passwords. However, not all environments have available secrets management solutions.

Ops Manager has provided something called {{credentialstool}} which manages a local file containing an encryption key, which is used to decrypt configuration entries.

A similar mechanism, or especially a compatible mechanism, would be convenient for these environments. This would allow system administrators to define keys and restrict access to them with filesystem permissions. Casual viewers of the MongoDB configuration file would be able to perform diagnostics, but wouldn't have the ability to learn protected values.",,,,,,,,,,,,HELP-11295,PRODUCT-1013,,,,,,,,,,,,,,,,,,,1.0,1.0,,,,,,,,,,,,,,,,,,,,5002K00000cfytwQAA,500A000000ZfjDHIAZ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2019-09-25 12:23:53.0,44064000,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,ratika.gandhi(ratika.gandhi),Wed Sep 25 12:23:53 UTC 2019,,,,,,,,,,,,,,backlog-server-security(backlog-server-security),sara.golemon(sara.golemon),spencer.jackson(spencer.jackson@10gen.com),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i49rrr:",,,,,,,"0|i4bkhb:",9223372036854775807,,,,,,,,,,,,Security 2019-12-16,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i49pvj:","Sep 25 2019 12:23:53 PM UTC;sara.golemon;In terms of built-in support for credentialstool encrypted passwords, that would require that the mongod process have access to the encryption key used by credentialstool.  That means either including the key in the config itself (bad), opening the keyfile up to being readable by the mongod process (bad in a different way), or running mongod as root (really bad).  

Alternatively, cloud could extend credentials tool to support decrypting passwords, then use the __exec support already present in config expansions.  Such a tool would still have the same set of options for making the encryption key available as above, but would have the additional option of applying /etc/sudoers rules to allow specific non-root users (e.g. uid:'mongo') to run the decrypt command without an interactive password prompt.
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Support different networks / nics for client & replication traffic,SERVER-1889,13255,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-server-servicearch,alvin,alvin,Oct 05 2010 04:00:10 PM UTC,Nov 21 2020 12:00:05 AM UTC,Feb 17 2021 11:15:18 AM UTC,,1.7.0,,,,Backlog,Replication,,,,26,,,,,,"Problem:
In order to scale network traffic for client connections and replication traffic, there are two options

a) add a NIC
b) swap out a 1Gig for a 10Gig Ethernet Card

Case b) is already supported. However, to support case a) we would need to be able to specify different networks for
-- client connections (and failover of client connections)
-- replication connections

Impact:

This would impact
-- mongod would need to accept connections over more than a single interface
-- replSetInitate configuration would need the ability to specify a different ip/port for the replication traffic


Other:
Would need test cases for the client nic failover from the replication nic failover.

",,,,,,,,,,,,SERVER-34986,PM-1289,,,,,,,,,,,,,,,,,,,3.0,,,,,,,,,,,,,,,,,,,,,500A000000WAs2DIAT,500A000000YfNCeIAN,500A000000ZqQtSIAV,500A000000bWSGQIA4,5002K00000dDI2BQAW,5002K00000cvot8QAA,5002K00000glHKoQAM,5002K00000nEKR7QAO,5002K00000lnmlcQAA,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2011-09-12 14:32:06.0,141609600,,,,,,,,PM-1109,,,,,,,,,,,,,,,,,,,,true,luke.prochazka(luke.prochazka),Mon Aug 22 20:05:47 UTC 2016,,,,,,,,No,,,,,,alvin(alvin),backlog-server-servicearch(backlog-server-servicearch),cwestin(cwestin),jwbito(jwbito),scotthernandez(scotthernandez),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i0732v:",,,,,,,"0|i1rpnb:",6216,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i1j007:","Sep 12 2011 02:32:06 PM UTC;cwestin;I just got request for this from another customer.  They cite the following reasons:

- security, since replication traffic is sent in the clear
  e.g. exchange allows this
- performance
  can apply QoS rules over a WAN link in order to prefer this
- doing this with MySQL and MSSQL today
  easier to manage by differentiating the traffic
  clients won't compete for bandwidth with the replication traffic
","Jun 03 2012 05:56:17 PM UTC;scotthernandez;This can be done today by simply having the configured names resolve to the correct network/interface by the respective clients.

For example, configure all names as relative host names, not fully qualified. Then configure each tier (web/app, replicas, etc) with a different domain search order where the FQDN resolves to the different ip/interface. This can also be done by overriding resolution in any other way, like via /etc/hosts. When the client or other replica member resolve the name they will now point to the correct ip/interface depending on their role.

It would good if it supported this on the server to specify priority/access control as an additional feature for cases like this.","Aug 22 2016 08:05:47 PM UTC;jwbito;We would also like to see the ability to configure clients with different connection URIs, so that the DB host appears to be in the same network sub-domain as the client, while serving clients in various sub-domains.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Using regexp patterns for resource scope in user-defined roles,SERVER-22951,269807,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-server-security,pavel.duchovny,pavel.duchovny,Mar 03 2016 08:21:19 PM UTC,Nov 20 2020 09:51:25 AM UTC,Feb 17 2021 11:15:18 AM UTC,,,,,,Backlog,Security,,,,6,security,,,,,"[Resource document within Collection-Level Access Control | https://docs.mongodb.org/manual/reference/resource-document/#resource-specific-db-collection] currently supports the  following. 
1. Explicit values :
{code:title=inventory collection in products database }

{ db: ""products"", collection: ""inventory"" }

{code}

2.  Empty strings that includes the entire scope :
{code:title=all collections in products database}

{ db: ""products"", collection: """" }

{code}
 Request is to have a pattern  matching on either db or collection fileds, this way permissions can be granted based on the matching  pattern rather then explicit literals.  

3. regexp example 
{code:title=all collections in products database}

{ db: ""products"", collection: ""^inve*"" }

{code}",,,,,,,,,,,SERVER-48632,CS-28436,SERVER-13696,PRODUCT-960,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,500A000000Xz5MuIAJ,500A000000bB3cfIAC,5002K00000e9iPPQAY,5002K00000hRlXqQAK,5002K00000f2GlpQAE,5002K00000jbkA3QAI,5002K00000kEP5CQAW,5002K00000qdYPGQA2,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2016-03-03 20:33:28.0,156470400,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,,2016-03-03 20:21:19.0,,,,,,,,,,,,,,backlog-server-security(backlog-server-security),pavel.duchovny(pavel.duchovny),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i023rj:",,,,,,,"0|i05mm7:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i0xbov:",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Create a mongos test with timeout,SERVER-48249,1352894,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-server-security,shreyas.kalyan,shreyas.kalyan,May 15 2020 07:33:51 PM UTC,Nov 18 2020 06:16:53 PM UTC,Feb 17 2021 11:15:18 AM UTC,,,,,,5.0 Desired,Security,Testing Infrastructure,,,0,,,,,,"For testing that SSL connections fail, it would be helpful to have a way to test that mongos fails to connect to a config server / a shell is unable to connect to a mongos. This would ideally be a bare-bones test with just a config server and a mongos.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,23932800,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,sara.williamson(sara.williamson),2020-05-15 19:33:51.0,,,,,,,,,,,,,,backlog-server-security(backlog-server-security),shreyas.kalyan(shreyas.kalyan),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i699sn:",,,,,,,"0|i64vk7:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i697w7:",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Drop pooled connections to nodes no longer in the replica set after a reconfig,SERVER-36417,581387,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-server-servicearch,jason.carey,jason.carey,Aug 02 2018 03:35:37 PM UTC,Nov 17 2020 06:45:52 PM UTC,Feb 17 2021 11:15:18 AM UTC,,,,,,Backlog,Replication,,,,1,sa-groomed,,,,,"After a repl set reconfig, drop pooled connections to the removed node.

This would allow removal of a node, changes to host name resolution, and adding the node back with a new ip.  Without changes, this either requires a long period to allow connection pools to age out, or manual intervention (if/when we implement SERVER-36416)",,,,,,,,SERVER-36415,PM-1519,,,HELP-7217,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,500A000000bUUbgIAG,500A000000armLAIAY,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2018-08-08 04:45:17.0,32572800,"<s><a href='https://jira.mongodb.org/browse/SERVER-36415'>SERVER-36415</a></s>, <s><a href='https://jira.mongodb.org/browse/PM-1519'>PM-1519</a></s>",,,,,,,PM-2032,,,,,,,,,,,,,,,,,,,,true,ratika.gandhi(ratika.gandhi),Wed Feb 05 20:32:15 UTC 2020,,,,,,,,,,,,,,backlog-server-servicearch(backlog-server-servicearch),jason.carey(jason.carey),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i2mpfb:",,,,,,,"0|i00jt3:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i2mnj3:","Feb 05 2020 08:32:15 PM UTC;jason.carey;PM-1519 introduces the client side support for ismaster with process id.  Marking this ticket as dependent on that work.

We'll have to see after that project wraps if this fell out naturally, or if there's still a small amount of work left to do",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Support cross-database lookup,SERVER-34935,542180,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-query-optimization,adinoyi.omuya,adinoyi.omuya,May 10 2018 05:52:19 PM UTC,Nov 17 2020 08:42:35 AM UTC,Feb 17 2021 11:15:18 AM UTC,,,,,,Backlog,Aggregation Framework,,,,7,,,,,,"This will increase the expressiveness of the aggregation pipeline and allow new applications to be supported by MongoDB.

Work should include banning $lookup stages that reference a foreign DB from non-materialized view definitions.",,,,,,,,SERVER-29159,,,,,,,,,,,,,,,,,,,,,,,,5.0,1.0,,,,,,,,,,,,,,,,,,,,5002K00000nmHevQAE,5002K00000qfrZBQAY,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2018-05-11 13:20:41.0,46569600,<a href='https://jira.mongodb.org/browse/SERVER-29159'>SERVER-29159</a>,,,,,,,PM-282,,,,,,,,,,,,,,,,,,,,true,,Tue Aug 27 17:12:20 UTC 2019,,,,,,,,,,,,,,adinoyi.omuya(adinoyi.omuya@10gen.com),backlog-query-optimization(JIRAUSER1257108),charlie.swanson(charlie.swanson),christian.kurze(christian.kurze),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i2g3xz:",,,,,,,"0|i00sxr:",9223372036854775807,,,,,,,,,,,,Query 2018-12-03,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i2g21r:","May 11 2018 01:20:41 PM UTC;charlie.swanson;[~adinoyi.omuya] did you mean to assign this to yourself?","May 11 2018 02:38:13 PM UTC;adinoyi.omuya;Nope, thanks for the update.","Nov 16 2018 06:04:41 PM UTC;charlie.swanson;Tentatively bringing this into the sprint and assigning to Devin. The scope here will probably have to be constrained to unsharded deployments to avoid breaking things, as a start.","Dec 03 2018 04:20:37 PM UTC;charlie.swanson;Unfortunately [~devin.hilly] has rotated off the query team before we could get this fully working so I'm moving this back onto the backlog user to be picked up in a later sprint.

 

The linked code review has the details on what we did get working and what still needs to be done/investigated. Thanks [~devin.hilly]!","Aug 27 2019 05:12:20 PM UTC;christian.kurze;Is there a tentative date when this issue moves back into active development? 

I have a case here, where data across different stages is modified until usable for the use cases. It involves some $lookups and different databases would be great for easier managment of privileges (e.g. read to the whole refined data, but no access to underlying stages).",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Add support for Czech language in text search,SERVER-12311,105378,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-query-execution,jirutka,jirutka,Jan 09 2014 08:18:26 PM UTC,Nov 14 2020 07:27:09 PM UTC,Feb 17 2021 11:15:18 AM UTC,,,,,,Backlog,Text Search,,,,6,czech,,,,,"Czech is not officially supported by Snowball. However, there’s a complete implementation of the Snowball stemmer for Czech language, including list of stop words etc. on [this page|http://www.fit.vutbr.cz/research/prod/index.php.en?id=133]. It’s released under GPL so I believe you can use it in MongoDB to provide text search for Czech.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,3.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2014-05-10 11:58:44.0,88128000,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,craig.homa(craig.homa),Thu May 03 14:32:41 UTC 2018,,,,,,,,No,,,,,,backlog-query-execution(JIRAUSER1257109),mimkorn(mimkorn),jirutka(jirutka),jennifer.huang(jennifer.huang),josef.sabl(josef.sabl),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i03tf3:",,,,,,,"0|i00uhz:",6459,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i175rr:","May 10 2014 11:58:44 AM UTC;mimkorn;We are considering usage of the full text search capabilities of mongo in our system, however, we need support for Czech language too. We are to make a decision if we should go with ElasticSearch, Solr or wait for this feature to be implemented. Is there any rough guesstimate, when it will be available? Thanks","Sep 30 2015 03:41:06 PM UTC;josef.sabl;This is one of the reasons why we decided not to use MongoDB for our website search. What a shame :-(","May 03 2018 02:32:41 PM UTC;jennifer.huang;One more vote for Czech language.(y)

My customer [http://www.cecg.cz/] would like Czech language support too :)

[https://mongodb.my.salesforce.com/001A000001NKBY7]

See support case: [https://support.mongodb.com/case/00493199] for details.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Add a way to determine a document's rank after a $sort,SERVER-8065,60782,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-query-execution,fommil,fommil,Jan 03 2013 11:35:46 AM UTC,Nov 14 2020 07:26:33 PM UTC,Feb 17 2021 11:15:18 AM UTC,,,,,,Backlog,Aggregation Framework,,,,8,expression,,,,,"It would be useful to be able to add a documents position in a sort to the document. For example, there could be an additional option to the {{$sort}} stage:
{code:js}
{$sort: {
    order: {a: 1, b: 1},
    includeSortIndex: 'index'
}}
{code}

Which would output documents sorted by \{a: 1, b: 1\}, and inject an additional field 'index', containing it's position in the sort order (overwriting an existing field if applicable).

h5. Original Description
Originally posted

https://groups.google.com/d/topic/mongodb-user/PL_g1RCmPsI/discussion

It would be very useful to be able to extract the indexed position of a document from a group statement, or a sort. e.g. consider the use case of building up a leader board / league table.

Workaround suggestions welcome in the meantime.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,6.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2013-01-03 13:07:51.0,158889600,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,craig.homa(craig.homa),Thu Feb 04 23:03:38 UTC 2016,,,,,,,,No,,,,,,asya(asya),backlog-query-execution(JIRAUSER1257109),charlie.swanson(charlie.swanson),eliot(eliot),fommil(fommil),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i05273:",,,,,,,"0|i00u9z:",6384,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i0s46n:","Jan 03 2013 01:39:31 PM UTC;fommil;Hi Stephen,

Not sure what the ""debugging with submitter"" status means. I consider MR / JS console approaches to be (hacky) workarounds. I'd still like to see a feature to insert the position of a document (in an aggregation) into the document through a group or project.

Regards,
Sam","Jan 03 2013 02:43:36 PM UTC;eliot;This could be interesting, but also problematic.
If that projection is the last step in a pipeline, then I'm not sure how much easier it is since you have the position in the client.

This could be very useful if the projection is not the last step.
i.e. do a sort, and the position, then re-sort based on something else.
Then you can see people sorted by name, with their position.

The problem is that requires consistency from all shards.
So it would be a scaling bottleneck.

","Jan 03 2013 02:59:00 PM UTC;fommil;Eliot, exactly this is not the last step in a pipeline for me (there are further constraints and limits, etc).

I don't shard this collection, so that is not a concern. Happy for this to be a no-shards-allowed function.","Jan 03 2013 03:02:00 PM UTC;eliot;We try not to do functions that only work non-sharded, as then people get quite surprised when they loose that functionality.

Will see if there is a way to implement this efficiently sharded.  ","May 15 2013 04:06:03 AM UTC;asya;if SERVER-4588 was implemented that might be a workaround for this.  Since you can basically group on a constant and build up an array with all documents (or at least known fields of interest) and then unwind with index if SERVER-4588 exists.
","Feb 04 2016 11:03:38 PM UTC;charlie.swanson;I've changed the title/description of this ticket to restrict the scope to the position in the {{$sort}}. I believe [Asya's comment above|https://jira.mongodb.org/browse/SERVER-8065?focusedCommentId=335895&page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-335895] describes a way to do this using {{$unwind}} with the {{includeArrayIndex}} option.

However, it is still impossible to get the position in the sort, so this ticket will track that work.

Please feel free to leave a comment if you disagree with this change.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
add a $inOrder operator to $project,SERVER-6257,42907,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-query-execution,redbeard0531,redbeard0531,Jun 29 2012 10:07:41 PM UTC,Nov 14 2020 07:26:05 PM UTC,Feb 17 2021 11:15:18 AM UTC,,,,,,Backlog,Aggregation Framework,,,,0,expression,,,,,"currently range tests need to be written like this:

{code}
        {
                ""$project"" : {
                        ""in_range"" : {
                                ""$and"" : [
                                        {
                                                ""$gt"" : [
                                                        ""$count"",
                                                        10
                                                ]
                                        },
                                        {
                                                ""$lt"" : [
                                                        ""$count"",
                                                        100
                                                ]
                                        }
                                ]
                        },
                        ""count"" : 1
                }
        }
{code}

It would be nice to write this as {'in_range': {$inOrder:[10, '$count', 100]}}

Naming is to be more clear when there are >3 arguments.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2015-06-25 14:35:18.0,54432000,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,craig.homa(craig.homa),Tue May 28 16:39:19 UTC 2019,,,,,,,,No,,,,,,asya(asya),backlog-query-execution(JIRAUSER1257109),redbeard0531(redbeard0531),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i05n7b:",,,,,,,"0|i00u7b:",5922,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i1iw4n:","May 28 2019 04:39:19 PM UTC;asya;I think $switch makes this less relevant...

 ",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Add statement-level statistics to the query plan cache (or elsewhere),SERVER-26084,315165,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-query-execution,shakir.sadikali,shakir.sadikali,Sep 09 2016 02:16:27 PM UTC,Nov 14 2020 07:25:59 PM UTC,Feb 17 2021 11:15:18 AM UTC,,,,,,Needs Further Definition,Diagnostics,Querying,WiredTiger,,6,,,,,,"The current timeseries implementation allows us to infer how often WT I/O requests result in a WT cache hit vs not.  

I define a logical I/O as a single request for a block or page (whatever our most granular request is) whether from cache or disk.

Is there explicit tooling that would let us
- aggregate the actual number of logical I/Os for a given query shape
- aggregate the actual number of logical I/Os for all query shapes
 
and then for the above

- aggregate the number of times the logical I/O was serviced by a WT cache hit
- aggregate the number of times the logical I/O was serviced by a filesystem cache hit
- aggregate the number of times the logical I/O resulted in a physical I/O request",,,,,,,,,,,,SERVER-13220,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2016-09-09 17:55:29.0,26438400,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,craig.homa(craig.homa),Thu Apr 16 19:44:54 UTC 2020,,,,,,,,,,,,,,asya(asya),backlog-query-execution(JIRAUSER1257109),shakir.sadikali(shakir.sadikali),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i01le7:",,,,,,,"0|i010a7:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i01h0f:","Apr 16 2020 07:44:54 PM UTC;asya;Note that the storage access piece of this was implemented in SERVER-38240 and is available in 4.0.9 and later.
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Ability use a GeoHash string vs. Lat/Long coordinates ,SERVER-40203,718958,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-query-execution,sigfrido.narvaez,sigfrido.narvaez,Mar 18 2019 10:46:11 PM UTC,Nov 14 2020 07:25:45 PM UTC,Feb 17 2021 11:15:18 AM UTC,,,,,,Backlog,Geo,,,,0,,,,,,"Many geo-location devices used in Scooters, Bikes and other IoT devices send their geo location using GeoHash vs. Lat/Long pairs. It would be great to be able to pass a GeoHash string on all of the geo-spatial Query & Agg operators. 

 

 ",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2019-03-18 23:14:52.0,60566400,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,craig.homa(craig.homa),Tue Mar 19 00:03:53 UTC 2019,,,,,,,,,,,,,,asya(asya),backlog-query-execution(JIRAUSER1257109),sigfrido.narvaez(sigfrido.narvaez),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i3a4yf:",,,,,,,"0|i00ynz:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i3a327:","Mar 18 2019 11:14:52 PM UTC;asya;What would be stored in the database?  Are they asking to be able to store geohash and query by geohash?  Or store long/lat but be able to query via geohash?

 ","Mar 19 2019 12:03:53 AM UTC;sigfrido.narvaez;It would be great if either geohash or long/lat can be stored in the database & indexed, and be able to query also using either geohash or long/lat",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Create a string accumulator for aggregation,SERVER-15697,164063,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-query-execution,mgervais,mgervais,Oct 16 2014 08:25:47 PM UTC,Nov 14 2020 07:25:36 PM UTC,Feb 17 2021 11:15:18 AM UTC,,,,,,Backlog,Aggregation Framework,,,,1,accumulator,expression,pm1457-nominee,,,"Hi,

I'd like to join all elements in an array in a aggregation. 
A string accumulator, should do the job. Is it plannes to create one?

Thanks",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,7.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2014-10-17 21:46:11.0,108172800,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,craig.homa(craig.homa),Wed Sep 13 15:32:38 UTC 2017,,,,,,,,,,,,,,asya(asya),backlog-query-execution(JIRAUSER1257109),mgervais(mgervais),ramon.fernandez(ramon.fernandez),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i03anr:",,,,,,,"0|i00vkn:",143130,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i019yn:","Oct 17 2014 09:46:11 PM UTC;ramon.fernandez;[~mgervais], can you provide a more detailed example of the kind of data you have and how would you like to manipulate it with this new hypothetical aggregation operator? Sample input and output would help clarify what is it you need, and whether there are alternative ways to do it.

Thanks,
Ramón.","Oct 18 2014 12:01:03 AM UTC;asya;I can see it being useful - if you have something like:

{noformat}
{ _id:1, b: [ ""a"", ""b"", ""c"" ] }
db.collection.aggregate({$unwind:""$b""},  {$group:{_id:""$_id"", bstring:{$concat:""$b""}}})
{ _id:1, bstring: ""abc"" }
{noformat}

I've made an assumption that {{""$concat""}} would work the way {{""$sum""}} does currently, though given that we use {{$sum}} and not {{$add}} maybe it makes sense for concatenating operator to be named something different from the project operator.
 ","Oct 21 2014 07:59:10 AM UTC;mgervais;Hi,

Thanks for your responses.

Asya has given a good example. I've an array of string, and  I  need to concatenate values with a separator (or not) to generate a key and check if this key exists in a map of rules.

In Java lambda, it's possible to reduce values by concatenating them.

Have I been clear enough ? :)","Oct 21 2014 04:02:44 PM UTC;ramon.fernandez;Thanks for following up [~mgervais], we've marked this ticket to be considered for future improvements in the aggregation framework.","Aug 02 2015 09:23:44 PM UTC;asya;Suggest we use this ticket to track operator equivalent to concat strings in array.  It's possible that if SERVER-17258 is implemented first, this one will become syntactic nicety (like $concatArrays, $avg, $sum(Arrays) accumulators for arrays in $project.
","Sep 13 2017 03:32:05 PM UTC;asya;As of 3.4 it's possible to do this via $reduce something like this:

{noformat}
db.c.aggregate({$addFields:{bAsString:{$reduce:{
        input:""$b"", 
        initialValue:"""", 
        in:{$concat:[""$$value"",""$$this""]}
}}}})
{ ""_id"" : 1, ""b"" : [ ""a"", ""b"", ""c"" ], ""bAsString"" : ""abc"" }
// with delimiter 
db.c.aggregate({$addFields:{bAsString:{$reduce:{
        input:{$slice:[""$b"",1,{$size:""$b""}]}, 
        initialValue:{$arrayElemAt:[""$b"",0]}, 
        in:{$concat:[""$$value"",""-"",""$$this""]}
}}}})
{ ""_id"" : 1, ""b"" : [ ""a"", ""b"", ""c"" ], ""bAsString"" : ""a-b-c"" }
{noformat}
","Sep 13 2017 03:32:38 PM UTC;asya;Leaving the ticket open to track whether we want to create a $group accumulator ""$concat"".
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Dynamic weights in full text search,SERVER-29085,380945,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-query-execution,juanroy,juanroy,May 05 2017 07:56:56 AM UTC,Nov 14 2020 07:25:28 PM UTC,Feb 17 2021 11:15:18 AM UTC,,,,,,Backlog,Text Search,,,,2,,,,,,"Currently, when we need to execute a full text search query with weights we must specify these in the createIndex command.

If we need to modify these weights we have to create a new index and drop the old one.

In order to improve the flexibility, we could specify the weights in the query and not in the index (ElasticSearch does it in this way.). Or in both, having priority those specified in the query?

Thank you!",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2017-05-05 14:38:42.0,119318400,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,craig.homa(craig.homa),Sun May 07 14:29:15 UTC 2017,,,,,,,,,,,,,,backlog-query-execution(JIRAUSER1257109),juanroy(juanroy),kelsey.schubert(thomas.schubert),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i1othj:",,,,,,,"0|i00x1b:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i0mec7:","May 05 2017 02:38:42 PM UTC;kelsey.schubert;Hi [~juanroy],

Thanks for the feature request. I've marked this ticket to be considered by the Query Team. Please continue to watch for updates.

Kind regards,
Thomas","May 07 2017 02:29:15 PM UTC;juanroy;Thanks, @Thomas Schubert",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Add server status counter ""time limit exceptions""",SERVER-11243,94651,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-query-execution,rassi,rassi,Oct 17 2013 05:35:15 PM UTC,Nov 14 2020 07:25:02 PM UTC,Feb 17 2021 11:15:19 AM UTC,,2.5.2,,,,Backlog,Diagnostics,,,,1,neweng,,,,,"Counter will be incremented in checkForInterrupt(), before the ErrorCodes::ExceededTimeLimit user assertion is thrown.",,,,,,,,,,,,SERVER-2212,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,231465600,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,craig.homa(craig.homa),2013-10-17 17:35:15.0,,,,,,,,No,,,,,,backlog-query-execution(JIRAUSER1257109),rassi(rassi@10gen.com),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i0405r:",,,,,,,"0|i00ugv:",7277,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i17dpj:",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
n-dimensional geospatial search,SERVER-691,11407,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-query-execution,eliot,eliot,Mar 02 2010 07:31:58 AM UTC,Nov 14 2020 07:24:56 PM UTC,Feb 17 2021 11:15:19 AM UTC,,,,,,Backlog,Geo,Indexing,,,50,,,,,,for 2d you cna use http://www.mongodb.org/display/DOCS/Geospatial+Indexing,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,16.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2010-03-03 23:43:43.0,46396800,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,craig.homa(craig.homa),Thu Aug 29 22:10:22 UTC 2019,,,,,,,,No,,,,,,Alex71(alex71),mixdev(mixdev),backlog-query-execution(JIRAUSER1257109),publicocean0(publicocean0),edmnc(edmnc),eliot(eliot),starefossen(starefossen),ianmercer(ianmercer),jamilbk(jamilbk),jhurliman(jhurliman),baccanno(baccanno),arjunsol(arjunsol),noeska(noeska),syagev@gmail.com(syagev@gmail.com),vradu.alex@gmail.com(vradu.alex@gmail.com),octave(octave),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i07ghb:",,,,,,,"0|i00tv3:",6044,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i1iw53:","Mar 03 2010 11:43:43 PM UTC;jhurliman;I would be interested in 3D geospatial searches for our virtual world backend (http://openmetaverse.googlecode.com/). We're currently using 2D MySQL and additional filtering in PHP, and considering PostgreSQL or other alternatives such as MongoDB.","Sep 08 2011 07:04:11 PM UTC;ianmercer;+1 but don't stop at 3.  I want to be able to search multi-dimensional spaces with an arbitrary number of dimensions.","Sep 13 2011 07:15:30 AM UTC;edmnc;+1 for n-dimentional. We use geospatial index with bit interleaving to turn 5 numbers into 2 and then sort by those. n-dimensional index would make this much more precise and simpler.","Sep 13 2011 07:40:38 AM UTC;octave;+1 for n-dim.
it enables to use mongodb for collaborative filtration purposes!","Sep 13 2011 07:44:58 AM UTC;noeska;This would be a great feature indeed. For now I implemented this by building a k-d Tree and storing that in a collection for fast graph traversal.","Mar 07 2012 06:12:33 AM UTC;mixdev;N-dim spatial index will be awesome for clustering algorithms. Please prioritize this. ","May 05 2012 01:41:56 AM UTC;jamilbk;+1. N-Dimensional distance queries would be highly useful for similarity and other clustering applications!

Noeska -- how are you implementing your KDtree in a collection?
","May 05 2012 06:44:43 AM UTC;noeska;Hi Jamil, I pasted my kd-tree python code for you here: http://pastebin.com/5e9AAQ7F
I hope that helps!","May 05 2012 03:54:42 PM UTC;jamilbk;Thanks Noeska.

I could implement nearest neighbor in non-realtime MapReduce but it would really help to have native DB implementation of this to be fast.

Even simple n-dimension Euclidean distance would suffice for now. http://en.wikipedia.org/wiki/Euclidean_distance.

Maybe I can hack it in on my own. Let the Source be with me...","Mar 11 2013 09:19:19 AM UTC;baccanno;I would also be very interested by this feature especially for 3D rendering (where you need 4 dimensional storage with the normalisation parameter !)","Oct 11 2013 04:45:09 PM UTC;Alex71;Very interested in such a feature to build a backend for a 3d world","Oct 15 2013 08:42:17 AM UTC;arjunsol;What gets me is that Thermopylae Sciences have largely solved this problem for 10-gen: http://www.slideshare.net/nknize/mongo-sv-knizefinal

Mongos licensing states that ""The goal of the server license is to require that enhancements to MongoDB be released to the community.""

http://www.mongodb.org/about/licensing/

Am I missing something here?

","Nov 17 2013 09:25:55 PM UTC;starefossen;Also related to this one: https://jira.mongodb.org/browse/SERVER-9220","May 26 2016 12:08:42 PM UTC;syagev@gmail.com;This could be super useful for machine learning / classification problems! ","May 03 2018 11:09:59 PM UTC;publicocean0;I m interessed in this  feature . In my case for 1d vectors","Aug 29 2019 10:10:22 PM UTC;vradu.alex@gmail.com;X-tree would be a good candidate for this.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Support longitude out of bound of [-180, 180]",SERVER-15626,163378,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-query-execution,siyuan.zhou,siyuan.zhou,Oct 13 2014 08:14:04 PM UTC,Nov 14 2020 07:23:53 PM UTC,Feb 17 2021 11:15:19 AM UTC,,,,,,Backlog,Geo,,,,0,,,,,,"Since some map libraries like leaflet support longitude less than -180 or greater than 180, but they are considered as invalid longitude in MongoDB. We can wrap the longitude out of bound into \[-180, 180\].  Note that this is only unambiguous in GeoJSON shapes - legacy points may exceed these bounds.

Reported in SERVER-15388",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,200275200,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,craig.homa(craig.homa),2014-10-13 20:14:04.0,,,,,,,,,,,,,,backlog-query-execution(JIRAUSER1257109),siyuan.zhou(siyuan.zhou@10gen.com),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i03b2v:",,,,,,,"0|i00vjz:",142465,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i0yq1b:",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Make a command to copy a collection locally, then have db.collection.copyTo use it.",SERVER-15571,162666,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-query-execution,rod.adams,rod.adams,Oct 08 2014 08:08:45 PM UTC,Nov 14 2020 07:23:45 PM UTC,Feb 17 2021 11:15:19 AM UTC,,,,,,Backlog,Usability,,,,0,,,,,,"Right now, db.collection.copyTo is implemented in as a shell helper which runs a server side javascript method. This serverside feature is nice, since it eliminates network hops to and from the client for each document.  However, this implementation suffers the problem using {{eval()}}, which in any situation with auth enabled, requires permissions that we actively advise not giving anybody.

Instead, what if there was a proper command on the server for this? We have several options for copying from another host, so it would seem to fit in. Once it exists, copyTo could be reimplemented to call the command, without the need for eval.",,,,,,,,,,,,SERVER-732,PM-828,,,,,,,,,,,,,,,,,,,4.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2016-03-07 21:48:24.0,82944000,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,craig.homa(craig.homa),Mon Jul 02 19:48:20 UTC 2018,,,,,,,,,,,,,,adam.midvidy(adam.midvidy),asya(asya),backlog-query-execution(JIRAUSER1257109),rod.adams(rod.adams),sara.golemon(sara.golemon),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i03bdj:",,,,,,,"0|i00tkn:",141760,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i0s5x3:","Mar 07 2016 09:48:24 PM UTC;adam.midvidy;Does cloneCollection (https://docs.mongodb.org/manual/reference/command/cloneCollection/) serve your use case?","Mar 15 2016 03:27:50 PM UTC;rod.adams;I don't believe it does. The case I'm talking about is more often someone wanting to move a collection from one database to another, within the same server. I could see cloneCollection work, if it was allowed to rename the collection, and had a ""local"" backdoor which could be made much faster.","Mar 23 2017 02:42:01 PM UTC;asya;Within the same DB (which is all copyTo can do, I believe) we have aggregation with ""$out"" stage.
","Jul 02 2018 07:48:20 PM UTC;sara.golemon;Additionally, the \{renameCollection:...} command (which aggregate $out uses internally to make the collection creation appear atomic, would precisely serve the purpose [~rod.adams] described including being able to work across databases (which neither the agg pipeline nor collection.copyTo() currently support.

There is still possibly a use case for a copyCollection which works across databases, or possibly: \{renameCollection: ..., dropSource: false} if one were to piggy-back on the existing command.  Or perhaps optimizing the case in cloneCollection where the from server is ourselves.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
findAndModify option to return before and after,SERVER-7968,59717,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-query-execution,marcelo,marcelo,Dec 17 2012 10:28:16 PM UTC,Nov 14 2020 07:23:34 PM UTC,Feb 17 2021 11:15:19 AM UTC,,,,,,features we're not sure of,Write Ops,,,,0,insert,query,,,,"I think findAndModify should enable to request all valid data, i.e. All the values from the fields when the document is found and the new _id if upserted.

Currently I want to decide if I need the old data or the new _id. Because i need both I have to restort back to a separate find and update.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,5.0,,,,,,,,,,,,,,,,,,,,,5002K00000nECiqQAG,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2012-12-17 22:43:59.0,232761600,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,craig.homa(craig.homa),Wed Oct 02 17:26:32 UTC 2013,,,,,,,,No,,,,,,backlog-query-execution(JIRAUSER1257109),derick(derick),marcelo(marcelo),scotthernandez(scotthernandez),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i053bb:",,,,,,,"0|i0101z:",6380,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i1ivpz:","Dec 17 2012 10:29:38 PM UTC;marcelo;Strange, I did not intended to submit this to the php driver although it is really my frontend.","Dec 17 2012 10:43:59 PM UTC;derick;[~marcelo] Should I move this to the SERVER project then?","Dec 17 2012 11:30:41 PM UTC;marcelo;Yes please","Dec 17 2012 11:32:18 PM UTC;marcelo;And I meant: ""Currently I have to decide"", not ""currently I want to decide""","Oct 02 2013 05:26:32 PM UTC;scotthernandez;Marcelo,

Do you have a use-case which you expect to work? A script/sample would help to make this request clear.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Allow findAndModify/Update to use a tailable cursor (w/await_data),SERVER-11753,98665,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-query-execution,mattparlane,mattparlane,Nov 18 2013 12:51:53 AM UTC,Nov 14 2020 07:23:04 PM UTC,Feb 17 2021 11:15:19 AM UTC,,,,,,features we're not sure of,Querying,,,,11,,,,,,"If one wanted to create a distributed message queue using MongoDB, the way to go about it would be to use tailable cursors to avoid having to poll, and use findAndModify to avoid the same message going to multiple consumers.

Either of these options are available separately, but not together. Having these two options available together would make MongoDB able to be used as a really nice message queue.

This was discussed briefly in SERVER-8602.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,228787200,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,craig.homa(craig.homa),2013-11-18 00:51:53.0,,,,,,,,No,,,,,,backlog-query-execution(JIRAUSER1257109),mattparlane(mattparlane),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i03wev:",,,,,,,"0|i0102f:",5042,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i179v3:",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
create graph database abilities on top of existing data,SERVER-16561,174789,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-query-execution,sallgeud,sallgeud,Dec 16 2014 04:02:48 PM UTC,Nov 14 2020 07:22:25 PM UTC,Feb 17 2021 11:15:19 AM UTC,,,,,,Needs Further Definition,Indexing,Performance,,,2,,,,,,"A great way to add some relational-ness to the database and give it more powerful features using data already in the system would be to implement a method to define nodes and vertices of a graph through some definition or configuration of an existing collection or set of collections, much the way you'd define an index.

Currently many of us are using another or our own custom build graph databases to get around quickly solving relational shortfalls well identified in mongo. Maintaining the same data in two systems for this could easily be overcome and improve the lives of many.

In the same way that you've improved your database by adding text indexing, collection / document locking, etc, it would be great to see this layer added on top for those of us with wildly complex relationships to create, but for whom a document database is still substantially better than a traditional relational SQL database.

There are others in the document db space doing this, but your document and api implementation are vastly superior. It would be great to see you give some method for self-defined n-tiered relationships through a graph style while keeping the query language as simple as possible.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,4.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2014-12-16 16:11:22.0,137462400,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,craig.homa(craig.homa),Sun Oct 09 18:57:56 UTC 2016,,,,,,,,,,,,,,asya(asya),backlog-query-execution(JIRAUSER1257109),sallgeud(sallgeud),bugslayer(bugslayer),ramon.fernandez(ramon.fernandez),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i035rj:",,,,,,,"0|i0109z:",153165,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i0ll9j:","Dec 16 2014 04:11:22 PM UTC;ramon.fernandez;[~sallgeud], can you please provide further information of what an ideal implementation would do? Details on what you're currently doing (or any similar existing system) and how is MongoDB falling short, samples of the data model, semantics... Anything that can provide a better picture and define the scope for this feature request.

Thanks,
Ramón.","Dec 16 2014 04:30:01 PM UTC;sallgeud;Sure. Some of that I'll have to provide privately. The short and sweet of it is:

We have data that's going to mostly fit a schema. However, being rigid about that schema is not important as it allows us to do internal schema changes without ever modifying the database.  

Within that schema are references from one document to another, typically defined in an property that's an array within each document. This lets us know that content in document A relates to documents B,C,D, for example.  We also provide functionality that allows our users to create formulas to do simple or even very complex math or functions against data n-tiers away. So in our system, we allow you to say, for example, that you want to add all the great-grandparent documents ""Age"" properties of document A.

So what we've got is a graph of all our data relationships which allows us to find grandparents of A through a specific relationship (property with array of _ids) in order to properly bring back some aggregation. Instead of querying A, all of A's relationships (Ar), all of Ar's relationships (Ar2) and then all of Ar2's relationships (great-grandparent), we simply query the graph and get the list back in one set of _ids.  

Alternately, in that formula scenario, we may change one of the great-grandparent documents and thus need to know all of the great-grandchildren who need to have their data updated based on any changes.

And that's the simple explanation. We actually do stuff wildly more complicated than that in some cases in order to accomplish some really cool features.

{quote} side note: In theory this could also be accomplished with the concept of Sub-selects like many SQL databases have, but would not let us define the relationship between data using properties. So, I've suggested something more powerful. sub-selects and n-tier sub-selects also work for most and would work in 80-90% of our cases.
{quote}","Sep 01 2015 03:05:06 AM UTC;bugslayer;In response to ""what an ideal implementation would do...what [people] are currently doing...samples of data models, semantics...""

One thing to consider carefully would be the Tinkerpop Blueprints API (see https://github.com/tinkerpop/blueprints/wiki). There is a 3rd party MongoDB backed implementation in Java that you can see at https://github.com/datablend/blueprints-mongodb-graph, but the original developer of that project has moved in a different direction (see https://groups.google.com/forum/#!topic/gremlin-users/nF-OUsQ4KVw), so it is unmaintained, and likely to never be maintained again. The implementation is also external to the database server, so likely had substantially lower performance than a more direct implementation could likely have provided (and the performance concerns of additional abstraction layer were a key factor in the author's abandonment of that project.)

A core level Blueprints implementation (similar to what ArangoDB and/or OrientDB have) would be an ideal first step, since this would allow the community to use the substantial and well maintained toolset associated with these APIs. This would provide a familiar, functional, comfortable interface for anyone familiar with graph databases, even if no other support was added.

As far as core language support, you presumably need some graph definition options for existing methods, some structural requirements for graph documents, and a couple of graph traversal operators for queries and pipeline. I would suggest:
 - graph: <boolean> option for .createCollection(). If true, collection actually stores vertices and edges for a graph.
 - graphVertexType: <string> and graphEdgeType: <string> options for .createIndex(). Optional, and mutually exclusive. When either is set, index applies only to the vertex or edge that has the given type. Can only be set on collections created with graph: true. This allows for targeted indexing of specific aspects of the graph without indexing everything. This could be worked around with some ugly hacks (based on sparse indexes) if omitted, but I think the extra options actually offer a more clean interface in this situation.
 - graphEdge: <boolean> option for .insert(), .update(), and .remove(). If true the operation manipulates an edge. If false (default) it manipulates a vertex.
 - Special fields required for all vertex records: {_type: <string>}
 - Special fields required for all edge records {_type: <string>, _in: {_id: <record id>, <shard key>: <shard key type, optional>}, _out: {_id: <record id>, <shard key>: <shard key type, optional>}}
 - $graphIn and $graphOut to traverse inbound and outbound edges. Only works when querying a graph collection. Ideal semantics in my mind would be: {$graphIn: {edge: <string>, as: <string, optional>, query: <object, optional>, queryEdge: <object, optional> }}. ""edge"" is required, and indicates the type of edge to traverse. ""as"" is optional, and indicates a document property to return the edge and connected vertices in, and is especially useful in pipelines. ""query"" is optional and allows additional filtering on the connected vertices (including additional $graphIn/$graphOut operators). ""queryEdge"" optionally allows filtering of the match based on any additional properties stored on the edge.

I think it is extremely important that any graph implementation fully support sharding. In particular, the graph collection should be able to be defined with a shard key that can be used to shard all vertices and edges. All vertices and edges in the collection would share the same shard key, regardless of type, which allows a high level of control over cardinality and query isolation during graph traversal. Sharding of a vertex is easy, and would work as with any other collection. Sharding of edges would be slightly more complicated: where _in and _out have the same shard key, it shards just like a vertex (except that _in and _out were evaluated for the key), and stored together using the same partition ranges, such that a vertex is always stored on the same shard as the connected edge. Where _in and _out are different (a so called ""split edge""), the edge would need to be stored on each shard, again, so that every edge for each vertex can be found on the same shard. I know that gets into territory that you have been avoiding (a single record split across multiple servers as a result of a split shard key), I don't know if that is a deal breaker for this or not.

Other possibilities to consider:
 - Possibly consider a graphEdge: <boolean> option for .find*() operations to allow querying of the edges directly, independent of any vertices. This would require an additional parameter for at least some (maybe all?) of these methods.
 - As an alternative to graphVertexType: <string> and graphEdgeType: <string> options for .createIndex(), consider a $value operator or similar for keys to allow an index to target only records with specific values. This would be a generalization of the same thing. Syntax something like: db.collection.createIndex( { _type: { $value: ""person"" } } ) to target only records matching {type: ""person""}
 - Instead of _type, consider _vertexType and _edgeType for better distinction between vertices and edges. This might also eliminate the need for the proposed graphEdge option, and would work better with the more generic alternative on .createIndex().
 - Future improvements might include semantics for enforcement of edge schema (what what types of vertices can be connected in which ways (1*1, 1*N, N*N, N*N unique, N*N with duplicates) using which edges.
 - Atomic inserts and updates to a batch of vertices and edges.","Oct 09 2016 06:57:56 PM UTC;asya;3.4 will add a new stage called [$graphLookup to aggregation framework|https://docs.mongodb.com/master/release-notes/3.4-reference/#pipe._S_graphLookup].

Need to determine how much of desired graph functionality remains in this ticket.
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Support ROLLUP function in the $group aggregation operator,SERVER-12927,115124,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-query-execution,linda.qin,linda.qin,Feb 27 2014 02:47:26 AM UTC,Nov 14 2020 07:22:01 PM UTC,Feb 17 2021 11:15:19 AM UTC,,,,,,Backlog,Aggregation Framework,,,,0,accumulator,expression,,,,"Like the ROLLUP command in SQL. So that when we use $group operator in the aggregation framework, we can not only calculate aggregate values for each group, but also get the aggregate values for all the groups. ",,,,,,,,,,,,SERVER-15611,SERVER-6365,SERVER-23654,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,500A000000UaVfUIAV,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2014-09-03 02:32:57.0,203817600,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,craig.homa(craig.homa),Wed Sep 03 02:32:57 UTC 2014,,,,,,,,No,,,,,,backlog-query-execution(JIRAUSER1257109),linda.qin(linda.qin@10gen.com),Deborah(deborah),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i03pnj:",,,,,,,"0|i00v9j:",104378,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i01e3z:","Sep 03 2014 02:32:57 AM UTC;Deborah;is there any solution?",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Allow client to specify or initially obtain op id,SERVER-19658,223348,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-query-execution,andre.defrere,andre.defrere,Jul 30 2015 03:57:44 AM UTC,Nov 14 2020 07:21:46 PM UTC,Feb 17 2021 11:15:19 AM UTC,,,,,,Backlog,Internal Code,,,,0,,,,,,"Currently it is necessary to query the currentOp output in order to determine which operations belong to a client.  It would be helpful if the client could obtain (or define) the op id (on cursor creation for example, or in a command result) so that the client could, for example 'clean up' after itself in the case of failure (or long running query).

For a practical example, the shell currently searches for all operations with it's own client address, in order to kill them when ctrl+c.  If the shell knew the op ids of the operations that it was running, it would be a cleaner way of killing those operations on ctrl+c",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,500A000000UaXfJIAV,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,175305600,,,,,,,,,,,,,,,,,,,,,,,,,,,,false,craig.homa(craig.homa),2015-07-30 03:57:44.0,,,,,,,,,,,,,,andre.defrere(andre.defrere),backlog-query-execution(JIRAUSER1257109),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i02o9r:",,,,,,,"0|i00vwf:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i0xy8n:",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Add Statistics to WriteResult Responses,SERVER-14379,144352,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-query-execution,djones@squarespace.com,djones@squarespace.com,Jun 27 2014 06:41:06 PM UTC,Nov 14 2020 07:20:49 PM UTC,Feb 17 2021 11:15:19 AM UTC,,,,,,Backlog,Write Ops,,,,2,,,,,,"Currently there is no information about the performance of a write in WriteResult. Having this information would be great. Here are some things that would be nice to have:

* Total execution time
* Time waiting to acquire lock
* Time holding lock
* Time waiting for replication 

To clarify the last point, this would be the additional time that the primary waited to hear a replication response from a secondary in the case that a write concern > 1 is used.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,209606400,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,craig.homa(craig.homa),2014-06-27 18:41:06.0,,,,,,,,,,,,,,backlog-query-execution(JIRAUSER1257109),djones@squarespace.com(djones@squarespace.com),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i03hvj:",,,,,,,"0|i00vg7:",124826,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i0yzc7:",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
add db.collection.getInfo() collection method,SERVER-33148,493431,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-query-execution,adinoyi.omuya,adinoyi.omuya,Feb 06 2018 09:00:45 PM UTC,Nov 14 2020 07:20:36 PM UTC,Feb 17 2021 11:15:19 AM UTC,,,,,,Backlog,Querying,Security,,,0,neweng,,,,,"We already have [{{db.getCollectionInfos()}}|https://docs.mongodb.com/manual/reference/method/db.getCollectionInfos/]. However, numerous users have run into issues where they aren't able to get information specific to a collection (information such as what {{listCollections}} provides) because they do not have the necessary privileges to do so.

Exposing a new method on the collection, one that returns the same information as {{db.getCollectionInfos()}} - but for the current namespace - will address most of these issues.",,,,,,,,,,,,SERVER-25804,,,,,,,,,,,,,,,,,,,,3.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2018-02-09 15:51:03.0,95299200,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,craig.homa(craig.homa),Fri Feb 09 15:59:25 UTC 2018,,,,,,,,,,,,,,adinoyi.omuya(adinoyi.omuya@10gen.com),asya(asya),backlog-query-execution(JIRAUSER1257109),kyle.suarez(kyle.suarez),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i27tpb:",,,,,,,"0|i00y3j:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i27rt3:","Feb 09 2018 03:51:03 PM UTC;kyle.suarez;[~adinoyi.omuya], would it be sufficient to provide this information in the {{$collStats}} aggregation stage? Are there particular auth requirements that we should be aware of?

[~spencer.jackson], should this go to Platforms if it's a security/privilege related thing?","Feb 09 2018 03:52:07 PM UTC;asya;It seems that the related ticket is the more correct solution - allow anyone to run listCollections but only return to them things they can see?
","Feb 09 2018 03:59:25 PM UTC;adinoyi.omuya;[~kyle.suarez] yes, that would suffice. I'm primarily requesting a feature tantamount to {{db.getCollectionInfos()}} - but for collections. AFAICT, a {{read}} role (or a {{colstat}} privilege) on the namespace should be all that's needed.

[~asya] I prefer this solution since it won't affect existing behavior in {{listCollections}} that users might be relying on. ",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
$cond operator should allow $match as a boolean expression,SERVER-9606,74523,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-query-execution,dillonkrug,dillonkrug,May 07 2013 05:16:48 PM UTC,Nov 14 2020 07:20:30 PM UTC,Feb 17 2021 11:15:19 AM UTC,,,,,,Backlog,Aggregation Framework,,,,3,asya,expression,needs-scope,,,"When using $cond in projections, it would be useful to have $match as a boolean expression.


Use Case:

{code:javascript} 
db.objects.aggregate([
	{
		$match: { status: ""active"" }
	}, {
		$project: {
			name: 1,
			meta: 1,
			tags: 1,
			score: {
				$add: [
					{
						$cond:[{
							$match: { tags: ""a tag I like"" }
						}, 100, 0]
					}, {
						$cond:[{
							$match: { tags: ""a tag I really like"" }
						}, 250, 0]
					}, {
						$cond:[{
							$match: { tags: ""a tag I dislike"" }
						}, -100, 0]
					}, {
						$cond:[{
							$match: { ""meta.promoted"": true }
						}, 1000, 0]
					}
				]
			}
		}
	},{
		$match: { score: { $gt: 0 } }
	}
])
{code} 


This would eliminate the need to add other $cond expressions like $in (SERVER-6146)






",,,,,,,,,,,,SERVER-8582,REALMC-6,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,Fully Compatible,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2017-05-19 23:53:01.0,57542400,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,craig.homa(craig.homa),Mon Apr 22 22:50:23 UTC 2019,,,,,,,,No,,,,,,asya(asya),backlog-query-execution(JIRAUSER1257109),grisanty.carlos@c-ven.com(grisanty.carlos@c-ven.com),dillonkrug(dillonkrug),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i04j7z:",,,,,,,"0|i00ubr:",7130,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i0s10v:","Apr 17 2019 08:02:41 PM UTC;grisanty.carlos@c-ven.com; 

Is there any difference between $eq and $match?

In my case I used the $eq instead of $match.

I think the solution you seek is something like this:

$cond: [ { $eq: [ tags: ""a tag I like"" ] }, 100, 0 ]","Apr 22 2019 10:50:23 PM UTC;asya;[~grisanty.carlos@c-ven.com] this ticket exists because there are tests that one can do in a match expression that cannot be expressed in an aggregation expression.  $eq is not one of them (in other words equality can be easily done already with $eq).  One such missing example are $geo related match expressions, among others.

 ",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
open location code support,SERVER-43314,925831,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-query-execution,lukas.strassel@mobilehead.de,lukas.strassel@mobilehead.de,Sep 13 2019 12:11:32 PM UTC,Nov 14 2020 07:20:06 PM UTC,Feb 17 2021 11:15:19 AM UTC,,,,,,Backlog,Geo,Querying,,,0,,,,,,"Hello,
we're currently developing an application which requires us to:
1. check in geo points are withing the radius of another point, which is easily solvable via `$geoWithin` & `$centerSphere`
2. check if a single point is within the radius of other points with a given radius, which essentially is the other side of the first coin.

I think 2) is not solvable in a way satisfying our performance needs.

While we can use `$geoNear` we cannot limit the results with `maxDistance` as each point might have a different radius. So we calculate the distance via geonear and then start sorting out entries in the next stage.

While:
https://jira.mongodb.org/browse/SERVER-30522 and
https://jira.mongodb.org/browse/SERVER-13667


might be solutions to that problem i'm wondering if it would make sense to also support *open-location-codes* as [https://github.com/google/open-location-code] they are simple string representations and ~imperfect circles(+-3m) are perfectly fine for a lot of application needs.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2019-09-16 16:29:45.0,44841600,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,craig.homa(craig.homa),Mon Sep 16 16:29:45 UTC 2019,,,,,,,,,,,,,,backlog-query-execution(JIRAUSER1257109),daniel.hatcher(daniel.hatcher),lukas.strassel@mobilehead.de(lukas.strassel@mobilehead.de),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i494pj:",,,,,,,"0|i00z47:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i492tb:","Sep 16 2019 04:29:45 PM UTC;daniel.hatcher;Thank you for the suggestion. I'll forward it to our Query team for consideration.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Ability to iterate over capped collection objects in insert order starting from random member.,SERVER-4116,23918,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-query-execution,marko,marko,Oct 21 2011 05:41:55 PM UTC,Nov 14 2020 07:20:02 PM UTC,Feb 17 2021 11:15:19 AM UTC,,,,,,Backlog,Querying,,,,2,,,,,,"In my case i will index the members of a capped collection by key/id.  I will then need to query a random member, then start iterating over all the following members in insert order.  I can do this starting from the beginning of the collection, but i need to start from any point inside the collection.  Here is a related discussion...
http://groups.google.com/group/mongodb-user/browse_thread/thread/ce5fea549a21d47c

Thank you.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,294278400,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,craig.homa(craig.homa),2011-10-21 17:41:55.0,,,,,,,,No,,,,,,backlog-query-execution(JIRAUSER1257109),marko(marko),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i06ct3:",,,,,,,"0|i00u0n:",6269,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i11oif:",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
javascript sort helper for custom sorting / indexing,SERVER-153,10294,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-query-execution,eliot,eliot,Jul 13 2009 11:27:33 AM UTC,Nov 14 2020 07:19:41 PM UTC,Feb 17 2021 11:15:19 AM UTC,,,,,,Backlog,Indexing,,,,108,js-in-agg,udf,,,,,,,,,,,,,,,,SERVER-5751,SERVER-14784,,,,,,,,,,,,,,,,,,,16.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2011-02-23 00:03:05.0,145756800,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,craig.homa(craig.homa),Wed Jul 06 03:23:33 UTC 2016,,,,,,,,,,,,,,backlog-query-execution(JIRAUSER1257109),fresheneesz(fresheneesz),dpamio(dpamio),eliot(eliot),ihristov(ihristov),keithbranton(keithbranton),flashy(flashy),niccottrell(niccottrell),nickh(nickh),liqiang(liqiang),rgpublic(rgpublic),cthulhu(cthulhu),serbrech(serbrech),baobeimm(baobeimm),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i07mpz:",,,,,,,"0|i00tun:",6355,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i024lj:","Feb 23 2011 12:03:05 AM UTC;keithbranton;I'd love to see a little detail on what this means.

If this is going to allow the use of expressions in sorts and ""function indexes"" then I wish I had more than one vote!

","May 14 2011 03:06:09 PM UTC;niccottrell;I would like to be able to sort the results based on a parameter, in this case the length of an example sentence I am doing a fuzzy match for. I'd like to be able to sort by something like:

""-Math.abs(textLength-28)"" 

and be able to pass a parameter instead of a hardcoded value.
","Sep 27 2011 08:22:19 PM UTC;cthulhu;I see that some thing like:

db.coll1.find().sort({ 
  $by : function( a, b ){ 
    return a._id < b._id 
  }
}).limit(100)

I could even add tests, or help with implementation, since i have some C++/STL/boost backgrounds.

That could be very useful feature","Oct 22 2011 02:15:12 AM UTC;baobeimm;I have an array defined. For example:

[{""name"":""food"", ""value"":1}, {""name"":""car"", ""value"":2}]

I would like to be able to sort by the value but on those with name either match ""food"" or ""car""","Feb 03 2012 04:31:50 PM UTC;nickh;Could this be used to sort alphabetically on a field, and put documents with a null value at the end of the result set?","Feb 06 2012 06:01:41 AM UTC;eliot;@nick - yes","Feb 06 2012 03:47:22 PM UTC;nickh;That would be a very, very useful improvement to MongoDB, then. Thanks, Eliot.","Feb 14 2012 08:29:24 AM UTC;serbrech;Wouldn't this mean tha mongodb will have to iterate over the whole collection to sort the result?
This is rarely a good option.

@NickHoffman to do this, I think there could/should be a much simpler sort option, like in SQL : null last, or null first.","Feb 14 2012 08:49:16 AM UTC;rgpublic;@Stephane: No, the title says ""custom sorting / *indexing(!)*"". This feature, at least as far as I understand it (@Eliot: please correct me if I'm wrong), means that one would be able to create an index on the functional result of any javascript calculation and subsequently make use of it during a query. Right now, for instance, we are using a property named ""folder"" with values like ""this/is/a/path"". At the moment we cannot query the name of the last folder (""path"") efficiently. Sorting by the last folder would be similarly problematic. Thus, we have created a second property ""_auto_foldername"" and try to keep this in sync. You need to do this everywhere in your code where the property changes. Admittedly not really a great solution. Implementing this feature would allow us to get rid of these unnecessary helper properties (we got a lot of them) and just create a special index on say folder.substr(folder.lastIndexOf(""/"")). Now, the interesting question would be how Mongo will detect when it can use that index. I suppose the easiest most-straightforward method would be to do a hash fingerprint of the function and just compare that. Furthermore, the function would have to be deterministic (i.e. using no random numbers etc). In Oracle you have to guarantee that by adding the keyword DETERMINISTIC to your PL/SQL function. Don't know if we really need that. Oracle isnt able to check if this is true anyway. It's just a keyword.
","Feb 14 2012 09:49:36 AM UTC;serbrech;Ok, thanks for details. That would for sure be useful. though overkill for my use case that only needs to return null last when sorting.
","Oct 25 2012 02:49:19 PM UTC;ihristov;This will be really a great feature. I'm especially interested in transforming a string field representing a number and then sorting by the number. ","Jan 12 2013 12:16:23 AM UTC;flashy;Something like Views in Couchbase. I need that so badly.","Feb 05 2015 01:50:03 AM UTC;liqiang;We would like to sort by computed values based on some time related fields.  e.g.  a document will be listed at the top if today is in its date range. it will not be practical to store  precomputed values.","May 06 2016 01:16:40 PM UTC;dpamio;We need it for the following use case:

{code}
var myPerceptualHash = '0239582305980';
db.coll1.find().sort({ 
    $by : function( a, b ) {
        var hummingDistance = require('humming-distance');
        return hummingDistance(myPerceptualHash, a.phash) < hummingDistance(myPerceptualHash, b.phash;
    }
}).limit(1)
{code}
","Jul 06 2016 12:15:41 AM UTC;fresheneesz;Being able to create custom indexes would be incredibly helpful. The most general way I can see this being done is something like this:

{code}
  // create the index
  db.MyCollection.createNamedIndex({name: ""mod5"", $expr:function(doc) {
    return doc.value%5
  }))

  // use the index
  db.MyCollection.find({x:5, $or[{value:100}, {$namedIndex: {name:'mod5', match: {$lt:1}}}]}).sort({$namedIndex: {name:'mod5', direction: -1}})
{code}

The named index would map the result of the given expression to the _ids with that result. You could then use that index for searching or sorting. This would be incredibly and open a huge number of potential optimizations without being required to store that data in each individual document.","Jul 06 2016 03:23:33 AM UTC;liqiang;I know this is irrelevant. I tried PostgreSQL. It has got great jsonb support since 9.4. what's more, you can have the best of both worlds.
https://www.postgresql.org/docs/9.4/static/datatype-json.html",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Order $graphLookup results by ascending depth from the source node,SERVER-26153,316959,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-query-execution,zamaraevk@gmail.com,zamaraevk@gmail.com,Sep 17 2016 06:25:12 PM UTC,Nov 14 2020 07:19:33 PM UTC,Feb 17 2021 11:15:19 AM UTC,,,,,,Backlog,Aggregation Framework,,,,1,graph,,,,,"Results array of the $graphLookup should be in order from the first node to the last(from closest nodes) . Currently, it's in reversed order.

Also, Output example in implementation ticket SERVER-23725 is incorrect order.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Sep 17 2016 06:25:12 PM UTC;zamaraevk@gmail.com;graph.js;https://jira.mongodb.org/secure/attachment/138881/graph.js",,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2016-09-18 17:43:35.0,139276800,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,craig.homa(craig.homa),Sun Sep 18 17:43:35 UTC 2016,,,,,,,,,,,,,,backlog-query-execution(JIRAUSER1257109),charlie.swanson(charlie.swanson),zamaraevk@gmail.com(zamaraevk@gmail.com),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i01kzr:",,,,,,,"0|i00wp3:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i0wop3:","Sep 18 2016 05:43:35 PM UTC;charlie.swanson;Hi [~zamaraevk@gmail.com],

Thanks for the request. I've marked this to be looked at by the query team for consideration and/or scheduling.

Please note in the meantime that there are no guarantees on the order of results in the output array from {{$graphLookup}}. The visited documents are put into a set, so will be output in no particular order. If you need an order, consider specifying the 'depthField' argument, and sorting by that.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"allow query option to return found documents enclosed in a ""meta"" document containing array offset information",SERVER-3362,19027,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-query-execution,tony_k,tony_k,Jul 03 2011 12:58:44 AM UTC,Nov 14 2020 07:19:09 PM UTC,Feb 17 2021 11:15:19 AM UTC,,,,,,Backlog,Querying,,,,1,,,,,,"if i have a collection of documents like:

{ name: 'fred', children: [{ name: 'bill', age: 10 }, { name: 'bob', age: 20 }, { name: 'ed', age: 30 }] }

and i want to operate on all children whose age is greater than 10, i don't believe there is a direct way to accomplish this.

i'm coming at this from the context of this jira entry: https://jira.mongodb.org/browse/SERVER-3347

i believe in the multi-geo case the document is returned once for each hit, which implies that multiple elements of an array met the search criteria.

in the multi-non-geo case the document is returned only once, i think it would be best to remain consistent, and in SERVER-3347 i suggest returning the document only once (after all returning the same document multiple times doesn't add much value),
but i allude to a ""wrapper"" document containing ""meta"" information on which elements of the array met the uery criteria.

i think the same pattern may be applicable to the multi-non-geo case, in a way to address the case in between the $ position operator and the multi (apply to all) mechanism.

so if there was a way to return something like:

{ 
  hits: [ 
    {field: ""children.age"", index: 1 }, 
    {field: ""children.age"", index: 2 } 
  ], 
  document: { // the actual document } 
}

i think it would give the caller enough information to operate on those elements of the array that were of interest...? 
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,303868800,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,craig.homa(craig.homa),2011-07-03 00:58:44.0,,,,,,,,No,,,,,,backlog-query-execution(JIRAUSER1257109),tony_k(tony_k),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i06lsv:",,,,,,,"0|i00tz3:",5172,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i08yhb:",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
File append through GridFS API,SERVER-7569,55427,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-query-execution,alvin,alvin,Nov 06 2012 09:01:29 PM UTC,Nov 14 2020 07:18:54 PM UTC,Feb 17 2021 11:15:19 AM UTC,,,,,,features we're not sure of,GridFS,,,,1,transactions,,,,,"Problem:
Append to the end of a file in GridFS. 

At present, you need to read the file, append to the object client side and then re-write the object.",Customer request,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2012-11-08 05:58:29.0,261187200,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,craig.homa(craig.homa),Thu Nov 08 05:58:29 UTC 2012,,,,,,,,No,,,,,,alvin(alvin),backlog-query-execution(JIRAUSER1257109),eliot(eliot),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i057wf:",,,,,,,"0|i01047:",6670,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i1i5pz:","Nov 08 2012 05:58:29 AM UTC;eliot;This becomes a locking problem.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
In place updating with partial chunk data for GridFS,SERVER-7524,54960,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-query-execution,zlwu,zlwu,Oct 31 2012 11:57:55 PM UTC,Nov 14 2020 07:18:23 PM UTC,Feb 17 2021 11:15:19 AM UTC,,,,,,features we're not sure of,GridFS,,,,0,update,,,,,"The GridFS is a great feature to the MongoDB. 

I'm thinking what the performance affected by random reading /writing to a dynamic GridFS file. The chunk data is huge and it looks like only the whole chunk can be updated to the GridFS file which at some time would require lot of data streaming for random writing. Here is the idea to add support paging within the chunk data as for that chunk data is mainly for storage while the paging is for client caching and updating, so that we can keep large size for the chunk data for storage and paging can split the chunk data into small subsets for client caching/updating.  I think this will require a lot of work to be able to split the chunk in client and server needs to allow in place updating partial chunk data. 

I'm not sure if similar feature is available or will be added in future? 

Thanks,


 ",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2012-11-04 15:16:47.0,261446400,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,craig.homa(craig.homa),Sun Nov 04 15:16:47 UTC 2012,,,,,,,,No,,,,,,backlog-query-execution(JIRAUSER1257109),eliot(eliot),zlwu(zlwu),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i058in:",,,,,,,"0|i0103z:",6667,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i1iw8v:","Nov 04 2012 03:16:47 PM UTC;eliot;The problem with this is that unless there is locking, there isn't anyway to prevent someone else from reading a corrupt file.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
text search on GridFS data,SERVER-10614,87211,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-query-execution,kapravel,kapravel,Aug 23 2013 07:28:53 PM UTC,Nov 14 2020 07:18:14 PM UTC,Feb 17 2021 11:15:19 AM UTC,,,,,,Backlog,GridFS,Text Search,,,4,,,,,,"text search is applied on string fields, but GridFS stores everything on chunks as BSON BinData. It would make sense to support also BinData for full text search, at least whenever the content type is marked as text.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,236217600,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,craig.homa(craig.homa),2013-08-23 19:28:53.0,,,,,,,,No,,,,,,kapravel(kapravel),backlog-query-execution(JIRAUSER1257109),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i047p3:",,,,,,,"0|i00uen:",6431,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i17hmn:",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Expose ability to directly execute a query plan to users,SERVER-12527,108220,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-query-execution,benjamin.becker,benjamin.becker,Jan 29 2014 06:27:39 PM UTC,Nov 14 2020 07:18:04 PM UTC,Feb 17 2021 11:15:19 AM UTC,,,,,,features we're not sure of,Querying,,,,0,perfomance,query,test,,,Testing performance of query execution can be difficult without the ability to explicitly specify what to execute.  Submitting query execution plans directly would help isolate components for testing correctness and performance.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,5002K00000d9moOQAQ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2014-01-30 05:44:33.0,222480000,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,craig.homa(craig.homa),2014-01-29 18:27:39.0,,,,,,,,No,,,,,,backlog-query-execution(JIRAUSER1257109),benjamin.becker(benjamin.becker),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i03rwv:",,,,,,,"0|i0105b:",4659,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i1743j:",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
mongodb Text Search with wild card,SERVER-10413,84488,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-query-execution,niravpatel44,niravpatel44,Aug 02 2013 04:28:23 PM UTC,Nov 14 2020 07:18:01 PM UTC,Feb 17 2021 11:15:19 AM UTC,,2.4.5,,,,Backlog,Text Search,,,,20,,,,,,"Is test search missing capability of utilizing wild cards(*, ?) in ""text' command.
I couldn't do following:
db.col_name.runCommand( ""text"", { search: ""\""the*hartford\"""" } )
to retrieve: the-hartford, the hartford, the xyz-abc hartford etc..",,,,,,,,,,,,SERVER-10227,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2013-08-12 18:06:43.0,236995200,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,craig.homa(craig.homa),Wed Aug 14 23:01:22 UTC 2013,,,,,,,,No,,,,,,backlog-query-execution(JIRAUSER1257109),rassi(rassi@10gen.com),niravpatel44(niravpatel44),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i049yn:",,,,,,,"0|i00udz:",6428,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i0dp5z:","Aug 12 2013 06:06:43 PM UTC;rassi;You can use dot (the ""wildcard"" character) in a regular expression predicate, e.g. {{db.collection.find(\{field:/the.*hartford/\})}}, but not in a text search string.  When querying a text index, your such string must include a list of terms and/or exact phrases.  You can specify a regular expression predicate as an additional filter to a text search, e.g {{db.collection.runCommand(""text"",\{search:""hartford"",filter:\{field:/the.*hartford/\}\})}}, but note that the filter will not use the text index.

I converted the type of this ticket to a feature request.","Aug 14 2013 11:01:22 PM UTC;niravpatel44;Thanks for making it ""feature request"". Problem with using regular expression is that it's very slow for us as we have so many search terms which starts with wildcard characters.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Allow default values to be set for new documents,SERVER-24430,291987,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-query-execution,styvane,styvane,Jun 07 2016 10:23:20 AM UTC,Nov 14 2020 07:17:11 PM UTC,Feb 17 2021 11:15:19 AM UTC,,,,,,Backlog,Querying,,,,5,validation,,,,,"This feature would allow users to set default values for fields within in a collection. If the field is not present in the document inserted, the field would be set to the default value.

A possible implementation could look like this:
{noformat}
> db.createCollection( ""coll"", 
     { ""validator"": { ""a"": { ""$type"": ""string"" }, ""b"": { ""$type"": ""string"" }, ""c"": { ""$type"": ""string"" }}}
     {""fieldValueDefaults"": { ""c"": ""defaultString""}}
 )
{ ""ok"" : 1 }
> db.coll.insert({ ""a"": ""A"", ""b"": ""B"" })
WriteResult({ ""nInserted"" : 1 })
> db.coll.findOne()
{
	""_id"" : ObjectId(""575721a2dc744047e1566f0f""),
	""a"" : ""A"",
	""b"" : ""B"",
	""c"" : ""defaultString""
}
{noformat}

h6. Original summary
Allow $or and $and in validation rule expression

h6. Original Description
From MongoDB 3.2, we can validate our documents during update or insertion, but we can't use the $or and the $and operators for complex validation rules.

{code}
db.createCollection( ""collection"", 
     { ""validator"": { 
         ""$and"": [         
              { ""a"": { ""$type"": ""string"" } },         
              { ""b"": { ""$type"": ""string"" } }, 
              { ""c"": { ""$or"": [ { ""$type"": ""string"" }, ""default"" ] }
          ]
     }}
 )
{code}

Failed with the following error:

{code}
{ ""ok"" : 0, ""errmsg"" : ""unknown operator: $or"", ""code"" : 2 }
{code}


source: https://stackoverflow.com/questions/37674538/how-can-i-ensure-that-only-certain-keys-are-present-in-a-document-using-mongodb",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,6.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2016-06-07 11:42:27.0,148176000,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,craig.homa(craig.homa),Wed Jun 08 01:54:19 UTC 2016,,,,,,,,,,,,,,backlog-query-execution(JIRAUSER1257109),pasette(dan@10gen.com),kelsey.schubert(thomas.schubert),styvane(styvane),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i01viv:",,,,,,,"0|i00whb:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i0x1k7:","Jun 07 2016 11:10:58 AM UTC;styvane;I got the `$or` syntax wrong here, as it should be:

{code}
{ ""$or"": [{ 'c': { ""$type"": ""string""}} , {'c': ""default""} ]}
{code}

Anyway that does solve the problem. We still have validation error if we insert something like this:
{code} db.collection.insert( { ""a"": ""any_value"",  ""b"": ""any_other_value""  } )
{code}

It yields:

{code}
WriteResult({
        ""nInserted"" : 0,
        ""writeError"" : {
                ""code"" : 121,
                ""errmsg"" : ""Document failed validation""
        }
})
{code}

This is because in our validation rule {'c': ""default""} means ""c"" equals ""default"". ","Jun 07 2016 11:42:27 AM UTC;pasette;What document are you trying to validate? Include your update or insert operator that is failing.

Also, it is not clear what you are trying to accomplish in your $or clause, because you are checking that ""c"" is a string or if the value of ""c"" is equal to the string ""default""","Jun 07 2016 12:41:36 PM UTC;styvane;What I want for example is assign a ""default"" to ""c"" if the ""c"" field is not present in the document being inserted.","Jun 07 2016 07:59:40 PM UTC;kelsey.schubert;Hi [~styvane],

I'd like to make sure I'm understanding this feature request. Please review my theoretical example below with made up syntax below. While this feature will most likely utilize a different syntax if it is implemented, I would first like to make sure we are the same page. 

{noformat}
> db.createCollection( ""coll"", 
     { ""validator"": { ""a"": { ""$type"": ""string"" }, ""b"": { ""$type"": ""string"" }, ""c"": { ""$type"": ""string"" }}}
     {""fieldValueDefaults"": { ""c"": ""defaultString""}}
 )
{ ""ok"" : 1 }
> db.coll.insert({ ""a"": ""A"", ""b"": ""B"" })
WriteResult({ ""nInserted"" : 1 })
> db.coll.findOne()
{
	""_id"" : ObjectId(""575721a2dc744047e1566f0f""),
	""a"" : ""A"",
	""b"" : ""B"",
	""c"" : ""defaultString""
}
> db.coll.insert({ ""a"": ""A"", ""b"": ""B"", ""c"": ""C"" })
WriteResult({ ""nInserted"" : 1 })
> db.coll.insert({ ""a"": ""A"", ""b"": ""B"", ""c"" : 1 })
WriteResult({
	""nInserted"" : 0,
	""writeError"" : {
		""code"" : 121,
		""errmsg"" : ""Document failed validation""
	}
})
{noformat}

Is this the behavior you would like to see implemented? If not, would you please clarify your request with additional examples?

Thank you,
Thomas","Jun 07 2016 11:30:17 PM UTC;styvane;Hi [~anonymous.user],

Yes, this exactly the behavior I would like to see implemented.

Thank you","Jun 08 2016 01:54:19 AM UTC;kelsey.schubert;Hi [~styvane],

Thanks for confirming! I've marked this ticket to be considered during the next round of planning. Please continue to watch for updates.

Kind regards,
Thomas",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Support $currentDate expression for insert,SERVER-13695,132811,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-query-execution,dancerjohn,dancerjohn,Apr 23 2014 02:34:07 PM UTC,Nov 14 2020 07:15:35 PM UTC,Feb 17 2021 11:15:19 AM UTC,,,,,,Backlog,Write Ops,,,,15,expression,insert,,,,The `$currentDate` update modifier is great and is something our project really needs. But we want to use it during an `insert`. As it stands we could do an update with upsert:true but we assume that the update will be slow/less-efficient than insert.,,,,,,,,,,,,FREE-71790,SERVER-2064,FREE-103997,SERVER-22963,,,,,,,,,,,,,,,,,19.0,,,,,,,,,,,,,,,,,Fully Compatible,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2014-04-23 18:41:58.0,166579200,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,craig.homa(craig.homa),Sat Nov 07 19:02:51 UTC 2015,,,,,,,,No,,,,,,asya(asya),backlog-query-execution(JIRAUSER1257109),pasette(dan@10gen.com),gfzabarino(gfzabarino),dancerjohn(dancerjohn),nilskp(nilskp),scotthernandez(scotthernandez),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i03lhj:",,,,,,,"0|i00vbz:",114113,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i0vndb:","Apr 23 2014 06:41:58 PM UTC;scotthernandez;There is currently no support for expressions during insert so adding something like this requires addressing that concept first.

(and yes, doing an update will be slightly slower since it has to first query and then if nothing is found, insert -- the query may be very fast but still is more work)","Apr 23 2014 06:47:33 PM UTC;dancerjohn;Scott, if the only thing in the query is `_id` would be close in performance to `insert`? After all, `insert` has to do a search on `_id` to ensure no duplicates.","Apr 23 2014 06:54:27 PM UTC;scotthernandez;Sort of, the _id check doesn't require an actual query, just an
attempt to record it in the index, like all other indexed fields. So
the query part isn't strictly needed for insert, just for update but I
suspect performance should be good enough going the update route even
with the extra query portion.


","Jan 20 2015 09:46:02 PM UTC;nilskp;We need $currentDate on insert also, hopefully with the timestamp returned, to avoid a subsequent query.","Aug 13 2015 09:55:53 PM UTC;gfzabarino;Yup, I hate having to do something like

var now = new Date();
// maybe this would be inside a bulk of inserts or just a plain insert call
db.collection.insert({ timestamp: now, ... });

In my particular case I need to insert a timestamp only when inserting, but not when updating, and I would love to be able to do that in just one db operation. Basically, make work $currentDate to apply only when inserting when { upsert: true }. A quick thought I have is to be able to insert a $currentDate entry inside a $setOnInsert one, but I know it doesn't look very good. Any thoughts?","Aug 13 2015 11:16:37 PM UTC;asya;Not sure what you mean by ""doesn't look very good"" - that's exactly the purpose of $setOnInsert to set fields during upsert only if it was an insert and not an update.  ","Aug 13 2015 11:24:13 PM UTC;gfzabarino;Well, the way I see it is that $setOnInsert is a specialized $set operation that is executed during inserts only. Setting a $currentDate entry on a $setOnInsert object is analog to setting a $currentDate entry on a $set object, which as far as I know does not work. That's what I mean when I say that it doesn't look good. It makes sense, but it doesn't feed good to me.","Aug 13 2015 11:26:51 PM UTC;gfzabarino;Yup, it doesn't work:
{code}
> db.a.insert({name:'a'})

WriteResult({ ""nInserted"" : 1 })

> db.a.update({name:'a'}, {$set:{$currentDate:{asd:true}}})

WriteResult({
	""nMatched"" : 0,
	""nUpserted"" : 0,
	""nModified"" : 0,
	""writeError"" : {
		""code"" : 52,
		""errmsg"" : ""The dollar ($) prefixed field '$currentDate' in '$currentDate' is not valid for storage.""
	}
})
{code}","Aug 14 2015 12:02:02 AM UTC;gfzabarino;$currentDateOnInsert comes to mind.","Aug 14 2015 12:11:17 AM UTC;asya;$currentDate does not work on *insert* operations.  It works on *updates* whether they are upserts or not. 

So if you want to use it on insert you can do it by doing an update with upsert option and $currentDate in $setOnInsert clause.  
","Aug 14 2015 12:15:38 AM UTC;gfzabarino;I know it doesn't. I was just stating my particular case in which I need to do an update with an upsert operation, do some modifications using $set to all documents (inserted and matching) but I only need to set a timestamp on inserted documents (which is why I was mentioning the $currentDateOnInsert idea). I understand it is not the original JIRA ticket's intention, but still, I wanted to state my case and it seemed appropriate at the time to do so.

NOTE: I just read again your comment, and you are saying to me that $currentDate works when updating with upsert. It does, yes, but it will also modify my existing documents which shouldn't be updated on my particular case. $setOnInsert is a functionality that doesn't have a counterpart for $currentDate. $setOnInsert will only apply to inserted documents. $currentDate will apply to both matching and inserted documents.","Aug 14 2015 12:50:38 AM UTC;nilskp;Upsert is not good enough. It won't fail on duplicate keys, which is required for my use case.","Aug 14 2015 12:58:45 AM UTC;gfzabarino;I might be wrong, but I think it does fail on unique indexes constraints. Did you try this and it inserts a duplicated document with the same value for the key that is uniquely indexed?","Aug 14 2015 03:23:50 AM UTC;asya;*edit* This comment mistakenly says that these two update operators can be combined - that is incorrect.  Leaving the comment in to avoid confusion around follow-ups.

--What you are describing already works.  It works exactly the way you need it to work. $setOnInsert support $currentDate.-- 

And upsert will absolutely fail on duplicate constraint Nils.  ","Aug 14 2015 03:42:57 AM UTC;gfzabarino;Hmm I just tried
{code}
db.a.update({asd:123}, { $setOnInsert: { $currentDate: { timestamp: true } } }, { upsert: true} )
{code}
and it throws the following error:
{code}
WriteResult({
	""nMatched"" : 0,
	""nUpserted"" : 0,
	""nModified"" : 0,
	""writeError"" : {
		""code"" : 52,
		""errmsg"" : ""The dollar ($) prefixed field '$currentDate' in '$currentDate' is not valid for storage.""
	}
})
{code}
I'm not using the latest version though. Was this introduced recently? I'm using:
db version v2.6.0
git version: 1c1c76aeca21c5983dc178920f5052c298db616c

Thanks for the support BTW.","Aug 14 2015 04:12:09 AM UTC;nilskp;Upsert will either update or insert. Not sure how a duplicate key exception makes sense in that context.","Aug 14 2015 04:15:58 AM UTC;gfzabarino;It does, you could search for three keys and have an unique compound key for two of those three keys. If the third key you are searching is different from a document with the two first keys equal, mongodb will try to insert another document, causing a duplicate error.","Aug 14 2015 04:25:54 AM UTC;nilskp;Fair enough, for a complex case like that it might work, but not for the simple case of ""_id"".","Nov 07 2015 07:02:51 PM UTC;pasette;This may be a duplicate of SERVER-2064",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Add support for Greek language in text search,SERVER-10589,86838,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-query-execution,jim.oleary,jim.oleary,Aug 21 2013 03:40:36 PM UTC,Nov 14 2020 07:14:40 PM UTC,Feb 17 2021 11:15:19 AM UTC,,,,,,Backlog,Text Search,,,,2,,,,,,"According to http://docs.mongodb.org/manual/reference/command/text/#text-search-languages, we currently do not explicitly support text searching or indexing for the greek language. ",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2014-11-02 18:39:24.0,236390400,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,craig.homa(craig.homa),2013-08-21 15:40:36.0,,,,,,,,No,,,,,,backlog-query-execution(JIRAUSER1257109),jim.oleary(jim.oleary@10gen.com),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i03173:",,,,,,,"0|i00uef:",6430,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i0r92v:",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
triggers ,SERVER-124,10249,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-query-execution,eliot,eliot,Jul 02 2009 02:50:19 PM UTC,Nov 14 2020 07:14:26 PM UTC,Feb 17 2021 11:15:19 AM UTC,,,,,,Backlog,Usability,,,,253,,,,,,insert/update/remove/missing object,,,,,,,,,,,,SERVER-6895,SERVER-8777,CS-9652,CS-9669,SERVER-13755,,,,,,,,,,,,,,,,59.0,,,,,,,,,,,,,,,,,,,,,500A000000UaVy3IAF,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2009-07-14 13:51:52.0,157248000,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,craig.homa(craig.homa),Tue Feb 23 19:25:17 UTC 2016,,,,,,,,,,,,,,walec51(walec51),aditya(aditya),plasma(plasma),backlog-query-execution(JIRAUSER1257109),memelet(memelet),chengas123(chengas123),ckaran(ckaran),colinmollenhour(colinmollenhour),danimal(danimal),amcgregor(amcgregor),drapeko(drapeko),eliot(eliot),klondike(klondike),flavius(flavius),harald(harald),jeffbski(jeffbski),tpneumat(tpneumat),joelthedrummer(joelthedrummer),bugslayer(bugslayer),jlhm(jlhm),a_musing_moose(a_musing_moose),hbf(hbf),keithbranton(keithbranton),kostya(kostya),c0dem4gnetic(c0dem4gnetic),mwaschkowski(mwaschkowski),matt.insler(matt.insler),mikerobi(mikerobi),mgiardinelli(mgiardinelli),nickp(nickp),algorian(algorian),mobius(mobius),raviv(raviv),rolyv19(rolyv19),sandstrom(sandstrom),smalloy(smalloy),cense(cense),tedx(tedx),tshawkins(tshawkins),turneliusz(turneliusz),va1en0k(va1en0k),vicary(vicary),yosefd(yosefd),yfinkelstein(yfinkelstein),xcoderzach(xcoderzach),,,,,,,,,,,,,,,"0|i022v3:",,,,,,,"0|i00y13:",6041,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i00i9j:","Jul 14 2009 01:51:52 PM UTC;sandstrom;Sounds like a relationship database to me. I think that query/insert (eg. the storage part) is the important thing. Triggers are often happier in the application layer.","Sep 25 2009 07:49:09 AM UTC;c0dem4gnetic;+1 on this feature. I for one would find it very beneficial if events from mongo could be aggregated out on a message bus-like thing but might be further down the line :) .. . braindump follows...

The simplest form of these triggers could be something like PostgreSQLs notifications: db.myCollection.addNotification(""insert"", prototype, ""notificationName"") where prototype is a query-like object which when matched against the operation object(s) leads to mongo notifying listeners. These could register either globally or per collection: db.myCollection.addListener(""notificationName"", function(notificationData) { ... }). Other semantics could allow these events to be triggered pre and post the operation being processed, additionally allowing listeners to modify the objects before they are stored.

Notifications could also be prioritzed to have some control over the order in which listeners are called. This could be an extra parameter to the addNotification function or included as metadata to the prototype object?

Triggers in the application layer is imho ""okay"" but consider the situation where you do not have access to it. Here, without triggers, you need to poll the database for changes (performance concerns) and also add infrastructure to determine when and how the database has changed.","Dec 11 2009 04:58:29 PM UTC;va1en0k;It will be really helpful.

Because of limited queries, we sometimes need tables to have some denormalized data, just to help searching. For example, we can store array size in separate field to allow queiring with size > or < constant using indexes. Without triggers having this fields can be a headache.","Feb 19 2010 10:39:23 AM UTC;mwaschkowski;Audit logs are really easy with this kind of feature, but there are a number of other use cases mentioned in this Jira that need a trigger mechanism","Feb 23 2010 08:50:14 AM UTC;a_musing_moose;+1 on Magnus Persson suggestion,

I really like the idea of notifications based on selection criteria. The using stored JavaScript functions to to listen for notifications and act accordingly. Allows for some very flexible arrangements.","Mar 10 2010 12:46:17 PM UTC;memelet;My desire for this feature is to publish changes to user interface clients. For simple entity updates its easy enough to handle in the application. But when criteria based updates are used there's not much the application can do to notify clients of the changes.","Mar 10 2010 01:01:41 PM UTC;mwaschkowski;""My desire for this feature is to publish changes to user interface clients. For simple entity updates its easy enough to handle in the application. But when criteria based updates are used there's not much the application can do to notify clients of the changes.""

Good point. This feature would be ideal for pushing changes through to clients rather than some ad hoc polling mechanism.

Another use case: when doing data imports. The import routine really shouldn't need to know about the business rules of a system, and yet if triggers are attached to the database itself, business operations (say, an email) can still be carried out without the import worrying about a thing.

I do have need of triggers as well, voting for this.","Mar 14 2010 10:23:48 AM UTC;kostya;I like this feature, but I would like to have an ability to use c++ for that (to use 3-d party dll's) and be sure that that code will be executed on the same machine as corresponding mongod process. I don't like the idea with client modification, that's not enough. I like postgres trigger feature with calling stored procedures writen in c++, but external message bus looks more flexible (maybe I'm wrong, and there are no difference in flexibility, but I'm sure that external message bus will be slower).","Mar 14 2010 10:44:57 AM UTC;kostya;But as there are no c++ stored procedures, and I'm  sure that not easy to implement, external message bus seems the only way... ","May 11 2010 09:42:25 AM UTC;tedx;I'd like to be able to update a user interface when another app updates a db, +1.","May 29 2010 07:08:43 PM UTC;matt.insler;In my humble opinion, I think you guys are might be using the wrong database for your problem set, or maybe you're looking at your problem set in too much of an RDBMS light.  Audit tables can be created by things other than triggers.  In mongo, I would just tail the replication log and persist that to a non-capped collection.  Or, you can use your slow triggers in your MySQL database to write audits into a Mongo collection, which will then be many many many times faster to query.  A big thing to realize is that Mongo is eventually consistent.  If you're using triggers to create audit tables for financial transaction information or audits that really really need to be there, then password your database and write the audits into your application layer.  I disagree with any trigger mechanism that will slow down my database.  If there must be a notification layer, then I think it should be a capped collection that any client can use a tailable cursor on.  This would be the fastest from a database perspective and just as flexible as any suggestion here.  I moved away from Oracle and MySQL because I didn't like the monolithic approach anymore, where I was pinging web services and sending emails and using wget from within PL/SQL.  This just doesn't scale.  You can easily use the replication log or something akin to amazon sqs to distribute the ""trigger"" operations horizontally across your entire infrastructure.  Just think of how much nicer that would be for scalability!","May 29 2010 09:36:34 PM UTC;mwaschkowski;-1 to Matt Insler's comment","May 30 2010 07:25:17 AM UTC;kostya;I've understood your ""humble opinion"" )) In large projects there are massage buses or event oriented architecture, what if integrate notification in a way that it could be disabled, and won't affect performance, of could be enabled and will waste some resources - but that  will be lover amount of them, in comparison to creating fully functional massage bus in every project, which needs it.","Oct 14 2010 07:27:38 PM UTC;bugslayer;+1

Shouldn't a basic version of this feature be trivial to implement?

@Matt, This is *more* important because Mongo isn't an RDBMS. Document databases like Mongo use data duplication to solve problems that relational databases solve with joins. Triggers would allow this to be handled trivially, with greater robustness. I can't imagine this would slow down your database. It should only require one extra op when no triggers are defined (you won't notice a single op).

@sandstorm, Triggers in the application layer look like a good idea...until you start needing to do batch updates and/or complex atomic operations. I can't imagine an application of any reasonable size that doesn't eventually need to update a number of records at once. If triggers are handled at the application level, the application has to fully read in every record it modifies, process any triggers, and write it out. Aside from being more work to code, this causes a ton of needless IO.


My vote is for the following syntax (similar to Magnus's, but simpler in the common cases):
db.MyCollection.AddTrigger(
 { trigger : <triggerfunction>
   [, type : <'insert' | 'update' | 'delete' | 'all' (default) >]
   [, query : <query filter object>]
   [, async : <true if the trigger can be completed asynchronously, false (default) if the trigger must be completed as part of the update/insert/delete>]
 }
);

An optional ""fields"" parameter (that works like the fields in find()) could be added iff it would reduce resource use (Memory, CPU, IO).","Oct 15 2010 12:13:05 AM UTC;memelet;John Crenshaw is right the mark. This would be a wonderful api/syntax.","Dec 08 2010 07:03:49 PM UTC;tpneumat;I agree.  This would help. 

To Matts & other's point, there were times when I thought I was using the wrong DB when I am missing SQL features such.  But, I like the Mongo approach which seems to be, if it is possible, why not do it as long as it doesn't compromise anything.  

Here is what I would like to use it for:

http://jira.mongodb.org/browse/SERVER-1650
http://groups.google.com/group/mongodb-user/browse_thread/thread/9276087d9cfc4741/e03ad48cbbaf5b5d?lnk=gst&q=polling#e03ad48cbbaf5b5d","Dec 19 2010 06:35:52 AM UTC;tshawkins;im not sure triggers are the correct solution to this issue, i personally believe that a slave framework that can act as an oplog reader, but have pluggable actions attached to it would be a better way of handling this.  that would allow all sorts of integrations outlined above to be performed without having to add any specific support to the core system. 

1)  Mirroring systems, like logs, fulltext indexes, even mirroring changes to other databases.
2) Converting events in mongodb to messagebus events etc. 

Something simple like a daemon that can spawn other processes passing Json/bson changes, simular to fcgi would allow folks to attach anything they like to the oplog. ","Dec 19 2010 06:00:54 PM UTC;memelet;For certain applications I agree with Tim. I created a simple oplog observer that sends out CRUD events. Quit trivial actually. ","Jan 11 2011 10:15:29 PM UTC;jlhm;+1 

This is a much wanted feature and I hope it will be in the next major release.","Mar 08 2011 04:35:00 AM UTC;xcoderzach;+1

I would love to see this implemented.","Mar 08 2011 04:42:55 AM UTC;memelet;One thing to be aware of when using the oplog to send events: For deletes you will only have the OID available.","Mar 16 2011 08:10:50 PM UTC;raviv;+1","Apr 11 2011 10:28:39 AM UTC;plasma;I just realised that this ticket is pretty similar to my suggestion of 'transactional write batching' at SERVER-2804

Personally I'd be leaning to write batching instead (I'd rather logic stays in the application rather than a database - triggers are the devil :) ) but have voted for these anyway as they would definitely be useful if write batching can't be done.","Apr 11 2011 10:42:36 AM UTC;bugslayer;Transactions (and/or loose ""write batches"") only have a small amount of overlap with this. They don't really solve the same set of problems that triggers solve. Don't get me wrong, any sort of transactional support in Mongo would be welcome, but I don't really see this as the same issue.

The main reason I want triggers is to move special indexing (including multi-sharding, field computation, and normalization) logic to the database layer, where it belongs. Right now any type of complex indexing process requires some heavy code in the application. Extreme levels of paranoia are involved in making sure that the code to maintain the index never gets circumvented. Whether or not the index updates are guaranteed eventually consistent is the smallest part of the problem.","Apr 12 2011 02:43:37 PM UTC;danimal;+1 for Magnus's syntax","Jun 08 2011 12:54:14 AM UTC;colinmollenhour;Another reason the ""why don't you tail the oplog"" solution is not a very good one is when you are sharding now your application has to be fully sharding-aware and you'll have to have separate threads watching the oplog of each shard or have copies of your application installed on each shard to watch the local oplog. Having a trigger mechanism would make it easy again by having one high-level interface even if it just amounted to filtering ops and aggregating them on one tailable collection.","Jun 08 2011 01:58:06 PM UTC;harald;We too went away from tailing the oplog, because we found it to be to error-prone relying upon a mechanism which wasn't intended for such things. A trigger would indeed be highly appreciated.","Jun 14 2011 11:28:03 AM UTC;aditya;+1 for this feature.

This helps me easy integration with our other systems which can be indexing, analytic on data. 
http://guide.couchdb.org/draft/notifications.html

For now, since feature is not available, any hacks?  ","Jun 22 2011 01:51:36 AM UTC;smalloy;+1 for a feature 

Implementation similar to the change notifications in couch","Jun 26 2011 11:50:08 AM UTC;hbf;+1 for this feature (reason: ability to index content in Solr or Elastic Search, or other such technology)","Jul 05 2011 08:58:42 AM UTC;walec51;+1 this would give some basic messaging capabilities like in Redis","Jul 07 2011 12:38:26 PM UTC;mobius;+1 However I don't think that there should be a traditional RDBMS trigger in the form John Crenshaw mentions above. I think what it would be best to have a mechanism to subscribe to an oplog like system, thus receiving all events occurring on a collection. Filters could be created via JavaScript to actually get only the data you need, in case you want to build a listening server (imaging a node.js server emiting events on mongodb collection changes) or if you want to actually to have a trigger like functionality, in the concept of MapReduce to have a MapAction functionality. (Map the changes, and perform actions triggered by them). 

One could finally apply the filter/ MapAction 'before' or 'after' the event.
","Jul 07 2011 06:38:42 PM UTC;bugslayer;I'm not sure what would actually be gained by only implementing an oplog. Isn't this basically just the same as triggers, but without support for conditions?

As far as allowing a map action, the standard query syntax is more clean and familiar. If you need the level of power available from a map-like filter, a $where clause in the query should give you that. If you want an oplog, just exclude the query parameter (it is optional in my proposed syntax).

Also, using the typical query syntax keeps the door open to interesting optimizations. For example, if the shard key is included in the query the trigger could be limited to only those mongod instances that may contain the given key, or the query could be optimized to do the least expensive comparisons (boolean, integer) before more expensive ones (strings, $where, regex) when attempting to determine whether a trigger applies to a record. A oplog monitor closes this door forever and guarantees that triggers always have the maximum possible overhead (this doesn't seem ideal).

Finally something more trigger-like and less oplog-like eases the transition from traditional RDBMSs, which is largely in keeping with what Mongo has done so far.","Jul 07 2011 07:10:18 PM UTC;mobius;You are right on the most part, especially regarding a trigger on a sharded environment. But the concept of having a capped collection containing the changes in your entire dataset opens the possibility to a publish/subscribe interface that could be extended to a more asynchronous environment. Nowadays the amount of data is getting rather huge and we usually only want to get as less information as possible down to the application and eventually to the end user.

A more strict RDBMS trigger from what I understand would restrict the event being raised inside mongo while it could be propagated further down an application. 

Furthermore what could also work on a sharded environment would be to have a separate mongod instance, like the configuration servers, to optionally propagate changes from triggers. So all replicas would propagate the changes to those. (So that you wouldn't have to have one separate oplog per replica set)

Finally, in my perspective we should not see mongodb as a RDBMS replacement, and we should choose Mongodb or any other document database for the unique features it has and not for the similarities to a system that we know already :)
","Jul 07 2011 08:40:04 PM UTC;keithbranton;@Paris, Let's not lose sight of the fact that this ticket is for triggers. Triggers have very specific meaning in the database world: http://en.wikipedia.org/wiki/Database_trigger. I suspect most (if not all) of the votes on this ticket are for database triggers.

If a capped collection would be sufficient for a message queue, then presumably a trigger could add records to such a capped collection and so accomplish this goal too.

One of the things I would want to do with triggers is to make the database responsible for computing and storing values that break 1nf - such as n/sum/max/min/mean of the values in an array and store these so they can be queried on. As application complexity increases, and more pieces of code change collections, (not always being written in the same language) it can be increasingly difficult to enforce the integrity of trivial-to-compute data fields like this throughout the application. Materializing these computable (duplicate) values in the database is often simply an optimization for most DBMS (though it is necessary to get certain queries to work in Mongo). I don't want to set up a message queue, and set up yet another mongo instance because I use sharding, and run a background task polling it so I can keep the number of items in a given array up to date whenever a document changes  -  that's way too much work.

Since a reasonably complex object graph can easily be represented by a single document in mongo the ""we should not see mongodb as a RDBMS replacement"" argument is rather moot. I for one use mongo for operational data, cache, queues, logging and image storage. It results in a super-simple stack that is easy to replicate on developer machines and easy to manage in production. It works very well in applications that do not require transactions (though I occasionally wish it had them) and where joins are seldom required (I tended to design for minimal joins on Oracle too - in heavy use it scales much better without them)

My only real concern is with using javascript functions - javascript generally performs very poorly.
","Jul 07 2011 09:44:57 PM UTC;mobius;@Keith Fair enough! I rest my case..I saw it as an opportunity to suggest an altermative and I dont want to impose. Triggers are definately important and my +1 definately stands! ","Jul 07 2011 09:53:16 PM UTC;bugslayer;@Paris, presumably you should still be able to do that capped collection + MQ thing with triggers. Just set up a simple trigger to push data to the queue collection. Triggers and subscribing to events are similar enough at the lowest levels that either one would allow a user mode implementation of the other.","Jul 07 2011 10:27:45 PM UTC;bugslayer;After Paris's comments I just realized that nothing above defines what the parameters to the trigger function would be. I think the best option would be to pass an event object, with a structure similar to the following:

{
    collection: ...name of collection, or alternately the collection object...,
    type: ""insert"" | ""update"" | ""delete"",
    recordId: ObjectId(...),
    oldRecord: {...document...},
    newRecord: {...document...},
    update: {...$set/$inc/etc. operations...},
    ...Any other properties that make sense (query or whatever)...,
    ...Any methods that make sense (preventDefault() or whatever)...
}

Using getters to expose the oldRecord, newRecord, and/or update fields would allow the implementation to avoid unnecessary overhead when the trigger doesn't actually use them.

""this"" should probably be set to the collection object.

I think this is a rough minimum. Without old/new (and/or update) many triggers will be crippled. Triggers to maintain a tombstone collection will probably be common, and will only need the collection name and id (so optimizations to avoid needless overhead on the larger values make sense.) Type is useful for keeping code DRY.

Thoughts?","Jul 08 2011 09:29:19 PM UTC;drapeko;it would be very great helper for rollup collection implementations (e.g. stats in real time).. 

now it's really a trick as implementation has to be transactional","Oct 04 2011 02:43:13 PM UTC;cense;Hi All,


mongoDB looks like an awesome DB, i want to use more in the future!

and... Triggers would make life more easy for a lot of developers... (i think)


At this moment i'm designing a new application that could need (again) this kind of future.


for a lot of functions like logging, notifying agents, db checks, ... it would be very handy.


Hopefully there will be an integration soon!


In the moment of, are there some alternatives whit mongoDB ? i would like to integrate mongoDB in a project 

whit a development time of 1 year, and we start developing in about 1 month.. so.. i cant just wait till

ist supported, and urgently need to make some decisions... 


Rgds Steven","Oct 11 2011 05:10:24 PM UTC;mikerobi;There should be pre and post operation triggers.  To make the most out of triggers, they need to be able to abort insert and update operations.  This would make triggers a flexible solution for apps that require some kind of schema validation.","Oct 14 2011 02:16:52 PM UTC;ckaran;I agree with Michael Robinson.  This will also make different types of replication/synchronization easier (think optimistic replication or BASE).  Right now, the only solution is to create a fake server that communicates with the real server, and offers trigger-like capabilities.  NOT optimal!","Nov 29 2011 04:32:27 PM UTC;nickp;+1 for this feature, much easier than using Tailable Cursors","Dec 30 2011 10:35:36 PM UTC;rolyv19;It seems like this this is the biggest obstacle to integration with ElasticSearch. Even something like CouchDB's Changes API would be useful.","Feb 16 2012 02:30:56 PM UTC;jeffbski;+1 Adding this feature to MongoDB would be game over for most of the other noSQL engines. This is the feature that pushes people to other engines, once it is here too, then no reason to go elsewhere IMHO.","Feb 20 2012 12:39:23 PM UTC;yosefd;+1 Very important feature.","Mar 04 2012 03:00:26 PM UTC;mgiardinelli;+1 please add....would be very beneficial feature and as noted many times before competing products already offer this. ","Mar 07 2012 05:14:59 PM UTC;klondike;To backup Magnus' comment from 2009, and Roly's more recent comment -- 

This would be perfect for supporting automatic denormalization with much less code complexity and maintenance. It would also make syncing data with other databases (like ElasticSearch, which I also use) so much easier. Supporting this at the database level, rather than in an ODM or other client library, is by far the most flexible and efficient, and would make a new class of ODM features and plugins possible.","Apr 16 2012 03:55:58 AM UTC;chengas123;CouchDB has _changes, which allows it to have very good elasticsearch support.  I'd love to see a MongoDB Elasticsearch River, but some sort of post-commit hook would be needed first.","Apr 16 2012 04:20:22 AM UTC;eliot;A lot of people use the oplog for getting notified of changes.","Apr 16 2012 08:31:19 AM UTC;turneliusz;+1","May 02 2012 07:05:44 AM UTC;yfinkelstein;This jira
https://jira.mongodb.org/browse/SERVER-5042
would provide everything ordinary triggers can provide and more since mongo will also do trigger filtering.

Eliot, polling oplog is not a portable solution (oplog format, table names, etc can change). Instead, - enhance your client APIs to receive change notifications in a standard, type-safe manner and custom filtering on the server (if required)
 ","May 08 2012 05:50:32 PM UTC;algorian;+1. Think that you have to check the XSD before inserting an JSON'ed XML document! I know you will say that I can do it in my application. But remember that may be I have only one Application Server but several MongoDB servers.
And here is another reason:
An application is constantly inserting data into MongoDB, and a seperate application is watching it live. How can second application know which rows inserted? Please don't tell me to use timestamp or something like that and make periodic queries.
There is a whole bunch of examples out there which actually ""need"" triggers.","May 08 2012 07:25:19 PM UTC;mwaschkowski;Our company is soon needing this kind of functionality.

Issues seen from previous comments, but not yet addressed:
-delete's only show the oid (not anything else about the element that was deleted), so how can you create triggers around deletes? You would really need to know more about deletes to trigger from, and doing logical deletes is a time wasting work around
-sharding, and having to worry about multiple oplogs
-optimizations not available (search for 'interesting optimizations' from John Crenshaw)
-oplog format isn't a portable solution (format may change in the future), so its really more of a hack than a real solution

Eliot, do you *really* want the all the developers out there needed trigger functionality parsing the oplog? If so, fine, I'll write my own version of code to do so. If not, can you me know what would be required to move this forward? My company wouldn't be able to afford funding this alone, but would have funds to put towards this.","Mar 06 2013 06:50:14 AM UTC;flavius;This feature would be extremely useful, particularily if there would be a trigger when starting the daemon.","Jul 30 2013 04:39:59 PM UTC;joelthedrummer;+1.  I would like this feature to be able to maintain consistency of duplicate data across collections.  Another usefulness would be able to execute some server-side JavaScript that would update a ""view"" as new data gets inserted/updated/deleted, similar to Couchbase views I believe.","Aug 16 2013 07:54:31 AM UTC;vicary;+1 Server scripts (Node.js, Java and else) would definitely take advantage from this, saving enormous resources from polling, while page scripts (PHP, Ruby ... etc) doesn't really care as they make queries every single HTTP request.","Jun 12 2014 06:26:26 AM UTC;vicary;It's been around for a few years, any thoughts from the developers?","Feb 23 2016 07:25:17 PM UTC;amcgregor;As a user, not developer, triggers are a point of concern.  Obviously not using them should incur no overhead, but they're very non-trivial to implement.

* Pre- and post- hook points.  (With pre- hooks potentially allowing the operation to be invalidated, i.e. pre-update indicating the update should not proceed.)
* For all hooks, the document must be passed.  It's not enough to say ""ID X is about to be deleted"", the trigger logic will need to be able to inspect the document.
* Many triggers may want to perform larger-scale operations, such as delivering e-mail in response to a record change. Clearly, mongod isn't the right place to be doing that, so you might inject a ""task"" record of some kind which an external process watches for… at which point you might as well be doing the ""trigger"" monitoring there anyway.
* The last point also leads to the potential for database-level amplification attacks.  (Requiring careful coding.)
* Using the new document validation mechanism as a method of filtering which operations execute a given trigger would then require iteration of candidates and repeated evaluation; not so efficient, with that overhead added to every call of every operation that is hooked.
* Like validation hooks would require some method to bypass, plus assorted tool changes to control trigger execution during import/restore.

There are existing ODM/DAO layers which provide signal/trigger/callback functionality, such as MongoEngine (Python) or, for the oplog approach, libraries such as mongo-oplog, Coccyx, or moplog (JavaScript examples).

Pre-aggregation via upsert operations is effectively the ""view"" process in MongoDB.  Pairing standard inserts with their pre-aggregate updates typically works well for that without the need to asynchonrously divorce the pre-aggregate update from the insert, no?  This very much sounds like a problem solved at the client driver (application) level and not server-side.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Add method for unwinding nested arrays,SERVER-6436,44103,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-query-execution,aaron,aaron,Jul 13 2012 03:02:26 AM UTC,Nov 14 2020 07:14:22 PM UTC,Feb 17 2021 11:15:19 AM UTC,,,,,,Backlog,Aggregation Framework,,,,2,expression,,,,,"Right now $unwind can only unwind an array that is not nested within another array.  For example 'a.b' can be unwound in this document:
{noformat}
{ a:{ b:[ 1, 2 ] } }

but not in this one:

{ a:[ { b:1 }, { b:2 } ] }

and not in this one:

{ a:[ { b:[ 1, 2 ] } ] }
{noformat}

Current behavior is to not unwind anything in these cases.",,,,,,,,,,,,SERVER-23754,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,5002K00000izzNxQAI,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2013-03-13 21:05:45.0,250300800,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,craig.homa(craig.homa),Wed Mar 13 21:05:45 UTC 2013,,,,,,,,No,,,,,,aaron(aaron),backlog-query-execution(JIRAUSER1257109),thaddeusmt(thaddeusmt),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i05l2n:",,,,,,,"0|i00yn3:",6541,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i0s4yf:","Mar 13 2013 09:05:45 PM UTC;thaddeusmt;I think some of these issues can be solved by using stacked $unwinds and $projects in the pipeline, like so:

db.foo.aggregate(
  { $unwind : ""$a.b"" },
  { $project : { ""b"" : ""$a.b""}},
  { $unwind : ""$b"" },
  { $match: { ""b"": 1 } }
);
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Querying along a polyline,SERVER-4339,25189,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-query-execution,enepper,enepper,Nov 21 2011 01:32:44 PM UTC,Nov 14 2020 07:13:55 PM UTC,Feb 17 2021 11:15:19 AM UTC,,,,,,Backlog,Geo,,,,4,,,,,,"I'll like to be able to query along a polyline. The idea is to give 
mongo an array of points and a max distance. Mongo should return every 
document within the max distance from the polyline. There should also 
be an option to tell if it should only be distinct document or not. 
polyline = [[10, 20], [10, 40], [30, 40], [30, 20]] 
db.places.find({ ""loc"": { $along: polygonA, $maxDistance: 5, 
$uniqueDocs: true } }) ",,,,,,,,,,,,SERVER-14948,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,291600000,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,craig.homa(craig.homa),2011-11-21 13:32:44.0,,,,,,,,No,,,,,,backlog-query-execution(JIRAUSER1257109),enepper(enepper),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i06a6v:",,,,,,,"0|i00u1j:",6006,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i1iurz:",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Create an efficient command for checking upon document existence: db.Collection.exists({ .. }),SERVER-6033,40685,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-query-execution,pmaedel,pmaedel,Jun 07 2012 03:45:12 PM UTC,Nov 14 2020 07:13:49 PM UTC,Feb 17 2021 11:15:19 AM UTC,,,,,,Backlog,Querying,,,,0,,,,,,"As detailed in the user group, querying for document existence via count() or find() is not as efficient as it could be done.

https://groups.google.com/group/mongodb-user/browse_thread/thread/7c18df7656d5765e",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,274406400,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,craig.homa(craig.homa),2012-06-07 15:45:12.0,,,,,,,,No,,,,,,backlog-query-execution(JIRAUSER1257109),pmaedel(pmaedel),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i05pwf:",,,,,,,"0|i00u6n:",6260,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i1i1k7:",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Introduce support for full-text for Polish language,SERVER-8332,63253,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-query-execution,turneliusz,turneliusz,Jan 25 2013 02:11:15 PM UTC,Nov 14 2020 07:13:13 PM UTC,Feb 17 2021 11:15:19 AM UTC,,,,,,Backlog,Text Search,,,,3,,,,,,As in summary. Currently MongoDB full-text dosen't support stemming nor Polish stopwords.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,254361600,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,craig.homa(craig.homa),2013-01-25 14:11:15.0,,,,,,,,No,,,,,,backlog-query-execution(JIRAUSER1257109),turneliusz(turneliusz),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i04yu7:",,,,,,,"0|i00uaf:",5012,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i006an:",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Add support for query results to return mapbox vector tiles,SERVER-37950,629836,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-query-execution,donnyv,donnyv,Nov 06 2018 06:40:03 PM UTC,Nov 14 2020 07:12:55 PM UTC,Feb 17 2021 11:15:19 AM UTC,,,,,,Backlog,Geo,Querying,,,4,,,,,,"Add the ability to return results in mapbox vector tile format. 

[https://www.mapbox.com/vector-tiles/specification/]

 

Recently PostGIS has added this feature.

[https://postgis.net/docs/ST_AsMVT.html]

 

This format is becoming the standard across the web gis world.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,4.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2018-11-06 21:21:29.0,63504000,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,craig.homa(craig.homa),Tue Feb 12 19:06:26 UTC 2019,,,,,,,,,,,,,,backlog-query-execution(JIRAUSER1257109),charlie.swanson(charlie.swanson),donnyv(donnyv),kelsey.schubert(thomas.schubert),tpisto(tpisto),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i2uyhj:",,,,,,,"0|i00yi7:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i2uwlb:","Nov 06 2018 09:21:29 PM UTC;kelsey.schubert;Hi [~donnyv],

Thanks for the feature request; I'm marking this ticket for consideration by the Query Team.

Kind regards,
 Kelsey","Nov 06 2018 09:45:47 PM UTC;donnyv;Awesome! Thank You!","Nov 07 2018 02:31:17 PM UTC;charlie.swanson;Adding 'querying' component. cc [~david.storch]","Feb 12 2019 07:06:26 PM UTC;tpisto;Absolutely wonderful suggestion. As said, this is very important industry standard now.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Text search Date awareness,SERVER-9779,76518,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-query-execution,redbeard0531,redbeard0531,May 24 2013 04:20:15 PM UTC,Nov 14 2020 07:12:22 PM UTC,Feb 17 2021 11:15:19 AM UTC,,,,,,Backlog,Text Search,,,,0,,,,,,"It would be great if Text Search could be aware of dates and boost the score of more recent entries. I could also see a use for a mode where it skips the text ranking and just returns the most recent matching results.

Ideally this would support both the proper Date type as well as extracting the time portion of an ObjectID.",,,,,,,,,,,,SERVER-9664,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,244080000,,,,,,,,,,,,,,,,,,,,,,,,,,,,false,craig.homa(craig.homa),2013-05-24 16:20:15.0,,,,,,,,No,,,,,,backlog-query-execution(JIRAUSER1257109),redbeard0531(redbeard0531),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i04h53:",,,,,,,"0|i00ucf:",6416,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i0ew8n:",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Better support for density-style geospatial searches,SERVER-13800,134217,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-query-execution,osmar.olivo,osmar.olivo,Apr 30 2014 06:54:15 PM UTC,Nov 14 2020 07:12:10 PM UTC,Feb 17 2021 11:15:19 AM UTC,,,,,,Backlog,Geo,Querying,,,2,,,,,,"API Support for searches such as ""which points have the most other points within a certain radius."" 

This ability would in turn open up the door for variations such as which points have the least, which points are furthest away from all other points, which points are more densely surrounded by other points, etc.

Currently the only way to do this is to build a quad tree using our indexes and points application side. Would be nice to have a way to do this natively to geo indexes. 
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2014-08-26 14:07:11.0,204422400,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,craig.homa(craig.homa),Tue Aug 26 14:07:11 UTC 2014,,,,,,,,No,,,,,,backlog-query-execution(JIRAUSER1257109),greg_10gen(greg_10gen),osmar.olivo(osmar.olivo@10gen.com),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i03ky7:",,,,,,,"0|i00vcn:",115363,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i0s6jr:","Aug 26 2014 02:07:11 PM UTC;greg_10gen;Think this belongs more in the aggregation/query/M-R framework than geo features specifically - density analysis is useful for lots of things, not just geospatial data.  That being said, ""unwinding"" and ""grouping"" shapes into raster grids and performing analysis on the aggregate properties is something we've discussed - we're still trying to consolidate the above frameworks to make it easier to add these new features.

Changed the title to avoid confusion with our current $geoNear searches.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Default collation for database,SERVER-28362,365598,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-query-execution,daniel.moqvist@knowit.se,daniel.moqvist@knowit.se,Mar 17 2017 06:35:19 AM UTC,Nov 14 2020 07:12:07 PM UTC,Feb 17 2021 11:15:19 AM UTC,,3.4.0,,,,Backlog,Indexing,Querying,,,10,,,,,,"It would be great if we can set default collation for the entire database. That way, all newly created collections and view will have the default collation.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,5002K00000pk6vPQAQ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2017-03-21 23:49:31.0,64540800,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,craig.homa(craig.homa),Thu Jan 31 18:46:11 UTC 2019,,,,,,,,,,,,,,asya(asya),backlog-query-execution(JIRAUSER1257109),daniel.moqvist@knowit.se(daniel.moqvist@knowit.se),ramon.fernandez(ramon.fernandez),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i1m79j:",,,,,,,"0|i00wyv:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i0mjj3:","Mar 21 2017 11:49:31 PM UTC;ramon.fernandez;Thanks for your report [~daniel.moqvist@knowit.se], we've sent this ticket to the Query team for evaluation.","Jan 31 2019 06:46:11 PM UTC;asya;This would be good because then all change streams that don't specify a collation can inherit the DB collation the way they inherit existing collection's collection (if they are watching the DB or if they are watching a collection that does not yet exist).
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
What if create something like CouchDB views with low cost of developing ? ,SERVER-775,11546,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-query-execution,kostya,kostya,Mar 17 2010 04:32:34 PM UTC,Nov 14 2020 07:12:04 PM UTC,Feb 17 2021 11:15:19 AM UTC,,,,,,features we're not sure of,Querying,,,,4,views,,,,,"I think that the only thing needed is ability to store query results to temp or existed collection, (or maybe only _id fields from matching docs, but better for flexibility we will need both first ) something like this http://jira.mongodb.org/browse/SERVER-610 . In CouchDB there are checking for changed documents already stored to view, this is not a good thing but I don't need that. I think that will be great to query already stored results from another query, that should be CPU efficient, but will take more disk space. And I think there are not so much work to do it.",,,,,,,,,,,,PM-764,SERVER-508,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2011-10-24 15:39:19.0,251856000,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,craig.homa(craig.homa),Sat Feb 23 19:43:03 UTC 2013,,,,,,,,No,,,,,,backlog-query-execution(JIRAUSER1257109),karl(karl),kostya(kostya),beatgammit(beatgammit),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i07fj3:",,,,,,,"0|i0102v:",6638,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i0c4jj:","Oct 24 2011 03:39:19 PM UTC;karl;FWIW, I think just copying CouchDB's general take on views would be great. Additional control over when views are updated would be good (after every X new/updated document OR ever X seconds, in the background).

You'd have to be able to index them, of course. It seems like a decent solution to MapReduce performance limits.","Feb 23 2013 07:43:03 PM UTC;beatgammit;Bump.

I like CouchDB's views, but I also like random queries in Mongo. Since Mongo already supports mapReduce, the results just need to be cached and inserts/updates need to trigger updates to the results.

I don't know Mongo that well, but a simple Google search didn't turn up anything like this.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Automatic incremental map-reduce,SERVER-17354,185752,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-query-execution,FREEZX,FREEZX,Feb 23 2015 07:35:57 PM UTC,Nov 14 2020 07:11:46 PM UTC,Feb 17 2021 11:15:19 AM UTC,,,,,,Backlog,MapReduce,,,,1,,,,,,"Hi,
I've been testing out couchdb, and came across the concept of views.
Views in couchdb are keeping a pre-calculated map-reduce on all data in one database(collection), and they are updated automatically on every change on the original data set.
Knowing that mongodb supports mapreduce, i think it would be a good idea to be able to set up mapreduce that would output to another collection while keeping the mapreduced data synchronized based on inserts, updates, and deletions of the documents in the original collection.

Often there are times where mapreduce is necessary to be used, and keeping the data set synchronized without the hassle or delay of the current incremental mapreduce method will make lives easier.

For details about the implementation in couchdb, read the following articles:
http://horicky.blogspot.com/2008/10/couchdb-implementation.html (sections Views Indexes and Incremental View Update)
http://damienkatz.net/2008/02/incremental_map.html",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2015-02-23 19:53:13.0,188784000,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,craig.homa(craig.homa),2015-02-23 19:35:57.0,,,,,,,,,,,,,,backlog-query-execution(JIRAUSER1257109),FREEZX(freezx),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i0316v:",,,,,,,"0|i00vp3:",163493,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i0s7af:",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Add expression indexes,SERVER-14784,150786,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-query-execution,scotthernandez,scotthernandez,Aug 04 2014 07:31:07 PM UTC,Nov 14 2020 07:11:19 PM UTC,Feb 17 2021 11:15:19 AM UTC,,,,,,Backlog,Indexing,,,,14,,,,,,"An expression index is one where the value being indexed is the result of an expression, like lower casing a string.

http://en.wikipedia.org/wiki/Expression_index
http://www.postgresql.org/docs/8.1/static/indexes-expressional.html

One possible way of specifying the expression could be through the existing aggregation expressions: http://docs.mongodb.org/manual/reference/operator/aggregation/#arithmetic-operators

{code}
db.coll.addIndex(""lowercase_name"", {$expression: {$toLower:""$name""}});
{code}
*Note*: In the example above there is no name for the expression, aside from the index name, because any name could conflict with documents. Also, the expression should be used in the query; the query expression may be a sub/superset of the index expression, or multiple indexes.

Any expression support in indexes requires those expressions be available in the query language as well; it could look like this:
{code}
db.coll.find({$expression: {$eq:[""scott"", {$toLower:""$name""}]}})
{code}",,,,,,,,,,,,PM-1654,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,Major Change,,,,5002K00000dWD99QAG,5002K00000hRb4VQAS,5002K00000lmFjjQAE,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,206323200,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,craig.homa(craig.homa),2014-08-04 19:31:07.0,,,,,,,,Cannot,,,,,,backlog-query-execution(JIRAUSER1257109),scotthernandez(scotthernandez),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i03fo7:",,,,,,,"0|i00vh3:",130842,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i0j9q7:",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Support socket disconnect kills for getMore,SERVER-39475,686306,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-query-execution,jason.carey,jason.carey,Feb 08 2019 08:44:53 PM UTC,Nov 14 2020 07:11:01 PM UTC,Feb 17 2021 11:15:19 AM UTC,,,,,,Backlog,Internal Code,,,,0,former-quick-wins,PM-1279,,,,"As part of the socket disconnect project, a new facility (OperationContext::markKillOnClientDisconnect) was introduced which, when invoked, makes the operation treat socket disconnect as a kill thereafter.

The litmus test for whether to flag an opctx this way is supposed to be whether the underlying operation is idempotent.  I.e. if someone from the outside could have detected if it suceeded or failed if they had connected, started running their command, saw it in currentop, then killed the socket (and gotten full value from the command).

For most cursors, this is a no brainer, if you die while reading a batch, we usually close the cursor.  There's some complexity around detecting whether a cursor is secretely a $out agg cursor that was initiated with batchSize 0 however.  In that case, we'd like to avoid applying the flag.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,Fully Compatible,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2019-04-04 18:31:52.0,59097600,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,craig.homa(craig.homa),Thu Apr 04 18:31:52 UTC 2019,,,,,,,,,,,,,,backlog-query-execution(JIRAUSER1257109),charlie.swanson(charlie.swanson),jason.carey(jason.carey),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i34ls7:",,,,,,,"0|i00tjz:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i34jvz:","Apr 04 2019 06:31:52 PM UTC;charlie.swanson;Noticed this was '4.1 Desired' but not attached to anything that would cause us to do it for 4.2. Flagging for scheduling to discuss if it's worth an effort to make that happen.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
$percentile aggregation accumulator,SERVER-7463,54262,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-query-execution,andre.defrere,andre.defrere,Oct 24 2012 09:52:33 PM UTC,Nov 14 2020 07:10:49 PM UTC,Feb 17 2021 11:15:19 AM UTC,,,,,,Backlog,Aggregation Framework,,,,33,accumulator,expression,pull-request,,,"Would enable computation of things like the median value or the 99th percentile value.

h5. Original Description
Now that the nuts and bolts of aggregation have been taken care of with the new aggregation framework, higher level functions like percentile and top, which we use extensively to report on metrics is highly desirable.
Splunk lets me write custom operators and hook them into the query pipeline. Having something similar would be a great enhancement to the aggregation framework.",,,,,,,,,,,,FREE-36962,SERVER-18427,PM-1457,PM-1883,,,,,,,,,,,,,,,,,7.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2013-04-13 22:29:05.0,151286400,,,,,,,,PM-1883,,,,,,,,,,,,,,,,,,,,true,craig.homa(craig.homa),Tue May 03 07:55:26 UTC 2016,,,,,,,,No,,,,,,andre.defrere(andre.defrere),atg@webperf.io(atg@webperf.io),asya(asya),backlog-query-execution(JIRAUSER1257109),charlie.swanson(charlie.swanson),real_ate(real_ate),cstepnitz(cstepnitz),sturadnidge(sturadnidge),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i0598n:",,,,,,,"0|i00s9j:",6983,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i019zz:","Apr 13 2013 10:29:05 PM UTC;sturadnidge;$pow and $log would be really useful to have, trying to use combinations of $multiply and $divide to do the same gets ugly fast!","May 20 2015 07:00:51 PM UTC;charlie.swanson;Let's keep this ticket focused on $top and $percentile. Other additions can be addressed separately.

In order to calculate $top or $percentile, we would need to hold on to all documents in the pipeline. This does not fit into the current streaming architecture. ","Jun 30 2015 06:44:04 PM UTC;cstepnitz;One possible implementation approach for quantiles would be to use a TDigest, such as is documented and implemented in this simple library: https://github.com/tdunning/t-digest","Feb 04 2016 11:15:05 PM UTC;charlie.swanson;I've restricted the scope of this ticket to be simply {{$percentile}}, as {{$top}} would be possible if we resolved SERVER-9377.","Feb 09 2016 04:24:30 PM UTC;real_ate;Has anyone discussed the potential implementation of this yet? I have a need for this operator and I have a few ideas how I might expect it to work, and if there hasn't been a design discussion about it I would like to start it here. ","Feb 09 2016 05:32:29 PM UTC;asya;[~real_ate] I don't believe we have - feel free to add your ideas here.  

To make sure we are on the same page, it would help to include some specific examples.

","May 03 2016 07:55:26 AM UTC;atg@webperf.io;+1 for TDigest implementation to build a $percentile aggregation accumulator. Moreover, for incremental aggregation and merge of several TDigest (e.g. to compute the percentile on a long running period by aggregating multiple TDigest for sub periods), a TDigest serializer/deserializer would be great to store TDigest as Binary Data.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Add user configurable stop word lists for text search,SERVER-10062,80751,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-query-execution,pasette,pasette,Jun 28 2013 08:53:44 PM UTC,Nov 14 2020 07:10:36 PM UTC,Feb 17 2021 11:15:19 AM UTC,,,,,,Backlog,Text Search,,,,14,,,,,,Configurable stop word lists can be loaded into a known configuration directory and loaded at server boot time.  Need to be able to version indexes based on stop word list used.,,,,,,,,,,,,SERVER-15027,CS-32690,,,,,,,,,,,,,,,,,,,6.0,,,,,,,,,,,,,,,,,,,,,500A000000XTHXiIAP,500A000000a88A7IAI,5002K00000msSsgQAE,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2013-12-20 13:48:29.0,56419200,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,craig.homa(craig.homa),Mon May 06 09:48:24 UTC 2019,,,,,,,,No,,,,,,backlog-query-execution(JIRAUSER1257109),benety.goh(benety.goh),pasette(dan@10gen.com),JoonasF(joonasf),massimo.brignoli(massimo.brignoli),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i04dvr:",,,,,,,"0|i00ucv:",6422,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i1iv0v:","Dec 20 2013 01:48:29 PM UTC;JoonasF;Would really need this one for couple of projects.","May 27 2014 06:49:02 PM UTC;benety.goh;Pull requests linked for sample stop word lists.","Dec 04 2014 10:37:41 AM UTC;JoonasF;Any ETA on completing this? We are waiting for this feature to replace a large stack of site searches to use MongoDB.","Oct 02 2015 05:59:20 AM UTC;massimo.brignoli;Any news on this topic?","Jan 17 2018 07:01:58 PM UTC;JoonasF;Any progress? Still eagerly waiting for this.","May 06 2019 09:48:24 AM UTC;JoonasF;Same as above. Any progress for this one? It's still relevant and haven't seen anything happening in almost six years.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Allow predicates to be covered when indexed path is prefix of matched path,SERVER-22451,262842,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-query-optimization,viaus,viaus,Feb 03 2016 03:35:36 PM UTC,Nov 14 2020 07:02:43 PM UTC,Feb 17 2021 11:15:19 AM UTC,,,,,,Backlog,Querying,,,,0,,,,,,"Consider the following script.

{noformat}
db.test.insert({_id : {a : 1, b : 1}})
db.test.insert({_id : {a : 1, b : 2}})
db.test.insert({_id : {a : 2, b : 1}})
db.test.insert({_id : {a : 2, b : 2}})
db.test.insert({_id : {a : 3, b : 1}})
db.test.insert({_id : {a : 3, b : 2}})
db.test.insert({_id : {a : 4, b : 1}})
db.test.insert({_id : {a : 4, b : 2}})
db.test.find({""$and"" : [{_id : {""$gte"" : {a : 2} }}, {_id : {""$lte"" : {a : 3, b : MaxKey()} }}, {""_id.b"" : 1}]})
{noformat}

==>

{noformat}
{ ""_id"" : { ""a"" : 2, ""b"" : 1 } }
{ ""_id"" : { ""a"" : 3, ""b"" : 1 } }
{noformat}

So far so good. Yet, doing explain() on that reveals the following:

{noformat}
{
    ""queryPlanner"" : {
        ""plannerVersion"" : 1,
        ""namespace"" : ""test.test"",
        ""indexFilterSet"" : false,
        ""parsedQuery"" : {
            ""$and"" : [
                {
                    ""_id.b"" : {
                        ""$eq"" : 1
                    }
                },
                {
                    ""_id"" : {
                        ""$lte"" : {
                            ""a"" : 3,
                            ""b"" : { ""$maxKey"" : 1 }
                        }
                    }
                },
                {
                    ""_id"" : {
                        ""$gte"" : {
                            ""a"" : 2
                        }
                    }
                }
            ]
        },
        ""winningPlan"" : {
            ""stage"" : ""FETCH"",
            ""filter"" : {
                ""$and"" : [
                    {
                        ""_id"" : {
                            ""$lte"" : {
                                ""a"" : 3,
                                ""b"" : { ""$maxKey"" : 1 }
                            }
                        }
                    },
                    {
                        ""_id"" : {
                            ""$gte"" : {
                                ""a"" : 2
                            }
                        }
                    },
                    {
                        ""_id.b"" : {
                            ""$eq"" : 1
                        }
                    }
                ]
            },
            ""inputStage"" : {
                ""stage"" : ""IXSCAN"",
                ""keyPattern"" : {
                    ""_id"" : 1
                },
                ""indexName"" : ""_id_"",
                ""isMultiKey"" : false,
                ""isUnique"" : true,
                ""isSparse"" : false,
                ""isPartial"" : false,
                ""indexVersion"" : 1,
                ""direction"" : ""forward"",
                ""indexBounds"" : {
                    ""_id"" : [
                        ""[{ a: 2.0 }, { a: 3.0, b: MaxKey }]""
                    ]
                }
            }
        },
        ""rejectedPlans"" : [ ]
    },
    ""executionStats"" : {
        ""executionSuccess"" : true,
        ""nReturned"" : 2,
        ""executionTimeMillis"" : 0,
        ""totalKeysExamined"" : 4,
        ""totalDocsExamined"" : 4,
        ""executionStages"" : {
            ""stage"" : ""FETCH"",
            ""filter"" : {
                ""$and"" : [
                    {
                        ""_id"" : {
                            ""$lte"" : {
                                ""a"" : 3,
                                ""b"" : { ""$maxKey"" : 1 }
                            }
                        }
                    },
                    {
                        ""_id"" : {
                            ""$gte"" : {
                                ""a"" : 2
                            }
                        }
                    },
                    {
                        ""_id.b"" : {
                            ""$eq"" : 1
                        }
                    }
                ]
            },
            ""nReturned"" : 2,
            ""executionTimeMillisEstimate"" : 0,
            ""works"" : 5,
            ""advanced"" : 2,
            ""needTime"" : 2,
            ""needYield"" : 0,
            ""saveState"" : 0,
            ""restoreState"" : 0,
            ""isEOF"" : 1,
            ""invalidates"" : 0,
            ""docsExamined"" : 4,
            ""alreadyHasObj"" : 0,
            ""inputStage"" : {
                ""stage"" : ""IXSCAN"",
                ""nReturned"" : 4,
                ""executionTimeMillisEstimate"" : 0,
                ""works"" : 5,
                ""advanced"" : 4,
                ""needTime"" : 0,
                ""needYield"" : 0,
                ""saveState"" : 0,
                ""restoreState"" : 0,
                ""isEOF"" : 1,
                ""invalidates"" : 0,
                ""keyPattern"" : {
                    ""_id"" : 1
                },
                ""indexName"" : ""_id_"",
                ""isMultiKey"" : false,
                ""isUnique"" : true,
                ""isSparse"" : false,
                ""isPartial"" : false,
                ""indexVersion"" : 1,
                ""direction"" : ""forward"",
                ""indexBounds"" : {
                    ""_id"" : [
                        ""[{ a: 2.0 }, { a: 3.0, b: MaxKey }]""
                    ]
                },
                ""keysExamined"" : 4,
                ""dupsTested"" : 0,
                ""dupsDropped"" : 0,
                ""seenInvalidated"" : 0
            }
        },
        ""allPlansExecution"" : [ ]
    },
    ""serverInfo"" : {
        ""host"" : ""***"",
        ""port"" : 27017,
        ""version"" : ""3.2.1"",
        ""gitVersion"" : ""a14d55980c2cdc565d4704a7e3ad37e4e535c1b2""
    },
    ""ok"" : 1
}
{noformat}

I may be misinterpreting the output, but it seems to me that the filter {""_id.b"" : 1} is applied AFTER the full document has been retrieved, NOT when scanning the index. I am led to this conclusion by seeing the filter spec in the FETCH stage and seeing
{noformat}
            ""nReturned"" : 2,
            ""docsExamined"" : 4,
{noformat}
in its stats.

So, basically, when the index is on a sub-document, and the query filter includes the sub-document's fields, the server does not seem to understand that it could use the index to evaluate the filter; it goes to the collection instead. That can be very costly.

Some background as to why this is important. The _id index is mandatory. It is therefore desirable to make it useful. It is also non-configurable, so one pretty much has to make _id a sub-document except in simplest cases.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2016-02-04 16:38:30.0,158630400,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,craig.homa(craig.homa),Mon Feb 08 10:46:46 UTC 2016,,,,,,,,,,,,,,backlog-query-optimization(JIRAUSER1257108),kelsey.schubert(thomas.schubert),viaus(viaus),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i01uc7:",,,,,,,"0|i00w6n:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i0xewn:","Feb 04 2016 04:38:30 PM UTC;kelsey.schubert;Hi [~viaus],

Thank you for opening this ticket. Currently, MongoDB does not support the behavior that you are requesting. For additional information, please see our documentation regarding [indexes on embedded documents|https://docs.mongodb.org/manual/core/index-single/#indexes-on-embedded-documents].

I am marking this ticket as a new feature to be scheduled during the next round of planning. Updates will be posted here as they happen.

Kind regards,
Thomas","Feb 08 2016 10:46:46 AM UTC;viaus;Unfortunately, the referenced documentation does not deal with this issue at hand. As far as I can tell, this issue is not addressed anywhere at all. So I suggest, if the feature does not make it (any time soon), explain in the documentation that a single-field index, if the field is a sub-document, cannot efficiently support range queries with additional filters on the sub-document's fields.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"""Casting"" geojson polygon to linestring",SERVER-28563,368577,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-query-optimization,buzz.moschetti,buzz.moschetti,Mar 28 2017 03:22:38 PM UTC,Nov 14 2020 07:01:55 PM UTC,Feb 17 2021 11:15:19 AM UTC,,,,,,Backlog,Geo,,,,0,,,,,,"A point INSIDE a polygon is considered by $geoNear to be distance zero.
Sometimes it is desirable to treat that polygon like a lake and given a point, calculate distance ""to the shore.""   The same polygon saved as a linestring (first poly only of course; no holes) yields the desired distance behavior.
Since it is not practical to store BOTH reps and we cannot run $geoNear on a ""literal shape"" a nice feature would be to somehow indicate to $geoNear that polygons should be treated as linestrings for the execution of the command.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2017-03-30 17:33:57.0,122774400,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,craig.homa(craig.homa),2017-03-28 15:22:38.0,,,,,,,,,,,,,,backlog-query-optimization(JIRAUSER1257108),buzz.moschetti(buzz.moschetti),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i1mpkf:",,,,,,,"0|i00wzb:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i0mhq7:",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Add Bitmap indexes,SERVER-1723,12991,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-query-optimization,rb2k,rb2k,Sep 03 2010 08:10:22 AM UTC,Nov 14 2020 07:01:33 PM UTC,Feb 17 2021 11:15:20 AM UTC,,,,,,Backlog,Indexing,,,,49,,,,,,"As an alternative to a B+Tree, using Bitmap Indexes (http://en.wikipedia.org/wiki/Bitmap_index) could allow a very speedy retrieval of simple queries like the equivalent of ""SELECT * FROM FOO WHERE GENDER = ""MALE"" AND ""STUDENT"" = TRUE.

Bitmap indexes used to be thought of a ""low cardinality"" thing, but in ""An Adequate Design for Large Data Warehouse Systems: Bitmap index versus B-tree index"" by Zaker et al, the authors go even as far as saying that for certain situations, the cardinality of the values does not even matter. Their conclusive statement is as follows:

Thus, we conclude that Bitmap index is the conclusive choice for a DW designing no matter for columns with high or low cardinality.

A highly optimized C++ library called Fastbit (https://sdm.lbl.gov/fastbit/) already exists.

Especially when using large amounts of data that have a low cardinality (e.g. a 'gender' field), the compressed bitmap indexes could keep the RAM usage low and outperform B+Trees.
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,6.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2010-12-07 04:06:52.0,156124800,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,craig.homa(craig.homa),Mon Mar 07 15:00:17 UTC 2016,,,,,,,,No,,,,,,plasma(plasma),backlog-query-optimization(JIRAUSER1257108),lemire@gmail.com(lemire@gmail.com),dlee(dlee),eliot(eliot),rb2k(rb2k),rlaferla(rlaferla),smasters(smasters),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i0758n:",,,,,,,"0|i00tw7:",6228,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i080hz:","Dec 07 2010 04:06:52 AM UTC;smasters;Even just having limited support for a tag would be highly useful and efficient.","Dec 09 2010 01:20:57 AM UTC;plasma;Bitmap indexes are also mergable; you can overlay multiple bitmap indexes to resolve queries by having individual, single column/field bitmap indexes where one covers GENDER, another with YEAR, and another that covers STUDENT.

This would mean you have three indexes that covers all permutations of those 3 fields (or just one or two of them), unlike with compound btree indexes where its a left-most matching prefix.","Dec 30 2010 10:57:55 AM UTC;dlee;UPDATE: I propose merging b-tree indexes using in-memory bitmap indexes, like PostgreSQL

Supporting in-memory bitmap indexes is a great way to increase performance using simpler (non-compound) indexes, and fits mongodb's philosophy of giving users greater performance in simplicity and flexibility. In-memory bitmap indexes allow single property indexes to go further without having to create various permutations of compound indexes.

Postgresql does this and explains it better: http://www.postgresql.org/docs/8.3/static/indexes-bitmap-scans.html","Feb 29 2012 07:53:11 PM UTC;rlaferla;This is an important feature.  Why hasn't it received much attention?","Apr 01 2012 06:13:57 AM UTC;eliot;There are a lot of important features, so its just on the list, just hasn't made it to the top yet.","Mar 07 2016 03:00:17 PM UTC;lemire@gmail.com;[~rb2k]:

Fastbit is indeed very good, but it uses WAH which is patented: http://www.google.ca/patents/US6831575

Alternatives include EWAH which is used, for example, by Git (https://github.com/git/git/tree/master/ewah), Apache Hive and so forth.  See  http://githubengineering.com/counting-objects/

There is also Roaring (http://roaringbitmap.org/) used by Apache Spark, Apache Kylin, Druid, Elastic and so forth. See https://www.elastic.co/blog/frame-of-reference-and-roaring-bitmaps

To the best of my knowledge, EWAH and Roaring are not encumbered by patents. They are both used is several major mission-critical projects.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Accept expressions (e.g. $range) for the 'boundaries' argument to $bucket.,SERVER-27152,333410,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-query-optimization,buzz.moschetti,buzz.moschetti,Nov 21 2016 08:17:15 PM UTC,Nov 14 2020 07:01:23 PM UTC,Feb 17 2021 11:15:20 AM UTC,,,,,,Backlog,Aggregation Framework,,,,0,,,,,,"I am hoping I am simply missing something so obvious I am ignoring it.
This works:
{noformat}
c=db.cscl2.aggregate([
{$bucket: {""groupBy"": ""$length"",
           boundaries: [0,5,10,15],
    default:""other"" }}
                      ]);
show(c);
{noformat}

This does not:      
{noformat}                                                             
c=db.cscl2.aggregate([
{$bucket: {""groupBy"": ""$length"",
           boundaries: {$range: [0,20,5 ]},
    default:""other"" }}]);
show(c);
 ""errmsg"" : ""The $bucket 'boundaries' field must be an array, but found type: object."",
 ""code"" : 40200,                                                                        
 ""codeName"" : ""Location40200""                                                           
{noformat}

So changing [0,5,10,15] to {$range: [0,20,5]} creates the error.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2016-11-22 15:54:47.0,133747200,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,craig.homa(craig.homa),2016-11-21 20:17:15.0,,,,,,,,,,,,,,backlog-query-optimization(JIRAUSER1257108),buzz.moschetti(buzz.moschetti),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i01fkf:",,,,,,,"0|i00wu7:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Not Needed,,,,,,,,,,,,,,,,,,,"0|i0mtx3:",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Support $unionWith in a transaction,SERVER-48122,1347526,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-query-optimization,charlie.swanson,charlie.swanson,May 12 2020 01:28:22 AM UTC,Nov 14 2020 07:01:20 PM UTC,Feb 17 2021 11:15:20 AM UTC,,4.4.0,,,,Backlog,Aggregation Framework,,,,0,,,,,,We could not enable this during the initial implementation due to missing dependencies tracked in other work linked here. This ticket tracks the work to enable $unionWith in a transaction and add some tests for it. ,,,,,,,,SERVER-46378,SERVER-46373,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,24278400,"<a href='https://jira.mongodb.org/browse/SERVER-46378'>SERVER-46378</a>, <a href='https://jira.mongodb.org/browse/SERVER-46373'>SERVER-46373</a>",,,,,,,,,,,,,,,,,,,,,,,,,,,true,craig.homa(craig.homa),2020-05-12 01:28:22.0,,,,,,,,,,,,,,backlog-query-optimization(JIRAUSER1257108),charlie.swanson(charlie.swanson),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i68j9r:",,,,,,,"0|i00zq7:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i68hdb:",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
I want to apply notablescan to per DB or per COLLECTION on production.,SERVER-15561,162522,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-query-optimization,crumbjp,crumbjp,Oct 08 2014 07:06:38 AM UTC,Nov 14 2020 07:01:00 PM UTC,Feb 17 2021 11:15:20 AM UTC,,,,,,Backlog,Querying,,,,8,asya,,,,,"h3.WISH
  Want to use notablescan on the production DB.
  Want to apply notablescan to per DB or per COLLECTION.

h3.REASON
  We can kill our mongod easily by sending query with no indexed field to the *more than hundreds GB of collection*.
  To make matters worse, we'll get same results by specifying *non-existent field* cause by simple *typo*.

  The feature of notablescan option can prevent these catastrophic incidents.
  Especially, on the production DB.

h3.ADDITIONAL
  But currently, likely to add this sentence to mongo-docs.

 {quote}
  +   Don't run production :program:`mongod` instances with
  +   :parameter:`notablescan` because preventing table scans can potentially
  +   affect queries in all databases, including administrative queries.
{quote}
 https://github.com/mongodb/docs/commit/43a37686f53102e639a33d404e9f73f47d1729a6#diff-ee73e0a6a2ede9af5743e69b8fad4f80R128

  I think, this is the wrong policy to keep our mongo system safety.
  On the contrary, I want to come to be that the notablescan option is applicable per DB or per COLLECTION.
",,,,,,,,,,,,SERVER-1143,,,,,,,,,,,,,,,,,,,,7.0,,,,,,,,,,,,,,,,,,,,,500A000000arDBtIAM,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2014-10-08 13:38:39.0,81475200,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,craig.homa(craig.homa),Thu Jul 19 20:04:38 UTC 2018,,,,,,,,,,,,,,asya(asya),backlog-query-optimization(JIRAUSER1257108),shaggie76(shaggie76),crumbjp(crumbjp),ramon.fernandez(ramon.fernandez),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i03bfb:",,,,,,,"0|i00vjj:",141618,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i0yqiv:","Oct 08 2014 03:49:21 PM UTC;ramon.fernandez;[~crumbjp], a tablescan should not kill {{mongod}}. If this happens to you it would be great if you could provide additional information to investigate if there's a bug somewhere. In particular:
* What platform are you using? OS name and version, virtualization platform if any, memory size...
* What kind of MongoDB deployment do you have? Are you using sharding? Replication?
* Are you able to upload logs from the {{mongod}} node that becomes unavailable during a tablescan?
* What does your schema look like? What type of queries make {{mongod}} unavailable?

In the meantime you may want to investigate the use of [maxTimeMS|http://docs.mongodb.org/manual/reference/operator/meta/maxTimeMS/#maxtimems] and/or [maxScan|http://docs.mongodb.org/manual/reference/operator/meta/maxScan/] in your queries, that may help you work around this issue.

Looking forward to hear more details so we can get to the bottom of this.

Regards,
Ramón.
","Oct 08 2014 04:57:02 PM UTC;crumbjp;OS: Linux (Cent, Ubuntu)
storage: SSD 
memory: more than 60 GB
Data size: more than 500GB ~ ?TB

If I issue a fullscan query, the OP occupy large resource, and tuｒn hot-data out and cause heavy thrashing.
So, entire the query will slowdown and mongod will be silent and finally died.
Continuous these events will conclude in some minutes.

I know that this is the harsh environment case.
Therefor to begin with, MongoDB is the product that intended for the above. I believe.

The maxTimeMS is good feature.
I already use it when I FEEL THE QUERY IS DANGER.
But I don't feel use it to all my query. (And difficult to prospect the time of query before issue ) 
","Oct 09 2014 08:41:29 PM UTC;ramon.fernandez;Hi [~crumbjp],

without full logs my only guess is that {{mongod}} could be being killed by the OOM killer from the OS, but we'd like to make sure there are no other bugs lurking that may be causing this issue. If you could upload full logs from the {{mongod}} process from startup until one of your queries kills it that would help us investigate the issue. If it's easy for you to reproduce the scenario you describe, please [increase the logLevel to 1|http://docs.mongodb.org/manual/reference/parameters/#param.logLevel] and upload the resulting logs from startup of the {{mongod}} process.

Additionally, we'd like to consider your suggestion so we're either going to keep this ticket open, or merge it with SERVER-1143 which suggest a similar enhancement.

Please let us know if you can upload the requested logs.

Thanks,
Ramón.","Oct 10 2014 01:02:28 AM UTC;crumbjp;I don't want to investigate the reason of the mongod killed.

This issue is obviously not caused from any bugs.
Simply, caused from (unintentionally) heavy load.

Not only MnogoDB, this is the theory of the all of the system that under the high-load.
The operation of  these kind of the system is very tense. 
So I want to reduce the risk of simple typo.

","Oct 14 2014 06:51:50 PM UTC;ramon.fernandez;Understood, thanks [~crumbjp]. We're keeping this ticket open to consider your request for a future version of MongoDB.","Jun 11 2015 04:56:32 PM UTC;shaggie76;As I mentioned in SERVER-1143 I think what would be best would be ""notablescan by default"" but you can opt out like rs.slaveOk() when you need to do something dangerous. This would prevent a large number of fat-finger fires.
","Jul 19 2018 08:04:38 PM UTC;asya;Most related tickets talk about ""typos"" - generally that only happens in the shell during interactive sessions.  I opened SERVER-36196 to make it possible to determine in the shell whether it's being run in interactive mode - that would allow us to alter the shell helpers to either disallow or warn on attempts to query a large collection without an index.

 ",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Support other scripting languages (eg perl) for map/reduce,SERVER-699,11422,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-query-optimization,joshr,joshr,Mar 04 2010 11:55:22 AM UTC,Nov 14 2020 06:59:36 PM UTC,Feb 17 2021 11:15:20 AM UTC,,,,,,features we're not sure of,Usability,,,,22,map-reduce,,,,,"It would be advantageous to be able to use other scripting languages in map/reduce tasks (for me, perl, though I could see python being a good fit too).

This would allow developers to write map/reduce tasks more easily,  and to allow them to access code and libraries in that language which might be advantageous during the map/reduce tasks.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,10.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2010-03-04 20:53:37.0,322272000,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,craig.homa(craig.homa),Thu Dec 02 00:56:16 UTC 2010,,,,,,,,No,,,,,,backlog-query-optimization(JIRAUSER1257108),bpoweski(bpoweski),bobbyj(bobbyj),shingara(shingara),eliot(eliot),evanwies(evanwies),joshr(joshr),kali(kali),csirac2(csirac2),vak(vak),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i07gdz:",,,,,,,"0|i0108n:",6642,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i00ulb:","Mar 04 2010 08:53:37 PM UTC;eliot;agree it would be nice - but non-trivial
we would either have to embed each one, or provide a general process io version of map/reduce
unclear how well that would work, but perhaps","Apr 05 2010 06:11:18 PM UTC;bpoweski;For us perl with all of its complexity, and well Perlisms, would a less desirable language.  I think Lua would be a natural fit.","Apr 15 2010 03:32:06 PM UTC;evanwies;Some notes on Lua.  Lua is really fast and designed to be embedded.  

mstearn said that preserving ordering of keys is important.  Lua doesn't do that.  There was a patch in January 2010 that does that (http://lua-users.org/lists/lua-l/2010-01/msg00199.html).  Since it is a patch rather than a library, it would only be feasible for the server.  Clients can't be expected to use patched VM.

Lua has an awesome JIT (http://www.luajit.org).  It would make a lot of sense for map/reduce.  You'd need to port the ordered  patch to it.   You'd also want to wait for the Foreign Function Interface (FFI) or raw struct access to be added.

Notes on syntax:  Lua table is a little cleaner syntax than pure JSON.
pure JSON:  { ""name"" : ""mongo"", ""type"" : ""db"" }
Lua: { name = ""mongo"", type = ""db"" }

Since the native (albeit configurable) data type in Lua is a double, there are issues storing 64-bit integers.  There are various solutions for this which are web-searchable.
","Jun 22 2010 03:18:57 AM UTC;kali;I had a conversation at MongoFR with Matthias, and I think it would be a good place to followup.

I think we need to have something similar to hadoop streaming. The principle is simple, each mapper starts an external process with a command specified by the user, push each document on the process STDIN, get each emitted value on its STDOUT. And same for reducer.

That would give support in m/r for any language that can read and write json and/or bson, instead of having to pick one or a few languages that will let most users frustrated and require more and more heavy code maintenance and complex dependencies

The nice point with this approach is also it is very easy to simulate map reduce using unix pipes in a development environment.

Matthias expressed concern about that feature allowing arbitrary code execution on the server, but that is a risk that can be mitigated : we may want to limit it to some directory where the admin put the scripts, or even a more defined list, or have a map/reduce worker running as nobody... but that would seriously make the installation more difficult.

As far as I'm concerned, I'd prefer the server to let me do whatever I want, with the user mongo is actually running. My data, my responsibility.

For your information, hadoop also manages code transport from wherever the job is launched to the various nodes.

The use case I'm investigating is log analysis, I would love to get all my logs into mongo to support real time collection, long term storage, massive analysis and pinpoint debugging. But in massive analysis, streaming is an absolute must.

http://wiki.apache.org/hadoop/HadoopStreaming","Jun 22 2010 05:21:57 AM UTC;shingara;I totaly agree with Mathieu. The streaming solution is really good solution to use what we want to do for map/reduce. In certain way, it can help us to made a multi-threading map/reduce function because it's our program to be multi-thread, not MongoDB.","Jun 22 2010 05:23:58 AM UTC;eliot;@mathieu @cyril  we agree.  we haven't gotten to it yet - but its definitely one of the things we want to support.
first version will probably require you to manage binaries, and the api will be BSON in and out","Sep 22 2010 06:00:41 PM UTC;vak;+1 to Mathieu Poumeyrol","Oct 16 2010 01:06:29 AM UTC;csirac2;I can appreciate that this task may be a little open-ended, there are some interesting design decisions to make. Turning mongo into a full-blown distributed HPC platform might be asking too much. But we would really appreciate a streaming solution also - no matter how primitive.

Although we will be storing raw data in mongodb, the system we are building is only able to exploit mongo for metadata (management of the raw data). As things currently stand, we either have to fund someone to re-work a precious few algorithms into mongo+m/r javascript (costly, unsustainable), relying on sharding to have any hope of reasonable CPU utilisation or alternatively we build an in-house API to bridge the raw data from mongob to an entirely separate distributed HPC framework.

We work in bioinformatics - many problems fit embarrassingly well into map/reduce, but we rely heavily on libraries to the bulk of the work (python, perl, ruby - probably in that order - though people use things like R on their workstations)","Dec 01 2010 11:53:13 PM UTC;bobbyj;Big priority for us.  We chose to use mongodb partly because pymongo integrated so nicely into our python codebase.  Now we find ourselves using hadoop for mapreduce jobs just so we can keep our mapper/reducer functionality in python.  Thanks for looking into this!","Dec 02 2010 12:56:16 AM UTC;joshr;I'm the original poster of this JIRA (not that I was the first to want support for other languages in m/r). It's been interesting to see how the conversation here has evolved.

To add my $0.01:  +1 to streaming solution. And BSON in/out sounds just fine.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Hyperloglog Counting,SERVER-31234,431931,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-query-optimization,hyades,hyades,Sep 24 2017 01:39:18 PM UTC,Nov 14 2020 06:59:15 PM UTC,Feb 17 2021 11:15:20 AM UTC,,,,,,Backlog,Aggregation Framework,,,,1,expression,,,,,"The use case is to count the number of distinct elements where the set size is very large, and we need approximate carnality

Presently to count the number of distinct elements in a set while grouping there are two ways-
# $addToSet followed by $size. 
# $group with the element in _id followed by another $group stage which collects and counts all such documents.

The first approach has a problem that the 16MB document size limit may be reached pretty fast. The second approach has a lot of memory overhead and thus is very slow.

A hyperloglog based approach would help reduce the overheads and probably will be faster.







",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2017-09-25 19:23:08.0,102643200,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,craig.homa(craig.homa),Thu Nov 16 23:11:28 UTC 2017,,,,,,,,,,,,,,hyades(hyades),backlog-query-optimization(JIRAUSER1257108),kelsey.schubert(thomas.schubert),apocarteres(apocarteres),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i1xgen:",,,,,,,"0|i00x9j:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i1xeif:","Sep 25 2017 07:23:08 PM UTC;kelsey.schubert;Hi [~hyades],

Thank you for the feature request; I've marked it for consideration. Please continue to watch this ticket for updates.

Kind regards,
Kelsey","Nov 16 2017 11:11:28 PM UTC;apocarteres;i guess it's not possible unless MongoDB will be supporting plugins. Having implemented cardinality counting with hardcoded HLL+ is going to produce backward compatibility issues in case MongoDB will decided to pickup something else to count cardinality in future. ",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
allow regex word character (\w) and word boundary (\b) escapes to be unicode-aware,SERVER-23881,281755,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-query-optimization,niccottrell,niccottrell,Apr 22 2016 05:06:28 PM UTC,Nov 14 2020 06:59:05 PM UTC,Feb 17 2021 11:15:20 AM UTC,,3.0.11,,,,Backlog,Querying,,,,1,,,,,,"Provide a way to use regular expressions in MongoDB where the word character (\w) and word boundary (\b) escapes work for code points greater than or equal to 256.

h5. Original description

$regex word boundary fails by treating Danish ø character as a non-character

{noformat}
db.collection.find({ ""name"" : { ""$regex"" : "".*\\bden\\b.*"" , ""$options"" : ""i""} })
{noformat}

returns a document:
{noformat}
{  ""name"": ""Death Is A Caress(Døden Er Et Kjærtegn).sub"" }
{noformat}",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,5.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2016-04-26 20:59:07.0,151718400,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,craig.homa(craig.homa),Wed Apr 27 19:32:30 UTC 2016,,,,,,,,,,,,,,backlog-query-optimization(JIRAUSER1257108),david.storch(david.storch),niccottrell(niccottrell),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i01ynz:",,,,,,,"0|i00wen:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i0319z:","Apr 26 2016 10:12:07 PM UTC;david.storch;Hi [~niccottrell],

Thanks for reporting this issue! You are absolutely correct that PCRE considers the Danish character ø to be a non-word character. This can be seen more clearly in the following example:
{code}
> db.c.drop();
> db.c.insert({test: ""ø""});
> db.c.insert({test: ""a""});
> db.c.find({test: /\w/});
{ ""_id"" : ObjectId(""571fe12e5bf4a8f145edf56c""), ""test"" : ""a"" }
> db.c.find({test: /\W/});
{ ""_id"" : ObjectId(""571fe12b5bf4a8f145edf56b""), ""test"" : ""ø"" }
{code}
This is why ø is forming a word boundary. The PCRE manual has the following to say on the subject:
{quote}
       PCRE handles caseless matching, and determines whether  characters  are
       letters,  digits, or whatever, by reference to a set of tables, indexed
       by character code point. When running in UTF-8 mode, or in the  16-  or
       32-bit libraries, this applies only to characters with code points less
       than 256. By default, higher-valued code  points  never  match  escapes
       such  as \w or \d. However, if PCRE is built with Unicode property sup-
       port, all characters can be tested with \p and \P,  or,  alternatively,
       the  PCRE_UCP option can be set when a pattern is compiled; this causes
       \w and friends to use Unicode property support instead of the  built-in
       tables.
{quote}

It elaborates:
{quote}
The character escapes \b, \B, \d, \D, \s, \S, \w, and \W correctly test characters of any code value, but, by default, the characters that PCRE recognizes as digits, spaces, or word characters remain the same set as in non-UTF mode, all with values less than 256. This remains true even when PCRE is built to include Unicode property support, because to do otherwise would slow down PCRE in many common cases. Note in particular that this applies to \b and \B, because they are defined in terms of \w and \W. If you really want to test for a wider sense of, say, ""digit"", you can use explicit Unicode property tests such as \p\{Nd\}. Alternatively, if you set the PCRE_UCP option, the way that the character escapes work is changed so that Unicode properties are used to determine which characters match. There are more details in the section on generic character types in the pcrepattern documentation.
{quote}

So, to summarize, this is the expected behavior of PCRE. Unfortunately, as a user of MongoDB, there is no way to make use of the PCRE_UCP option or to otherwise coerce PCRE to use the unicode-aware regular expression semantics you desire. Therefore, we will keep this ticket open as a feature request. I am going to move it into Needs Triage state, and our development team will evaluate it at our next triage meeting. Please continue to watch for updates.

Best,
Dave","Apr 27 2016 08:26:52 AM UTC;niccottrell;Thanks for the details. Strange that there's not a way to flip PCRE into Unicode mode. Most regex platforms/libraries I know allow a ""u"" Unicode flag to force behaviour like this. It feels a bit wrong for Mongo to not include regex support for at least other European languages out of the box.","Apr 27 2016 01:15:52 PM UTC;david.storch;Hi [~niccottrell], just to clarify: I believe that we do build PCRE with UTF-8 support enabled. It appears that the default behavior of the escapes \b and \w, among others, is simply not changed when unicode support is enabled.","Apr 27 2016 07:21:18 PM UTC;niccottrell;Thanks - I just read up and understand. It's a bit of a shock since I'm used to Java's engine that seems to be the exception..","Apr 27 2016 07:32:30 PM UTC;niccottrell;It seems that this will work for my case:

{noformat}
{ ""name"" : { ""$regex"" : ""(^|.*\\s+)den(\\s+.*|$)"" , ""$options"" : ""i""} }
{noformat}
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Add Weighted Average method to aggregation framework,SERVER-32790,484898,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-query-optimization,yair.lenga@gmail.com,yair.lenga@gmail.com,Jan 19 2018 02:32:04 PM UTC,Nov 14 2020 06:57:34 PM UTC,Feb 17 2021 11:15:20 AM UTC,,3.6.0,,,,Backlog,Aggregation Framework,,,,1,expression,,,,,"Add '$weightedAverage'  operator to the aggregation framework.

Currently, MongoDB has the $avg operator. It simplify the calculation of simple averages. The request is to create built in operator for calculating weighted average - where the weight of each item is specified by a different field.

Weighted average is used extensively in financial, statistical and scientific analysis of large data set. While it is technically possible to implement it based on existing operators (sum(...)), the implementation is error-prone, and correct handling of missing/non-numeric values make is difficult.

Proposed operator: $weightedAvg($weight, $value)

Should calculation
{noformat}
RESULT = (w1*v1 + w2*v2 + w3*v3 ... + w(n)*v(n)) / (w1 + w2 + w3 + ... + W(n))
{noformat}

Calculation should ignore any record where w(I), or v(I) is not numeric. this is important, as the current replacement $sum($multiply($v1, $w1)) / sum($w1) does not handle missing values correctly, and require complex filtering.

If possible, it will be nice to allow for multiple values to be calculated with the same pass.
$weightedAvg($weight, $v1, $v2, $v3) will return the weighted average of the specific value list, weighted by the specific weight, similar to the ability to perform sum/average on multiple values.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,97113600,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,craig.homa(craig.homa),2018-01-19 14:32:04.0,,,,,,,,,,,,,,backlog-query-optimization(JIRAUSER1257108),yair.lenga@gmail.com(yair.lenga@gmail.com),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i26do7:",,,,,,,"0|i00y1r:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i26brz:",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
merge sequential $project stages and $addFields stages when appropriate,SERVER-27744,346826,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-query-optimization,adinoyi.omuya,adinoyi.omuya,Jan 18 2017 10:50:39 PM UTC,Nov 14 2020 06:57:25 PM UTC,Feb 17 2021 11:15:20 AM UTC,,,,,,Backlog,Aggregation Framework,,,,0,neweng,optimization,patrick,,,"Consider{noformat}
{""$project"": {""__joinedPipeline_1_c"":""$c"",""__joinedPipeline_1_e"":""$e"",""_id"":""$__joined_bar._id"",""c"":""$__joined_bar.c""}},
{""$project"": {""__joinedPipeline_1_c"":1,""__joinedPipeline_1_e"":1,""_id"":1,""bar_DOT__id"":""$_id"",""bar_DOT_c"":""$c"",""c"":1}},
{""$project"":{""bar_DOT_c"":""$c"",""foo_DOT_e"":""$__joinedPipeline_1_e""}}
{noformat}
The pipeline can be consolidated into a single {{$project}} stage:{noformat}
{""$project"":{""bar_DOT_c"":""$__joined_bar.c"",""foo_DOT_e"":""$e""}}{noformat}
",,,,,,,,,,,,PM-851,,,,,,,,,,,,,,,,,,,,8.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2017-01-26 23:50:01.0,74649600,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,craig.homa(craig.homa),Sat Oct 06 15:07:29 UTC 2018,,,,,,,,,,,,,,adinoyi.omuya(adinoyi.omuya@10gen.com),asya(asya),backlog-query-optimization(JIRAUSER1257108),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i1izg7:",,,,,,,"0|i00wx3:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i0mny7:","Jan 26 2017 11:50:01 PM UTC;asya;it'll make the pipeline shorter - would this have any measurable performance improvement?
","Apr 28 2017 07:16:56 PM UTC;asya;And answering my own question, after testing for SERVER-29010 coalescing these will make the pipeline run faster.

In addition, coalescing adjacent $addFields stages will also improve performance - this ticket can track both.
","May 16 2017 08:22:06 PM UTC;asya;I believe only all inclusion or all exclusion stages can be coalesced (i.e. we can't coalesce an exclusion project with an $addFields or inclusion $project).
","Sep 20 2017 08:52:37 PM UTC;adinoyi.omuya;I'm not following Asya, I think the example I included in the description should be coalesce-able. Do you agree? If not, why won't it be possible?","Dec 08 2017 05:07:53 PM UTC;adinoyi.omuya;Do you mean that since the expected coalesced $project excludes _id (an exclusion), the server won't be able to coalesce the 3 stages? If so, why? Why would multiple {{$project}}s that contain inclusion/exclusion directives preclude coalescing?","Apr 07 2018 04:56:00 PM UTC;asya;Yes the example given is coalesceable, however, the three project example in the description gives result with \_id field equal to original \_\_joined_bar._id and in the second single stage it's the original field.  I think the single combined stage has to be corrected to:

{noformat}
{""$project"":{_id:""$__joined_bar._id"",""bar_DOT_c"":""$__joined_bar.c"",""foo_DOT_e"":""$e""}}
{noformat}

As far as inclusion and exclusion combining, while this example you gave with all inclusion project is combinable, I was pointing out that mixing $projects with inclusions and $projects with exclusions is not really possible.

The tricky part will be ""when appropriate"" qualification.  :)
","Oct 01 2018 03:30:00 PM UTC;asya;I just did some quick benchmarking and on an ""extreme"" case - only N sequential project or sequential addFields stages, compared with a single same stage, when you have about seven stages, the execution time on the server roughly doubles.  So this is worthwhile an effort.


","Oct 06 2018 03:07:29 PM UTC;asya;Here are detailed numbers, on same collection, same plan, doing $count following single $project with 7 fields removed vs 7 $projects each with single field removed (after several warm-up runs):

Single $project: 57ms to 66ms over four runs.
Seven $projects: 112ms to 119ms over four runs.
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Ability to use Limit() with Distinct(),SERVER-2130,13767,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-query-optimization,sym3tri,sym3tri,Nov 22 2010 03:20:06 AM UTC,Nov 14 2020 06:57:22 PM UTC,Feb 17 2021 11:15:20 AM UTC,,,,,,Backlog,Querying,,,,55,query_triage,,,,,"Ability to use Limit() with Distinct()... or any of the cursor methods for the matter (sort, count, skip, etc. although limit has the biggest impact).

Apparently there is no simple way to currently perform the following SQL query:

SELECT DISTINCT(myField) FROM myTable WHERE x = y LIMIT(20)

The current Distinct() implementation only allows for bringing back ALL distinct values in the collection or matching a query, but there is no way to limit these results. This would be very convenient and there are many use cases.",all,,,,,,,,,,,SERVER-25184,SERVER-27915,SERVER-9507,SERVER-4507,,,,,,,,,,,,,,,,,15.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2011-04-14 15:02:27.0,8899200,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,craig.homa(craig.homa),Thu Nov 05 18:47:08 UTC 2020,,,,,,,,No,,,,,,asya(asya),backlog-query-optimization(JIRAUSER1257108),abaetu(abaetu),sosh(sosh),axom(axom),devin.matte@datadoghq.com(JIRAUSER1257520),dominik(dominik),sym3tri(sym3tri),gerhardb(gerhardb),ian.whalen(ian@10gen.com),ivan.fioravanti@4ward.it(ivan.fioravanti@4ward.it),jhgustafsson(jhgustafsson),micseydel(micseydel),mozillazg(mozillazg),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i070a7:",,,,,,,"0|i00twf:",4733,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i0gljb:","Apr 14 2011 03:02:27 PM UTC;gerhardb;Using distinct with sort would be my biggest hope for 1.9.0 apart from limit.","Oct 03 2011 02:06:48 PM UTC;dominik;Sort() with Distinct() could also be very useful, for example in the following case:

Email messages and attachments (attachments saved in an array inside the email message document).
Getting the distinct list of attachment names ordered by message date would ask for the distinct on 'attachment name', but with a sort on 'message date'.
","Sep 16 2012 08:21:26 AM UTC;jhgustafsson;Is this feature resolved yet? If not, is it planned for any version? (and is the PHP-driver likely to be updated soon after?)","Sep 17 2012 02:30:45 PM UTC;ian.whalen;[~jhgustafsson] this has not been completed yet, and it isn't scheduled for the upcoming 2.4 release.  We will re-evaluate this for upcoming releases as we begin preparing them.","Feb 19 2014 11:10:35 AM UTC;sosh;Very surprised I couldn't do this.  Last comment Sept 2012! Any update?","Nov 11 2014 11:26:25 PM UTC;ivan.fioravanti@4ward.it;Any news on this feature request? It is quite useful in some scenario.","Dec 09 2014 06:17:19 AM UTC;mozillazg;Is there any news about this feature request?","Dec 09 2014 05:19:02 PM UTC;asya;This can be done using aggregation framework as

*edited*
{noformat}
db.collection.aggregate([{$match:{<your-filter>}}, {$group:{_id:""$myField""}}},
/* optionally */ {$sort:{_id:1}} /* or by another field that was preserved in $group stage */
{$limit:20}])
{noformat}
","Feb 22 2016 07:58:16 PM UTC;axom;Asya's suggestion may have worked in a past iteration of mongo, but at least currently you will need to adjust the group stage to get the limit to do anything.

{noformat}{$group: {_id: ""$myField""}}{noformat}","Feb 22 2016 09:03:46 PM UTC;asya;[~axom] you absolutely correct, I will fix or remove mine. ","Jul 17 2017 07:36:12 AM UTC;abaetu;If you have 7 mil documents and you perform the collection.aggregate([{$group : {_id : ""$field""}},{$limit:1}]) you will wait ~20 seconds. This is not ok. If i need a set of ""field""  values having the cardinal 1, i shouldn't wait that long.","Jun 12 2018 11:25:31 PM UTC;micseydel;Is this still a possible feature? Given how long it's been open, and a ""workaround"" being provided, I would imagine this should be closed a Won't Complete.","Jun 13 2018 08:44:10 PM UTC;asya;[~micseydel] we still have plans to provide simpler syntax (and more performant execution) for what is requested here.

The two linked SERVER tickets describe the work that we hope to schedule in the future.
","Jul 04 2019 02:50:50 PM UTC;asya;4.2 has the fix SERVER-9507 - while it is not a direct solution to this problem, it will use an  efficient DISTINCT_SCAN of the index while doing $group: on an indexed field.

The real solution for $limit after $group being optimized will be SERVER-4507.

 

 ","Nov 05 2020 06:47:08 PM UTC;devin.matte@datadoghq.com;Is there any progress on this feature? Aggregate is an okay workaround however it's not ideal, hoping to be able to apply limit with distinct",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Add support for $geoIntersects with geo operator $centerSphere,SERVER-30390,409507,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-query-optimization,wan.bachtiar,wan.bachtiar,Jul 28 2017 07:56:57 AM UTC,Nov 14 2020 06:57:15 PM UTC,Feb 17 2021 11:15:20 AM UTC,,,,,,Backlog,Geo,Querying,,,2,query-44-grooming,,,,,"There is no code implementation for {{$geoIntersects}} / {{$centerSphere}}.
Although there is also no documentation for usage of {{$geoIntersects}} with {{$centerSphere}} shape operator 

The manual on https://docs.mongodb.com/manual/reference/operator/query/geoIntersects/ mentions:
{code}
The $geoIntersects operator uses the $geometry operator to specify the GeoJSON object.
{code}

Although if you specify {{$centerSphere}} instead of {{$geometry}} for {{$geoIntersects}}, it does not throw {{unknown geo specifier}} error. 

This ticket could be either to add a catch to throw an error to indicate 'not supported' or to add functionality behind the scene for it. ",,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Jul 28 2017 07:56:47 AM UTC;wan.bachtiar;geointersect_sphere.js;https://jira.mongodb.org/secure/attachment/161920/geointersect_sphere.js",,,3.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2017-08-03 14:48:55.0,111369600,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,craig.homa(craig.homa),Tue Aug 08 06:34:29 UTC 2017,,,,,,,,,,,,,,backlog-query-optimization(JIRAUSER1257108),ian.whalen(ian@10gen.com),tess.avitabile(tess.avitabile),thomasr(thomasr),wan.bachtiar(wan.bachtiar),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i1tpqn:",,,,,,,"0|i00x7b:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i1tnuf:","Aug 03 2017 02:48:55 PM UTC;ian.whalen;[~tess.avitabile] can you take a look and decide what we should do here?","Aug 07 2017 08:54:28 PM UTC;tess.avitabile;[~thomasr], is this an issue for Compass (i.e. does Compass use $geoIntersects)?","Aug 08 2017 06:34:29 AM UTC;thomasr;[~tess.avitabile] Not yet, but we would like to add more geo features, including $geoIntersects, in the future.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Support for explaining query solution in the presence of hypothetical indexes,SERVER-15600,163049,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-query-optimization,acm,acm,Oct 10 2014 05:53:29 PM UTC,Nov 14 2020 06:57:03 PM UTC,Feb 17 2021 11:15:20 AM UTC,,,,,,Backlog,Querying,,,,0,,,,,,"It would be useful to be able to ask the query planner to explain a query solution given some additional hypothetical index specification(s). This would allow a user to experiment with how a query would be planned with other indexes without needing to create those indexes.

Something like, in the shell::

find(...).explain().hypothesizing([indexSpec0, indexSpec1, ..., indexSpecn])
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2014-10-10 17:57:02.0,200534400,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,craig.homa(craig.homa),Fri Oct 10 18:23:17 UTC 2014,,,,,,,,,,,,,,acm(acm),pavlo(pavlo),backlog-query-optimization(JIRAUSER1257108),scotthernandez(scotthernandez),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i03b7r:",,,,,,,"0|i00vjr:",142139,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i0yq87:","Oct 10 2014 05:57:02 PM UTC;scotthernandez;You would also need to be able to specify if the potential index would be multi-key or not; Once/if we have stats that too would affect index ranking/selection.","Oct 10 2014 06:23:17 PM UTC;pavlo;Per my discussion with Andrew yesterday, this would be similar to the ""what-if"" API used in RDBMSs:

http://dl.acm.org/citation.cfm?doid=276305.276337",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Allow multi-collection and multiple connect  in $graphLookup,SERVER-37539,616416,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-query-optimization,whrrmydragons,whrrmydragons,Oct 10 2018 06:35:52 AM UTC,Nov 14 2020 06:56:54 PM UTC,Feb 17 2021 11:15:20 AM UTC,,,,,,Backlog,Aggregation Framework,,,,1,,,,,,"allow the following to receive a single value or an array
 *     from
 *     startWith
 *     connectFromField
 *     connectToField

 

 ",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2019-02-12 19:32:23.0,63504000,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,craig.homa(craig.homa),Tue Feb 12 19:32:23 UTC 2019,,,,,,,,,,,,,,backlog-query-optimization(JIRAUSER1257108),cristian.vertiz@mojix.com(cristian.vertiz@mojix.com),whrrmydragons(whrrmydragons),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i2snqn:",,,,,,,"0|i00yhj:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i2sluf:","Feb 12 2019 07:32:23 PM UTC;cristian.vertiz@mojix.com;A good idea would be to have a source collection and connection collection for n:m relationship graph starting from a pivot document",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
$expr does not use partial index,SERVER-38799,662888,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-query-optimization,bastosbf,bastosbf,Dec 29 2018 06:32:00 AM UTC,Nov 14 2020 06:56:45 PM UTC,Feb 17 2021 11:15:20 AM UTC,,,,,,Backlog,Querying,,,,0,query-44-grooming,,,,,"In the following example:

 ",,,,,,,,,,,,PM-283,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2019-01-03 16:31:13.0,53913600,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,craig.homa(craig.homa),Mon Jun 03 14:02:53 UTC 2019,,,,,,,,,,,,,,asya(asya),backlog-query-optimization(JIRAUSER1257108),bastosbf(bastosbf),daniel.hatcher(daniel.hatcher),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i30lb3:",,,,,,,"0|i00yl3:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i30jev:","Jan 03 2019 04:31:13 PM UTC;daniel.hatcher;Hello Bruno,

Thank you for your report. I have assigned this to our Query team to take a look.

Danny","Jun 03 2019 02:02:53 PM UTC;asya;Confirmed (with 4.1.13) that this has to do with $expr syntax specifically as using the matcher syntax I see:
{noformat}
db.getCollection('contacts').find({name:""A""}).explain()
{
	""queryPlanner"" : {
		""plannerVersion"" : 1,
		""namespace"" : ""test.contacts"",
		""indexFilterSet"" : false,
		""parsedQuery"" : {
			""name"" : {
				""$eq"" : ""A""
			}
		},
		""queryHash"" : ""01AEE5EC"",
		""planCacheKey"" : ""4C5AEA2C"",
		""winningPlan"" : {
			""stage"" : ""FETCH"",
			""inputStage"" : {
				""stage"" : ""IXSCAN"",
				""keyPattern"" : {
					""name"" : 1,
					""email"" : 1
				},
				""indexName"" : ""name_1_email_1"",
				""isMultiKey"" : false,
				""multiKeyPaths"" : {
					""name"" : [ ],
					""email"" : [ ]
				},
				""isUnique"" : false,
				""isSparse"" : false,
				""isPartial"" : true,
				""indexVersion"" : 2,
				""direction"" : ""forward"",
				""indexBounds"" : {
					""name"" : [
						""[\""A\"", \""A\""]""
					],
					""email"" : [
						""[MinKey, MaxKey]""
					]
				}
			}
		},
		""rejectedPlans"" : [ ]
	},
	""serverInfo"" : {
		""host"" : ""asyas-macbook-pro-3.local"",
		""port"" : 41130,
		""version"" : ""4.1.13"",
		""gitVersion"" : ""441714bc4c70699950f3ac51a5cac41dcd413eaa""
	},
	""ok"" : 1
}
{noformat}
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Prefix Indexes,SERVER-3260,18266,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-query-optimization,bdarfler,bdarfler,Jun 14 2011 03:20:30 PM UTC,Nov 14 2020 06:56:24 PM UTC,Feb 17 2021 11:15:20 AM UTC,,,,,,Backlog,Indexing,,,,18,,,,,,"It would be great if we could specify indexes that only index on the prefix of a field. i.e. for BinData on the first n bytes, for strings on the first n characters, etc. This might not work on all data types but it is a great tool for trimming index sizes when applicable.",,,,,,,,,,,,SERVER-14784,SERVER-15090,,,,,,,,,,,,,,,,,,,5.0,,,,,,,,,,,,,,,,,,,,,5002K00000llAL0QAM,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2014-03-10 19:21:13.0,118972800,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,craig.homa(craig.homa),Thu May 11 16:01:38 UTC 2017,,,,,,,,No,,,,,,backlog-query-optimization(JIRAUSER1257108),bdarfler(bdarfler),sallgeud(sallgeud),charity@parse.com(charity@parse.com),Budulianin(budulianin),mdcallag(mdcallag),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i06n2f:",,,,,,,"0|i00ty7:",6121,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i0j8pr:","Mar 10 2014 07:21:13 PM UTC;charity@parse.com;Any plans to implement this soon?  It would really help ease the transition to a world where keys too large to index don't get inserted.","Mar 13 2014 05:12:03 PM UTC;mdcallag;This will help with long index keys. Pre-2.6 behavior is to let insert/update succeed and skip index maintenance when the index key is too long. This is bad for index scans that will miss the unindexed doc. 2.6 changed the server to raise an error and make the insert/update fail. This makes the index correct but will be a problem for some existing apps.

Prefix keys are the solution.","Aug 20 2014 05:24:30 PM UTC;sallgeud;See our related one. Since 2.6 this has become far more important. I think under nearly all circumstances we would limit every text field we index to something fairly small.","Aug 20 2014 05:25:44 PM UTC;sallgeud;This would allow for several benefits:
* more configurable and useful indexes
* less memory and/or disk space requirements for indexes
* higher performance indexing
* higher performance sorting
* potentially reduce indexing time on document save","May 11 2017 04:01:38 PM UTC;Budulianin;Hey guys, when will you implement this feature?
This ticket was created 3 years ago!
How can I do prefix search now? Use regex?",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Add full query support for $meta values geoNearDistance/geoNearPoint,SERVER-17929,194769,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-query-optimization,rassi,rassi,Apr 08 2015 02:10:39 PM UTC,Nov 14 2020 06:56:12 PM UTC,Feb 17 2021 11:15:20 AM UTC,,,,,,Backlog,Geo,Querying,,,0,,,,,,"The $meta values ""geoNearDistance""/""geoNearPoint"" should be given full query support.

Exposing ""geoNearDistance"" to users will allow them to get off of the $near/$nearSphere query operators, which suffer from no real query planner support and poor semantics.

For example:
- Preferred: find(\{geo: \{$geoWithin: ...}}, \{dist: \{$meta: ""geoNearDistance""}}).sort({dist: \{$meta: ""geoNearDistance""}})
- Not preferred: find(\{geo: \{$nearSphere: ...}})",,,,,,,,,,,,SERVER-12335,SERVER-18056,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2015-04-15 17:59:39.0,184377600,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,craig.homa(craig.homa),Wed Apr 15 17:59:39 UTC 2015,,,,,,,,,,,,,,backlog-query-optimization(JIRAUSER1257108),rassi(rassi@10gen.com),siyuan.zhou(siyuan.zhou@10gen.com),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i02y3z:",,,,,,,"0|i00vrj:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i0ya33:","Apr 15 2015 05:59:39 PM UTC;siyuan.zhou;If $near is considered as projection and sorting explicitly, we don't have to enforce the use of geo index if another normal index can be more efficient, see SERVER-18056.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Index on key anywhere in the document,SERVER-6191,42224,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-query-optimization,leanberw,leanberw,Jun 24 2012 11:17:20 AM UTC,Nov 14 2020 06:55:48 PM UTC,Feb 17 2021 11:15:20 AM UTC,,,,,,Backlog,Indexing,,,,0,index,,,,,"It would be great to have an index feature, so that when I am looking for an ""address"" it not only looks for it in the main field of the document, but also in the fields of the subdocuments. So it is an index on ""address"" AND ""*.address"". This way I can search for ""phoneNumber"" (e.g. using ""*phoneNumber"" as the search field name) and MongoDB has an index with all occurrences including ""phoneNumber"", ""leader.phoneNUmber"", ""guests[].phoneNumber"".",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2012-06-24 18:47:22.0,272937600,,,,,,,,,,,,,,,,,,,,,,,,,,,,false,craig.homa(craig.homa),Sun Jun 24 18:47:22 UTC 2012,,,,,,,,No,,,,,,schwerin(schwerin),backlog-query-optimization(JIRAUSER1257108),leanberw(leanberw),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i05o07:",,,,,,,"0|i00yrb:",5926,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i1i28v:","Jun 24 2012 06:47:22 PM UTC;schwerin;Interesting idea.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Ability to specify the batch size in data size,SERVER-41017,758619,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-query-optimization,linda.qin,linda.qin,May 06 2019 06:33:37 AM UTC,Nov 14 2020 06:55:08 PM UTC,Feb 17 2021 11:15:20 AM UTC,,,,,,Backlog,,,,,0,,,,,,"When we run a query on a sharded cluster, if batch size is not specified, the shards will return the results with the default batch size (16MB). For a sharded cluster with a large number of shards (e.g. 80 shards), this could cause high memory usage on the mongos (16MB * 80 = 1.28G).

Currently we can specify the batch size in term of the number of documents. If the average document size is already known, we can specify the batch size to reduce the memory usage in this case. However, in some cases, specifying the batch size by the number of documents might not be very optimal:
- The document size varies for the collection.
- Projection is being used in the query, so it's hard to predicate how much data will be returned without first querying the document.

It would be nice to allow specifying the batch size in term of the data size. Also it would be nice if the size based batch limit (the default 16MB) could be customized with a `setParameter`.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,5002K00000dWGijQAG,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2019-12-30 17:18:06.0,56419200,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,craig.homa(craig.homa),2019-05-06 06:33:37.0,,,,,,,,,,,,,,backlog-query-optimization(JIRAUSER1257108),linda.qin(linda.qin@10gen.com),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i3gwxj:",,,,,,,"0|i00ypz:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i3gv1b:",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Query to return every Nth value from the collection,SERVER-2397,14279,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-query-optimization,jmthomas,jmthomas,Jan 21 2011 11:07:04 PM UTC,Nov 14 2020 06:54:45 PM UTC,Feb 17 2021 11:15:20 AM UTC,,,,,,Backlog,Querying,,,,4,,,,,,"Various relational databases have all implemented their own methods to return every nth value from the database. It doesn't seem like MongoDB has the capability at all. 

My use case it storing a year's worth of data with second granularity. I want to graph an overview of the year and allow a drill down to smaller time granulations. Thus my year query would request every 10000th value (for example) while an hours worth would return every value. Both of these queries would return roughly the same amount of data so be worked with in the application.

I realize you'd incur a lot of file seek times if you had to grab data spanning multiple files but I still need the capability.",,,,,,,,,,,,FREE-3211,,,,,,,,,,,,,,,,,,,,3.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2011-01-23 08:15:42.0,295574400,,,,,,,,,,,,,,,,,,,,,,,,,,,,false,craig.homa(craig.homa),Thu Oct 06 19:15:03 UTC 2011,,,,,,,,No,,,,,,backlog-query-optimization(JIRAUSER1257108),eliot(eliot),jmthomas(jmthomas),redbeard0531(redbeard0531),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i06xb3:",,,,,,,"0|i00twv:",6181,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i0q6nz:","Jan 23 2011 08:15:42 AM UTC;eliot;How would you do this in sql?","Jan 24 2011 07:11:14 PM UTC;jmthomas;It varies by DB  because SQL doesn't define a good way to do this.

In Oracle:
     select <item> from <table> group by <item>, rownum having mod(rownum, 100)=0

In MySQL:
      SET @row=0;select <item>,@row:=@row+1 as num FROM <table> HAVING (num+1)%100=0

In Sqlite:
     select <item> from <table> group by <item> having rowid % 100=0

","Oct 06 2011 07:15:03 PM UTC;redbeard0531;Some discussion of workarounds at http://groups.google.com/group/mongodb-user/browse_thread/thread/3d730dd50bffea1c",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Pagination w/ Server Side Range Queries,SERVER-20305,228585,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-query-optimization,christopher.price@mtvn.com,christopher.price@mtvn.com,Sep 06 2015 03:05:45 PM UTC,Nov 14 2020 06:54:33 PM UTC,Feb 17 2021 11:15:20 AM UTC,,,,,,Backlog,Querying,,,,1,,,,,,"The .min() and .max() features are nice but require specifying min or max values for all fields in the index.  This makes it difficult to mix and match sort orders.  Additionally, it would be beneficial to be able to specify some fields from the index in the search criteria (using $all or $in) and the remainder of the criteria in the .min() or .max() or in a new potential method such as.getNextPage().

If such a feature as getNextPage() (or a better name) were available, the customer would pass in just enough sorting information such that combined with the standard search criteria, the system could pick up where the previous query left off.  More specifically, the customer would pass in the partial sort values from the last document of the previous result set.  The system in return would transform these values into additional search criteria.  

Documentation and examples attached.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Sep 06 2015 03:05:45 PM UTC;christopher.price@mtvn.com;MongoDB Pagination with Range Queries.docx;https://jira.mongodb.org/secure/attachment/88935/MongoDB+Pagination+with+Range+Queries.docx",,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2015-09-08 12:09:39.0,171763200,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,craig.homa(craig.homa),Tue Sep 08 12:20:52 UTC 2015,,,,,,,,,,,,,,backlog-query-optimization(JIRAUSER1257108),christopher.price@mtvn.com(christopher.price@mtvn.com),ramon.fernandez(ramon.fernandez),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i02kjj:",,,,,,,"0|i00vyn:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i0xtzr:","Sep 08 2015 12:09:39 PM UTC;ramon.fernandez;Thanks for your detailed report [~christopher.price@mtvn.com]. We've set the fixVersion to ""Needs Triage"" for this new feature to be considered in the next round of planning. Updates will be posted on this ticket as they happen.

Regards,
Ramón.","Sep 08 2015 12:20:52 PM UTC;christopher.price@mtvn.com;I neglected to mention that my preferred signature of a getNextPage method would be all of the sort values of the last document from the previous page.  Even placing the effort on the customer to ensure that the combination of sort/filter values are sufficiently unique for their application is acceptable.  ",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Add $fmod, or some way to mod by fractional numbers, to the match expression language",SERVER-32961,488820,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-query-optimization,charlie.swanson,charlie.swanson,Jan 29 2018 05:36:13 PM UTC,Nov 14 2020 06:53:54 PM UTC,Feb 17 2021 11:15:20 AM UTC,,,,,,Backlog,Aggregation Framework,Querying,,,0,expression,mql-semantics,,,,The {{$mod}} query operator converts fractional numbers to integers to do the modular arithmetic. It still makes sense to mod by a fractional number in some scenarios. ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,4.0,,,,,,,,,,,,,,,,,Fully Compatible,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2018-01-29 18:56:05.0,96163200,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,craig.homa(craig.homa),Tue Jan 30 15:37:08 UTC 2018,,,,,,,,,,,,,,backlog-query-optimization(JIRAUSER1257108),charlie.swanson(charlie.swanson),david.storch(david.storch),geert.bosch(geert.bosch),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i271iv:",,,,,,,"0|i00tdr:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i26zmn:","Jan 29 2018 05:36:56 PM UTC;charlie.swanson;[~geert.bosch] can you elaborate on the use case you were describing earlier? Not sure I followed enough to summarize myself :)","Jan 29 2018 06:56:05 PM UTC;david.storch;As part of JSON Schema, we implemented internal support for fmod in the match expression language: {{$_internalSchemaFmod}}:

https://github.com/mongodb/mongo/blob/2487ab101a42434e1f61e68ee7c2383432861f8b/src/mongo/db/matcher/schema/expression_internal_schema_fmod.h

Assuming this implements the behavior we want in general, we could change this to be exposed to clients.","Jan 30 2018 02:59:48 PM UTC;geert.bosch;Actually, it seems {{$mod}} aggregation operator does support fractional numbers:
{noformat}
> db.money.insert({amount: NumberDecimal(""12.30"")})
WriteResult({ ""nInserted"" : 1 })
> db.money.aggregate([{$addFields: { quarters: {$trunc: {$divide:[""$amount"", NumberDecimal(""0.25"")]}}, cents:{$mod: [""$amount"",NumberDecimal(""0.25"")]}}}])
{ ""_id"" : ObjectId(""5a7086df3130aa7be79b246f""), ""amount"" : NumberDecimal(""12.30""), ""quarters"" : NumberDecimal(""49""), ""cents"" : NumberDecimal(""0.05"") }
{noformat}
The {{ExpressionMod}} code looks correct as well. ","Jan 30 2018 03:37:08 PM UTC;david.storch;[~geert.bosch], if I understand correctly, this ticket is specifically about the match expression language, not the agg expression language. I've updated the title of the ticket to clarify.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Extend listIndexes to support listing all indexes for a database,SERVER-29067,380563,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-query-optimization,dustyburwell,dustyburwell,May 04 2017 02:53:13 PM UTC,Nov 14 2020 06:53:36 PM UTC,Feb 17 2021 11:15:20 AM UTC,,,,,,Backlog,Querying,,,,0,,,,,,"The original proposal below was to support this with new syntax \{listIndexes: ""*""\}. Another option is to add {{$listIndexes}} support to the agg framework and allow such pipelines to be specified over an entire database by omitting the collection name:

{code}
myDB.runCommand({aggregate: 1, cursor: {}, pipeline: [{$listIndexes: {}}, ...]});
{code}

h5. Original description

We've found that we needed the ability to get all indexes for a db, similar to how we used to be able to query ""system.indexes"". We've patched mongod to enable this with the command `\{'listIndexes': '*'\}`.

Would anyone be interested in us submitting this to upstream?",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2017-05-08 16:55:34.0,48816000,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,craig.homa(craig.homa),Fri Aug 02 00:36:54 UTC 2019,,,,,,,,,,,,,,backlog-query-optimization(JIRAUSER1257108),bartle(bartle),david.storch(david.storch),dustyburwell(dustyburwell),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i1or4n:",,,,,,,"0|i00x13:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i01hvb:","May 08 2017 04:55:34 PM UTC;david.storch;Hi [~dustyburwell],

Thanks for filing this feature request and for your willingness to upstream code changes that you've found useful. This is something which we would like the MongoDB server to support in the future. However, we have tentative plans to move listIndexes support into the aggregation framework, by introducing a new {{$listIndexes}} aggregation data source. This would be akin to existing metadata agg sources such as [$indexStats|https://docs.mongodb.com/manual/reference/operator/aggregation/indexStats/] and [$collStats|https://docs.mongodb.com/manual/reference/operator/aggregation/collStats/].

In addition, we are tentatively considering changes that will allow some special aggregation data sources to omit the collection, in order to indicate that the agg source should apply to the database as a whole. In the event that both the {{$listIndexes}} agg source and aggregations over a whole database rather than just a single collection are implemented for versions 3.6 or 3.8, we would prefer to support ""list all indexes for a database"" via the aggregation framework. This would be instead of implementing the proposed \{listIndexes: ""*""\} syntax.

Since the patch would conflict with our future plans, I do not think we would accept this code upstream at the moment. Plans and priorities are always subject to change though, in which case we will re-evaluate this decision! For the time being, I am going to convert this ticket into a feature request which does not specify the exact \{listIndexes: ""*""\} user-facing syntax. Let me know if you have any questions or concerns.

Best,
Dave","Aug 02 2019 12:36:54 AM UTC;bartle;Hello, was just curious if there's been any progress on this, or if there was interest in us sending a patch upstream for the original {{listIndexes: ""*""}} proposal?",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Support for $elemMatch inside $in,SERVER-14203,140976,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-query-optimization,mdelamere,mdelamere,Jun 07 2014 08:25:13 PM UTC,Nov 14 2020 06:53:24 PM UTC,Feb 17 2021 11:15:20 AM UTC,,,,,,Backlog,Querying,,,,7,,,,,,"We allow $elemMatch clauses inside an $all as shown below, but we reject this for $in. We should allow an $in-$elemMatch query which says ""the document must match one of these $elemMatch clauses"".

h5. Original Description

Hello,

In mongodb I can query with either $and or $or which is important for deciding whether all elements need to match or just one.

Looking at the following example provided in the mongob-docs:

{noformat}
db.inventory.find( {
                     qty: { $all: [
                                    { ""$elemMatch"" : { size: ""M"", num: { $gt: 50} } },
                                    { ""$elemMatch"" : { num : 100, color: ""green"" } }
                                  ] }
                   } )
{noformat}

you can see that one can specify - in combination with $elemMatch - that all ($all) the subqueries must match.

What I would like to do is to say that only one of these has to match, which is important for doing certain types of search-queries. I noticed though, that although for $and there is the alternative $or, this does not seem to exist for $all. I would therefore like to request something like a $any keyword which behaves like $or, but can be used like $all.

I think this is quite an important issue and shouldn't be to hard to implement - or is it?

Thanks for the great work.

Best regards,
Michael",,,,,,,,,,,,SERVER-589,,,,,,,,,,,,,,,,,,,,5.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2014-06-08 23:40:01.0,211161600,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,craig.homa(craig.homa),Mon Jun 09 23:22:57 UTC 2014,,,,,,,,,,,,,,backlog-query-optimization(JIRAUSER1257108),david.storch(david.storch),mdelamere(mdelamere),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i03irb:",,,,,,,"0|i00vf3:",121588,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i0z0dj:","Jun 09 2014 02:05:01 PM UTC;david.storch;Hi [~mdelamere],

Thanks for the feature request! There is something quite similar to the hypothetical ""$any"" operator you describe. It's called $in and is documented here: [http://docs.mongodb.org/manual/reference/operator/query/in/]. Here is an example $in query:
{code}
db.inventory.find({qty: {$in: [4, 5, 6]}});
{code}

However, you are correct that currently it is illegal to nest $elemMatch queries inside an $in (even though you can nest $elemMatch inside an $all). I'm going to change the title and description of this ticket to be about supporting $elemMatch within an $in query. This would allow you to write a query like this:
{code}
db.inventory.find( {
                      qty: { $in: [
                                     { ""$elemMatch"" : { size: ""M"", num: { $gt: 50} } },
                                     { ""$elemMatch"" : { num : 100, color: ""green"" } }
                                   ] }
                    } 
)
{code}

The $in operator is syntactic sugar for $or, so you can get the same logical result as the currently unsupported $in-$elemMatch query using an $or:
{code}
db.inventory.find( {
                      $or: [
                                {qty: { ""$elemMatch"" : { size: ""M"", num: { $gt: 50} } } },
                                {qty: { ""$elemMatch"" : { num : 100, color: ""green"" } } }
                      ]
})
{code}

I'm going to reformat this ticket to be about supporting $elemMatch under $in and mark it for triage.

Thanks,
Dave","Jun 09 2014 06:39:11 PM UTC;mdelamere;Hi,

Thanks very much for your response and for editing the ticket accordingly. The idea with the $in sounds excellent and would fit my needs perfectly. I actually tried replacing the $all with $or, but unfortunately that yielded an error. In my concrete case, this works:

{code}
db.products.find({ 
  ""attributes"" : { 
    ""$all"" : [ 
      { ""$elemMatch"" : { ""attr_id"" : 123 , ""val"" : { ""$elemMatch"" : { ""val"" : { ""$regex"" : ""^my_name.*""}}}}}, 
      { ""$elemMatch"" : { ""attr_id"" : 456 , ""val"" : { ""$elemMatch"" : { ""val"" : { ""$regex"" : ""^my_article_number.*""}}}}}
    ]
  }
})
{code}

But when I replaced the $all with $or I got:

{code}
error: {
	""$err"" : ""Can't canonicalize query: BadValue unknown operator: $or"",
	""code"" : 17287
}
{code}

Thanks again and best regards,
Michael
","Jun 09 2014 06:50:15 PM UTC;david.storch;Hi Michael,

You can write an $or query with $elemMatch clauses using the following syntax:
{code}
db.products.find({
    $or: [
        {attributes: {$elemMatch: {attr_id: 123, val: {$elemMatch: {val: {$regex: ""^my_name.*""}}}}}},
        {attributes: {$elemMatch: {attr_id: 456, val: {$elemMatch: {val: {$regex: ""^my_article_number.*""}}}}}}
    ]
});
{code}

Our reference pages for $or are here: [http://docs.mongodb.org/manual/reference/operator/query/or/].

Best,
Dave","Jun 09 2014 09:45:12 PM UTC;mdelamere;Hi Dave,

Yes that would work (if we replace ""products:"" with ""attributes:""). I would still like to see the $in coming because:

a) it is less verbose and I prefer the $in syntax,
b) I miss it because I expected $all to have a similar alternative as $and/$or do,
c) it makes it easier to switch queries from $all to $in without writing completely new queries (although to be fair - your query could also be written with $and)

Obviously there was a reason for creating $all, even although that could have been written as a $and query. I think therefore the same reasons could apply for a $in supporting $elemMatch. As the $or does the trick though, I can see that this will not be on the top of your list.

Thanks agan for you time!

Best regards,
Michael ","Jun 09 2014 11:22:57 PM UTC;david.storch;[~mdelamere], agreed that we should have parity between $in and $all just as we do between $or and $and. This makes lots of sense. We will take this into account as we plan for future development cycles.

{quote}
Yes that would work (if we replace ""products:"" with ""attributes:"").
{quote}
Whoops, good catch! I fixed this in my comment above.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
I would like a way to specify automatic creation of indexes on new collections,SERVER-3573,20839,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-query-optimization,fields,fields,Aug 10 2011 08:29:24 PM UTC,Nov 14 2020 06:52:57 PM UTC,Feb 17 2021 11:15:20 AM UTC,,,,,,features we're not sure of,Indexing,,,,0,,,,,,"New feature request: we often make collections dynamically based on some naming convention, and I'd like a way to specify that any new collections whose name matches a regexp condition should automatically get a particular set of indexes when created.

I'd envision this as being specified by a hash where the key is the regexp and the value is an array of normal index hash specifications to add.

Something like: 

db.autoIndexCollections( { ""/page_logs_%d{6}/"": [ {""date"":-1}, {""source"":1} ] } );

would create two indexes on date descending and source ascending for a newly created page_logs_201108 collection.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,300499200,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,craig.homa(craig.homa),Wed Aug 10 21:17:09 UTC 2011,,,,,,,,No,,,,,,fields(fields),backlog-query-optimization(JIRAUSER1257108),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i06jbz:",,,,,,,"0|i0103r:",6568,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i1i2i7:","Aug 10 2011 09:17:09 PM UTC;fields;Naturally, there would also need to be a way to list existing auto index specifications.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
find_try_modify and $collide operator to streamline two-phase commit,SERVER-5951,39788,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-query-optimization,khabok,khabok,May 29 2012 06:46:21 AM UTC,Nov 14 2020 06:52:51 PM UTC,Feb 17 2021 11:15:20 AM UTC,,,,,,Backlog,Querying,Write Ops,,,0,core,transactions,,,,"Let's say you're attacking an update with a two-phase commit, colliding on a timestamp field. The second phase uses find_and_modify to ensure the timestamp is the same before applying the update. So far so good. However, should the timestamp be unequal, find_and_modify will simply fail to find, returning no document. In order to take another crack at the update, it's probably necessary to query the record all over again to find out what changed, which is kind of a waste since mongo has (probably) already found the record once before disqualifying it.

An alternate proposal is find_try_modify, basically the opposite of find_and_modify. It returns a document only if the update fails, which should definitely be expressed as an exception by the drivers. For a nice example (in say, python) let's try to $set `resultField` based on data from `documentState` but only if `timestamp` hasn't changed. If it has, we want to look at `documentState` again. The server can assume we want `timestamp` too, since we set it as a collision field. Perhaps setting it as false in the return fields should be permitted, as it is with _id.
{noformat}try:
 db.Records.find_try_modify(
      {_id:578923, $collide:{timestamp:123456789}}}, 
      {$set:{documentState:stateObject}},
      {documentState:true}
)
 except Collision as newState:
      stateObject = buildUpdate (newState['documentState'])
      try: # just one more attempt
      db.Records.find_try_modify(
          {_id:578923, $collide:{timestamp:newState['timestamp']}}, 
          {$set:{documentState:stateObject}},
          {documentState:true}
       )
       except Collision:
           sendFailureResponse()
 sendSuccessResponse()
 {noformat}",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,4.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2013-01-17 17:06:51.0,51667200,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,craig.homa(craig.homa),Sun Jun 30 10:18:22 UTC 2019,,,,,,,,No,,,,,,asya(asya),backlog-query-optimization(JIRAUSER1257108),eliot(eliot),khabok(khabok),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i05quv:",,,,,,,"0|i00yv3:",6313,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i1ivr3:","May 29 2012 06:50:59 AM UTC;khabok;Um.  Lemme try that again...

{code:title=Example|borderStyle=solid}
try:
     db.Records.find_try_modify({_id:578923, $collide:{timestamp:123456789}}}, {$set:{documentState:stateObject}}, {documentState:true})
except Collision as newState:
     stateObject = buildUpdate (newState['documentState'])
     try: # just one more attempt
          db.Records.find_try_modify({_id:578923, $collide:{timestamp:newState['timestamp']}}, {$set:{documentState:stateObject}}, {documentState:true})
     except Collision:
          sendFailureResponse()
          return
sendSuccessResponse()
{code} ","Jan 17 2013 05:06:51 PM UTC;eliot;Agree we should make this easier, not sure what the optimal syntax is","Jun 30 2019 10:17:11 AM UTC;asya;My thinking was that we should close this ticket given there are transactions available already.

Proposed flow (without using timestamp as the transaction machinery will let you know if there is a write conflict):

Start session
Start transaction
Get document
Make changes
Save document+Commit transaction

If you get a write conflict at the last step, you have to get the document again.  

On the other hand, the read-modify-save pattern should not be necessary in 4.2 given that updates can now be expressions as aggregation pipeline with full access to all the fields of the document during the update.

So the given example:
> let's try to $set `resultField` based on data from `documentState` but only if `timestamp` hasn't changed.

can be done without two-phase-commit approach simply with:
{noformat}
// update could be find and modify
db.coll.update( {_id: 578923}, 
                           [ { $set: { resultField: ""$documentState""} } ] 
)
{noformat}

""$documentState"" can be any agg expression which references any field of the document, here I'm just setting resultField to whatever is in documentState but instead it could be used as a conditional/branch.  See examples here: https://docs.mongodb.com/master/reference/command/update/index.html#update-command-example-agg

","Jun 30 2019 10:18:22 AM UTC;asya;Setting for triage to see if there is still a use case for adding this or if the ticket should be closed.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Provide a way for the Aggregation framework to query against intervals of a hashed index,SERVER-28667,371891,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-query-optimization,sylvain.chambon,sylvain.chambon,Apr 07 2017 11:21:35 AM UTC,Nov 14 2020 06:52:38 PM UTC,Feb 17 2021 11:15:20 AM UTC,,3.4.3,,,,Backlog,Aggregation Framework,,,,6,,,,,,"The Spark connector uses the Aggregation Framework to create data partitions that are sent to Spark workers. In a sharded cluster it makes sense to align these partitions to chunk boundaries so that each worker's data loading query is targeted to a single shard.

This however is impossible when the shard key is a hashed index. A simple find can use $min / $max but there is no comparable facility in the aggregation framework.",,,,,,,,,,,,SERVER-24274,,,,,,,,,,,,,,,,,,,,3.0,,,,,,,,,,,,,,,,,,,,,500A000000Wk7J5IAJ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2017-04-07 14:10:54.0,121651200,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,craig.homa(craig.homa),Tue Apr 11 01:13:51 UTC 2017,,,,,,,,,,,,,,andrew.ryder(andrew.ryder@10gen.com),backlog-query-optimization(JIRAUSER1257108),kelsey.schubert(thomas.schubert),sylvain.chambon(sylvain.chambon),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i1n9mv:",,,,,,,"0|i00wzr:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i01dc7:","Apr 07 2017 02:10:54 PM UTC;kelsey.schubert;Hi [~sylvain.chambon], 

I've linked to SERVER-24274, which might provide the functionality that your looking for. Can you take a look and let me know? Specifically, please see [Charlie's comment about a possible workaround|https://jira.mongodb.org/browse/SERVER-24274?focusedCommentId=1293770&page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-1293770].

Thank you,
Thomas","Apr 07 2017 02:51:19 PM UTC;sylvain.chambon;Hi [~anonymous.user], Charlie's $bucketAuto is a good idea for creating partitions in general. Unfortunately it doesn't help with the specific goal of having partitions targeted to a single shard while using a hashed shard key. Using $bucketAuto, each partition would be spread across all shards.","Apr 11 2017 01:13:51 AM UTC;andrew.ryder;I think SERVER-24274 is a different (though related) use case. Here is my summary:

SERVER-24274: Ability to query against a non-sharded collection in a way that makes it behave a lot like it's sharded. $bucketAuto should be a suitable candidate to fulfil these use cases (the cases specifically are not load related, they are about data distribution).

SERVER-28667 (this ticket): Ability to constrain query results to being sourced from a particular shard. This permits the ability to manage workloads at the shards caused by distributed processing systems like Spark -- these systems would ideally be prescient about the load that is generated at any single shard by their members in combination without actually requiring all members to be constantly negotiating. The MongoDB distribution model has this information, and it can be used in a query, but not in aggregation. That is the only missing piece of the puzzle.
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Creating a unique index should have an ignore null values option,SERVER-4815,29458,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-query-optimization,ajsharp,ajsharp,Jan 30 2012 09:40:50 PM UTC,Nov 14 2020 06:52:12 PM UTC,Feb 17 2021 11:15:20 AM UTC,,2.0.2,,,,Backlog,Indexing,,,,6,,,,,,"I've seen Issue 2028 (https://jira.mongodb.org/browse/SERVER-2028) and I don't think a sparse index is a good enough solution. One of the reasons I think a sparse index fails as a solution is because when the index is used in a lookup, the documents that *do* have null values in the indexed field are ignored in search results. Let me give a concrete example of what I think the behavior should be...

Let's say I'm adding a new property to a ""users"" collection. The new property is an api token, and needs to be unique across the entire collection. I'd like to be able to do db.users.ensureIndex({""token"": 1, ""unique"": true}), but this will of course fail b/c mongo will hit more than one null value. On the other hand, a sparse index here doesn't work because when I try to do a read query on that column where that column would get used (db.users.find({token: {""$ne"": null}}).count) the result set excludes all the users b/c it's a new property.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,4.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2012-02-16 06:25:18.0,251856000,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,craig.homa(craig.homa),Sat Feb 23 21:46:36 UTC 2013,,,,,,,,No,,,,,,ajsharp(ajsharp),backlog-query-optimization(JIRAUSER1257108),daniel.sinclair@nupe.com(daniel.sinclair@nupe.com),eliot(eliot),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i064fb:",,,,,,,"0|i00u3z:",4143,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i1ivsn:","Feb 16 2012 06:25:18 AM UTC;eliot;This probably should be the default like postgres, et al.","May 22 2012 08:36:41 PM UTC;ajsharp;Have there been any updates on this?","May 22 2012 09:52:00 PM UTC;ajsharp;It appears that the sparse option will only work if the documents don't have values set at all for the unique sparse field. If there is a value set, and it is null, document insert will fail due to a uniqueness violation. For unique indexes, null values should behave the same as an unset field.","Feb 23 2013 09:46:36 PM UTC;daniel.sinclair@nupe.com;I think unique sparse indexes already work the way they should. I'm happy with the differentiation between missing and null fields and I think it's an important distinction.

However, I'd like to see an option to prevent null values altogether on unique indexes. It doesn't make sense to me. Particularly, as the first time you add an entry with a null field it works just fine. I'm picking this up in my unit tests (just about). I'd prefer that if anyone tried to add a document with a null field that's required for the unique index it should reject even the very FIRST entry as an index violation. If I want to use the sparse index, I'll make my fields sparse.

This would trap errors better IMHO.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
String padding functionality,SERVER-31702,450134,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-query-optimization,kaitlin.mahar,kaitlin.mahar,Oct 24 2017 06:23:58 PM UTC,Nov 14 2020 06:51:47 PM UTC,Feb 17 2021 11:15:20 AM UTC,,,,,,Backlog,Aggregation Framework,,,,0,expression,,,,,It would be useful to have some operator to pad strings to specified lengths,,,,,,,,,,,,BI-1237,,,,,,,,,,,,,,,,,,,,3.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2017-10-26 16:47:24.0,33609600,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,craig.homa(craig.homa),Fri Jan 24 19:34:22 UTC 2020,,,,,,,,,,,,,,asya(asya),backlog-query-optimization(JIRAUSER1257108),jacek.s.gajek@gmail.com(jacek.s.gajek@gmail.com),kaitlin.mahar(kaitlin.mahar),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i20ikn:",,,,,,,"0|i00x9z:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i20gof:","Oct 26 2017 04:47:24 PM UTC;asya;You can already achieve it with existing aggregation expressions:

{noformat}
lpad = function (str, len, padstr="" "") {
     var redExpr={$reduce:{input:{$range:[0,{$subtract:[len, {$strLenCP:str}]}]}, initialValue:"""", in:{$concat:[""$$value"",padstr]}}};
     return {$cond:{if:{$gte:[{$strLenCP:str},len]}, then:str, else:{$concat:[ redExpr, str]}}}; 
}
lpad(""$string"", 20, ""x"")
{
	""$cond"" : {
		""if"" : {
			""$gte"" : [
				{
					""$strLenCP"" : ""$string""
				},
				20
			]
		},
		""then"" : ""$string"",
		""else"" : {
			""$concat"" : [
				{
					""$reduce"" : {
						""input"" : {
							""$range"" : [
								0,
								{
									""$subtract"" : [
										20,
										{
											""$strLenCP"" : ""$string""
										}
									]
								}
							]
						},
						""initialValue"" : """",
						""in"" : {
							""$concat"" : [
								""$$value"",
								""x""
							]
						}
					}
				},
				""$string""
			]
		}
	}
}
{noformat}

With sample data:
{noformat}
db.strings.find()
{ ""_id"" : ObjectId(""59f2107bf8e2fe24ca29dd80""), ""a"" : ""xxx"" }
{ ""_id"" : ObjectId(""59f2107ff8e2fe24ca29dd81""), ""a"" : ""yyyyyy"" }
{ ""_id"" : ObjectId(""59f21083f8e2fe24ca29dd82""), ""a"" : ""zzzzzzzzz"" }
db.strings.aggregate({$project:{_id:0, paddedA:lpad(""$a"",10)}})
{ ""paddedA"" : ""       xxx"" }
{ ""paddedA"" : ""    yyyyyy"" }
{ ""paddedA"" : "" zzzzzzzzz"" }
{noformat}
","Jan 24 2020 02:35:52 PM UTC;jacek.s.gajek@gmail.com;@Asya.kamsky

How to access it by Java/Kotlin driver? I'd like to return a sorted list of documents, using a padded with ze1roes string as a sort key. I tried:

{noformat}
mongoDb.runCommand(Document.parse("""" +
        ""\n"" +
      ""lpad = function (str, len, padstr=\"" \"") {\n"" +
       ""     var redExpr={\$reduce:{input:{\$range:[0,{\$subtract:[len, {\$strLenCP:str}]}]}, initialValue:\""\"", in:{\$concat:[\""\\$\$value\"",padstr]}}};\n"" +
      ""     return {\$cond:{if:{\$gte:[{\$strLenCP:str},len]}, then:str, else:{\$concat:[ redExpr, str]}}}; \n"" +
 ""}""))


col.aggregate(mutableListOf(
 Aggregates.addFields(Field(""refint"", """"""lpad(""${""$""}ref"", 10,""0"" }"""""")),
 Aggregates.sort(Sorts.ascending(""refint""))
 ))
{noformat}

Obviously it fails in the first stepbecause lpad=function(...) is not a valid JSON, but I have no idea how to do it in other way. Also, is the second step correct even assuming that a function already exist? (although it does not)","Jan 24 2020 07:34:22 PM UTC;asya;[~jacek.s.gajek@gmail.com]  I created the function in Javascript because I ran it in mongo shell.  You would want to create a local method that generated an appropriate pipeline.   In other words, that function should be local to your code and generate the pipeline you then pass to aggregate command.
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Allow hashed indexes to support $ne queries,SERVER-22442,262656,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-query-optimization,nmardiks,nmardiks,Feb 02 2016 08:52:14 PM UTC,Nov 14 2020 06:51:08 PM UTC,Feb 17 2021 11:15:20 AM UTC,,,,,,Backlog,Querying,,,,1,,,,,,"When performing a $ne query such as:
{noformat}
db.getCollection('users').find({ 'name.middle': { '$ne': null } }).hint({'name.middle': 'hashed'}).explain()
{noformat}

I can see a full table scan is being performed before returning the result and the hash index is being ignored.
In our case, most of the records would have a null value and thus using the index to quickly reach out to the few relevant documents would have been much more efficient.

To workaround this, we had to resort to using a regular index on top of the more efficient/small hashed index.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2016-02-02 21:36:21.0,159062400,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,craig.homa(craig.homa),Wed Feb 03 01:38:59 UTC 2016,,,,,,,,,,,,,,backlog-query-optimization(JIRAUSER1257108),pasette(dan@10gen.com),kelsey.schubert(thomas.schubert),nmardiks(nmardiks),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i02813:",,,,,,,"0|i00w6f:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i0xf07:","Feb 02 2016 09:36:21 PM UTC;kelsey.schubert;Hi [~nmardiks],

Thank you opening this ticket. Hashed indexes do not support [range based queries|https://docs.mongodb.org/manual/core/index-hashed/], so I am marking it as a new feature to be scheduled during the next round of planning.

Kind regards,
Thomas","Feb 03 2016 01:38:59 AM UTC;pasette;[~nmardiks], It may be useful for your use case to use a partial index if you want to index only a subset of your documents.  https://docs.mongodb.org/manual/core/index-partial/",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
add NGRAM index,SERVER-32157,467666,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-query-optimization,scsynergy,scsynergy,Dec 04 2017 01:58:49 PM UTC,Nov 14 2020 06:50:47 PM UTC,Feb 17 2021 11:15:20 AM UTC,,,,,,Backlog,Text Search,,,,7,,,,,,"Using a REGEX for a String.contains search is slow. Text search only works on word boundaries, so it does not yield any results for partial string matches.

If MongoDB were to add an NGRAM Index (http://lucene.apache.org/solr/guide/7_1/tokenizers.html) then searches using String.contains would be as fast as a ""prefix expression” a.k.a regex String.startsWith(/^/). Of course, people would have to be careful concerning index size, but maybe one could specify a maximum length for the field to index and if that length is exceeded on document inserting / updating the write operation would fail stating the reason for the failure (""string too long for ngram index with max size n"").

Additionally, one would need to specify whether to automatically cast the field to either lowercase or uppercase when creating the index.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,500A000000ZN0RtIAL,500A000000aPJFwIAO,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,101088000,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,craig.homa(craig.homa),2017-12-04 13:58:49.0,,,,,,,,,,,,,,backlog-query-optimization(JIRAUSER1257108),scsynergy(scsynergy),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i23ia7:",,,,,,,"0|i00xcv:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i23gdz:",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Project array by text search predicate,SERVER-24832,297311,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-query-optimization,cmmp,cmmp,Jun 28 2016 11:20:50 PM UTC,Nov 14 2020 06:50:08 PM UTC,Feb 17 2021 11:15:20 AM UTC,,,,,,Backlog,Querying,Text Search,,,0,,,,,,"Suppose I create the following db/collection:

{code:js}
> use articles
> db.stores.insert( [ 
             {_id : 1, arr : ['abc xyz', 'def']}, 
             {_id : 2, arr : ['jadskf', 'ljh abc']}])
> db.stores.createIndex({""arr"" : ""text""})
{code}

I want to do text search over the arrays arr and obtain only the array elements that match the search.

For instance,

{code:js}
> db.stores.find({$text : {$search : ""abc""}})
{ ""_id"" : 1, ""arr"" : [ ""abc xyz"", ""def"" ] }
{ ""_id"" : 2, ""arr"" : [ ""jadskf"", ""ljh abc"" ] }
{code}

Ideally I'd like to only obtain the first element of the arr in the first document: abc xyz and only the second element of the arr in the second document: ljh abc, and also the _id of the matched documents.

Note that what I want is not a simple projection of the arr element, but of the elements of the arr where the match occurred.",,,,,,,,SERVER-17648,,,,,,,,,,,,,,,,,,,,,,,,6.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2016-06-29 00:19:54.0,145756800,<a href='https://jira.mongodb.org/browse/SERVER-17648'>SERVER-17648</a>,,,,,,,,,,,,,,,,,,,,,,,,,,,true,craig.homa(craig.homa),Tue Jul 05 16:28:50 UTC 2016,,,,,,,,,,,,,,backlog-query-optimization(JIRAUSER1257108),cmmp(cmmp),ramon.fernandez(ramon.fernandez),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i01t4f:",,,,,,,"0|i00wjj:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i0s6c7:","Jun 29 2016 12:19:54 AM UTC;ramon.fernandez;[~cmmp], perhaps the [aggregation framework|https://docs.mongodb.com/manual/aggregation/] can meet your needs:
{code:js}
> db.foo.find()
{ ""_id"" : 1, ""arr"" : [ ""abc xyz"", ""def"" ] }
{ ""_id"" : 2, ""arr"" : [ ""jadskf"", ""ljh abc"" ] }
{ ""_id"" : 3, ""arr"" : [ ""foo1"", ""foo2 abc"", ""test"", ""abc foo3"" ] }
>
> db.foo.aggregate([{$unwind : ""$arr""}, {$match : {arr : /abc/}}, {$group : {_id: '$_id', arr: {$push: ""$arr""}}}, {$sort : {_id : 1}}])
{ ""_id"" : 1, ""arr"" : [ ""abc xyz"" ] }
{ ""_id"" : 2, ""arr"" : [ ""ljh abc"" ] }
{ ""_id"" : 3, ""arr"" : [ ""foo2 abc"", ""abc foo3"" ] }
{code}

Is this the functionality you're looking for?
","Jun 29 2016 12:26:35 PM UTC;cmmp;Hi [~ramon.fernandez],

That is a possibility.

I also got a nice ""trick"" from a stackoverflow question I posted: http://stackoverflow.com/questions/38085710/return-only-the-array-element-on-which-a-text-search-matched

{code:javascript}
db.stores.find({
    $text : {
        $search : ""abc""
    }
}, {
    arr : {
        $elemMatch : {
            $regex : /abc/i
        }
    }
})
{code}

But your proposed solution and the one I got from stack overflow (listed above) use regexs. While that does solve my simple toy case, regexs do not have the same semantics of full text search in Mongo. FTS uses stop words, stemming, which are not present in regexes.

If you can provide me with an example that solves the problem using the aggregation framework (or map reduce) while using FTS I'd be happy the functionality already exists.

PS: Thanks for the quick response!","Jun 29 2016 12:37:03 PM UTC;ramon.fernandez;I am sending this feature request to the Query team for evaluation. Note that this feature introduces new semantics for multikey indices, so even if it's accepted it may require a considerable effort. I think it would help your case if you were able to produce an example where using regular expressions is not sufficient.

Thanks,
Ramón.","Jun 29 2016 05:00:00 PM UTC;cmmp;Hi, thanks for looking into it [~ramon.fernandez].

The problem with regexes is that you're going to have to hardcode them.

For instance, suppose the following new example:

{code}
use articles
db.stores.insert( [{_id : 1, arr : ['i watched a movie last night', 'def']}, {_id : 2, arr : ['i went fishing last thursday', 'ljh abc']}])
db.stores.createIndex({""arr"" : ""text""})
{code}

FTS can find the entries with the following queries:

{code}
> db.stores.find({$text : {$search : ""fish""}})
{ ""_id"" : 2, ""arr"" : [ ""i went fishing last thursday"", ""ljh abc"" ] }
> db.stores.find({$text : {$search : ""watch""}})
{ ""_id"" : 1, ""arr"" : [ ""i watched a movie last night"", ""def"" ] }
{code}

How would you write a *generic* regular expression that handles both cases? 

Notice that for FTS stemming is going on on the background.

Hardcoding fish* and watch* is not allowed. Imagine the input is coming from a search box for a user.","Jul 05 2016 03:16:34 PM UTC;ramon.fernandez;Thanks for the additional information. The Query team has added this to their backlog for consideration in the future. Please continue to watch the ticket for updates.","Jul 05 2016 04:28:50 PM UTC;cmmp;Thanks for the update [~ramon.fernandez]. Will do.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
TopoJSON Support!,SERVER-30522,412901,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-query-optimization,victorstewart,victorstewart,Aug 04 2017 05:07:03 PM UTC,Nov 14 2020 06:49:59 PM UTC,Feb 17 2021 11:15:20 AM UTC,,,,,,Backlog,Geo,,,,1,,,,,,"For very complex shapes, GeoJSON becomes almost unusable because the representation is so unnecessarily explicit. Expressing GeoJSON data in TopoJSON can express these complex shapes in a fraction of the size!

Beyond the initial size reduction, TopoJSON also lends itself much better to simplification methods.

For example, all of the world's timezones in GeoJSON is some 120MB! Converting to TopoJSON and applying some simplification methods, this can be reduced to some 30MB easily.

This also facilitates must quicker computations, in a performance critical live environment. (Like locating users within a timezone).

https://github.com/topojson/topojson

",,,,,,,,,,,,SERVER-14360,PRODUCT-594,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2017-08-05 04:13:05.0,110764800,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,craig.homa(craig.homa),Mon Aug 14 14:57:20 UTC 2017,,,,,,,,,,,,,,backlog-query-optimization(JIRAUSER1257108),ian.whalen(ian@10gen.com),kelsey.schubert(thomas.schubert),victorstewart(victorstewart),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i1u9e7:",,,,,,,"0|i00x87:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i1u7hz:","Aug 05 2017 04:13:05 AM UTC;kelsey.schubert;Thanks for the feature request, [~victorstewart]. I've marked this ticket for consideration by Query Team – please continue to watch for updates. ","Aug 14 2017 02:57:20 PM UTC;ian.whalen;[~asya] could you please link this as related to any other requests for alternate geo representations?",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Extend JSON Schema implementation to support built-in format formats,SERVER-42036,831134,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-query-optimization,david.storch,david.storch,Jul 02 2019 12:42:03 AM UTC,Nov 14 2020 06:49:23 PM UTC,Feb 17 2021 11:15:20 AM UTC,,,,,,Backlog,Querying,,,,1,,,,,,"The JSON Schema specification includes validation of a number of built-in formats: see https://json-schema.org/understanding-json-schema/reference/string.html#built-in-formats. Drafts 6 and 7 of the JSON Schema extend this built-in format validation. The {{format}} keyword was never implemented in MongoDB, so we should add it. MongoDB users may wish to validate that their email addresses, ip addresses, hostnames, URIs, and so on are well-formed with an out of the box implementation.",,,,,,,,,,,,SERVER-42035,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,51494400,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,craig.homa(craig.homa),2019-07-02 00:42:03.0,,,,,,,,,,,,,,backlog-query-optimization(JIRAUSER1257108),david.storch(david.storch),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i3szrj:",,,,,,,"0|i00yvz:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i3sxvb:",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Include/Exclude Projection Syntax,SERVER-9106,69543,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-query-optimization,smilesrg,smilesrg,Mar 24 2013 11:18:46 AM UTC,Nov 14 2020 06:49:08 PM UTC,Feb 17 2021 11:15:20 AM UTC,,,,,,features we're not sure of,Querying,,,,0,projection,query,,,,"Hello!

I have a proposition for impovements in MongoDB. I want to tell about
db.collection.find() improvements.

Currently syntax of query with projection is like:
db.things.find( \{ param : ""value"" \} , \{ field1 : 1, field2: 1 \} )

Why don't change the syntax to
db.things.find( \{ param : ""value"" \} , \{ (include/exclude): \[fields\]\} )

I'll try to give you examples that you could understand what I mean:

db.things.find( \{ x : 4 \} , \{include:\[_id, j\]\} )
db.things.find( \{ x : 4 \} , \{exclude:\[_id, x\]\} )

In such syntax we can use _id field as a usual field, an it is not
included to projection implicitly. Another advantage is that we can
just pass array of fields instead of giving 0 or 1 values to field
names.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,232675200,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,craig.homa(craig.homa),Thu Oct 03 21:54:41 UTC 2013,,,,,,,,No,,,,,,backlog-query-optimization(JIRAUSER1257108),smilesrg(smilesrg),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i04p5r:",,,,,,,"0|i0104v:",6634,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i1ivov:","Mar 24 2013 11:20:03 AM UTC;smilesrg;By the way it is better to add new syntax instead of changing old one.","Oct 03 2013 09:54:41 PM UTC;smilesrg;The formatting of the description was slightly corrupted somewhy.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Extend JSON Schema implementation to support conditional application of subschemas,SERVER-42035,831132,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-query-optimization,david.storch,david.storch,Jul 02 2019 12:34:21 AM UTC,Nov 14 2020 06:49:05 PM UTC,Feb 17 2021 11:15:20 AM UTC,,,,,,Backlog,Querying,,,,1,,,,,,"JSON Schema draft 7 added an {{if}}, {{then}}, {{else}} construct for conditionally applying a subschema: https://json-schema.org/draft-07/json-schema-release-notes.html. This would be a useful feature for users with {{$jsonSchema}} match expressions inside a document validator. We should add support for this in MongoDB's implementation of JSON Schema.",,,,,,,,,,,,SERVER-48451,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,51494400,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,craig.homa(craig.homa),2019-07-02 00:34:21.0,,,,,,,,,,,,,,backlog-query-optimization(JIRAUSER1257108),david.storch(david.storch),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i3szr3:",,,,,,,"0|i00yvr:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i3sxuv:",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Allow the delimiter set recognized by text search tokenizer to be configurable,SERVER-23619,278479,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-query-optimization,kelsey.schubert,kelsey.schubert,Apr 08 2016 05:36:05 PM UTC,Nov 14 2020 06:48:59 PM UTC,Feb 17 2021 11:15:20 AM UTC,,,,,,Backlog,Text Search,,,,5,,,,,,"This feature would enable users to include or exclude delimiter characters. For example, the user could specify whether to treat ""twenty-three"" as one word or two words by including or excluding the ""-"" character from the set of delimiters.",,,,,,,,,,,,SERVER-22583,SERVER-23599,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2016-04-15 20:27:20.0,36979200,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,craig.homa(craig.homa),Mon Dec 16 18:01:30 UTC 2019,,,,,,,,,,,,,,webtobesocial(webtobesocial),backlog-query-optimization(JIRAUSER1257108),kelsey.schubert(thomas.schubert),rinoto(rinoto),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i0205r:",,,,,,,"0|i00wcn:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i0x7bj:","Jan 17 2018 09:41:21 AM UTC;rinoto;+1 - This would be really helpful in our case","Dec 16 2019 06:01:30 PM UTC;webtobesocial;Hey is there any plan to implement this in the near future? Having problems with [https://purplepee.co|https://purplepee.co/] search causing wired results when queering for 'abra-card-abra.com' the hyphen or other delimiter are the problem... Would really love to help you out, but I'm not famiar with C++...",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Consider creating an index filter parameter which modifies how queries are matched,SERVER-28116,357498,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-query-optimization,christopher.harris,christopher.harris,Feb 27 2017 02:01:23 PM UTC,Nov 14 2020 06:48:41 PM UTC,Feb 17 2021 11:15:20 AM UTC,,,,,,Backlog,Querying,,,,0,storch,,,,,"The current implementation of index filters allows for granular control as they are set and matched against the [full query shape|https://docs.mongodb.com/manual/core/query-plans/#index-filters]:

bq.Index filters determine which indexes the optimizer evaluates for a [query shape|https://docs.mongodb.com/manual/reference/glossary/#term-query-shape]. A query shape consists of a combination of query, sort, and projection specifications. If an index filter exists for a given query shape, the optimizer only considers those indexes specified in the filter.

This is very nice as it allows for quite a bit of flexibility.  However, this matching pattern does not work well for all use cases.  Consider an application that allows the customer to dynamically select projections.  If index filters are needed in that environment, then it may not be feasible to try to determine and manage them based on the modifiable projections.

While the default matching level should remain the same, we could consider introducing a tunable parameter for relaxing it.  Using the example above, the option could be set to a mode that instructs the optimizer to only consider the query predicates and sort fields (eg: not consider projections) when checking for matches against index filters.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,5002K00000dZPlZQAW,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2017-03-15 15:26:35.0,125280000,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,craig.homa(craig.homa),2017-02-27 14:01:23.0,,,,,,,,,,,,,,backlog-query-optimization(JIRAUSER1257108),christopher.harris(christopher.harris),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i1kta7:",,,,,,,"0|i00wxr:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i0ml0v:",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
add $throw/$error as pipeline operator,SERVER-27190,334605,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-query-optimization,adinoyi.omuya,adinoyi.omuya,Nov 28 2016 05:32:13 PM UTC,Nov 14 2020 06:48:02 PM UTC,Feb 17 2021 11:15:20 AM UTC,,,,,,Backlog,Aggregation Framework,,,,0,,,,,,"There are cases where MongoDB's behavior is inconsistent with a user's expectation and in such cases, it would be helpful if the user could force the aggregation framework to return an error - instead of having operations proceed.

An example is the power function:
{noformat}db.xy.aggregate({""$project"":{""pow"":{ ""$pow"": [ -2, 4.4 ] }}})
{
  ""result"": [
    {
      ""_id"": ObjectId(""56d4699e3a0b52029321e0d5""),
      ""pow"": NaN
    },
  ],
  ""ok"": 1
}{noformat}

Other relational databases - e.g. MySQL - return an error:{noformat}ERROR 1690 (22003): DOUBLE value is out of range in 'pow(-(2),-(4.4))'{noformat}

It would be helpful if I could write something like:{noformat}
{
  ""$project"": {
    ""pow"": {
      ""$cond"": [
        {
          ""$eq"": [
            {
              ""$pow"": [
                -2,
                4.4
              ]
            },
            NaN
          ]
        },
        {
          ""$throw"": ""invalid operation""
        },
        ""good""
      ]
    }
  }
}{noformat}

",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2016-11-30 20:12:50.0,132969600,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,craig.homa(craig.homa),Wed Nov 30 21:14:51 UTC 2016,,,,,,,,,,,,,,adinoyi.omuya(adinoyi.omuya@10gen.com),asya(asya),backlog-query-optimization(JIRAUSER1257108),charlie.swanson(charlie.swanson),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i01fcv:",,,,,,,"0|i00wuf:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i0mtkn:","Nov 30 2016 08:12:50 PM UTC;asya;Is the issue that we should be throwing an error on invalid expression (the way MySQL does)?

Or is it a more general ""we need a way to allow pipeline to throw an error"" and this was just an example?

","Nov 30 2016 09:14:51 PM UTC;charlie.swanson;I think this should be treated as a more general request to allow users to cause a pipeline to fail based on some computed condition. If we're only interested in different $pow semantics or some other subset, we should track that work in a separate ticket.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Add support for majority read concern level to MapReduce,SERVER-38117,633311,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-query-optimization,martin.neupauer,martin.neupauer,Nov 13 2018 05:51:43 PM UTC,Nov 14 2020 06:47:39 PM UTC,Feb 17 2021 11:15:20 AM UTC,,,,,,Backlog,MapReduce,,,,0,query-44-grooming,,,,,The original ticket SERVER-20445 added majority read concern to $out only. This is the follow up for MapReduce.,,,,,,,,,,,,PHPLIB-290,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2019-07-09 12:05:25.0,50803200,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,craig.homa(craig.homa),Tue Jul 09 18:47:46 UTC 2019,,,,,,,,,,,,,,backlog-query-optimization(JIRAUSER1257108),charlie.swanson(charlie.swanson),martin.neupauer(martin.neupauer),pawel.terlecki(pawel.terlecki),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i2vjxr:",,,,,,,"0|i00yjr:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i2vi1j:","Jul 09 2019 12:05:25 PM UTC;pawel.terlecki;[~charlie.swanson], [~james.wahlin] would this be easier after MR in Agg completes? Is it worth including this in that epic?","Jul 09 2019 06:47:46 PM UTC;charlie.swanson;[~pawel.terlecki] we're not planning on doing this as part of PM-766. See this non-goal in the scope:
{quote}
Removing any restrictions of usage of mapReduce. We do not plan to make the command available within transactions (which will require PM-1247), nor do we plan on removing any restrictions on readConcern, writeConcern, or similar options.
{quote}

I don't think it will be technically challenging to do this once we complete PM-766, but we were trying to keep the scope as limited as possible so chose not to investigate here. ",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
allow aggregation to take an 'allowPartialResults' option,SERVER-31782,453615,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-query-optimization,esha.maharishi,esha.maharishi,Nov 01 2017 03:22:45 AM UTC,Nov 14 2020 06:47:14 PM UTC,Feb 17 2021 11:15:20 AM UTC,,3.6.0-rc1,,,,Backlog,Querying,,,,0,neweng,,,,,"The infrastructure for this is already in place: it's just a matter of parsing an 'allowPartialResults' option (similar to the [find command|https://docs.mongodb.com/manual/reference/command/find/]) and passing it down to establishCursors(), which takes 'allowPartialResults' as a standalone boolean argument that [the agg code currently always sets to false|https://github.com/mongodb/mongo/blob/r3.6.0-rc1/src/mongo/s/commands/cluster_aggregate.cpp#L398].

We should also first double-check that it makes sense to accept allowPartialResults for all aggregations ($facet? $lookup? $graphLookup?).

SERVER-28874 fixed the behavior of 'allowPartialResults' in establishCursors() and added thorough unit testing. It also added a jstest, jstests/sharding/allow_partial_results.js, which explicitly checks that aggregation does not accept the 'allowPartialResults' option, so this ticket should update that test.",,,,,,,,,,,,SERVER-3322,SERVER-17696,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2017-11-03 14:29:08.0,103766400,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,craig.homa(craig.homa),Fri Nov 03 14:29:08 UTC 2017,,,,,,,,,,,,,,asya(asya),backlog-query-optimization(JIRAUSER1257108),esha.maharishi(esha.maharishi@10gen.com),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i2141r:",,,,,,,"0|i00xa7:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i2125j:","Nov 03 2017 02:29:08 PM UTC;asya;This is a good idea and could help with resolving SERVER-3322 and/or SERVER-17696 (which are two requests currently in conflict with each other, and having this flag would allow behavior in SERVER-3322 when the flag is set and implementing SERVER-17696 when it's not).

",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Text search should be able to support AND of search terms,SERVER-13947,136438,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-query-optimization,felipe.albrecht,felipe.albrecht,May 14 2014 04:10:51 PM UTC,Nov 14 2020 06:46:54 PM UTC,Feb 17 2021 11:15:20 AM UTC,,,,,,Backlog,Text Search,,,,2,,,,,,"From instance: ""word cup brazil""  is translated to ""word"" OR ""cup"" OR ""brazil"". How I do ""word"" AND ""cup"" AND ""brazil"" ?

I use the hyphen (-) operator, how do thing about the plus (+)?
$search(""+word +cup +brazil"") ",,,,,,,,,,,,FREE-182541,,,,,,,,,,,,,,,,,,,,4.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2014-07-09 17:47:41.0,54604800,,,,,,,,,,,,,,,,,,,,,,,,,,,,false,craig.homa(craig.homa),Sun May 26 20:25:41 UTC 2019,,,,,,,,No,,,,,,backlog-query-optimization(JIRAUSER1257108),dandv(dandv),felipe.albrecht(felipe.albrecht),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i03k5r:",,,,,,,"0|i00ve7:",117405,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i0z24n:","May 26 2019 12:37:25 AM UTC;dandv;This is such an important feature, it was submitted 5+ years ago, yet it only had 1 upvote before I've added mine. What am I missing? Does everyone just give up on MongoDB FTS and use ElasticSearch?","May 26 2019 07:50:55 PM UTC;felipe.albrecht;Hello Dan,

I even had forgotten about this issue. In fact, what people are doing is indeed MongoDB + Elastic Search, that is a pitty and also annoying.

Currently, I 'emulate' an 'and' command in MongoDB putting the text that must appear in double quotes, but I do not know if it is an official feature.","May 26 2019 08:21:36 PM UTC;dandv;If you put the entire phrase between double quotes, that's not going to find occurrences of the individual words.

If you put each word between double quotes, this [post|https://groups.google.com/d/msg/mongodb-user/qb36QRIzvAc/FjXw-7tdsWkJ] in the thread you started says ""you won't be able to take advantage of the stemming functionality to see results that contain similar terms"".","May 26 2019 08:25:41 PM UTC;felipe.albrecht;I mean, each word in a double quote:

example query : 'If you put the ""entire"" phrase ""between"" double quotes, that's not ""going"" to find occurrences of the individual words.', it will force that the words ""entire"", ""between"", and ""going"" must be presented.

But it is a workaround and I wish one day they will implement the suggestion in this issue.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Implement Index Choice based on Partial Filter Expression,SERVER-23808,280875,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-query-optimization,william.cross,william.cross,Apr 19 2016 07:13:31 PM UTC,Nov 14 2020 06:46:45 PM UTC,Feb 17 2021 11:15:20 AM UTC,,3.2.5,,,,Backlog,Indexing,,,,0,,,,,,"Request for index selection based solely on the partialFilterExpression.

Currently, the query optimizer decides on an index based on the match and sort arguments of a query. With partial indexes, it will also consider the partialFilterExpression, but as implemented, it can still miss an index that would be performant on the query. 

Here's an example where the current implementation is sub-optimal:

{code}
db.foo.dropIndex();
db.foo.createIndex( { a : 1 }, { partialFilterExpression : { b : { $gte : 5 } } } );
for (i=1; i<=10; i++) { db.foo.insertOne( { a : i, b : i } ) };
db.foo.find( { b : { $gte : 5 } }, { _id : 0, a : 1 } ).explain()
{code}

Desired result: The query uses the index, and it is a covered query
Current result: the query performs a collection scan
-Variation: db.foo.find( \{ a : \{ $exists: true }, b : \{ $gte : 5 } }, \{ _id : 0, a : 1 } ).explain() results in an index scan, but does not cover the query even though the index could cover this query.-",,,,,,,,,,,,SERVER-26580,SERVER-29247,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2016-12-27 15:30:09.0,130032000,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,craig.homa(craig.homa),Tue Jan 03 18:29:43 UTC 2017,,,,,,,,,,,,,,asya(asya),backlog-query-optimization(JIRAUSER1257108),william.cross(william.cross),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i01z2n:",,,,,,,"0|i00wdz:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i0x5w7:","Dec 27 2016 03:30:09 PM UTC;asya;same as SERVER-26896?
","Jan 03 2017 06:29:43 PM UTC;william.cross;I think this ticket is different in scope than SERVER-26896. Per your reference to SERVER-12869 (Index null values and missing values differently), I'm removing the mention of expecting a covered query for { a : { $exists : true } }.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Support both include and exclude on field filters,SERVER-391,10808,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-query-optimization,redbeard0531,redbeard0531,Oct 28 2009 12:57:08 PM UTC,Nov 14 2020 06:46:27 PM UTC,Feb 17 2021 11:15:20 AM UTC,,,,,,Backlog,Querying,,,,17,asya,QFB,,,,"find({}, {a:1, b.c:0})",,,,,,,,,,,,SERVER-44558,,,,,,,,,,,,,,,,,,,,7.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2010-10-18 18:44:34.0,118281600,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,craig.homa(craig.homa),Fri May 19 18:25:37 UTC 2017,,,,,,,,No,,,,,,antonimmo(antonimmo),asya(asya),backlog-query-optimization(JIRAUSER1257108),david.storch(david.storch),ezequi(ezequi),zippy1981(zippy1981),redbeard0531(redbeard0531),mitar(mitar),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i07k8n:",,,,,,,"0|i00yb3:",20618,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i1c0fb:","Oct 18 2010 06:44:34 PM UTC;zippy1981;See http://groups.google.com/group/mongodb-user/browse_thread/thread/c53d99916e46ae1a/d4a79a34104377f9#d4a79a34104377f9 for commentary.","Oct 18 2010 06:45:27 PM UTC;zippy1981;The message this currently generates is: 

db.events.findOne(null, {_id:1, Name:1, ""Locations"":1, ""Locations.v.Dates"": 0}) 

Mon Oct 18 12:23:27 uncaught exception: error { 
        ""$err"" : ""You cannot currently mix including and excluding fields. Contact us if this is an issue."", 
        ""code"" : 10053 
} ","Nov 15 2013 12:03:04 PM UTC;mitar;My use case is:

Publications.find({'importing.person._id': personId}, {'importing.$': 1, 'importing.$.temporaryFile': 0})

So I would like to get only that subdocument of importing belonging to the person, but remove temporaryFile field in those subdocument.","Jan 10 2014 06:44:04 PM UTC;antonimmo;Hi! I've got this error.

My case is the following:

- I've made a mapReduce(map(),reduce(),options) and, by construction, each document in the options.out.reduce collection has a {_id, value} structure
- The collection has a lot of documents, so it would be better if I can query directly from there instead of running an ""almost-never-ending"" find+forEach to create a new structure from it
- There's some documents in that collection (about 5%, but it's still a large amount of data and MB to transfer along the network/internet) which need some update
- My query if more or less (for security reasons I modified the field names) like this:
db.find({""value.Coupons"":{$size:0}},{""_id.field1"":1, ""_id.field2"":1, ""_id.field3"":0, ""_id.field4"":0})
- As I've already said, I only need 2 of the 4 fields of the key subdocument because of network traffic (and time, obviously) reasons, and this is an issue for us because it spends twice the time we would like it to. This is the main goal of the projection operator, isn't it?","Jan 21 2015 09:59:19 AM UTC;ezequi;Hello, these are some tests that I have been doing concerning this issue:

> db.test.findOne()
{
	""_id"" : ObjectId(""54b4fa2618c1e7c4365f43dc""),
	""family"" : ""Smith"",
	""children"" : [
		{
			""child_name"" : ""John""
		},
		{
			""child_name"" : ""Anna""
		}
	]
}

And at the moment of executing the following queries:

> db.test.find({""family"" : ""Smith""},{""children"" : 1, ""family"" : 0,""_id"":0})
error: {
	""$err"" : ""You cannot currently mix including and excluding fields. Contact us if this is an issue."",
	""code"" : 10053
}
> db.test.find({""family"" : ""Smith""},{""children"" : 0,  ""family"" : 1 ,""_id"":0})
error: {
	""$err"" : ""You cannot currently mix including and excluding fields. Contact us if this is an issue."",
	""code"" : 10053
}
> db.test.find({""family"" : ""Smith""},{""children"" : 0,  ""family"" : 1 ,""_id"":1})
error: {
	""$err"" : ""You cannot currently mix including and excluding fields. Contact us if this is an issue."",
	""code"" : 10053
}
> db.test.find({""family"" : ""Smith""},{""children"" : 0,  ""family"" : 0 ,""_id"":1})
error: {
	""$err"" : ""You cannot currently mix including and excluding fields. Contact us if this is an issue."",
	""code"" : 10053
}

In this case for instance the result is fine:

> db.test.find({""family"" : ""Smith""},{""children"" : 1,  ""family"" : 1 ,""_id"":0})
{ ""family"" : ""Smith"", ""children"" : [  {  ""child_name"" : ""John"" },  {  ""child_name"" : ""Anna"" } ] }","May 15 2017 11:13:27 PM UTC;asya;Do we really need this?  Assuming we merge projection and aggregation $project stage, I think there will be ways to get the thing described in the initial description?

{noformat}
{$project:{a:1,b:1}},{$addFields:{""b.c"":""$$REMOVE""}}
or
{$project:{a:1,b:1}},{$project:{""b.c"":0}}
{noformat}
","May 19 2017 06:25:37 PM UTC;david.storch;[~asya], interesting observation that this can now be achieved in the aggregation framework with sequential projection stages. I'd like to keep this open, however, since I think in the future we may want to design a more elegant way to express this kind of document transformation within a single aggregation stage.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Allow n-ary aggregation expressions to compute their array of arguments dynamically,SERVER-31991,459495,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-query-optimization,devnopt,devnopt,Nov 15 2017 10:57:21 PM UTC,Nov 14 2020 06:46:15 PM UTC,Feb 17 2021 11:15:20 AM UTC,,,,,,Backlog,Aggregation Framework,,,,2,,,,,,"For example, a user might store the arguments to an n-ary expression like {{$concatArrays}} inside a document in the collection:

{code}
db.c.insert({arraysToConcat: [[1, 2, 3], [4, 5, 6]]});
{code}

There should be a way to use the the value of the field path expression ""$arraysToConcat"" as the list of arguments to {{$concatArrays}}. Neither the expressions \{$concatArrays: ""$arraysToConcat""\} nor \{$concatArrays: \[""$arraysToConcat""\]\} have this meaning. SERVER-31786 has a more detailed discussion of the use case.

h5. Original description

The $concatArrays operator does not handle using a multi array field already in the collection.

The current work around is to use $reduce with $concatArrays.

See SERVER-31786 for more details.",,,,,,,,,,,,SERVER-31786,SERVER-31831,,,,,,,,,,,,,,,,,,,2.0,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2017-11-15 23:10:38.0,54259200,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,craig.homa(craig.homa),Thu May 30 16:45:20 UTC 2019,,,,,,,,,,,,,,asya(asya),backlog-query-optimization(JIRAUSER1257108),devnopt(devnopt),mark.agarunov(mark.agarunov),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i224bz:",,,,,,,"0|i00yw7:",9223372036854775807,,,,,,,,,,,,Query 2019-06-17,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i222fr:","Nov 15 2017 11:10:38 PM UTC;mark.agarunov;Hello [~devnopt],

Thank you for the report. I've set the fixVersion to ""Needs Triage"" for this new feature to be scheduled against our currently planned work. Updates will be posted on this ticket as they happen.

Thanks,
Mark","May 30 2019 04:45:20 PM UTC;asya;Linking to a number of related tickets, all basically expecting to be able to use a stored array where aggregation is expecting an array of specified input values.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Allow for $pushall / $push with $each to allow pushing all elements of array in $group,SERVER-16284,170818,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-query-optimization,dancerjohn,dancerjohn,Nov 22 2014 09:54:05 PM UTC,Nov 14 2020 06:46:06 PM UTC,Feb 17 2021 11:15:21 AM UTC,,,,,,Backlog,Aggregation Framework,,,,16,accumulator,asya,expression,needs-scope-approval,pm1457-nominee,"I would like to be able to push all elements of an array field into a new field. So, in a $group, I could do a $push or $addToSet of a field that is an array field and the resulting field would be an array of the elements instead of an array of arrays.

Seems like the $each operator in update is the solution if added to aggregations.",,,,,,,,,,,,SERVER-29339,PM-1457,PM-1395,,,,,,,,,,,,,,,,,,9.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2014-11-25 23:44:57.0,112406400,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,craig.homa(craig.homa),Wed Jul 26 18:42:07 UTC 2017,,,,,,,,,,,,,,asya(asya),backlog-query-optimization(JIRAUSER1257108),charlie.swanson(charlie.swanson),david.storch(david.storch),dancerjohn(dancerjohn),tinkler@vocabulary.com(tinkler@vocabulary.com),neillunn(neillunn),nodoze(nodoze),ramon.fernandez(ramon.fernandez),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i037af:",,,,,,,"0|i00vlr:",149513,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i01han:","Nov 25 2014 11:44:57 PM UTC;ramon.fernandez;You may want to try using [the $unwind operator|http://docs.mongodb.org/manual/reference/operator/aggregation/unwind/] to achieve what you need; for example:

{code:js}
> db.foo.drop()
> db.foo.insert({x:1, a:[1,2]})
> db.foo.insert({x:1, a:[3,4]})
// $push creates an array of arrays
> db.foo.aggregate([{$group: {_id:'$x', res:{$push:""$a""}}}])
{ ""_id"" : 1, ""res"" : [ [ 1, 2 ], [ 3, 4 ] ] }
// using $unwind before $group does the trick
> db.foo.aggregate([{$unwind:'$a'}, {$group: {_id:'$x', res:{$push:""$a""}}}])
{ ""_id"" : 1, ""res"" : [ 1, 2, 3, 4 ] }
{code}

Is this the behavior you're looking for?","Nov 26 2014 02:10:51 PM UTC;dancerjohn;So yes, I am familiar with unwind but here is how it ended up. In my case I would like to do a two-step group. Group 1 produces a count and creates new arrays of values. Group 2 gives me an overall count and concatenates the two arrays (via the $pushall or $push / $each to produce an array of values instead of an array or arrays).

Instead of doing the aggregation as two simple groups, I have to do the following:

group1
unwind array1
unwind array2
group2 (this group is limited in that I cannot get a count of unique values because of the double unwind)
project to get a count that could have been done in group2 if I had not had to unwind twice

So yes, I was able to do a workaround. The point however is that this seems to be a functionality ($each I believe) that would not be uncommonly used if available in aggregate and seems to be available for update. I ask that you make it available in aggregate as well.","Jul 28 2015 11:35:59 PM UTC;nodoze;It would be nice if $push in aggregation could support $each and @slice etc.

Having the option to limit array items with slice in the $project stage is now supported (SERVER-6074) but it would be good to have these options as part of the @group stage as well. ","Nov 04 2015 08:23:27 PM UTC;charlie.swanson;Hi [~oeberle@cellmobs.com],

That ticket is slightly misnamed. You can use the $slice operator in a $group stage, just as you can use any other operator available in the project stage. e.g. given the following documents:
{code:js}
{_id: 0, comments: [{text: 'hello there'}, {text: 'hi!'}]}
{_id: 1, comments: [{text: 'hello again!'}, {text: 'yo'}]}
{code}
You can run the following pipeline
{code:js}
db.foo.aggregate([{
  $group: {
    _id: null,
    comments: {
      $push: {
        $slice: ['$comments', 1]
      }
    }
  }
}])
{code}
To get this result
{code:js}
{_id: null, comments: [{text: 'hello there'}, {text: 'hello again!'}]}
{code}","Nov 05 2015 07:18:28 PM UTC;charlie.swanson;I should add to my example that $slice is new in 3.2, so this won't work against a mongod <=3.0, but the point remains, any expression can be used in the group stage, just substitute $slice for your favorite projection operator.","Apr 24 2016 02:43:10 AM UTC;neillunn;I would actually see this more in this form:

{code:javascript}
    db.foo.drop()
    db.foo.insertMany([
        { ""x"": 1, ""a"": [1,2] },
        { ""x"": 1, ""a"": [2,3] }
    ])
{code}

Where accumulators functioned something like the following and without needing to resort to $unwind

{code:javascript}

    db.foo.aggregate([
       { ""$group"": {
           ""_id"": ""$x"",
          ""a"": { ""$pushEach"": ""$a"" }
      }}
    ])
   // Results in 
   { ""_id"": 1, ""a"": [1,2,2,3] }

    db.foo.aggregate([
       { ""$group"": {
           ""_id"": ""$x"",
          ""a"": { ""$addEach"": ""$a"" }
      }}
    ])
   // Results in 
   { ""_id"": 1, ""a"": [1,2,3] }

{code}

Or even as an allowed ""modifier"" from a syntax point of view

{code:javascript}

    db.foo.aggregate([
       { ""$group"": {
           ""_id"": ""$x"",
          ""a"": { ""$addToSet"": { ""$each"": ""$a"" } }
      }}
    ])
   // Results in 
   { ""_id"": 1, ""a"": [1,2,3] }

   // Or with expressions
   db.foo.drop()
   db.foo.insert({ ""a"": 1, ""b"": 2 })

    db.foo.aggregate([
       { ""$group"": {
         ""_id"": null,
         ""data"": {
           ""$push"": {
             ""$each"": {
                 ""$setUnion"": [
                   [{ ""a"": ""$a"", ""b""; ""$b"" }],
                   [{ ""a"": ""$b"", ""b"": ""$a"" }]
                 ]
             }
           }
         }
       }}
    ])
   // Results in
   { ""_id"": null, ""data"": [{ ""a"": 2, ""b"": 1 }, { ""a"": 1, ""b"": 2 }] }
{code}

Point being that there should be an operator syntax for applying each element of an existing array or ""set"" without needing to resort to $unwind.

The $unwind operation should be reserved for cases where it is necessary to actually transfer elements from those arrays into part of the grouping key itself.

Allowing such modifiers and even $sort as well removes various use cases requiring $unwind and should significantly improve performance where the array/""set"" can be merged/sorted within the accumulator result.","Jan 23 2017 02:59:41 PM UTC;david.storch;As noted in SERVER-27484, allowing a set union operation in $group would be useful, in addition to array concatenation. Both are in scope for this ticket. In other words, given the input documents for a group
{code}
{_id: ""myGroup"", arr: [1, 2, 3]}
{_id: ""myGroup"", arr: [2, 3, 4]}
{code}
there should be an easy way to reduce this to either \{_id: ""myGroup"", resultArr: \[1, 2, 3, 4\]\} or \{_id: ""myGroup"", resultArr: \[1, 2, 3, 2, 3, 4\]\}.","Jul 26 2017 10:33:49 AM UTC;tinkler@vocabulary.com;Just my 2 cents, but if you are going to be adding accumulators like $mergeObjects (SERVER-24879) you really should consider adding support for set union when grouping.","Jul 26 2017 06:42:07 PM UTC;asya;SERVER-29339 would allow this, and any other arbitrary grouping but I would agree that the more common use cases should have simplest possible syntax.
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Support for XPath like queries,SERVER-736,11483,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-query-optimization,mongonix,mongonix,Mar 11 2010 10:39:41 AM UTC,Nov 14 2020 06:45:30 PM UTC,Feb 17 2021 11:15:21 AM UTC,,,,,,Backlog,Indexing,JavaScript,Performance,Querying,19,,,,,,"It would  be very nice to be able to express  XPath-like queries with MongoDB. 

For example, let's say there is a JSON document that contains a certain subtree, but it is not known where it is inside the JSON 
document. 

In the XML world, one could use XPath and write something like this to 
express relative path (which returns all sub-trees matching the 
pattern): 
 //tree_root_node/subnode1/subnode2 and so on. 
But how can somethig like this expressed with MongoDB? According to the documentation found on Mongo web-site, it is only possible to use  the following two syntaxes: 
 1) {tree_root_node: { subnode1 : {subnode2 : ...}}} 
 2) { 'tree_root_node.subnode1.subnode2': ...} 
in both cases, one needs to know the full path from the JSON document  root to the subtree of interest. But it is not known in my case as I 
explained before. 

And, BTW, it would be really cool if generic XPath queries could be 
applied on JSON documents. There are some proposals for JSON based 
XPath: 
 http://goessner.net/articles/JsonPath/ 
 http://bluelinecity.com/software/jpath/ 
 http://somewebguy.wordpress.com/tag/Query/ 
 http://www.hugoware.net/projects/jlinq 
 
(BTW, many XML databases do actually support XPath natively. They even  opimize their  indexing and storage  backends for effective XPath  queries evaluation) 

Is something like this planned for the future releases? How difficult would it be to  implement something like this? Would it require additional, more  detailed indexing for effective implementation? 

Of course, it is easy to provide support at the syntactic level using  whatever syntax (jQuery-like, XPath like, etc) - there are enough libraries for that. But implementing such queries effectively would eventually require new kinds of (additional) indexing, unless you want to  iterate over all entries and check each one for the required sub- trees. 

Proposal by Eliot: An easy first idea might just be wildcard operator a.*b 

Please see this mailing list thread for more information:
http://groups.google.com/group/mongodb-user/browse_thread/thread/d359c8ed8eacddea

",,,,,,,,,,,,SERVER-267,,,,,,,,,,,,,,,,,,,,3.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2012-12-06 22:47:22.0,78624000,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,craig.homa(craig.homa),Tue Aug 21 15:39:16 UTC 2018,,,,,,,,No,,,,,,yokotoka(yokotoka),backlog-query-optimization(JIRAUSER1257108),mongonix(mongonix),rguenette(rguenette),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i07fzz:",,,,,,,"0|i00tvb:",6311,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i0darj:","Dec 06 2012 10:47:22 PM UTC;yokotoka;Yes, JsonPath functionality is sorely missed in the pyMongo driver...","Dec 06 2012 10:48:44 PM UTC;yokotoka;http://goessner.net/articles/JsonPath/","Aug 21 2018 03:39:16 PM UTC;rguenette;Hi,

 

What is the status of this request? It is classified as ""Major"" but still opened since 2010!

 

Thank you",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Whole index scan on sparse index should be able to provide a sort,SERVER-13908,136088,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-query-optimization,rassi,rassi,May 12 2014 06:43:03 PM UTC,Nov 14 2020 06:45:21 PM UTC,Feb 17 2021 11:15:21 AM UTC,,2.6.1,,,,Backlog,Querying,,,,1,,,,,,"Sparse indexes can generally be used to answer queries that include a ""non-sparse"" predicate on an indexed field.

This is not the case, however, for query plans that perform a whole index scan to provide a sort.  These query plans should be able to use sparse indexes if a ""non-sparse"" predicate is given on an indexed field.

{code:js}
> db.foo.dropIndexes()
{
	""nIndexesWas"" : 2,
	""msg"" : ""non-_id indexes dropped for collection"",
	""ok"" : 1
}
> db.foo.ensureIndex({a:1,b:1},{sparse:true})
{
	""createdCollectionAutomatically"" : true,
	""numIndexesBefore"" : 1,
	""numIndexesAfter"" : 2,
	""ok"" : 1
}
> db.foo.find({a:1,b:1}).sort({a:1}).explain().cursor
BtreeCursor a_1_b_1 // Bounded index scan; sparse index is used.
> db.foo.find({b:1}).sort({a:1}).explain().cursor
BasicCursor // Whole index scan; sparse index not used.
{code}",,,,,,,,,,,,SERVER-10801,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2015-05-08 19:52:03.0,213580800,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,craig.homa(craig.homa),2014-05-12 18:43:03.0,,,,,,,,No,,,,,,backlog-query-optimization(JIRAUSER1257108),rassi(rassi@10gen.com),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i03kdj:",,,,,,,"0|i00vdz:",117123,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i0z2jz:",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
$lookup and $graphLookup should only fetch fields needed,SERVER-26602,323157,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-query-optimization,rroxysam,rroxysam,Oct 12 2016 06:40:46 PM UTC,Nov 14 2020 06:44:55 PM UTC,Feb 17 2021 11:15:21 AM UTC,,,,,,Backlog,Aggregation Framework,,,,4,optimization,,,,,"$lookup is a great feature, but it must provide the option to limit the fields from joins",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,4.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2016-10-12 19:03:21.0,136339200,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,craig.homa(craig.homa),Sat Oct 22 20:03:00 UTC 2016,,,,,,,,,,,,,,backlog-query-optimization(JIRAUSER1257108),kelsey.schubert(thomas.schubert),rroxysam(rroxysam),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i01in3:",,,,,,,"0|i00wqv:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i0s60f:","Oct 12 2016 07:03:21 PM UTC;kelsey.schubert;Hi [~rroxysam],

Would following the {{$lookup}} stage with a [{{$project}}|https://docs.mongodb.com/manual/reference/operator/aggregation/project/] stage work for your use case?

Thank you,
Thomas","Oct 13 2016 12:01:19 PM UTC;rroxysam;@Thomas, Yes this is absolutely right & i did same in my scenario following $lookup stage with $project. But isn't be great if there is an option for projection in $lookup for retrieving only particular fields for the associate collection.","Oct 15 2016 03:56:47 AM UTC;kelsey.schubert;Hi [~rroxysam],

Thanks for confirming that you are using the {{$project}} stage after {{$lookup}}. I've modified this ticket to have the aggregation pipeline recognize this pattern and only fetch fields that are needed in subsequent stages. I believe this would accomplish the same goal, and users would need not modify their aggregation queries. Please continue to watch for updates.

Kind regards,
Thomas","Oct 22 2016 08:03:00 PM UTC;rroxysam;@Thomas. Thanks",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
RTree Implementation for Spatial Indexing,SERVER-3551,20711,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-query-optimization,nknize,nknize,Aug 08 2011 09:10:21 PM UTC,Nov 14 2020 06:44:50 PM UTC,Feb 17 2021 11:15:21 AM UTC,,,,,,Backlog,Geo,Indexing,,,13,indexing,performance,query,,,"This feature could be implemented in a number of ways.  

1. Extend existing BTree to include B+ Tree functionality, implement MBR bucket functionality
2. Extend existing BTree to include R* tree functionality (e.g. geo dependent splitting, hilbert value inserts) and implement MBR bucket functions


",,,,,,,,SERVER-8791,,,,,,,,,,,,,,,,,,,,,,,,8.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2011-08-16 17:42:52.0,203990400,<s><a href='https://jira.mongodb.org/browse/SERVER-8791'>SERVER-8791</a></s>,,,,,,,,,,,,,,,,,,,,,,,,,,,true,craig.homa(craig.homa),Sun Aug 31 18:00:12 UTC 2014,,,,,,,,No,,,,,,backlog-query-optimization(JIRAUSER1257108),ctonhaeuser(ctonhaeuser),eliot(eliot),nknize(nknize),p.kennedy@fugro.com.au(p.kennedy@fugro.com.au),radoslav(radoslav),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i06jkv:",,,,,,,"0|i00tzj:",6068,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i014e7:","Aug 09 2011 06:13:43 PM UTC;nknize;Thanks Eliot. I've got an R* implementation i'm working to merge in my own sandbox... I created this feature in case the whistle blowers wanted to flag it as a duplicate effort.  I'd prefer not waste time if someone is already working it.  ","Aug 16 2011 05:40:32 PM UTC;nknize;I am about halfway done merging an initial R* implementation.  I wouldn't mind someone assigning this task to me so I can keep updating the progress.  When I finish I can push the code to a working branch on GitHub for peer review and community testing.","Aug 16 2011 05:42:52 PM UTC;eliot;I'm not sure this is something we want to bring in right now.
Happy to help review it when you publish though.","Aug 16 2011 06:29:08 PM UTC;nknize;Sounds great Eliot!  I will post a copy to my GitHub account and notify when its ready for review.  

Re: some background on this feature.  I believe it was Greg Studer that I spoke w/ on #mongodb about polygonal indexing and search.  There was no support for polygonal clipping (aka query failed unless a point fell w/in the polygon search area; see: http://twitpic.com/67457c )  This is a much needed feature for spatial search beyond simple point data.  Greg mentioned there wouldn't be much work in this area because of the interest to migrate to an RTree approach (ala. PostGIS, Oracle Spatial, etc.) sometime in v.2.1.  Is that not the case?  

At any rate, the implementation is primarily an extension of the following publications (w/ some original contribution and distributed modifications):

N. Beckmann, H.-P. Kriegel, R. Schneider, B. Seeger: The R*-Tree: An Efficient and Robust Access Method for Points and Rectangles. SIGMOD Conference 1990: 322-331.
I. Kamel, C. Faloutsos: Hilbert R-Tree: An Improved R-Tree Using Fractals. VLDB '94 Proceedings of the 20th International Conference on Very Large Data Bases 1994: 500-509.

I will keep this issue posted w/ updates.","Oct 01 2011 08:23:11 AM UTC;ctonhaeuser;Hi Nicholas,
have you already made progress on the integration of your R* implementation?

I'm currently facing a similar issue in a project of mine, and this sounds like the ideal solution to me.","Dec 03 2011 02:42:57 AM UTC;p.kennedy@fugro.com.au;hi,
from my perspective the current spatial index on points only is insufficent for us to move to mongodb.  I believe the engine needs to index (R-tree) all spatial data types as supported by GeoJSON, ie point, line, polygon, multipoint.  each data type build on point, so they are not terribly complex, but not having them indexed makes it impossible to use mongo, which is why geocouch exists.

I do not mind if you use r-tree or anything else.  The end game is a spatial index using bounding box envelopes.

Can this please get bumped up the development priority list.  It would be highly appreciated by many geospatial developers.","Dec 03 2011 02:55:58 AM UTC;p.kennedy@fugro.com.au;Hi Nicholas,
any update on your progress?  i would be happy to contribute dev/test resources if this looks promising.
","Aug 31 2014 06:00:12 PM UTC;radoslav;Hi there,

Could someone please give some sort of a progress update? Is this feature something that you guys plan to release in 2014/2015? This is an essential element for many geo-based apps and it would be really helpful if you guys could just give us a general idea of where is RTree indexing on the roadmap for you.

Thanks in advance and cheers!",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
add support for $elemMatch-like semantics in restrictSearchWithMatch of $graphLookup,SERVER-29735,395889,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-query-optimization,futurist,futurist,Jun 20 2017 02:54:35 AM UTC,Nov 14 2020 06:44:41 PM UTC,Feb 17 2021 11:15:21 AM UTC,,,,,,Backlog,Aggregation Framework,,,,0,usability,,,,,"*restrictSearchWithMatch* of *$graphLookup* with array not work when search into array element.
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,6.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2017-06-20 19:02:21.0,114652800,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,craig.homa(craig.homa),Sat Jul 01 02:42:02 UTC 2017,,,,,,,,,,,,,,asya(asya),backlog-query-optimization(JIRAUSER1257108),david.storch(david.storch),futurist(futurist),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i1rdp3:",,,,,,,"0|i00x4f:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i1rbsv:","Jun 23 2017 08:47:15 PM UTC;david.storch;Hi [~futurist],

Thanks for this issue report. From what I can tell, this query is working as designed. Let's just take the example of what happens when the document \{id: 2\} passes through the {{$graphLookup}} stage.

First, {{$graphLookup}} will evaluate the {{startsWith}} value. In this case, {{startsWith}} evaluates to 2. This value is used to seed the breadth-first search. The system will look for documents in the {{from}} collection for documents whose {{connectToField}} has a value of 2, and will filter out documents based on the {{restrictSearchWithMatchCondition}}. That is, the system will internally issue the following query against the {{ooo}} collection:

{code}
> db.ooo.find({""to.id"": 2, ""to.valid"": true});
{ ""_id"" : ObjectId(""594d7b5df3b4dbe4b93e3045""), ""id"" : 1, ""to"" : [ { ""id"" : 2 }, { ""id"" : 4, ""valid"" : true } ] }
{code}

Since this document matches, it appears in the {{as}} field (""relation""). The behavior does not change when you remove the {{restrictSearchWithMatch}} condition because the internally issued query still matches the same document:

{code}
> db.ooo.find({""to.id"": 2});
{ ""_id"" : ObjectId(""594d7b5df3b4dbe4b93e3045""), ""id"" : 1, ""to"" : [ { ""id"" : 2 }, { ""id"" : 4, ""valid"" : true } ]
{code}

If I understand correctly, you wish the internally issued query to apply {{$elemMatch}}-like semantics:
{code}
> db.ooo.find({to: {$elemMatch: {id: 2, valid: true}}});
// No results.
{code}

In other words, an {{id}} of 2 and {{value: true}} must appear in the same array element in order for the document to match. This functionality is currently not supported by {{$graphLookup}}. I am going to move this ticket into ""waiting for user info"" state; please confirm whether or not this is the functionality you need so that I can convert this ticket into the appropriate feature request. Also, let me know if you have any questions about my explanation.

Best,
Dave","Jun 24 2017 12:22:37 AM UTC;futurist;Hi, David,

Thanks for the answer.

{quote}
an id of 2 and value: true must appear in the same array element
{quote}

Is just what I'm thinking of the *$graphLookup* working, since the reasonable steps of above example:

 when the document {color:green}{id: 2}{color} passes through the $graphLookup stage

1. *$graphLookup* will perform {color:blue}find({'to.id': 2}){color}, which will find below document:

{code:javascript}
{ id:1, to:[{id:2}, {id:4, valid: true}]}
{code}

2. then after that, *restrictSearchWithMatchCondition* should take into account of the graph connection, since array element {color:green}{id:4, valid: true}{color} is not connected in *connectToField*, it should not appear in any further condition match. In other words, *restrictSearchWithMatchCondition* should only be *restrict* match from the already connected array elements only, not a simple find *again* query: {color:blue}find({""to.id"": 2, ""to.valid"": true}){color}, which will extend the connection, not a *restrict*.

Below

{code:javascript}
{$elemMatch: {id: 2, valid: true}}
{code}

is the right behavior, I believe.



","Jun 26 2017 07:27:19 PM UTC;david.storch;Thanks for the additional info, [~futurist]! I don't think the system currently supports this behavior. I am going to convert this report into a feature request and send it to the Query Team for triage.","Jun 27 2017 04:47:31 PM UTC;asya;In current version, there is a workaround possible using ""views"" - a view is defined via a pipeline and you can create a view that only contains valid relation entries.

Create view with only {{valid:true}} entries:
{noformat}
db.createView(""oooview"", ""ooo"", 
  [ 
       {$match:{""to.valid"":true}},
       {$addFields:{to:{$filter:{input:""$to"",cond:{$eq:[""$$this.valid"",true]}}}}}
  ]
)
{ ""ok"" : 1 }
db.oooview.find({},{_id:0})
{ ""id"" : 1, ""to"" : [ { ""id"" : 4, ""valid"" : true } ] }
{ ""id"" : 3, ""to"" : [ { ""valid"" : true } ] }
{noformat}

Now you would omit the restrictWithMatch condition and just do:
{noformat}
db.ooo.aggregate([
   {$graphLookup:{
       startWith:'$id',
       from:'oooview',
       connectFromField:'id',
       connectToField:'to.id',
       as:'relation'
   } }, 
   {$project:{_id:0,'relation._id':0,'relation.to':0,to:0}}
])
{ ""id"" : 1, ""relation"" : [ ] }
{ ""id"" : 2, ""relation"" : [ ] }
{ ""id"" : 3, ""relation"" : [ ] }
{noformat}
","Jun 30 2017 01:24:37 AM UTC;futurist;@asya, your solution of *createView* is very good, now running in the project with no problem. Thank you! However, it's just a *workaround*, using *restrictSearchWithMatchCondition* is the best choice.


","Jul 01 2017 02:42:02 AM UTC;asya;Absolutely agreed, as creating a new view is not always feasible, but I'm glad the workaround is helping you until a full solution can be implemented. ",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Write USDT tools around lock contention,SERVER-42480,878830,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-server-servicearch,nathan.brown,nathan.brown,Jul 29 2019 08:46:29 PM UTC,Nov 12 2020 07:15:48 PM UTC,Feb 17 2021 11:15:21 AM UTC,,,,,,4.3 Desired,,,,,0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,49075200,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,ratika.gandhi(ratika.gandhi),2019-07-29 20:46:29.0,,,,,,,,,,,,,,backlog-server-servicearch(backlog-server-servicearch),nathan.brown(nathan.brown),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i413gv:",,,,,,,"0|i02ulr:",9223372036854775807,,,,,,,,,,,,Dev Tools 2019-08-12,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i411kn:",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Implement any MatchExpressions produced in SERVER-39943 in SBE,SERVER-52745,1538454,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-query-execution,charlie.swanson,charlie.swanson,Nov 10 2020 08:51:43 PM UTC,Nov 11 2020 03:10:27 PM UTC,Feb 17 2021 11:15:21 AM UTC,,,,,,Backlog,Aggregation Framework,Querying,,,0,,,,,,"In SERVER-39943 we anticipate adding some expressions to ensure certain queries can be indexed. For example, we will likely need a new comparison MatchExpression which does not have type bracketing semantics to represent {{{$expr: {$lt: [x, y]}}}} This ticket tracks the work to implement these new expressions in SBE.",,,,,,,,SERVER-39943,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2020-11-10 21:24:02.0,8467200,<s><a href='https://jira.mongodb.org/browse/SERVER-39943'>SERVER-39943</a></s>,,,,,,,PM-2104,,,,,,,,,,,,,,,,,,,,true,david.storch(david.storch),Tue Nov 10 20:53:27 UTC 2020,,,,,,,,,,,,,,backlog-query-execution(JIRAUSER1257109),charlie.swanson(charlie.swanson),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i74rsn:",,,,,,,"0|i6yzg7:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i74pw7:","Nov 10 2020 08:53:27 PM UTC;charlie.swanson;[~bernard.gorman] and [~david.storch] FYI I created this ticket to split out the QE work as we discussed. I don't recall whether we decided to add it to the duration expressions epic.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Investigate adding an option to shrink the oplog at startup,SERVER-49475,1407970,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-server-execution,geert.bosch,geert.bosch,Jul 13 2020 03:52:22 PM UTC,Nov 10 2020 03:45:04 AM UTC,Feb 17 2021 11:15:21 AM UTC,,,,,,Backlog,Replication,Storage,,,0,,,,,,"When a user finds themselves in an out-of-disk-space situation, recovering can be tricky: data can only be removed after startup is complete, but without provisioning extra storage, startup will likely again fail due to disk full as a result of replaying the oplog for recovery purposes.

Investigate whether shrinking the oplog at startup, potentially in combination with restarting as standalone and running {{compact}} on the oplog, would actually help users and would be worthwhile in terms of development cost.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,Fully Compatible,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,18835200,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,dbeng-pm-bot(dbeng-pm-bot),2020-07-13 15:52:22.0,,,,,,,,,,,,,,backlog-server-execution(backlog-server-execution),geert.bosch(geert.bosch),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i6ifwf:",,,,,,,"0|i00dtb:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i6idzz:",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Allow creation of sparse index over a regular index,SERVER-3150,17541,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-server-execution,jeff.yemin@mtvstaff.com,jeff.yemin@mtvstaff.com,May 26 2011 05:16:16 PM UTC,Nov 10 2020 03:40:40 AM UTC,Feb 17 2021 11:15:21 AM UTC,,1.8.1,,,,Backlog,Indexing,,,,1,,,,,,"Currently, if you already have a regular index for a given field, there is no way to make it sparse without first deleting the regular index.
But this is painful when upgrading from 1.6.x, because during the time that the sparse index is being created all your queries that rely on that index become table scans.

Would be better if there was a way to replace an existing index with a sparse one with no time during which neither index is usable.
",,,,,,,,,,,,SERVER-36202,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2019-02-25 16:43:54.0,307065600,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,dbeng-pm-bot(dbeng-pm-bot),2011-05-26 17:16:16.0,,,,,,,,No,,,,,,backlog-server-execution(backlog-server-execution),jeff.yemin@mtvstaff.com(jeff.yemin@mtvstaff.com),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i06oef:",,,,,,,"0|i00d8n:",6056,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i1c77z:",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Writable views,SERVER-10788,90094,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-server-execution,schwerin,schwerin,Sep 16 2013 06:33:56 PM UTC,Nov 10 2020 03:40:31 AM UTC,Feb 17 2021 11:15:21 AM UTC,,,,,,Backlog,Usability,,,,7,,,,,,"Supposing support for read-only views (SERVER-142), a desirable extension would be for the ability to construct writable views.  A set of rules for what constitutes a writable view would need to be constructed.",,,,,,,,,,,,SERVER-10650,SERVER-10787,SERVER-142,SERVER-27698,SERVER-3498,PM-1952,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2017-05-03 12:04:10.0,119664000,,,,,,,,,,,,,,,,,,,,,,,,,,,,false,dbeng-pm-bot(dbeng-pm-bot),Wed May 03 12:07:37 UTC 2017,,,,,,,,No,,,,,,schwerin(schwerin),backlog-server-execution(backlog-server-execution),milkie(milkie),senthinil(senthinil),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i045mv:",,,,,,,"0|i00d7z:",7251,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i17glj:","May 03 2017 12:04:10 PM UTC;senthinil;When do we expect fix for this issue?","May 03 2017 12:07:37 PM UTC;milkie;As of now, it's indefinite.  I see you have voted for this issue, and we take into account number of votes when deciding which new features to implement next.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Materialized Views,SERVER-27698,346113,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-server-execution,bugslayer,bugslayer,Jan 16 2017 11:43:07 PM UTC,Nov 10 2020 03:40:11 AM UTC,Feb 17 2021 11:15:21 AM UTC,,,,,,Backlog,Usability,,,,27,,,,,,"Materialized views would allow developers that use MongoDB to move data denormalization from the application layer to the database layer. While the process of materializing the view will require additional writes and slow the effective throughput of the database per write request, if used properly it should be a net wash in terms of real world performance as applications will not be sending additional requests to write the same denormalized data.

h3. Proposed Command

A simple expansion of the command for creating a view. A new materialized: <bool> option which defaults to false would allow the view to be created as a materialized view:

{code}
db.runCommand( { create: <view>, viewOn: <source>, pipeline: <pipeline>, materialized: <bool> } )
{code}

h3. Proposed Behavior

* Materialized views exist on disk but cannot be written to by the user. Internally a materialized view is a normal collection that is maintained by MongoDB using a defined pipeline rather than maintained by writes from an application.
* Updates to the materialized view are not atomic. In other words, queries against the collection(s) that back(s) a materialized view may return results that are inconsistent with the results of the materialized view.
* Materialized views do not use the indexes or sharding of the underlying collection(s)
* Materialized views can be indexed and/or sharded like a normal collection
* The aggregation pipline for a materialized view must emit an _id
* Materialized views write the result of the pipeline as an upsert against _id
* When updating a document in the underlying collection the pipeline will only be run against the document being updated. To ensure correct results materialized views should only use operators that can properly work against a single document. Materialized views typically should not use pipeline stages that operate against a set of documents such as:
   * $limit
   * $skip
   * $group
   * $sample
   * $sort
   * $out
   * $bucket
   * $bucketAuto
   * $sortByCount
   * $count
 * The database should not enforce any limitation on the above commands because they may still be useful in connection with other stages such as $unwind.
 * Materialized views may use $lookup, however, updates against the joined collection will not update associated documents in the materialized view. Applications may force an update of associated materialized documents by forcing an update of the appropriate backing documents in the collection that the materialized view is based on.

h3. Other Considerations
 * It seems that the ability to update the definition of a materialized view would be extremely desirable, however, this could also be a monumentally expensive operation during which data on the collection would be in an inconsistent state. Ensuring consistency doubles the space requirements. If updates to the definition are allowed, it might make sense to allow the user to choose between consistency or an in-place strategy (inPlace: <bool>, default false).
 * I'm not sure how to handle the $match stage, especially in the case where a record matched, and so was materialized, and later does not match, and should be removed. The simplistic implementation could simply dictate that match is bad, and you should emit an empty record instead, but that seems messy. It may be that materialized views require an extra internal collection of some sort to store the relationships between the input document(s) and the output record(s). Such a collection might conceivably also be useful for allowing a strong materialization of records pulled in from $lookup.",,,,,,,,PM-764,,,,FREE-127451,,,,,,,,,,,,,,,,,,,,6.0,,,,,,,,,,,,,,,,,,,,,500A000000aNnozIAC,5002K00000d5iU1QAI,5002K00000dWflsQAC,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2017-01-17 18:02:50.0,15724800,<a href='https://jira.mongodb.org/browse/PM-764'>PM-764</a>,,,,,,,,,,,,,,,,,,,,,,,,,,,true,dbeng-pm-bot(dbeng-pm-bot),Tue Aug 18 22:02:17 UTC 2020,,,,,,,,,,,,,,backlog-server-execution(backlog-server-execution),pasette(dan@10gen.com),bugslayer(bugslayer),marcelnsquaredsoftware@gmail.com(JIRAUSER1255754),mark.agarunov(mark.agarunov),ramon.fernandez(ramon.fernandez),ravi.kumar.nagireddy@morganstanley.com(ravi.kumar.nagireddy@morganstanley.com),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i1iv1z:",,,,,,,"0|i00d6n:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i0mocn:","Jan 17 2017 06:02:50 PM UTC;mark.agarunov;Hi [~bugslayer],

Thank you for the detailed example. I've set the fixVersion to ""Needs Triage"" for this new feature to be scheduled against our currently planned work. Updates will be posted on this ticket as they happen.

Thanks,
Mark
","Dec 12 2018 07:31:39 AM UTC;ravi.kumar.nagireddy@morganstanley.com;Is there a timeline when this feature would be available?","Dec 20 2018 03:43:35 PM UTC;ramon.fernandez;[~ravi.kumar.nagireddy@morganstanley.com], this feature is in our backlog but unfortunately there's no concrete timeline for it at the moment. We'll post updates to this ticket as that changes in the future.

Thanks,
Ramón.","Dec 21 2018 04:42:14 AM UTC;ravi.kumar.nagireddy@morganstanley.com;﻿Thank you.
If it was implemented it would be good and helps developers a lot.

Ravi Kumar Nagireddygari   
Morgan Stanley | Corporate & Funding Technology   
7-8/F, Campus 6A, RMZ Ecoworld, Sarjapur | Marathahalli Outer Ring Rd, Devarabisana Halli, Bengaluru East Taluk   
Bengaluru, 560103   
Phone: +91 80 6104-2021   
Mobile: +91 7 7022-22170   
Ravi.Kumar.Nagireddy@morganstanley.com   
   
   
Be carbon conscious. Please consider our environment before printing this email.    
   
","Aug 18 2020 09:38:33 PM UTC;marcelnsquaredsoftware@gmail.com;+1 to this. Not being able to do an SQL equivalent materialised view makes dealing with datasets spanning millions of records a real issue especially when we are dealing with down stream clients having to wait for complex aggregate queries to complete on large data sets (or even hit HTTP timeouts due to the query taking too long).

In cases where 100% accuracy isn't required being able to instantly query even old data would be preferable if the result returned near instantaneously.

 

M.

 ","Aug 18 2020 10:02:17 PM UTC;pasette;[~marcelnsquaredsoftware@gmail.com], I wonder if using a pattern of ""[on-demand materialized views|https://docs.mongodb.com/manual/core/materialized-views/]"" (which leverages the $merge functionality released in v4.2) would apply to your use case.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
truncate command to provide removal of all documents without removal of metadata,SERVER-1773,13065,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-server-execution,jalava,jalava,Sep 10 2010 08:05:24 PM UTC,Nov 10 2020 03:39:40 AM UTC,Feb 17 2021 11:15:21 AM UTC,,1.6.2,,,,Backlog,Performance,,,,4,QFB,,,,,"Our environment requires possibility to remove all documents from collection without reseting indexing and sharding settings.

This is because we use staggered collections to manage throw away data which is inserted at thousands of documents per second.

Using normal remove is very slow when you have millions of documents (we were clocking about 50k documents per second on collection with 150M documents) and you are getting inserts to the collection at the same time.

Drop is fast but requires setting up sharding , shardkeys and indexing everytime collection is dropped.  removeAll() would be same as drop but would retain indexes and other metadata.",,,,,,,,,,,,PM-1952,,,,,,,,,,,,,,,,,"Aug 17 2018 07:52:05 PM UTC;ben.judd;server1773.patch;https://jira.mongodb.org/secure/attachment/194213/server1773.patch",,,3.0,7.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2010-09-26 04:47:14.0,82425600,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,dbeng-pm-bot(dbeng-pm-bot),Mon Jul 09 04:06:17 UTC 2018,,,,,,,,No,,,,,,asya(asya),backlog-server-execution(backlog-server-execution),ben.judd(ben.judd),eliot(eliot),jalava(jalava),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i074kf:",,,,,,,"0|i00d4n:",6223,,,,,,,,,,,,Storage NYC 2018-07-16,Storage NYC 2018-07-30,Storage NYC 2018-08-13,Storage NYC 2018-08-27,Storage NYC 2018-09-10,Storage NYC 2018-09-24,Storage NYC 2018-10-08,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i09lin:","Sep 26 2010 04:47:14 AM UTC;eliot;Called truncate in other systems","Jul 06 2018 03:29:53 PM UTC;ben.judd;[~asya] What is the preferred behavior when the collection/db specified do not exist, an ok:1, with a message letting them know _or_ should the command fail?","Jul 09 2018 04:06:17 AM UTC;asya;I think we should be consistent with remove and drop for non-existent collections/dbs. ",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
partitioning,SERVER-2097,13699,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,michael.gargiulo,suno,suno,Nov 15 2010 06:15:05 PM UTC,Nov 10 2020 03:38:46 AM UTC,Feb 17 2021 11:15:21 AM UTC,,,,,,Backlog,Performance,Storage,,,23,,,,,,"Like currently in existence RDBMSs provide so-called
partitioning, it would also be nice to have this with MongoDB.

If not partitioning then at least something akin like clustering
similar data on disk in order to reduce seeks (might become less
of an issue the more SSD penetrates the storage market).

 - http://wiki.postgresql.org/wiki/Table_partitioning
 - http://groups.google.com/group/mongodb-user/browse_thread/thread/0ef4bc96d4fea3f0/9bf96a61ae95c078",,,,,,,,,,,,FREE-139314,,,,,,,,,,,,,,,,,,,,5.0,,,,,,,,,,,,,,,,,,,,,500A000000XUasMIAT,500A000000a89keIAA,500A000000UaZtZIAV,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2010-11-15 18:16:45.0,53222400,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,dbeng-pm-bot(dbeng-pm-bot),Tue Jun 11 15:05:41 UTC 2019,,,,,,,,No,,,,,,andy222(andy222),dimamatz(dimamatz),eliot(eliot),giri.saranu@panerabread.com(giri.saranu@panerabread.com),suno(suno),michael.gargiulo(michael.gargiulo),TattiQ(tattiq),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i070lz:",,,,,,,"0|i00d1b:",6602,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i0acqn:","Nov 15 2010 06:16:45 PM UTC;eliot;partitioning is a very specific thing","Oct 28 2015 07:20:30 AM UTC;andy222;This feature is a must-have for us. We are collecting time-based data (lots of it) in single node installations and we want user to have control over data life span (how old data is retained). Ordinary remove() is too slow for us. 

Two currently available solutions in MongoDB are TTL and capped collections, neither of which are appropriate in our case:

  - TTL still removes record-by-record. While app doesn't have to do that, MongoDB server still suffers performance problems. Also, we want the user to be able to change this time whenever he wishes.
  - capped collections don't give any guarantee as to the time frame that will be retained.

This is a good overview of options available: https://dzone.com/articles/storing-time-series-data

Compression (which was not supported back then by MongoDB) and partitioned collections were the reasons we migrated to TokuMX: https://www.percona.com/blog/2014/05/29/introducing-partitioned-collections-for-mongodb-applications/
However since being acquired by Percona there was little activity on their front so we will probably have to migrate back to MongoDB (if we can) or elsewhere.

When making such system, it would be nice if one could convert existing tables to partitioned ones without migration. TokuMX doesn't allow that (you need to create new collection).

Do you have any plans on supporting partitioned collections?","Aug 11 2017 07:27:32 PM UTC;giri.saranu@panerabread.com;We are looking for partitioning at collection due to the size of the our collection data size. If the partitioning feature doesn't support in Mongo, we might have to look into some other databases like Postgres. ","Jul 05 2018 06:19:54 AM UTC;TattiQ;Hi guys, we also would like mongo to be able to partition collections. Any idea about the eta ? Is it on the roadmap at all? 

 

Thanks!","Jun 11 2019 03:05:41 PM UTC;dimamatz;Hello Team!

We're also very interesting in this feature as we're going to keep historical data in MongoDB and want to collect them on a daily basis.

Could you please share your vision and plans regarding this feature?",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Allow wildcard indexes to be compounded with preceding fields,SERVER-48570,1370909,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-query-optimization,ralf.strobel,ralf.strobel,Jun 03 2020 04:26:49 PM UTC,Nov 06 2020 02:55:09 PM UTC,Feb 17 2021 11:15:21 AM UTC,,,,,,Backlog,Indexing,,,,6,,,,,,"[Wildcard Indexes|https://docs.mongodb.com/master/core/index-wildcard/] currently do not support compounding in any fashion. Given the way they are implemented, it seems logical that no additional compound field should follow the wildcard part. However, a preceding compound field should not violate the premises of wildcard indexing and would support additional use cases.

Consider a collection containing polymorphic documents that share a common ""type"" field but may otherwise contain varying content fields...
{code:javascript}{
    ""_id"": <ObjectId>,
    ""type"": <int>,
    ""content"": {
        ""field1"": <string>,
        ""field2"": <string>
        ....
    }
}
{code}
In such cases, many queries will want to match documents based on a content field, but only within a given target type. Hence it would be preferable to create the following index:
{code:javascript}db.coll.createIndex({ ""type"": 1, ""content.$**"": 1 }){code}
Which is currently not permitted and will be answered with a generic ""wildcard indexes do not allow compounding"" error message.

MongoDB currently scales better with few large collections and few indexes than it does with many small collections and many indexes (WT-5479). Given that one of the major advantages of MongoDB is that it is schema-free, building polymorphic collections seems like the natural way to go. More flexible wildcard indexes could provide key support in this regard.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,5.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2020-06-08 15:08:22.0,8812800,,,,,,,,PM-1646,,,,,,,,,,,,,,,,,,,,true,lguignard@splio.com(JIRAUSER1257530),Fri Nov 06 14:54:43 UTC 2020,,,,,,,,,,,,,,asya(asya),backlog-query-optimization(JIRAUSER1257108),carl.champain(carl.champain),lguignard@splio.com(JIRAUSER1257530),ralf.strobel(ralf.strobel),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i6c77r:",,,,,,,"0|i00r1z:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i6c5bb:","Jun 08 2020 03:08:22 PM UTC;carl.champain;Hi [~ralf.strobel],

Thank you for the report. 
We're passing this ticket along to the appropriate team for additional investigation. Updates will be posted on this ticket as they happen.

Kind regards,
Carl","Jun 09 2020 07:11:05 AM UTC;ralf.strobel;I just stumbled upon SERVER-28743, which effectively does something quite similar on a deeper storage level. Are there still plans to roll out this alternate storage mode and is it already compatible with wildcard indexes?","Jun 09 2020 03:43:30 PM UTC;asya;[~ralf.strobel] note that there is a workaround for cases where you want a leading field (like type or tenant id) before the wildcard subdocument index, it's described here: [https://www.mongodb.com/blog/post/wildcard-indexes-and-multitenant-deployments]

You can use a similar approach by making type a key name of the subdocument {{content}}

 ","Jun 10 2020 10:22:49 AM UTC;ralf.strobel;I will definitely give you some credit for coming up with this solution. But yeah, it is a workaround (to avoid the word ""hack""). This does not seem like a way I would actually like to re-schematize all of our customer databases.

Your solution might be workable in the situation with distinct tenants. But I intentionally used the word ""polymorphism"", as in there may actually be a complex system of types and subtypes or (traits), where some types may share certain fields while others don't. And yeah then you could go ahead and use explicit $or-Queries whenever you want a multi-type query and then pick the right sub-document from each result etc. But there it gets very messy very quick.

So no, my feature request still stands. :)","Nov 06 2020 02:54:43 PM UTC;lguignard@splio.com;This is required for any SaaS using MongoDB with a multi-tenant architecture and dynamic schema features. Really looking forward for this one. Thanks!",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Create log redaction fuzzer,SERVER-32112,465327,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-server-stm,judah.schvimer,judah.schvimer,Nov 29 2017 05:03:26 PM UTC,Nov 05 2020 04:52:11 PM UTC,Feb 17 2021 11:15:21 AM UTC,,,,,,Backlog,Logging,Testing Infrastructure,,,0,stm,,,,,Currently log redaction is only caught in code review and in a manual review at the end of each release. One automated way to look for unredacted strings would be to put a canary string like 'XXXXXXXXX' in places that we expect to be redacted and make sure that we don't see it in the logs. ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2017-12-19 21:22:09.0,99792000,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,judah.schvimer(judah.schvimer),Tue Dec 19 21:24:53 UTC 2017,,,,,,,,,,,,,,acm(acm),backlog-server-stm(backlog-server-stm),judah.schvimer(judah.schvimer),max.hirschhorn(max.hirschhorn@10gen.com),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i233uf:",,,,,,,"0|i28ybj:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i231y7:","Dec 19 2017 09:22:09 PM UTC;max.hirschhorn;[~acm], would you consider [DataFlowSanitizer|https://clang.llvm.org/docs/DataFlowSanitizer.html] too heavy-weight for this purpose? I'd be curious if we could somehow tag the memory that comes out of the storage engine in such a way that {{log()}} would fail on it.

One question that also came up during our triage meeting earlier today was whether Server engineers would benefit from being able to write a C++ unit test to affirm that the {{redact()}} function is being used in the log messages written by a particular function. (For example, by using a {{mongo::RamLog}} while running the test.) My impression is that Judah's request of trying to automate places where we're currently failing to redact contents of a log message is more useful.

CC [~pasette]","Dec 19 2017 09:24:53 PM UTC;acm;I think it is a cool idea, and may well be the right tool. I think it had been mentioned at one point when Jason and I were proposing implementing redaction via data-tainting, either at the language level or via tooling. We don't have any experience with it though, or know how to teach it what we want it to do.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Multiple out stages in aggregate,SERVER-28954,377302,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-query-optimization,paul.reed,paul.reed,Apr 25 2017 12:05:26 PM UTC,Nov 03 2020 07:18:12 PM UTC,Feb 17 2021 11:15:21 AM UTC,,,,,,Backlog,Aggregation Framework,,,,0,,,,,,"I would like to be able to use the $out pipeline embedded into the aggregation in multiple locations to snapshot the current output.


{panel:title=Example}

{noformat}
[stock] is made up like:
{ _id:1, type:'widgets', material:'metal', 	name:'item1', count:5 }
{ _id:2, type:'widgets', material:'metal', 	name:'item2', count:3 }
{ _id:3, type:'widgets', material:'wood', 	name:'item3', count:2 }
{ _id:4, type:'widgets', material:'wood', 	name:'item4', count:5 }
{ _id:5, type:'widgets', material:'plastic',name:'item5', count:6 }
{ _id:6, type:'casing', material:'metal', 	name:'item6', count:0 }
{ _id:7, type:'casing', material:'wood', 	name:'item7', count:1 }
{ _id:8, type:'casing', material:'plastic', name:'item8', count:9 }
{ _id:9, type:'casing', material:'plastic', name:'item9', count:2 }

db.stock.aggregate([
	{ $group:{ _id: { k1:'$type', k2:'$material' }, totalcount:{$sum:'$count'} } },
	{ $out:'group_type_material' },
	{ $group:{ _id: '$_id.k1', totalcount:{$sum:'$totalcount'} } },
	{ $out:'group_type' },
	{ $group:{ _id: null, totalcount:{$sum:'$totalcount'} } },
	{ $out:'group_all' },
])
{noformat}

which would result in collections of

{noformat}
[group_type_material]:

{ _id: { k1:'widgets', k2:'metal'}, totalcount:8 }
{ _id: { k1:'widgets', k2:'wood'}, totalcount:7 }
{ _id: { k1:'widgets', k2:'plastic'}, totalcount:6 }
{ _id: { k1:'casing',  k2:'metal'}, totalcount:0 }
{ _id: { k1:'casing',  k2:'wood'}, totalcount:1 }
{ _id: { k1:'casing',  k2:'plastic'}, totalcount:11 }


[group_type]:

{ _id: 'widgets', totalcount:21 }
{ _id: 'casing', totalcount:12 }


[group_all]:

{ _id: null, totalcount:33 }
{noformat}

{panel}

This would make this aggregation truly powerful in my opinion.
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,3.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2017-04-25 12:31:36.0,99100800,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,ted.tuckman(ted.tuckman),Wed Dec 27 21:08:22 UTC 2017,,,,,,,,,,,,,,asya(asya),backlog-query-optimization(JIRAUSER1257108),paul.reed(paul.reed),ramon.fernandez(ramon.fernandez),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i1o707:",,,,,,,"0|i00x0n:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i01dnb:","Apr 25 2017 12:09:23 PM UTC;paul.reed;ALSO - if I could have previewed this post before committing then I would have changed my formatting. 
OR - if I could edit this item then I would have changed my formatting after posting.

","Apr 25 2017 12:31:36 PM UTC;ramon.fernandez;Thanks for your feature request [~paul.reed], I'm sending it to the Query team for evaluation.

I've fixed this ticket's description for you. For future tickets, look for a blue rectangle on the bottom left corner of text windows (like ticket description) to preview. [Here's the JIRA formatting reference|https://jira.atlassian.com/secure/WikiRendererHelpAction.jspa?section=all] if you're curious about formatting options.

Regards,
Ramón.","Dec 27 2017 09:08:22 PM UTC;asya;Note that something similar can be done with $facet:
{noformat}
db.stock.aggregate([{$facet:{
   group_type_material:[{ $group:{ _id: { k1:'$type', k2:'$material' }, totalcount:{$sum:'$count'} } }], 
   group_type:[{ $group:{ _id: '$type', totalcount:{$sum:'$count'} } }], 
   group: [{ $group:{ _id: null, totalcount:{$sum:'$count'} } } ]
}}] )
{
	""group_type_material"" : [
		{
			""_id"" : {
				""k1"" : ""casing"",
				""k2"" : ""plastic""
			},
			""totalcount"" : 11
		},
		{
			""_id"" : {
				""k1"" : ""casing"",
				""k2"" : ""metal""
			},
			""totalcount"" : 0
		},
		{
			""_id"" : {
				""k1"" : ""widgets"",
				""k2"" : ""plastic""
			},
			""totalcount"" : 6
		},
		{
			""_id"" : {
				""k1"" : ""widgets"",
				""k2"" : ""wood""
			},
			""totalcount"" : 7
		},
		{
			""_id"" : {
				""k1"" : ""casing"",
				""k2"" : ""wood""
			},
			""totalcount"" : 1
		},
		{
			""_id"" : {
				""k1"" : ""widgets"",
				""k2"" : ""metal""
			},
			""totalcount"" : 8
		}
	],
	""group_type"" : [
		{
			""_id"" : ""casing"",
			""totalcount"" : 12
		},
		{
			""_id"" : ""widgets"",
			""totalcount"" : 21
		}
	],
	""group"" : [
		{
			""_id"" : null,
			""totalcount"" : 33
		}
	]
}
{noformat}
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Change facility for audit messages written to syslog,SERVER-18404,203210,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-server-security,andre.defrere,andre.defrere,May 11 2015 03:03:11 AM UTC,Oct 27 2020 04:33:21 AM UTC,Feb 17 2021 11:15:21 AM UTC,,3.0.2,,,,Backlog,Logging,Security,,,3,,,,,,"When writing the log to syslog, you have the ability to change the facility level for the messages written (with the syslogFacility config option).

When writing the audit log to syslog, there is no option to change the facility.  All messages are written to ""user"" at ""info"" level severity.

Being able to change the facility would allow users to write audit messages to other syslog destinations.",,,,,,,,,,,,DOCS-10991,,,,,,,,,,,,,,,,,,,,2.0,4.0,,,,,,,,,,,,,,,,,,,,5002K00000eAF7QQAW,5002K00000qdLUuQAM,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2015-05-11 11:46:53.0,59961600,,,,,,,,PM-1591,,,,,,,,,,,,,,,,,,,,true,,Mon Mar 25 15:49:22 UTC 2019,,,,,,,,,,,,,,andre.defrere(andre.defrere),acm(acm),schwerin(schwerin),backlog-server-security(backlog-server-security),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i02vjr:",,,,,,,"0|i03khz:",9223372036854775807,,,,,,,,,,,,Dev Tools 2019-01-28,Dev Tools 2019-02-11,Dev Tools 2019-02-25,Dev Tools 2019-03-11,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i0y6yf:","May 26 2015 05:07:54 PM UTC;schwerin;Using the syslog support in libc, one cannot set distinct identities or facilities within a single process.  As such, mongodb processes use the syslogFacility setParameter for both audit and diagnostic log messages.

Doing more requires us to use a different (non-standard) library for interfacing with syslog.","Mar 25 2019 03:49:22 PM UTC;acm;[~matt.lord] - Assigning to you as investigating to come to a conclusion about what we are going to do here, if anything.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Text search support for Hebrew language,SERVER-16803,178137,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-query-optimization,melkin@dbs-h.com,melkin@dbs-h.com,Jan 12 2015 07:54:42 AM UTC,Oct 23 2020 07:12:21 PM UTC,Feb 17 2021 11:15:21 AM UTC,,,,,,Backlog,Text Search,,,,4,,,,,,"Does text search support Hebrew language ?

Thank you

Michael",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,4.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2015-01-12 14:58:36.0,28425600,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,alice.neff(alice.neff),Wed Mar 25 09:35:20 UTC 2020,,,,,,,,,,,,,,backlog-query-optimization(JIRAUSER1257108),sinai.doron@gmail.com(sinai.doron@gmail.com),matt.kangas(matt.kangas@10gen.com),melkin@dbs-h.com(melkin@dbs-h.com),ofergr@matrix.co.il(ofergr@matrix.co.il),yonatan@alhatorah.org(yonatan@alhatorah.org),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i034c7:",,,,,,,"0|i00vnj:",156297,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i010pj:","Jan 12 2015 02:58:36 PM UTC;matt.kangas;Hi [~melkin@dbs-h.com],

As of MongoDB 2.6 we support 15 text search languages. Hebrew is not currently supported.
http://docs.mongodb.org/manual/reference/text-search-languages/#text-search-languages

I will update this ticket to make it a feature request for Hebrew support.
","Jul 07 2015 08:01:50 AM UTC;ofergr@matrix.co.il;Hello,

What is the status of this request?","Dec 29 2015 06:23:29 PM UTC;sinai.doron@gmail.com;Do you know when its scheduled for?","Mar 25 2020 09:35:20 AM UTC;yonatan@alhatorah.org;Hello,

I did a search in the MongoDB codebase, and it seems that the $text language support comes from an external library called ""libstemmer_c"". This library seems to be the C implementation of the Snowball stemmers, current website: [https://snowballstem.org/]

If this is true, then:

A) MongoDB should update it's copy of libstemmer, since it now contains (in addition to Danish, Dutch, English, Finnish, French, German, Hungarian, Italian, Norwegian, Portuguese, Romanian, Russian, Spanish, Swedish, Turkish) also the following new languages: Arabic, Basque, Catalan, Greek, Hindi, Indonesian, Irish, Lithuanian, Nepali, Tamil

B) Can someone explain how to make a Hebrew stemmer?",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Add support for Ukrainian language in text search.,SERVER-15914,166897,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-query-optimization,asya,asya,Nov 02 2014 06:40:10 PM UTC,Oct 23 2020 07:11:24 PM UTC,Feb 17 2021 11:15:21 AM UTC,,,,,,Backlog,Text Search,,,,5,,,,,,"Add support for Ukrainian language
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Jan 06 2015 09:54:19 PM UTC;Ciget;stop_words_ukrainian.txt;https://jira.mongodb.org/secure/attachment/61044/stop_words_ukrainian.txt",,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2015-01-06 21:54:19.0,192931200,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,alice.neff(alice.neff),Tue Jan 06 21:54:19 UTC 2015,,,,,,,,,,,,,,asya(asya),backlog-query-optimization(JIRAUSER1257108),Ciget(ciget),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i039fr:",,,,,,,"0|i00vlb:",145829,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i0ynzj:","Jan 06 2015 09:54:19 PM UTC;Ciget;This is list of stop words for Ukrainian lang",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Add number of chunks and estimated routing table size to serverStatus metrics,SERVER-50944,1474732,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-server-sharding,dmitry.agranat,dmitry.agranat,Sep 15 2020 12:17:27 PM UTC,Oct 22 2020 02:52:31 PM UTC,Feb 17 2021 11:15:21 AM UTC,,,,,,Backlog,Diagnostics,,,,0,,,,,,"This information would better help us troubleshooting sharding related issues, especially related to memory consumption.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2020-09-15 21:12:58.0,13305600,,,,,,,,PM-1902,,,,,,,,,,,,,,,,,,,,true,ratika.gandhi(ratika.gandhi),2020-09-15 12:17:27.0,,,,,,,,,,,,,,backlog-server-sharding(backlog-server-sharding),dmitry.agranat(dmitry.agranat),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i6tuy7:",,,,,,,"0|i6ohiv:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i6tt1r:",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
SPIKE: Selected tests should be applied to multiversion tasks,SERVER-49460,1406916,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-server-dag,lydia.stepanek,lydia.stepanek,Jul 10 2020 09:59:37 PM UTC,Oct 21 2020 08:16:02 PM UTC,Feb 17 2021 11:15:21 AM UTC,,,,,,Backlog,Testing Infrastructure,,,,0,,,,,,"Currently, selected tests does not generate mutiversion tasks. (See https://jira.mongodb.org/browse/SERVER-48105 for more info.)

As a server engineer,
I should know that changes I make to src files will result in the related multiversion tasks being generated,
so that my patch only runs the tasks that are related to my code changes.

AC:
* [MULTIVERSION_TASK_PATTERN|https://github.com/mongodb/mongo/blob/83a0479dbb78f73366a91b4afe9da44f6f5e9cf0/buildscripts/selected_tests.py#L63-L69] is no longer used to exclude multiversion tasks from being generated
* selected-tests alias in evergreen no longer pulls in multiversion tasks",,,,,,,,,,,,SERVER-48105,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2020-07-17 14:19:30.0,19094400,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,brooke.miller(brooke.miller),2020-07-10 21:59:37.0,,,,,,,,,,,,,,backlog-server-dag(backlog-server-dag),lydia.stepanek(lydia.stepanek),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i6i9e7:",,,,,,,"0|i01ddr:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i6i7hr:",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Auto-generated short-lived collections for output from $merge or $out,SERVER-5149,31878,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-query-execution,acm,acm,Feb 29 2012 10:48:52 PM UTC,Oct 21 2020 06:33:43 PM UTC,Feb 17 2021 11:15:21 AM UTC,,1.8.0,2.0.0,,,Backlog,Aggregation Framework,MapReduce,,,1,query-44-grooming,,,,,"It would be useful to have the ability to store results from your computations in the server for future inspection in a way that would go away after some period of time (perhaps when the session ends?) without having to choose unique names.

h3. Original Description
With mongo 1.8 the ability to have a mapreduce write its results to a temporary table was removed, according to the documentation here: http://www.mongodb.org/display/DOCS/MapReduce#MapReduce-Outputoptions.

This means that clients that want 'one shot' MR operations are forced to either use inline output, or to manage the naming, creation, and reaping of the output collection. If, as is *very often* the case, the total data size that will be created exceeds the current database maximum BSON object size (16MB these days), then you cannot use inline, and the only option is for the client to manually manage the lifetime of the output collection. However, this is not as easy as it sounds:

- The client must have some mechanism for generating unique names for the output collection. While not necessarily hard, this is annoying. It also creates a risk that less than diligent authors will pick a 'unique' name like 'my_secret_output_collection', which then of course will inevitably collide months later when some other genius picks the same 'unique' name. However, the database server can easily construct non-colliding temporary collection names and communicate the name back to the client in the MR response. Even if you don't restore the server side reaping feature, the server could still synthesize a safe unique name for you.

- The client needs to carry about the name of the output collection somewhere so that it can (try its best to) drop the collection later. This frustrates certain programming idioms like iterating the cursor from a coroutine/generator, since there now needs to be a post-iteration action that drops the collection.

- The client needs to drop the collection when it is done with it, but is unequipped to reliably do so. No matter how many exception handlers, signal handlers, finalizers, or redundant power supplies and switches you pollute your code and infrastructure with, there is always a way that the client fails to honor its obligation to drop the collection. On the other hand, the mongodb server is in a uniquely qualified position to reap stale temporary collections, since it can easily detect that the client responsible for the collection has gone away and that it should now reap the useless collection. In addition, the server can much more easily work around the sort of failure modes noted above, since in the event of its own crash, it should easily be able to identify temporary collections on restart/shutdown and destroy them.

Overall, I'm perplexed why this very useful feature was removed. It takes away something that the server should be easily able to do with very high reliability, and forces clients to make complex (but ultimately hopeless) efforts to re-implement the feature themselves.
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,4.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2012-03-01 05:07:08.0,34128000,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,craig.homa(craig.homa),Sat Jan 18 21:33:31 UTC 2020,,,,,,,,No,,,,,,acm(acm),asya(asya),backlog-query-execution(JIRAUSER1257109),charlie.swanson(charlie.swanson),eliot(eliot),pawel.terlecki(pawel.terlecki),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i060pb:",,,,,,,"0|i00z1r:",6057,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i1izin:","Mar 01 2012 05:07:08 AM UTC;eliot;The major problem was that the previous incarnation didn't make a lot of sense as designed.

Agree it is a good feature, just not sure on all the design issues at this point.","Mar 22 2019 05:35:38 PM UTC;asya;[~acm] is this an issue? the way mr (and agg) output now it's written to a temp collection that's then renamed, so is that sufficient?  I'm not sure what pre 1.8 behavior was.
","Aug 22 2019 08:35:33 PM UTC;charlie.swanson;Converting this to a feature request since it's been long enough since that release that I wouldn't consider this a bug anymore.","Jan 18 2020 09:33:31 PM UTC;pawel.terlecki;Support for temp collections is fundamental if one wants to Mongo to act as a node in any cross-database federated processing. For example, ETL in Alteryx, Tableau and basically any other cross-db processing engine is the only way to move piece of data across databases, e.g. for joins. Without this feature data from mongo will always need to be extracted fully for processing, even if most data in the scenario is in Mongo. This will happen in live federated models involving mongo and other databases in Tableau. Some of data blending scenarios will be completely unavailable.

In addition, large filters are often externalized by temp collections for fast filtering. E.g. Tableau is extremely slow against data sources that do not support temp tables. In our case, we first need to fix our lookups with SBE to actually be faster in this scenario.

 ",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Provide a way to get notification when results of a query change,SERVER-31720,451102,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-query-execution,mitar,mitar,Oct 25 2017 07:23:25 PM UTC,Oct 21 2020 06:32:52 PM UTC,Feb 17 2021 11:15:21 AM UTC,,,,,,Backlog,Querying,,,,8,,,,,,"If one wants to observe changes to a set of documents matching a query, you can use fullDocument to match on document's content and get notifications for changes made to those documents. But this is limited in use by the fact that there is no notification when a document stops being matched by the query. See https://github.com/meteor/meteor-feature-requests/issues/158#issuecomment-339376181 of the issue as we are investigating how to use Change Streams to support reactivity in Meteor.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,14.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2017-10-26 15:37:22.0,68428800,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,craig.homa(craig.homa),Mon Dec 17 21:05:54 UTC 2018,,,,,,,,,,,,,,alyson.cabral(alyson.cabral),asya(asya),backlog-query-execution(JIRAUSER1257109),charlie.swanson(charlie.swanson),kelsey.schubert(thomas.schubert),mitar(mitar),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i20ojr:",,,,,,,"0|i00y5r:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i20mnj:","Oct 26 2017 03:37:22 PM UTC;alyson.cabral;Hi Mitar,

I'm updating the type of this ticket to an 'improvement' as opposed to a 'bug'. We definitely want to enable seamless and straightforward ways to specify active queries in future versions of MongoDB. However, the 3.6 change streams design favors the resumability of change streams over this functionality. I want to point out that there are ways to satisfy these use cases with MongoDB 3.6, but we recognize that the approaches are not ideal. I linked my video presentation and Jesse's blog post below for further details (also linked on the github thread). 

In order to automatically notify listening applications once a query is no longer satisfied, we would need to keep around a pre-image in addition to the post-image of each operation you can resume from, either doubling the size or halving the operation capacity of the oplog. Another approach could be requiring some kind of pre registration of streams to minimize expense. While your desired functionality is not in the first version of Change Streams we are releasing, these are areas of feature development we are actively considering. We expect to learn a lot from the communities that adopt change streams and want work together on building out the feature development roadmap. 

Thanks for passing on thread to us. As you guys integrate with and develop against change streams, please reach out with any questions, concerns, or points of feedback. If you have specific examples of change stream use cases you want to support, I can help recommend the best approaches.

Aly Cabral

[1] [Video: Using Change Streams to Keep Up with Your Data|https://explore.mongodb.com/mongodb-local-san-francisco/using-change-streams-to-keep-up-with-your-data]
[2] [Blog: New Driver Features for MongoDB 3.6|https://emptysqua.re/blog/driver-features-for-mongodb-3-6/]","Nov 06 2017 09:52:53 AM UTC;mitar;Thanks for the links. I think I have seen those.

So our main use case is simply to reactively follow a query. But I must say that I do not understand why you would have to keep preimage around? If I make a query like {language: 'english'}

The main issue from our experience comes when you also want to have sorting and limiting, but those basic queries should be pretty easy to detect? If there comes a change to language field which is not english, you know that you have to notify a listener that _id got removed. If change is to english, you notify that it has been added.","Nov 13 2017 01:56:29 PM UTC;alyson.cabral;Hi Mitar,

You guys offer this functionality today by tailing the oplog, right? How do you do this?

When an update happens to a document where {language : 'english'} --> {language : 'german'} the oplog only stores the new values not the values that were replaced. I imagine in order to notify on documents that no longer satisfy the query you must keep around a cache of pre-images with the old values. In order to do this on the core server, we would have to build something similar.

Aly ","Mar 23 2018 05:58:53 PM UTC;kelsey.schubert;Hi [~mitar],

We haven’t heard back from you for some time, so I’m going to mark this ticket as resolved. If this is still an issue for you, please provide additional information and we will reopen the ticket.

Regards,
Kelsey","Mar 23 2018 06:06:53 PM UTC;mitar;Ah, yes. Sorry. To my understanding, we keep around the cache of preimages. We can then also notify users of a change between old and new value.

But for this API, I am realizing that I think maybe the same thing could be achieved by opening two change stream requests. One with positive query and one with its negation. When a document ID appears in the second stream, you know it was removed from the first.

So maybe this is something which could be internally handled by MongoDB in this way?","Mar 24 2018 02:09:20 AM UTC;asya;I think the solution should be in one change stream but it should be watching the mutable field for *any* changes, which for an update operation means matching if it's in the $set document (with $exists:true) or whether it's in the $unset array (so that document can be removed when the field is unset as it will no longer match whatever the value/threshold is).

In other words, rather than watching for \{x:{$gt:5\} and \{x:\{$lte:5\}\} just watch for \{x:\{$exists:true\}\} in $set but if x can be unset also include $unset:""x"" unoined (via $or) in the same match condition.","Mar 28 2018 08:23:31 AM UTC;mitar;I think the issue here is that we hope to use MongoDB Change Stream to get changes for a particular (and all types of) Mongo queries. Currently the easiest way to do so is by putting the query into $match pipeline against full document. We would not to have to parse queries ourselves and convert it in a way you are mentioning above. I am also not sure if more complicated queries can really be converted in this way.

Ideally, API would be something like collection.find({...}).watch() to start getting all changes for documents matching a query and when they stop matching a query. Is there a simple way to match this to the existing API? I do not see it.","Mar 29 2018 05:55:14 AM UTC;asya;There is not a way to do this because that was not an intended use case for change streams.

We hope to implement support for materialized views some time in the future and are keeping this use case in mind - so one possibility is it will be possible to watch for changes on materialized view (which will report inserts when documents start matching the query and deletes when documents stop matching).

This is not something change streams the way it's design now can do.

I'm going to convert this ticket to a new feature request to have this (or equivalent) functionality.
","Apr 09 2018 10:29:59 PM UTC;mitar;But would those materialized views be scalable? I think current main issue is that change streams are already limited in number of concurrent streams you can open. Now if for each query one would have to make a materialized view and then change stream on top of that view, this could become a hit on performance.","Sep 14 2018 09:55:06 PM UTC;asya;[~mitar] sorry, I missed your question earlier.

If you could provide several examples of such queries so I can think about whether there are efficiency issues when trying to address them, that would help.

 ","Dec 06 2018 06:02:04 PM UTC;asya;I think this is a duplicate  of SERVER-2150 no?

 ","Dec 06 2018 06:13:11 PM UTC;charlie.swanson;Looks like a duplicate to me! That old one could use some of the references to change streams here - I think they're helpful for the context of why this isn't just change streams.","Dec 06 2018 06:55:13 PM UTC;mitar;Seems like the same feature request, but yes, now things changed much more so this could be seen only as a feature request on top of change streams, or materialized views.

@asya: Sorry for not replying back, but there is really no set of queries one would be interested in. Frameworks like Meteor allow one to observe any type of queries in a reactive manner. So the question is how we could implement this natively using MongoDB instead of having to observe oplog or use change streams but then still cache all documents from the query in the server-side of the app as well, to detect deletions, reorderings and other aspects of changes to the query which is not really possible currently with change streams. Ideally, this would all be provided by MongoDB who has much better grasp of the query, indexes used, and knows well when something changed.","Dec 17 2018 09:05:54 PM UTC;asya;I've decided to close the old ticket in favor of this one (as a duplicate) because this one has more context that current and relevant to the discussion of this feature, and leave this ticket as the one tracking the work that would be necessary to solve this request.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Intra-query parallelism,SERVER-5088,31528,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-query-execution,pasette,cwestin,Feb 25 2012 12:19:04 AM UTC,Oct 21 2020 06:32:42 PM UTC,Feb 17 2021 11:15:21 AM UTC,,,,,,Backlog,Querying,,,,16,,,,,,"Certain query execution stages could benefit from parallelism. For instance, the SORT stage could use a multi-threaded algorithm, or IXSCAN could scan several index ranges in parallel.",,,,,,,,,,,,PRODUCT-172,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,5002K00000llALGQA2,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,283392000,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,craig.homa(craig.homa),2012-02-25 00:19:04.0,,,,,,,,No,,,,,,backlog-query-execution(JIRAUSER1257109),pasette(dan@10gen.com),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i061g7:",,,,,,,"0|i00u47:",6323,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i0u1mf:",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
parallelize aggregating operations ($group and $sort),SERVER-5091,31531,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-query-execution,pasette,cwestin,Feb 25 2012 12:21:22 AM UTC,Oct 21 2020 06:32:39 PM UTC,Feb 17 2021 11:15:21 AM UTC,,,,,,Backlog,Aggregation Framework,,,,21,optimization,performance,,,,"If we could scan multiple underlying extents in parallel, we could parallelize some of the aggregation operations in aggregation pipelines.  The code that would combine the results of smaller parallel tasks that results could be used in both mongos and within mongod when parallel cursor scans are available.
",,,,,,,,SERVER-5088,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,283392000,<a href='https://jira.mongodb.org/browse/SERVER-5088'>SERVER-5088</a>,,,,,,,,,,,,,,,,,,,,,,,,,,,true,craig.homa(craig.homa),2012-02-25 00:21:22.0,,,,,,,,No,,,,,,backlog-query-execution(JIRAUSER1257109),pasette(dan@10gen.com),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i061ev:",,,,,,,"0|i00u4f:",4808,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i01dsn:",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Allow mapreduce Javascript code to perform HTTP requests,SERVER-14136,108374,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-query-execution,mr.bleez,mr.bleez,Jan 30 2014 03:46:08 PM UTC,Oct 21 2020 06:31:59 PM UTC,Feb 17 2021 11:15:21 AM UTC,,,,,,features we're not sure of,MapReduce,,,,0,,,,,,"Instead of relying on hadoop to do a mapreduce, it would be really useful to call c++ or java or python or ... libraries from inside mongo mapreduce, and a way to do this would be to allow to do get or post request to a localhost server

If I am not clear, imagine the following :
you have :
- a mongodb containing lots of pictures
- an awesome library in c++ that tells you if you are on the picture or not

you want to do :
- make a c++ server that runs on localhost:12345 and that takes a picture as an argument and returns true or false
- mapreduce over your library (or foreach) and call the server with your data

I was originally thinking of an EASY way to call external (c++/...) libraries from mongo without going through hadoop, so maybe you have other ideas ! As long as it can ease a lot of pain for users I am fine :)

Thanks !",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,3.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2014-06-02 19:38:20.0,211593600,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,craig.homa(craig.homa),Thu Jun 05 06:30:12 UTC 2014,,,,,,,,,,,,,,backlog-query-execution(JIRAUSER1257109),matt.kangas(matt.kangas@10gen.com),mr.bleez(mr.bleez),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i03j47:",,,,,,,"0|i010m7:",99181,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i0z0uv:","Jun 02 2014 07:38:20 PM UTC;matt.kangas;I think what you want is user loadable modules in the server which are callable from server-side javascript. The ticket for the first part is SERVER-8583.","Jun 03 2014 08:38:18 PM UTC;matt.kangas;I've updated the ticket title to better reflect your description.

You want to call external code from MongoDB Map/Reduce JS. Paths for achieving this include:
# Allow mapreduce JS to perform HTTP requests, as you describe.
# Some IPC mechanism besides HTTP.
# Dynamically loadable server modules, with an interface for calling them from mapreduce JS. SERVER-8583.

Enabling HTTP requests from server-side Javascript is challenging from a security perspective, so we are unlikely to pursue this course.","Jun 05 2014 06:30:12 AM UTC;mr.bleez;Exactly, any solution will do. Im not a pro of javascript so the only thing I could think of was a hack to call localhost. (is it a big security hack to allow only that ?)
I hope you can get that in soon !",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
$bucketInterval for grouping data in intervaled buckets (eg. time series),SERVER-37136,604844,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-query-optimization,danielfaust,danielfaust,Sep 14 2018 12:53:26 PM UTC,Oct 21 2020 06:28:10 PM UTC,Feb 17 2021 11:15:21 AM UTC,,,,,,Backlog,Aggregation Framework,,,,0,,,,,,"The following StackOverflow question and answer raises the issue and provides a solution for this feature.

[Resample Time Series Data using Javascript and Mongodb|https://stackoverflow.com/questions/24636209/resample-time-series-data-using-javascript-and-mongodb]

 

In addition of creating a bucket with predefined boundaries ($bucket), or one with autogenerated boundaries ($bucketAuto), it would be helpful to have a bucket stage which is given an upper and lower boundary, and the buckets are generated automatically at fixed, predefined intervals, for example

 

{{{}}
{{  $bucketInterval: {}}
{{    groupBy: '$timestamp',}}
{{    }}{{lower: ISODate(""2014-10-23T00:00:00.000+02:00""),}}
{{    }}{{upper: ISODate(""2014-10-24T00:00:00.000+02:00""),}}
{{    }}{{interval: 5*60*1000,}}
{{    }}{{output: {}}
{{      }}{{total:    \{$sum: 1},}}
{{      }}{{incoming: \{$sum: ""$i""},}}
{{      outgoing: \{$sum: ""$o""},}}
{{    }}{{}}}
{{  }}}
{{}}}

 

 ",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,4.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2018-09-14 20:36:00.0,75945600,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,craig.homa(craig.homa),Fri Sep 21 15:22:37 UTC 2018,,,,,,,,,,,,,,backlog-query-optimization(JIRAUSER1257108),danielfaust(danielfaust),david.storch(david.storch),nick.brewer(nick.brewer),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i2qq3z:",,,,,,,"0|i00ygn:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i2qo7r:","Sep 14 2018 08:36:00 PM UTC;nick.brewer;[~danielfaust] Thanks for your request - I've passed this along to our Query team for consideration. 

-Nick","Sep 18 2018 01:53:55 PM UTC;danielfaust;Also a growth direction would be useful. `growth: +ASC+|DESC`.

For example, if `lower = 0`, `upper = 17` and `interval = 5`, then
 * ASC – would result in [0-5),[5-10),[10-15),[15-17) and
 * DESC – in [0,2),[2,7),[7,12),[12,17)  (starts at 17 and goes down) ( or (0,2],(2,7],(7,12],(12,17] ? )","Sep 18 2018 01:58:58 PM UTC;danielfaust;And maybe also an `inclusiveUpper: true|+false+`, maybe also add `inclusiveLower : +true+|false`

For example, if `lower = 0`, `upper = 17` and `interval = 5`, then
 * ASC – would result in [0-5),[5-10),[10-15),[15-17*]* (17 included in last bucket) and
 * DESC – in [0,2),[2,7),[7,12),[12,17*]*","Sep 21 2018 03:22:37 PM UTC;david.storch;One nice way to achieve this might be to allow the existing {{$bucket}} stage to accept an expression, and expressing the boundaries with [{{$range}}|https://docs.mongodb.com/manual/reference/operator/aggregation/range/].",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Add an option to the $sample stage to specify weights to use in the sampling.,SERVER-22123,246506,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-query-optimization,m3t4lukas,m3t4lukas,Jan 11 2016 02:50:00 PM UTC,Oct 21 2020 06:28:03 PM UTC,Feb 17 2021 11:15:21 AM UTC,,3.2.0,,,,Backlog,Aggregation Framework,,,,1,grab-bag,stage,,,,"Specifying this option would prevent any optimized random cursor implementation from the storage engine, and would always use a top-k random sort, with the random value used to sort being multiplied by the specified weight.

For example:
{code:js}
db.example.aggregate([{
    $sample: {
        size: 100,
        weight: ""$myWeightField""
    }
}]);
{code}",,,,,,,,,,,,SERVER-30405,,,,,,,,,,,,,,,,,,,,12.0,,,,,,,,,,,,,,,,,Fully Compatible,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2016-01-11 15:30:00.0,159667200,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,craig.homa(craig.homa),Wed Jan 27 06:58:37 UTC 2016,,,,,,,,,,,,,,backlog-query-optimization(JIRAUSER1257108),charlie.swanson(charlie.swanson),m3t4lukas(m3t4lukas),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i02a4n:",,,,,,,"0|i00w4f:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i01hbz:","Jan 11 2016 03:30:00 PM UTC;charlie.swanson;Hi [~m3t4lukas],

I've filled in the description with what I believe you are asking for, let me know if this is not correct.

I've downgraded the priority of this ticket to the default priority. We don't use the priority field when prioritizing new features, so I've changed it to the default to avoid possible confusion in other search results.","Jan 12 2016 03:12:44 PM UTC;m3t4lukas;Hi Charlie,

what you assumed is correct. If you like you can assign it to me, as I am already working on it.
Thanks for filling me in on priorities. I just used that priority since I can't continue to work on my current project without that feature.","Jan 12 2016 07:08:20 PM UTC;charlie.swanson;[~m3t4lukas], I'm excited to hear that you are working on a patch!

If you're planning to submit a pull request to have this merged into the server project, here is a useful [guide to getting started|https://docs.mongodb.org/manual/contributors/]. In particular, you'll have to sign the [Contributor's Agreement|https://www.mongodb.com/legal/contributor-agreement]. Apologies if you already knew this, or already signed that. 

I'll assign this ticket to myself in the meantime, since I'll likely review your patch, and we can't assign tickets to people outside of MongoDB.

Let me know if there's anything I can do to help!","Jan 13 2016 08:54:50 AM UTC;m3t4lukas;Hi Charlie,

thanks for the heads up on contributing guidelines and the agreement. I was aware of the guideline but I had yet to sign the agreement. It's all done now.

Regards,
Lukas Wagner","Jan 13 2016 10:11:16 PM UTC;charlie.swanson;Hi Lukas,

Before we go forward with implementing this (sorry if you've already started), can you describe why you need this expression? What are you using it for?

We have some concerns that this may add some subtle complexity to aggregation's optimizer. This would be the first expression that would return different results depending on which order you called it in, or if you called it multiple times, which will make reasoning about which optimizations are safe to apply harder to analyze.","Jan 13 2016 10:42:01 PM UTC;m3t4lukas;Hi Charlie,

you'd need it for any kind of randomized access onto a collections data. Right now there is no possibility whatsoever. Let's use a real world example that is commonly used.
Imagine a database that has to serve ads. Now of course there are some criteria upon which ads to show to a user are chosen. There might be some kind of rating behind it. Now imagine you had several hundreds of ads you could serve to a user. What you'd need to do now is query them all, which uses up network resources, and randomize on the CDN stage. That is rather inefficient. If you would not randomize at all the user would see the same ads all the time which is not what you want since when the user did not click on the ad the first several times it was served to him it is highly unlikely he will in the near future. The most efficient way to do that would be to randomize and filtering upon randomization as early in the aggregation pipeline as possible. That would save on ram and it would in particular in that case save on networking resources (several hundred ads transferred from db to cdn server vs only the one needed [per request!!!]).
Another option would be to add a field to the collection with a random number. That approach would have two major disadvantages: for once it would be the same random numbers for each user and each request for a period of time which causes clumping and on the other hand would cause a whole lot of writes every time there is ""feeding time"".","Jan 13 2016 10:52:15 PM UTC;charlie.swanson;Would the [{{$sample}}|https://docs.mongodb.org/manual/reference/operator/aggregation/sample/] stage do what you wanted?","Jan 13 2016 11:45:04 PM UTC;m3t4lukas;Hi Charlie,

yep, that would be an option. However, there is no option to weigh the randomness upon some kind of rating system. Maybe it would be a better approach to add that option to the sample stage.","Jan 15 2016 03:24:11 PM UTC;charlie.swanson;Hi Lukas,

I think your use case might be addressed by something like the following?
{code:js}
db.foo.aggregate([{$sample: {size: 10, weight: ""$myWeightField""}}])
{code}

This wouldn't be so hard to do. Let me know if that would work for you, and I'll confirm that this makes sense from our end.","Jan 16 2016 01:58:31 PM UTC;m3t4lukas;Hi Charlie,

yes that would be great.
An option for allowing duplicates or not would be great, too. As far as I've seen you have no choice but to accept that there can be duplicates right now.","Jan 26 2016 12:11:11 AM UTC;charlie.swanson;Hi Lukas,

I've proposed this internally, and if/when we all agree on the syntax and semantics, we'll work on a fix. I've updated this ticket to reflect the revised plan. I've also removed the backport request, since this is a new feature, and we generally do not backport new features to released versions.

As for the duplicates, the {{$sample}} stage is logically a sample without replacement, but we cannot guarantee there are not duplicates because of our isolation semantics (see [here|https://docs.mongodb.org/manual/core/read-isolation-consistency-recency/#cursor-snapshot] for more details). This is not a trivial issue to fix, and I don't think we would want to add de-duplicating logic to only the {{$sample}} stage, since this is a general problem that should be solved everywhere.","Jan 27 2016 06:58:37 AM UTC;m3t4lukas;Hi Charlie,

thanks for proposing the issue internally.
Yeah the duplicates part is kind of a nice to have but it works without. It's just to avoid confusion with the users. But at least for me it's not critical to functionality. There might be people that may disagree with me on that part.
Edit: This is kind of a PS but there is weighted randomness built into boost. http://www.boost.org/doc/libs/1_59_0/doc/html/boost_random/tutorial.html#boost_random.tutorial.generating_integers_with_different_probabilities",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Allow $count/$size in $graphLookup,SERVER-31748,451891,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-query-optimization,jgl,jgl,Oct 27 2017 01:59:34 PM UTC,Oct 21 2020 06:28:00 PM UTC,Feb 17 2021 11:15:21 AM UTC,,,,,,Backlog,Aggregation Framework,,,,0,,,,,,"There are many times that you don't need to retrieve the documents from a graphLookup, you only want the number of resulting documents after performing the graphLookup stage, you are throwing away capacity in the process, if you after the graphLookup are going to do a $size operation. 

If the graphLookup could resolve in a number being this number the count of the resulting documents, could be way more easy to retrieve the needed data without having to use so many resources.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2017-10-27 18:09:49.0,104371200,,,,,,,,,,,,,,,,,,,,,,,,,,,,false,craig.homa(craig.homa),Fri Oct 27 19:09:35 UTC 2017,,,,,,,,,,,,,,backlog-query-optimization(JIRAUSER1257108),james.wahlin(james.wahlin@10gen.com),jgl(jgl),mark.agarunov(mark.agarunov),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i20tev:",,,,,,,"0|i00xc7:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i20rin:","Oct 27 2017 06:09:49 PM UTC;mark.agarunov;Hello [~jgl],

Thank you for the detailed description. I've set the fixVersion to ""Needs Triage"" for this new feature to be scheduled against our currently planned work. Updates will be posted on this ticket as they happen.

Thanks,
Mark","Oct 27 2017 07:09:35 PM UTC;james.wahlin;Hi Jose,

The feature you request will be available for $lookup in MongoDB 3.6 and can be tested in our 3.6.1-rc1 release candidate. We are introducing a new $lookup syntax that lets you specify your own foreign pipeline syntax. You can learn more about on the following page:

https://docs.mongodb.com/master/reference/operator/aggregation/lookup/#join-conditions-and-uncorrelated-sub-queries

Given this I am going to narrow the scope of this feature request to $graphLookup, which does not yet have this capability and won't for 3.6.

Thanks,
James",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Introduce a $replaceFields pipeline stage,SERVER-41564,791726,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-query-optimization,HappyNomad,HappyNomad,Jun 06 2019 05:02:36 PM UTC,Oct 21 2020 06:27:30 PM UTC,Feb 17 2021 11:15:21 AM UTC,,,,,,Backlog,Aggregation Framework,,,,0,expression,,,,,"The {{$addFields}} pipeline stage allows us to replace a field if the field already exists.  Unfortunately, the intention to _replace_ rather than _add_ becomes muddled for documents returned from the query that don't contain the field.  The nonexistence of the field in those documents changes the effect from _replace_ to _add_, even though we really just wanted to _replace_.

In my application, I often must return query results where nested arrays are filtered.  I've found that using {{$addFields}} pipeline stages mostly accomplishes this.  For each nested array that I must filter, I construct the corresponding pipeline stage as follows:
{code:c#}""{ $addFields: { '"" + arrayFilter.field +
    ""': { $filter: { input: '$"" + arrayFilter.field +
    ""', cond: { "" + arrayFilter.cond + "" } } } } }"" );
{code}
But a problem arises when one of the path segments in {{arrayFilter.field}} doesn't exist in the database.  The problem is compounded when {{arrayFilter.field}} is nested, i.e. contains dots.

Under those circumstances, I want the stage to have zero effect. Unfortunately, the query result is such that:
 # the path leading to the nonexistent array is materialized
 # the unwanted array is given a {{null}} value.

Such problems could be avoided by introducing a {{$replaceFields}} pipeline stage that we can use to unambiguously declare our intention to _replace_ rather than _add_.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,4.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2019-06-06 20:43:41.0,53308800,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,craig.homa(craig.homa),Mon Jun 10 20:45:18 UTC 2019,,,,,,,,,,,,,,HappyNomad(happynomad),backlog-query-optimization(JIRAUSER1257108),eric.sedor(eric.sedor),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i3mfpj:",,,,,,,"0|i00yun:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i3mdtb:","Jun 06 2019 08:43:41 PM UTC;eric.sedor;Hi [~HappyNomad]; Do the $project options to [conditionally exclude fields|https://docs.mongodb.com/manual/reference/operator/aggregation/project/#conditionally-exclude-fields] and [include computed fields|https://docs.mongodb.com/manual/reference/operator/aggregation/project/#include-computed-fields] help satisfy your use-case?","Jun 08 2019 05:18:49 PM UTC;HappyNomad;Hi @eric.sedor, thanks for the doc links.  Including computed fields was what I was already doing, but the ""conditionally exclude fields"" link led me to try something new:
{code:c#}""{ $addFields: { '"" + arrayFilter.field +
	""': { $ifNull: [ { $filter: { input: '$"" + arrayFilter.field +
	""', cond: { "" + arrayFilter.cond + "" } } }, '$$REMOVE' ] } } }"" );
{code}
That got me a little closer, but no cigar.  The problem remains when {{arrayFilter.field}} is nested, i.e. contains dots.  In that case, the path to the nonexistent array is still materialized in the query results.  The only improvement over my earlier attempt is that the leaf array field is now absent rather than present with a {{null}} value.","Jun 10 2019 04:38:51 PM UTC;HappyNomad;As an alternative to the {{$replaceFields}} feature idea, you could consider changing {{$$REMOVE}}'s behavior in situations like this.  It seems unhelpful to remove only the leaf field, while leaving behind the trail of empty documents that lead to it.  {{$$REMOVE}} could instead remove (or never include in the first place) every document in the path that doesn't exist in the database.","Jun 10 2019 08:45:18 PM UTC;eric.sedor;Thanks for the added detail, [~HappyNomad]; I'm passing this on to an appropriate team for consideration. Please keep an eye on this ticket in case we have more questions or additional information about currently available workarounds.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
aggregation:  $group should have a $median accumulator,SERVER-4929,30378,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-query-optimization,pasette,cwestin,Feb 10 2012 08:14:16 PM UTC,Oct 21 2020 06:27:27 PM UTC,Feb 17 2021 11:15:21 AM UTC,,,,,,Backlog,Aggregation Framework,,,,32,accumulator,expression,pm1457-nominee,,,"This has been suggested a couple of times through forums, meetups, and office hours.  $median would go with $avg, $min, $max, etc, as a $group expression.
",,,,,,,,,,,,FREE-37230,,,,,,,,,,,,,,,,,,,,5.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2012-03-16 21:41:43.0,41040000,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,craig.homa(craig.homa),Wed Oct 30 23:58:07 UTC 2019,,,,,,,,No,,,,,,backlog-query-optimization(JIRAUSER1257108),charlie.swanson(charlie.swanson),cwestin(cwestin),pasette(dan@10gen.com),massimo.brignoli(massimo.brignoli),redbeard0531(redbeard0531),virendra.agarwal@timesinternet.in(virendra.agarwal@timesinternet.in),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i062zz:",,,,,,,"0|i00yqf:",7993,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i0132v:","Mar 16 2012 09:41:43 PM UTC;cwestin;Moved to ""Planning Bucket A"" to match the disposition of the duplicate SERVER-4571.","Sep 16 2015 07:31:45 AM UTC;virendra.agarwal@timesinternet.in;It will be good if Median comes with percentile option for Data.","Feb 23 2016 05:11:49 PM UTC;charlie.swanson;It's subtle, but {{$percentile}} is actually very different from just another accumulator. Computing the Xth percentile requires looking at all the inputs (and sorting them?) before knowing the answer. This makes it just as memory-intensive as $push. It would also introduce some weird behavior in a sharded cluster. Since a $group would be split to run half on the shards, and half on the merging shard, the shards would have to send over their accumulated data. Everything goes over the wire as BSON, so the intermediate accumulated data could be at most 16MB. It would be surprising for some users to hit an excessive memory error on something that produces a pretty small output.

As far as I can tell, {{$median}} is just a special case of {{$percentile}}, computing the 50th percentile.

There may be an easy answer, which is just to introduce a {{$percentile}} expression, which operates over an array. Then if you wanted to compute the median, you could do the following:
{code:js}
db.example.aggregate([
  {$group: {_id: ""$group_id"", valuesOfInterest: {$push: ""$valueOfInterest""}}},
  {$project: {_id: 1, median: {$percentile: [""$valuesOfInterest"", 50]}}}
])
{code}

This would make it explicit that you have to store all the data to compute the percentile. The downside is that there's probably a way to compute percentile as an accumulator that would use a smaller memory footprint (e.g. if there are a lot of duplicate values) that this would miss out on.

[~redbeard0531], do you have any thoughts?","Feb 12 2018 11:30:42 PM UTC;massimo.brignoli;Someone had the chance to have a look at tdigest? Seems quite compatible with Aggregation Framework and sharding...

https://github.com/CamDavidsonPilon/tdigest","Oct 30 2019 11:58:07 PM UTC;redbeard0531;[~charlie.swanson] sorry for the delay in replying, I just came across this again today. If we are OK with giving fast but imprecise results (which is somewhat implied if you are using {{$sample}}), there are algorithms for on-line streaming computation of approximate percentiles and medians. The one I'm familiar with is  [P-squared|https://www.cse.wustl.edu/~jain/papers/ftp/psqr.pdf] which uses some dynamically moving markers and counts. There is a [boost implementation|https://www.boost.org/doc/libs/1_71_0/doc/html/accumulators/user_s_guide.html#accumulators.user_s_guide.the_statistical_accumulators_library.p_square_quantile] and we even had one in [our codebase|https://github.com/mongodb/mongo/blob/v2.6/src/mongo/util/descriptive_stats-inl.h] way back when, but it was removed since the feature it was built for was never productionized. We would need to modify the algorithm to provide some way to merge results from multiple shards, but IIRC that should be possible. There may also be newer algorithms that are designed with that in mind.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Support for Serbian language in FTS,SERVER-45617,1100572,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-query-optimization,petkovic8@gmail.com,petkovic8@gmail.com,Jan 16 2020 09:24:42 PM UTC,Oct 21 2020 06:27:00 PM UTC,Feb 17 2021 11:15:21 AM UTC,,,,,,Backlog,Text Search,,,,0,serbian,,,,,"We would like to contribute by adding a support for Serbian language to FTS component.

This would require:
 # Update of the _libstemmer_c_ library - Serbian stemmer is available under the Snowball project,
 # Change in the /_src/mongo/db/fts/fts_language.cpp_ - in order to register a new language,
 # New list of stopwords (_stop_words_serbian.txt_) under the _/src/mongo/db/fts_ folder and a Change to the SConscript file (to register this new list),
 # Change to the _/src/mongo/db/fts/unicode/codepoints_diacritic_map.cpp_ - two new cases inside _codepointRemoveDiacritics_ function for letters ""Đ"" and ""đ"".

 ",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2020-01-17 16:09:57.0,34214400,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,craig.homa(craig.homa),Fri Jan 17 16:09:57 UTC 2020,,,,,,,,,,,,,,backlog-query-optimization(JIRAUSER1257108),carl.champain(carl.champain),petkovic8@gmail.com(petkovic8@gmail.com),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i52qtz:",,,,,,,"0|i00zf3:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i52oxj:","Jan 17 2020 04:09:57 PM UTC;carl.champain;Hi [~petkovic8@gmail.com],

Thanks for the report.
 I'm passing this ticket along to the appropriate team for further investigation. Updates will be posted on this ticket as they happen.

Kind regards,
 Carl
  ",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Add ability to subquery on an array with similar syntax as querying documents,SERVER-35230,549756,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-query-optimization,rod.adams,rod.adams,May 25 2018 04:02:28 PM UTC,Oct 21 2020 06:26:53 PM UTC,Feb 17 2021 11:15:21 AM UTC,,,,,,Backlog,Querying,,,,0,,,,,,"Finding the right way to construct a find against elements in an array field can get rather tricky, and the rules become very opaque for those with less experience with MongoDB. 

 

What I suggest is the ability to essentially nest a subquery into your find/$match, which would treat an array as the new collection. The results of the subquery would replace the array for the rest of the parent find's execution (including what is returned as final result).

Example:
{code}db.collection.find({
 firstname: 'Jones',
 lastname: 'Sally',
 addresses: {$arrayFind: {
   state:'TX',
   $sort:{zip:1},
 }}
)
{code}
 

We already have pieces of this in filter, elemmatch, etc, but this feels like it would be a much cleaner interface overall, and allow for some constructs we're still missing. 

 ",,,,,,,,,,,,PM-35,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2018-06-01 02:22:30.0,81734400,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,craig.homa(craig.homa),Mon Jul 16 16:31:51 UTC 2018,,,,,,,,,,,,,,asya(asya),backlog-query-optimization(JIRAUSER1257108),rod.adams(rod.adams),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i2hepj:",,,,,,,"0|i00ydz:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i2hctb:","Jul 11 2018 03:20:06 PM UTC;asya;[~rod.adams] you specifically say ""The results of the subquery would replace the array for the rest of the parent find's execution (including what is returned as final result).""  

Regarding the parenthetical comment - we always treat the query part separate from the projection part (in find and aggregate).   Are you suggesting that new syntax would conflate the two?   I don't think that would fit into the existing language semantics very easily (and since sometimes you want to query on one thing - like subset of array matching something - and return different thing, we could not ever remove separate specification for both parts. ","Jul 16 2018 04:31:51 PM UTC;rod.adams;[~asya] – So yes, that is basically what I meant.

I don't see it as a limiting issue, since what I'm suggesting is that we basically have a recursive filter & project system.  The Array Query would be open to having it's own filter and projection steps, and then the outer document would process it's own filter and projection steps, only with the end projection of the Array Query having replaced the contents of the array. If your conditions for filtering array elements consist wholly in the array data, then you're fine. If not, yes, you'll have to keep some of it around. There'll be corner cases, to be sure, but I believe that in the common case, this would be a lot cleaner interface for users.

Thus, I don't see where we'd be giving up functionality in this way... but I'm certainly open to reviewing any counterexamples you provide. 

 

I could see optimizing this as moderately tricky, but 90s of semi-amateur attacking of the problem leads me to believe there's room to make it work.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Add $isNull aggregation expression,SERVER-18759,207583,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-query-optimization,matt.kalan,matt.kalan,May 31 2015 04:00:25 PM UTC,Oct 21 2020 06:26:46 PM UTC,Feb 17 2021 11:15:21 AM UTC,,3.0.3,,,,Backlog,Aggregation Framework,,,,0,expression,pm1457-nominee,,,,"We should add an $isNull aggregation expression, that returns true for missing, null, or undefined values.

h5. Original Description
I have documents that sometimes have an array field called purchases and sometimes not and it fails when $size hits a document without the purchases field.  I don't see how to check if it is an array before running it.  $exists does not seem to work within $project nor $type to check if it is an array type.  The easiest would be if $size just doesn't fail and returns null.  ",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,6.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2015-05-31 17:28:07.0,95299200,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,craig.homa(craig.homa),Fri Feb 09 18:34:44 UTC 2018,,,,,,,,,,,,,,asya(asya),backlog-query-optimization(JIRAUSER1257108),charlie.swanson(charlie.swanson),matt.kalan(matt.kalan@10gen.com),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i02tmn:",,,,,,,"0|i00vtz:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i01dmv:","Jul 15 2015 01:45:58 AM UTC;asya;$size probably should continue behaving as it currently does, but it would be nice to have an $isNull test to go with $isArray to allow projecting size of 0 or 1 for non-arrays depending on whether there's a value there or not.
","Nov 04 2015 07:28:10 PM UTC;charlie.swanson;Given the discussion, I have morphed this ticket into a request for an $isNull expression.

Generally, accumulators (used in the $group stage, e.g. $push, $sum, $avg), are more tolerant of malformed inputs, whereas expressions (used in a couple places, most commonly in $project, e.g. $concat, $add, $isArray) tend to error on malformed inputs.

My understanding is that this will solve all issues, and avoid weird behavior of $size. Let me know if I missed anything.","Jul 15 2016 03:39:21 AM UTC;asya;for array use case originally described, it seems $ifNull:[""$possibleArray"", [ ] ] should work, no?

{noformat}
{$project:{sizeA:{$size:{$ifNull:[""$a"",[]]}}}}
{noformat}

will always succeed on array or missing or null field.

","Jul 15 2016 03:52:50 AM UTC;asya;In addition, for 3.4 you will be able to use $type to determine the type of the field.  I'm sure $isNull can still be useful as syntactic sugar for some expressions, but it just becomes short for {noformat} {$in: [ {$type:""$FIELD""}, [ ""missing"", ""null"", ""undefined"" ] ] } {noformat}
","Feb 09 2018 05:46:18 PM UTC;asya;Is there a need for {{$isNull}} expression given that it's exactly the same as {{$not}} of the same value?

\{$isNull:""$exp""\} is true guarantees that \{$not:""$exp""\} is also true.

{noformat}
db.badtypes.aggregate({$project:{_id:0, isNull_A:{$not:""$a""}, type_A:{$type:""$a""}, original_A:""$a""}})
{ ""isNull_A"" : true, ""type_A"" : ""null"", ""original_A"" : null }
{ ""isNull_A"" : true, ""type_A"" : ""missing"" }
{ ""isNull_A"" : true, ""type_A"" : ""undefined"", ""original_A"" : undefined }
{ ""isNull_A"" : false, ""type_A"" : ""double"", ""original_A"" : 1 }
{ ""isNull_A"" : false, ""type_A"" : ""array"", ""original_A"" : [ ] }
{ ""isNull_A"" : false, ""type_A"" : ""array"", ""original_A"" : [ null ] }
{ ""isNull_A"" : false, ""type_A"" : ""array"", ""original_A"" : [ {  } ] }
{ ""isNull_A"" : false, ""type_A"" : ""array"", ""original_A"" : [ [ ] ] }
{ ""isNull_A"" : true, ""type_A"" : ""missing"" }
{ ""isNull_A"" : true, ""type_A"" : ""missing"" }
{ ""isNull_A"" : true, ""type_A"" : ""missing"" }
{ ""isNull_A"" : true, ""type_A"" : ""missing"" }
{ ""isNull_A"" : false, ""type_A"" : ""object"", ""original_A"" : { ""b"" : 1 } }
{ ""isNull_A"" : false, ""type_A"" : ""object"", ""original_A"" : { ""b"" : 1, ""c"" : 1, ""d"" : 1 } }
{ ""isNull_A"" : false, ""type_A"" : ""object"", ""original_A"" : { ""b"" : 1, ""c"" : 1, ""d"" : 1 } }
{ ""isNull_A"" : false, ""type_A"" : ""objectId"", ""original_A"" : ObjectId(""5925af23a4365a72f0a568d4"") }
{ ""isNull_A"" : false, ""type_A"" : ""date"", ""original_A"" : ISODate(""2017-05-24T16:04:58.266Z"") }
{ ""isNull_A"" : false, ""type_A"" : ""object"", ""original_A"" : { ""$id"" : ObjectId(""5925af40a4365a72f0a568d7""), ""$ref"" : ""coll1"" } }
{noformat}","Feb 09 2018 06:34:44 PM UTC;asya;Never mind my previous comment, I forgot about {{false}} and {{0}} which are not considered ""null-ish"" but would return ""true"" here.
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Add an option to $sample to perform a more statistically unbiased sample,SERVER-22068,245795,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-query-optimization,charlie.swanson,charlie.swanson,Jan 05 2016 07:37:06 PM UTC,Oct 21 2020 06:26:24 PM UTC,Feb 17 2021 11:15:21 AM UTC,,,,,,Backlog,Aggregation Framework,,,,1,expression,,,,,"The {{$sample}} stage currently has two algorithms to select a random sample:
# Using a random cursor (does a random walk over some B-tree like structure).
# A full collection scan, sorting by a random value.

The latter strategy has a better statistical distribution, since it only relies on the random number generator, and doesn't depend on any trees being balanced. It is also better at weighting the results from shards with different amounts of data accordingly. The random walk approach has some special logic to approximate weighting per shard, but it is flawed because it only has an estimate of the number of owned documents on the shard.

We should add an option to the {{$sample}} stage to force it to perform the scan + random sort approach. When this option is passed, it should probably use the better random number generator as well.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,161481600,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,craig.homa(craig.homa),2016-01-05 19:37:06.0,,,,,,,,,,,,,,backlog-query-optimization(JIRAUSER1257108),charlie.swanson(charlie.swanson),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i02ag7:",,,,,,,"0|i00w47:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i0xhef:",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Support for read-only fields,SERVER-33827,509986,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-query-optimization,mitar,mitar,Mar 12 2018 06:24:12 PM UTC,Oct 21 2020 06:26:04 PM UTC,Feb 17 2021 11:15:21 AM UTC,,,,,,Backlog,Security,Write Ops,,,1,,,,,,"It would be great if we could have some fields be write-once only. So that we could make sure our application logic is never changing them (like timestamps, or entries for audit log). Currently there is some support for validation, but it just checks that schema matches, not what changes are being made.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2018-03-12 18:34:26.0,92275200,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,craig.homa(craig.homa),Sat Mar 17 00:37:57 UTC 2018,,,,,,,,,,,,,,backlog-query-optimization(JIRAUSER1257108),kelsey.schubert(thomas.schubert),mitar(mitar),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i2an0f:",,,,,,,"0|i00y5z:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i2al47:","Mar 16 2018 09:00:02 PM UTC;kelsey.schubert;Hi [~mitar],

Would you please clarify what your use case? For example, are you describing a use case where only one app can write some of the fields and another app can only read the document and write *some* of the fields, or do you require that some can be written by any app, but only once?

Thanks,
Kelsey","Mar 17 2018 12:37:57 AM UTC;mitar;The latter. So we would like to have fields which once written nobody can change (or at least, nobody with regular write permissions). Then our app would have regular write permissions. We would like this to be assured at the database level so that we have a single point of failure.

This would then help us making sure audit documents are not tampered with at the lowest possible level.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Add expression that evaluates to shardName,SERVER-41854,810044,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-query-optimization,anton.korshunov,anton.korshunov,Jun 21 2019 01:25:49 PM UTC,Oct 21 2020 06:25:55 PM UTC,Feb 17 2021 11:15:21 AM UTC,,,,,,Backlog,Aggregation Framework,Querying,,,0,expression,pull-request,,,,"For troubleshooting and testing purposes it could be very helpful to be able to quickly check data distribution in a collection. This could be done by adding an ability to project out the shard name for a document. For example,

 
{code:java}
db.employee.insert({_id: 1, name: ""Joe Smith""})
db.employee.insert({_id: 2, name: ""Mary Scott""})
db.employee.insert({_id: 3, name: ""Ann Power""})
db.employee.aggregate([{$addFields: {shardName: {$shardName: 1}}}])
{ ""_id"" : 1, ""name"" : ""Joe Smith"", ""shardName"" : ""shard0"" }
{ ""_id"" : 2, ""name"" : ""Mary Scott"", ""shardName"" : ""shard0"" }
{ ""_id"" : 3, ""name"" : ""Ann Power"", ""shardName"" : ""shard1"" }
{code}
 ",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,3.0,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2019-07-06 22:40:52.0,22809600,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,craig.homa(craig.homa),Fri May 29 02:06:45 UTC 2020,,,,,,,,,,,,,,anton.korshunov(anton.korshunov),backlog-query-optimization(JIRAUSER1257108),david.storch(david.storch),kateryna.kamenieva(kateryna.kamenieva),krk(krk),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i3perz:",,,,,,,"0|i00z67:",9223372036854775807,,,,,,,,,,,,Query 2019-07-29,Query 2019-10-07,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i3pcvr:","Jul 06 2019 10:40:52 PM UTC;krk;I have created [PR 1317|https://github.com/mongodb/mongo/pull/1317] that adds this functionality in the form of a {{$meta}} projection.

See the PR comment for details.

{{Example:}}
{noformat}
db.items.find({}, {shard: {$meta: ""shardName""}}) 
{ ""_id"" : 1, ""a"" : 1, ""foo"" : 1, ""shard"" : ""toe"" }
{ ""_id"" : 5, ""a"" : 5, ""foo"" : 5, ""shard"" : ""toe"" }
{ ""_id"" : 2, ""a"" : 2, ""foo"" : 2, ""shard"" : ""tic"" }
{ ""_id"" : 3, ""a"" : 3, ""foo"" : 3, ""shard"" : ""tic"" }
{ ""_id"" : 4, ""a"" : 4, ""foo"" : 4, ""shard"" : ""tic"" }{noformat}","Oct 09 2019 10:29:23 PM UTC;david.storch;Thanks [~krk]! I responded on the pull request with a few pieces of feedback.","May 29 2020 02:06:45 AM UTC;kateryna.kamenieva;[~krk], thank you for the pull request and review followups. Currently, this feature is not on the list of our immediate priorities. Once it gets prioritized, we'll work with you to make it happen.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Add distance expressions for image feature comparison ,SERVER-39057,673680,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-query-optimization,kelsey.schubert,kelsey.schubert,Jan 16 2019 11:44:09 PM UTC,Oct 21 2020 06:25:39 PM UTC,Feb 17 2021 11:15:21 AM UTC,,,,,,Backlog,,,,,1,pull-request,,,,,"This ticket tracks the work contained in [Pull Request #1291|https://github.com/mongodb/mongo/pull/1291].

{quote}
We added these expressions: 

'$cossim', '$chi2', '$euclidean', '$squared_euclidean', '$manhattan'

Which allow us to compare long vectors (image features) stored as arrays or BSON.
It is useful to find the most similar images in a dataset. The usage is the following:

{noformat}
db.test_speed.aggregate([
    {   
        '$project':
        {
            'id': '$id',
            ""other_id"": '$other_id',
            'distance': {'$cossim': [vector, '$vector']},
        },
    },
    {""$sort"": {""distance"": -1}},
    {""$limit"": 20}
])
{noformat}

In addition implementations using avx2 and avx512 are included in this pull request.
{quote}",,,,,,,,WRITING-3510,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2019-01-17 15:45:34.0,44496000,<a href='https://jira.mongodb.org/browse/WRITING-3510'>WRITING-3510</a>,,,,,,,,,,,,,,,,,,,,,,,,,,,true,craig.homa(craig.homa),Fri Sep 20 21:09:16 UTC 2019,,,,,,,,,,,,,,asya(asya),backlog-query-optimization(JIRAUSER1257108),kelsey.schubert(thomas.schubert),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i32fvz:",,,,,,,"0|i00z4v:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i32dzr:","Sep 20 2019 09:09:16 PM UTC;asya;Marc,

I'm sorry about the long delay to let you know that unfortunately, we will not be able to accept this pull request.


 I'd like to outline a few reasons why this can't be merged:

The PR proposes several generic operations for computing the Euclidean, squared Euclidean, cosine similarity, Chi-squared and Manhattan distances between two N-dimensional vectors. Adding these particular vector operations would invariably produce subsequent requests to backfill more basic operations (vector addition, scalar times vector, dot product, etc.) Just considering distance measures, why those four in particular? SciPy provides a couple dozen, and OpenCV provides 4, albeit a different 4.

These types of functions might be a great addition to enhancing our analytics capabilities, but we feel it should only be done as part of a broader effort to add more computational operations. This should be probably spec'ed out as part of full slate of related functions, e.g. numeric vector and matrix operations.

Another related concern is about implementation for the new expressions – it is somewhat non-standard relative to existing expressions; for instance, the vectors themselves are passed in as raw float* with a separate parameter to indicate their length. In fact, it is likely that we would want to add something even for simple vectors that considers best storage format, possibly a new type of arrays that contain a single type, which is tracked in SERVER-9380.

Again, I apologize that it took me so long to get back to you on this, and thank you for your interest in contributing to MongoDB!

Asya Kamsky",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Add command and shell helper to create SB Indexes (or add that ability to createIndex() ),SERVER-41339,778790,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-query-optimization,harshad.dhavale,harshad.dhavale,May 28 2019 05:11:39 PM UTC,Oct 21 2020 06:25:36 PM UTC,Feb 17 2021 11:15:21 AM UTC,,,,,,Backlog,Indexing,,,,0,FTS,,,,,"Right now, SB indexes can be created only from the Atlas UI. This is a feature request to add a command or shell helper that allows for creating a Full Text Search Index in Atlas _*or*_ add the ability to the *createIndex()* command so that SB indexes can be created using it.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2019-06-17 15:44:53.0,54432000,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,craig.homa(craig.homa),2019-05-28 17:11:39.0,,,,,,,,,,,,,,backlog-query-optimization(JIRAUSER1257108),harshad.dhavale(harshad.dhavale),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i3kbhz:",,,,,,,"0|i00ysv:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i3k9lr:",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Extend shell helpers to allow setting 'comment' field to all commands.,SERVER-43284,923588,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-query-optimization,arun.banala,arun.banala,Sep 11 2019 04:34:51 PM UTC,Oct 21 2020 06:25:26 PM UTC,Feb 17 2021 11:15:21 AM UTC,,,,,,Backlog,,,,,0,,,,,,"After SERVER-29794 is implemented, all the commands will be able to attach 'comment' fields to the command object. Most of the shell helpers currently have an 'options' parameter using which any new field can be attached. But some helpers like 'explain' or 'insert' do not have this option. We need to audit all the major shell helper and allow options/comment parameter where necessary. ",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,45273600,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,craig.homa(craig.homa),2019-09-11 16:34:51.0,,,,,,,,,,,,,,arun.banala(arun.banala),backlog-query-optimization(JIRAUSER1257108),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i48qun:",,,,,,,"0|i00z3j:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i48oyf:",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Add break statement for $reduce,SERVER-37224,607615,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-query-optimization,renato.riccio,renato.riccio,Sep 20 2018 03:33:49 PM UTC,Oct 21 2020 06:25:10 PM UTC,Feb 17 2021 11:15:22 AM UTC,,,,,,Backlog,,,,,0,,,,,,"There are use cases when you need to stop looping over an array once a condition is reached.

Currently, it is not possible to do that and we are obliged to loop over the entire array even if functionally we could just stop.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,76032000,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,craig.homa(craig.homa),2018-09-20 15:33:49.0,,,,,,,,,,,,,,backlog-query-optimization(JIRAUSER1257108),renato.riccio(renato.riccio),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i2r5wn:",,,,,,,"0|i00ygv:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i2r40f:",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
aggregation:  support nested pipelines on array-valued fields,SERVER-4438,26054,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-query-optimization,pasette,cwestin,Dec 06 2011 12:59:52 AM UTC,Oct 21 2020 06:24:57 PM UTC,Feb 17 2021 11:15:22 AM UTC,,,,,,Backlog,Aggregation Framework,,,,2,usability,,,,,"For each document passing through a document pipeline, allow a nested pipeline to be used on array-valued fields.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2014-04-17 06:08:27.0,290390400,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,craig.homa(craig.homa),2011-12-06 00:59:52.0,,,,,,,,No,,,,,,backlog-query-optimization(JIRAUSER1257108),pasette(dan@10gen.com),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i06927:",,,,,,,"0|i00u2n:",5998,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i01gbj:",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Support Korean language in full text search,SERVER-29598,393273,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-query-optimization,matt.lee,matt.lee,Jun 13 2017 08:44:26 AM UTC,Oct 21 2020 06:24:28 PM UTC,Feb 17 2021 11:15:22 AM UTC,,,,,,Backlog,Text Search,,,,6,,,,,,"Add Korean to languages supported in MongoDB FTS.

Original description:
First of all, MongoDB support stemming for major language like english.
But there's no stemming for CJK (Especially I am focusing on Korean). So MongoDB text search is useless for korean language unless stemming Korean in application code.

I am not sure you are interested in Korean,
Anyway Korean use only suffix(postpositional word) after stem(base word) like ..
{code:java}
Stem : 한글
With suffix : 한글은, 한글이, 한글을, 한글과, 한글도, 한글처럼, ...
{code}

But current MongoDB implementation, MongoDB search exact match with search term. So Korean word does not matched because of suffix(""은"", ""는"", ""이"", ""가"", ""처럼"", ...)

So if MongoDB support range search for text search like below example, We (Korean) can use text-search for Korean language.
{code:java}
Text : ""한글은 뛰어난 언어입니다.""
Search term : ""한글""
Range search in Text-search : ""한글"" <= range < ""한긁"" 
  (where ""한긁"" is generated simple increment of last character of search term, [like this|https://github.com/mongodb/mongo/pull/1151/commits/641c3041282746aff280b685424d55926bab93b2#diff-bc6db30f2a5f9618496534d03aeabf54R108])
{code}

Of course, this feature is not needed for language which has stemming.
So I want you add knob to enable or disable this range search for text-search (and default is false). Then we can use text search with this knob=true for Korean language.

I pushed pull-request for this simple idea to [MongoDB github|https://github.com/mongodb/mongo/pull/1151]

This feature will save a lot of Korean guys. Please consider adding this feature seriously.
(I am not sure this feature is useful for Japanese or China which does not have space in phrase)

Thanks.",,,,,,,,,,,,SERVER-45859,,,,,,,,,,,,,,,,,,,,3.0,,,,,,,,,,,,,,,,,,,,,500A000000XWvtzIAD,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2017-06-16 16:41:10.0,114739200,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,craig.homa(craig.homa),Fri Jun 30 08:55:47 UTC 2017,,,,,,,,,,,,,,asya(asya),backlog-query-optimization(JIRAUSER1257108),mark.agarunov(mark.agarunov),matt.lee(matt.lee),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i1qxjz:",,,,,,,"0|i00x3b:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i1qvnr:","Jun 16 2017 04:41:10 PM UTC;mark.agarunov;Hello [~matt.lee],

Thank you for providing the detailed example. I've set the fixVersion on this ticket to ""Needs Triage"" for this new feature to be scheduled against our currently planned work. Updates will be posted on this ticket as they happen.

Thanks,
Mark
","Jun 28 2017 09:33:22 PM UTC;asya;[~matt.lee],

You are correct, MongoDB text search currently does not provide support for Korean (you can see the list of currently supported languages [here|https://docs.mongodb.com/manual/reference/text-search-languages/]).

The best solution would be for us to add support for Korean, which would include support for appropriate stemming and stop words.   As you found, if the language is not supported, text search uses simple tokenization with no list of stop words and no stemming.

Your proposed pull request tries to implement prefix text search, a new feature we are already tracking in SERVER-15090, however, we cannot accept the pull request for several reasons:

- there are no tests included, so there is no way to make sure that the changes didn't break existing functionality
- text indexes can be [part of compound indexes|https://docs.mongodb.com/manual/core/index-text/#text-index-compound] and the proposed changes don't look like they would work correctly with a compound index
- please see our [contributor guidelines|https://github.com/mongodb/mongo/wiki#contributing-to-mongodb] for other requirements, like contributor agreement, coding style, etc.

Since we already have a JIRA ticket for prefix search, I think the proposed work for that feature should be tracked there.  I'm going to convert this ticket into a new feature request for MongoDB to add proper text search support for Korean language.

Thanks for your interest in MongoDB.

Regards,
Asya Kamsky
Lead Product Manager, MongoDB Server","Jun 30 2017 08:55:47 AM UTC;matt.lee;Hi Asya.

>> I'm going to convert this ticket into a new feature request for MongoDB to add proper text search support for Korean language.
Sure, I just added simple code to explain how mongodb can support korean full text search without stemming. And also my pull-request is not complete patch.

Anyway, I hope ""SERVER-15090"" is implemented sooner or later.

Thanks.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
shorthand syntax for checking if _id value is missing,SERVER-42019,828815,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-query-optimization,asya,asya,Jun 30 2019 04:32:24 PM UTC,Oct 21 2020 06:24:24 PM UTC,Feb 17 2021 11:15:22 AM UTC,,,,,,Backlog,Aggregation Framework,Write Ops,,,0,,,,,,"In pipeline update specification it is common to check if a field doesn't exist and the way to tell if you're doing an upsert would be to check if _id doesn't exist.  I'm proposing a shorthand syntax expression {{$onInsert}} or {{ifUpsert}} (exact work TBD) which would be short for:
{noformat} {$eq:[ {$type:""$_id""}, ""missing"" ] } {noformat}
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,51580800,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,craig.homa(craig.homa),Sun Jun 30 16:33:51 UTC 2019,,,,,,,,,,,,,,asya(asya),backlog-query-optimization(JIRAUSER1257108),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i3slg7:",,,,,,,"0|i00yvj:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i3sjjz:","Jun 30 2019 04:33:51 PM UTC;asya;This would be useful the same way $setOnInsert was used in regular update modifiers.

 ",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Support Turkish rules for case folding in $regex,SERVER-24633,294660,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-query-optimization,admin@yellow.com.tr,admin@yellow.com.tr,Jun 17 2016 11:27:17 AM UTC,Oct 21 2020 06:24:18 PM UTC,Feb 17 2021 11:15:22 AM UTC,,,,,,Backlog,Text Search,,,,1,,,,,,"h6. Original summary
Case Sensitivity Mistake --  i-İ 

h6. Original Description
Example data:
{
  ""_id"" : ObjectId(""562395d2f4ac61190f8b463a""),
  ""category_name"" : ""İçme Suları ve Kaynak Suları"",
  ""category_name_en"" : ""Water - Bottled & Bulk""
}

db.categories.find({category_name:{ $regex: 'İçme', $options: 'i'}})
One result found. it is works well

However
 
When i swap capital İ with small i,i received no result.
 
db.categories.find({category_name:{ $regex: 'içme', $options: 'i'}})
no result.

The problem might be because of incompability of turkish characters . 

King Regards , 






",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2016-06-17 21:58:48.0,147052800,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,craig.homa(craig.homa),Tue Jun 21 03:53:48 UTC 2016,,,,,,,,,,,,,,backlog-query-optimization(JIRAUSER1257108),admin@yellow.com.tr(admin@yellow.com.tr),kelsey.schubert(thomas.schubert),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i00b5z:",,,,,,,"0|i00wif:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i035af:","Jun 21 2016 03:53:48 AM UTC;kelsey.schubert;Hi [~admin@yellow.com.tr],

Thanks for reporting this behavior. As you correctly identified, this is the result of a difference in casing between [English and Turkish languages|https://en.wikipedia.org/wiki/Dotted_and_dotless_I]:

{quote}
Most Unicode software uppercases ı to I and lowercases İ to i, but, unless specifically set up for Turkish, it lowercases I to i and uppercases i to I. Thus uppercasing then lowercasing, or vice versa, changes the letters.
{quote}

Since the current behavior is expected, I am modifying this ticket to be a feature request to support Turkish rules for case folding and marking this ticket to be considered during the next round of planning. Please continue to watch for updates.

Kind regards,
Thomas",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Add Hindi language support in text search ,SERVER-15139,156339,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-query-optimization,eoin.brazil,eoin.brazil,Sep 04 2014 11:09:13 AM UTC,Oct 21 2020 06:24:11 PM UTC,Feb 17 2021 11:15:22 AM UTC,,,,,,Backlog,Text Search,,,,0,,,,,,"Hindi is not officially supported by full text search. However, there’s a [complete implementation of a stemmer|http://research.variancia.com/hindi_stemmer/] for Hindi language on this page. It’s released under Creative Commons Attribution 3.0 Unported License. This could be used to help add Hindi support to the text search in MongoDB.",,,,,,,,,,,,CS-33794,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,203731200,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,craig.homa(craig.homa),2014-09-04 11:09:13.0,,,,,,,,,,,,,,backlog-query-optimization(JIRAUSER1257108),eoin.brazil(eoin.brazil),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i03dsf:",,,,,,,"0|i00vi7:",135925,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i0ytpj:",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Allow constant integer in $group clause  ,SERVER-37276,608792,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-query-optimization,renato.riccio,renato.riccio,Sep 23 2018 10:46:46 PM UTC,Oct 21 2020 06:24:04 PM UTC,Feb 17 2021 11:15:22 AM UTC,,,,,,Backlog,Aggregation Framework,,,,0,mql-semantics,,,,,"Currently, {{$group}} does not allow to have a constant integer in a group clause, on the other hand, it supports strings. For example

{code:java}
db.foo.aggregate([{$group:{_id: {a:""$a"", d:1},c: {$sum:""$c""}}}])
assert: command failed: {
    ""ok"" : 0,
    ""errmsg"" : ""$group does not support inclusion-style expressions"",
    ""code"" : 17390,
    ""codeName"" : ""Location17390""
} : aggregate failed
{code}

If set {{d}} as a string we don't get any error
{code:java}
db.foo.aggregate([{$group:{_id: {a:""$a"", d:""1""},c: {$sum:""$c""}}}])
{code}

In order to be consistent group should support also integer inside {{_id}} ",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,3.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2018-09-24 00:09:21.0,75772800,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,craig.homa(craig.homa),Mon Sep 24 07:13:12 UTC 2018,,,,,,,,,,,,,,schwerin(schwerin),asya(asya),backlog-query-optimization(JIRAUSER1257108),renato.riccio(renato.riccio),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i2rcp3:",,,,,,,"0|i00ten:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i2rasv:","Sep 24 2018 12:09:21 AM UTC;schwerin;Can you use {{{$literal:1}}}?","Sep 24 2018 03:15:13 AM UTC;asya;You can use $literal. But it’s a bit silly - we fixed it somewhere else I’m pretty sure. ","Sep 24 2018 07:13:12 AM UTC;renato.riccio;I confirm {{$literal}} it works as workaround:

{code:java}
db.foo.aggregate([{$group:{_id: {a:""$a"", d:{$literal:1}},c: {$sum:""$c""}}}])
{code} ",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Add $some array query operator,SERVER-44355,987163,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-query-optimization,christofer@markethype.io,christofer@markethype.io,Nov 01 2019 10:17:13 AM UTC,Oct 21 2020 06:23:39 PM UTC,Feb 17 2021 11:15:22 AM UTC,,,,,,Backlog,Querying,,,,0,,,,,,"Using the $in and $all operators to query array fields cover a lot of ground, but when you want query for documents where the array holds at least 4 values, or exactly 8, then MongoDB is missing a useful operator.

Let’s take a simple example. You have a collection of Customers, and each customer document has a purchasedProducts field, which is an array of ObjectId’s (references to all products the customer have purchased). Now, for a marketing campaign you want to find all your customers who have purchased at least 3 out of a set of 10 selected products, in order to send a message to these customers.

In this scenario, the $in operator won’t do, because it would give you all customers who have purchased at least one of the products. The $all operator won’t work either, because it would only give you the customers who have purchased all 10 products in the set. In this scenario a *$some* operator would come in handy.

As a suggestion, the $some operator could take an array with two items - the first item being an array of values to match against and the second item being an object declaring the condition for a match.
{code:javascript}/*
 * Example of a $some operator where the document would match if purchasedDocuments 
 * contain at least two of the three provided ObjectIds
 */

db.collection.find({
  purchasedProducts: {
    $some: [[ObjectId('ID1'), ObjectId('ID2'), ObjectId('ID3')], { $gte: 2 }]
  }
})
{code}
Using an aggregation pipeline we get access to the tools we need to create the equivalent of a $some operator, as I've outlined in this [Medium story|https://medium.com/@christofer.eliasson/the-missing-some-operator-in-mongodb-895f08d8f34c] but it gets quite verbose and it would be really convenient to have it available as regular query operator.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2019-11-01 15:28:07.0,40867200,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,craig.homa(craig.homa),Fri Nov 01 21:09:25 UTC 2019,,,,,,,,,,,,,,asya(asya),backlog-query-optimization(JIRAUSER1257108),carl.champain(carl.champain),christofer@markethype.io(christofer@markethype.io),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i4jgcf:",,,,,,,"0|i00z8n:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i4jeg7:","Nov 01 2019 03:28:07 PM UTC;carl.champain;Hi [~christofer@markethype.io],

Thanks for taking the time to submit this request. 
I'm assigning this ticket to the Query team for additional investigation. Updates will be posted on this ticket as they happen.

Kind regards,
Carl
","Nov 01 2019 09:09:25 PM UTC;asya;This is currently possible via $expr in find or $match:

{noformat}
purchasedEvents=[ObjectId('ID1'), ObjectId('ID2'), ObjectId('ID3')];
db.collection.find({
     purchasedEvents: { $in:purchasedEvents },
    $expr:{$gt:[ {$size: {$setIntersection: [‘$purchasedEvents’, purchasedEvents]}}, 2] }
})
{noformat}
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Support field projection based on string inside of field name,SERVER-36261,575745,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-query-optimization,akerti,akerti,Jul 24 2018 08:27:13 PM UTC,Oct 21 2020 06:23:35 PM UTC,Feb 17 2021 11:15:22 AM UTC,,,,,,Backlog,Aggregation Framework,,,,0,,,,,,"Suppose you have documents that look similar to this:
{code:java}
{ ""PRE-field1"" : ""value"",  ""PRE-field2"" : ""value"", ""PRE-field3"" : ""value""}{code}
Fields in a document may start with ""PRE-"" and have any characters after that. During the projection stage, I want to be able to project all fields that contain the string ""PRE-"". Maybe the project statement looks something like this:
{code:java}
 ""$fieldNameSearch"" : /.*PRE-.*/i
{code}",,,,,,,,,,,,SERVER-11947,SERVER-267,,,,,,,,,,,,,,,,,,,3.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2018-07-25 13:57:26.0,80179200,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,craig.homa(craig.homa),Fri Aug 03 17:17:33 UTC 2018,,,,,,,,,,,,,,akerti(akerti),asya(asya),backlog-query-optimization(JIRAUSER1257108),nick.brewer(nick.brewer),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i2lqlr:",,,,,,,"0|i00ycv:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i2lopj:","Jul 25 2018 01:57:26 PM UTC;nick.brewer;[~akerti] I believe the behavior you're describing is covered as part of a larger ticket for adding enhanced regex support to the aggregation pipeline: SERVER-11947.

You can follow along with that ticket for updates on the status of this work. 

-Nick

","Jul 25 2018 02:22:10 PM UTC;nick.brewer;[~akerti] On looking at this closer I can see that your request is a little different, as you're trying to match against field names as opposed to values. I'm passing this along to our Query team as a feature request. 

-Nick","Aug 03 2018 05:17:33 PM UTC;asya;[~akerti]

You can do this currently with aggregation if you can express the regular expression as  simple substring match.  SERVER-11947 is absolutely relevant here because then in the conditional statement below you would be able to use full regex syntax.

For simple cases like the prefix comparison with sample document you provided, you can do this:
{noformat}
> db.foo.find()
{ ""_id"" : ObjectId(""5b6486405a6efe4780ae9c43""), ""PRE-field1"" : ""value"", ""PRE-field2"" : ""value"", ""PRE-field3"" : ""value"", ""notPREfield"" : 1 }
> db.foo.aggregate([{$replaceRoot:{newRoot:{
   $arrayToObject:{
      $filter:{
         input:{$objectToArray:""$$ROOT""},
         cond:{
            $eq:[
               ""PRE-"",
               {$substr:[""$$this.k"",0,4]}
            ]
         }
      }
   }
}}}])
{ ""PRE-field1"" : ""value"", ""PRE-field2"" : ""value"", ""PRE-field3"" : ""value"" }
{noformat}

This ticket is more directly related to SERVER-267 which asks for support of wildcards in queries, projections and indexes - though that's not specific to aggregation $project stage.
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Add a weighted average aggregation function,SERVER-31594,446491,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-query-optimization,randar,randar,Oct 17 2017 02:52:51 AM UTC,Oct 21 2020 06:22:16 PM UTC,Feb 17 2021 11:15:22 AM UTC,,,,,,Backlog,Aggregation Framework,,,,0,,,,,,"Although it's possible to aggregate data and use a weighted average (https://support.microsoft.com/en-ca/help/214049/how-to-calculate-weighted-averages-in-excel), it is very cumbersome requiring a nested set of group and projection aggregates. See https://stackoverflow.com/questions/46739027/using-weighted-average-with-mongodb-and-group. 

I would like to see a weighted average accumulator function along with $avg. e.g.
{code:javascript}
db.sales.aggregate(
   [
      {
        $group : {
           _id : { month: { $month: ""$date"" }, day: { $dayOfMonth: ""$date"" }, year: { $year: ""$date"" } },
           totalPrice: { $sum: { $multiply: [ ""$price"", ""$quantity"" ] } },
           averageQuantity: { $weighted_avg: { $value : ""$quantity"", $weight: ""$weight"" },
           count: { $sum: 1 }
        }
      }
   ]
)
{code}",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2017-10-17 16:18:58.0,105235200,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,craig.homa(craig.homa),Tue Oct 17 16:18:58 UTC 2017,,,,,,,,,,,,,,backlog-query-optimization(JIRAUSER1257108),mark.agarunov(mark.agarunov),randar(randar),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i1zwif:",,,,,,,"0|i00x9r:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i1zum7:","Oct 17 2017 04:18:58 PM UTC;mark.agarunov;Hello [~randar],

Thank you for the detailed example. I've set the fixVersion to ""Needs Triage"" for this new feature to be scheduled against our currently planned work. Updates will be posted on this ticket as they happen.

Thanks,
Mark",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Need of toTitleize Aggregation Pipeline Operator,SERVER-51486,1510186,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-query-execution,akansha.kumari@joshsoftware.com,akansha.kumari@joshsoftware.com,Oct 11 2020 12:40:21 PM UTC,Oct 21 2020 06:16:11 AM UTC,Feb 17 2021 11:15:22 AM UTC,,,,,,Backlog,Aggregation Framework,,,,0,qexec-team,,,,,"Currently there isn't existing Aggregate Pipeline operator which returns a string in Tileize format. There are some use-case where we need the result in Titleize format. And it will be useful if we add that operator. 

Kindly let me know if you also think there is a need for toTileize operator...",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,7.0,,,,,,,,,,,,,,,,,Minor Change,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2020-10-14 19:49:45.0,10281600,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,akansha.kumari@joshsoftware.com(JIRAUSER1257220),Wed Oct 21 06:16:11 UTC 2020,,,,,,,,,,,,,,akansha.kumari@joshsoftware.com(JIRAUSER1257220),asya(asya),backlog-query-execution(JIRAUSER1257109),edwin.zhou(JIRAUSER1257066),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i6zxo7:",,,,,,,"0|i6udwv:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i6zvrr:","Oct 14 2020 07:49:45 PM UTC;edwin.zhou;Thank you for your feature request. We're assigning this ticket to the appropriate team to be evaluated against our currently planned work. Updates will be posted on this ticket as they happen.

Best,

Edwin","Oct 14 2020 07:54:29 PM UTC;akansha.kumari@joshsoftware.com;Hi Edwin, I would like to work on the feature I requested. ","Oct 20 2020 03:25:38 PM UTC;asya;I'm not sure what this would do.  Is this meant to take a string of words (space separated) and capitalize first letter of every word?

input: ""kids went to the store"" output: ""Kids Went To The Store""?
(Like https://apidock.com/rails/String/titleize or https://docs.python.org/3/library/stdtypes.html?highlight=title#str.title)

{noformat}
db.title.find()
{ ""_id"" : ObjectId(""5f8eff87e3bf9919fec309f6""), ""text"" : ""man from the boondocks"" }
{ ""_id"" : ObjectId(""5f8eff94e3bf9919fec309f7""), ""text"" : ""x-men: the last stand"" }
db.title.aggregate({$set:{titlized:{$substr:[{$reduce:{input:{$split:[""$text"","" ""]}, initialValue:"""", in:{$concat:[""$$value"","" "",{$toUpper:{$substr:[""$$this"",0,1]}},{$substr:[""$$this"",1,{$strLenCP:""$$this""}]}]}}},1,{$strLenCP:""$text""}]}}})
{ ""_id"" : ObjectId(""5f8eff87e3bf9919fec309f6""), ""text"" : ""man from the boondocks"", ""titlized"" : ""Man From The Boondocks"" }
{ ""_id"" : ObjectId(""5f8eff94e3bf9919fec309f7""), ""text"" : ""x-men: the last stand"", ""titlized"" : ""X-men: The Last Stand"" }
{noformat}

I'm not sure this is a common enough functionality to have a named expression for...   ","Oct 20 2020 03:27:28 PM UTC;asya;The above syntax might be simpler if we supported some sort of string ""join"" like SERVER-15697 (if it took a separator on which to join the array of words).

 ","Oct 20 2020 03:43:30 PM UTC;akansha.kumari@joshsoftware.com;Yes Asya, Correct! It will capitalise the first letter of every word (space separated) of a string.

 ","Oct 20 2020 05:58:05 PM UTC;asya;There are a few other ways to do it ...
{noformat}
db.title.aggregate({$set:{titlized:{$reduce:{
    input:{$range:[1,{$strLenCP:""$text""}]},
    initialValue:{$toUpper:{$substr:[""$text"",0,1]}},
    in:{$let:{
       vars:{
          char:{$substr:[""$text"", ""$$this"", 1]}, 
          prevChar: {$substr:[""$text"", {$add:[-1,""$$this""]}, 1]}
       }, 
       in: {$concat:[
            ""$$value"", {$cond:{if:{$in:[ ""$$prevChar"", ["" "",""_"", ""-""] ]},then: {$toUpper:""$$char""}, else: ""$$char""}}]}
    }}
}}}})
 {noformat}

This will treat "" "", ""_"", and ""-"" as character indicating next letter should be capitalized.","Oct 21 2020 06:16:11 AM UTC;akansha.kumari@joshsoftware.com;Hi Asya, This would work.

Thank-you for the response.

I guess we can close this ticket then.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Collection aliases,SERVER-3498,20251,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-query-execution,kgorman,kgorman,Jul 28 2011 05:25:26 PM UTC,Oct 20 2020 11:56:02 PM UTC,Feb 17 2021 11:15:22 AM UTC,,,,,,Backlog,Storage,,,,20,,,,,,"It would be nice to be able to create alias's/synonyms.  The use case would be to swap out collections and/or data movement activities.  For instance, fill up a collection with some data, then swap it into the spot where the application can see it.

db.mycol.save({""status"":1})
db.alias({mycol:myprodcol})
db.myprodcol.find()
{status:1}
db.mynewcol.save({""status"":0})
db.alias({mynewcol:myprodcol})
<locks for metadata swap>
db.myprodcol.find()
{status:0}

",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,9.0,,,,,,,,,,,,,,,,,,,,,500A000000ZNyPFIA1,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2015-06-25 12:18:48.0,30240000,,,,,,,,PM-764,,,,,,,,,,,,,,,,,,,,true,geert.bosch(geert.bosch),Tue Mar 03 22:08:53 UTC 2020,,,,,,,,No,,,,,,AndrewDoumaux(andrewdoumaux),asya(asya),backlog-query-execution(JIRAUSER1257109),geert.bosch(geert.bosch),jan@apify.com(jan@apify.com),kgorman(kgorman),rmihael@gmail.com(rmihael@gmail.com),peter.vdc@gmail.com(peter.vdc@gmail.com),slaurent(slaurent),venkata.surapaneni@elastica.co(venkata.surapaneni@elastica.co),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i06k4v:",,,,,,,"0|i00t0f:",6065,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i1ivuv:","Jun 25 2015 12:18:48 PM UTC;AndrewDoumaux;I think this could be a very useful feature, and might be able to get around some of the issues associated with not being able to rename sharded collections","Jun 30 2015 02:32:39 PM UTC;rmihael@gmail.com;+1 for this feature. Implementing it will make long-term support for MongoDB deployments easier. In many cases it also allows to decouple applications from old data retention and archiving logic. Check ElasticSearch, they have tons of good use-cases for aliases.","Mar 03 2016 09:30:06 AM UTC;slaurent;+1","Nov 03 2016 12:53:51 AM UTC;venkata.surapaneni@elastica.co;Yes we use ES aliases a lot for index rollovers. I am requesting a same kind of feature in mongoDB that application should always r/w only through ""alias"" and the collections (sharded or unsharded) underlying the aliases can be added or removed atomically without changing any application DB connection string. this is useful for our monthly, quarterly collection rollovers for time-series data.

+1","Oct 23 2017 09:03:54 AM UTC;peter.vdc@gmail.com;+1 for this feature. And it would be nice to have aliassen for databases as well. ","Mar 01 2018 07:19:43 PM UTC;geert.bosch;This is implemented by read-only views:
{noformat}
> db.x.insert({_id:1})
WriteResult({ ""nInserted"" : 1 })
> db.createView(""y"", ""x"", [])
{ ""ok"" : 1 }
> db.y.find()
{ ""_id"" : 1 }
{noformat}
With a non-empty pipeline this can in particularly be useful for changes in the dataformat: you can see the same physical collection in both formats at the same time, allowing for backward compatibility.","Mar 01 2018 07:26:00 PM UTC;asya;Alias should be usable for reads and writes - in other words, transparent to the client.

If the use case is for read-only then read-only views can address that - you can even redefine a view definition to point to a different underlying collection without any downtime (existing operations on previous definition will complete, but new ones will correctly read the new underlying collection).

","Feb 28 2020 08:30:17 PM UTC;jan@apify.com;Big +1 for this feature.

As our production database at [Apify|https://apify.com] evolves, we'd like to fix some old bad naming decisions to keep the database tidy, maintainable and easy to understand for new engineers. With collection aliases, renaming the collections would be easy. Doing it now means a lot of engineering complexity and downtime for our users.","Mar 03 2020 10:08:53 PM UTC;geert.bosch;There is no way why (some) non-materialized views cannot be made writeable. Determining the columns (ahem, fields) of a view that are writeable, and whether a view is insertable is a well studied topic. Having a non-materialized view with empty pipeline writable would implement aliases. We can allow a {{$match}} state by checking that a changed or inserted document matches. Then expand to projections etc. Even a union view can be insertable/modifiable as long as all sources have disjoint matches on them. At that point you can implement sharding using writable views.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Allow $group stage memory limit to be configured,SERVER-20879,233960,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-query-execution,stickfigure,stickfigure,Oct 12 2015 04:45:08 PM UTC,Oct 20 2020 10:10:00 PM UTC,Feb 17 2021 11:15:22 AM UTC,,,,,,Backlog,Aggregation Framework,,,,1,asya,neweng,usability,,,"Stage memory is limited to 100MB, hardcoded in document_source_group.cpp. It would be great to have this as a server-wide configuration setting instead. 

For dedicated analytics databases, this number should be much larger.",,,,,,,,WRITING-2971,WRITING-3015,,,,,,,,,,,,,,,,,,,,,,,3.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2018-01-17 20:23:44.0,88819200,"<a href='https://jira.mongodb.org/browse/WRITING-2971'>WRITING-2971</a>, <a href='https://jira.mongodb.org/browse/WRITING-3015'>WRITING-3015</a>",,,,,,,,,,,,,,,,,,,,,,,,,,,true,craig.homa(craig.homa),Wed Apr 25 17:56:45 UTC 2018,,,,,,,,,,,,,,asya(asya),backlog-query-execution(JIRAUSER1257109),ian.whalen(ian@10gen.com),stickfigure(stickfigure),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i02hav:",,,,,,,"0|i00tp3:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i0xpyf:","Jan 17 2018 08:23:44 PM UTC;asya;Probably should be an internalQuery parameter that can be set through setParameter.
","Jan 19 2018 07:59:44 PM UTC;ian.whalen;Should also consider handling $sort when doing this.","Apr 25 2018 05:56:45 PM UTC;asya;Not clear if it should be on {{mongod}} level or cluster-level or per aggregation operation limit - in case of sharded cluster it would be problematic if some of the nodes had a higher limit and others didn't and the operation failed only when it landed on some of the shards/nodes.
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
sets (trees) into BSON - log(n) insert/removal,SERVER-10915,91577,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-query-execution,duraid.madina@10gen.com,duraid.madina@10gen.com,Sep 26 2013 02:10:39 AM UTC,Oct 20 2020 10:05:27 PM UTC,Feb 17 2021 11:15:22 AM UTC,,,,,,Backlog,Write Ops,,,,0,bson,,,,,"We should support fast O(log n) set operations.
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,233366400,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,craig.homa(craig.homa),2013-09-26 02:10:39.0,,,,,,,,No,,,,,,backlog-query-execution(JIRAUSER1257109),duraid.madina@10gen.com(duraid.madina@10gen.com),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i0446n:",,,,,,,"0|i00ug7:",6438,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i17fv3:",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Support day-of-year placeholder (%j) for $dateFromString,SERVER-32864,486434,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-query-execution,justin.seyster,justin.seyster,Jan 23 2018 10:02:44 PM UTC,Oct 20 2020 09:57:46 PM UTC,Feb 17 2021 11:15:22 AM UTC,,,,,,Backlog,,,,,0,,,,,,"Users should be able to parse a date that contains the year (%Y) and day of year (%j), so long as it does not include the month or day of week.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,96768000,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,craig.homa(craig.homa),2018-01-23 22:02:44.0,,,,,,,,,,,,,,backlog-query-execution(JIRAUSER1257109),justin.seyster(justin.seyster),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i26n5j:",,,,,,,"0|i00y2n:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i26l9b:",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Add a $distinct aggregation stage,SERVER-25184,302750,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-query-optimization,david.storch,david.storch,Jul 20 2016 07:44:43 PM UTC,Oct 20 2020 09:49:17 PM UTC,Feb 17 2021 11:15:22 AM UTC,,,,,,Backlog,Aggregation Framework,,,,3,neweng,,,,,This can be implemented using the same aliasing technique that we added for the $count stage.,,,,,,,,,,,,SERVER-25899,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2016-07-20 20:03:19.0,144460800,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,craig.homa(craig.homa),Wed Jul 20 20:03:19 UTC 2016,,,,,,,,,,,,,,backlog-query-optimization(JIRAUSER1257108),david.storch(david.storch),kyle.suarez(kyle.suarez),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i01r3z:",,,,,,,"0|i00wkn:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i01fuf:","Jul 20 2016 08:03:19 PM UTC;kyle.suarez;This would also be a great help for views, as we manually need to construct a pipeline with a $match and a $group with an addToSet.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
BSON should offer a high resolution 'UTC datetime' field type.,SERVER-1460,12511,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-query-optimization,acm,acm,Jul 22 2010 01:53:48 PM UTC,Oct 20 2020 09:42:33 PM UTC,Feb 17 2021 11:15:22 AM UTC,,1.5.2,,,,Backlog,Usability,,,,8,bson,bson2,,,,"The BSON spec defines a 'UTC datetime' field, specified as number of milliseconds since the epoch. However, milliseconds is often far too coarse grained for recording timestamps in high performance systems. It is also rather wasteful of the entire 64 bit range. A signed 64 bit integer can represent slightly less than 300 milliion years worth of milliseconds. That is a very long time.

The BSON spec should offer a high resolution UTC datetime type, denominated either in microseconds (almost 300,000 years in an int64_t), or even nanoseconds (still almost 300 years). Perhaps both?

",all,,,,,,,,,,CS-181,,,,,,,,,,,,,,,,,,,,,8.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2010-07-22 14:06:14.0,249350400,,,,,,,,PM-475,,,,,,,,,,,,,,,,,,,,true,craig.homa(craig.homa),Mon Mar 25 03:54:00 UTC 2013,,,,,,,,No,,,,,,acm(acm),backlog-query-optimization(JIRAUSER1257108),brianknox(brianknox),eliot(eliot),jzwinck(jzwinck),victorhooi(victorhooi),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i078f3:",,,,,,,"0|i00szr:",6548,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i1ivnz:","Jul 22 2010 02:06:14 PM UTC;eliot;We're trying to keep the types in the spec pretty low or all the drivers have to implement.

In this case - since you can just store it in a regular long long field and know its a datetime from logic - is it really needed?","Jul 22 2010 02:51:03 PM UTC;acm;Yes, I am currently storing high-res timestamps in a normal long long field. This works OK, but it isn't great, since things like BSONObj::toString and BSONObj::jsonString don't know that it is meant to be a timestamp, and just print it as a raw long integer value. That means that if I want to use b2json, say in a shell pipeline, then I would need to write some sort of post-processor that knows that certain things (based on key?) that look like 64 bit integers are really timestamps, and mangle them appropriately in order to get readable output. That is rather fragile.

If BSONObj::jsonString was aware that it was a high-res timestamp, it could choose to represent it in some more useful format, and I wouldn't need to make a context dependent tool.

Thinking about this some more, is there any way in the current BSONObj::toString or BSONObj::jsonString to specify how UTC datetime objects should be formatted, especially in the 'pretty' case of jsonString? Since I haven't used the UTC datetime field, due to its limited precision, I don't actually know how it gets printed.

Anyway, I understand your point about keeping the type-space for BSON small, and that it is painful to add new types. However, I imagine I'm not the only one who will want something more fine-grained than milliseconds when representing timestamps.
","Jul 22 2010 03:20:25 PM UTC;acm;I should clarify: this is of particular interest w.r.t. to using BSON as a logging format, where the consumer is often a human trying to read log entries after conversion from BSON to JSON. Obviously, if the consumer is code, it is much easier for it to understand that certain fields, though represented as a raw int64, are really timestamps.","Mar 29 2012 04:50:34 PM UTC;brianknox;Any plans for this feature?  I ask because Rainer just added millisecond precision unix time to rsyslog, and it would be awesome to go straight into mongo with that information using the ommongodb output plugin.  Thanks!","Mar 29 2012 05:11:47 PM UTC;eliot;@brian - datetime is already millisecond precision.

this ticket is for micro (or nano)","Mar 29 2012 05:21:52 PM UTC;jzwinck;I really want this feature, and I really want it to be with nanoseconds (else I'll be stuck where I am now, which is exactly where Andrew was stuck almost two years ago).  Pretty please?  This would be very valuable for people who write high-frequency events to MongoDB, regardless of syslog.

This is literally the only extra field type I really wish BSON had, and I've used it for a while.","Mar 29 2012 05:22:52 PM UTC;brianknox;Oh!  I should have read more carefully - well that's great news then.  :)
You have me the feature I wanted without having to do anything other than
point out it already does it ;)

Brian


","Mar 25 2013 03:54:00 AM UTC;victorhooi;Hi,

I can second that this feature would be awesome as well.

We have high-precision events (nano-seconds) that we'd like to store in MongoDB, and have it be aware that they were datetimes as well.

Any idea on whether this will ever be implemented?

Cheers,
Victor",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Allows hints when multiple indexes are used,SERVER-1649,12860,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-query-execution,scotthernandez,scotthernandez,Aug 21 2010 07:22:29 PM UTC,Oct 20 2020 09:41:29 PM UTC,Feb 17 2021 11:15:22 AM UTC,,1.6.1,,,,Backlog,Querying,,,,15,asya,,,,,"Currently for $or specifying a hint is ambiguous since more than one index can be used. It would be nice to have a syntax to specify a hint of/for multiple indexes.

I have no idea how to do this; Maybe you could specify a list and the query optimizer will try to the choose per query clause...

As the query optimizer gets more complex (and more than one index can be used per query) this is only going to become more of an issue.",,,,,,,,,,,,SERVER-22741,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,5002K00000fGlIkQAK,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,331084800,,,,,,,,PM-272,,,,,,,,,,,,,,,,,,,,true,craig.homa(craig.homa),2010-08-21 19:22:29.0,,,,,,,,No,,,,,,backlog-query-execution(JIRAUSER1257109),scotthernandez(scotthernandez),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i0766f:",,,,,,,"0|i00st3:",6231,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i1ivx3:",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Need Option to Set Null Semantics,SERVER-27371,337973,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-query-optimization,bryan.reinero,bryan.reinero,Dec 12 2016 06:31:10 AM UTC,Oct 20 2020 09:40:52 PM UTC,Feb 17 2021 11:15:22 AM UTC,,,,,,Backlog,Aggregation Framework,,,,0,,,,,,"In SQL NULL is not a value, which means that any comparison to NULL is false, even if both sides are NULL.  In MongoDB, however, null is considered a value. It would be helpful to have an aggregation option to set SQL null semantics, where fields that are either NULL, undefined, or missing return false when compared to NULL.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2016-12-21 16:10:56.0,131155200,,,,,,,,PM-873,,,,,,,,,,,,,,,,,,,,true,craig.homa(craig.homa),Wed Dec 21 16:10:56 UTC 2016,,,,,,,,,,,,,,asya(asya),backlog-query-optimization(JIRAUSER1257108),bryan.reinero(bryan.reinero@10gen.com),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i01ebb:",,,,,,,"0|i00t27:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i01h9j:","Dec 21 2016 04:10:56 PM UTC;asya;In addition, in MongoDB language, when a field is missing, sometimes it's considered equal/equivalent to the value being null.

Aggregation framework in particular has a concept of ""null-ish"" values which are treated the same way in some contexts.
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
array indexes and object subfields should be referenced with different syntax,SERVER-4753,29024,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-query-optimization,nsanch,nsanch,Jan 24 2012 04:35:03 PM UTC,Oct 20 2020 09:39:31 PM UTC,Feb 17 2021 11:15:22 AM UTC,,,,,,Backlog,Write Ops,,,,4,,,,,,"It is currently the case that if you send an update like:

{ $set: { ""foo.0"": ""x"" } }

You may be updating either index 0 of the array foo or the key ""0"" in an object. If ""foo"" exists as an array, then it updates index 0. If it's an object, it updates the key ""0"". The problem is that if ""foo"" doesn't yet exist, then mongo assumes you want an object.

This has bitten us a couple times, where we've ended up with objects with numeric keys, instead of arrays.

Ideally the syntax for these two cases would be different so there wouldn't be ambiguity. For example, array indexes could be referenced with []. It would be difficult to ever deprecate the old dot notation, but callers could switch to the square brackets and not run the risk of having this problem.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,8.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2012-01-25 06:30:59.0,279936000,,,,,,,,PM-1253,,,,,,,,,,,,,,,,,,,,true,craig.homa(craig.homa),Wed Apr 04 19:24:09 UTC 2012,,,,,,,,No,,,,,,backlog-query-optimization(JIRAUSER1257108),eliot(eliot),glenn(glenn),nsanch(nsanch),scotthernandez(scotthernandez),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i06567:",,,,,,,"0|i00qw7:",4810,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i17qqn:","Jan 25 2012 06:30:59 AM UTC;eliot;this could work:
{code}
{ $set : { ""foo[0]"" : ""X"" } }
{code}

this might be less breaking:
{code}
{ $set : { ""foo.[0]"" : ""X"" } }
{code}
","Jan 25 2012 07:07:51 PM UTC;nsanch;is foo.[0] a valid way to reference the key ""[0]"" in the object foo? if so, i'm not a big fan since there's still some ambiguity there -- mongo would have to decide whether an update to foo.[0] is supposed to change an object subfield or an array index, and if the foo key doesn't exist, has to decide whether to make an object or an array. making that decision based on the format of the key is unintuitive at the least, and will bite someone else in the long run.","Jan 25 2012 07:13:32 PM UTC;scotthernandez;It is not currently a valid way, no. But the idea is that it could be a syntax to allow more explicit behavior when inserting/update+upsert to affirm you want an array and not a field name.

As you said, unless there are characters which cannot be used in field names then this could be ambiguous and confusing to some (even if some is < .001 %). It is also possible to declare brackets numbers as special in field names... so that at least it is documented.","Jan 25 2012 08:53:36 PM UTC;nsanch;But if you only use dots for objects and square brackets for arrays there's no potential ambiguity, and no concerns about existing data with ""[0]"" as a key name in an embedded object. Is there an advantage to using dot-then-square-brackets in the array case given that it introduces ambiguity?","Jan 25 2012 09:02:46 PM UTC;scotthernandez;I think Eliot was just suggesting it as it would break less things since we already have the dot - ordinal notation for arrays, and somewhat special handling for that whole field name (in dot notation) for the "".#.""","Jan 25 2012 09:07:09 PM UTC;nsanch;Got it, thanks for the explanation.","Apr 04 2012 07:10:44 PM UTC;glenn;It's a bit ugly, but {""foo.$[0]"": ""X""} is unambiguous, since an object key can't begin with $.

""foo.$idx[0]"" might be a bit more future-proof.

I strongly recommend against ""foo[0]"".  I have to parse and navigate dotted paths by hand now and then, and that's a lot more work to parse compared to 'a.b.c'.split('.').  It's also still ambiguous.  (Please don't make brackets special in field names!  There are already too many keys which are valid JSON object keys that aren't allowed as keys in Mongo, like email addresses.)
","Apr 04 2012 07:24:09 PM UTC;nsanch;$idx is fine by me.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Using dot-notation to field-select an element by position from a nested Array fails to return the element,SERVER-1831,13153,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-query-optimization,glennmoki,glennmoki,Sep 22 2010 09:14:30 PM UTC,Oct 20 2020 09:39:23 PM UTC,Feb 17 2021 11:15:22 AM UTC,,1.6.2,,,,Backlog,Querying,,,,16,query-44-grooming,,,,,"It seems reasonable that if dot-notation works as a field-selector when selecting object members, that it should also work when selecting array indexes,
but that doesn't seem to be the case with the current version of MongoDB.
Case:

{noformat}
// Get the entire array (succeeds):

> db.foo.find({""key"":""12345""}, {""array_field""})

{ ""_id"" : ObjectId(""4c9a41204cb16aa4fe28c4cc""), ""array_field"" : [
        {
                ""bar"" : ""data"",
                ""bam"" : ""more data"",
        }
] }


// Attempt to get first element in array (index 0):

> db.foo.find({""key"":""12345""}, {""array_field.0"":1})

{ ""_id"" : ObjectId(""4c9a41204cb16aa4fe28c4cc""), ""array_field"" :
[ { } ] } 
{noformat}

The second command fails to return anything.  You can in fact use the $slice operator to get the element, but then the command becomes large and ugly:

{noformat}
> db.foo.find({""key"":""12345""}, {_id:1, array_field:{$slice:[0,1]}}) 
{noformat}

When developing custom ORM classes to access Mongo, this special case will be needed when accessing an array element by index.  This seems unnecessary.
I suggest that Mongo handle dot-notation the same for Arrays as it already does for Objects, and simply allow you to select by index.  (Note, that a find query does allow array indexes in the dot notation, but the field select param does not)
",Mac OSX 64bit,,,,,,,,,,,PM-684,PM-869,PM-1253,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2012-08-07 08:13:19.0,50544000,,,,,,,,PM-1253,,,,,,,,,,,,,,,,,,,,true,craig.homa(craig.homa),Fri Jul 12 17:51:24 UTC 2019,,,,,,,,No,,,,,,backlog-query-optimization(JIRAUSER1257108),david.storch(david.storch),glennmoki(glennmoki),lvishnu87(lvishnu87),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i073un:",,,,,,,"0|i00qvz:",4746,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i0qcjr:","Aug 07 2012 08:13:19 AM UTC;lvishnu87;It is very reasonable since mongodb design drives people to prefer embedding and one does not want to fetch all the array elements into program memory. ","Jul 12 2019 05:51:24 PM UTC;david.storch;Projection does not currently support the concept of including or excluding by array index, either in the {{find}} command or in aggregate's {{$project}} stage. We should add this as a new feature, though it would likely involve the introduction of new syntax, e.g. find(<match>, \{""arr.$[0]"": 1}) for including only the first element of the array {{arr}}.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
slowms should be per database for profiler,SERVER-4785,29213,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-query-optimization,scotthernandez,scotthernandez,Jan 26 2012 07:05:06 PM UTC,Oct 20 2020 09:38:36 PM UTC,Feb 17 2021 11:15:22 AM UTC,,,,,,Backlog,Performance,,,,2,profiling,query-44-grooming,stats,,,"The slowms constant is not per database but is process wide.

{code}
> db.setProfilingLevel(1,1000)
{ ""was"" : 0, ""slowms"" : 100, ""ok"" : 1 }
> db.getProfilingStatus()
{ ""was"" : 1, ""slowms"" : 1000 }
> use test2
switched to db test2
> db.setProfilingLevel(1,2)
{ ""was"" : 0, ""slowms"" : 1000, ""ok"" : 1 }
> db.getProfilingStatus()
{ ""was"" : 1, ""slowms"" : 2 }
> use test
switched to db test
> db.getProfilingStatus()
{ ""was"" : 1, ""slowms"" : 2 }
{code}

Notice how slowms went to 2 in the test database... That is not good.",,,,,,,,WRITING-2440,,,,SERVER-4786,SERVER-11125,,,,,,,,,,,,,,,,,,,3.0,,,,,,,,,,,,,,,,,,,,,500A000000UaSWwIAN,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2018-01-02 15:28:07.0,96681600,<a href='https://jira.mongodb.org/browse/WRITING-2440'>WRITING-2440</a>,,,,,,,PM-1041,,,,,,,,,,,,,,,,,,,,false,craig.homa(craig.homa),Wed Jan 24 23:33:53 UTC 2018,,,,,,,,No,,,,,,asya(asya),backlog-query-optimization(JIRAUSER1257108),scotthernandez(scotthernandez),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i064s7:",,,,,,,"0|i00qtr:",4886,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i0sgbr:","Jan 02 2018 03:28:07 PM UTC;asya;SERVER-5266 was closed won't fix but if the syntax of db.setProfilingLevel is changed to only affect a single database there will be requirement to have syntax to set globally what slowms is (without having to restart mongod with new slowms setting).

Note that this change as proposed is backwards breaking to every instruction given by our support which is currently assumed to have global effect. 

Recommend we consider non-backwards breaking syntax, like {{db.setProfilingLevel(0,1,false)}} where last parameter is ""applyGlobally"" and by default is true.  (or applyToCurrentDB only and by default is false).
","Jan 24 2018 11:33:21 PM UTC;asya;Open questions that aren't clear and need to be clarified before implementation for this ticket can be completed (as well as for any ticket dealing with logging operations on mongos).

Does the ""db-only"" flag apply to slowms *and* sampleRate? 

What if global setting is later changed, does the global setting override earlier set DB only setting?   

Or should the most ""verbose"" setting apply between global and per-db?
 

","Jan 24 2018 11:33:53 PM UTC;asya;Since slowms applies to profiling as well as logging, should per-db change also apply to both or to profiling only?
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Provide stack limit for javascript measured in call depth, rather than bytes",SERVER-34850,539288,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-query-execution,jason.carey,jason.carey,May 04 2018 05:36:56 PM UTC,Oct 20 2020 09:37:21 PM UTC,Feb 17 2021 11:15:22 AM UTC,,,,,,Backlog,JavaScript,,,,1,,,,,,"Being able to specify recursion limits in stack depth, rather than in bytes, would improve diagnostics and reliability of exceeding the limit.

We could also use it to quickly limit execution in fuzzing tests

 ",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,Fully Compatible,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2020-09-21 21:39:54.0,88041600,,,,,,,,PM-1145,,,,,,,,,,,,,,,,,,,,true,craig.homa(craig.homa),2018-05-04 17:36:56.0,,,,,,,,,,,,,,backlog-query-execution(JIRAUSER1257109),jason.carey(jason.carey),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i2fman:",,,,,,,"0|i00quv:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i2fkef:",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Provide options to JSThread which control heap and stack limits,SERVER-34849,539287,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-query-execution,jason.carey,jason.carey,May 04 2018 05:34:16 PM UTC,Oct 20 2020 09:37:14 PM UTC,Feb 17 2021 11:15:22 AM UTC,,,,,,Backlog,JavaScript,Testing Infrastructure,,,1,,,,,,Options to set the heap limit and stack depth of javascripts scopes created by jsthread in the shell would allow for smaller sandboxes (and quicker time to failure) when running fuzzing code,,,,,,,,,,,,SERVER-28922,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,Fully Compatible,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2020-09-21 21:39:55.0,88041600,,,,,,,,PM-1145,,,,,,,,,,,,,,,,,,,,true,craig.homa(craig.homa),2018-05-04 17:34:16.0,,,,,,,,,,,,,,backlog-query-execution(JIRAUSER1257109),jason.carey(jason.carey),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i2fmaf:",,,,,,,"0|i00qun:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i2fke7:",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
distinct needs to have a way to output to a cursor for large result sets,SERVER-3141,17476,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-query-optimization,vkuznet,vkuznet,May 25 2011 12:03:23 PM UTC,Oct 20 2020 09:36:08 PM UTC,Feb 17 2021 11:15:22 AM UTC,,,,,,Backlog,Querying,,,,8,query,,,,,"For use case please see http://groups.google.com/group/mongodb-user/browse_frm/thread/b9de8d8c90125ddd

The current distinct operation return different from cursor type, the list. The returned list can be large, which creates problem at application level. For example, making pagination become cumbersome, since it requires to fetch the list at every page, rather then using cursor/idx/limit/count operations. The situation get worse in concurrent applications.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,4.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2011-05-26 05:59:13.0,269136000,,,,,,,,PM-941,,,,,,,,,,,,,,,,,,,,true,craig.homa(craig.homa),Tue Aug 07 19:57:22 UTC 2012,,,,,,,,No,,,,,,backlog-query-optimization(JIRAUSER1257108),eliot(eliot),rlaferla(rlaferla),vkuznet(vkuznet),zacwitte(zacwitte),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i06oif:",,,,,,,"0|i00t5j:",6130,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i0bp2n:","May 26 2011 05:59:13 AM UTC;eliot;This may be handled by the new aggregation framework","Oct 25 2011 06:40:04 PM UTC;zacwitte;@Eliot, have any update for us? This would be hugely useful.","Oct 25 2011 06:43:03 PM UTC;eliot;Not at this time.
The new aggregration framework should be in 2.2, and therefore in 2.1 at some point.
You can follow SERVER-447","Aug 07 2012 07:57:22 PM UTC;rlaferla;This doesn't appear to be working in 2.1.2 nor 2.2.0-rc0.  I really need distinct to return a cursor because I have a large database with 25M records to work with.
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
$graphLookup doesn't support search within specific field(like SQL based grammar of 'select'),SERVER-38560,651326,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-query-optimization,tyin,tyin,Dec 12 2018 11:12:38 AM UTC,Oct 20 2020 09:30:57 PM UTC,Feb 17 2021 11:15:22 AM UTC,,,,,,Backlog,Aggregation Framework,,,,5,,,,,,"As designed, $graphLookup is only capable of traversing a graph recursively, that is, by performing repeated queries on the ""connectToField"" value. However, if documents are huge because of many other fields that are not important(want to be ignored) for current graphlookup search, this will lead to the search exceeding the maximum memory usage. Leverage disk during the search will make bad performance.   $graphLookup should support an option that accepts a select within fields(very similar to  $project.), and this could be applied at each stage of the breadth-first search.  

For example, consider a set of flight data, where each document represents a flight between two cities:

 
|{ from: '1', to: '2' , oi: 'hugeJsonString1' }|
|{ from: '2', to: '3', oi: 'hugeJsonString1' }|
|{ from: '4', to: '5',  oi: 'hugeJsonString1' }|
|...|

 

If a user wishes to figure out all cities they can fly to from New York within two stops, but he doesn't care about the 'oi' part, they could add a 'project' keyword to exclude it during each stage of graphlookup search, like below: 

 
|{$graphLookup: {|
|from: 'flights',|
|project: \{'oi': 0},|
|connectToField: 'from',|
|connectFromFIeld: 'to',|
|as: 'destinations'|
|}}|",,,,,,,,,,,,PRODUCT-515,PM-814,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2018-12-14 16:44:34.0,20044800,,,,,,,,PM-851,,,,,,,,,,,,,,,,,,,,true,craig.homa(craig.homa),Tue Jun 30 06:06:54 UTC 2020,,,,,,,,,,,,,,backlog-query-optimization(JIRAUSER1257108),dennis@valueblue.nl(dennis@valueblue.nl),kelsey.schubert(thomas.schubert),tyin(tyin),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i2ylzj:",,,,,,,"0|i00t1r:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i2yk3b:","Dec 14 2018 04:44:34 PM UTC;kelsey.schubert;Thank you for the feature request, [~tyin]. I've marked this ticket for consideration by the Query Team.

Kind regards,
Kelsey","Jun 30 2020 06:06:54 AM UTC;dennis@valueblue.nl;This is really needed so a good implementation of $graphlookup can be done. In ""real"" collections there is a good possibility for a out of memory. When there is a option to ""$project"" the fields of the related documents this can be eliminated. I'm now forced to implement a custom solution because there is no such feature in place. I was really expecting this to be in place since we are almost on version 4.4 now (where $graphlookup was implemented in 3.4).",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Keep track of how many times a particular query shape was used and its cumulative latency,SERVER-29115,382084,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-query-execution,alex.komyagin,alex.komyagin,May 08 2017 09:41:24 PM UTC,Oct 20 2020 09:29:42 PM UTC,Feb 17 2021 11:15:22 AM UTC,,,,,,Backlog,Querying,,,,1,,,,,,"For index building purposes it would be extremely useful to have a counter per query shape and the associated cumulative latency, even if it's not super accurate.

While it's possible to parse profiler and/or mongod logs to obtain the same information, this generates extra disk IO and requires users to essentially duplicate the effort (since we have to determine the shape and measure the latency in the server anyway).",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2017-05-12 14:40:36.0,119232000,,,,,,,,PM-279,,,,,,,,,,,,,,,,,,,,false,craig.homa(craig.homa),2017-05-08 21:41:24.0,,,,,,,,,,,,,,alex.komyagin(alex.komyagin@10gen.com),backlog-query-execution(JIRAUSER1257109),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i1p0iv:",,,,,,,"0|i00str:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i00a3j:",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
[FLE] Mark literals for encryption that will be written as part of pipeline updates,SERVER-41485,787992,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-query-optimization,jacob.evans,jacob.evans,Jun 03 2019 10:38:28 PM UTC,Oct 20 2020 09:26:10 PM UTC,Feb 17 2021 11:15:22 AM UTC,,,,,,Backlog,Querying,,,,0,,,,,,"Without this task, all literals will be assumed to be unencrypted if not sourced from an already encrypted field and failure will occur if we attempt to update an encrypted field with a literal. We can improve this situation by maintaining a set of literals headed to ""Fowarded"" output. Once we are done walking the pipeline, if headed to an encrypted field, we can mark each member of the set for encryption.

We could also use the mechanism to mark literals that were part of previous stages in non-update pipelines for extra credit.",,,,,,,,SERVER-41807,,,,,,,,,,,,,,,,,,,,,,,,2.0,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2019-06-18 16:30:42.0,52617600,<a href='https://jira.mongodb.org/browse/SERVER-41807'>SERVER-41807</a>,,,,,,,PM-1479,,,,,,,,,,,,,,,,,,,,true,craig.homa(craig.homa),Tue Jun 18 16:31:14 UTC 2019,,,,,,,,,,,,,,backlog-query-optimization(JIRAUSER1257108),xgen-internal-githook(xgen-internal-githook),jacob.evans(jacob.evans),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i3ltvz:",,,,,,,"0|i00qyf:",9223372036854775807,,,,,,,,,,,,Query 2019-06-17,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i3lrzr:","Jun 18 2019 04:30:42 PM UTC;xgen-internal-githook;Author:{'name': 'Jacob Evans', 'email': 'jacob.evans@10gen.com'}
Message: SERVER-41485 Make tree type to support yet-to-be-determined encryption
Branch: master
https://github.com/10gen/mongo-enterprise-modules/commit/044fb8157b04c68384593c0dd4fc55774ad5b4a2","Jun 18 2019 04:31:14 PM UTC;xgen-internal-githook;Author:{'name': 'Jacob Evans', 'email': 'jacob.evans@10gen.com'}
Message: SERVER-41485 Make tree type to support yet-to-be-determined encryption
Branch: v4.2
https://github.com/10gen/mongo-enterprise-modules/commit/0be92a9dc8f55661089eb3cbef7357a2ef612f0a",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Statistics-based query optimization,SERVER-20619,231398,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-query-optimization,david.storch,david.storch,Sep 24 2015 06:42:09 PM UTC,Oct 20 2020 09:03:19 PM UTC,Feb 17 2021 11:15:22 AM UTC,,,,,,Backlog,Querying,,,,4,,,,,,,,,,,,,,,,,,SERVER-20616,SERVER-13740,SERVER-12923,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2015-12-18 23:24:06.0,170380800,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,craig.homa(craig.homa),2015-09-24 18:42:09.0,,,,,,,,,,,,,,backlog-query-optimization(JIRAUSER1257108),david.storch(david.storch),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i02isn:",,,,,,,"0|i00vzz:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i06t5z:",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Add optimization to execute $lookup on local shards when possible,SERVER-28705,372480,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-query-optimization,geekox86,geekox86,Apr 10 2017 04:48:56 AM UTC,Oct 20 2020 09:02:17 PM UTC,Feb 17 2021 11:15:22 AM UTC,,,,,,Backlog,Aggregation Framework,Sharding,,,1,,,,,,"Performing joins using local shard indices is cheap. In this setup, parent-child relationships can be implemented as long parent and child documents live on the same shard through proper routing by application developers. This feature is similar to ElasticSearch has_parent and has_child queries. $joinOne works with a single object while $joinMany works with an array of objects.",,,,,,,,SERVER-29159,,,,SERVER-27496,,,,,,,,,,,,,,,,,,,,3.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2017-04-10 12:33:50.0,118886400,<a href='https://jira.mongodb.org/browse/SERVER-29159'>SERVER-29159</a>,,,,,,,PM-282,,,,,,,,,,,,,,,,,,,,true,craig.homa(craig.homa),Fri May 12 15:47:52 UTC 2017,,,,,,,,,,,,,,backlog-query-optimization(JIRAUSER1257108),charlie.swanson(charlie.swanson),kelsey.schubert(thomas.schubert),geekox86(geekox86),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i1nd9j:",,,,,,,"0|i00sxj:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i0139z:","Apr 10 2017 12:33:50 PM UTC;kelsey.schubert;Hi [~geekox86],

Thank you for the feature request. I've linked a related ticket, SERVER-27496, would you please review it and see if it meets your requirements. If not, would you please clarify how these commands would behave, and give an example of their usage?

Kind regards,
Thomas","Apr 11 2017 04:34:21 AM UTC;geekox86;Hi, I think in MongoDB terminology, if both the local and foreign fields of the $lookup operation on all documents to be joined share the same shard key then this means that this operation can happen during scatter phase locally on shards, correct? If yes then the linked issue is very similar to what I am asking.","May 12 2017 03:47:52 PM UTC;charlie.swanson;Hi all,

I'd like to clarify a couple things. For one, the $joinOne part of this ticket has already been requested in SERVER-22384, so I will remove that part of this request so that it can be tracked independently. Please add comments related to that request on SERVER-22384 to help us track the discussion. Second, I don't think I understand this request given that [$lookup cannot look up into sharded collections|https://docs.mongodb.com/manual/reference/operator/aggregation/lookup/]:
{quote}
The from collection cannot be sharded.
{quote}

Knowing this, I can't think of any case where the described optimization makes sense, so I'd like to close this as ""Won't Fix"", or maybe mark it as 'depends on' SERVER-29159. Further, even if the 'from' collection were allowed to be sharded, there is no way that I know of to define a relationship between the shard keys of two collections to guarantee that some sort of parent/child or primary key/foreign key relationship will always be co-located.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Implement CST cases for $regex,SERVER-51294,1498120,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-query-optimization,david.percy,david.percy,Oct 01 2020 09:08:45 PM UTC,Oct 20 2020 07:00:50 PM UTC,Feb 17 2021 11:15:22 AM UTC,,,,,,Backlog,,,,,0,qopt-team,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,11923200,,,,,,,,PM-1749,,,,,,,,,,,,,,,,,,,,true,craig.homa(craig.homa),2020-10-01 21:08:45.0,,,,,,,,,,,,,,backlog-query-optimization(JIRAUSER1257108),david.percy(david.percy),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i6xv7z:",,,,,,,"0|i00r33:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i6xtbj:",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Allow union of dynamic collection names,SERVER-48923,1382896,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-query-optimization,charlie.swanson,charlie.swanson,Jun 17 2020 06:36:38 PM UTC,Oct 20 2020 07:00:00 PM UTC,Feb 17 2021 11:15:22 AM UTC,,,,,,Backlog,Aggregation Framework,,,,0,qopt-team,,,,,"The $unionWith stage requires a collection name given as a string. It would be great if we could add an option for somehow specifying a regex or an array/range to union many collections at once. Perhaps something like 

{code:js}
db.example.aggregate([{$unionWith: {regex: /^months2020.[0-9]*/}}])
{code}
 ",,,,,,,,,,,,INIT-53,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,21081600,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,craig.homa(craig.homa),2020-06-17 18:36:38.0,,,,,,,,,,,,,,backlog-query-optimization(JIRAUSER1257108),charlie.swanson(charlie.swanson),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i6e55b:",,,,,,,"0|i00ztr:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i6e38v:",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Provide mechanism to clear/acknowledge startup warnings,SERVER-19790,224372,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-server-security,victor.hooi,victor.hooi,Aug 06 2015 02:56:34 AM UTC,Oct 20 2020 06:58:05 PM UTC,Feb 17 2021 11:15:22 AM UTC,,,,,,Backlog,Admin,Logging,,,6,move-sec,,,,,"The {{mongod}} process can generate startup warnings under a number of scenarios (running as root, read-ahead values not optimal, THP enabled, _id index missing).

These warnings appear both in the {{mongod.log}} logfile, as well as at the {{mongo}} shell prompt each time you login. (It's the second of these which this ticket concerns).

However, these warnings are static - that is, they will not disappear even if the original condition is resolved, until the {{mongod}} process is restarted.

Whilst some of these warnings refer to situations that would not change without a {{mongod}} restart anyway (e.g. read-ahead settings), others refer to situations that may be transient or that could have already been resolved (e.g. missing _id index, or THP settings).

{{mongod}} should provide some mechanism to acknowledge/suppress or clear a warning for a condition that the user already knows has already been resolved, so that it would not appear on each subsequent {{mongo}} login.",,,,,,,,,,,,SERVER-17522,MMSSUPPORT-14347,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,5002K00000ek3wHQAQ,5002K00000pmMIxQAM,5002K00000pnbZTQAY,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2015-08-06 03:47:48.0,33177600,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,,Thu Jan 30 11:00:30 UTC 2020,,,,,,,,,,,,,,backlog-server-security(backlog-server-security),nicholas.cottrell(nicholas.cottrell),victor.hooi(victor.hooi),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i02njj:",,,,,,,"0|i05oz3:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i0qorz:","Jan 30 2020 11:00:30 AM UTC;nicholas.cottrell;I'd like to see a new configuration option to disable specific startup warnings, so that remaining warnings are true positives and don't spam Ops Manager alerts etc.

I envisage a new configuration file option like {{systemLog.hideWarnings}} which takes an array of strings like {{""dbPath-ext4""}} that disables just the ext4 dbPath volume warning, but leaves all others in place.

This will require naming every warning and adding logic in [startup_warnings_mongod.cpp|https://github.com/mongodb/mongo/blob/master/src/mongo/db/startup_warnings_mongod.cpp] and [startup_warnings_common.cpp|https://github.com/mongodb/mongo/blob/master/src/mongo/db/startup_warnings_common.cpp].",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Add a new $elemMatch-like operator which matches both arrays and scalars,SERVER-47925,1338881,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-query-execution,shaggie76,shaggie76,May 04 2020 03:25:37 PM UTC,Oct 20 2020 06:54:11 PM UTC,Feb 17 2021 11:15:22 AM UTC,,4.0.16,,,,Backlog,Querying,,,,0,qexec-team,,,,,"Imagine a collection where the field ""a"" can store either an integer or an array of integers:

{code}
> db.c.find();
{_id: 1, a: 3}
{_id: 2, a: [4, 11]}
{_id: 3, a: [-1, 10]}
{code}

Now, suppose that a user wishes to find documents where either ""a"" is a number in the interval \[0, 10\], or ""a"" is an array containing at least one number in the interval \[0, 10\]. This query should match documents {{_id:1}} and {{_id:2}}, but not {{_id:3}}. A naive way to write this query would be like so:

{code}
> db.c.find({a: {$gte: 0, $lte: 10}});
{_id: 1, a: 3}
{_id: 2, a: [4, 11]}
{_id: 3, a: [-1, 10]}
{code}

As you can see, the semantics of this query are to match all three documents, which was not our intention. This is because there is no requirement that an individual array element satisfy both the {{$gte}} and the {{$lte}} predicate simultaneously. In order to express this simultaneity for array elements, the match language offers [{{$elemMatch}}|https://docs.mongodb.com/manual/reference/operator/query/elemMatch/]:

{code}
> db.c.find({a: {$elemMatch: {$gte: 0, $lte: 10}}});
{_id: 2, a: [4, 11]}
{code}

Unfortunately, as you can see above, this query is not quite right either. {{_id:3}} no longer matches, which is good, but {{_id:1}} also no longer matches. Recall that the query which we want to express should match {{_id:1}} and {{_id:2}}. However, the {{$elemMatch}} predicate filters out documents where ""a"" is not an array. This scenario motivates a feature request. We should have an operator in the match language which is akin to {{$elemMatch}}, but also matches scalars:

{code}
> db.c.find({a: {$inventedNewKindOfElemMatch: {$gte: 0, $lte: 10}}});
{_id: 1, a: 3}
{_id: 2, a: [4, 11]}
{code}

This hypothetical new operator would also allow the query planner to use tight index bounds over multikey indexes, which should avoid any slow plans with loose index bounds such as those discussed in the original issue report below.

h4. Original description

We have a collection of 28 million records that have a IP field that is sometimes a NumberInt (for IPv4), sometimes BinData (for IPv6), and sometimes an array of two elements of either type (we sometimes need to track two addresses).

Historically this was a regular index – IP was just a scalar – and way back in those days we had scripts that would run range queries to find people associated with a CIDR block or an ASN routing block. Before we went multi-key these range queries were super fast however today I found that now a range query is so slow I'm not sure it's actually doing anything:

db.accounts.count(\{IP:{$gte:NumberInt(-656117760),$lte:NumberInt(-656116737)}})

I waited for over 5 minutes before aborting it.

If I convert this into a dumb loop of 1023 scalar queries it's super fast:

var count = 0; for(var i = -656117760; i <= -656116737; ++i) \{ count += db.accounts.count({IP:NumberInt(i)}); } print(count);

This took about 2 seconds, if that.

I double checked with query-explain and it looks like it's still doing an IXSCAN so I can't understand why the smart query should take so long (see attached explain.txt). The only difference seems to be that when it's scanning a multi-key index the index bounds are infinite on one side.

I did a quick skim of the 4.2 release notes and didn't see any mention of this being improved - sorry if I missed it.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,"May 05 2020 03:17:04 PM UTC;shaggie76;diagnostic.data.zip;https://jira.mongodb.org/secure/attachment/258685/diagnostic.data.zip","May 04 2020 03:14:17 PM UTC;shaggie76;explain.txt;https://jira.mongodb.org/secure/attachment/258512/explain.txt","May 05 2020 03:17:04 PM UTC;shaggie76;mongod.zip;https://jira.mongodb.org/secure/attachment/258684/mongod.zip",10.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2020-05-04 19:26:56.0,24019200,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,craig.homa(craig.homa),Thu May 14 22:05:34 UTC 2020,,,,,,,,,,,,,,backlog-query-execution(JIRAUSER1257109),carl.champain(carl.champain),david.storch(david.storch),shaggie76(shaggie76),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i674fb:",,,,,,,"0|i00zrz:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i672iv:","May 04 2020 07:26:56 PM UTC;carl.champain;Hi [~shaggie76],

Thanks for the report.
Would you please archive (tar or zip) the {{mongod.log}} files and the {{$dbpath/diagnostic.data}} directory (the contents are described [here|https://docs.mongodb.com/manual/administration/analyzing-mongodb-performance/#full-time-diagnostic-data-capture]) covering this issue? I've created a secure [upload portal|https://10gen-httpsupload.s3.amazonaws.com/upload_forms/432bca42-9658-49fb-b899-b2cf76cb7ca8.html] for you. Files uploaded to this portal are visible only to MongoDB employees and are routinely deleted after some time.

Kind regards,
 Carl
  ","May 05 2020 03:16:58 PM UTC;shaggie76;To avoid straining our production servers I ran a very slow mongoexport to extract just _id and IP and host it in a developer workstation to gather this information for you.

Having 99% of the document data removed does help considerably – roughly speaking the for-loop brute force query takes about 1 second and the single count query takes 22 seconds.

I will attach the data and log as requested – please let me know if I have missed something because now that I have a test bench I can run it again easily.

 ","May 06 2020 05:10:22 PM UTC;carl.champain;Hi [~shaggie76],

We think that using [$elemMatch|https://docs.mongodb.com/manual/reference/operator/query/elemMatch/] in your query should solve the performance issue:
{noformat} db.accounts.find({IP: {$elemMatch: {$gte:NumberInt(-656117760),$lte:NumberInt(-656116737)}}}){noformat}
Let us know if it worked!
 Carl","May 06 2020 06:07:15 PM UTC;shaggie76;I realized something was up when I noticed that the brute force way didn't match the range query:
{code:java}> var count = 0; for(var i = -656117760; i <= -656116737; ++i) { count += db.accounts.count( {IP:NumberInt(i)} ); } print(count);
49 
> db.accounts.count({IP:{$gte:NumberInt(-656117760),$lte:NumberInt(-656116737)}})
2971
{code}
So it occurred to me that exact match was missing array elements or range match might be returning results that don't belong (spoiler: it's returning results that don't belong).
  
 I checked if it was counting all arrays blindly, but it turns out that isn't it:
{code:java}> db.accounts.count({IP:{$type:4}})
23024
{code}
I checked elemMatch and it doesn't work for scalars (as expected)
{code:java}> db.accounts.count({IP: {$elemMatch: {$gte:NumberInt(-656117760),$lte:NumberInt(-656116737)}}})
0
{code}
It does work for array elements of course:
{code:java}> db.accounts.find({IP: {$elemMatch: {$gte:NumberInt(782650415),$lte:NumberInt(782650417)}}})
{ ""_id"" : ObjectId(""xxx""), ""IP"" : [ 782650416, -1338277100 ] }
{code}
 
  The standard range-query works for scalar matches which makes sense:
  
{code:java}> db.accounts.find({IP:{$gte:NumberInt(-656117760),$lte:NumberInt(-656116737)}},{IP:1}).limit(1).pretty()
{ ""_id"" : ObjectId(""xxx""), ""IP"" : -656117739 }  {code}
However the multi-key index also has array elements and the same query has matches that don't belong:
{code:java}> db.accounts.find({IP:{$gte:NumberInt(-656117760),$lte:NumberInt(-656116737)}},{IP:1}).skip(1000).limit(1).pretty()
{
        ""_id"" : ObjectId(""xxx""),
        ""IP"" : [
                782650416,
                -1338277100
        ]
}{code}
What's surprising to me is that an exact match seems to work (and is what we generally do):
{code:java}> db.accounts.find({IP:NumberInt(782650416)},{IP:1}).pretty()
{ ""_id"" : ObjectId(""xxx""), ""IP"" : 782650416 }
{ ""_id"" : ObjectId(""xxx""), ""IP"" : 782650416 }
{ ""_id"" : ObjectId(""xxx""), ""IP"" : 782650416 }
{
        ""_id"" : ObjectId(""xxx""),
        ""IP"" : [
                782650416,
                -1338277100
        ]
}
{ ""_id"" : ObjectId(""xxx""), ""IP"" : 782650416 }
 
{code}
So exact match hits scalars and array elements alike (righteous!) but range queries are hitting array elements they shouldn't (bogus!) 
  
 I tried being explicit about this:
{code:java}> db.accounts.count({
    $or : [
        {IP: {$not:{$type:4},$gte:NumberInt(-656117760),$lte:NumberInt(-656116737)}},
        {IP: {$elemMatch: {$gte:NumberInt(-656117760),$lte:NumberInt(-656116737)}}}
    ]
})
49
{code}
Which produces what I believe to be the correct count but my rough timing shows it takes about 10 seconds (again, 10x slower than the for-loop).
  
 And just to make sure I'm not crazy, I made sure there's an index:
{code:java}> db.accounts.getIndexes()
[
        {
                ""v"" : 2,
                ""key"" : {
                        ""_id"" : 1
                },
                ""name"" : ""_id_"",
                ""ns"" : ""index_test.accounts""
        },
        {
                ""v"" : 2,
                ""key"" : {
                        ""IP"" : 1
                },
                ""name"" : ""IP_1"",
                ""ns"" : ""index_test.accounts"",
                ""sparse"" : true
        }
]
{code}
In summary:
 # Exact match and elemMatch queries work as expected
 # Bounded range queries ($gte,$lte) return results for arrays that don't contain a matching element
 # 1023 exact-match querie still run about 10x faster than a $or with elemMatch

 
   
  
  
 -g","May 07 2020 05:01:22 PM UTC;carl.champain;[~shaggie76], thank you for all the info!

We could convert this ticket into a new feature request ticket: an $elemMatch-like operator that also matches scalars. What do you think?

 

 ","May 07 2020 05:40:09 PM UTC;shaggie76;I think that would be inconsistent with out exact match queries work and doesn't address the fact that range queries match results they shouldn't. If it were up to me I'd fix range queries so they work like exact-match queries.","May 08 2020 03:44:54 PM UTC;carl.champain;[~shaggie76],

We were proposing an $elemMatch-like operator that also matches scalars because we don’t have the tools yet to express the query you want: matching documents where x is a scalar in a given range, or where x is an array that has a scalar in the range. $elemMatch does the latter part, but doesn't match scalars. 

 
{quote}Bounded range queries ($gte,$lte) return results for arrays that don't contain a matching element{quote}
{{{a: {$gte: 0, $lte: 10}}}} is saying to match documents where {{a}} has at least one element greater than or equal to 0 (0, 1, …, 11 will match) AND at least one element lesser than or equal to 0 (0, -1, -2 will match). This means that {{\{a: [-1, 11]}\}} matches. The scan range is {{[0, to infinity+]}} and {{[infinity-, 10]}}, not just {{[0, 10]}}.

I hope this helps clarify!
 Carl","May 08 2020 06:03:35 PM UTC;shaggie76;Fascinating! I suppose that does make sense and I can understand that changing this behavior is impossible.

Something still isn't quite right though, because this works (but is excruciatingly slow):

 
{code:java}
> db.accounts.count({
    $or : [
        {IP: {$not:{$type:4},$gte:NumberInt(-656117760),$lte:NumberInt(-656116737)}},
        {IP: {$elemMatch: {$gte:NumberInt(-656117760),$lte:NumberInt(-656116737)}}}
    ]
}){code}
I just ran a 'time mongo --eval...' for this on a production server with dual-socket Xeon E5-2620 (24 threads) and 128GB of RAM backed by Optane SSDs and it ran for 26 minutes before I lost interest in waiting. In contrast the for-loop took 409ms and returned the right answer.

 

It's not the $or either: the 'not an array' clause is also frighteningly slow:

 
{code:java}
> db.accounts.count({IP: {$not:{$type:4},$gte:NumberInt(-656117760),$lte:NumberInt(-656116737)}})
{code}
So is it possible that it's easier to fix (and justify fixing!) the ""not an array"" part of the index walk? Or is there some other way to express this query so that it plays nice?

 

 

 ","May 11 2020 06:44:49 PM UTC;carl.champain;Hi [~shaggie76],

{noformat}db.accounts.count({IP: {$not:{$type:4},$gte:NumberInt(-656117760),$lte:NumberInt(-656116737)}}){noformat}
In order to correctly answer that query the index scan will still be large: [-656117760, infinity+]. When you create a multikey index on \{IP: [1, 2, 3]} there are three index keys: 1, 2, and 3. This means that {{{$not: {$type: 4}}}  is only applied after the index scan since Mongodb can't know from the index which document is an array or not.

That said, the SERVER project is for bugs and feature suggestions for the MongoDB server. As this ticket does not appear to be a bug, I will now close it. If you need further assistance troubleshooting, I encourage you to ask our community by posting on the [MongoDB Community Forums|http://community.mongodb.com/] or on [Stack Overflow with the {{mongodb}} tag|https://stackoverflow.com/questions/tagged/mongodb].

Kind regards,
Carl","May 14 2020 10:05:34 PM UTC;david.storch;I'm re-opening this ticket and converting it into a feature request rather than a bug report. I think the scenario of field which can be either a scalar or an array would be reason for us to add a new operator to the {{$match}} language whose semantics are {{$elemMatch}}-like, but which matches scalars instead of arrays. A similar idea was proposed long ago under SERVER-6050 and duplicate SERVER-5320. This idea was rejected, however, since it would be a major breaking change. There is nothing preventing us from adding a new concept to the language in a non-breaking fashion, however, whose semantics are like an {{$elemMatch}} that also matches scalars. I searched the backlog but couldn't find a pre-existing request for this.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
provide a way to get result/outcome of $merge or $out,SERVER-43194,918534,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-query-execution,asya,asya,Sep 06 2019 03:27:38 PM UTC,Oct 20 2020 06:53:29 PM UTC,Feb 17 2021 11:15:22 AM UTC,,,,,,Backlog,Aggregation Framework,Diagnostics,Logging,,1,qexec-team,usability,,,,"Currently there is no way to find out how many documents were written with $out or how many were merged/ignored/etc. with $merge - it would be nice to have a way to get that back from the pipeline.
",,,,,,,,,,,,SERVER-49952,SERVER-49954,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,5002K00000nC8U4QAK,5002K00000pEmOYQA0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2020-05-14 07:13:07.0,17539200,,,,,,,,PM-2025,,,,,,,,,,,,,,,,,,,,true,craig.homa(craig.homa),Tue Jul 28 18:26:15 UTC 2020,,,,,,,,,,,,,,asya(asya),backlog-query-execution(JIRAUSER1257109),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i47vnz:",,,,,,,"0|i00sr3:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i47trr:","Apr 07 2020 04:29:15 PM UTC;asya;or to see it in the log line at least.

 ","Jul 28 2020 06:26:15 PM UTC;asya;I split off the logline request into SERVER-49954 - this ticket should remain to track returning information back in the command result.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Add support for unordered object comparison in MQL,SERVER-45384,1077739,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-query-execution,mihai.andrei,mihai.andrei,Jan 06 2020 10:20:32 PM UTC,Oct 20 2020 06:53:14 PM UTC,Feb 17 2021 11:15:22 AM UTC,,,,,,Backlog,,,,,0,qexec-team,,,,,"Currently, there is no simple way to perform an unordered object comparison in MQL. It would be helpful to have an expression like $unorderedEq that would allow this.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,5.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2020-01-07 16:08:20.0,33609600,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,craig.homa(craig.homa),Fri Jan 24 14:41:51 UTC 2020,,,,,,,,,,,,,,backlog-query-execution(JIRAUSER1257109),charlie.swanson(charlie.swanson),david.storch(david.storch),jack.mulrow(jack.mulrow),mihai.andrei(mihai.andrei),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i4yv1r:",,,,,,,"0|i00zfr:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i4yt5j:","Jan 07 2020 04:08:20 PM UTC;charlie.swanson;[~mihai.andrei] and [~david.storch] our understanding is that this ticket is required for the project to ensure indexes are consistent on all shards? Should it be linked to something? Based on that assumption, we've slotted it into the next sprint and gave it the fixVersion ""4.3 Required"". Let me know if that's reasonable.","Jan 09 2020 04:03:23 PM UTC;david.storch;[~mihai.andrei] [~jack.mulrow] which team is going to do the work for this? I was under the assumption that the sharding team would do the work, and the query team will review. If this is the case, then I think this ticket should be added to the epic and moved to the sharding backlog.","Jan 09 2020 10:53:38 PM UTC;jack.mulrow;[~david.storch] I agree it would make sense for sharding to do this ticket, since we need it for a sharding project. We're hoping to avoid doing this work at all by changing how we detect inconsistent indexes to use JavaScript instead of an aggregation, but in case it does end up being necessary I took your suggestion and moved it into the indexes epic / assigned it to the sharding backlog.","Jan 22 2020 08:07:06 PM UTC;jack.mulrow;[~david.storch], [~charlie.swanson], it turns out we didn't need to implement this (we used Asya's trick to sort each object's fields with $objectToArray, $setUnion, and $arrayToObject instead) - do you want me to move this to the query backlog, or should I close it?","Jan 24 2020 02:41:51 PM UTC;david.storch;[~jack.mulrow], I'll move it to the query team's backlog. This is a useful general enhancement to the language outside of the context of finding inconsistent indexes on the shards.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Allow upsert when specifying dotted sub-paths of _id in query predicate,SERVER-44615,1001558,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-query-execution,charlie.swanson,charlie.swanson,Nov 13 2019 09:53:37 PM UTC,Oct 20 2020 06:52:48 PM UTC,Feb 17 2021 11:15:22 AM UTC,,,,,,Backlog,Querying,Write Ops,,,0,qexec-team,,,,,"[~bernard.gorman] and I had a long discussion about this when working on SERVER-43860. Today, with a shard key pattern of {{\{""bar.x"": 1, ""bar.y"": 1\}}} you are able to do an upsert in either of the following ways:
{code:js}
mongos> db.bar.replaceOne({""bar"": {x: 3, ""y"": 3}}, {unrelated: 2}, {upsert: true})
{
    ""acknowledged"" : true,
    ""matchedCount"" : 0,
    ""modifiedCount"" : 0,
    ""upsertedId"" : ObjectId(""5dcc733e983b13bb23055039"")
}
mongos> db.bar.replaceOne({""bar.x"": 2, ""bar.y"": 5}, {unrelated: 4}, {upsert: true})
{
    ""acknowledged"" : true,
    ""matchedCount"" : 0,
    ""modifiedCount"" : 0,
    ""upsertedId"" : ObjectId(""5dcc734f983b13bb23055041"")
}
{code}

However, because _id is immutable, we are not quite smart enough to allow you to perform both styles of update when your shard key is {{\{""_id.x"": 1, ""_id.y"": 1\}}}. You can only perform the version which specifies the entire {{_id}} object:
{code:js}
mongos> db.testing.update({_id: {x: 150, y: 150}}, {_id: {x: 150, y: 150}, updated: true}, true)
WriteResult({
    ""nMatched"" : 0,
    ""nUpserted"" : 1,
    ""nModified"" : 0,
    ""_id"" : {
        ""x"" : 150,
        ""y"" : 150
    }
})
mongos> db.testing.update({""_id.x"": 150, ""_id.y"": 150}, {_id: {x: 150, y: 150}, updated: true}, true)
WriteResult({
    ""nMatched"" : 0,
    ""nUpserted"" : 0,
    ""nModified"" : 0,
    ""writeError"" : {
        ""code"" : 111,
        ""errmsg"" : ""field at '_id' must be exactly specified, field at sub-path '_id.x'found""
    }
})
mongos> db.testing.update({""_id.x"": 150, ""_id.y"": 150}, {updated: true}, true)
WriteResult({
    ""nMatched"" : 0,
    ""nUpserted"" : 0,
    ""nModified"" : 0,
    ""writeError"" : {
        ""code"" : 61,
        ""errmsg"" : ""Expected replacement document to include all shard key fields, but the following were omitted: { missingShardKeyFields: [ \""_id.x\"", \""_id.y\"" ] }""
    }
})
{code}

This is of course inconsistent. It also seems prudent to favor the dotted-path form of querying over the explicit object, to avoid issues like {{\{x: 1, y: 1}\}} not comparing equal to {{\{y: 1, x: 1\}}}.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,39830400,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,craig.homa(craig.homa),2019-11-13 21:53:37.0,,,,,,,,,,,,,,backlog-query-execution(JIRAUSER1257109),charlie.swanson(charlie.swanson),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i4lvyn:",,,,,,,"0|i00z9z:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i4lu2f:",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Integrate UndoDB build variant into selected_tests_gen,SERVER-49501,1409204,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-server-stm,richard.samuels,richard.samuels,Jul 14 2020 08:07:53 PM UTC,Oct 20 2020 04:19:26 PM UTC,Feb 17 2021 11:15:22 AM UTC,,,,,,Backlog,,,,,0,,,,,,"Add a new build variant (make it required) in evergreen.yml that just runs selected tests with Undo.

We will need to disable certain suites in selected_tests_gen that don't succeed consistently when run on Undo. (We believe there are 3.) ",,,,,,,,SERVER-50315,SERVER-50314,SERVER-50313,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,Fully Compatible,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,18748800,"<a href='https://jira.mongodb.org/browse/SERVER-50315'>SERVER-50315</a>, <s><a href='https://jira.mongodb.org/browse/SERVER-50314'>SERVER-50314</a></s>, <s><a href='https://jira.mongodb.org/browse/SERVER-50313'>SERVER-50313</a></s>",,,,Not Needed,,,PM-1956,,,,,,,,,,,,,,,,,,,,true,brooke.miller(brooke.miller),2020-07-14 20:07:53.0,,,,,,,,,,,,,,backlog-server-stm(backlog-server-stm),richard.samuels(richard.samuels),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i6inin:",,,,,,,"0|i6evbj:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i6ilm7:",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Add read_timeout setting for the client,SERVER-46986,1282127,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-server-servicearch,georgy.savva@gmail.com,georgy.savva@gmail.com,Mar 19 2020 02:27:09 PM UTC,Oct 19 2020 08:14:31 PM UTC,Feb 17 2021 11:15:22 AM UTC,,4.2.3,,,,Backlog,,,,,0,,,,,,"The documentation says that I should always set maxTimeMS for operations that use ""linearizable"" read concern:
[https://docs.mongodb.com/manual/reference/read-concern-linearizable/#performance-comparisons]
{code:java}
db.restaurants.find( { _id: 5 } ).readConcern(""linearizable"").maxTimeMS(10000)
{code}
Otherwise my query will block indefinitely in case the majority of the nodes are unavailable, because the Primary node needs to check with majority of nodes that it's still the Primary.
Originally, maxTimeMS setting purpose is to limit time that query takes to process on the server, and it seems that,  it also covering this case with majority of nodes unavailable too, what is a network issue actually. So as I understand, it works the same way as wtimeout setting for write operations. 
The only difference is that I can specify wtimeout as a part of the write concern globally for my client via the connection URI. Or even on the server in replication configuration. 
And it's not the case for the maxTimeMS, because I need to add it to every query. 
It's very inconvenient when I need my database to be highly consistent and ""linearizable"" is my default read concern level for the client and I specify it in my connection URI. 
I believe that we should have global read_timeout setting for the client and configure it via the connection URI as we do with wtimeout.




 ",,,,,,,,DRIVERS-555,,,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2020-03-19 19:00:36.0,26697600,<a href='https://jira.mongodb.org/browse/DRIVERS-555'>DRIVERS-555</a>,,,,,,,,,,,,,,,,,,,,,,,,,,,true,matthew.tretin(JIRAUSER1254107),Mon Apr 13 17:37:07 UTC 2020,,,,,,,,,,,,,,jesse(jesse),backlog-server-servicearch(backlog-server-servicearch),carl.champain(carl.champain),georgy.savva@gmail.com(georgy.savva@gmail.com),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i5xgt3:",,,,,,,"0|i5tron:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i5xewn:","Mar 19 2020 07:00:36 PM UTC;carl.champain;Hi [~georgy.savva@gmail.com],

Thank you for the report.
We are passing this ticket along to the appropriate team for further investigation. Updates will be posted as they happen.

Kind regards,
Carl
 ","Apr 13 2020 05:37:07 PM UTC;jesse;Hello, we are planning a project this year to create one operation timeout to rule them all. It will behave the same in all drivers and the shell, and it will supersede many of our existing timeouts. Instead of adding a specific read_timeout setting like you propose, we plan for the shell to implement the same universal timeout as the one we design for drivers.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Enable windows error reporting to collect crash information from our community edition ,SERVER-17641,190246,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-server-security,eitan.klein,eitan.klein,Mar 17 2015 09:54:51 PM UTC,Oct 19 2020 07:42:32 PM UTC,Feb 17 2021 11:15:22 AM UTC,,,,,,Backlog,Logging,,,,0,28qa,ml-retriage,move-sec,platforms-re-triaged,,"I would like to enable us to access to Microsoft Watson report for mongo binaries, 
https://msdn.microsoft.com/en-us/library/windows/hardware/dn641144.aspx
 
This will enable us to capture crash dumps that has been reported to Microsoft 

in order to implement it, we should 

1) Sign the binary similar to the method we are doing to MSI  (using a valid digital certificate) 
2) Modify the current error handler, in addition to the log we should  push the data using WER API


",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2015-03-26 16:37:17.0,186883200,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,brooke.miller(brooke.miller),2015-03-17 21:54:51.0,,,,,,,,,,,,,,backlog-server-security(backlog-server-security),eitan.klein(eitan.klein),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i02zmf:",,,,,,,"0|i05otj:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i0u2rj:",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Feature that allows Renaming Replica Sets (sharded as well as un-sharded environments),SERVER-34869,540351,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-server-repl,harshad.dhavale,harshad.dhavale,May 07 2018 05:35:41 PM UTC,Oct 16 2020 08:27:04 AM UTC,Feb 17 2021 11:15:22 AM UTC,,,,,,Backlog,Replication,Sharding,,,9,,,,,,"As [documented|https://docs.mongodb.com/manual/reference/replica-configuration/#rsconf._id], we officially +do not+ support renaming of replica sets. There are some unofficial-procedures documented on [Stack Overflow|https://stackoverflow.com/questions/11265997/can-i-change-the-name-of-my-replica-set-while-mongod-processes-are-running] and DOCS-4798. However, there is *no* *officially-supported procedure or feature* for renaming replica sets (sharded or unsharded).

 

This enhancement request is for requesting an *_officially-supported_* feature that will allow changing replica set names for sharded as well as unsharded environments.",,,,,,,,,,,,HELP-5381,SERVER-18831,SERVER-46901,SERVER-46905,TSEXP-381,PRODUCT-417,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,500A000000aQyVWIA0,500A000000auD5jIAE,500A000000cDzFoIAK,5002K00000e811dQAA,5002K00000nmcxsQAA,5002K00000nqA0EQAU,5002K00000pkG9IQAU,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2018-05-07 21:35:24.0,18662400,,,,,,,,PM-1187,,,,,,,,,,,,,,,,,,,,true,nuno.costa(nuno.costa),Wed Jul 15 17:58:03 UTC 2020,,,,,,,,,,,,,,backlog-server-repl(backlog-server-repl),harshad.dhavale(harshad.dhavale),holee@expedia.com(holee@expedia.com),rarumuga@cisco.com(rarumuga@cisco.com),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i2fsnj:",,,,,,,"0|i2n02v:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i2fqrb:","Oct 08 2018 09:18:02 PM UTC;holee@expedia.com;It'd be nice to have a feature, implemented in a form a mongo shell command, or thru automation agent, to change the {{replica set name}} without downtime. We have clusters set up from years ago that retained {{rs0}}replica set (since it is what was used in MongoDB Doc). We also have clusters that needed to change replica set name to be more identifiable in a Project.","Jul 15 2020 05:58:03 PM UTC;rarumuga@cisco.com;We have been using MongoDB for several years.    Some time Business/ Application team wants to change/rename the Replica Set (RS) name online to meet some internal requirements.

Supported methods are backup/restore or mongodump/mongo restore.    It requires downtime.  If the database size is high, it takes several hrs of downtime.   This will not help for critical instances, which requires 24x7 availability.

Few years back, we used this method to rename Replica Sets.   It worked fine.    However Mongo officially do not support.   At the same did not provide alternative feature even after several years.    Mongo sould come with rename feature by ""updating metadata"" rather than migrating ""huge amount of user data"" (like other database products does)

It will be a good future most of Customers will need.   It will benefit and attract more customers use MongoDB.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Creating unique index on sharded clusters apart from shard key,SERVER-19860,225046,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-server-sharding,jebas,jebas,Aug 11 2015 01:46:02 PM UTC,Oct 16 2020 08:27:03 AM UTC,Feb 17 2021 11:15:22 AM UTC,,3.0.5,,,,features we're not sure of,Sharding,,,,0,,,,,,"Hi Team,
Say, we are having two collections named ""Students"" & ""Department"" and in ""Students"" collection we are having the reference of department using the departmentID and each department is having more or less equal number of students. As ""Students"" collection is having more number of data, I am planning to shard/partition the same with respect to departments to maintain equal distribution and my queries will be modified to include the shard key also. In this case anyhow, I need to maintain uniqueness of ""studentID"". But unfortunately, currently our MongoDB is not supporting the same. We need to handle the same through application.
Please consider this scenario in your future builds.

Adding to this point, the following comments from your Chairman (Dwight Merriman) regarding maintaining the referenceIDs as the shard keys in both the collections to enable join-like sementics in future, clearly indicates that we need this option.
""It's possible there will be some join-type features in mongodb in the future that have a restricted scope -- for example if you sharded all the customer data and orders on customer id, and all those documents are on the same partition, the problem then goes away for that scope.""",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,5002K00000jbxb1QAA,5002K00000iPr2jQAC,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2015-08-17 16:29:59.0,173664000,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,nuno.costa(nuno.costa),Mon Aug 17 16:29:59 UTC 2015,,,,,,,,,,,,,,backlog-server-sharding(backlog-server-sharding),jebas(jebas),ramon.fernandez(ramon.fernandez),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i01pdb:",,,,,,,"0|i0c3r3:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i0xws7:","Aug 17 2015 04:29:59 PM UTC;ramon.fernandez;[~jebas], this is currently [a limitation of unique indexes in sharded clusters|https://docs.mongodb.com/v3.4/reference/limits/#Unique-Indexes-in-Sharded-Collections].

I'm going to keep this ticket as an enhancement request to discuss adding this functionality in the future.

Regards,
Ramón.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Build and store grpcio for arm64, ppc, and s390x",SERVER-48521,1368182,New Feature,Blocked,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,robert.guo,julian.edwards,julian.edwards,Jun 01 2020 06:33:45 PM UTC,Oct 08 2020 03:41:58 PM UTC,Feb 17 2021 11:15:23 AM UTC,,,,,,5.0 Desired,,,,,0,,,,,,"There are no pre-built wheels for grpcio for arm64 (ARMv8), ppc and s390x. They can't be compiled with the toolchain out of the box and would take 15+ min even if compile does work, so we need to either set up a CI project to compile them or to ask upstream to get us a version that works with the above platforms.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,1.0,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2020-08-31 14:50:29.0,14601600,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,april.schoffer(april.schoffer),Mon Aug 31 14:50:29 UTC 2020,,,,,,,,,,,,,,acm(acm),julian.edwards(julian.edwards),robert.guo(robert.guo),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i6bs33:",,,,,,,"0|i00l4n:",9223372036854775807,,,,,,,,,,,,STM 2020-08-10,,,,,,,,,4.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i6bq6n:","Aug 31 2020 02:50:29 PM UTC;acm;Please note that if you build these from source, that process must not use the mongodbtoolchain to do so, as it cannot be used to safely build anything other than the server. The system toolchain should be used.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Add support to resmoke.py undodb command to download recordings from a JIRA ticket,SERVER-50693,1459933,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-server-stm,richard.samuels,richard.samuels,Sep 02 2020 01:07:12 PM UTC,Sep 22 2020 02:52:28 PM UTC,Feb 17 2021 11:15:23 AM UTC,,,,,,5.0 Required,Testing Infrastructure,,,,0,tig-resmoke,,,,,"Allow the undodb --fetch command to accept a JIRA BF or BFG ticket. the code should reach out to JIRA, find the underlying task (ex: ""jscore_decimal""), and then try and find a task in the live-record build variant with the same name. If it exists, and there are recordings, download them.",,,,,,,,SERVER-49498,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,Fully Compatible,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2020-09-09 20:39:51.0,14428800,<s><a href='https://jira.mongodb.org/browse/SERVER-49498'>SERVER-49498</a></s>,,,,Not Needed,,,PM-1956,,,,,,,,,,,,,,,,,,,,true,brooke.miller(brooke.miller),2020-09-02 13:07:12.0,,,,,,,,,,,,,,backlog-server-stm(backlog-server-stm),richard.samuels(richard.samuels),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i6rc6v:",,,,,,,"0|i6m1hr:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,3.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i6raaf:",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Annotate OperationContext with Command details,SERVER-45858,1121212,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-server-servicearch,ben.caimano,ben.caimano,Jan 30 2020 01:56:18 AM UTC,Sep 21 2020 04:26:21 PM UTC,Feb 17 2021 11:15:23 AM UTC,,,,,,Backlog,,,,,0,,,,,,"The [Command infrastructure|https://github.com/mongodb/mongo/blob/3cd3a6d/src/mongo/db/commands.h] uses a combination of {{OperationContext}}, {{OpMsgRequest}}, and {{CommandInvocation}}, all by pointer or reference, for many function signatures. However, both the OMR and the CI have well defined lifetimes and factory functions. We can annotate the {{OperationContext}} with pointers to the other two types and reset those pointers when the underlying memory goes out of scope. This will allow us to tremendously simplify the api around commands.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,Fully Compatible,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,33177600,,,,,,,,PM-1620,,,,,,,,,,,,,,,,,,,,true,matthew.tretin(JIRAUSER1254107),2020-01-30 01:56:18.0,,,,,,,,,,,,,,backlog-server-servicearch(backlog-server-servicearch),ben.caimano(ben.caimano),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i5678n:",,,,,,,"0|i01lo7:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i565c7:",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Allow resmoke.py to filter tests by function name in test file,SERVER-33175,494011,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-server-stm,robert.guo,robert.guo,Feb 07 2018 08:33:04 PM UTC,Sep 16 2020 06:56:47 PM UTC,Feb 17 2021 11:15:23 AM UTC,,3.7.1,,,,Backlog,Testing Infrastructure,,,,0,stm,tig-resmoke,,,,"resmoke's test filtering currently operates on a file level. But for unit tests and benchmark tests, there is usually more than one test per file. They support the {{\-\-filter}} and {{\-\-benchmark_filter}} respectively to run specific functions in a file. We could add an option to resmoke to support these options, maybe as another phase in the selector on top of the existing file-based selection.

Some JS tests also have more than one ""test"" per file, so it might be interesting to pipe this logic to JS files as well.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,Fully Compatible,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,95472000,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,brooke.miller(brooke.miller),2018-02-07 20:33:04.0,,,,,,,,,,,,,,backlog-server-stm(backlog-server-stm),robert.guo(robert.guo),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i27xa7:",,,,,,,"0|i2dlun:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i27vdz:",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Add a resmoke hook to ensure no failpoints are left on after any test,SERVER-30867,421041,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-server-stm,redbeard0531,redbeard0531,Aug 28 2017 06:15:31 PM UTC,Sep 16 2020 06:56:45 PM UTC,Feb 17 2021 11:15:23 AM UTC,,,,,,Backlog,Testing Infrastructure,,,,0,stm,tig-qwin-eligible,tig-resmoke,,,"Leaving a failpoint enabled after test completion is always a bug in a test and it can lead to hard-to-debug failures in later tests.

When this hook finds an enabled failpoint, it should mark the test as failed and either turn the failpoint off or mark the servers as invalid and restart them before running the next test.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,109555200,,,,,,,,,,,,,,,,,,,,,,,,,,,,false,brooke.miller(brooke.miller),2017-08-28 18:15:31.0,,,,,,,,,,,,,,backlog-server-stm(backlog-server-stm),redbeard0531(redbeard0531),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i1vnmf:",,,,,,,"0|i21s5j:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i1vlq7:",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Add a way to detect when mongobridge is ready to accept connections after startup,SERVER-35350,552872,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-server-stm,william.schultz,william.schultz,Jun 01 2018 06:16:27 PM UTC,Sep 16 2020 06:48:27 PM UTC,Feb 17 2021 11:15:23 AM UTC,,,,,,Backlog,Testing Infrastructure,,,,0,stm,tig-mongobridge,,,,"There is a period of time after a mongobridge process starts up but before it is ready to accept connections. If a mongod server tries to connect to the mongobridge in this period, it will fail. This can be a problem, for example, when we restart a mongobridge and its associated mongod server in a replica set test. If we restart the mongobridge, and then restart the mongod, the mongod replica set node will try to identify itself by calling {{_isSelf}} against the mongobridge host. If the mongobridge is not ready to accept connections yet, then the command will fail, causing the node to consider itself removed from the replica set config. We should have some way to make sure the mongobridge is ready to accept connections in our tests.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,85622400,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,brooke.miller(brooke.miller),2018-06-01 18:16:27.0,71.0,,,,,,,,,,,,,backlog-server-stm(backlog-server-stm),william.schultz(william.schultz),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i2hwuf:",,,,,,,"0|i2mqqv:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i2huy7:",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Create tag for tests that cannot run with CheckReplDBHashInBackground,SERVER-50279,1439900,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-server-stm,jesse,jesse,Aug 12 2020 07:25:13 PM UTC,Sep 14 2020 07:46:00 PM UTC,Feb 17 2021 11:15:23 AM UTC,,,,,,Backlog,Replication,,,,0,,,,,,"There are a half-dozen other tests that can't run with CheckReplDBHashInBackground, and these tests must all be excluded from 29 YAML tests that execute CheckReplDBHashInBackground. Any time we make a new test that's incompatible with CheckReplDBHashInBackground we must add it to all the YAML files, and if we make a new suite that invokes CheckReplDBHashInBackground, we make a new copy of the list. This is a lot of copying, and a very high chance of provoking build failures.

Let's introduce a tag for tests that are incompatible with CheckReplDBHashInBackground. Let's consider tags for other test fixtures as well.",,,,,,,,PM-1559,,,,BF-18485,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2020-08-31 17:28:38.0,16243200,<a href='https://jira.mongodb.org/browse/PM-1559'>PM-1559</a>,,,,,,,,,,,,,,,,,,,,,,,,,,,true,brooke.miller(brooke.miller),2020-08-12 19:25:13.0,20.0,,,,,,,,,,,,,jesse(jesse),backlog-server-stm(backlog-server-stm),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i6nwmf:",,,,,,,"0|i01w1z:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i6nupz:",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Ability to start a node in maintenance mode,SERVER-17124,181576,New Feature,Investigating,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,evin.roesle,andre.defrere,andre.defrere,Jan 29 2015 10:56:06 PM UTC,Sep 11 2020 02:24:39 PM UTC,Feb 17 2021 11:15:23 AM UTC,,,,,,,Replication,,,,2,,,,,,"Under certain conditions, it is preferred to have a node start and join the replica set, but not be the target for any client reads.

A config option to set maintenance mode on start would ensure that the member doesn't take any queries until an operator affirmatively verifies it's good to go. For larger deployments with lots of shards & replicas, a few nodes in maintenance mode waiting for manual verification is operationally safer than serving stale data.",,,,,,,,,,,,CS-18231,,,,,,,,,,,,,,,,,,,,5.0,,,,,,,,,,,,,,,,,,,,,500A000000UaUA7IAN,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2017-09-27 15:59:40.0,27648000,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,evin.roesle(evin.roesle),Thu Apr 02 19:06:06 UTC 2020,,,,,,,,,,,,,,andre.defrere(andre.defrere),asya(asya),bartle(bartle),evin.roesle(evin.roesle),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i032hb:",,,,,,,"0|i0btbb:",159529,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i0yf5j:","Dec 07 2017 06:49:11 PM UTC;asya;So be able to start up in MAINTENANCE mode by option.
","Dec 07 2017 06:50:58 PM UTC;asya;One can start up and do {{replSetMaintenance}} command but that leaves a window open for clients to connect.

Would ability to start up with flag that run [replSetMaintenance|https://docs.mongodb.com/manual/reference/command/replSetMaintenance/] before coming on line for clients.
","Dec 07 2017 06:54:25 PM UTC;asya;Note that if clients don't want to read stale data they should use the driver option [maxStalenessSeconds|https://docs.mongodb.com/manual/core/read-preference/#maxstalenessseconds] to avoid reading from still catching up secondaries.
","Jul 20 2018 06:12:19 AM UTC;bartle;I think that's the ideal solution, but it can be difficult to audit every application that connects to mongo and uses secondary read preference.

 

For some background, the way we perform long-running maintenance tasks (e.g. index builds) is:

1) Restart node without --replst and on some alternate port (e.g. 9000)

2) Performance maintenance task

3) Update {{local.replset.minvalid}} to the current time

4) Restart node with --replset on the standard port (i.e. 27017)

5) adminCommand(\{replSetMaintenance: 1})

 

Step 3 ensures that the node will remain in RECOVERING state until it's caught up to minvalid, which gives us ample time to switch the node to maintenance mode.

 

A less hacky solution might be to allow maintenance mode to be persistent across mongod restarts.","Apr 02 2020 07:06:06 PM UTC;bartle;fwiw, we recently switched away from this approach and now reconfigure the replset to make the node under maintenance hidden with priority 0.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
support more than 1 checkpoint thread for WiredTiger,SERVER-16736,177183,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-server-storage-engines,mdcallag,mdcallag,Jan 06 2015 04:33:16 PM UTC,Sep 08 2020 03:53:49 AM UTC,Feb 17 2021 11:15:23 AM UTC,,,,,,Backlog,Storage,WiredTiger,,,4,wiredtiger,,,,,"Discussion started in SERVER-16665. WT supports multiple eviction threads but uses only 1 checkpoint thread. Both eviction and checkpoint threads can do compression when compression is used for a collection/index so more threads for checkpoint is likely to reduce write stalls during slow checkpoints. The wt_perf.c benchmark client uses more than 1 checkpoint thread, so I assume that is supported for WT. ",,,,,,,,,,,,WT-1744,WT-1463,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2015-06-08 16:52:49.0,179712000,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,brian.lane(brian.lane),Mon Jun 08 16:52:49 UTC 2015,,,,,,,,,,,,,,backlog-server-storage-engines(backlog-server-storage-engines),pasette(dan@10gen.com),mdcallag(mdcallag),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i034q7:",,,,,,,"0|i01kzz:",155407,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i0yi33:","Jan 06 2015 04:55:29 PM UTC;mdcallag;And if checkpoint cannot be multi-threaded it should still benefit from helper threads to do compression and call pwrite concurrent with other work done by the main checkpoint thread.","Jun 08 2015 04:52:49 PM UTC;pasette;We hope this will be addressed by bounding the work we do in a checkpoint.  See WT-1744.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Port over Top's operation latency tracking to mongos,SERVER-46713,1253192,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-server-sharding,blake.oler,blake.oler,Mar 09 2020 03:44:51 PM UTC,Sep 04 2020 07:28:54 AM UTC,Feb 17 2021 11:15:23 AM UTC,,4.3.4,,,,Backlog,Sharding,,,,1,,,,,,"The [Top class|https://github.com/mongodb/mongo/blob/master/src/mongo/db/stats/top.h] keeps an [operation latency histogram|https://github.com/mongodb/mongo/blob/master/src/mongo/db/stats/operation_latency_histogram.h] for each collection. However, this is currently only plugged into mongod. This means that we don't currently track operation latency on mongos.

This ticket is to evaluate the best way to get this functionality onto the mongos. There are two requirements we need to fulfill:

# Figuring out the best place to record the end of an operation (a [mongod example|https://github.com/mongodb/mongo/blob/997841bdace7ff9ed5fd5bd0f952ec20880b9d92/src/mongo/db/ops/write_ops_exec.cpp#L123] here. You can also grep for all other places where Top::record is called).
## Read and write operation logging could be placed [here|https://github.com/mongodb/mongo/blob/997841bdace7ff9ed5fd5bd0f952ec20880b9d92/src/mongo/s/service_entry_point_mongos.cpp#L180-L184]. This mirrors the location of read operations monitored on the mongod.
## Command-based operation logging is a little tricker, since writes can come in as commands as well. If we have a write come in as a command, its ReadWriteType as seen by [CurOp|https://github.com/mongodb/mongo/blob/997841bdace7ff9ed5fd5bd0f952ec20880b9d92/src/mongo/db/curop.h#L565-L568] will be a command. Whoever does this ticket will need to be careful in separating out actual writes from other command operations, and in making sure that operations aren't double-counted. In a local patch, I special-cased inserts and updates in the cluster write command operation counting logic [here|https://github.com/mongodb/mongo/blob/997841bdace7ff9ed5fd5bd0f952ec20880b9d92/src/mongo/s/commands/cluster_write_cmd.cpp#L517-L550], but this is by no means an official endorsement for where the operation _should_ be recorded.
# Figuring out the best way to expose this information to a client. In a local patch I added in the latency stats to the cluster coll stats command [here|https://github.com/mongodb/mongo/blob/master/src/mongo/s/commands/cluster_coll_stats_cmd.cpp]. Current convention has us leaning towards using the collStats aggregation stage instead, so the ticket assignee may want to consult with Query to figure out the best place to expose this information.

We will also need to look at the rest of the functionality of Top.h, and see if it's something we want to fulfill. There are more metrics than we currently intend to use, and some information may not make sense on a mongos (tracking the Read/Write lock type used for an operation). So attention should be paid to separating out the logic we need -- maybe separate files for tracking on mongos/mongod?


",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,Fully Compatible,,,,5002K00000pCpynQAC,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,29721600,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,,2020-03-09 15:44:51.0,,,,,,,,,,,,,,backlog-server-sharding(backlog-server-sharding),blake.oler(blake.oler),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i5si5b:",,,,,,,"0|i5p19j:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i5sg8v:",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Add option to gather collection stats,SERVER-21070,235644,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-server-security,bruce.lucas,bruce.lucas,Oct 22 2015 11:23:21 AM UTC,Aug 31 2020 06:29:29 PM UTC,Feb 17 2021 11:15:23 AM UTC,,3.2.0,,,,Backlog,Diagnostics,,,,0,FTDC,move-sec,SWDI,,,"It would be useful for debugging certain kinds of issues to gather stats() from arbitrary collections along with serverStatus() etc using the ""Full Time Data Capture"" system (see: SERVER-19585). This would be enabled and disabled by a run-time option.

",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,3.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2015-10-22 11:51:20.0,167961600,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,ian.whalen(ian@10gen.com),Thu Oct 22 18:14:12 UTC 2015,,,,,,,,,,,,,,backlog-server-security(backlog-server-security),bruce.lucas(bruce.lucas@10gen.com),mark.benvenuto(mark.benvenuto),scotthernandez(scotthernandez),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i01gqv:09",,,,,,,"0|i05qy7:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i0s5gv:","Oct 22 2015 11:51:20 AM UTC;scotthernandez;It seems like anything that isn't system wide, and automatic, should really be an external tool, since manual configuration is needed either way.

Bruce, can you provide an example of how you expect this feature to surface and to be used? Also, how would it work with anything more than a single server, like in the context of replication and sharding?","Oct 22 2015 12:28:02 PM UTC;bruce.lucas;The idea is to collect, compress, and store this along with other ftdc data in $dbpath/diagnostics.data (sorry I wasn't clearer about that) for easy and space-efficient operation at a customer site, and an external tool wouldn't accomplish that. Also it seems like an easy add-on, leveraging the existing ftdc infrastructure. I would imagine that it would be manually configured separately for each node of a replica set and each shard; we could consider automatically propagating this across a cluster, but my initial thought is that's an unnecessary complication. It would be analyzed and visualized by the tooling we are developing for ftdc data. [~dan@10gen.com] and [~mark.benvenuto] I think will understand how this request relates to our new ftdc capabilities in 3.2.","Oct 22 2015 06:14:12 PM UTC;mark.benvenuto;While there is definitely an opportunity to evolve this into a more general purpose metric logging component, we do not have time to do this until a later release. We also have to decide what fits into the core of the product, and what belongs external to it. If it goes into MongoD, then we need to consider how to expose configuration of the system, etc. There are also unanswered questions around who, and what consumes this information for users.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Write test for CSRS using different numbers of config servers,SERVER-22424,262319,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-server-sharding,spencer,spencer,Feb 01 2016 08:11:12 PM UTC,Aug 24 2020 08:09:44 PM UTC,Feb 17 2021 11:15:23 AM UTC,,,,,,Backlog,Sharding,,,,0,,,,,,"Currently we only test CSRS with 3 config servers.  We should probably test at least the following configurations:
* 1 config server
* 5 config servers
* 7 config servers
* 7 voting config servers + 43 non-voting config servers.

Probably can just write a test that does a bunch of basic operations: CRUD on sharded/unsharded collections, splits, migrates, creating and dropping collections and databases, etc, then run that test against these different config server configurations",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2.0,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2016-02-01 20:38:06.0,159148800,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,esha.maharishi(esha.maharishi@10gen.com),Tue Feb 02 00:12:15 UTC 2016,,,,,,,,,,,,,,backlog-server-sharding(backlog-server-sharding),pasette(dan@10gen.com),spencer(spencer),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i0289r:",,,,,,,"0|i0a6zb:",9223372036854775807,,,,,,,,,,,,Sharding 10 (02/19/16),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i011on:","Feb 01 2016 08:38:06 PM UTC;pasette;is it possible to adapt the existing sharding suite tests (or some subset within) to use variable numbers of config servers?","Feb 02 2016 12:12:15 AM UTC;spencer;[~pasette] - yeah, it would be fairly trivial to add new test suites that run the existing sharding tests with various numbers of config servers.  I was just worried about adding too many redundant sharding suites adding too much usage to evergreen for low payoff.  I guess if we made the suite only run once per day or something it wouldn't be too bad.

Adding more suites is definitely an easier approach and will get us better coverage.  So long as we don't mind the extra MCI usage, we should probably go with that approach.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
JSON to text conversion tool,SERVER-45559,1090006,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-server-security,sara.williamson,sara.williamson,Jan 14 2020 04:09:42 PM UTC,Aug 24 2020 06:17:07 PM UTC,Feb 17 2021 11:15:23 AM UTC,,,,,,Backlog,Logging,,,,1,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,1.0,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2020-03-19 17:38:51.0,28857600,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,sara.williamson(sara.williamson),Thu Mar 19 17:38:51 UTC 2020,,,,,,,,,,,,,,backlog-server-security(backlog-server-security),ratika.gandhi(ratika.gandhi),sara.williamson(sara.williamson),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i50ydr:",,,,,,,"0|i51h93:",9223372036854775807,,,,,,,,,,,,Dev Tools 2020-03-09,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i50whj:","Mar 19 2020 05:38:51 PM UTC;ratika.gandhi;Questions from Dev Tools iteration planning: [~schwerin], should we do this ticket this sprint?",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Provide option to stream audit log to a database or external system,SERVER-12670,110291,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-server-security,rob.young@10gen.com,rob.young@10gen.com,Feb 10 2014 06:27:36 PM UTC,Aug 18 2020 12:29:25 AM UTC,Feb 17 2021 11:15:23 AM UTC,,,,,,Backlog,Logging,Security,,,9,Auditing,,,,,"This enhancement removes the coupling between the audit log and the file system, allowing users to define and log it as a stream to a secured collection within a secured database, or to a remote service like Oracle Audit Vault, WORM storage, Splunk, etc.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,500A000000bTW2uIAG,5002K00000no6rcQAA,5002K00000obLAjQAM,5002K00000pCq7BQAS,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2018-02-23 14:39:50.0,94089600,,,,,,,,PM-1591,,,,,,,,,,,,,,,,,,,,true,,Fri Feb 23 14:55:50 UTC 2018,,,,,,,,No,,,,,,backlog-server-security(backlog-server-security),matt.kalan(matt.kalan@10gen.com),rob.young@10gen.com(rob.young@10gen.com),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i03r33:",,,,,,,"0|i05okv:",6467,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i1732v:","Feb 23 2018 02:55:50 PM UTC;matt.kalan;I believe Splunk can take syslog as an input so they might be able to do this today. It is worth checking whether this is common for most WORM endpoints. One would think it would be",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Add support for hashing in idl generated classes,SERVER-30764,418501,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-server-servicearch,jason.carey,jason.carey,Aug 21 2017 05:47:34 PM UTC,Aug 13 2020 02:52:56 PM UTC,Feb 17 2021 11:15:23 AM UTC,,,,,,Backlog,IDL,Internal Code,,,0,,,,,,"A common extension of idl types is the generation of a hash function (for use in unordered containers).

We currently have free functions in the codebase which use both all fields, as well as limited subsets, so a code reducing impl should include support for both.

An example syntax might look like:

For all fields:

hash: all

For a subset:

hash: [a,c, b]

I'm on the fence whether we should expose these as:
* std::hash specializations
* dependent types as T::Hash
* adl lookup.

We probably also want to support a facility for attaching a c++ function to a type as the hash function (to bootstrap user defined types)",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,Fully Compatible,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,110160000,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,ratika.gandhi(ratika.gandhi),2017-08-21 17:47:34.0,,,,,,,,,,,,,,backlog-server-servicearch(backlog-server-servicearch),jason.carey(jason.carey),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i1v7xz:",,,,,,,"0|i05nzb:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i1v61r:",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Provide a way for a secondary to warm up the cache automatically by matching the cached data on the primary,SERVER-41923,814881,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-server-repl,dmitry.ryabtsev,dmitry.ryabtsev,Jun 26 2019 04:23:38 AM UTC,Aug 12 2020 02:47:43 PM UTC,Feb 17 2021 11:15:23 AM UTC,,,,,,Backlog,Storage,,,,1,,,,,,"Right now if a replica set (shard) member is restarted it brings a performance impact since the members has to load data into the cache from the disk before the performance returns to the normal level.

The only workaround for that so far is by synthesizing a custom workload that would warm up the cache for the users ad-hoc. This presents the problem as it would require certain development effort and, for instance, in Atlas the failovers (restarts) are pretty frequent phenomenon due to the maintenance activities.

It would be great if the secondary could get the map of the cached data from another member (say, primary) and use it to warm up its own cache.",,,,,,,,,,,,INIT-4,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,5002K00000fGBR5QAO,5002K00000e81yaQAA,5002K00000g50JWQAY,500A000000UaQuEIAV,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2019-06-27 16:44:58.0,50630400,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,kelsey.schubert(thomas.schubert),Thu Jul 11 21:00:27 UTC 2019,,,,,,,,,,,,,,backlog-server-repl(backlog-server-repl),dmitry.ryabtsev(dmitry.ryabtsev),siyuan.zhou(siyuan.zhou@10gen.com),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i3q7mn:",,,,,,,"0|i3sjxz:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i3q5qf:","Jul 11 2019 08:42:56 PM UTC;siyuan.zhou;Closing this ticket as a dup of SERVER-3767.","Jul 11 2019 09:00:27 PM UTC;siyuan.zhou;Reopened the ticket as the proposal of SERVER-3767 is slightly different from this one.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Add support for kerberos style gMSA extensions,SERVER-46292,1167916,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-server-security,luke.prochazka,luke.prochazka,Feb 21 2020 04:39:33 AM UTC,Aug 12 2020 08:16:10 AM UTC,Feb 17 2021 11:15:23 AM UTC,,4.2.3,,,,Backlog,Security,,,,0,,,,,,"This is a feature request to enhance the existing Kerberos capabilities to include the [gMSA|https://docs.microsoft.com/en-us/windows-server/security/group-managed-service-accounts/group-managed-service-accounts-overview] authentication API.

Specifically this is an evolution to the use of SPNs and machine accounts created by Microsoft, and is Windows proprietary.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,5002K00000iOvTyQAK,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2020-03-11 21:13:01.0,29548800,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,luke.prochazka(luke.prochazka),Wed Mar 11 21:13:01 UTC 2020,,,,,,,,,,,,,,backlog-server-security(backlog-server-security),luke.prochazka(luke.prochazka),spencer.jackson(spencer.jackson@10gen.com),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i5dyhr:",,,,,,,"0|i5cl1r:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i5dwlb:","Mar 11 2020 09:13:01 PM UTC;spencer.jackson;It appears that gMSA accounts have credentials which authorized principals can obtain via [GetServiceAccountPassword|https://docs.microsoft.com/en-us/windows/win32/secmgmt/getserviceaccountpassword]. SSPs, such as the Kerberos implementation of SSPI, should invoke GetServiceAccountPassword from inside of {{InitializeSecurityContext}} or {{AcceptSecurityContext}}. It appears consumers of this functionality must have the ""TCB privilege"" or be a network service.

It appears that SSPI is expected to work normally with credentials provided by this mechanism, but configuration and deployment of Active Directory in this mode, in order to validate this fact, looks deeply non-trivial. I expect that the act of setting up an environment with gMSA enabled will be very time consuming.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Support copy and paste of queries from mongod log into mongo shell,SERVER-18240,200797,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-server-security,eoin.brazil,eoin.brazil,Apr 28 2015 04:42:28 PM UTC,Aug 11 2020 08:20:32 PM UTC,Feb 17 2021 11:15:23 AM UTC,,,,,,Backlog,Internal Code,Logging,,,1,move-sec,,,,,"I want to be able to retrospectively analyse the slow queries in my {{mongod}} log file. The current logging format for MongoDB is not conducive to doing do since slow queries output in the log cannot always be copied and pasted verbatim into the mongo shell.  For example:

- nested field names are not quoted in the log, and this causes a parsing issue when pasting the output verbatim from the log output into a Mongo Shell.
- queries including binary data are stringified as ""BinData...."" whereas the query must be entered with ""HexData..."" in the shell

",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,1.0,,,,,,,,,,,,,,,,,,,,500A000000UaXvYIAV,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2015-09-17 17:47:46.0,183254400,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,ratika.gandhi(ratika.gandhi),2015-04-28 16:42:28.0,,,,,,,,,,,,,,backlog-server-security(backlog-server-security),eoin.brazil(eoin.brazil),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i02wev:",,,,,,,"0|i05otz:",9223372036854775807,,,,,,,,,,,,Platform B (10/30/15),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i0y7xr:",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Enable fsm workloads to work over multiple collections,SERVER-46251,1161995,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-server-stm,charlie.swanson,charlie.swanson,Feb 19 2020 04:42:45 PM UTC,Aug 06 2020 12:49:42 PM UTC,Feb 17 2021 11:15:23 AM UTC,,,,,,Backlog,Concurrency,Testing Infrastructure,,,0,fsm-new-feature,,,,,"When adding some tests for $unionWith, it became clear the framework is all built around the one collection with the unique name. In order to better integrate testing things like $unionwith into the framework, we should be able to opt-in to having the test operate on multiple namespaces. This would allow:
# benefitting from the test setup, including things like sharding the collection.
# Plug in better to simultaneous variants - letting the test infrastructure know about all the collections involved
# Make things easier to manage for the infrastructure and test authors. For example, [this code|https://github.com/mongodb/mongo/blob/21692cab486977a3c70f1a2a746ff12e5ffa3358/jstests/concurrency/fsm_libs/runner.js#L263-L264] should probably know of all used collections.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2020-05-21 20:15:06.0,16761600,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,robert.guo(robert.guo),Thu Aug 06 12:49:32 UTC 2020,,,,,,,,,,,,,,backlog-server-stm(backlog-server-stm),charlie.swanson(charlie.swanson),robert.guo(robert.guo),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i5cxyf:",,,,,,,"0|i5c1wf:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i5cw1z:","May 21 2020 08:15:06 PM UTC;robert.guo;[~charlie.swanson] This feature might be too well hidden, but you can pass in {{TestData.sameCollection = false}} and {{TestData.sameDB = false}} to allow each thread to use a separate NS. [You can also shard|https://github.com/mongodb/mongo/blob/21692cab486977a3c70f1a2a746ff12e5ffa3358/jstests/concurrency/fsm_libs/runner.js#L224] if not using the same collection.

Cleanup is not automatic but you can have the workload's {{teardown()}} function take care of dropping additional collections created for {{$unionwith}}.

Let me know if the above seems reasonable. Happy to provide a more detailed example if you'd like.","Aug 06 2020 12:49:32 PM UTC;robert.guo;Moving it to the backlog for now since there is a workaround; if there's additional functionality you'd like, feel free to comment on this ticket.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Support global secondary indexes in sharded clusters,SERVER-33588,504304,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-server-sharding,bartle,bartle,Mar 01 2018 08:32:07 PM UTC,Jul 28 2020 03:05:00 PM UTC,Feb 17 2021 11:15:23 AM UTC,,,,,,Backlog,Indexing,Sharding,,,1,,,,,,"If you have a collection containing ""foo"" and ""bar"", it could be the case that you need to make queries against both ""foo"" and ""bar"".  You could configure a sharded collection to range shard over ""foo"", which would make any queries against ""foo"" only hit 1 replset shard, but any query against ""bar"" would require fanning out to every replset, which can adversely impact load/latency/availability if you have many replset shards.

An approach to solving this would be to have global secondary indexes (GSI; c.f. https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/GSI.html), where you store the keys you want to index (""foo"" and ""bar"" here), along with the underlying {{_id}} of the document, or possibly the entire document.  These collections would be range sharded (by ""foo""+""bar""), so that a query to a GSI would tend to only hit 1 replset initially.  If you chose to store the entire document in the GSI, you'd be done.  If you instead stored just {{_id}}, you'd need to query the underlying collection.  If you end up returning 100's of documents you probably end up hitting all replset shards as before, but for the nReturned=0 or nReturned=1 case you'd only hit a single additional replset.

Initially, you'd probably want GSIs to be eventually consistent, though with MongoDB's new transaction support you could conceivably make them more strongly consistent.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,4.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2018-03-04 01:15:43.0,64800000,,,,,,,,,,,,,,,,,,,,,,,,,,,,false,ratika.gandhi(ratika.gandhi),Mon Jan 28 15:58:27 UTC 2019,,,,,,,,,,,,,,schwerin(schwerin),backlog-server-sharding(backlog-server-sharding),bartle(bartle),ramon.fernandez(ramon.fernandez),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i29nyf:",,,,,,,"0|i2f3wn:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i29m27:","Mar 01 2018 08:42:15 PM UTC;bartle;Sorry, you'd want to range shard by ""bar"" in your GSI so that you can efficiently service queries on ""bar"" (you'd range shard the underlying collection by ""foo"").  Or, you could have two GSIs, on ""foo"", and on ""bar"", and then hash shard your underlying collection by _id, if you tended to make a lot of _id lookups.","Mar 05 2018 12:56:54 PM UTC;ramon.fernandez;Thanks for your report [~bartle]. Sending it to the sharding team for consideration.","Jan 26 2019 04:24:07 AM UTC;bartle;Any update on this?","Jan 28 2019 03:58:27 PM UTC;schwerin;It's still on the backlog waiting for scheduling. I'm pretty interested in the project, but I can't promise we'll have a chance to do it in 2019. It's definitely not going to make 4.2.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Support rename collection for sharded collections,SERVER-6063,40967,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-server-sharding,spencer,spencer,Jun 11 2012 02:57:24 PM UTC,Jul 16 2020 04:06:19 PM UTC,Feb 17 2021 11:15:23 AM UTC,,,,,,Backlog,Sharding,,,,21,,,,,,,,,,,,,,,,,,SUPPORT-1293,,,,,,,,,,,,,,,,,,,,3.0,,,,,,,,,,,,,,,,,,,,,5002K00000lli7KQAQ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2014-11-12 11:23:10.0,178243200,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,ratika.gandhi(ratika.gandhi),Thu Jun 25 11:47:13 UTC 2015,,,,,,,,No,,,,,,AndrewDoumaux(andrewdoumaux),backlog-server-sharding(backlog-server-sharding),itsmejainh(itsmejainh),ryanovas(ryanovas),spencer(spencer),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i05pkv:",,,,,,,"0|i0bxnr:",6497,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i0s7dr:","Nov 12 2014 11:23:10 AM UTC;itsmejainh;Hi, 

Any updates on this jira ? 
I am stuck because of this. I have to backup collection (shared) with '/' in name which has billion of documents. 

Just can't think of dropping and re-inserting documents. 

Pls suggest.  Thank you.","Jan 17 2015 08:10:44 PM UTC;ryanovas;In the same boat as Himanshu Jain. Any progress on this?","Jun 25 2015 11:47:13 AM UTC;AndrewDoumaux;My use case for this feature:

I'm using Mongo as an analytic cache.  Every period of time I get a fresh copy of an analytic and load that analytic into a ""staging"" collection and when the load is completed I rename the collection to the ""active"" collection name.  I was hoping to shard those collections so I could use the horizontal scaling of Mongo to cache larger analytic output.  

This pattern is very similar to how mongo's $out aggregation operation works if an existing collection exists.  

Thanks",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Update signal processing package version,SERVER-47882,1335824,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-server-dag,jim.oleary,jim.oleary,May 01 2020 03:13:43 PM UTC,Jul 09 2020 10:55:10 PM UTC,Feb 17 2021 11:15:23 AM UTC,,,,,,Backlog,,,,,0,,,,,,"As a DAG engineer,
I'd like to use the latest version of signal processing, such that, the newest version of signal processing algorithms is being used.

----
AC:

* Upgrade to 3.0
* ensure perf / sys perf is updated
* backport
",,,,,,,,DAG-161,DAG-204,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,24796800,"<s><a href='https://jira.mongodb.org/browse/DAG-161'>DAG-161</a></s>, <s><a href='https://jira.mongodb.org/browse/DAG-204'>DAG-204</a></s>",,,,,,,,,,,,,,,,,,,,,,,,,,,true,brooke.miller(brooke.miller),Tue May 05 14:18:46 UTC 2020,,,,,,,,,,,,,,backlog-server-dag(backlog-server-dag),jim.oleary(jim.oleary@10gen.com),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i66lkf:",,,,,,,"0|i01zov:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i66jnz:","May 05 2020 02:18:46 PM UTC;jim.oleary;Update [signal_processing_setup.sh|https://github.com/mongodb/mongo/blob/master/buildscripts/signal_processing_setup.sh#L27] to the latest compatible version (~=3.0.1).

A sys perf and performance patch should also be run.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Enforce ""namespace: ignored"" only accept 1 as the argument",SERVER-33646,505029,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-server-servicearch,siyuan.zhou,siyuan.zhou,Mar 03 2018 12:08:02 AM UTC,Jun 29 2020 05:13:31 PM UTC,Feb 17 2021 11:15:23 AM UTC,,,,,,Backlog,IDL,,,,0,dev_tools,former-quick-wins,move-sa,,,"Specifying ""namespace: ignored"" on IDL command will completely ignore the argument. We need a way to enforce the argument to be 1, for example, {{\{commitTransaction: 1\}}}.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,93484800,,,,,,,,PM-1528,,,,,,,,,,,,,,,,,,,,true,jason.carey(jason.carey),2018-03-03 00:08:02.0,,,,,,,,,,,,,,backlog-server-servicearch(backlog-server-servicearch),siyuan.zhou(siyuan.zhou@10gen.com),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i29sf3:",,,,,,,"0|i03npb:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i29qiv:",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
IDL should natively support commands that take the fully-qualified ns as the command parameter,SERVER-34592,531648,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-server-servicearch,redbeard0531,redbeard0531,Apr 20 2018 03:49:06 PM UTC,Jun 29 2020 05:13:23 PM UTC,Feb 17 2021 11:15:23 AM UTC,,,,,,Backlog,IDL,,,,1,dev_tools,former-quick-wins,move-sa,,,Example command: _configsvrCreateCollection,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2018-10-09 14:21:51.0,74217600,,,,,,,,PM-1528,,,,,,,,,,,,,,,,,,,,true,jason.carey(jason.carey),Thu Oct 11 22:41:50 UTC 2018,,,,,,,,,,,,,,backlog-server-servicearch(backlog-server-servicearch),mark.benvenuto(mark.benvenuto),redbeard0531(redbeard0531),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i2eckf:",,,,,,,"0|i03non:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i2eao7:","Oct 09 2018 02:21:51 PM UTC;mark.benvenuto;What do you need IDL to support in this ticket? Is typed command support sufficient?","Oct 11 2018 10:41:50 PM UTC;mark.benvenuto;Today, the {{namespace}} in commands supports ignored, typed, and concatenate_with_db. The proposal is to add a new choice that would require the command parameter to be a fully qualified namespace. This means ""db.collection"" instead of just the ""collection"" that concatenate_with_db supports. In this case, the {{$db}} field is ignored.

{noformat}
    SampleFullNamespaceCommand:
        description: A sample command with a fully-qualified namespace
        namespace: full_namespace
        fields:
            field1: int
{noformat}

Here is what would be sent to the server in such a case:
{noformat}
{ SampleFullNamespaceCommand : ""db.collection"", field1 : 123 }
{noformat}
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
IDL: Add the ability to generate operator== overload only,SERVER-39677,700941,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-server-servicearch,nicholas.zolnierz,nicholas.zolnierz,Feb 19 2019 10:38:02 PM UTC,Jun 29 2020 05:12:12 PM UTC,Feb 17 2021 11:15:23 AM UTC,,,,,,Backlog,IDL,,,,0,,,,,,"The IDL supports generate_comparison_operators: <bool>, however it's often that only equality is needed (or makes sense).",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2019-02-25 16:49:49.0,62380800,,,,,,,,PM-1528,,,,,,,,,,,,,,,,,,,,true,jason.carey(jason.carey),Mon Feb 25 16:49:49 UTC 2019,,,,,,,,,,,,,,backlog-server-servicearch(backlog-server-servicearch),craig.homa(craig.homa),nicholas.zolnierz(nicholas.zolnierz),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i371sv:",,,,,,,"0|i03np3:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i36zwn:","Feb 25 2019 04:49:49 PM UTC;craig.homa;When doing this also generate != simultaneously. ",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
delete limited expired docs in every TTL period,SERVER-43244,921864,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-server-triage,pengzhenyi,pengzhenyi,Sep 10 2019 12:06:35 PM UTC,Jun 29 2020 02:49:47 PM UTC,Feb 17 2021 11:15:23 AM UTC,,Needs Further Definition,,,,Backlog,TTL,,,,4,,,,,,"TTL monitor delete all the expired docs every 60 seconds.
Sometimes a few expired docs exist in one TTL monitor period, and lots of expired docs in the next TTL monitor period. Then a big performance degration happens as too many delete requests appears in a short time.

If 'ttlDeleteBatch' is supported, we can delete a limited number of docs in one period which is under control, then no performance degration will happen.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2019-09-10 14:25:34.0,45360000,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,asya(asya),Tue Sep 10 12:14:21 UTC 2019,,,,,,,,,,,,,,backlog-server-triage(backlog-server-triage),pengzhenyi(pengzhenyi),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i48g7j:",,,,,,,"0|i4aafj:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i48ebb:","Sep 10 2019 12:14:21 PM UTC;pengzhenyi;The pull request: https://github.com/mongodb/mongo/pull/1322

A server parameter 'ttlDeleteBatch' is declared to control the maximum deleted docs number every TTL period.
The default value is std::numeric_limits::max(), which means no limitation",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Remove/update util/concepts.h macros after C++20,SERVER-48898,1381856,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-server-servicearch,jason.carey,jason.carey,Jun 16 2020 05:31:00 PM UTC,Jun 23 2020 05:05:50 PM UTC,Feb 17 2021 11:15:23 AM UTC,,,,,,Backlog,Internal Code,,,,0,,,,,,"The macros in util/concepts.h were meant as transitional tools smooth over template restrictions until c++20 support was made available.

Once we're onto C++20, we should replace the template/requires macros and re-evaluate the necessity of the REQUIRES_OUT_OF_LINE_DEF and REQURES_FOR_NON_TEMPLATE.

We should also think about prefixing any macros we retain, as mentioned in SERVER-47912",,,,,,,,PM-1666,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,Fully Compatible,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,21168000,<a href='https://jira.mongodb.org/browse/PM-1666'>PM-1666</a>,,,,,,,,,,,,,,,,,,,,,,,,,,,true,ratika.gandhi(ratika.gandhi),2020-06-16 17:31:00.0,,,,,,,,,,,,,,backlog-server-servicearch(backlog-server-servicearch),jason.carey(jason.carey),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i6dyq7:",,,,,,,"0|i699l3:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i6dwtr:",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Mongo endpoints currently don't support headers,SERVER-47546,1315183,New Feature,Waiting For User Input,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-server-triage,eduardomilpas@gmail.com,eduardomilpas@gmail.com,Apr 15 2020 12:50:54 AM UTC,Apr 15 2020 03:48:27 PM UTC,Feb 17 2021 11:15:23 AM UTC,,4.3.6,,,,,Usability,,,,0,,,,,,"Mongo endpoints currently don't support headers.

 

I was testing this using spring integration and setting some custom headers and those are lost when the receiver gets a message.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2020-04-15 15:48:18.0,26524800,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,carl.champain(carl.champain),Wed Apr 15 15:48:18 UTC 2020,,,,,,,,,,,,,,backlog-server-triage(backlog-server-triage),carl.champain(carl.champain),eduardomilpas@gmail.com(eduardomilpas@gmail.com),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i6327j:",,,,,,,"0|i5yza7:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i630b3:","Apr 15 2020 03:48:18 PM UTC;carl.champain;Hi [~eduardomilpas@gmail.com],

To help us move this ticket forward, can you please provide a concrete example?

Thank you!
Carl",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Very, very fast counters",SERVER-9393,72248,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-server-platform,paul.pedersen,paul.pedersen,Apr 18 2013 04:53:43 PM UTC,Apr 09 2020 02:24:06 AM UTC,Feb 17 2021 11:15:23 AM UTC,,,,,,Backlog,Performance,,,,0,move-sa,platforms-re-triaged,,,,"Fast Counters

Scope

To provide very fast counters and timers - making possible an increase in the volume and granularity of stats accumulated within the server.

Not in scope

DTrace integration is not part of this project.  Non-x86 processors will not be supported.

Design

Each counter consists of a vector of counters, one per core (or virtual core, in the case of hyper-threading).  Counter increments occurs per-core independently and without locking.  The counter value is aggregated across the per-core counters.  Experiments confirm that core migration errors occur about 1 in 10M counts, an acceptable error rate.

Implementation

The key to the fast implementation is the x86  rdtscp  instruction.  It loads the 64-bit timestamp counter into EAX,EDX, and the core / hyper-core (i.e.) “node” label into ECX.  We need to implement a module that determines the node count in order to correctly allocate fast counter / timer arrays.

Portability issues

Within the class of x86 processors the instruction set varies.  For older intel processors, OS support for finding the core label is needed (mainly access to model-specific registers, as opposed to the rdtscp instruction).  Each of Linux, Windows, Free BSD, Solaris, and OS X have different system calls for accessing msr’s. The initial implementation should use OS call for obtaining the processor label.   It greatly simplifies the code.

Testing Results

Testing shows that per-core counters provide large speed improvements v. single atomic integer with fetch-and-add (15 v. 230 nanos per incr).  Using non-locking v. locking increment instructions (with per-node counters) provides about 2X speedup (15 v. 30 nanos per incr).  Using Linux sched_getcpu() v. inlined rdtscp instructions provides small additional speedup.  It seems very likely that Linux is in fact uses the rdtscp instruction via vsyscall (see: http://lxr.linux.no/#linux+v3.8.7/arch/x86/include/asm/vsyscall.h in the Linux cross-reference).  Other OS’s may not be as smart.






System Calls

Windows

(1) find current core id

   DWORD cpui;

   cpuid = GetCurrentProcessorNumber();

   Requirements

   Minimum supported client  Windows Vista

   Minimum supported server  Windows Server 2003

   Header                    WinBase.h on Windows Server 2003,

                               Windows Vista, Windows 7, Windows Server 2008,

                               Windows Server 2008 R2 (with Windows.h);

                             Processthreadsapi.h on Windows 8, Windows Server 2012

   Library                   Kernel32.lib

   DLL                       Kernel32.dll

  

(2) Find core count

        

   vSYSTEM_INFO sysinfo;
   GetSystemInfo( &sysinfo );

   numCPU = sysinfo.dwNumberOfProcessors;

   Requirements

   Minimum supported client  Windows 2000 Professional

   Minimum supported server  Windows 2000 Server

   Header                    WinBase.h (include Windows.h)



Linux

(1) find current core id


   #include <sched.h>
   int cpu = sched_getcpu();

   Requirements

   glibc 2.6

(2) Find core count

   #include <unistd.h>

   numCPU = sysconf( _SC_NPROCESSORS_ONLN );

   Requirements

   This is a POSIX standard function, although _SC_NPROCESSOES_ONLN

   is non-standard.




FreeBSD, Mac OS X

(1) find current core id:

    tbd

(2) Find core count:

   int mib[2];

   size_t len = 4;

   uint32_t numCPU;

   mib[0] = CTL_HW;
   mib[1] = HW_AVAILCPU;


   sysctl(mib, 2, &numCPU, &len, NULL, 0);

   if (numCPU < 1) {
       mib[1] = HW_NCPU;
       sysctl( mib, 2, &numCPU, &len, NULL, 0 );
       if (numCPU < 1) numCPU = 1;
   }

   Requirements

   OS X versions >= 10.2.




Solaris


(1) find current core id:

          

   #include <sys/processor.h>
   processorid_t getcpuid(void);


(2) Find core count:

   #include <unistd.h>

   numCPU = sysconf( _SC_NPROCESORS_ONLN );",,,,,,,,,,,,CAP-130,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2013-04-18 17:52:26.0,177292800,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,sara.williamson(sara.williamson),Mon Jul 06 12:41:52 UTC 2015,,,,,,,,No,,,,,,schwerin(schwerin),backlog-server-platform(backlog-server-platform),martin.bligh(martin.bligh),paul.pedersen(paul@10gen.com),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i04lrr:",,,,,,,"0|i05ofr:",4315,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i0nbgf:","Apr 18 2013 05:52:26 PM UTC;schwerin;On systems for which the current core id is unavailable, you could fallback to threadid % COUNTER_VECTOR_SIZE.  You can steer COUNTER_VECTOR_SIZE up and down based on how averse you are to multiple threads simultaneously using the same counter.","Jul 06 2015 12:41:52 PM UTC;martin.bligh;[~paul@10gen.com] do you still have the code for this somewhere? Would like to replace global atomics by this in various places.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Create a SCOM plugin for monitoring mongo on Windows,SERVER-3033,16570,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-server-platform,sridhar,sridhar,May 02 2011 09:37:41 PM UTC,Apr 09 2020 02:23:33 AM UTC,Feb 17 2021 11:15:23 AM UTC,,,,,,Backlog,Admin,,,,7,move-sa,Windows,,,,"Systems Center Operations Manager is Microsoft's monitoring tool. 
SCOM - http://www.microsoft.com/systemcenter/en/us/operations-manager.aspx
SCE - http://www.microsoft.com/systemcenter/en/us/essentials.aspx",windows,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,5002K00000g4AtzQAE,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,309139200,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,sara.williamson(sara.williamson),2011-05-02 21:37:41.0,,,,,,,,No,,,,,,backlog-server-platform(backlog-server-platform),sridhar(sridhar),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i06prr:",,,,,,,"0|i05o5r:",6148,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i001nz:",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Expose performance counters (Windows),SERVER-2541,14712,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-server-platform,scotthernandez,scotthernandez,Feb 12 2011 07:01:17 PM UTC,Apr 09 2020 02:23:22 AM UTC,Feb 17 2021 11:15:23 AM UTC,,,,,,Backlog,Admin,,,,6,metrics,move-sa,pull-request,stats,Windows,Expose (performance) counters in windows for monitoring and performance. ,,,,,,,,,,,,SERVER-3033,SERVER-13576,,,,,,,,,,,,,,,,,,,5.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2012-08-01 12:29:12.0,258249600,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,sara.williamson(sara.williamson),Tue Dec 11 19:29:16 UTC 2012,,,,,,,,No,,,,,,backlog-server-platform(backlog-server-platform),siedler(siedler),ian.whalen(ian@10gen.com),scotthernandez(scotthernandez),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i06vjj:",,,,,,,"0|i05o4v:",6921,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i013zj:","Aug 01 2012 12:29:12 PM UTC;siedler;I am submitting my implementation for your consideration: github pull request #275 https://github.com/mongodb/mongo/pull/275.

There is a readme worth having a look, and I've put some code review related comments in the request.

I've created some 30 counters based on serverStatus() mostly to have it up and running, but I'm no mongodb user or admin. It's probably good if someone scrap these counters and came up with a new set.

Best regards.
","Aug 01 2012 12:43:53 PM UTC;ian.whalen;@erich, thanks for submitting your pull request.  Before we can begin discussing with you we'll need you to read and sign our Contributor Agreement at http://www.10gen.com/contributor.","Aug 01 2012 01:09:19 PM UTC;siedler;Ian, sorry about that. It's done.","Dec 11 2012 06:19:18 PM UTC;siedler;Any interest?","Dec 11 2012 07:29:16 PM UTC;ian.whalen;Hey Erich, thanks for signing the CA and I'm sorry for the delay in looking at this - we're just finishing up the 2.4 release cycle so I don't think we'll be able to merge this at the moment, but as we start the 2.6 cycle I'll try to have one of our engineers begin a discussion with you.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Enable dynamic loading of extensions in mongo via DLLs/shared objects.,SERVER-8583,65356,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-server-platform,schwerin,schwerin,Feb 14 2013 10:42:27 PM UTC,Apr 09 2020 02:23:13 AM UTC,Feb 17 2021 11:15:23 AM UTC,,,,,,Backlog,Internal Code,,,,2,move-sa,platforms-re-triaged,,,,,,,,,,,,,,,,SERVER-9031,PS-658,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2015-12-10 18:26:37.0,252633600,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,sara.williamson(sara.williamson),2013-02-14 22:42:27.0,,,,,,,,No,,,,,,schwerin(schwerin),backlog-server-platform(backlog-server-platform),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i04vi7:",,,,,,,"0|i05oen:",4294,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i011nj:",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Automatically generate documentation of new server parameters from IDL files,SERVER-42859,898810,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-server-servicearch,sara.williamson,sara.williamson,Aug 16 2019 07:40:51 PM UTC,Apr 03 2020 09:46:17 PM UTC,Feb 17 2021 11:15:23 AM UTC,,,,,,Backlog,,,,,0,,,,,,"Now that new server parameters are defined via IDL, we should add in the functionality to automatically generate documentation of new server parameters when they are added.",,,,,,,,,,,PROG-2381,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2019-08-16 20:29:50.0,47520000,,,,,,,,PM-1545,,,,,,,,,,,,,,,,,,,,true,ian.whalen(ian@10gen.com),2019-08-16 19:40:51.0,,,,,,,,,,,,,,backlog-server-servicearch(backlog-server-servicearch),sara.williamson(sara.williamson),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i44iq7:",,,,,,,"0|i46j2n:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i44gtz:",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
use same shard key and chunks config on multiple collections,SERVER-924,10736,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-server-sharding,eliot,eliot,Oct 13 2009 07:57:33 AM UTC,Mar 24 2020 01:51:59 PM UTC,Feb 17 2021 11:15:23 AM UTC,,,,,,Backlog,Sharding,,,,9,,,,,,,,,,,,,,PM-1687,,,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2013-09-07 21:39:07.0,28512000,<a href='https://jira.mongodb.org/browse/PM-1687'>PM-1687</a>,,,,,,,,,,,,,,,,,,,,,,,,,,,true,kaloian.manassiev(kaloian.manassiev),Mon Mar 23 20:52:03 UTC 2020,,,,,,,,,,,,,,backlog-server-sharding(backlog-server-sharding),eliot(eliot),nvcook42(nvcook42),nicholas.cottrell(nicholas.cottrell),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i003rb:",,,,,,,"0|i0bxlr:",5152,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i1i3c7:","Sep 07 2013 09:39:07 PM UTC;nvcook42;A team of four of us have some time to dedicate to a first implementation of this feature. We have some ideas of our own but if any voters, watchers, or others have any recommendations they would be much appreciated. Thanks.","Mar 23 2020 08:52:03 PM UTC;nicholas.cottrell;What's the use case for this? A multi-tenant setup where many databases have the same repeated collections? Or for multiple collections in the same database that happen to use the same fields?",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Expose ping times for hosts on the ReplicaSetMonitor,SERVER-45607,1099573,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-server-servicearch,ben.caimano,ben.caimano,Jan 16 2020 06:03:23 PM UTC,Mar 11 2020 03:36:51 PM UTC,Feb 17 2021 11:15:23 AM UTC,,,,,,Backlog,,,,,0,,,,,,"We have ping time information in the RSM, and this information is useful for calculating timeouts for commands. We should make public functions to acquire this information.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,2.0,,,,,,,,,,,,,,,,Fully Compatible,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,34300800,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,ben.caimano(ben.caimano),2020-01-16 18:03:23.0,,,,,,,,,,,,,,backlog-server-servicearch(backlog-server-servicearch),ben.caimano(ben.caimano),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i52knz:",,,,,,,"0|i582l3:",9223372036854775807,,,,,,,,,,,,Service Arch 2020-02-24,Service Arch 2020-03-09,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i52irj:",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Extend failCommand to return an error after executing the command,SERVER-39346,682266,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-server-servicearch,shane.harvey,shane.harvey,Feb 01 2019 08:47:08 PM UTC,Mar 04 2020 06:11:34 PM UTC,Feb 17 2021 11:15:23 AM UTC,,,,,,Backlog,,,,,0,neweng,,,,,"The {{failCommand}} fail point should have an option to return the configured error only after executing the command normally (similar to how the {{failBeforeCommitExceptionCode}} option works for the {{onPrimaryTransactionalWrite}} fail point). Right now, the error is returned before executing the command. This is important for testing sharded transactions in drivers because the recoveryToken only allows us to recover the state of the transaction.

I did not see the need for this feature earlier because I did not connect the dots with how the recoveryToken works and how the fail point works. Specifically, a commit on a new mongos cannot initiate the 2PC procedure when the first commit is never initiated on the original mongos, instead it simply waits for the transaction to timeout.

So right now, drivers can only test the following scenarios:
- commit succeeds on mongos A with no retry.
- commit fails on mongos A with no retry (because of a non-retryable error).
- commit fails on mongos A, retry succeeds on mongos A.
- commit fails on mongos A, retry fails on mongos A.
- commit fails on mongos A, retry fails on mongos B.

With this feature we can start testing the following:
- commit fails on mongos A (but it actually succeeds on the cluster), retry succeeds on mongos B because the initial commit succeeded.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,3.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2019-02-11 18:47:30.0,63504000,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,ben.caimano(ben.caimano),Tue Feb 12 23:04:40 UTC 2019,,,,,,,,,,,,,,backlog-server-servicearch(backlog-server-servicearch),greg.mckeon(greg.mckeon),shane.harvey(shane.harvey),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i33wun:",,,,,,,"0|i373jj:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i33uyf:","Feb 01 2019 11:42:27 PM UTC;shane.harvey;It looks like when failCommand is configured to return a writeConcernError, the write is actually applied and then the writeConcernError is added to the reply. Since certain writeConcernErrors cause driver to automatically retry the commit, I think this behavior might be good enough to test all the scenarios we want.

Here's an example of the failCommand/writeConcernError behavior:
{code}
mongos> db.test.drop();
true
mongos> db.adminCommand({
...     ""configureFailPoint"" : ""failCommand"",
...     ""mode"" : { ""times"" : 1 },
...     ""data"" : {
...         ""failCommands"" : [""insert""],
...         ""writeConcernError"" : {
...             ""code"" : 91,
...             ""errmsg"" : ""Replication is being shut down""
...         }
...     }
... });
{ ""ok"" : 1 }
mongos> db.runCommand({insert: ""test"", documents: [{_id:1}]});
{
	""n"" : 1,
	""writeConcernError"" : {
		""code"" : 91,
		""errmsg"" : ""Replication is being shut down""
	},
	""ok"" : 1
}
mongos> db.test.find();
{ ""_id"" : 1 }
{code}","Feb 12 2019 08:52:44 PM UTC;shane.harvey;I've confirmed that the current ""writeConcernError"" failCommand behavior is sufficient to test 4.2 sharded transactions so I think we can de-prioritize this ticket. Can someone on the server confirm that this behavior is intentional and not subject to change?

I still think it would still be nice to have this feature because a ""failAfterRunningCommand: true"" flag would be much more clear and slightly less verbose than using ""writeConcernError"". Also I suspect drivers might want this feature to test non-write concern errors in the future.","Feb 12 2019 11:04:40 PM UTC;greg.mckeon;[~shane.harvey] per SERVER-35083, this is intentional and you can rely on this behavior.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Expand AlarmScheduler to work with ReactorTimers,SERVER-46419,1188956,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-server-servicearch,ben.caimano,ben.caimano,Feb 26 2020 04:13:55 PM UTC,Mar 03 2020 06:08:10 PM UTC,Feb 17 2021 11:15:23 AM UTC,,,,,,Backlog,,,,,0,,,,,,"The [AlarmScheduler|https://github.com/mongodb/mongo/blob/ce4f6d6f6e0be8478e1f2f6f728dcc89f4b1e271/src/mongo/util/alarm.h#L52] is potentially a powerful interface we can hook up to the [ReactorTimer|https://github.com/mongodb/mongo/blob/ce4f6d6f6e0be8478e1f2f6f728dcc89f4b1e271/src/mongo/transport/transport_layer.h#L122]. We might be able to potentially expose the background thread alarm scheduler as a ServiceContext decoration to provide more generic alarm functionality throughout the system.",,,,,,,,,,,,SERVER-45117,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2020-02-26 20:10:52.0,30758400,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,ratika.gandhi(ratika.gandhi),Wed Feb 26 20:10:52 UTC 2020,,,,,,,,,,,,,,backlog-server-servicearch(backlog-server-servicearch),ben.caimano(ben.caimano),xgen-internal-githook(xgen-internal-githook),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i5hj8f:",,,,,,,"0|i5fe6n:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i5hhbz:","Feb 26 2020 08:10:52 PM UTC;xgen-internal-githook;Author:{'name': 'Ben Caimano', 'email': 'ben.caimano@10gen.com'}
Message: SERVER-45117 Guard NetworkInterfaceTL::setAlarm() more aggressively

The underlying issue is that NetworkInterfaceTL::_state and
NetworkInterfaceTL::_inProgressMutex do not synchronize with each other.
This is at best a temporary fix. Reasoning about alarm ordering in the
context of the NetworkInterface itself is messy. This approximates what
a proper composible AlarmScheudler type looks like. Hopefully, there
will be more consistent work under SERVER-46419.
Branch: master
https://github.com/mongodb/mongo/commit/57f6385025adf630a410f9d658f61b5afd140121",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Allow mongod to run on read-only media,SERVER-43378,932930,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,brian.lane,mark.brinsmead,mark.brinsmead,Sep 19 2019 08:39:04 PM UTC,Feb 18 2020 03:37:28 AM UTC,Feb 17 2021 11:15:23 AM UTC,,,,,,Backlog,Security,Storage,,,0,,,,,,Allow mongod instance to be started on read-only filesystem or read-only media (e.g. WORM device) for archival or regulatory purposes.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,3.0,,,,,,,,,,,,,,,,,,,,,5002K00000glCbaQAE,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2019-09-24 19:24:17.0,39398400,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,brian.lane(brian.lane),Tue Nov 19 03:05:32 UTC 2019,,,,,,,,,,,,,,brian.lane(brian.lane),mark.brinsmead(mark.brinsmead),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i4aciv:",,,,,,,"0|i03hqn:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i4aamn:","Sep 24 2019 07:24:17 PM UTC;brian.lane;Hey [~mark.brinsmead],

WiredTiger does already support a [read-only mode|http://source.wiredtiger.com/3.2.1/readonly.html].  We would probably start from there and see what else is required.

-Brian","Nov 19 2019 01:46:22 AM UTC;mark.brinsmead;Hi, [~brian.lane].  This was opened (meant to have been opened) as a feature request as much as anything.  This customer (and maybe others) still wants to be able to have an instance (or maybe individual collections) on read-only media.

It is *possible* that data-lake could meet some of that need, but I expect most used cases will still call for the same query performance as usual -- just a guarantee that data cannot be modified.","Nov 19 2019 03:05:32 AM UTC;brian.lane;Thanks [~mark.brinsmead] - I figured.  I can just set it to open for now, as I am not actively investigating this ticket if that was causing any confusion.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Always close user sockets during global process shutdown,SERVER-43992,969146,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-server-servicearch,jason.carey,jason.carey,Oct 14 2019 06:24:55 PM UTC,Feb 10 2020 04:13:11 PM UTC,Feb 17 2021 11:15:23 AM UTC,,,,,,Backlog,Networking,,,,0,,,,,,"During global process shutdown, we kill all operations and return a shutdown error over client sockets.  But this doesn't actually make a lot of sense, as the host is unlikely to be a good target for more operations over those sockets and network errors are already retriable.  Just closing the socket would probably produce better results than what we're doing today.

This should be a reasonably simple change (a check, probably somewhere in the service state machine / entry point, to close the socket rather than return a result if we're in global shutdown and we've been killed with a shutdown error)",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,5002K00000fMdR3QAK,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,42422400,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,ratika.gandhi(ratika.gandhi),2019-10-14 18:24:55.0,,,,,,,,,,,,,,backlog-server-servicearch(backlog-server-servicearch),jason.carey(jason.carey),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i4gj53:",,,,,,,"0|i4i4iv:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i4gh8v:",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Create a no-throw HTTP variant in the Server,SERVER-45731,1111486,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-server-security,shreyas.kalyan,shreyas.kalyan,Jan 23 2020 07:50:22 PM UTC,Feb 10 2020 03:53:54 PM UTC,Feb 17 2021 11:15:23 AM UTC,,,,,,Backlog,Security,,,,0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,33696000,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,shreyas.kalyan(shreyas.kalyan),2020-01-23 19:50:22.0,,,,,,,,,,,,,,backlog-server-security(backlog-server-security),shreyas.kalyan(shreyas.kalyan),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i54l4v:",,,,,,,"0|i54v27:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i54j8f:",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"""sleep"" command not available with mongos with enableTestCommands=1",SERVER-36066,570256,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-server-sharding,derick,derick,Jul 11 2018 02:12:27 PM UTC,Feb 06 2020 02:16:08 PM UTC,Feb 17 2021 11:15:23 AM UTC,,,,,,features we're not sure of,Testing Infrastructure,,,,0,neweng,,,,,"As part of out test suite, we use {{enableTestCommands}} to be able to use things like the {{sleep}} command. When running our tests, we verify for tests that make use of {{sleep}} that {{enableTestCommands}} is enabled by running {{getParameter}} against the (primary) server.

I've recently extended our test suite to also cover a sharded cluster, and now have run into the problem. Even though calling {{ getParameter : 1, parameter: ""enableTestCommands"" }} on mongos returns {{ ok: 1 }}, the {{sleep}} command is not available, and I get the following error when attempting to run it.

This is my full command transcript of what the test internally would run:

{code}
mongos> db.runCommand( { getParameter: 1, 'enableTestCommands' : 1 } );
{
	""enableTestCommands"" : true,
	""ok"" : 1,
	""operationTime"" : Timestamp(1531318115, 1),
	""$clusterTime"" : {
		""clusterTime"" : Timestamp(1531318115, 1),
		""signature"" : {
			""hash"" : BinData(0,""AAAAAAAAAAAAAAAAAAAAAAAAAAA=""),
			""keyId"" : NumberLong(0)
		}
	}
}
mongos> db.runCommand( { sleep: 1 } );
{
	""ok"" : 0,
	""errmsg"" : ""no such cmd: sleep"",
	""code"" : 59,
	""codeName"" : ""CommandNotFound"",
	""operationTime"" : Timestamp(1531318125, 1),
	""$clusterTime"" : {
		""clusterTime"" : Timestamp(1531318125, 1),
		""signature"" : {
			""hash"" : BinData(0,""AAAAAAAAAAAAAAAAAAAAAAAAAAA=""),
			""keyId"" : NumberLong(0)
		}
	}
}
{code}

When connecting to a standalone node, the following is returned (as expected):

{code}
> db.runCommand( { getParameter: 1, 'enableTestCommands' : 1 } );
{
	""enableTestCommands"" : true,
	""ok"" : 1,
	""$configServerState"" : {
		""opTime"" : {
			""ts"" : Timestamp(1531318185, 1),
			""t"" : NumberLong(1)
		}
	}
}
> db.runCommand( { sleep: 1 } );
{
	""ok"" : 1,
	""$configServerState"" : {
		""opTime"" : {
			""ts"" : Timestamp(1531318201, 1),
			""t"" : NumberLong(1)
		}
	}
}

{code}",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2019-05-24 20:42:45.0,54777600,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,sheeri.cabral(sheeri.cabral),Fri May 24 20:42:45 UTC 2019,,,,,,,,,,,,,,backlog-server-sharding(backlog-server-sharding),derick(derick),kaloian.manassiev(kaloian.manassiev),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i2kswf:",,,,,,,"0|i2pdxr:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i2kr07:","May 24 2019 08:42:45 PM UTC;kaloian.manassiev;I went through the {{sleep}} command on MongoD and it looks like it supports taking locks, sleeping under locks, etc. Since MongoS doesn't support locking, this part cannot be duplicated there.

[~derick], what is the scenario where drivers need to wait on the server site?",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
ability to split and balance chunks based on load and not only based on chunk size,SERVER-2472,14477,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-server-sharding,maimonoded,maimonoded,Feb 03 2011 05:40:33 AM UTC,Jan 27 2020 02:53:43 PM UTC,Feb 17 2021 11:15:23 AM UTC,,,,,,Backlog,Sharding,,,,4,,,,,,"currently mongodb will rebalance chunks on inserts, but in some cases the collection key is a numeric sequence which makes all first X amount of records go to one server and the second to the other...
this is ok as long as the load on that collection is not high, but if the collection usage is high, it means that manual sharding should be invoked by the admin.

i think that re-balancing  a collection based on its load should also be added to the balancer.  when a collection chink have a high load of queries the chunk should be splited and move to the other server/servers...",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2012-04-06 16:44:31.0,279763200,,,,,,,,PM-631,,,,,,,,,,,,,,,,,,,,true,nicholas.cottrell(nicholas.cottrell),Fri Apr 06 16:44:31 UTC 2012,,,,,,,,No,,,,,,backlog-server-sharding(backlog-server-sharding),glenn(glenn),maimonoded(maimonoded),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i06wdb:",,,,,,,"0|i0bw33:",5133,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i0it53:","Apr 06 2012 04:44:31 PM UTC;glenn;The webpage says that MongoDB already splits based on load:

http://www.mongodb.org/display/DOCS/Sharding
> Automatic balancing for changes in load and data distribution
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Audit trail not captured old values while update operartion,SERVER-27489,340407,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-server-security,ranjeetblore@gmail.com,ranjeetblore@gmail.com,Dec 21 2016 06:17:06 PM UTC,Jan 21 2020 06:09:18 PM UTC,Feb 17 2021 11:15:23 AM UTC,,,,,,Backlog,Admin,Security,,,1,,,,,,"Hello All,

I have requirement to track update information like old values, new values, updated by, timestamp, collection, etc ..

I have enabled the audit for crud operation with parameter as below ....

{noformat}
--auditDestination file --auditFormat JSON --auditPath /data/db/auditLog.json --setParameter auditAuthorizationSuccess=true
{noformat}


old  values  :
==================

""statusCode"" : ""NOACTN""

==============
update statement :

{noformat}
MongoDB Enterprise > db.preauth_case.update(
...    { ""createdByUserId"" : -2 },
...    {
...       $set: {""statusCode"" : ""Update"", }
...      }
... )

WriteResult({ ""nMatched"" : 1, ""nUpserted"" : 0, ""nModified"" : 1 })
{noformat}

======================
Audit Trail  : ==>

{noformat}
{ ""atype"" : ""authCheck"", ""ts"" : { ""$date"" : ""2016-12-20T22:19:45.416-0500"" }, ""local"" : { ""ip"" : ""127.0.0.1"", ""port"" : 27017 }, ""remote"" : { ""ip"" : ""127.0.0.1"", ""port"" : 65465 }, ""users"" : [], ""roles"" : [], ""param"" : { ""command"" : ""ping"", ""ns"" : ""test"", ""args"" : { ""ping"" : 1 } }, ""result"" : 0 }
{ ""atype"" : ""authCheck"", ""ts"" : { ""$date"" : ""2016-12-20T22:19:45.416-0500"" }, ""local"" : { ""ip"" : ""127.0.0.1"", ""port"" : 27017 }, ""remote"" : { ""ip"" : ""127.0.0.1"", ""port"" : 65506 }, ""users"" : [], ""roles"" : [], ""param"" : { ""command"" : ""ping"", ""ns"" : ""ACMP_DEMO"", ""args"" : { ""ping"" : 1 } }, ""result"" : 0 }
{ ""atype"" : ""authCheck"", ""ts"" : { ""$date"" : ""2016-12-20T22:20:08.977-0500"" }, ""local"" : { ""ip"" : ""127.0.0.1"", ""port"" : 27017 }, ""remote"" : { ""ip"" : ""127.0.0.1"", ""port"" : 63357 }, ""users"" : [], ""roles"" : [], ""param"" : { ""command"" : ""update"", ""ns"" : ""ACMP_DEMO.preauth_case"", ""args"" : { ""update"" : ""preauth_case"", ""updates"" : [ { ""q"" : { ""createdByUserId"" : -2 }, ""u"" : { ""$set"" : { ""statusCode"" : ""Update"" } }, ""multi"" : false, ""upsert"" : false } ], ""ordered"" : true } }, ""result"" : 0 }
{ ""atype"" : ""authCheck"", ""ts"" : { ""$date"" : ""2016-12-20T22:20:08.998-0500"" }, ""local"" : { ""ip"" : ""127.0.0.1"", ""port"" : 27017 }, ""remote"" : { ""ip"" : ""127.0.0.1"", ""port"" : 63357 }, ""users"" : [], ""roles"" : [], ""param"" : { ""command"" : ""isMaster"", ""ns"" : ""ACMP_DEMO"", ""args"" : { ""isMaster"" : 1, ""forShell"" : 1 } }, ""result"" : 0 }
{ ""atype"" : ""authCheck"", ""ts"" : { ""$date"" : ""2016-12-20T22:20:45.423-0500"" }, ""local"" : { ""ip"" : ""127.0.0.1"", ""port"" : 27017 }, ""remote"" : { ""ip"" : ""127.0.0.1"", ""port"" : 65467 }, ""users"" : [], ""roles"" : [], ""param"" : { ""command"" : ""ping"", ""ns"" : ""admin"", ""args"" : { ""ping"" : 1 } }, ""result"" : 0 }
{ ""atype"" : ""authCheck"", ""ts"" : { ""$date"" : ""2016-12-20T22:20:45.423-0500"" }, ""local"" : { ""ip"" : ""127.0.0.1"", ""port"" : 27017 }, ""remote"" : { ""ip"" : ""127.0.0.1"", ""port"" : 49201 }, ""users"" : [], ""roles"" : [], ""param"" : { ""command"" : ""ping"", ""ns"" : ""admin"", ""args"" : { ""ping"" : 1 } }, ""result"" : 0 }
{ ""atype"" : ""authCheck"", ""ts"" : { ""$date"" : ""2016-12-20T22:20:45.423-0500"" }, ""local"" : { ""ip"" : ""127.0.0.1"", ""port"" : 27017 }, ""remote"" : { ""ip"" : ""127.0.0.1"", ""port"" : 65464 }, ""users"" : [], ""roles"" : [], ""param"" : { ""command"" : ""ping"", ""ns"" : ""admin"", ""args"" : { ""ping"" : 1 } }, ""result"" : 0 }
{ ""atype"" : ""authCheck"", ""ts"" : { ""$date"" : ""2016-12-20T22:20:45.424-0500"" }, ""local"" : { ""ip"" : ""127.0.0.1"", ""port"" : 27017 }, ""remote"" : { ""ip"" : ""127.0.0.1"", ""port"" : 65505 }, ""users"" : [], ""roles"" : [], ""param"" : { ""command"" : ""ping"", ""ns"" : ""admin"", ""args"" : { ""ping"" : 1 } }, ""result"" : 0 }
{ ""atype"" : ""authCheck"", ""ts"" : { ""$date"" : ""2016-12-20T22:20:45.424-0500"" }, ""local"" : { ""ip"" : ""127.0.0.1"", ""port"" : 27017 }, ""remote"" : { ""ip"" : ""127.0.0.1"", ""port"" : 49195 }, ""users"" : [], ""roles"" : [], ""param"" : { ""command"" : ""ping"", ""ns"" : ""admin"", ""args"" : { ""ping"" : 1 } }, ""result"" : 0 }
{ ""atype"" : ""authCheck"", ""ts"" : { ""$date"" : ""2016-12-20T22:20:45.426-0500"" }, ""local"" : { ""ip"" : ""127.0.0.1"", ""port"" : 27017 }, ""remote"" : { ""ip"" : ""127.0.0.1"", ""port"" : 49202 }, ""users"" : [], ""roles"" : [], ""param"" : { ""command"" : ""ping"", ""ns"" : ""ACMP_DEMO"", ""args"" : { ""ping"" : 1 } }, ""result"" : 0 }
{ ""atype"" : ""authCheck"", ""ts"" : { ""$date"" : ""2016-12-20T22:20:45.427-0500"" }, ""local"" : { ""ip"" : ""127.0.0.1"", ""port"" : 27017 }, ""remote"" : { ""ip"" : ""127.0.0.1"", ""port"" : 65468 }, ""users"" : [], ""roles"" : [], ""param"" : { ""command"" : ""ping"", ""ns"" : ""ACMP_DEMO"", ""args"" : { ""ping"" : 1 } }, ""result"" : 0 }
{ ""atype"" : ""authCheck"", ""ts"" : { ""$date"" : ""2016-12-20T22:20:45.428-0500"" }, ""local"" : { ""ip"" : ""127.0.0.1"", ""port"" : 27017 }, ""remote"" : { ""ip"" : ""127.0.0.1"", ""port"" : 65465 }, ""users"" : [], ""roles"" : [], ""param"" : { ""command"" : ""ping"", ""ns"" : ""test"", ""args"" : { ""ping"" : 1 } }, ""result"" : 0 }
{ ""atype"" : ""authCheck"", ""ts"" : { ""$date"" : ""2016-12-20T22:20:45.428-0500"" }, ""local"" : { ""ip"" : ""127.0.0.1"", ""port"" : 27017 }, ""remote"" : { ""ip"" : ""127.0.0.1"", ""port"" : 49196 }, ""users"" : [], ""roles"" : [], ""param"" : { ""command"" : ""ping"", ""ns"" : ""ACMP_DEMO"", ""args"" : { ""ping"" : 1 } }, ""result"" : 0 }
{ ""atype"" : ""authCheck"", ""ts"" : { ""$date"" : ""2016-12-20T22:20:45.428-0500"" }, ""local"" : { ""ip"" : ""127.0.0.1"", ""port"" : 27017 }, ""remote"" : { ""ip"" : ""127.0.0.1"", ""port"" : 65506 }, ""users"" : [], ""roles"" : [], ""param"" : { ""command"" : ""ping"", ""ns"" : ""ACMP_DEMO"", ""args"" : { ""ping"" : 1 } }, ""result"" : 0 }
{noformat}

Manually formatted  : >

{noformat}
{ ""atype"" : ""authCheck"", 

""ts"" : { ""$date"" : ""2016-12-20T22:20:08.977-0500"" }, 

""local"" : { ""ip"" : ""127.0.0.1"", ""port"" : 27017 }, 

""remote"" : { ""ip"" : ""127.0.0.1"", ""port"" : 63357 },

 ""users"" : [], 

""roles"" : [],

""param"" : { ""command"" : ""update"", ""ns"" : ""ACMP_DEMO.preauth_case"", ""args"" : { ""update"" : ""preauth_case"", ""updates"" : [ { ""q"" : { ""createdByUserId"" : -2 }, ""u"" : { ""$set"" : { ""statusCode"" : ""Update"" } }, ""multi"" : false, ""upsert"" : false } ], ""ordered"" : true } }, 

""result"" : 0 }
{noformat}

============

Question  Here :

1 > Could be track the old values also from audit trail  ?
2 > How could be collected all audit trail important information in a collection.

I would be appreciate if you guys have some input on above query.

",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,3.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2016-12-22 20:43:40.0,130636800,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,sara.williamson(sara.williamson),Tue Dec 27 18:55:16 UTC 2016,,,,,,,,,,,,,,backlog-server-security(backlog-server-security),ranjeetblore@gmail.com(ranjeetblore@gmail.com),spencer.jackson(spencer.jackson@10gen.com),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i1hvuf:",,,,,,,"0|i05pfz:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i0mq9z:","Dec 22 2016 08:43:40 PM UTC;spencer.jackson;Hi! It's not currently possible to audit the the old values which existed in a document before an update. This seems like a feature request, so we'll keep this ticket open to track it.
As for point 2, is there any collection information in particular are you interested in logging?","Dec 27 2016 04:27:54 PM UTC;ranjeetblore@gmail.com;Thanks for update  of first query.

With reference of second query , I would like to know , Is mongodb having  any features to convert audit trail log in  collection  ?  
So that end user can easily track all transaction history for audit purpose from collection itself .



 ","Dec 27 2016 06:55:16 PM UTC;spencer.jackson;[~ranjeetblore@gmail.com], the ability to store the audit log directly into a collection is not currently a supported feature, sorry. However, it looks like there is already an open ticket tracking a request to implement it: SERVER-12670. I encourage you to watch and vote for that issue, which will help us track demand and make scheduling decisions. Thanks!
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Server Selection localThresholdMS enhancement,SERVER-31010,425608,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-server-servicearch,shakir.sadikali,shakir.sadikali,Sep 08 2017 06:53:36 PM UTC,Jan 09 2020 08:00:08 PM UTC,Feb 17 2021 11:15:24 AM UTC,,,,,,Backlog,Replication,,,,1,,,,,,"From the documentation

{quote}
_When localThresholdMS is used :
During monitoring, drivers regularly record the RTT of ismaster commands. The Server Selection specification calls for these to be calculated using an exponentially-weighted moving average function.
{quote}

If the prior average is denoted RTTt-1, then the new average (RTTt) is computed from a new RTT measurement (Xt) and a weighting factor (α) using the following formula:
{noformat}
  t = α·Xt + (1-α)·RTTt-1
{noformat}

The weighting factor is set to 0.2, which was chosen to put about 85% of the weight of the average RTT on the 9 most recent observations. Weighting recent observations more means that the average responds quickly to sudden changes in latency._

Would it be possible to have another similar configuration option to tell the client to observe query/operation response times over a window of time or over n executions, be able to specify a threshold for response times so that servers with best response times can be picked over slow responding servers?",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,3.0,,,,,,,,,,,,,,,,,,,,,500A000000Y087tIAB,500A000000YRGA2IAP,500A000000YQAWhIAP,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2017-09-08 20:27:33.0,53568000,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,jason.carey(jason.carey),Fri Jun 07 16:59:23 UTC 2019,,,,,,,,,,,,,,backlog-server-servicearch(backlog-server-servicearch),jason.carey(jason.carey),nmayakuntla(nmayakuntla),shakir.sadikali(shakir.sadikali),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i1wdyv:",,,,,,,"0|i04n7j:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i1wc2n:","Sep 08 2017 10:00:48 PM UTC;nmayakuntla;Example Scenario:

    5 Node Cluster (2 in DC1, 2 in DC2, 1 DC3). Primary in DC1.
    Client is using secondaryPreferred
    localThresholdMs is set to 3ms
    Latency from DC1 <=> DC2 is 8ms, DC2 <=> DC3 is 8ms, DC1 <=> DC2 is 15ms. Inter-DC is ~1ms.

If a Client in DC2 sends a request, the 2 nodes in DC2 are eligible.

If one of the nodes in DC2 has a storage/disk i/o latency problem, the RTT calculation via Heartbeat will not be aware (because isMaster does not interact w/ disk). Therefore, the client will continue to consider a node that is consistently returning queries past the desired SLA). It's likely that localThresholdMs was meant to only consider network latency, but if it could be amended (or a new parameter added) to consider end-to-end execution ...","Sep 15 2017 05:19:38 PM UTC;nmayakuntla;It would also help if an event can be generated to let application know that a node(s) were not considered because of high latency so that we can know certain node(s) had issue and maybe log/alert based on that.","Jun 07 2019 04:59:23 PM UTC;jason.carey;I wanted to provide an update on a feature that provides some help in situations like the one above, albeit through a very different kind of mechanism.

After SERVER-41132 (which is in master, and planned to land in 4.2.0), we've made an update to how read preference targeting is utilized for command dispatch.

Specifically, in pre-4.2 land, read preference targeting finds all eligible hosts, then selects one at random to execute a command against.  After 4.2, read preference targeting will:
* Generate a list of all known hosts that satisfy that read preference
* Request connections to each host in an order dictated by random selection
* Use the first connection acquired (either because we have one available, or when we're able to initialize one)
* Cease requesting new connections after one is acquired

This should cause us to preferentially route requests to hosts with more ready connections (either because of a transient drop in performance/availability or because of heterogeneous capacity).

This functionality is only in mongos for the moment (so you can't get it in a driver), and it isn't precisely what's described here, but it solves a similar set of use cases.  It has some other benefits in allowing us to respond much quicker than a time windowing system would allow, as well as allowing for uneven distribution of work to heterogeneous servers (rather than being an all or nothing threshold)",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
SNMP Support for simple admin operations,SERVER-5758,37759,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-server-security,schwerin,schwerin,May 03 2012 04:59:21 PM UTC,Dec 24 2019 12:36:48 AM UTC,Feb 17 2021 11:15:24 AM UTC,,,,,,Backlog,Admin,,,,0,,,,,,"Some edition of mongo should have full-featured SNMP support -- at least the ability to observe the same counters that MMS observes, and maybe the ability to perform basic management (step down primaries, e.g.).",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2012-05-03 17:03:38.0,255657600,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,spencer.jackson(spencer.jackson@10gen.com),Thu Jan 10 15:15:15 UTC 2013,,,,,,,,No,,,,,,schwerin(schwerin),backlog-server-security(backlog-server-security),eliot(eliot),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i05t9b:",,,,,,,"0|i05o9j:",5938,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i1i2an:","Jan 10 2013 03:15:15 PM UTC;eliot;Will leave this for admin ops, SERVER-6299 for statistics, etc...",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Option to limit connections per database,SERVER-12288,105075,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-server-security,andre.defrere,andre.defrere,Jan 08 2014 02:50:04 AM UTC,Dec 24 2019 12:28:36 AM UTC,Feb 17 2021 11:15:24 AM UTC,,,,,,features we're not sure of,Internal Code,,,,6,,,,,,"New option similar to maxConns, that enables a user to tune the number of connections to any database.

Requirement would be to have this to be able to be tuned for specific databases, and allow the connection limit be changed dynamically.

In multi tenant situations, it would be very helpful and useful to be able to limit connections to any particular database, as this gives finer grained control than limiting the total number of connections to a host.",,,,,,,,,,,,CS-10199,CS-11041,PM-138,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,500A000000UaVoeIAF,500A000000UaYsOIAV,500A000000a9J7gIAE,5002K00000glkFeQAI,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2014-01-08 04:08:38.0,224294400,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,spencer.jackson(spencer.jackson@10gen.com),Wed Jan 08 14:30:49 UTC 2014,,,,,,,,No,,,,,,andre.defrere(andre.defrere),backlog-server-security(backlog-server-security),eliot(eliot),milkie(milkie),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i03tjr:",,,,,,,"0|i05r3b:",6710,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i175xj:","Jan 08 2014 04:08:38 AM UTC;eliot;Connections aren't associated with a database, so not sure this is possible.","Jan 08 2014 02:30:49 PM UTC;milkie;One thing we might consider is to limit the number of authenticated sessions per user per server instance.  Then you could use user permissions to achieve the goal of sessions per database.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Support logging/auditing to the Windows Event Log ,SERVER-12453,107316,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-server-security,andreas.nilsson,andreas.nilsson,Jan 23 2014 03:22:46 PM UTC,Dec 24 2019 12:28:20 AM UTC,Feb 17 2021 11:15:24 AM UTC,,2.5.4,,,,Backlog,Logging,,,,3,Auditing,community-team,platforms-re-triaged,Windows,,"There is currently no support for sending logs to the Windows Event Log.

Windows Event Log is the standard way of logging on Windows so it's a long-term ""should have"" feature. This should include normal logs as well as audit logs. 

Implementation steps:
1. Determine how our logs fits into the different event log categories/labeling system.
2. During install register MongoDB as a logging application in the event log manager using the Win32 API.
3. Implement a log facility for the event log in the server using Win32 API and forward logs and audit logs to it.",Windows,,,,,,,,,,,HELP-354,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,Fully Compatible,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2014-01-23 19:15:13.0,202176000,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,spencer.jackson(spencer.jackson@10gen.com),Mon Sep 22 10:14:29 UTC 2014,,,,,,,,No,,,,,,andreas.nilsson(andreas.nilsson@10gen.com),backlog-server-security(backlog-server-security),mark.benvenuto(mark.benvenuto),mikeb@asos.com(mikeb@asos.com),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i03sbr:",,,,,,,"0|i05ok7:",3734,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i174qn:","Jan 23 2014 07:15:13 PM UTC;mark.benvenuto;We also need to evaluate how this will integrate with our ETW story. We will need to decide what log content goes to each and under which verbosity level. Windows Event Log is not designed for a high volume of logs while ETW is. Windows Event Log is easier to alert for administrators.","Sep 22 2014 10:14:29 AM UTC;mikeb@asos.com;Alert monitoring is handled by our Data Management Centre.
Alerting by Mongo DB instances by writing to the Windows event log & MMS gathering these alerts will provide the ability for our DM staff to pick up & inform the relevant team of issues.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Add support for inline deadline + uninterruptibility in Interruptible,SERVER-43665,942440,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-server-servicearch,jason.carey,jason.carey,Sep 26 2019 10:03:23 PM UTC,Dec 17 2019 06:20:01 PM UTC,Feb 17 2021 11:15:24 AM UTC,,,,,,Backlog,Internal Code,,,,0,,,,,,"Add support for a single level form of subsidiary deadlines + uninterruptibility in Interruptible with a syntax that looks like:

{code:cpp}
future.get(interruptible->makeTimer(deadline, code));
{code}

That syntax should produce a type convertible to an Interruptible* which wraps underlying calls to checkForInterrupt or waitForConditionOrInterruptUntil calls in the appropriate guards.  It should replace the more wordy:

{code:cpp}
interruptible->runWithDeadline(deadline, code, [&]{
  future.get(interruptible);
});
{code}

when a subsidiary deadline or uninterruptible invocation is needed at the very bottom of the callstack.

That type should not nest and should not alter the state of the parent interruptible",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,Fully Compatible,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,43977600,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,ratika.gandhi(ratika.gandhi),2019-09-26 22:03:23.0,,,,,,,,,,,,,,backlog-server-servicearch(backlog-server-servicearch),jason.carey(jason.carey),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i4byk7:",,,,,,,"0|i4do8v:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i4bwnz:",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Ability to distribute collections in a single db,SERVER-939,10661,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-server-sharding,eliot,eliot,Sep 28 2009 08:59:36 AM UTC,Dec 05 2019 10:54:14 PM UTC,Feb 17 2021 11:15:24 AM UTC,,,,,,Backlog,Sharding,,,,99,pm-1051-legacy-tickets,,,,,"The implementation of this feature (without moveCollections) has the following work items:

* Add new parsing functionality to mongos/mongod for chunk manager logic
* Build new scatterCollections and createCollection commands
* Deprecate enableSharding
* Moderate refactoring of the mongod config reload codebase (d_logic.cpp)

To implement moveCollections some additional work is probably necessary, but we can leverage much of the cloneCollection framework.",,,,,,,,PERF-54,,,,SERVER-4621,CS-4220,SERVER-8870,SERVER-4773,CS-11745,CS-15699,CS-16046,CS-21599,PM-497,HELP-2219,HELP-2579,,,,,,,,,,93.0,,,,,,,,,,,,,,,,,,,,,500A000000XOXLCIA5,5002K00000iQAWfQAO,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2010-11-19 18:44:32.0,197942400,<s><a href='https://jira.mongodb.org/browse/PERF-54'>PERF-54</a></s>,,,,,,,,,,,,,,,,,,,,,,,,,,,true,,Sun Nov 09 17:06:01 UTC 2014,,,,,,,,,,,,,,alerner(alerner),aravindhu(aravindhu),asya(asya),auto(auto),azat(azat),backlog-server-sharding(backlog-server-sharding),eliot(eliot),greg_10gen(greg_10gen),ian.whalen(ian@10gen.com),crazyzh1984(crazyzh1984),karl(karl),matrix64(matrix64),mediamath(mediamath),desmortes(desmortes),remonvv(remonvv),ukolov_sergey(ukolov_sergey),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i07dwf:",,,,,,,"0|i0bshb:",4086,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i01gk7:","Dec 17 2010 04:57:18 AM UTC;eliot;Sorry for continuing to push this, don't want to hack it in a bad way.","Dec 17 2010 06:35:22 PM UTC;matrix64;What exactly does this feature mean? Doesn't MongoDB already support sharding of collections within a database among nodes in a set?","Dec 17 2010 06:42:42 PM UTC;eliot;No - currently we distribute databases and objects (in a sharded collection), but not collections themselves. ","Dec 17 2010 08:19:02 PM UTC;matrix64;I don't understand. Could you please explain what scenario is currently unavailable that this feature will make available?","Dec 17 2010 09:27:36 PM UTC;eliot;If you have 1 database, and 1000 collections, all 1000 collections will be on the same shard without this.
If you have 10 databases, and 100 collections per shard, then your databases (and therefore collections) will be distributed across shards.","Dec 17 2010 09:28:22 PM UTC;alerner;If you create a new database, the most available shard at that time will be picked to host that entire database. That is , all its collections would be in that shard. If you create another database, possible another shard will be picked for all the collections of that database.

With this feature, each of the collections could have a different shard.

","Dec 18 2010 09:33:47 AM UTC;matrix64;Thank you for the answers so far. So how can a single collection have documents stored on many shards if it's limited to one shard?","Dec 18 2010 02:00:19 PM UTC;alerner;http://www.mongodb.org/display/DOCS/Configuring+Sharding#ConfiguringSharding-ShardingaCollection","Apr 01 2011 08:38:01 AM UTC;remonvv;Any news on ETA and implementation details? This is becoming a problem for us.","Apr 01 2011 02:08:19 PM UTC;eliot;No further information that is attached to the ticket, so its currently in 1.9 planning which as the version says is things we're hoping to get in 1.9","Aug 19 2011 02:19:39 AM UTC;karl;A particularly useful reason to have this is to be able to use capped collections in a greater number of scenarios.  For example, if you want to maintain X logs per server via a capped collection, you need each servers to have its own collection (because you don't want the last 1000 logs in total, you want the last 1000 logs *per server*.) However, once you do this, you can't shard..and I get sad face. (edit: you can shard, you just need to do it yourself, obviously).","Jan 04 2012 10:16:27 PM UTC;eliot;SERVER-4621 will give the ability to do this with a little manual effort - but at least it will be possible.","Jan 04 2012 10:31:17 PM UTC;mediamath;
Even if you can disable balancer on per collection bases, you still need a way to set ""primary"" for collections which I have been told that it is not possible yet. Has that changed yet?","Jan 05 2012 12:17:55 AM UTC;eliot;With SERVER-4621 - you can shard a collection, mark it as no balancing, and the move the 1 chunk to a different shard - effectively doing what you want.","Apr 24 2012 07:52:46 AM UTC;ukolov_sergey;any news about this? When do you think it will be implemented? With big amount of unsharded collections SERVER-4621 will be a problem...","Apr 25 2012 06:10:00 PM UTC;azat;Eliot, how #SERVER-4621 allows set primary server for collection? (related to #SERVER-5707)","Apr 25 2012 06:13:15 PM UTC;eliot;@azat - you can shard a collection, move the only chunk to where you want it and then disable balancing for that collection.
","Apr 25 2012 06:23:28 PM UTC;azat;@eliot how can I do this? (Simple code would be usefull)","Jul 31 2012 11:44:15 AM UTC;ukolov_sergey;Don't you have in plans to implement this in next release? Sorry, but this is very important ticket for me...","Jul 31 2012 02:30:28 PM UTC;ian.whalen;Ukolov, this will not be in the 2.2 release.  We're still finalizing the feature set for the 2.4 release and will definitely take your concerns and votes here into consideration.","Sep 18 2012 05:10:42 AM UTC;aravindhu;When can I expect this feature , I am badly in need of this , because I create collections dynamically , and collections get filled with data seamlessly . Please let me know when this feature is going to be implemented ","Oct 16 2012 11:14:16 AM UTC;desmortes;This will be a great feature to have and I am eagerly looking forward to it.","Oct 23 2012 07:12:15 PM UTC;alerner;Author:{u'date': u'2012-10-23T12:29:57-07:00', u'name': u'Alberto Lerner', u'email': u'alerner@10gen.com'}
Message:Introduced constants to refer to collection names and fields in the config server.
Branch: master
https://github.com/mongodb/mongo/commit/03f6428015116124d70a61287c89b191fa3c9ab7","Nov 06 2012 12:16:03 AM UTC;auto;Author:{u'date': u'2012-10-26T21:49:50Z', u'email': u'alerner@10gen.com', u'name': u'Alberto Lerner'}
Message: SERVER-939 Introduced more collection and fields names constants.
Branch: master
https://github.com/mongodb/mongo/commit/0785b7a0a33c56a5915121ec87949304dd55052c","Nov 09 2012 09:59:14 PM UTC;auto;Author:{u'date': u'2012-11-08T20:33:44Z', u'email': u'alerner@10gen.com', u'name': u'Alberto Lerner'}
Message: SERVER-939 Introduced type for config.collection docs.
Branch: master
https://github.com/mongodb/mongo/commit/e0efa2671623d2b034c4aee673f070dd8ff15c17","Nov 10 2012 09:05:41 PM UTC;auto;Author:{u'date': u'2012-11-10T20:55:37Z', u'email': u'alerner@10gen.com', u'name': u'Alberto Lerner'}
Message: SERVER-939 Included generic bson header (fix compile)
Branch: master
https://github.com/mongodb/mongo/commit/4c78e38659901dfb3e3ca91b7aa7f4864401ee7d","Nov 10 2012 10:23:51 PM UTC;auto;Author:{u'date': u'2012-11-10T22:23:42Z', u'email': u'alerner@10gen.com', u'name': u'Alberto Lerner'}
Message: SERVER-939 Corrected bson ownership (fixed unit test)
Branch: master
https://github.com/mongodb/mongo/commit/894cc05556fbf69ee515b3685a60e8a5e6d345aa","Nov 11 2012 08:41:52 PM UTC;auto;Author:{u'date': u'2012-11-11T00:10:46Z', u'email': u'alerner@10gen.com', u'name': u'Alberto Lerner'}
Message: SERVER-939 Changed FieldParser to have the correct BSON ownership semantics.
Branch: master
https://github.com/mongodb/mongo/commit/889fd753e98dfb91970560c798c3b9c15bdb96f2","Nov 19 2012 07:53:21 PM UTC;auto;Author:{u'date': u'2012-11-13T19:58:20Z', u'email': u'shaun.verch@10gen.com', u'name': u'Shaun Verch'}
Message: SERVER-939 Added field type constants for config.locks collection
Branch: master
https://github.com/mongodb/mongo/commit/77bf7870d02267ff3dde6ac87c2e7d9ddac92ddd","Nov 19 2012 11:58:11 PM UTC;auto;Author:{u'date': u'2012-11-19T23:49:17Z', u'email': u'alerner@10gen.com', u'name': u'Alberto Lerner'}
Message: SERVER-939 Introduced types for config.databases and config.chunks collections.
Branch: master
https://github.com/mongodb/mongo/commit/3cc16161de9e097c34f8992bd7376203af86182e","Nov 20 2012 12:51:34 AM UTC;auto;Author:{u'date': u'2012-11-19T20:29:23Z', u'email': u'shaun.verch@10gen.com', u'name': u'Shaun Verch'}
Message: SERVER-939 Added field type constants for config.lockpings collection
Branch: master
https://github.com/mongodb/mongo/commit/ec38a5b7f242987fdabd27c6acc257b79936ffd7","Nov 20 2012 03:03:25 AM UTC;auto;Author:{u'date': u'2012-11-20T02:57:50Z', u'email': u'alerner@10gen.com', u'name': u'Alberto Lerner'}
Message: SERVER-939 Introduced type for config.shards collection.
Branch: master
https://github.com/mongodb/mongo/commit/38a48227486caecfe45e4754418e22f804cdbf84","Nov 21 2012 06:53:27 PM UTC;auto;Author:{u'date': u'2012-11-20T21:07:28Z', u'email': u'shaun.verch@10gen.com', u'name': u'Shaun Verch'}
Message: SERVER-939 Added field type constants for config.mongos collection
Branch: master
https://github.com/mongodb/mongo/commit/ca6b31d9d2da68bb14ea896d3db8de72fb0bed5d","Nov 22 2012 12:13:41 AM UTC;auto;Author:{u'date': u'2012-11-21T19:38:44Z', u'email': u'shaun.verch@10gen.com', u'name': u'Shaun Verch'}
Message: SERVER-939 Added field type constants for config.changelog collection
Branch: master
https://github.com/mongodb/mongo/commit/319c7f0ced3935dd9d28ed89895112e6504612cd","Nov 29 2012 05:55:20 AM UTC;auto;Author:{u'date': u'2012-11-26T20:15:08Z', u'email': u'alerner@10gen.com', u'name': u'Alberto Lerner'}
Message: SERVER-939 new CollectionManager and MetadataLoader classes (not yet hooked).
Branch: master
https://github.com/mongodb/mongo/commit/eb3cf24e3ed24169c45cfa8dcf0e49ead12eeb49","Nov 29 2012 06:07:48 AM UTC;auto;Author:{u'date': u'2012-11-29T06:04:38Z', u'email': u'alerner@10gen.com', u'name': u'Alberto Lerner'}
Message: SERVER-939 Cleaned CollectionManager.
Branch: master
https://github.com/mongodb/mongo/commit/5352721ef242ae2f2531dbfb10b868444129fe80","Nov 29 2012 10:10:42 AM UTC;auto;Author:{u'date': u'2012-11-29T10:10:19Z', u'email': u'tad@10gen.com', u'name': u'Tad Marshall'}
Message: SERVER-939 whitespace (indent) for cpplint
Branch: master
https://github.com/mongodb/mongo/commit/8c4d33f505fb0a3374583894a3dccc10a754eb36","Nov 29 2012 10:18:17 AM UTC;auto;Author:{u'date': u'2012-11-29T10:17:59Z', u'email': u'tad@10gen.com', u'name': u'Tad Marshall'}
Message: SERVER-939 fix compile
Branch: master
https://github.com/mongodb/mongo/commit/9c6912e0a70e2ff95bc2a30c4e07dae56205521b","Nov 29 2012 11:17:45 PM UTC;auto;Author:{u'date': u'2012-11-26T23:22:02Z', u'email': u'shaun.verch@10gen.com', u'name': u'Shaun Verch'}
Message: SERVER-939 Added field type constants for config.settings collection
Branch: master
https://github.com/mongodb/mongo/commit/b8bdc320d5bf4ad9ad24eacbb310bddc1e3133ad","Nov 29 2012 11:17:48 PM UTC;auto;Author:{u'date': u'2012-11-29T22:05:23Z', u'email': u'shaun.verch@10gen.com', u'name': u'Shaun Verch'}
Message: SERVER-939 Added shard tags to field constants and document type
Branch: master
https://github.com/mongodb/mongo/commit/40577e84f4fc3e9b2ec7e6db3448ff5cedaa9c6c","Dec 03 2012 10:03:26 PM UTC;auto;Author:{u'date': u'2012-11-26T19:09:25Z', u'email': u'greg@10gen.com', u'name': u'Greg Studer'}
Message: SERVER-939 simplify use of scoped distributed and balancer lock
Branch: master
https://github.com/mongodb/mongo/commit/94fe9334b1d09383d583ab5e56c05a1fb3754753","Dec 03 2012 10:03:28 PM UTC;auto;Author:{u'date': u'2012-11-26T19:09:49Z', u'email': u'greg@10gen.com', u'name': u'Greg Studer'}
Message: SERVER-939 toString() for random part of OID
Branch: master
https://github.com/mongodb/mongo/commit/b8185fc4eac2726d0e850698ac100b9686f8755f","Dec 03 2012 10:03:31 PM UTC;auto;Author:{u'date': u'2012-11-26T19:14:51Z', u'email': u'greg@10gen.com', u'name': u'Greg Studer'}
Message: SERVER-939 error handling for string*
Branch: master
https://github.com/mongodb/mongo/commit/d26f22eb2e4280f3dc5713ab99da810208c783da","Dec 03 2012 10:03:32 PM UTC;auto;Author:{u'date': u'2012-11-26T19:14:35Z', u'email': u'greg@10gen.com', u'name': u'Greg Studer'}
Message: SERVER-939 modify config types for config version changes
Branch: master
https://github.com/mongodb/mongo/commit/64408b78c89a65a4a727b57d552b64bf5f7eb803","Dec 03 2012 10:03:34 PM UTC;auto;Author:{u'date': u'2012-11-30T21:32:43Z', u'email': u'greg@10gen.com', u'name': u'Greg Studer'}
Message: SERVER-939 enhance owned pointer vector and add owned pointer map
Branch: master
https://github.com/mongodb/mongo/commit/ceddaa1ac65b1c06e62a217f4a78086e0a354f23","Dec 03 2012 10:03:36 PM UTC;auto;Author:{u'date': u'2012-11-26T19:11:46Z', u'email': u'greg@10gen.com', u'name': u'Greg Studer'}
Message: SERVER-939 make scopedDbConnection take ConnectionStrings directly
Branch: master
https://github.com/mongodb/mongo/commit/e857f6608ceafa5dbb4b863ca78193de47694402","Dec 03 2012 10:03:38 PM UTC;auto;Author:{u'date': u'2012-12-03T20:50:15Z', u'email': u'greg@10gen.com', u'name': u'Greg Studer'}
Message: SERVER-939 minor fixes to test cases for new type_ parsing
Branch: master
https://github.com/mongodb/mongo/commit/d2df0645428251b2d107b8ebe2f6f37b203ec057","Dec 03 2012 10:03:40 PM UTC;auto;Author:{u'date': u'2012-12-03T21:38:28Z', u'email': u'greg@10gen.com', u'name': u'Greg Studer'}
Message: SERVER-939 rollback bson element error message change
Branch: master
https://github.com/mongodb/mongo/commit/603b9c6795e4cc0db9ff8f344cb9bf1100ff8b1d","Dec 05 2012 04:19:07 PM UTC;greg_10gen;Yeah - forgot that debug builds fail immediately on verify.  Will work to try and fix.  ","Dec 06 2012 03:45:11 PM UTC;auto;Author:{u'date': u'2012-12-06T15:43:28Z', u'email': u'greg@10gen.com', u'name': u'Greg Studer'}
Message: SERVER-939 temporarily remove scoped dist lock tests, currently incompatible with debug builds
Branch: master
https://github.com/mongodb/mongo/commit/a781f5a0f6ae1ee24cd83b210c779e400bfaac96","Dec 11 2012 07:34:54 PM UTC;auto;Author:{u'date': u'2012-12-11T19:28:45Z', u'email': u'greg@10gen.com', u'name': u'Greg Studer'}
Message: SERVER-939 field parser and BSON enhancements for vectors and maps
Branch: master
https://github.com/mongodb/mongo/commit/9bc4f3efb3455e0bcd41de908f7ec10532255b2d","Dec 11 2012 07:34:56 PM UTC;auto;Author:{u'date': u'2012-12-11T19:29:01Z', u'email': u'greg@10gen.com', u'name': u'Greg Studer'}
Message: SERVER-939 fixes to database type
Branch: master
https://github.com/mongodb/mongo/commit/d53150750557b974d859da3c56dc0ae847e67cc2","Dec 18 2012 04:41:44 PM UTC;auto;Author:{u'date': u'2012-11-30T02:16:08Z', u'name': u'Shaun Verch', u'email': u'shaun.verch@10gen.com'}
Message: SERVER-939 Changed ChunkFields to ChunkType
Branch: master
https://github.com/mongodb/mongo/commit/566cf01bd870036b0dfd4b2babaf414b65de444c","Dec 18 2012 04:41:46 PM UTC;auto;Author:{u'date': u'2012-11-30T19:47:49Z', u'name': u'Shaun Verch', u'email': u'shaun.verch@10gen.com'}
Message: SERVER-939 Changed ShardFields to ShardType
Branch: master
https://github.com/mongodb/mongo/commit/6cd748eccdcea47c6413a144f921cd8ec9dfcff4","Dec 18 2012 04:41:48 PM UTC;auto;Author:{u'date': u'2012-12-01T01:08:14Z', u'name': u'Shaun Verch', u'email': u'shaun.verch@10gen.com'}
Message: SERVER-939 Changed CollectionFields to CollectionType
Branch: master
https://github.com/mongodb/mongo/commit/9c07a059fedfe534c890a59d13e0fc6536fd8ee8","Dec 18 2012 04:41:50 PM UTC;auto;Author:{u'date': u'2012-12-02T01:52:01Z', u'name': u'Shaun Verch', u'email': u'shaun.verch@10gen.com'}
Message: SERVER-939 Added type class for documents in config.mongos collection
Branch: master
https://github.com/mongodb/mongo/commit/a8b8f95cf7263f0c58c6347fb9f738b490fea5c5","Dec 18 2012 04:41:51 PM UTC;auto;Author:{u'date': u'2012-12-01T01:34:37Z', u'name': u'Shaun Verch', u'email': u'shaun.verch@10gen.com'}
Message: SERVER-939 Changed DatabaseFields to DatabaseType
Branch: master
https://github.com/mongodb/mongo/commit/99d046d0d95c748b414e42ffd37e225d4b4cb05c","Dec 18 2012 04:41:53 PM UTC;auto;Author:{u'date': u'2012-12-07T02:05:38Z', u'name': u'Shaun Verch', u'email': u'shaun.verch@10gen.com'}
Message: SERVER-939 Added type class for documents in config.settings collection
Branch: master
https://github.com/mongodb/mongo/commit/bf7614739eb869fafff8f04297b47edb1bfccc0a","Dec 18 2012 04:41:55 PM UTC;auto;Author:{u'date': u'2012-12-07T02:19:28Z', u'name': u'Shaun Verch', u'email': u'shaun.verch@10gen.com'}
Message: SERVER-939 Changed SettingsFields to SettingsType
Branch: master
https://github.com/mongodb/mongo/commit/5e91da251e332abc79749c8167b3bdc273e95a54","Dec 18 2012 04:41:57 PM UTC;auto;Author:{u'date': u'2012-12-06T01:00:12Z', u'name': u'Shaun Verch', u'email': u'shaun.verch@10gen.com'}
Message: SERVER-939 Added type class for documents in config.locks collection
Branch: master
https://github.com/mongodb/mongo/commit/fa70853dca0990371cf1fde0a9f86088aa6be4c0","Dec 18 2012 04:41:59 PM UTC;auto;Author:{u'date': u'2012-12-06T01:04:06Z', u'email': u'shaun.verch@10gen.com', u'name': u'Shaun Verch'}
Message: SERVER-939 Changed LockFields to LocksType
Branch: master
https://github.com/mongodb/mongo/commit/f2446eaa5a23641da12f8a63f34fc3183e055906","Dec 18 2012 04:42:01 PM UTC;auto;Author:{u'date': u'2012-12-06T19:52:51Z', u'name': u'Shaun Verch', u'email': u'shaun.verch@10gen.com'}
Message: SERVER-939 Added type class for documents in config.tags collection
Branch: master
https://github.com/mongodb/mongo/commit/213d731ccc2b82e53e64fe8091484649370cb9d3","Dec 18 2012 04:42:04 PM UTC;auto;Author:{u'date': u'2012-12-06T20:04:40Z', u'name': u'Shaun Verch', u'email': u'shaun.verch@10gen.com'}
Message: SERVER-939 Changed TagFields to TagsType
Branch: master
https://github.com/mongodb/mongo/commit/b22f069ac1a494baa7d40db52bdcb49e961eb4ad","Dec 18 2012 04:42:05 PM UTC;auto;Author:{u'date': u'2012-12-05T21:24:35Z', u'name': u'Shaun Verch', u'email': u'shaun.verch@10gen.com'}
Message: SERVER-939 Changed MongosFields to MongosType
Branch: master
https://github.com/mongodb/mongo/commit/b2e3587f9cad2c681a236da5702280a4295ca153","Dec 18 2012 04:42:07 PM UTC;auto;Author:{u'date': u'2012-12-06T01:25:57Z', u'name': u'Shaun Verch', u'email': u'shaun.verch@10gen.com'}
Message: SERVER-939 Added type class for documents in config.lockpings collection
Branch: master
https://github.com/mongodb/mongo/commit/bd9ae50abf96abe78226d827916e366ce5cc9e51","Dec 18 2012 04:42:09 PM UTC;auto;Author:{u'date': u'2012-12-06T01:32:04Z', u'name': u'Shaun Verch', u'email': u'shaun.verch@10gen.com'}
Message: SERVER-939 Changed LockPingFields to LockpingsType
Branch: master
https://github.com/mongodb/mongo/commit/b1845ec73b8e5fbb23f67639f3319bb010df9f0f","Dec 18 2012 04:42:10 PM UTC;auto;Author:{u'date': u'2012-12-05T22:52:52Z', u'name': u'Shaun Verch', u'email': u'shaun.verch@10gen.com'}
Message: SERVER-939 Added type class for documents in config.changelog collection
Branch: master
https://github.com/mongodb/mongo/commit/9631cda23dce21242c1032b4a4c35498b880fe58","Dec 18 2012 04:42:12 PM UTC;auto;Author:{u'date': u'2012-12-05T23:40:17Z', u'name': u'Shaun Verch', u'email': u'shaun.verch@10gen.com'}
Message: SERVER-939 Changed ChangelogFields to ChangelogType
Branch: master
https://github.com/mongodb/mongo/commit/7784598c79b6514c1ebd9fab27ecdc878ef7aea4","Dec 19 2012 07:49:13 PM UTC;auto;Author:{u'date': u'2012-12-14T20:05:24Z', u'email': u'shaun.verch@10gen.com', u'name': u'Shaun Verch'}
Message: SERVER-939 Added errMsg to parseBSON in *Type classes
Branch: master
https://github.com/mongodb/mongo/commit/d2adeeb4a74dac9f41280d42635fa60d2d58a864","Jan 17 2013 03:25:41 PM UTC;auto;Author:{u'date': u'2013-01-10T20:02:37Z', u'email': u'randolph@10gen.com', u'name': u'Randolph Tan'}
Message: SERVER-939 abilitiy to distribute collections in a single db

Port tests from d_chunk_manager_tests.cpp for metadata_loader_test.cpp
Branch: master
https://github.com/mongodb/mongo/commit/1e2283a07f07d417f7bcb600b7a8fbd0720f25bd","Jan 17 2013 03:25:43 PM UTC;auto;Author:{u'date': u'2013-01-10T20:11:30Z', u'email': u'randolph@10gen.com', u'name': u'Randolph Tan'}
Message: SERVER-939 abilitiy to distribute collections in a single db

Fix memory leak when error is encountered while creating a CollectionManager
Branch: master
https://github.com/mongodb/mongo/commit/e923e7695bc6492d383e1125f12b73ff7c5125c2","Jan 17 2013 04:11:41 PM UTC;auto;Author:{u'date': u'2012-12-19T17:26:41Z', u'email': u'shaun.verch@10gen.com', u'name': u'Shaun Verch'}
Message: SERVER-939 Added information about whether field was set to field_parser
Branch: master
https://github.com/mongodb/mongo/commit/39d2b276b6b5ed4c4671973641d3c89fb0afba3e","Jan 17 2013 04:11:43 PM UTC;auto;Author:{u'date': u'2013-01-04T19:46:14Z', u'email': u'shaun.verch@10gen.com', u'name': u'Shaun Verch'}
Message: SERVER-939 Store defaults in BSONField and handle defaults in FieldParser extract functions
Branch: master
https://github.com/mongodb/mongo/commit/e0fa2f1eea17be8faeaad2a550c82e833a3eadeb","Jan 17 2013 04:11:45 PM UTC;auto;Author:{u'date': u'2013-01-17T12:13:21Z', u'email': u'shaun.verch@10gen.com', u'name': u'Shaun Verch'}
Message: SERVER-939 Update DatabaseType with new method of recording field presence and handling defaults
Branch: master
https://github.com/mongodb/mongo/commit/20e12facef46d7d3edd98c5240559eaab57e37c7","Jan 17 2013 04:11:47 PM UTC;auto;Author:{u'date': u'2013-01-17T11:50:31Z', u'email': u'shaun.verch@10gen.com', u'name': u'Shaun Verch'}
Message: SERVER-939 Update TagsType with new method of recording field presence and handling defaults
Branch: master
https://github.com/mongodb/mongo/commit/2a12fd677b029f8cff7c12f2baf2b4acffb82def","Jan 17 2013 04:11:48 PM UTC;auto;Author:{u'date': u'2013-01-17T11:50:30Z', u'email': u'shaun.verch@10gen.com', u'name': u'Shaun Verch'}
Message: SERVER-939 Update ShardType with new method of recording field presence and handling defaults
Branch: master
https://github.com/mongodb/mongo/commit/f8d9f5d434e1898e4d14c6215e948abcf4164aeb","Jan 17 2013 04:11:51 PM UTC;auto;Author:{u'date': u'2013-01-17T11:50:30Z', u'email': u'shaun.verch@10gen.com', u'name': u'Shaun Verch'}
Message: SERVER-939 Update SettingsType with new method of recording field presence and handling defaults
Branch: master
https://github.com/mongodb/mongo/commit/a0aaf99845554ff826cc0caaba6e6b9842475c19","Jan 17 2013 04:11:53 PM UTC;auto;Author:{u'date': u'2013-01-17T11:50:30Z', u'email': u'shaun.verch@10gen.com', u'name': u'Shaun Verch'}
Message: SERVER-939 Update MongosType with new method of recording field presence and handling defaults
Branch: master
https://github.com/mongodb/mongo/commit/810aa6cb78a29b584e44d01ba417399ccc1e481a","Jan 17 2013 04:11:55 PM UTC;auto;Author:{u'date': u'2013-01-17T11:50:29Z', u'email': u'shaun.verch@10gen.com', u'name': u'Shaun Verch'}
Message: SERVER-939 Update LocksType with new method of recording field presence and handling defaults
Branch: master
https://github.com/mongodb/mongo/commit/04296d4f271aacfaaa8fc7c822e07dba76ae4a50","Jan 17 2013 04:11:57 PM UTC;auto;Author:{u'date': u'2013-01-17T11:50:29Z', u'email': u'shaun.verch@10gen.com', u'name': u'Shaun Verch'}
Message: SERVER-939 Update LockpingsType with new method of recording field presence and handling defaults
Branch: master
https://github.com/mongodb/mongo/commit/588a5937884a07c72af6e40a98cd592eedebc74e","Jan 17 2013 04:11:59 PM UTC;auto;Author:{u'date': u'2013-01-17T11:50:28Z', u'email': u'shaun.verch@10gen.com', u'name': u'Shaun Verch'}
Message: SERVER-939 Update VersionType with new method of recording field presence and handling defaults
Branch: master
https://github.com/mongodb/mongo/commit/4d4f0c4fb1708ca5ab95d6efc334e185459c2621","Jan 17 2013 04:12:01 PM UTC;auto;Author:{u'date': u'2013-01-17T11:50:28Z', u'email': u'shaun.verch@10gen.com', u'name': u'Shaun Verch'}
Message: SERVER-939 Update CollectionType with new method of recording field presence and handling defaults
Branch: master
https://github.com/mongodb/mongo/commit/72c63c5853fb5e130c3311192ebaf9046a5db4cb","Jan 17 2013 04:12:03 PM UTC;auto;Author:{u'date': u'2013-01-17T11:50:28Z', u'email': u'shaun.verch@10gen.com', u'name': u'Shaun Verch'}
Message: SERVER-939 Update ChunkType with new method of recording field presence and handling defaults
Branch: master
https://github.com/mongodb/mongo/commit/19be6832a2e64bede6c6120c8933e4a97caf9312","Jan 17 2013 04:12:05 PM UTC;auto;Author:{u'date': u'2013-01-17T11:50:27Z', u'email': u'shaun.verch@10gen.com', u'name': u'Shaun Verch'}
Message: SERVER-939 Update ChangelogType with new method of recording field presence and handling defaults
Branch: master
https://github.com/mongodb/mongo/commit/058b24ef9aae96edfc9d70f7d9cedf284f3d8bb5","Jan 17 2013 05:10:25 PM UTC;auto;Author:{u'date': u'2013-01-17T17:04:05Z', u'email': u'shaun.verch@10gen.com', u'name': u'Shaun Verch'}
Message: SERVER-939 Added defaults to fields to fix field_parser test
Branch: master
https://github.com/mongodb/mongo/commit/5205372fbe4eddc3296c2c155ea0699b661a10e8","Jan 18 2013 11:41:38 PM UTC;auto;Author:{u'date': u'2013-01-18T22:46:27Z', u'email': u'randolph@10gen.com', u'name': u'Randolph Tan'}
Message: SERVER-939 abilitiy to distribute collections in a single db

Fixed test failure due to uninitialized flag in the mock cursor.
Branch: master
https://github.com/mongodb/mongo/commit/3dfc22e239d7455608a2ad2bc1197eac78550a23","Jan 22 2013 06:49:13 PM UTC;auto;Author:{u'date': u'2013-01-22T17:23:50Z', u'email': u'shaun.verch@10gen.com', u'name': u'Shaun Verch'}
Message: SERVER-939 Made is*Set methods const
Branch: master
https://github.com/mongodb/mongo/commit/aa8e450455f538d3fd631b0b19f4cfba2ddde4ae","Jan 22 2013 06:49:15 PM UTC;auto;Author:{u'date': u'2013-01-22T17:26:31Z', u'email': u'shaun.verch@10gen.com', u'name': u'Shaun Verch'}
Message: SERVER-939 Change FIELD_VALID to FIELD_SET
Branch: master
https://github.com/mongodb/mongo/commit/f9b9bb1f42814b7aa487d1c589cbee3bbde9ed3b","Jan 22 2013 06:49:17 PM UTC;auto;Author:{u'date': u'2013-01-22T17:33:03Z', u'email': u'shaun.verch@10gen.com', u'name': u'Shaun Verch'}
Message: SERVER-939 Made source argument of parseBSON const ref
Branch: master
https://github.com/mongodb/mongo/commit/24b35b78bc6f7b7e964edfa2ae96813a39aac4f7","Jan 22 2013 06:49:19 PM UTC;auto;Author:{u'date': u'2013-01-22T18:36:24Z', u'name': u'Shaun Verch', u'email': u'shaun.verch@10gen.com'}
Message: SERVER-939 Removed unused default parameter from extract function
Branch: master
https://github.com/mongodb/mongo/commit/439ce8c8911e33ec47fd1bec9bb6289baf3edfc0","Feb 08 2013 10:34:40 PM UTC;auto;Author:{u'date': u'2013-01-29T16:08:11Z', u'email': u'randolph@10gen.com', u'name': u'Randolph Tan'}
Message: SERVER-939 abilitiy to distribute collections in a single db

Port tests from d_chunk_manager_tests.cpp for collection_manager_test.cpp
Branch: master
https://github.com/mongodb/mongo/commit/d305bf71dd0c49909c7c59eb3d8c282f9d966128","Nov 09 2014 07:41:44 AM UTC;crazyzh1984;Because documents has size limit of 4MB, so we use collections to aggregate records.
For example：There is a blog cloud(SAAS),
we create a collection of mongodb dynamiclly for each author, to store their own blog posts privately.
we may create millions of collections, and we wish to shard on collections level.
As each author has limited number of posts, so all the data of a collection will shard into one single server.

We wish to shard on collections dynamically, a use case: 
collections with name ends with 'A' will go to shard1,
collections with name ends with 'B' will go to shard2,
etc

We really expect this feature. 
thks","Nov 09 2014 05:06:01 PM UTC;asya;[~crazyzh1984] first of all, document size limit is 16MB and not 4MB.

And you can already distribute collections across shards via tag aware sharding - I have a write-up with some examples here:

http://askasya.com/post/taggedcollectionbalancing

In addition you can store all blog posts in a single collection, just identifying it with a specific author and then shard the collection by author.
"
add ability to bind idl generated server parameters to names with linkage,SERVER-40141,717119,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-server-servicearch,jason.carey,jason.carey,Mar 14 2019 09:17:47 PM UTC,Nov 19 2019 10:54:36 PM UTC,Feb 17 2021 11:15:24 AM UTC,,,,,,Backlog,Internal Code,,,,0,,,,,,"Currently idl generated server parameters (the typed params) are generated and never bound with type information into the larger problem (they're exposed through the central registry, but after being type erased).

If instead they could be bound to named types, it would be possible to access them outside of their immediate TU, which would allow for patterns like registering listeners, optionally, from other contexts.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,1.0,1.0,,,,,,,,,,,,,,,,Fully Compatible,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2019-03-18 19:06:06.0,39312000,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,jason.carey(jason.carey),Tue Nov 19 22:21:05 UTC 2019,,,,,,,,,,,,,,backlog-server-servicearch(backlog-server-servicearch),jason.carey(jason.carey),kelly.lewis(kelly.lewis),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i39tlr:",,,,,,,"0|i3cqg7:",9223372036854775807,,,,,,,,,,,,Security 2019-04-08,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i39rpj:","Nov 19 2019 10:21:05 PM UTC;kelly.lewis;Hi [~sara.golemon] and [~jason.carey], if this is on the backlog, can we move it from 'Investigating' to 'Open'?",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Support for serially using multiple connections in steady state replication,SERVER-42943,901809,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-server-servicearch,jason.carey,jason.carey,Aug 20 2019 10:39:21 PM UTC,Nov 18 2019 05:24:55 PM UTC,Feb 17 2021 11:15:24 AM UTC,,,,,,features we're not sure of,Networking,Replication,,,0,,,,,,"Using a single persistent connection for steady state replication could be a problem if the volume of traffic is very high and the socket used is transiting a WAN with limited bandwidth (that's also used for other critical traffic).

Providing an option which forced some kind of round robin-ing, or even just dropping the connection occasionally, would ensure that we balance that traffic across unique 5 tuples, which would ensure we don't oversubscribed any one particular path.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,47174400,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,lingzhi.deng(lingzhi.deng),2019-08-20 22:39:21.0,,,,,,,,,,,,,,backlog-server-servicearch(backlog-server-servicearch),jason.carey(jason.carey),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i4518f:",,,,,,,"0|i470i7:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i44zc7:",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Add server status metric for average parallelism per oplog application batch,SERVER-43318,926141,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-server-repl,judah.schvimer,judah.schvimer,Sep 13 2019 02:24:06 PM UTC,Nov 01 2019 08:34:19 PM UTC,Feb 17 2021 11:15:24 AM UTC,,,,,,Backlog,Diagnostics,Replication,,,0,former-quick-wins,,,,,"This is split off from SERVER-34722 so it can be done after the Oplog Application Tech Debt project. [~bruce.lucas] in that ticket defined this as ""Average parallelism for each batch, updated at end of each batch, could be useful: sum of times spent by individual worker threads applying ops divided by total time for batch.""",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2019-09-20 14:31:18.0,45100800,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,steven.vannelli(steven.vannelli),Fri Sep 13 14:25:17 UTC 2019,,,,,,,,,,,,,,backlog-server-repl(backlog-server-repl),judah.schvimer(judah.schvimer),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i496mf:",,,,,,,"0|i2khkf:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i494q7:","Sep 13 2019 02:25:17 PM UTC;judah.schvimer;[~alyson.cabral], [~sheeri.cabral], [~kelsey.schubert], and [~bruce.lucas] how useful do you think this metric would be?",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Full consensus arbiter (i.e. uses an oplog),SERVER-14539,146793,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-server-repl,charlie.page@10gen.com,charlie.page@10gen.com,Jul 12 2014 03:11:16 PM UTC,Sep 20 2019 06:30:18 PM UTC,Feb 17 2021 11:15:24 AM UTC,,,,,,Backlog,Replication,,,,5,,,,,,"Allow arbiters to fully participate in consensus with an oplog (like view stamped replication).  {{--ArbiterWithOplog=<size in mb of oplog>}}

This would mean that w:majority including arbiters works as expected; No rollbacks assuming no one falls off the oplog.  Doing so would prevent rollbacks with network flapping and the use of an arbiter.

This would also mean that a primary may not be elected with a majority up until one of the data bearing nodes has replicated the oplog of the arbiter.

Let's say your replica set configuration calls for N data bearing nodes and M arbiters.

Consider the case where M and N are both positive. If exactly ceil(N/2) data nodes go offline but no arbiters do, you'll still have
a primary, but no w:majority writes can be acknowledged. Therefore, any write into a replica set in such a degraded state is subject to eventual rollback.

Observe that the common, minimally expensive mode of operation for replica sets is the above with N=2 and M=1. If either data node is offline, no writes are rollback-proof (though, barring a second failure, none of them will get rolled back). Further, no write concern stronger than w=1 will be confirmed to the application.

At present, all replica sets with greater than zero arbiters will have such pathological modes of operation around sufficiently many data node failures.

This leaves the operator with 3 choices in a 3 node set with an arbiter (these are the same choices in a larger set just easier to describe with a concrete example):
1)w:1 and accept rollbacks (i.e. silently lose data, it is currently possible to loss an arbitrary amount of data via multiple rollbacks)
2)w:2 and accept the system goes down with a single node
3)Monitor rs.status and dynamically change write concern before every write to try and get the best of both worlds

This would create choice 4:
4)w:2 and know that all committed writes won't be rolled back and that loss of a single node won't take down the set (limited by oplog time but it can be given a week).

For completeness, the 3 choices in a replica set for write concern that can be mapped to larger replicas:
w:1, less than majority.
w:2, majority.
w:3, greater than majority.",,,,,,,,PM-252,,,,CS-11301,SERVER-20820,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,5002K00000g3woUQAQ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2014-07-13 04:02:49.0,150595200,<s><a href='https://jira.mongodb.org/browse/PM-252'>PM-252</a></s>,,,,,,,,,,,,,,,,,,,,,,,,,,,true,ratika.gandhi(ratika.gandhi),Tue May 10 13:19:25 UTC 2016,,,,,,,,,,,,,,backlog-server-repl(backlog-server-repl),charlie.page@10gen.com(charlie.page@10gen.com),jason.coombs@yougov.com(jason.coombs@yougov.com),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i03gzz:",,,,,,,"0|i0btfj:",127084,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i03pvb:","May 10 2016 01:19:25 PM UTC;jason.coombs@yougov.com;This feature would also serve another purpose - to allow the creation of nodes with unusually large oplogs for the purposes of initializing new replicas where the current oplog size on members of the set is too small and is overrun before a new member can be synced. Such a feature would save us dozens of hours every year and make our replica sets so much easier to manage.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Allow Change streams in standalone servers,SERVER-35855,564957,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-server-repl,julien_c,julien_c,Jun 28 2018 02:14:03 AM UTC,Sep 18 2019 10:54:32 PM UTC,Feb 17 2021 11:15:24 AM UTC,,,,,,Backlog,Aggregation Framework,Replication,,,1,,,,,,"I understand the technical reason behind Change streams not currently being implemented for standalone servers, but I think you should implement this sooner rather than later.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,8.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2018-06-28 05:00:03.0,44668800,,,,,,,,PM-1194,,,,,,,,,,,,,,,,,,,,true,mitar(mitar),Wed Sep 18 22:54:32 UTC 2019,,,,,,,,,,,,,,asya(asya),backlog-server-repl(backlog-server-repl),charlie.swanson(charlie.swanson),danielfaust(danielfaust),julien_c(julien_c),mitar(mitar),tess.avitabile(tess.avitabile),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i2jxmf:",,,,,,,"0|i2ol6v:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i2jvq7:","Jun 28 2018 02:52:10 PM UTC;charlie.swanson;[~julien_c] we can't produce change streams on a standalone server because a standalone server does not have an oplog. As a workaround, you can turn your standalone server into a single-node replica set. This will create an oplog and allow us to provide a change stream, without requiring more than one server. Have you considered that?","Jun 28 2018 03:02:59 PM UTC;julien_c;Yes, we have considered that, but it makes setting up development environments significantly more complex (as opposed to `brew install mongodb` right now). Our devs aren't MongoDB specialists, and the feature we wanted to use change streams for is not central, so we will probably keep using an inferior polling-based system for now.","Jul 10 2018 06:13:29 PM UTC;tess.avitabile;[~greg.mckeon], can you please create the standalones with oplog epic and add this ticket?","Nov 14 2018 05:38:07 PM UTC;danielfaust;I erroneously opened a duplicate issue of this one here: https://jira.mongodb.org/browse/SERVER-38079

The following was my line of reasoning in that issue: ""_The issue is that in the case of a small database, for example a 20 MB database storing the current status of devices in a local area network, like environment sensors, it is not feasible to enable replication if it is not required for the data, because that would force the creation of a 1 GB oplog._""","Feb 08 2019 01:12:44 PM UTC;danielfaust;Hi, is there any development regarding this issue?","Feb 12 2019 06:26:23 AM UTC;asya;[~danielfaust] what is the obstacle to creating a single node replica with a 20MB oplog (or however small you want it to be)?
","Mar 04 2019 06:50:36 AM UTC;danielfaust;@Asya Kamsky you're right, my mistake. Thanks a lot for the heads-up.","Sep 18 2019 10:54:32 PM UTC;mitar;This would be useful because it can make it easier to quickly turn on MongoDB and has this change streams available. For testing/CI this is useful, or for simple tutorials. Explaining that you have to do the whole replica setup first is trickier.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Create oplog entry applier registry,SERVER-43117,914438,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-server-repl,jesse,jesse,Aug 31 2019 02:32:19 PM UTC,Sep 09 2019 05:29:04 PM UTC,Feb 17 2021 11:15:24 AM UTC,,,,,,Backlog,Replication,,,,0,,,,,,"This idea is originally from [~siyuan.zhou] as part of the Address tech debt in oplog application code path project.

The logic to apply command oplog entries is all in oplog.cpp. The command-appliers are implemented as lambdas, which are defined inline in a single 400-line statement that initializes a map called kOpsMap. The logic that applies insert, update, and delete oplog entries is implemented separately in a single 400-line function.

Having all the applier logic in oplog.cpp couples this file with many other subsystems, such as DDL and transactions. Thus the file must include headers from all over the codebase, and the file must be linked with 18 library dependencies.

Solution: Make an OpApplier interface. Each subsystem implements OpApplier subclasses for the commands it can apply. Create an OpApplierRegistry (similar to CommandRegistry) where subsystems can register command appliers during startup. This will minimize oplog.cpp's includes and link dependencies. Remove unnecessary headers by guesswork and trial and error. If the [Libdeps Linter project|https://jira.mongodb.org/browse/PM-1112] is ready, use it to remove link dependencies, otherwise we must remove link dependencies by guesswork too.

Consider implementing insert, update, and delete ops with the same OpApplier interface as commands. Note that, for performance reasons, there is special logic for ""grouped inserts"" (in InsertGroup), which should remain special.

Note from Andrew Morrow: ""Avoid doing implicit self-registration of types by creating static instances of the class, like the Command registry does. Doing so creates libraries that don't satisfy symbol references, but silently break things if they drop out of the graph. It makes it much harder to manipulate the library dependency graph.""

In other words, let's not continue to use the sort of pattern we see in replication_info.cpp, for example:
{noformat}
class CmdIsMaster : public CommandBase {
 ...
 } cmdIsMaster;
{noformat}
That source file isn't required to satisfy any symbol references: If you forget to link to that file, you won't get a linker error about an undefined symbol. However, mongod won't work, because the singleton instance ""cmdIsMaster"" must be constructed in order to add itself to the command registry.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2019-09-09 17:29:04.0,45446400,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,ratika.gandhi(ratika.gandhi),Mon Sep 09 17:29:04 UTC 2019,,,,,,,,,,,,,,jesse(jesse),backlog-server-repl(backlog-server-repl),ratika.gandhi(ratika.gandhi),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i476nb:",,,,,,,"0|i472gf:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i474r3:","Aug 31 2019 02:34:31 PM UTC;jesse;Andy Schwerin's advice about the registry:

You want to use ServiceContext::ConstructorActionRegisterer ([https://github.com/mongodb/mongo/blob/master/src/mongo/db/service_context.h#L250|https://www.google.com/url?q=https://github.com/mongodb/mongo/blob/master/src/mongo/db/service_context.h%23L250&sa=D&ust=1567264903276000&usg=AFQjCNEYYAN2SqCAX4ly1fbYfBeLiueKRw]).

Used here with ""prerequisites"", which is helpful when you need to control order of initialization: [https://github.com/mongodb/mongo/blob/master/src/mongo/db/auth/sasl_mechanism_registry.cpp#L148-L152|https://www.google.com/url?q=https://github.com/mongodb/mongo/blob/master/src/mongo/db/auth/sasl_mechanism_registry.cpp%23L148-L152&sa=D&ust=1567264903276000&usg=AFQjCNHGdK7eLLnZr3lXnGqckmhVC2QiNA]

In general, you want to attach state to ServiceContext rather than make it global, and if you attach it to ServiceContext, you want to initialize it with ConstructorActions. It's still grosser than I want, but has some useful properties compared to MONGO_INITIALIZERS.

(1) They run when you construct and destroy the ServiceContext, and have access to the ServiceContext.

(2) You're allowed to start and stop threads in them, because they run after the MONGO_INITIALIZERS have finished.","Sep 09 2019 05:29:04 PM UTC;ratika.gandhi;This will require a Design document. It is more than a quick win so will likely need its open epic. Will revisit during quarterly planning.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Deal better/Fail more gracefully when mongoD runs out of disk space,SERVER-13811,134473,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,brian.lane,osmar.olivo,osmar.olivo,May 01 2014 09:21:19 PM UTC,Sep 02 2019 12:56:07 AM UTC,Feb 17 2021 11:15:24 AM UTC,,,,,,Backlog,Stability,Storage,,,8,,,,,,"Currently when a mongoD process runs out of disk space and fails to preallocate a file or write to the journal, it responds with terminating the server process. 

This proves to be a difficult place to be in because the remove operation in and of itself will fail when attempting to reclaim space. Furthermore, things that write to disk temporarily like external sort or temporary agg results will also have problems with this.

A more graceful approach would be to allow us to limit mongoD space utilization to some threshold before filling the disk, so that cleanup and stabilization of the system is facilitated.

Something like ""Stop accepting writes (other than removes) if less than 10% (or some number of GB) disk space available"" or ""If preallocation fails due to lack of space (2GB) for the final datafile, stop accepting writes aside from removes"" would be much more graceful.  This would of course mean $out and external sorts should fail as well. but would save from dealing with all the other issues associated with full disk.

Of course there are edge cases to be considered such as, if a secondary hits this threshold, it can no longer replicate therefore it should be marked as down or unavailable with respect to the quorum.  (Which I believe already happens ) but then how do we process cleanup if it can't replicate the removes? We'll just have to increase capacity or do a full resync in situations where a secondary runs out of disk before a primary. 

But for the general case, this would be a huge win, whether the number is configurable or not. 

",,,,,,,,,,,,CS-15848,CS-16480,CAP-2045,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,500A000000UaYjOIAV,500A000000UaYlSIAV,500A000000Zqmd5IAB,500A000000aNg76IAC,500A000000bz9UNIAY,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2015-04-01 19:52:38.0,75686400,,,,,,,,,,,,,,,,,,,,,,,,,,,,false,brian.lane(brian.lane),Mon Sep 24 23:00:52 UTC 2018,,,,,,,,No,,,,,,brian.lane(brian.lane),geert.bosch(geert.bosch),kjmd75(kjmd75),osmar.olivo(osmar.olivo@10gen.com),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i03kvr:",,,,,,,"0|i03hof:",115594,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i0z37b:","Dec 01 2015 05:51:44 PM UTC;geert.bosch;Example backtrace of running out of diskspace with WiredTiger as storage engine.
{noformat}
 WT_CURSOR.insert: index-29--7668984530888323570.wt write error: failed to write 8192 bytes at offset 7509319680: No space left on device
2015-12-01T01:48:40.653-0500 I -        [conn26] Fatal Assertion 28559
2015-12-01T01:48:40.653-0500 I -        [conn26]

***aborting after fassert() failure


2015-12-01T01:48:40.660-0500 F -        [conn30] Got signal: 6 (Aborted).

 0x12ea5c2 0x12e9719 0x12e9f32 0x7f89fc998340 0x7f89fc5f6bb9 0x7f89fc5f9fc8 0x1274c92 0x1072ef5 0x106d42c 0x1069b1c 0x10527d0 0xc8982f 0xae1549 0xae57df 0xae5880 0xac51f5 0xac5501 0xca3fb8 0xca4369 0xca4454 0xca99f6 0xcabf25 0x9966cc 0x1298145 0x7f89fc990182 0x7f89fc6bafbd
----- BEGIN BACKTRACE -----
{""backtrace"":[{""b"":""400000"",""o"":""EEA5C2""},{""b"":""400000"",""o"":""EE9719""},{""b"":""400000"",""o"":""EE9F32""},{""b"":""7F89FC988000"",""o"":""10340""},{""b"":""7F89FC5C0000"",""o"":""36BB9""},{""b"":""7F89FC5C0000"",""o"":""39FC8""},{""b"":""400000"",""o"":""E74C92""},{""b"":""400000"",""o"":""C72EF5""},{""b"":""400000"",""o"":""C6D42C""},{""b"":""400000"",""o"":""C69B1C""},{""b"":""400000"",""o"":""C527D0""},{""b"":""400000"",""o"":""88982F""},{""b"":""400000"",""o"":""6E1549""},{""b"":""400000"",""o"":""6E57DF""},{""b"":""400000"",""o"":""6E5880""},{""b"":""400000"",""o"":""6C51F5""},{""b"":""400000"",""o"":""6C5501""},{""b"":""400000"",""o"":""8A3FB8""},{""b"":""400000"",""o"":""8A4369""},{""b"":""400000"",""o"":""8A4454""},{""b"":""400000"",""o"":""8A99F6""},{""b"":""400000"",""o"":""8ABF25""},{""b"":""400000"",""o"":""5966CC""},{""b"":""400000"",""o"":""E98145""},{""b"":""7F89FC988000"",""o"":""8182""},{""b"":""7F89FC5C0000"",""o"":""FAFBD""}],""processInfo"":{ ""mongodbVersion"" : ""3.2.0-rc4-16-g764f8a3"", ""gitVersion"" : ""764f8a33034392758d033f449d480121d3bb32e1"", ""compiledModules"" : [], ""uname"" : { ""sysname"" : ""Linux"", ""release"" : ""3.13.0-39-generic"", ""version"" : ""#66-Ubuntu SMP Tue Oct 28 13:30:27 UTC 2014"", ""machine"" : ""x86_64"" }, ""somap"" : [ { ""elfType"" : 2, ""b"" : ""400000"", ""buildId"" : ""FE28A46DBAB02AE578EDCCF59C9B4A9C75243BC7"" }, { ""b"" : ""7FFF99CE0000"", ""elfType"" : 3, ""buildId"" : ""0074678E5FFFF79F46C476077E67057161772F37"" }, { ""b"" : ""7F89FDBC8000"", ""path"" : ""/lib/x86_64-linux-gnu/libssl.so.1.0.0"", ""elfType"" : 3, ""buildId"" : ""24273411CD5FDB1E42F868F4E53513A26C404DBB"" }, { ""b"" : ""7F89FD7E8000"", ""path"" : ""/lib/x86_64-linux-gnu/libcrypto.so.1.0.0"", ""elfType"" : 3, ""buildId"" : ""98690042D55F842BD5D326A2A7234CB59FFEE78D"" }, { ""b"" : ""7F89FD5E0000"", ""path"" : ""/lib/x86_64-linux-gnu/librt.so.1"", ""elfType"" : 3, ""buildId"" : ""92FCF41EFE012D6186E31A59AD05BDBB487769AB"" }, { ""b"" : ""7F89FD3D8000"", ""path"" : ""/lib/x86_64-linux-gnu/libdl.so.2"", ""elfType"" : 3, ""buildId"" : ""C1AE4CB7195D337A77A3C689051DABAA3980CA0C"" }, { ""b"" : ""7F89FD0C8000"", ""path"" : ""/usr/local/lib64/libstdc++.so.6"", ""elfType"" : 3 }, { ""b"" : ""7F89FCDC0000"", ""path"" : ""/lib/x86_64-linux-gnu/libm.so.6"", ""elfType"" : 3, ""buildId"" : ""574C6350381DA194C00FF555E0C1784618C05569"" }, { ""b"" : ""7F89FCBA8000"", ""path"" : ""/usr/local/lib64/libgcc_s.so.1"", ""elfType"" : 3 }, { ""b"" : ""7F89FC988000"", ""path"" : ""/lib/x86_64-linux-gnu/libpthread.so.0"", ""elfType"" : 3, ""buildId"" : ""FE662C4D7B14EE804E0C1902FB55218A106BC5CB"" }, { ""b"" : ""7F89FC5C0000"", ""path"" : ""/lib/x86_64-linux-gnu/libc.so.6"", ""elfType"" : 3, ""buildId"" : ""B515361E474796AF29DE9992B76A97CFFB39B2A7"" }, { ""b"" : ""7F89FDE28000"", ""path"" : ""/lib64/ld-linux-x86-64.so.2"", ""elfType"" : 3, ""buildId"" : ""9F00581AB3C73E3AEA35995A0C50D24D59A01D47"" } ] }}
 mongod(_ZN5mongo15printStackTraceERSo+0x32) [0x12ea5c2]
 mongod(+0xEE9719) [0x12e9719]
 mongod(+0xEE9F32) [0x12e9f32]
 libpthread.so.0(+0x10340) [0x7f89fc998340]
 libc.so.6(gsignal+0x39) [0x7f89fc5f6bb9]
 libc.so.6(abort+0x148) [0x7f89fc5f9fc8]
 mongod(_ZN5mongo13fassertFailedEi+0x82) [0x1274c92]
 mongod(_ZN5mongo17wtRCToStatus_slowEiPKc+0x365) [0x1072ef5]
 mongod(_ZN5mongo17WiredTigerSession13releaseCursorEmP11__wt_cursor+0x12C) [0x106d42c]
 mongod(_ZN5mongo16WiredTigerCursorD1Ev+0x1C) [0x1069b1c]
 mongod(_ZN5mongo15WiredTigerIndex6insertEPNS_16OperationContextERKNS_7BSONObjERKNS_8RecordIdEb+0xD0) [0x10527d0]
 mongod(_ZN5mongo17IndexAccessMethod6insertEPNS_16OperationContextERKNS_7BSONObjERKNS_8RecordIdERKNS_19InsertDeleteOptionsEPl+0x18F) [0xc8982f]
 mongod(_ZN5mongo12IndexCatalog21_indexFilteredRecordsEPNS_16OperationContextEPNS_17IndexCatalogEntryERKSt6vectorINS_10BsonRecordESaIS6_EE+0x109) [0xae1549]
 mongod(_ZN5mongo12IndexCatalog13_indexRecordsEPNS_16OperationContextEPNS_17IndexCatalogEntryERKSt6vectorINS_10BsonRecordESaIS6_EE+0x11F) [0xae57df]
 mongod(_ZN5mongo12IndexCatalog12indexRecordsEPNS_16OperationContextERKSt6vectorINS_10BsonRecordESaIS4_EE+0x80) [0xae5880]
 mongod(_ZN5mongo10Collection16_insertDocumentsEPNS_16OperationContextEN9__gnu_cxx17__normal_iteratorIPKNS_7BSONObjESt6vectorIS5_SaIS5_EEEESB_b+0x325) [0xac51f5]
 mongod(_ZN5mongo10Collection15insertDocumentsEPNS_16OperationContextEN9__gnu_cxx17__normal_iteratorIPKNS_7BSONObjESt6vectorIS5_SaIS5_EEEESB_bb+0x1B1) [0xac5501]
 mongod(_ZN5mongo17insertMultiVectorEPNS_16OperationContextERNS_16OldClientContextEbPKcRNS_5CurOpEN9__gnu_cxx17__normal_iteratorIPNS_7BSONObjESt6vectorISA_SaISA_EEEESF_+0x138) [0xca3fb8]
 mongod(_ZN5mongo11insertMultiEPNS_16OperationContextERNS_16OldClientContextEbPKcRSt6vectorINS_7BSONObjESaIS7_EERNS_5CurOpE+0xF9) [0xca4369]
 mongod(_ZN5mongo15_receivedInsertEPNS_16OperationContextERKNS_15NamespaceStringEPKcRSt6vectorINS_7BSONObjESaIS8_EEbRNS_5CurOpEb+0xD4) [0xca4454]
 mongod(_ZN5mongo14receivedInsertEPNS_16OperationContextERKNS_15NamespaceStringERNS_7MessageERNS_5CurOpE+0x376) [0xca99f6]
 mongod(_ZN5mongo16assembleResponseEPNS_16OperationContextERNS_7MessageERNS_10DbResponseERKNS_11HostAndPortE+0x11C5) [0xcabf25]
 mongod(_ZN5mongo16MyMessageHandler7processERNS_7MessageEPNS_21AbstractMessagingPortE+0xEC) [0x9966cc]
 mongod(_ZN5mongo17PortMessageServer17handleIncomingMsgEPv+0x285) [0x1298145]
 libpthread.so.0(+0x8182) [0x7f89fc990182]
 libc.so.6(clone+0x6D) [0x7f89fc6bafbd]
-----  END BACKTRACE  -----
Aborted (core dumped)
{noformat}","Sep 24 2018 11:00:52 PM UTC;kjmd75;I agree with this.  The system shouldn't stop working if you run out of space.  Write should obviously fail, but reads and deletes should still be accepted.  Causing an outage when one isn't necessary is bad design.  Think of how Oracle has their archiver error when disk fills up, it still allows read and delete operations, but insert/updates will fail.  ",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Use four part version in MSI to allow MSI patching,SERVER-15672,163816,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-server-build,ernie.hershey,ernie.hershey,Oct 15 2014 07:09:43 PM UTC,Sep 01 2019 03:36:38 AM UTC,Feb 17 2021 11:15:24 AM UTC,,2.6.5,2.7.7,,,4.1 Desired,Build,Packaging,,,0,build-later,,,,,"Our MSI version should include a 4th component which is 0 by default (2.6.5.0, for example), and can be used to release new MSI's as upgrades to previous MSI's without doing an entire new server release.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,200102400,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,dbeng-pm-bot(dbeng-pm-bot),2014-10-15 19:09:43.0,,,,,,,,,,,,,,backlog-server-build(backlog-server-build),ernie.hershey(ernie.hershey@10gen.com),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i03atb:",,,,,,,"0|i02ua7:",142873,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i0yppb:",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Change Windows installer to add mongo binaries to the PATH,SERVER-15682,163945,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-server-build,jianfa.tang,jianfa.tang,Oct 16 2014 01:34:39 PM UTC,Sep 01 2019 03:36:19 AM UTC,Feb 17 2021 11:15:24 AM UTC,,,,,,4.1 Desired,Packaging,,,,2,build-later,,,,,"1) Download and install MongoDB for windows 64bits(or 32bits)
2) Open a DOS window
3) Type ""mongo""

Expected:

    Mongo shell should run and error out(no mongod)

Actual:

    mongo is not an internal or external command, ...

The problem is the mongodb install's bin directory is not added to the %PATH% environment variable. ",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2014-10-16 15:12:43.0,200016000,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,dbeng-pm-bot(dbeng-pm-bot),2014-10-16 13:34:39.0,,,,,,,,,,,,,,backlog-server-build(backlog-server-build),jianfa.tang(jianfa.tang),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i03arr:",,,,,,,"0|i02u6n:",143021,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i0ypnr:",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Clear the 'jumbo' flag from the chunk document when the chunk is no longer over-sized,SERVER-13024,117363,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-server-sharding,william.zola@10gen.com,william.zola@10gen.com,Mar 04 2014 04:10:13 PM UTC,Aug 30 2019 02:39:37 PM UTC,Feb 17 2021 11:15:24 AM UTC,,,,,,Backlog,Sharding,,,,2,,,,,,"Currently, if the balancer goes to split a chunk and cannot, the chunk gets marked as 'jumbo', which will prevent the balancer from migrating that chunk and from trying to split it again.

If in the future, documents are deleted from that shard key range or the cluster's {{chunksize}} setting changes, the chunk itself may no longer be 'jumbo', but MongoDB will not clear the 'jumbo' flag from that chunk.  

If you have a system where documents are short-lived (say, one week) and are then removed from the system, this will result in a system with a large number of chunks that are incorrectly marked 'jumbo'.  In addition, the number of 'jumbo' chunks will grow over time.
",,,,,,,,,,,,SERVER-11629,CS-10578,SERVER-14121,DOCS-4163,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2018-07-27 16:34:54.0,80784000,,,,,,,,PM-631,,,,,,,,,,,,,,,,,,,,true,ratika.gandhi(ratika.gandhi),Fri Jul 27 16:34:54 UTC 2018,,,,,,,,No,,,,,,backlog-server-sharding(backlog-server-sharding),kaloian.manassiev(kaloian.manassiev),william.zola@10gen.com(william.zola@10gen.com),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i03p3j:",,,,,,,"0|i0bxev:",5066,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i0h3en:","Jul 27 2018 04:34:54 PM UTC;kaloian.manassiev;One thing that should also be noted is that since the balancer utilizes the catalog cache to get the jumbo status of chunks, it is not sufficient to just unset the jumbo field on the chunk, because due to incremental refresh these changes will not be seen in the balancer's cache.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Allow configuration of timeouts for getMores on oplog for replication,SERVER-38973,671837,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-server-repl,dharshanr@scalegrid.net,dharshanr@scalegrid.net,Jan 14 2019 07:25:46 AM UTC,Aug 05 2019 05:30:53 PM UTC,Feb 17 2021 11:15:24 AM UTC,,3.4.16,,,,Backlog,Replication,,,,0,,,,,,"We are running into issues with oplog timeout.

 

2019-01-14T07:05:11.295+0000 I REPL [replication-175] Restarting oplog query due to error: ExceededTimeLimit: Operation timed out, request was RemoteCommand 1472496 – target:<xxx>:27017 db:local expDate:2019-01-14T07:05:11.295+0000 cmd:{ getMore: 16260654145, collection: ""oplog.rs"", maxTimeMS: 5000, term: 37, lastKnownCommittedOpTime:`

{ ts: Timestamp 1 547154618000|17, t: 37 }

}. Last fetched optime (with hash): \{ ts: Timestamp 1547364761000|168, t: 37 }[-6073438480613680634]. Restarts remaining: 3

 

As per instructions in text https://jira.mongodb.org/browse/SERVER-19605 we have set 

setParameter:
 oplogInitialFindMaxSeconds: 600

 

Is there a separate timeout for the oplog getMore command that is not documented?

 ",,,,,,,,PM-1232,,,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2019-01-14 21:26:19.0,65923200,<s><a href='https://jira.mongodb.org/browse/PM-1232'>PM-1232</a></s>,,,,,,,,,,,,,,,,,,,,,,,,,,,true,ratika.gandhi(ratika.gandhi),Wed Jan 16 00:40:57 UTC 2019,,,,,,,,,,,,,,backlog-server-repl(backlog-server-repl),dharshanr@scalegrid.net(dharshanr@scalegrid.net),eric.sedor(eric.sedor),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i324j3:",,,,,,,"0|i35gm7:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i322mv:","Jan 15 2019 06:24:19 PM UTC;eric.sedor;Hello,

We can confirm that SERVER-19605 is for the initial find only and not additional getMores. We can consider this a feature request.

That said, because of the implications of changing behavior around oplog getMore timeouts, we would generally recommend you consider the health of the deployment using guidance from [mongodb-user group|https://groups.google.com/group/mongodb-user] or [Stack Overflow with the mongodb tag|https://stackoverflow.com/questions/tagged/mongodb]. It sounds like if this timeout needs to be changed there could be serious issues with the deployment that aren't caused by oplog getMores specifically.

Does this make sense?","Jan 16 2019 12:40:57 AM UTC;dharshanr@scalegrid.net;Hi Eric,

I think its better to have the timeouts configurable instead of hardcoded - I dont see this as a broken replica. We have a replica in China in one of our scenarios and we repeatedly hit this issue. ",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
User management commands should ensure the created user is usable,SERVER-39161,676909,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-server-security,joe.caswell,joe.caswell,Jan 23 2019 08:39:56 PM UTC,Jul 25 2019 06:58:01 PM UTC,Feb 17 2021 11:15:24 AM UTC,,,,,,Backlog,Admin,,,,0,,,,,,"If the role graph produced by usersInfo with the showPrivileges option exceeds the BSON document size limit, an exception is thrown.  

Since usersInfo is used in the authentication process, this prevents the user from authenticating. 

Currently the user and role management commands do not validate that the modifications made actually result is usable users.  The worst case scenario is a userAdmin could lock themselves out.

There should be some manner of warning or error when this occurs.

",,,,,,,,,,,,HELP-8670,PRODUCT-960,,,,,,,,,,,,,,,,"Jan 24 2019 11:07:11 PM UTC;joe.caswell;bigusertest.js;https://jira.mongodb.org/secure/attachment/207147/bigusertest.js",,,0.0,,,,,,,,,,,,,,,,,,,,,5002K00000d5hytQAA,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2019-01-24 00:06:48.0,65232000,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,sara.williamson(sara.williamson),2019-01-23 20:39:56.0,,,,,,,,,,,,,,backlog-server-security(backlog-server-security),joe.caswell(joe.caswell),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i32ztj:",,,,,,,"0|i367wv:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i32xxb:",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Bypass authentication when connecting from localhost,SERVER-22085,246064,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-server-security,ankit.kakkar,ankit.kakkar,Jan 07 2016 05:33:30 AM UTC,Jul 22 2019 03:45:59 PM UTC,Feb 17 2021 11:15:24 AM UTC,,,,,,Backlog,Security,,,,2,,,,,,"When enabling authentication on mongodb instances, would be useful to be able to bypass it (without credentials) when connecting locally i.e. localhost bypass.",,,,,,,,,,,,CS-25657,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2016-01-07 13:10:21.0,161395200,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,sara.williamson(sara.williamson),2016-01-07 05:33:30.0,,,,,,,,,,,,,,ankit.kakkar(ankit.kakkar),backlog-server-security(backlog-server-security),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i02ac7:",,,,,,,"0|i05mlz:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i0xhbr:",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Attempt best effort reverse dns for ingress connections,SERVER-35540,557730,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-server-servicearch,jason.carey,jason.carey,Jun 11 2018 10:44:07 PM UTC,Jul 15 2019 03:31:08 PM UTC,Feb 17 2021 11:15:24 AM UTC,,,,,,Backlog,Networking,,,,0,,,,,,"On connection accepted we print the ip address of the remote host in the logs.  Any efforts we could make towards doing reverse dns would help correlate ingress and egress log lines (egress are always host and port, not resolved address).

A minimal effort might include a cache of ip address to host and port that was derived from egress connections.  That would at least allow us to identify we ourselves are connecting to (like other replica set members).",,,,,,,,,,,,SERVER-35453,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,Fully Compatible,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2018-06-13 22:50:05.0,50284800,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,jason.carey(jason.carey),Mon Jul 15 15:31:08 UTC 2019,,,,,,,,,,,,,,backlog-server-servicearch(backlog-server-servicearch),jason.carey(jason.carey),spencer(spencer),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i2ip1b:",,,,,,,"0|i04t8f:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i2in53:","Jun 13 2018 10:50:05 PM UTC;spencer;This would be helpful when reading log files for correlating incoming internal connections with which member of the replica set they belong to","Jul 15 2019 03:31:08 PM UTC;jason.carey;Whatever we decide, we should ensure that we don't add dns resolution overload unnecessarily to operations.

Doing something asynchronously (where we load things into the cache when we see them, use it from that cache if it's there), might be a reasonable approach",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Prevent non-authenticated users from accessing libfuzzer test logs,SERVER-42146,850491,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-server-security,roxane.fruytier,roxane.fruytier,Jul 10 2019 05:38:30 PM UTC,Jul 12 2019 06:37:22 PM UTC,Feb 17 2021 11:15:24 AM UTC,,,,,,Backlog,,,,,0,,,,,,"Once EVG-6429 is completed, we should prevent non-authenticated users from accessing   the test logs of the libfuzzertests! task on evergreen",,,,,,,,EVG-6429,,,,PM-1386,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2019-07-10 17:44:17.0,50716800,<a href='https://jira.mongodb.org/browse/EVG-6429'>EVG-6429</a>,,,,,,,,,,,,,,,,,,,,,,,,,,,true,sara.williamson(sara.williamson),2019-07-10 17:38:30.0,,,,,,,,,,,,,,backlog-server-security(backlog-server-security),roxane.fruytier(roxane.fruytier),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i3w9bb:",,,,,,,"0|i02zan:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i3w7f3:",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Periodically record all active configuration settings in the mongod and mongos.,SERVER-29291,384923,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-server-security,mark.brinsmead,mark.brinsmead,May 18 2017 11:47:36 PM UTC,Jun 27 2019 06:57:15 PM UTC,Feb 17 2021 11:15:24 AM UTC,,,,,,Backlog,Diagnostics,Logging,,,0,SWDI,,,,,"Periodically sample and record all configuration settings, including command-line options, dynamic parameters, hidden parameters, and internal storage engine parameters.

Capturing these every 15 minutes or so in the log file may be adequate. (May as well also report the DB version at the same time, and the storage engine.)  Including them in FTDC would be nice.

People often work with small slices of logfiles; when viewing a partial logfile, version and configuration information is often unavailable.",,,,,,,,,,,,PRODUCT-563,PRODUCT-564,SERVER-18985,SERVER-29290,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2017-05-19 02:27:03.0,118368000,,,,,,,,PM-1391,,,,,,,,,,,,,,,,,,,,true,rupa.narayanan(rupa.narayanan),2017-05-18 23:47:36.0,,,,,,,,,,,,,,backlog-server-security(backlog-server-security),mark.brinsmead(mark.brinsmead),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i01gqv:00b",,,,,,,"0|i03mev:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i1mfcv:",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Make parallel/basic.js test respect resmoke.py tag-based exclusions,SERVER-39362,682875,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-server-stm,max.hirschhorn,max.hirschhorn,Feb 04 2019 03:16:37 AM UTC,May 02 2019 03:44:54 AM UTC,Feb 17 2021 11:15:24 AM UTC,,,,,,4.1 Desired,Testing Infrastructure,,,,2,tig-qwin-eligible,tig-resmoke,,,,"The {{jstests/parallel/basic*.js}} tests have a couple shortcomings due to how they are a JavaScript test that runs other JavaScript tests:
# resmoke.py doesn't know the individual tests being run and therefore cannot apply tag-based exclusion using {{exclude_any_with_tags}}.
# resmoke.py doesn't spawn separate mongo shell processes for the individual tests being run and therefore cannot (a) create separate log endpoints for their output or (b) report separate pass/fail statuses.

*This ticket is only intended to address #1.* Addressing #2a is difficult due to the existing logkeeper schema because it makes an assumption that a test has ended as soon as another test that's part of the same {{build_id}} has started. Addressing #2b is difficult because [creating a new {{test_id}} is tied in resmoke.py to starting a test|https://github.com/mongodb/mongo/blob/r4.1.7/buildscripts/resmokelib/testing/report.py#L92-L117].

A new {{parallel_js_test}} test kind should be introduced that makes use of resmoke.py's {{buildscripts/resmokelib/selector.py}} module within the {{ParallelJSTestCase}} class to filter out tests from the {{jstests/core/}} directory that shouldn't be run by the {{jstests/parallel/basic*.js}} tests. {{ParallelJSTestCase._make_process()}} should spawn a mongo shell process with a new {{TestData.testSchedule}} array option (or similar name) where each element corresponds to the list of tests for a {{ScopedThread}} spawned by the {{jstests/parallel/basic*.js}} tests to run.

{code:javascript}
TestData.testSchedule = [
  [
    // This list should be sourced exclusively from the executor.config.serial_execution section.
    '0',
    'jstests/core/killop_drop_collection.js',
    'jstests/core/fsync.js',
    'jstests/core/currentop.js',
    ...
  ],
  [
    // This list and the following ones should be sourced exclusively from tests filted by the
    // executor.config.selector section that aren't present in the executor.config.serial_execution
    // section.
    '1',
    'jstests/core/all.js',
    ...
  ],
  [
    '2',
    'jstests/core/all2.js',
    ...
  ],
  [
    '3',
    'jstests/core/all3.js',
    ...
  ],
];
{code}

All of the logic of [the {{ParallelTester.createJstestsLists()}} function|https://github.com/mongodb/mongo/blob/r4.1.7/jstests/libs/parallelTester.js#L143-L323] should be expressed in the resmoke.py YAML suite file and performed by the {{ParallelJSTestCase}} class. In particular,
* [These tests|https://github.com/mongodb/mongo/blob/r4.1.7/jstests/libs/parallelTester.js#L212-L222] should be automatically excluded when resmoke.py is invoked with {{\-\-excludeWithAnyTags=requires_find_command}} as [the {{parallel_compatibility}} Evergreen task|https://github.com/mongodb/mongo/blob/r4.1.7/etc/evergreen.yml#L5883] configures it.
* The order of all of the tests in {{TestData.testSchedule}}, including those mentioned in the {{executor.config.serial_execution}} section should be shuffled.
* It should be an error to explicitly mention a test in the {{executor.config.selector}} section that doesn't exist. (This should happen automatically.)
* It should be an error to explicitly mention a test in the {{executor.config.serial_execution}} section that doesn't exist.

A few other notes:
* The number of array elements to generate in {{TestData.testSchedule}} should be defined as a constant (=4) on the {{ParallelJSTestCase}} class but need not be configurable via YAML.
* New {{parallel_jscore_passthrough}} and {{parallel_jscore_compatibility_passthrough}} Evergreen tasks should be introduced to all build variants that currently run the {{parallel}} and {{parallel_compatibility}} tasks, respectively.

{code:yaml|title=buildscripts/resmokeconfig/suites/parallel_jscore_passthrough.yml}
test_kind: parallel_js_test

selector:
  roots:
  - jstests/parallel/basic*.js
  
executor:
  archive:
    hooks:
    - ValidateCollections
  config:
    selector:
      roots:
      - jstests/core/**/*.js
      exclude_files:
      # Transactions are not supported on MongoDB standalone nodes.
      - jstests/core/txns/**/*.js

    serial_execution:
    # The following tests run the {fsync: 1, lock: 1} command.
    - jstests/core/currentop.js
    - jstests/core/fsync.js
    - jstests/core/killop_drop_collection.js
    ...

    shell_options:
      readMode: commands
  hooks:
  - class: ValidateCollections
  fixture:
    class: MongoDFixture
    mongod_options:
      set_parameters:
        enableTestCommands: 1
{code}",,,,,,,,,,,,SERVER-36256,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2019-02-27 17:55:03.0,62208000,,,,,,,,,,,,,,,,,,,,,,,,,,,,false,max.hirschhorn(max.hirschhorn@10gen.com),Wed Feb 27 17:55:03 UTC 2019,,,,,,,,,,,,,,backlog-server-stm(backlog-server-stm),james.wahlin(james.wahlin@10gen.com),max.hirschhorn(max.hirschhorn@10gen.com),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i340lz:",,,,,,,"0|i3774f:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,4.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i33ypr:","Feb 27 2019 05:55:03 PM UTC;james.wahlin;+1 for this feature. It is surprising that tags are not respected by the parallel suites and non-intuitive that a separate blacklist exists and requires updating.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Master-Master replication,SERVER-2956,16167,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-server-repl,zsombor,zsombor,Apr 17 2011 06:19:54 PM UTC,Apr 30 2019 04:30:03 PM UTC,Feb 17 2021 11:15:24 AM UTC,,1.8.0,,,,Backlog,Replication,,,,52,master-master,multimaster,,,,"There were once a 'master-master replication' described here : http://www.mongodb.org/display/DOCS/Master+Master+Replication
which we used successfully with 1.4.2. However this configuration is not supported anymore, and it's not clear that is it working with newer versions, or can kill our kittens, if we try to use.
 Replica sets are not enough for this kind of work, when read, and write response times are extremely crucial to be fast, and we can accept that writes are propagated lazily in the background to the other server(s). So it would be nice, if clients could connect to 'slave' servers in the replica sets, and issue write request. For a write request the following needs to be performed :
 - apply the write request locally
 - respond to the client with success message - so the client see fast response times
 - the write request put into a 'localInitiatedOpLog' queue, which periodically flushed/sent to the actual master server.
 - the master server apply that changes and propagates to all the servers in the replica set. This algorithm will produce some strange effects, if the same object is modified concurrently by different slaves, or by the same slave in rapid succession, but at the end, every node will see the same objects, as the master node decides.
",,,,,,,,,,,,FREE-35271,FREE-56660,,,,,,,,,,,,,,,,,,,23.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2011-07-01 14:37:19.0,195955200,,,,,,,,PM-1422,,,,,,,,,,,,,,,,,,,,true,greg.mckeon(greg.mckeon),Tue Dec 02 16:04:53 UTC 2014,,,,,,,,No,,,,,,meirelles(meirelles),asya(asya),backlog-server-repl(backlog-server-repl),eliot(eliot),zsombor(zsombor),kzk_mover(kzk_mover),mani(mani),michaelbrenden(michaelbrenden),tubaguy50035(tubaguy50035),ricardo.mayerhofer@ideais.com.br(ricardo.mayerhofer@ideais.com.br),sd(sd),smitra(smitra),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i06qh3:",,,,,,,"0|i0c247:",6156,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i0he1b:","Apr 17 2011 06:20:41 PM UTC;zsombor;This is the thread, which I've explained our setup & requirements in detail: 
http://groups.google.com/group/mongodb-user/browse_thread/thread/625b5e3c30bf1d45/8f635c70b5a8c895","Jul 01 2011 02:37:19 PM UTC;sd;This is what I would like as well and is one of the reasons I'm thinking perhaps Couch is a better approach when this requirement is needed.","Jul 05 2011 04:54:57 AM UTC;kzk_mover;Planned? Planned in 3 years? not planned?
","Jul 05 2011 05:01:09 AM UTC;eliot;It is not on any planned release, though it is something we are interested in looking at in the future.","Jul 05 2011 05:06:54 AM UTC;kzk_mover;What makes this ""not-planned"" status? Just for curious.","Jul 05 2011 05:10:20 AM UTC;eliot;It is something we are planning on doing, but is not schedules for any version at this point.
Though not sure I understand the question.","Jul 05 2011 05:16:58 AM UTC;kzk_mover;Sorry, my concern is: Is there any technical difficulty for achieving this? or just scheduling/roadmap issue?
","Jul 05 2011 05:19:34 AM UTC;eliot;Its not difficulty per se, but the semantics are very different than current mongo semantics, so there is no ""simple"" solution.
","Jul 05 2011 05:22:49 AM UTC;kzk_mover;That sounds reasonable, thanks :-)
","Jul 05 2011 05:24:57 AM UTC;sd;If this was available at one point why was it removed? Also, since it was done already why would re-enabling the feature be time consuming? Could this be a configuration setting so you could have the option to use sharding or master-master but not both at first with the understanding the features are mutually exclusive?

I as well would like to see this feature in Mongo since it better suits the application(s) I'm working on than sharding.

Thanks","Jul 05 2011 05:37:21 AM UTC;eliot;It was never a supported feature, but you can set the system up to do it kind of the same way you can with mysql.
There was never support for conflict resolution, etc... so it's not really a viable thing to use.","Jul 05 2011 02:42:43 PM UTC;sd;Really, the document http://www.mongodb.org/display/DOCS/Master+Master+Replication mentioned is no longer available. Can we get this again?

If this can be done can it be on a collection basis? I mean, can I have a 3-5 server replica set with only one collection that it applies to? This would be ideal.

Thanks","Jul 06 2011 03:07:04 AM UTC;eliot;It was never supported - you were able to hack it with --master and --slave.
It was no per collection, and easily can lead to inconsistent bad data.","Oct 26 2011 09:36:41 PM UTC;meirelles;Eliot, how I can exactly hack it to force both be master? Which type of inconsistent bad data we are talking about? I mean which kind of updates/inserts operations can lead inconsistent? If of course the application guarantee no collision of keys.

We work with two DCs with 150ms of latency (each other). This is very important for us, also is impossible every write wait that long to reach the master on another continent. 

Our application guarantee no key collision on MySQL which works fine for years. Both DCs are totally independent (very failover friend) with eventually consistent read AND write, both amazing fast because the application only use DB servers localized few inches away (in same rack).","Oct 28 2011 05:29:39 AM UTC;eliot;If you start both nodes with --master and --slave.
If its insert only - can work ok.","Feb 28 2013 10:21:05 AM UTC;michaelbrenden;It seems to me that every single telecommuter need this master-master feature.

Imagine

-- being on cable or DSL at home

-- having a mongo slave on the at-home LAN

-- developing write-heavy database

It's painful to wait for every write to hit the distant master.  Very painful.  Almost more pain than mongo otherwhere alleviates.
","Mar 06 2013 03:53:35 AM UTC;michaelbrenden;Master-master is so important.  It's causing us to take up Redis.  What a split!","Apr 19 2013 11:18:58 PM UTC;ricardo.mayerhofer@ideais.com.br;I think the lack of master-master replication is a major drawback of Mongo comparing to other dynamo-like NoSQL solutions. We're looking into Mongo as our single database technology, but we're having a hard time to solve some problems without this feature.","May 14 2013 02:25:49 PM UTC;mani;Hello Everyone,

Can you recommend any workarounds/external sync tool to achieve this?

Thanks,
Mani","Jul 09 2013 09:26:19 PM UTC;tubaguy50035;The auto elections are wonderful, but multi-master would be better.","Nov 19 2014 05:54:28 AM UTC;michaelbrenden;Still waiting on this VITAL feature.  Please up-vote and join the silent energetic influence!","Dec 02 2014 09:01:03 AM UTC;smitra;This feature would solve many design issue , please read my post
https://groups.google.com/forum/#!starred/mongodb-user/tG1ekPAaSW0
","Dec 02 2014 04:04:53 PM UTC;asya;[~smitra] you linked to description of  ""on demand"" two-way replication.   That does not really match the definition of standard master-master that this ticket describes. ",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
a semaphore type that returns a SemiFuture<void> on wait,SERVER-35681,561665,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-server-servicearch,jason.carey,jason.carey,Jun 19 2018 07:56:10 PM UTC,Apr 24 2019 09:47:12 PM UTC,Feb 17 2021 11:15:24 AM UTC,,,,,,Backlog,Internal Code,,,,0,service_architecture_future,,,,,It's likely that we'll want rate limiters which are first class future citizens,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,Fully Compatible,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,84067200,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,jason.carey(jason.carey),2018-06-19 19:56:10.0,,,,,,,,,,,,,,backlog-server-servicearch(backlog-server-servicearch),jason.carey(jason.carey),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i2jdbj:",,,,,,,"0|i04rlj:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i2jbfb:",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Expand executor.archive granularity for subdirectories,SERVER-39854,705251,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-server-stm,ben.caimano,ben.caimano,Feb 26 2019 08:52:29 PM UTC,Mar 16 2019 05:08:55 AM UTC,Feb 17 2021 11:15:24 AM UTC,,,,,,Backlog,Testing Infrastructure,,,,0,tig-resmoke,,,,,"The [executor.archive functionality|https://github.com/mongodb/mongo/blob/04c29046dfe2f40ed53b643c7eef964fa39616d6/buildscripts/resmokelib/testing/hook_test_archival.py#L102] allows the user to archive the entire data directory on certain conditions. I would like this to be expanded to allow the user to only archive potential subfolders ""diagnostics.data"" and ""traffic.data"". I suspect that, if turned on for a limited set of suites, this will be useful for the purposes of diagnosing a common set of failures in sharding.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,62294400,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,max.hirschhorn(max.hirschhorn@10gen.com),2019-02-26 20:52:29.0,,,,,,,,,,,,,,backlog-server-stm(backlog-server-stm),ben.caimano(ben.caimano),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i37sdz:",,,,,,,"0|i3atrj:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i37qhr:",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Metadata freeze command,SERVER-12500,107905,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-server-sharding,alex.komyagin,alex.komyagin,Jan 28 2014 12:38:37 AM UTC,Dec 20 2018 03:57:14 PM UTC,Feb 17 2021 11:15:24 AM UTC,,,,,,Backlog,Admin,Sharding,,,0,,,,,,"In sharded clusters some ""advanced"" maintenance operations like manual chunk rebalancing, performed by DBAs, can benefit from stopping the config metadata changes (i.e. balancer, splits).

It should be usable, something like sh.freeze() and sh.unfreeze(). Of course, if somebody calls this, they should be ready to handle the implications, e.g. jumbo chunks.

Currently you can shut down the second or the third config server to achieve the desired effect, but I'm hesitant to call it a solution.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,222652800,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,greg.mckeon(greg.mckeon),2014-01-28 00:38:37.0,,,,,,,,No,,,,,,alex.komyagin(alex.komyagin@10gen.com),backlog-server-sharding(backlog-server-sharding),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i03s27:",,,,,,,"0|i0c547:",6711,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i174cf:",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Support user-definable MongoDB Cluster Name,SERVER-12322,105533,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-server-sharding,rob.young@10gen.com,rob.young@10gen.com,Jan 10 2014 05:10:51 PM UTC,Dec 06 2018 03:59:57 PM UTC,Feb 17 2021 11:15:24 AM UTC,,,,,,Backlog,Sharding,,,,0,,,,,,"Add MongoDB sharded clusters to the current set of supported, user-definable “named resources” and components (these currently include replicasets, databases, collections, roles, etc.)  This allows private cloud providers to enable users with a specific named resource, in this case a cluster by name, while abstracting the user from the components that comprise a dynamically managed and provisioned cluster.  

Most relational databases provide such a concept using a combination of administration, CLI and tool support, internal database service awareness of cluster changes, and meta-management .  

There is also a concept of providing external awareness of cluster name and component structure via existing directory or service-based resources.  For example, PostGres provides this via service names, which can be used in the connection string and tied to an external look-up via LDAP. 

Requirement – phase 1

• Support user-definable cluster names as “named resources” in the same/similar way other resources (replicasets, databases, collections, users, etc.) are supported.
• Cluster will be aware of its cluster name.
• User/clients should only interact/connect with the cluster name.  The database service should maintain the cluster host:port list and ensure that changes are propagated with little/no effect on existing users or connections.  
• CLI should provide interface to query and return topology/inventory and status of a specified cluster name (lookup key).  
o	MongoS nodes – top level
o	Would be helpful to also return shard/mongod/config server information below the mongos nodes
o	State of the cluster as failures/configuration changes occur

Requirement – phase 2 (this should spawn a separate, linked SERVER ticket)

Enable MongoDB cluster name and underlying inventories to be “advertised” and accessed via external look-up directory services (such as LDAP, Zookeeper, etc.)

• The primary use case is to enable external access to cluster status and topology changes without connecting directly to MongoDB.  This enables informed connections to cluster inventory components for monitoring, maintenance, availability 
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2018-12-06 15:59:56.0,224121600,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,greg.mckeon(greg.mckeon),2014-01-10 17:10:51.0,,,,,,,,No,,,,,,backlog-server-sharding(backlog-server-sharding),rob.young@10gen.com(rob.young@10gen.com),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i03td3:",,,,,,,"0|i0bxnj:",6460,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i03qan:",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Add support to create/define chunks in a given shard for empty collections,SERVER-14298,142904,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-server-sharding,jlpedrosa,jlpedrosa,Jun 18 2014 08:40:41 PM UTC,Nov 21 2018 12:44:35 AM UTC,Feb 17 2021 11:15:24 AM UTC,,,,,,Backlog,Sharding,,,,0,,,,,,"Hi All

When pre-spliting a large collection that requires a significant number of chunks, the procedure of splitting and then moving chunks to the desired shard can take a significant amount of time. In some cases can be done by making an small initial split and move, and then split with a seed in each chunk, this is not always possible.

As config.chunks collection is not part of the ""API"", it would be nice to have a way to instruct the DB to create the chunks in a determined shard.

Possible options:
1) pass an array of { min : { key : value}, max : { key : value } , shard : name } on the shardCollection command, this only solves the initial creation.

2) Allow specify the destination shard of a chunk in a split if the left or right side are empty.

",,,,,,,,,,,,SERVER-14394,,,,,,,,,,,,,,,,,,,,3.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2014-06-19 18:58:41.0,199670400,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,kevin.pulo(kevin.pulo@10gen.com),Mon Oct 20 15:52:07 UTC 2014,,,,,,,,,,,,,,backlog-server-sharding(backlog-server-sharding),greg_10gen(greg_10gen),jlpedrosa(jlpedrosa),thomasr(thomasr),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i03i9z:",,,,,,,"0|i0bxuf:",123440,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i0yztb:","Jun 19 2014 06:58:41 PM UTC;thomasr;Hi Jose,

I'd like to better understand your feature request and need some more information. 

You say: 
bq. and then split with a seed in each chunk, this is not always possible.

1. Can you explain under which circumstances it's not possible to create n chunks (for n shards), move each of them to a shard and then continue the splits locally?

2. Do I understand correctly that you want to enhance the shardCollection and split command to do the following:

a) For the shardCollection command, provide the initial chunk distribution manually. This requires an additional parameter that takes a list of chunks (with min and max) for each shard. The initial chunks are created and placed according to the provided distribution. If the full range from minKey to maxKey is not covered or if there are overlaps, the command aborts with an error.

b) enhance the split command to be able to provide a target shard for splits on a boundary. The empty chunk of the two new chunks will be directly placed on the target shard.

Both of these changes assume that there is no data, either in the collection (2a) or in one of the new chunks resulting from a split (2b), therefore the metadata can be written directly without having to migrate data.

If this what you had in mind? If not, can you please elaborate on the requested changes?

Thanks,
Thomas
","Jun 20 2014 12:42:19 AM UTC;jlpedrosa;Hi Thomas

Indeed you explained it much more clearly, it is exactly what I ment.

Answering your question, the case when I think it's not possible to create the chunks without a lot of moves, is when the desired chunk distribution is ciclic to the shards: 
{code}
min : { KeyName : {$minKey : 1} }, max : { KeyName :  0 }, shard: ""sh0""
min : { KeyName : 0 }, max : { KeyName :  1 }, shard: ""sh1""
min : { KeyName : 1 }, max : { KeyName :  2 }, shard: ""sh2""
min : { KeyName : 2 }, max : { KeyName :  3 }, shard: ""sh0""
.....
min : { KeyName : n }, max : { KeyName :   {$maxKey : 1} } }, shard: ""shx""
{code}

One example could be dates, each day goes to one shard, so 2a would be suefull for initial creation and 2b for maintenance:  Always the shard for   $maxKey will be a single chunk, if you split that chunk the new chunk now lives on the same shard... so this forces to move empty chunks.

This options is what I could think of to improve shard/chunk management, feel free to change it to any other approach. 

Thanks!
Jose Luis","Oct 20 2014 03:52:07 PM UTC;greg_10gen;See the comments here:
https://jira.mongodb.org/browse/SERVER-14394?focusedCommentId=639257&page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-639257

This is definitely something that is planned, it just requires moving shardCollection to mongod to implement safely.  Mongos isn't capable of holding the locks required to ensure that no data is written to the collection on the primary while we're creating chunks elsewhere.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
should be able to share setup code across multiple tests,SERVER-21313,238025,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-server-stm,charlie.swanson,charlie.swanson,Nov 05 2015 08:10:13 PM UTC,Nov 15 2018 08:08:35 PM UTC,Feb 17 2021 11:15:24 AM UTC,,,,,,Backlog,Testing Infrastructure,,,,0,stm,tig-resmoke,,,,"Currently we have a huge test (jstests/aggregation/testshard1.js) that tests many different things, and we would like to split it into multiple files. However, tests in this file all rely on some setup code that inserts a bunch of data into a sharded collection. This takes a while, and we would significantly slow down the tests if we split them up by functionality.

We should add some logic, probably to resmoke.py, to set up a fixture with some data already loaded. For example, we could specify in the suite's YAML what collections to create, how to shard them, and what data to insert. This way, we could have a bunch of different test files that share a common setup, and can avoid large tests that obscure what they are testing.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,4.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2015-11-05 20:35:08.0,166752000,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,april.schoffer(april.schoffer),Thu Nov 05 21:36:53 UTC 2015,,,,,,,,,,,,,,backlog-server-stm(backlog-server-stm),charlie.swanson(charlie.swanson),scotthernandez(scotthernandez),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i02etj:",,,,,,,"0|i1a6fj:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i0u4in:","Nov 05 2015 08:35:08 PM UTC;scotthernandez;Is this about sharing test data or sharing code? It sounds more like getting shared test data/initial-start-conditions together for multiple tests.","Nov 05 2015 08:53:36 PM UTC;charlie.swanson;It's about both sharing data and sharing code. We could get equivalent functionality by making a passthrough in javascript, but that sacrifices the nice evergreen output (logs/failures split per test) and our ability to parallelize the tests.

I'm not quite sure what you mean by ""getting shared test data/initial-start-conditions together for multiple tests"", but I think that is what we're looking for.","Nov 05 2015 09:05:51 PM UTC;scotthernandez;I guess I'm asking if it would be sufficient if we simply said that blah*.js all needed data-set4, and they weren't responsible for populating -- making it a dependency and requirement before they could be run.

When I read the title it sounds like our tests, in javascript, need to be able to share code (which they can, btw, but using a load/include), not that their initial env+data should be provided by resmoke. 

So it sounds like the task here is to have a resmoke test fixture which includes data loading/cleaning before running a set of tests.","Nov 05 2015 09:36:53 PM UTC;charlie.swanson;Ah okay. Yes, as you can see in the description, it's the latter. This is asking for resmoke's fixture to load data, shard collections, etc. before it runs any tests. Feel free to update the title if you can think of a better one.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Resmoke should support derived suites,SERVER-29906,399008,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-server-stm,redbeard0531,redbeard0531,Jun 28 2017 06:11:05 PM UTC,Sep 27 2018 10:18:18 PM UTC,Feb 17 2021 11:15:24 AM UTC,,,,,,Backlog,Testing Infrastructure,,,,1,stm,tig-resmoke,,,,"Many of our suites are really just some other suite with a single small change. As an example, I'd like to introduce sharding_jscore_passthrough_opquery which is the same as sharding_jscore_passthrough, except it sets executor.config.shell_options.rpcProtocols to opQueryOnly. Unfortunately this requires duplicating the whole file which almost guarantees that they will fall out of sync in the future.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,4.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2017-06-29 14:47:12.0,113097600,,,,,,,,,,,,,,,,,,,,,,,,,,,,false,april.schoffer(april.schoffer),Tue Jul 18 18:20:28 UTC 2017,,,,,,,,,,,,,,backlog-server-stm(backlog-server-stm),ian.whalen(ian@10gen.com),redbeard0531(redbeard0531),max.hirschhorn(max.hirschhorn@10gen.com),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i1rwy7:",,,,,,,"0|i1yab3:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i1rv1z:","Jun 29 2017 02:47:12 PM UTC;max.hirschhorn;[~redbeard0531], I think that if we were to tag the tests to exclude from the sharding_jscore_passthrough.yml suite (SERVER-18395), then would be less of an issue. There's been ideas of having separate test suites for the MMAPv1 and WiredTiger versions of the same test suite (i.e. the Evergreen tasks) so that exclusions can be done on a storage engine-specific level. The other way I could see this going is to introduce a {{\-\-shellRpcProtocols}} option to resmoke.py that sets {{shell_options.rpcProtocols}} like you described.","Jul 17 2017 07:39:15 PM UTC;ian.whalen;[~max.hirschhorn] can you clarify why this is in debugging with submitter?  Are you waiting on something from Mathias?","Jul 18 2017 06:13:15 PM UTC;max.hirschhorn;{quote}
Max Hirschhorn can you clarify why this is in debugging with submitter? Are you waiting on something from Mathias?
{quote}

[~ian.whalen], I was curious if Mathias was comfortable having this sit on our backlog and instead (1) have a separate ticket for adding a {{\-\-shellRpcProtocols}} option to resmoke.py for testing OP_MSG and (2) move SERVER-18395 from Backlog to 3.5 Desired.","Jul 18 2017 06:20:28 PM UTC;redbeard0531;Given that I already committed https://github.com/mongodb/mongo/commit/013f374c9d055cf434102fad2b6bfd83bb7616a9, this isn't a burning problem for me. It just seems like something that would improve our testing situation.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Operation priorities,SERVER-12388,106486,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-server-servicearch,wlaforest,wlaforest,Jan 17 2014 06:18:37 AM UTC,Sep 24 2018 05:25:14 PM UTC,Feb 17 2021 11:15:24 AM UTC,,,,,,Backlog,Concurrency,Security,,,1,,,,,,"It would be good to be able to specify priorities for operations.  For instance one query may be more important then another one and if they are running at the same time it would be good for the more important one to get a bigger slice of the resources.   Additionally this is a requirement for the STIG requirement SRG-APP-000245-DB-000132:

""A variety of technologies exist to limit, or in some cases, eliminate the effects of DoS attacks. For example, boundary protection devices can filter certain types of packets to protect devices on an organization’s internal network from being directly affected by DoS attacks. Employing increased capacity and bandwidth combined with service redundancy may reduce the susceptibility to some DoS attacks. Some of the ways databases can limit their exposure to DoS attacks are through limiting the number of connections that can be opened by a single user and database clustering.""",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,223603200,,,,,,,,PM-1109,,,,,,,,,,,,,,,,,,,,true,sara.williamson(sara.williamson),2014-01-17 06:18:37.0,,,,,,,,No,,,,,,backlog-server-servicearch(backlog-server-servicearch),wlaforest(wlaforest),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i03syn:",,,,,,,"0|i05mzj:",6143,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i1759r:",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Support using keytab / non-MSLA kerberos cache on Windows for mongo shell,SERVER-19864,225061,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-server-security,anil.kumar,anil.kumar,Aug 11 2015 03:09:38 PM UTC,Sep 10 2018 06:00:31 PM UTC,Feb 17 2021 11:15:24 AM UTC,,,,,,features we're not sure of,Security,,,,1,,,,,,"Currently the only way to use mongo shell using Kerberos on Windows is using the windows kerberos cache. This inhibits usage of keytabs / separate cache on the windows for using multiple application account under one login.
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,3.0,,,,,,,,,,,,,,,,,,,,500A000000UaXhDIAV,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,174182400,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,greg.mckeon(greg.mckeon),2015-08-11 15:09:38.0,,,,,,,,,,,,,,anil.kumar(anil.kumar),backlog-server-security(backlog-server-security),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i02n3r:",,,,,,,"0|i05r9b:",9223372036854775807,,,,,,,,,,,,Security D (12/11/15),Security E (01/01/16),Security F (01/29/16),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i0xwq7:",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Allow Kerberos Principal Name Override,SERVER-22471,263183,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-server-security,daniel.hatcher,daniel.hatcher,Feb 04 2016 06:12:05 PM UTC,Sep 10 2018 06:00:30 PM UTC,Feb 17 2021 11:15:24 AM UTC,,,,,,features we're not sure of,Security,,,,1,,,,,,"While handling incoming authentication attempts with the GSSAPI SASL mechanism, MongoDB uses a combination of its service name, 'mongodb' by default, and the local hostname to form a principal name. The components of the principal name are structured by GSSAPI when it imports the name. MongoDB searches its keytab for an entry with this principal name and uses it to handle incoming authentication attempts.

Currently, mechanisms are in place which allow a user to override each of these components individually. One might desire the ability to explicitly request a principal name directly through a single configuration variable with none of the structure imposed by GSSAPI. This would enable a user to ask MongoDB to load keytab entries with arbitrary names.",,,,,,,,,,,,CS-27372,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2016-02-12 06:39:50.0,149126400,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,greg.mckeon(greg.mckeon),Fri May 27 16:46:33 UTC 2016,,,,,,,,,,,,,,backlog-server-security(backlog-server-security),bereket.aloto@pimco.com(bereket.aloto@pimco.com),daniel.hatcher(daniel.hatcher),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i027p3:",,,,,,,"0|i05rbj:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i0xesn:","Apr 12 2016 04:16:13 PM UTC;bereket.aloto@pimco.com;Team, whats the ETA for this one?

Thanks
Bereket","May 27 2016 04:46:33 PM UTC;bereket.aloto@pimco.com;Hi Team, can you give us a status on this one and ETA?

Thanks
Bereket",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Check Kerberos ticket expiration when authz checking,SERVER-7123,51259,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-server-security,milkie,milkie,Sep 24 2012 01:27:00 PM UTC,Sep 10 2018 06:00:28 PM UTC,Feb 17 2021 11:15:24 AM UTC,,,,,,Backlog,Security,,,,0,kerberos,platforms-re-triaged,,,,,,,,,,,,,,,,CS-13012,,,,,,,,,,,,,,,,,,,,3.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2012-11-07 17:26:12.0,219369600,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,greg.mckeon(greg.mckeon),Thu Mar 06 15:35:48 UTC 2014,,,,,,,,No,,,,,,andreas.nilsson(andreas.nilsson@10gen.com),backlog-server-security(backlog-server-security),milkie(milkie),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i05cxb:",,,,,,,"0|i05oc7:",4481,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i1hzd3:","Mar 06 2014 03:29:11 PM UTC;andreas.nilsson;check expirations of what?","Mar 06 2014 03:32:26 PM UTC;milkie;Expiration of the Kerberos ticket, I believe.  If your ticket expires, right now you can continue operating as if it were still valid.","Mar 06 2014 03:35:48 PM UTC;andreas.nilsson;You mean re-checking of the ticket expiration during an active user session? I think this is easiest implemented using proper session management with a configurable session timeout.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
New authz probe command to check user privileges,SERVER-19253,214354,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-server-security,pasette,pasette,Jul 01 2015 09:14:53 PM UTC,Sep 10 2018 06:00:13 PM UTC,Feb 17 2021 11:15:24 AM UTC,,,,,,Backlog,Security,,,,0,platforms-re-triaged,,,,,"Create a new command to enable ""pre-flight"" checks for long running jobs in the mongodb tools (dump, restore, import, export).

* Verify that the user possesses the required privilege actions to perform the restore/import when authorization is on.
* Verify that the user possesses the required privilege actions to perform the dump/restore when authorization is on.
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2015-07-02 02:05:23.0,177724800,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,greg.mckeon(greg.mckeon),Thu Jul 02 02:05:23 UTC 2015,,,,,,,,,,,,,,schwerin(schwerin),backlog-server-security(backlog-server-security),pasette(dan@10gen.com),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i02qpb:",,,,,,,"0|i05oxb:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i0y18f:","Jul 02 2015 02:05:23 AM UTC;schwerin;I think syntax similar to the explain command is the right approach, here.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Provide option to allow ""masking"" of query variables within audit stream.",SERVER-12671,110292,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-server-security,rob.young@10gen.com,rob.young@10gen.com,Feb 10 2014 06:30:17 PM UTC,Sep 10 2018 05:59:39 PM UTC,Feb 17 2021 11:15:24 AM UTC,,,,,,Backlog,Logging,Security,,,1,Auditing,,,,,"This enhancement allows users to optionally ""mask"" variables within the audit log.  Use case would include logging of CRUD commands generated by applications that manage sensitive data (SSN, credit card data, medical records, etc.).  This could be implemented globally or via collection, document, field level tagging.  Most competing rdbms' provide this level of data obsfuscation for sensitive data.
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,221443200,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,greg.mckeon(greg.mckeon),2014-02-10 18:30:17.0,,,,,,,,No,,,,,,backlog-server-security(backlog-server-security),rob.young@10gen.com(rob.young@10gen.com),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i03r2v:",,,,,,,"0|i05ol3:",5082,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i1732f:",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Support Kerberos authentication for split, cross-realm domain environments",SERVER-10683,88556,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-server-security,rob.young@10gen.com,rob.young@10gen.com,Sep 04 2013 09:36:31 PM UTC,Sep 10 2018 05:59:13 PM UTC,Feb 17 2021 11:15:24 AM UTC,,,,,,Backlog,Security,,,,0,kerberos,,,,,"MongoDB servers currently support cross-realm authentication in the sense that a user must be defined in the system.users collection for each domain they may authenticate and hold a credential for. For example, if you have a MongoDB server in the DOMAIN.COM realm, and a user, ""u"" can login into in the DOMAIN.COM and OTHER.DOMAIN.COM realms, user documents 
{ user: ""u@OTHER.DOMAIN.COM"", userSource: ""$external"", ... } and
{ user: ""u@DOMAIN.COM"", userSource: ""$external"", ... }
must exist in the system.users collection for ""u"" to authenticate successfully and acquire privileges to perform operations.  This creates the potential for the same user, ""u"" in this case, to exist on the same database with different roles and privileges. 

There a several options available for solving this problem:
1. Support mapping multiple Kerberos principals to a single MongoDB user.

2. Support realm/domain as a multi-valued field within the user document so that multiple, but not necessarily all, realms are accepted as an identity in the authentication phase.

3. Leverage user-defined roles (2.6 and higher) to map user to a defined set of privileges. Changes in user privileges are made only to the role.  This lessens the the chance of an out of sync condition but still requires multiple user entries, which is the crux of the issue for admins managing large numbers of users.

4. Other options.


","Windows, Linux",,,,,,,,,,,CS-8071,CS-16326,INT-1351,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2013-09-05 22:32:02.0,235180800,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,greg.mckeon(greg.mckeon),2013-09-04 21:36:31.0,,,,,,,,No,,,,,,backlog-server-security(backlog-server-security),rob.young@10gen.com(rob.young@10gen.com),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i046y7:",,,,,,,"0|i05ogv:",4784,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i0z7rr:",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Check Extended Key Usage in mongod SSL certificate on startup,SERVER-14511,146277,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-server-security,alex.komyagin,alex.komyagin,Jul 09 2014 06:00:55 PM UTC,Sep 10 2018 05:58:52 PM UTC,Feb 17 2021 11:15:24 AM UTC,,2.4.5,2.6.3,,,Backlog,Security,,,,1,,,,,,"If Extended Key Usage is specified, it should contain both ""TLS Web Server Authentication"" and ""TLS Client Server Authentication"", because the same cert is being used for creating and accepting internal connections in between the RS members.",,,,,,,,,,,,CS-15557,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2014-07-09 18:03:32.0,208569600,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,greg.mckeon(greg.mckeon),2014-07-09 18:00:55.0,,,,,,,,,,,,,,alex.komyagin(alex.komyagin@10gen.com),backlog-server-security(backlog-server-security),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i03h5j:",,,,,,,"0|i05op3:",5083,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i03cmv:",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
create shard tag ranges for name spaces using wildcards or regex matching,SERVER-9527,73798,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-server-sharding,norberto.leite,norberto.leite,May 01 2013 04:54:31 PM UTC,Jul 12 2018 06:52:27 PM UTC,Feb 17 2021 11:15:24 AM UTC,,,,,,Backlog,Sharding,,,,4,sharded-cluster,,,,,"Nowadays to configure dynamic creation of sharded dbs/collections we need to set a tagRange for each new namespace.

By defining a wildcard namespace or regex expression to match namespaces we could dynamically allocate to a set of shards the data of these dynamically generated databases/collections:

sh.addTagRange( '$**', {key:MinKey}, {key:MaxKey}, 'DYNAMIC' )
or
sh.addTagRange( 'prefix*.*', ... , 'DYNAMIC')


",,,,,,,,,,,,SERVER-12971,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,Fully Compatible,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,246067200,,,,,,,,PM-904,,,,,,,,,,,,,,,,,,,,true,greg.mckeon(greg.mckeon),2013-05-01 16:54:31.0,,,,,,,,No,,,,,,backlog-server-sharding(backlog-server-sharding),norberto.leite(norberto@10gen.com),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i04k7b:",,,,,,,"0|i0c3rb:",7127,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i1hzhz:",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Write FSM concurrency workload for removeShard and movePrimary,SERVER-30483,411771,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-server-sharding,hugh.han,hugh.han,Aug 02 2017 07:40:20 PM UTC,Mar 09 2018 07:18:21 PM UTC,Feb 17 2021 11:15:25 AM UTC,,,,,,Backlog,Sharding,,,,0,PM-1017,sharding,,,,"Consider the case where we have two nodes, *A* and *B*, where *A* is the primary. If we call {{movePrimary}} to move *A* to *B* and at the same time call {{removeShard}} on *B*, then the following might happen.
# {{movePrimary}} copies unsharded collections from *A* to *B*.
# {{removeShard}} checks if *B* is the primary, which it is not.
# {{movePrimary}} updates the config server, which now thinks *B* is the primary.
# {{removeShard}} removes *B*.
# {{movePrimary}} deletes original unsharded collections from *A*.
If the above were to happen, then all unsharded collections are deleted, and there would exist no primary, which is very bad.

An FSM concurrency workload should be written to test this type of behavior, and what would happen.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2.0,1.0,,,,,,,,,,,,,,,,Fully Compatible,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2017-08-03 01:22:28.0,109814400,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,ian.whalen(ian@10gen.com),Fri Aug 25 20:08:04 UTC 2017,,,,,,,,,,,,,,asya(asya),backlog-server-sharding(backlog-server-sharding),hugh.han(hugh.han),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i1u2wv:",,,,,,,"0|i2095j:",9223372036854775807,,,,,,,,,,,,Sharding 2017-08-21,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i1u10n:","Aug 03 2017 01:22:28 AM UTC;asya;Wouldn't SERVER-30404 prevent that?
","Aug 25 2017 08:08:04 PM UTC;hugh.han;docs: https://paper.dropbox.com/doc/Metadata-Command-FSM-Workloads-1pbVk0Ao7R0PPCmoCTbyE",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Extending Exception and Error Handling,SERVER-5990,40184,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-server-platform,nask,nask,Jun 01 2012 04:21:32 PM UTC,Feb 26 2018 03:24:05 PM UTC,Feb 17 2021 11:15:25 AM UTC,,,,,,features we're not sure of,Diagnostics,JavaScript,Stability,,0,,,,,,"JavaScript within a browser and Node.js have concepts of error handling and exception handling.

Need mongo to provide similar support for error/exception handling.

A very trivial example: when running a cron to execute a script; I need any JavaScript syntax errors captured by my custom code. If mongo says a query was invalid, I need that also captured by my code so I can log it with contextual details.",All,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,Fully Compatible,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2012-06-01 16:40:39.0,274924800,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,ian.whalen(ian@10gen.com),Fri Jun 01 17:23:13 UTC 2012,,,,,,,,No,,,,,,backlog-server-platform(backlog-server-platform),nask(nask),tad(tad),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i05qcf:",,,,,,,"0|i05r13:",6499,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i1iw0n:","Jun 01 2012 04:40:39 PM UTC;tad;You can use try/catch/throw in JavaScript in the shell to control error handling, depending on what you consider ""errors"".  You can exit the shell with an error code with quit(exitCode) to pass status to cron.  Does this get you started?

Not everything that you might consider an error will throw JavaScript exceptions; for example, not finding a document that you query for is not an error from MongoDB's perspective, but you could throw an exception from your own code if that is an error for your logic.","Jun 01 2012 05:23:13 PM UTC;nask;Using try/catch is valid, but it requires all developers to wrap 100% of everything they write.  If they miss one spot then we're back to the same problem :)  In a browser, window.onerror helps make it idiot proof :)

> try { foo(); } catch(e) {}
>
> foo()
Fri Jun 01 10:01:42 ReferenceError: foo is not defined (shell):1

Granted, if try/catch is not used; we will not get the benefit of recovering within the catch; but that's okay/expected.

Instead of:
window.onerror = function(message,url,line,stack) { .... };

Something like this would be great:
mongo.onerror = function(message,file,line,stack) { .... };
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Replica set fail-over on high volume latency,SERVER-5217,32312,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-server-repl,sebastian.dahlgren@gmail.com,sebastian.dahlgren@gmail.com,Mar 06 2012 11:55:57 AM UTC,Feb 22 2018 08:49:34 PM UTC,Feb 17 2021 11:15:25 AM UTC,,2.0.1,2.0.2,,,Backlog,Replication,,,,1,replication,,,,,"MongoDB's heartbeat function does not monitor the health of the disk writes / reads. So in case the underlying disks on the primary node are having problems MongoDB will not switch primary.

I would like a feature in the heartbeat function that includes health checking the read/write performance. It would probably be good if this more extensive heartbeat function is optional. See the discussion on mongodb-user maillist https://groups.google.com/forum/?fromgroups#!starred/mongodb-user/gY7r3f-yz0k. 

Right now the only option for us when a node has disk problems is to stop the mongod process in order to force a change of primary node.",Debian GNU/Linux 6,,,,,,,,,,,CS-2475,CS-2804,SERVER-32867,,,,,,,,,,,,,,,,,,3.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2012-03-06 13:02:35.0,282441600,,,,,,,,PM-1039,,,,,,,,,,,,,,,,,,,,true,greg.mckeon(greg.mckeon),Tue Mar 06 14:57:03 UTC 2012,,,,,,,,,,,,,,backlog-server-repl(backlog-server-repl),eliot(eliot),sebastian.dahlgren@gmail.com(sebastian.dahlgren@gmail.com),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i05zx3:",,,,,,,"0|i0c227:",5961,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i1i2bz:","Mar 06 2012 01:02:35 PM UTC;eliot;Interesting, but tricky.
Concerns:
 - increased load causes disk to get busy.  failing over doesn't help, just moves load
 - jitter 

This is really something ec2/ebs specific thing...

What might make more sense is a hook such that you can specify a binary to execute that determines ""health"".","Mar 06 2012 01:15:55 PM UTC;sebastian.dahlgren@gmail.com;Thanks for the quick feedback Elliot.

Two thoughts:
 * This would indeed increase the load, however it could be optional (with default to off)
 * The thought about a hook for this is a cool approach, might be the way to go","Mar 06 2012 02:57:03 PM UTC;eliot;Sorry - I didn't mean this would increase the load, I mean a short term user load spike could flip the set unnecessarily.  Or an overall increase could just cause the set to flip back and forth constantly.  ",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Additional information for bsonobj size assertions,SERVER-10784,90081,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-server-platform,alex.komyagin,alex.komyagin,Sep 16 2013 05:35:59 PM UTC,Feb 12 2018 03:53:30 PM UTC,Feb 17 2021 11:15:25 AM UTC,,,,,,Backlog,Diagnostics,,,,1,,,,,,"In order to be able to diagnose BSONObj size assertions we need to log additional information along with them:
{noformat}
Sun Sep  1 17:09:17 [conn509177] Assertion: 10334:Invalid BSONObj size: 1953785856 (0x00687474) first element: ://XXXXXXXXX.com/XXXXXXXXX/picture: ?type=112
0xb07561 0xacd449 0xacd5cc 0x5721e8 0x80cdb5 0x80d748 0x6515d1 0x83081e 0x6f1152 0x6e8e51 0x6ea7e0 0x6eb67c 0x837468 0x83abb0 0x7b0afd 0x7b3e23 0x56c688 0xaf57b5 0x7f40aebdae9a 0x7f40adef04bd 
 /usr/bin/mongod(_ZN5mongo15printStackTraceERSo+0x21) [0xb07561]
 /usr/bin/mongod(_ZN5mongo11msgassertedEiPKc+0x99) [0xacd449]
 /usr/bin/mongod() [0xacd5cc]
 /usr/bin/mongod(_ZNK5mongo7BSONObj14_assertInvalidEv+0x468) [0x5721e8]
 /usr/bin/mongod(_ZNK5mongo19CoveredIndexMatcher7matchesERKNS_7BSONObjERKNS_7DiskLocEPNS_12MatchDetailsEb+0x1f5) [0x80cdb5]
 /usr/bin/mongod(_ZNK5mongo19CoveredIndexMatcher14matchesCurrentEPNS_6CursorEPNS_12MatchDetailsE+0xa8) [0x80d748]
 /usr/bin/mongod(_ZN5mongo6Cursor14currentMatchesEPNS_12MatchDetailsE+0x41) [0x6515d1]
 /usr/bin/mongod(_ZN5mongo8runCountEPKcRKNS_7BSONObjERSsRi+0x6ce) [0x83081e]
 /usr/bin/mongod(_ZN5mongo8CmdCount3runERKSsRNS_7BSONObjEiRSsRNS_14BSONObjBuilderEb+0x62) [0x6f1152]
 /usr/bin/mongod(_ZN5mongo12_execCommandEPNS_7CommandERKSsRNS_7BSONObjEiRNS_14BSONObjBuilderEb+0x51) [0x6e8e51]
 /usr/bin/mongod(_ZN5mongo11execCommandEPNS_7CommandERNS_6ClientEiPKcRNS_7BSONObjERNS_14BSONObjBuilderEb+0xe70) [0x6ea7e0]
 /usr/bin/mongod(_ZN5mongo12_runCommandsEPKcRNS_7BSONObjERNS_11_BufBuilderINS_16TrivialAllocatorEEERNS_14BSONObjBuilderEbi+0x2ac) [0x6eb67c]
 /usr/bin/mongod(_ZN5mongo11runCommandsEPKcRNS_7BSONObjERNS_5CurOpERNS_11_BufBuilderINS_16TrivialAllocatorEEERNS_14BSONObjBuilderEbi+0x38) [0x837468]
 /usr/bin/mongod(_ZN5mongo8runQueryERNS_7MessageERNS_12QueryMessageERNS_5CurOpES1_+0xc10) [0x83abb0]
 /usr/bin/mongod() [0x7b0afd]
 /usr/bin/mongod(_ZN5mongo16assembleResponseERNS_7MessageERNS_10DbResponseERKNS_11HostAndPortE+0x3a3) [0x7b3e23]
 /usr/bin/mongod(_ZN5mongo16MyMessageHandler7processERNS_7MessageEPNS_21AbstractMessagingPortEPNS_9LastErrorE+0x98) [0x56c688]
 /usr/bin/mongod(_ZN5mongo3pms9threadRunEPNS_13MessagingPortE+0x415) [0xaf57b5]
 /lib/x86_64-linux-gnu/libpthread.so.0(+0x7e9a) [0x7f40aebdae9a]
 /lib/x86_64-linux-gnu/libc.so.6(clone+0x6d) [0x7f40adef04bd]
<...>
Sun Sep  1 17:06:59 [conn630365] remove COLLECTION_XXXX query: { FIELD_XXXX._id: ObjectId('XXXXXXXXXXXXXXXXXXXXXXXXXX') } keyUpdates:0 exception: Invalid BSONObj size: 1953785856 (0x00687474) first element: ://XXXXXXXXX.com/XXXXXXXXXXXXXXXXXXX/picture: ?type=112 code:10334 locks(micros) w:4748 4ms
{noformat}

At this point it seems reasonable to have the following in addition to stack trace:
* namespace
* file name
* offset",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,Fully Compatible,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2013-09-20 22:24:55.0,233798400,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,ian.whalen(ian@10gen.com),Fri Sep 20 22:39:40 UTC 2013,,,,,,,,,,,,,,alex.komyagin(alex.komyagin@10gen.com),pasette(dan@10gen.com),backlog-server-platform(backlog-server-platform),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i045on:",,,,,,,"0|i05oh3:",6698,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i17gmv:","Sep 20 2013 10:24:55 PM UTC;pasette;We don't have any blanket way to return this information after this check fails.","Sep 20 2013 10:39:40 PM UTC;alex.komyagin;Is this information unavailable at the moment we detect the invalid BSONObj size?",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Do not automatically wipe existing data before initial sync,SERVER-17710,191495,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-server-repl,andre.defrere,andre.defrere,Mar 24 2015 02:12:13 AM UTC,Jan 05 2018 09:58:52 PM UTC,Feb 17 2021 11:15:25 AM UTC,,3.0.1,,,,Backlog,Replication,,,,0,initialization,PM248,replicaset,,,"When running rs.initiate(), if any nodes other than the initiator node have data (but not an oplog), an error results:
{code}
""errmsg"" : ""couldn't initiate : member <node> has data already, cannot initiate set.  All members except initiator must be empty.""
{code}

If you later use rs.add() to a node that has data (but not an oplog), then it will cause that node to initial sync and throw no errors.

If you can rs.add() a node with data in it, it follows that you should be able to have a configuration object for rs.initiate() that contains a node with data in it (and both should cause an initial sync of that node).",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,5.0,,,,,,,,,,,,,,,,,Major Change,,,,500A000000UaYQiIAN,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2015-03-30 19:49:17.0,185068800,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,spencer(spencer),Tue Apr 07 15:36:13 UTC 2015,,,,,,,,,,,,,,andre.defrere(andre.defrere),backlog-server-repl(backlog-server-repl),dmurphy(dmurphy),milkie(milkie),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i02z9b:",,,,,,,"0|i0amuf:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Not Needed,,,,,,,,,,,,,,,,,,,"0|i0ybi7:","Mar 30 2015 07:49:17 PM UTC;milkie;I would argue that we should be going the other way in terms of safety over convenience; we should change initial sync to not delete data if data is present, except for the case where we are restarting a prior failed initial sync.","Apr 07 2015 03:00:18 PM UTC;dmurphy;I would say it should only remove  data if

1) There is an oplog
2) Its data in local says it was a valid slave for this replSet name at some point.


Otherwise it would wipe the data if its sync  with and new replSet string.","Apr 07 2015 03:12:04 PM UTC;milkie;I think it was an oversight to allow a reconfig to add a node and have its data wiped.  This ticket will be the work to remove that misfeature; an admin will then need to erase data on the node by hand as preparation for initial sync.

[~dmurphy] your conditions listed above do not trigger an initial sync.  The trigger conditions for initial sync are:
1. Previous initial sync was incomplete.
2. local.rs.oplog is empty or nonexistant.
3. Someone runs the resync command.","Apr 07 2015 03:15:43 PM UTC;dmurphy;Eric,

I was not suggesting initial sync triggers but deletion criteria, if either of those are  are true, then  the inital sync can  continue, if false it means either it  was not in a replSet but has data, or it was from another replSet. Those are the cases you would want to bail in my line of thought. Initial sync should remove  data if its from the current replSet  and has an oplog ( aka someone manually called resync).

Does that make more sense?

David ","Apr 07 2015 03:36:13 PM UTC;milkie;Once begun, an initial sync always clears all the data as a first step; there are no deletion criteria to invoke there.  Essentially, the deletion criteria *are* the initial sync triggers.
If a node's current config replica set name does not match the name in a proposed config via a replSetReconfig command, it will not accept the proposed config -- thus it never considers running an initial sync. ",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
fully support sharding on geo field,SERVER-1982,13444,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-server-sharding,redbeard0531,redbeard0531,Oct 20 2010 09:35:01 PM UTC,Sep 26 2017 01:20:38 PM UTC,Feb 17 2021 11:15:25 AM UTC,,,,,,Backlog,Geo,Sharding,,,58,,,,,,"Currently ""works"" by routing geo queries to all shards. Correct results, but inefficient.",,,,,,,,,,,,SERVER-926,HELP-125,,,,,,,,,,,,,,,,,,,16.0,,,,,,,,,,,,,,,,,,,,,500A000000UaRvnIAF,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2012-02-28 23:29:23.0,206928000,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,,Mon Jul 28 17:11:18 UTC 2014,,,,,,,,No,,,,,,backlog-server-sharding(backlog-server-sharding),bgsosh(bgsosh),eliot(eliot),ignlg(ignlg),zantvoort(zantvoort),redbeard0531(redbeard0531),mkalish(mkalish),jokeyrhyme(jokeyrhyme),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i071y7:",,,,,,,"0|i0c3db:",6209,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i1d7ov:","Feb 28 2012 11:29:23 PM UTC;zantvoort;(Sorry for duplicating this comment, but I think this issue is better suited for it...)

Are there any plans to support sharding on geo key?

As long as this isn't supported, geospatial searching doesn't scale with Mongo, or am I missing something here?","Feb 29 2012 12:00:36 AM UTC;redbeard0531;That is what this case is for.","Feb 29 2012 09:57:26 AM UTC;zantvoort;Hi Mathias,

Since this case is created over 16 months ago ""Planning Bucket A"" is not telling me if this will be picked up within the coming 16 months or later... ;-)

Leon","Feb 29 2012 10:10:09 AM UTC;ignlg;And it's critical since it is the common case scenario for a MongoDB setup.

As an example: Foursquare uses MongoDB mainly because Sharding and Geospatial Index. (#ref http://www.10gen.com/customers/foursquare)

It's ironic that both features aren't compatible yet. I mean: efficient and useful, not a call to all shards.","Feb 29 2012 02:00:23 PM UTC;eliot;A call to all shards scales pretty well, as each shard is doing 1/N the work.
So for large data sets, it can actually be considerably faster.","Feb 29 2012 02:56:38 PM UTC;zantvoort;Hi Eliot,

I would like to use the geo key for sharding, so I can lookup documents near a given location efficiently (and in a scalable way). 

If I understand correctly, if sharding for geo keys would be fully supported, only a single shard is accessed for getting documents near a given location (maybe two shards in case the given location is close to a range boundary). For that reason, it would be a waste of resources, if other shards are accessed, as they don't have any documents near this location.

Thanks,
Leon

 ","Feb 29 2012 04:00:02 PM UTC;eliot;Sort of. 
The problem is that if you search on a boundary, you still might be hitting many shards, so there is no guarantee you only hit 1 shard.


If one shard is handling it, then it may have to look at 1000 documents.
If you have 10 shards, then each shard looks at 100, and mongos merges.

Pros and cons, but I would test sharding by a different key as well.","Feb 29 2012 04:34:24 PM UTC;zantvoort;First of all, thanks for being responsive. This is appreciated!

I'm not sure what the time complexity is of geo spatial queries, but for sake of simplicity say it's O(log n). 

If I apply this to your suggestion, we would get the following:

Geo key is used for sharding: O(log n)
Alternative key is used for sharding (key is not part of search query): O(s log n/s) where s is number of shards and n is total number of documents.

This means that the more shards I add, the quicker each individual shard will find results (performance gain is sublinear), however this needs to be multiplied by the number of shards. 

So from a response time perspective (single user system, weakest link not taken into account), you are right about performance improvement using multiple shards. But from a scalability perspective, this approach will add more and more load on the system as a whole if more shards are added.

","Feb 29 2012 04:43:10 PM UTC;zantvoort;Again, taking O(log n) as an example.

1000 documents, 1 shard would be:
Reponse time: 3
System load: 3

1000 documents equally distribibuted of 10 shards:
Response time: 2
System load: 20

I know there is more to it, but this is the point I'm trying to make.

","Feb 29 2012 04:48:24 PM UTC;redbeard0531;To be clear, you went from 30% to 20% load. Also, by spreading the data out you are able to keep more data in ram which is the #1 determiner of performance. Since having all data in ram is between 1000 (high-end SSD) to 1,000,000 (spinning disk) times faster so is much more important when it comes to scalability than reducing the processing that each server has to do.","Mar 01 2012 09:47:30 AM UTC;zantvoort;You describe the benefits of sharding. I totally agree with you on those positive effects. 

In general, my statement boils down to: 

""Sharding on key 'A' and querying on (solely) key 'B' is not efficient. It is more efficient compared to a non-partitioned approach for the reasons you describe above, but fact remains that all shards are involved in a search if the shard key is not part of the query.""

As long as sharding on geo key is not fully supported, it looks like Mongo behaves like this.","Mar 01 2012 01:07:46 PM UTC;eliot;Yes - but its unclear if that's good or bad in this case.
Have you tried it and seen performance issues?","Mar 01 2012 03:03:34 PM UTC;zantvoort;@Eliot I don't have any performance issues at this moment. I was just checking the (theoretical) scalability properties of geo/sharding in case I do need to scale.

Thanks for the response anyway!","Mar 30 2012 08:41:56 AM UTC;bgsosh;I was exited to see the geo indexing capabilities of mongo, but was dissapointed that this has not been properly implemented with regards to sharding.  IMO this makes geo data a second class citizen in mongo. Are there plans for this to be implemented?","Mar 20 2013 02:16:42 AM UTC;jokeyrhyme;Here's a scenario:
- you have a single MongoDB cluster than spans multiple data-centres across the Earth
- you have application worker instances in each data-centre and geographic DNS routing
- traffic to/from particular data-centres is expensive (e.g. South Africa) or slow (e.g. Singapore)
- it is more important to limit network traffic to a particular zone than it is to optimise query time

I realise you could accomplish this with separate MongoDB clusters, but then you have to maintain application-level logic to know which configurations to use and when. But this is a slippery slope: after all, I can use application-level logic to get sharding to work with MySQL.

To me, the philosophy of MongoDB is to let the DB make intelligent choices about data storage and retrieval. This seems like an entirely reasonable request to increase the ability for MongoDB to make intelligent choices.","Jul 28 2014 05:11:18 PM UTC;mkalish;Any update on when this might make it in?  Seems like this would be vital for operating with multiple, geographically distant data centers.
As far as I can tell, the only real alternative is using the nearest when reading from secondaries, but this does not seem like a satisfactory solution.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
command to change shard key of a collection,SERVER-4000,23132,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-server-sharding,dwight_10gen,dwight_10gen,Oct 02 2011 04:40:31 PM UTC,Aug 26 2017 11:10:28 PM UTC,Feb 17 2021 11:15:25 AM UTC,,,,,,Backlog,Sharding,,,,31,sharding-lifecycle,,,,,"Changing shard keys is fundamentally very expensive, but a helper to do this would be useful.  The main thing needed would be to do the operation with good parallelism.

first cut might require the source collection be read only during the operation.  

might do something like 
- measure what the new distribution would be like by looking at a sampled set of records from the originating collection
- presplit based on statistics above
- cluster wide copy of data from src to dest collection
- build the index(es) for dest after the copy to make things as fast as possible

i suppose this is just a better version of cloneCollection which we'll want anyway.


",,,,,,,,,,,,SERVER-4246,SERVER-14813,,,,,,,,,,,,,,,,,,,15.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2012-03-12 17:44:28.0,159062400,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,kelsey.schubert(thomas.schubert),Tue Feb 02 22:27:17 UTC 2016,,,,,,,,No,,,,,,AnneTheAgile(annetheagile),backlog-server-sharding(backlog-server-sharding),dwight_10gen(dwight_10gen),eliot(eliot),bugslayer(bugslayer),jonhyman(jonhyman),mghosh4@illinois.edu(mghosh4@illinois.edu),mhobbs(mhobbs),tubededentifrice(tubededentifrice),lizhenyu2000(lizhenyu2000),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i06e6v:",,,,,,,"0|i0c2hb:",6025,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i0u3pr:","Mar 12 2012 05:44:28 PM UTC;bugslayer;Not needed very often, but on rare occasion it can become really important. I think the most likely use of this may be to fix a collection that was sharded on a linear key (like a MongoId) and needs to be changed to shard against something else (like a hash of that key).

IMO supporting writes is probably vital. Sharding isn't likely to be used in environments where it would be OK for writes to fail for a prolonged period of time. If triggers are done first you could easily ensure that new data is copied over. The process might be:
 - Create a new sharded destination collection
 - Guess at distribution and presplit
 - Add insert/update/delete triggers on the source collection to clone any changes to the destination collection
 - Copy the data
 - Add the indexes to the destination collection

Also, wondering about some stuff at the end:
 - Sanity checks? (verify that record counts match, possibly other checks?)
 - Rename the collections dest>>src? (lock needed to make this atomic?)
 - Remove the old source collection or not?","Mar 12 2012 07:21:22 PM UTC;mhobbs;A first pass at providing this functionality might be to allow a shard key to be refined. That is, additional fields could be added to an existing key, which would allow more granularity along the existing keys.

We have sometimes discovered that our collections grow in unexpected ways and that a shard key no longer fits in a 64MB chunk. We can currently increase the max chunk size, but ideally, we'd like to redefine the shard key to make it more granular.","Mar 12 2012 07:53:01 PM UTC;eliot;For making a key more granular we should probably add a new case as that's a lot easier to do since it requires no data movement.","Mar 13 2012 05:25:45 PM UTC;mhobbs;One option that doesn't require write locks, triggers, or 2X storage capacity:

The sharding config can have 2 shard configurations per collection - a previous configuration and a current configuration. When a collection is re-keyed, the previous configuration is frozen so that no more splits or migrations are performed based on the previous key. The collection is then re-split and moved about based on the new key. As the data is re-distributed, the previous configuration is *not* updated - it remains frozen. 

When a collection has multiple shard configurations, the mongos processes would distribute operations out to several shards based on both the previous and current configurations. A record will exist in its old shard if it has not yet moved - or it could potentially exist in a new shard if it has been moved. (There is an issue here when non-multi updates, upserts, and inserts do not contain both the previous and the new shard key)

When all chunks are migrated based on the new key, the previous configuration is removed.","Mar 14 2012 02:04:10 AM UTC;eliot;You still have to handle data changes.
If I change the shard key from (a) to (b) the documents in each chunk will be totally different.
The meta data changes aren't so bad - its the actual in flight data that's hard.","Apr 23 2012 05:24:22 PM UTC;mhobbs;Regarding my earlier comment from Mar 13:

I'm sure there are subtleties to the implementation of chunks that I'm not fully appreciating, but if there was a special move operation, though, that could move individual records from one shard to another, it would facilitate the migration of records from one key to another. Perhaps such a move operation could be the first step in solving this problem?

Again, I am ignorant about the implementation of chunks, so forgive me if such an idea is naive.
","Apr 24 2012 04:57:28 AM UTC;eliot;Sadly not that simple.

Lets say you have 100 shards, and you want to change shard key from (a) to (b).
If those keys aren't related, then 99% of the data has to be moved.

So, question is how to do you move data while maintaining state and keeping data live.

More later if your curious...","Jul 25 2014 01:00:31 AM UTC;tubededentifrice;At least there should be a way to unshard a collection when all chunks are on the same shard. This way, to change the shard key you'd simply migrate all the chunks to a single shard, unshard, reshard and rebalance. Not ideal, but could fit some use cases.","Aug 25 2014 11:28:03 PM UTC;lizhenyu2000;I wish there is tool to change the shard key and re-distribute a large amount of data (in TB range). I know you guys can figure this out ;)","Nov 20 2014 08:02:55 PM UTC;AnneTheAgile;@Vincent, that idea of 'unshard-if-one-shard' sounds good. Did you make a ticket for it?","Nov 20 2014 08:21:41 PM UTC;tubededentifrice;@Anne Nope I didn't, I thought this would be enough","Nov 20 2014 09:31:27 PM UTC;AnneTheAgile;@Vincent, it might be  a good idea since this ticket may possibly eventually get implemented in the full version.","Nov 21 2014 10:52:53 AM UTC;tubededentifrice;@Anne, done => https://jira.mongodb.org/browse/SERVER-16264","Dec 22 2015 02:52:56 AM UTC;mghosh4@illinois.edu;Hello,

I am 4th year PhD student in UIUC working with Prof. Indranil Gupta. We have worked on this problem (wrote some code and published a paper). You can find the details of the solution in this link http://dprg.cs.uiuc.edu/docs/ICAC2015/Conference.pdf. We are currently in the process of porting the code to the new Mongo version as the original code was written v 2.2. Let me know if the solution is of interest to you and we can chat about it.

Thanks and Regards,
Mainak Ghosh.","Feb 02 2016 10:27:17 PM UTC;jonhyman;It would also be helpful to be able to extend a shard key for increased cardinality. We are running into an issue where we shard on

{a:1}

and have an index on {a:1, b:1}

and after two years we're starting to see some jumbo chunks. It would be nice to be able to extend the shard key to 

{a:1, b:1}

and have the balancer now be able to split chunks on the added cardinality.

EDIT: I see https://jira.mongodb.org/browse/SERVER-4246 exists for this. I'll vote, thanks.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Provide enterprise MongoDB builds having single-step binary upgrade paths directly from all currently-supported MongoDB release versions.,SERVER-26559,322524,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,server-release,scott.kurowski,scott.kurowski,Oct 10 2016 07:15:23 PM UTC,Jun 27 2017 03:48:41 PM UTC,Feb 17 2021 11:15:25 AM UTC,,,,,,Backlog,Internal Code,,,,2,,,,,,"(e.g., Please formally support drop-in mongod binary build image replacement of [say] 3.0, 3.2, 3.4, 3.8 with a future version 4.0).

Some MongoDB versions have multi-step upgrade paths where one or more intermediate upgrade step(s) is(are) necessary, such as 2.6.3 -> 2.6.12 (latest available patch) -> 3.0.x -> 3.2.x.

The requested feature, if, for example, it had been available in 3.2.x, would have permitted the single-step, direct upgrade of 2.6.3 -> 3.2.x.

*Customer Value*

Configuration change-controls surround high-value big database assets. A customer's introduction of a new MongoDB build binary triggers formal change control testing and gate-keeping requirements in many applications. Enabling formally-supported single-step ""long"" upgrade paths maximizes the efficiency of such customer investments.

The requested feature's customer value effectively:

 (a) spares operating time and budget by cutting the cost of re-qualifying / re-certifying the MongoDB binaries and post-upgrade database for each upgrade path step - as formal change control typically require, and

 (b) ""buys time"" by deferring the must-upgrade path time horizon's approach, extending the post-EOL support ""last chance"" opportunity to upgrade MongoDB.

This efficiency gain is amplified by the non-linear risk-mitigating costs of data at increasing scales, availabilities and reliability, core strengths of MongoDB. It is therefore a potential strategic product priority to the *largest customers* that MongoDB binaries can operate stably upon well-formed (and perhaps auto-repair malformed) ancestor-versioned database metadata, over a time horizon compatible with the budgets and infrastructure upgrade cadence of large data asset holders.

*Second Possible Example Feature Behavior*

Not intended as design guidance, but to convey the customer's value perspective. Say a (future) MongoDB 4.0 binary is swapped-in for a MongoDB 3.0/3.2/3.4 binary that was gracefully shutdown in a known good state, the expectation is that the new 4.0 binary starts up, joins the cluster and operates normally. 'Stepping-up' compatibility levels - upgrading/rebuilding database file structures and enabling new features - may be DBA-directed, or self-coordinated by a critical quorum of 4.0 nodes, or automation-directed under Atlas/Cloud/Ops Manager, etc., but proceeds without intervening-version binaries having to be dropped-in and re-started which can trigger formal (expensive, time-consuming) data, performance and applications re-qualifications.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,500A000000V6HwRIAV,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2016-10-11 01:42:17.0,137376000,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,ramon.fernandez(ramon.fernandez),2016-10-10 19:15:23.0,,,,,,,,,,,,,,server-release(server-release),scott.kurowski(scott.kurowski),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i01ivj:",,,,,,,"0|i1mrg7:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i0wm0f:",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Ability to immediately mark the node as unable to service user queries,SERVER-14983,153981,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-server-repl,alex.komyagin,alex.komyagin,Aug 21 2014 04:32:56 AM UTC,Jun 12 2017 10:29:27 PM UTC,Feb 17 2021 11:15:25 AM UTC,,2.6.4,,,,Needs Further Definition,Replication,Usability,,,1,,,,,,"In production systems there is a common problem scenario when a particular underprovisioned mongod node becomes overloaded by a sudden load peak, causing service timeouts on the application level. In this case a plain retry strategy will add more load to the already overloaded system, frequently causing massive service degradation and prolonged periods of outage.

The ideal, yet very complicated way to gracefully handle the situation is for drivers or mongoS to detect that the node is overloaded and route user traffic away from it (there is a ticket for that, I think). This way the node will be able to process its backlog and successfully get through the issue, without disrupting the service further.

A simpler solution is to defer the judgement to the operator, and give him the ability to immediately mark the node as unable to service user queries.

Functionally, it should be a trigger that meets the following requirements:
# must not block on *anything*, and must take effect *immediately* upon triggering
# In case of error, it must be reported
# If activated, mongoS and drivers must not send new user queries to that node
# serverStatus and/or rs.status() must report the state of the trigger
# The trigger should not require a new connection to be established
# A special override should be supported to allow execution on Primary servers causing them to step down

As it currently stands, we have a replSetMaintenance command, which doesn't yet satisfy 1, 5, or 6. In particular for (1), setting maintenance mode requires a global write lock, which it grabs after locking the replset mutex (see SERVER-14982).

This ticket is filed to provide a functional spec for the feature that we currently don't have. It should give us flexibility with choosing a solution, should we decide to implement something else, other than the replSetMaintenance command.",,,,,,,,,,,,SERVER-5921,SERVER-13925,SERVER-14982,SERVER-16349,,,,,,,,,,,,,,,,,5.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2014-08-21 12:15:39.0,204854400,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,kelsey.schubert(thomas.schubert),Thu Aug 21 14:47:14 UTC 2014,,,,,,,,,,,,,,alex.komyagin(alex.komyagin@10gen.com),backlog-server-repl(backlog-server-repl),milkie(milkie),scotthernandez(scotthernandez),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i03emn:",,,,,,,"0|i0c2r3:",133690,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i0s6qv:","Aug 21 2014 12:15:39 PM UTC;scotthernandez;How is this different than stepdown for the primary, or maintenance mode?","Aug 21 2014 12:32:00 PM UTC;milkie;I think ""stepdown or maintenance mode"" doesn't yet satisfy 1, 5, or 6.  In particular for (1), setting maintenance mode requires a global write lock, which it grabs after locking the replset mutex.","Aug 21 2014 01:18:09 PM UTC;scotthernandez;That sounds like a separate issue wrt locking pre 2.7.

Are you saying we need a mechanism which does not require a network request?

","Aug 21 2014 01:23:19 PM UTC;milkie;I think a network request will be fine, since it will take a network request for drivers (or other nodes) to determine that the state of the node has changed, anyway.","Aug 21 2014 02:47:14 PM UTC;alex.komyagin;Ideally it should not require a network request, but as Eric pointed it, it's not mandatory. 

I apologize for omitting context here. This ticket was filed to provide a functional spec for the feature that we currently don't have. I filed separate tickets for specific issues with the setMaintenance command (see SERVER-13925 and SERVER-14982). Having a separate ticket with a functional spec will give us flexibility should we decide to implement another solution.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Balancer activeWindow calendar support,SERVER-17711,191519,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-server-sharding,luke.prochazka,luke.prochazka,Mar 24 2015 06:11:53 AM UTC,Mar 17 2017 02:07:53 PM UTC,Feb 17 2021 11:15:25 AM UTC,,2.4.14,2.6.10,3.0.1,,Backlog,Sharding,,,,0,,,,,,"Currently the activeWindow only supports single start and stop times independent of date.

This feature request is to add:
# Define day of week/month/year
# recurring schedules
# Schedule exception dates/times",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,186364800,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,schwerin(schwerin),2015-03-24 06:11:53.0,,,,,,,,,,,,,,backlog-server-sharding(backlog-server-sharding),luke.prochazka(luke.prochazka),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i02z93:",,,,,,,"0|i0bxwv:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i0idsf:",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Command to test network connectivity to all hosts,SERVER-4183,24309,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-server-sharding,redbeard0531,redbeard0531,Oct 31 2011 08:11:58 PM UTC,Mar 02 2017 06:19:40 PM UTC,Feb 17 2021 11:15:25 AM UTC,,,,,,Backlog,Admin,,,,0,,,,,,"We've seen many client networking issues that would be much easier to debug if there was an easy way to test connectivity between all nodes. Common examples of failure conditions include over-restrictive firewalls and misconfigured DNS or /etc/hosts.conf.

It would be nice to be able to run a command on mongos that will gather up all ""important"" hosts in the cluster (all config servers, all non-hidden members of all shards), then have everyone test connecting to everyone else. The output would be an N*N matrix that will show any potential networking issues. Ideally this could use the _isSelf command or something similar to make sure that everyone agrees about which server ""host1234"" is.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,293414400,,,,,,,,,,,,,,,,,,,,,,,,,,,,false,milkie(milkie),2011-10-31 20:11:58.0,,,,,,,,No,,,,,,backlog-server-sharding(backlog-server-sharding),redbeard0531(redbeard0531),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i06bzj:",,,,,,,"0|i0bwov:",4827,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i1iuhj:",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Add balancer strategy that balances based on working set estimation,SERVER-9114,69626,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-server-sharding,spencer,spencer,Mar 25 2013 02:36:15 PM UTC,Oct 18 2016 06:30:03 PM UTC,Feb 17 2021 11:15:25 AM UTC,,,,,,features we're not sure of,Sharding,,,,2,balancer,balancingStrategy,chunks,mongos,,Would be nice to have a balancing strategy that uses the working set estimator to pick chunks to migrate based on trying to evenly distribute the working set across shards.,,,,,,,,,,,,SERVER-3294,SERVER-5047,SERVER-2472,SERVER-9120,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2013-03-25 15:59:36.0,249264000,,,,,,,,PM-631,,,,,,,,,,,,,,,,,,,,true,kaloian.manassiev(kaloian.manassiev),Mon Mar 25 15:59:36 UTC 2013,,,,,,,,No,,,,,,backlog-server-sharding(backlog-server-sharding),scotthernandez(scotthernandez),spencer(spencer),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i04p3j:",,,,,,,"0|i0c5sv:",7087,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i1i05j:","Mar 25 2013 02:38:09 PM UTC;spencer;Having a way to group document on-disk order by chunk is likely a prerequisite for this.","Mar 25 2013 03:59:36 PM UTC;scotthernandez;I don't think we need storage by chunk first. Simply moving (active) chunks to the shard with the most effective working set will do it.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Record all replica set config versions,SERVER-15051,155053,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-server-repl,scotthernandez,scotthernandez,Aug 27 2014 11:59:35 AM UTC,Jul 09 2016 10:23:22 PM UTC,Feb 17 2021 11:15:25 AM UTC,,,,,,Backlog,Replication,,,,0,,,,,,"Currently only the latest configuration is persisted on each member (to local.system.replset). It would be very useful to record each configuration change individually for future comparison.

With a history of config docs tools could then be written to find events, like when a host is added or removed, or a what ""majority"" write concern meant at a given time, or to present a history.",,,,,,,,,,,,SERVER-13502,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,Fully Compatible,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2014-08-27 13:58:04.0,204336000,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,ramon.fernandez(ramon.fernandez),2014-08-27 11:59:35.0,,,,,,,,Cannot,,,,,,backlog-server-repl(backlog-server-repl),scotthernandez(scotthernandez),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i03e9b:",,,,,,,"0|i0c2c7:",134718,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i0yubb:",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Automatically re-balance shards/replica-sets, as you add/remove nodes, and allow multiplexing shards/replica-sets on the same node",SERVER-15105,155738,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-server-sharding,victor.hooi,victor.hooi,Sep 01 2014 06:11:12 AM UTC,Dec 14 2015 07:11:16 PM UTC,Feb 17 2021 11:15:25 AM UTC,,2.7.5,,,,features we're not sure of,Sharding,,,,9,,,,,,"In ElasticSearch, each ""index"" (equivalent to a database in our parlance) is split across multiple ""shards"", each of which holds a portion of the data. Shards can be either primary shards, or replica shards (redundant copies of the data).

When you create a ES index, you can specify both the number of shards, and the number of replicas to create. For example, the below will create a index called ""blogs"", which has 3 shards, and 1 replica for each shard:
{code}
PUT /blogs
{
   ""settings"" : {
      ""number_of_shards"" : 3,
      ""number_of_replicas"" : 1
   }
}
{code}
As you add and remove nodes from a cluster, ES will *transparently* handle re-balancing the shards, as well as re-creating replica-shards to maintain the specified number of replicas. ES will not put a primary shard and a replica for that primary shard on the same node - if you don't have enough nodes for it to re-balance properly, it will report the cluster status as degraded (e.g. yellow), until you add another node.

There is a description of the operational semantics in ES's [Life in a Cluster|http://www.elasticsearch.org/guide/en/elasticsearch/guide/current/distributed-cluster.html] document, as well as a discussion of it in Exploring ElasticSearch's [Advanced Topics|http://exploringelasticsearch.com/advanced_techniques.html#advanced-internals] chapter.

So from an operational point of view, it is much simple to manage adding/removing nodes, and changing the number of replicas versus in MongoDB.

Another advantage is that it makes it seamless to multiplex multiple shards onto one node. That is, ES will automatically arrange things so that each node will automatically contain both a primary shard, as well as replica shards for other primary shards:

!02-05_replicas.png!

Cassandra 2.0 does something similar using a replication factor, which is defined per keyspace, however, it's nowhere near as automated and transparent to the end-user as ES.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Sep 01 2014 06:11:12 AM UTC;victor.hooi;02-05_replicas.png;https://jira.mongodb.org/secure/attachment/51139/02-05_replicas.png",,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2014-09-02 14:05:29.0,203817600,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,crystal.horn(crystal.horn@10gen.com),Tue Sep 02 17:25:55 UTC 2014,,,,,,,,,,,,,,backlog-server-sharding(backlog-server-sharding),greg_10gen(greg_10gen),jlpedrosa@gmail.com(jlpedrosa@gmail.com),victor.hooi(victor.hooi),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i03dyn:",,,,,,,"0|i0c3sn:",135372,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i096pr:","Sep 02 2014 02:05:29 PM UTC;greg_10gen;This is a large change to MongoDB's replication and sharding model, as is mentioned above.

> As you add and remove nodes from a cluster, ES will transparently handle re-balancing the shards, as well as re-creating replica-shards to maintain the specified number of replicas.

MongoDB automatic rebalancing currently works in an analogous way given our sharding/replication model, though there's certainly plenty of room for improvement.  It seems like the real thrust of this ticket, in MongoDB terminology, is the replication of chunks across shards to allow for A) simpler administration and B) better distribution of write load in a cluster with the same number of total nodes.

These are both valid goals, but it's not currently clear that this is the only approach to get there - for now, changing the replication model isn't planned.","Sep 02 2014 05:25:55 PM UTC;jlpedrosa@gmail.com;I'd like to add, that this also add some challenges to what current model supports. 
When thinking about site failovers: How the custer should determine if we want both DC actives (with primary nodes)  taking advantage of data/request locality or we are having a disaster recovery site that should only have active shards in case of no other available?
Those scenarios right now can be easily tuned by the DBAs shards and tagging. This model presents a lot of advantages for single site solutions, but a lot of challenges for many other scenarios (from DBA/Developer perspective).

",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Combine Replica Sets and Shards to a single system, using RAID5 style parity",SERVER-3088,16981,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-server-repl,savewave,savewave,May 12 2011 06:57:49 PM UTC,Nov 13 2015 07:19:00 PM UTC,Feb 17 2021 11:15:25 AM UTC,,,,,,features we're not sure of,Replication,,,,0,,,,,,"As discussed at http://groups.google.com/group/mongodb-user/browse_thread/thread/c18a9d181de2e5f6 , it would be tremendously useful for us to be able to use a RAID-5/6 style distributed parity system to combine ReplicaSets with Shards.  

The current system of sharding and using replica sets requires that we have 2x servers as we have shards.
While this does gives us is effectively RAID0+1 level protection.
Every bit is replicated to another server that is ensuring it's safe.

It would dramatically reduce the number of servers that large deployments need, if we could instead use RAID-5/6 style protection.
The RAID5 system would store and distribute a parity block, that allows the other blocks to be reconstructed, using the remaining data, and XOR. 

While I'm sure you know how RAID works, it might be helpful to quickly  review the exact mechanism- 
http://www.scottklarr.com/topic/23/how-raid-5-really-works/ 

So in this system, with 5 shards, we'd use six servers. 
Each shard would store 1/5th of the data, plus a parity block. 

When any one of the systems went down, we could reconstruct it, by using the data remaining on the other 5. 

You can increase redundancy, by increasing the number of parity blocks.
 
RAID6 uses the same system, but two parity blocks, to increase the overall reliability of the system, and ensure it can handle two 
failures at the same time. 



If Mongo were to support such a system, companies could deploy  dramatically fewer servers, while maintaining a very high level of  reliability and failover. ",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2011-05-14 02:56:21.0,308188800,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,crystal.horn(crystal.horn@10gen.com),Sat May 14 03:14:43 UTC 2011,,,,,,,,No,,,,,,backlog-server-repl(backlog-server-repl),savewave(savewave),eliot(eliot),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i06p4v:",,,,,,,"0|i0c2kv:",6550,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i03qon:","May 14 2011 02:56:21 AM UTC;eliot;You can do this manually now.
So if you have 5 servers, you could have 5 shards.
Each node will handle 1 master and 2 secondaries.
","May 14 2011 03:14:43 AM UTC;savewave;I apologize for not understanding-

Do you mean each Physical Hardware server would have one shard server, and two replica sets for shard servers on other machines? 

From my understanding of Mongo Sharding and replication, as described on the web and at http://bit.ly/dm6G9v
Mongo replication requires that each shard consists of 2+ replica set members; The primary, and at least one secondary.

If you had 5 Physical Hardware servers, you could run multiple Mongod instances on each server, giving you redundancy, but it would still require the same number of processes running in total, just spread across fewer machines, right?
That would increase the RAM requirements on each server, versus using explicit parity that is distributed..

Do continue our RAID analogy, If I'm understanding you correctly, you seem to be suggesting partitioning the my drives, and then using RAID 0+1 to mirror partitions.

I still need 2x-1 the server resources that I would with a RAID-5 style setup, no?

I apologize again if I'm missing something.
-CPD
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Add time spent during waitUntilOptime on OpDebug,SERVER-20430,229937,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-server-repl,renctan,renctan,Sep 15 2015 10:07:38 PM UTC,Nov 13 2015 06:41:22 PM UTC,Feb 17 2021 11:15:25 AM UTC,,3.1.8,,,,Backlog,Diagnostics,Replication,,,1,,,,,,"This can help in diagnosing time spent on doing read after optime, by including that information in the slow query log messages.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,171158400,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,crystal.horn(crystal.horn@10gen.com),2015-09-15 22:07:38.0,,,,,,,,,,,,,,backlog-server-repl(backlog-server-repl),renctan(renctan),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i02jvr:",,,,,,,"0|i0c29z:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i0xt4v:",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Add command to manage the slave map,SERVER-15427,160554,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-server-repl,scotthernandez,scotthernandez,Sep 26 2014 07:57:52 PM UTC,Nov 13 2015 06:41:20 PM UTC,Feb 17 2021 11:15:25 AM UTC,,,,,,Backlog,Replication,,,,0,,,,,,"For diagnostic purposes it would be good to be able to get access to the slave map, and/or clear it. It might also be useful to manually add/update it.

I'm thinking something like:
{code}
db.adminCommand({replSetSlaveMap:1}) // dumps
{ rid:   { _id:x, host:.., optime:OpTime}, 
  rid2: { _id:x, host:.., optime:OpTime}}
db.adminCommand({replSetSlaveMap:1, reset:true}) // clears/resets
db.adminCommand({replSetSlaveMap:1, update:{rid:OpTime}}) // updates  ember
{code}",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,201744000,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,crystal.horn(crystal.horn@10gen.com),2014-09-26 19:57:52.0,,,,,,,,,,,,,,backlog-server-repl(backlog-server-repl),scotthernandez(scotthernandez),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i03c6n:",,,,,,,"0|i0c26n:",139854,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i0yrjz:",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Sharding on arrays,SERVER-2065,13629,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-server-sharding,bugslayer,bugslayer,Nov 05 2010 09:01:24 AM UTC,Nov 12 2015 05:56:23 PM UTC,Feb 17 2021 11:15:25 AM UTC,,,,,,features we're not sure of,Sharding,,,,2,,,,,,"Consider the following:

conversation
{
  users: [id1, id1, id3, ...],
  ...other conversation data...
}

Displaying a list of a single user's conversations with no further restrictions is impossible without querying every shard. Even restructuring the collection doesn't fix the problem.

This can be worked around at the application level by creating and maintaining a separate collection with one entry per user, but that isn't very elegant. If the user needs to be able to arbitrarily filter their list of conversations, this gets worse, because most or all of the data needs to be available at query time, and therefore a large amount of data needs to be duplicated per user.

When duplicating at the code level, it is necessary to create one duplicate per entry, regardless of whether they actually get placed on different shards, because they MAY get placed on different shards, or may get rebalanced to another shard later. Sharding based on array contents would still require duplication sometimes, but it could be greatly reduced, and may not require any duplication at all if all entries in the array resolve to the same shard.

The logical implementation for this is actually fairly straightforward:

Insert:
1. look at the elements in the array and determine which shards are within range of any of the elements
2. Insert the record on each shard

Update:
1. look up the complete sharded array from any copy of the record using the provided shard key
2. If the sharded array is being modified, determine whether the list of shards it resides on will change, and remove from or insert to those shards as needed.
3. Update the record on all shards

Delete:
1. look up the complete sharded array from any copy of the record using the provided shard key
2. remove from all shards it resides on

I don't know for sure whether or not this would complicate re-balancing, but I don't think so. Unless I've missed something you SHOULD be able to treat each value as effectively distinct for this. When you split the chunk, just split the records as needed. The catch here is that the actual gains may be somewhat unpredictable, especially when the split was inspired by high disk space use. In any case though, it couldn't be any _worse_ than having to duplicate everything all the time, even when it isn't needed.",,,,,,,,,,,,CS-4860,,,,,,,,,,,,,,,,,,,,3.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2011-08-16 17:46:16.0,285811200,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,crystal.horn(crystal.horn@10gen.com),Sat Jan 28 04:33:43 UTC 2012,,,,,,,,No,,,,,,backlog-server-sharding(backlog-server-sharding),eliot(eliot),bugslayer(bugslayer),jdcoder36(jdcoder36),redbeard0531(redbeard0531),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i070xz:",,,,,,,"0|i0c46n:",6603,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i1dxtz:","Aug 16 2011 05:46:16 PM UTC;redbeard0531;If we decide to support this in the future will need to undo restrictions in SERVER-3586","Jan 27 2012 04:29:37 AM UTC;jdcoder36;How would this affect find()? Would more than one result be returned when there is a match on more than one element in the array ($in)?

Currently I duplicate entires for documents that are 'imitating' sharding on an array, but I have to identify duplicates when searching the collection and remove them at the 'code level' (at least until distinct() is a cursor ).

Even if the gains in disk space are marginal this could be a good idea to simplify searching as well.","Jan 28 2012 04:33:43 AM UTC;eliot;@julian - you would never get more than 1 copy of a document ",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Store config server data in accessible, redundant collection in mongos itself for disaster recovery",SERVER-2613,14858,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-server-sharding,kbanker,kbanker,Feb 23 2011 06:48:49 PM UTC,Nov 12 2015 05:56:20 PM UTC,Feb 17 2021 11:15:25 AM UTC,,,,,,Backlog,Sharding,,,,0,,,,,,"There have been a number of situations where users have entirely lost their config data (usually because they're running just one config server). 

It might be useful to store an easily accessible copy of the config database in each mongos. As long as they still have a single mongos online, the recovery of the data could be greatly simplified.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2011-02-23 22:23:22.0,315014400,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,crystal.horn(crystal.horn@10gen.com),Wed Feb 23 22:23:22 UTC 2011,,,,,,,,No,,,,,,backlog-server-sharding(backlog-server-sharding),eliot(eliot),kbanker(kbanker),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i06unz:",,,,,,,"0|i0bwzj:",4925,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i1i2kn:","Feb 23 2011 10:23:22 PM UTC;eliot;Would be easy to add a command to write config to a new server.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
provide an option to deny global queries (queries running on all shards),SERVER-6497,44607,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-server-sharding,alonho,alonho,Jul 17 2012 09:20:21 PM UTC,Nov 12 2015 05:56:18 PM UTC,Feb 17 2021 11:15:25 AM UTC,,,,,,Backlog,Admin,Sharding,,,3,,,,,,"global queries can be sent innocently to a large cluster and hurt it's overall performance. In many systems global queries are intentionally avoided in order to make the system truly scalable (see a more elaborate explanation about the scale issue in the next paragraph).
This issue attempts to request a collection level configuration that won't allow global queries, in other words, require the query to contain a shard key.

Why global queries don't scale?:
Usually there is a correlation between the size of the data and the number of queries per second invoked. Take for example a social network implementation: you start off with one shard and 1000 users. when you find yourself with 50 shards and 50000 you make 50 times more queries. if queries are global, the more users you have, the more shards you have, more queries are invoked per shard. I've heard MongoDB devs say before: each shard is doing 1/50 of the work. well that might be true for some map reduce queries, but not for many other simple queries.
Another killer example is the system i'm working on: A 50 shard cluster scattered across the U.S, do I really want to suffer cross data center latencies for each query? I think not.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2014-07-08 07:43:18.0,270950400,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,crystal.horn(crystal.horn@10gen.com),2012-07-17 21:20:21.0,,,,,,,,No,,,,,,alonho(alonho),backlog-server-sharding(backlog-server-sharding),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i05kcf:",,,,,,,"0|i0c1zb:",5918,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i1hz33:",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Make mongos connection pool more configurable for users with large #s of shards,SERVER-4466,26345,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Major - P3,,backlog-server-sharding,greg_10gen,greg_10gen,Dec 09 2011 08:13:42 PM UTC,Nov 12 2015 05:56:10 PM UTC,Feb 17 2021 11:15:25 AM UTC,,2.1.0,,,,Backlog,Sharding,,,,2,,,,,,"If users have very large numbers of shards, the default connection pool behavior may open too many unnecessary connections.  It would be good to make this more configurable, at least to allow a configurable limit of baseline connections.",,,,,,,,,,,,SERVER-1714,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2011-12-11 05:15:26.0,289958400,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,crystal.horn(crystal.horn@10gen.com),Sun Dec 11 05:15:26 UTC 2011,,,,,,,,No,,,,,,backlog-server-sharding(backlog-server-sharding),eliot(eliot),greg_10gen(greg_10gen),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i068on:",,,,,,,"0|i0c2e7:",5995,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i1i2en:","Dec 11 2011 05:15:26 AM UTC;eliot;I think the more important part is better multiplexing SERVER-1714",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Install a registry key with the path to the current version's installation directory on Windows,SERVER-22825,267607,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Minor - P4,,backlog-server-build,trevork4001,trevork4001,Feb 24 2016 12:41:22 AM UTC,Feb 14 2021 03:34:33 AM UTC,Feb 17 2021 11:15:25 AM UTC,,3.0.7,3.3.2,,,Needs Further Definition,Packaging,,,,0,,,,,,"Mongo is installing to directories defined by its major version on Windows. 
https://github.com/mongodb/mongo/blob/master/src/mongo/installer/msi/wxs/Installer.wxs

For the benefit of other installers that depend on mongo and need to execute command line procedures, it would be helpful if the installation directory of the currently installed version was accessible from a registry key. For example:
HKLM\SOFTWARE\MongoDB\Server\CurrentVersion with a registry value named ""Path"" with value ""HKEY_LOCAL_MACHINE\SOFTWARE\MongoDB\Server\3.0""",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,157248000,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,ian.whalen(ian@10gen.com),Wed Feb 24 01:50:00 UTC 2016,,,,,,,,,,,,,,backlog-server-build(backlog-server-build),trevork4001(trevork4001),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i024gf:",,,,,,,"0|i00nmu:zzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzy",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i0i233:","Feb 24 2016 01:50:00 AM UTC;trevork4001;A comment to correct the copy and paste error:
HKLM\SOFTWARE\MongoDB\Server\CurrentVersion with a registry value named ""Path"" with value ""C:\Program Files\MongoDB\Server\3.0""
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
ARM binaries for Debian 10,SERVER-44532,995141,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Minor - P4,,backlog-server-build,philipp@kolmann.at,philipp@kolmann.at,Nov 09 2019 08:47:33 PM UTC,Feb 12 2021 12:08:32 AM UTC,Feb 17 2021 11:15:25 AM UTC,,4.2 Required,,,,Backlog,Build,,,,0,,,,,,"I would love to see a native Mongo-Org Debian .deb for armhf architecture to install on my NAS.

Thanks

Philipp",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,5002K00000oapdDQAQ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2019-11-20 00:56:26.0,39312000,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,ian.whalen(ian@10gen.com),Wed Nov 20 00:56:26 UTC 2019,,,,,,,,,,,,,,backlog-server-build(backlog-server-build),brian.lane(brian.lane),philipp@kolmann.at(philipp@kolmann.at),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i4kssn:",,,,,,,"0|i00nmu:zzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzr",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i4kqwf:","Nov 09 2019 08:48:39 PM UTC;philipp@kolmann.at;This was once already requested:

 

https://jira.mongodb.org/browse/SERVER-1811?focusedCommentId=1971007&page=com.atlassian.jira.plugin.system.issuetabpanels%3Acomment-tabpanel#comment-1971007","Nov 20 2019 12:56:26 AM UTC;brian.lane;Hi [~philipp@kolmann.at],

For ARM we currently only offer support for Ubuntu.  I have put this request in the backlog for consideration for a future release.  In the upcoming 4.4 release of MongoDB, we do plan to continue to support ARM on Ubuntu but do not plan to expand ARM support to other Linux distributions at this time.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Publish RPM repos under workstation and computenode version directories,SERVER-32651,481349,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Minor - P4,,backlog-server-build,ernie.hershey,ernie.hershey,Jan 10 2018 10:55:37 PM UTC,Feb 12 2021 12:08:23 AM UTC,Feb 17 2021 11:15:25 AM UTC,,3.6.2,,,,Backlog,Packaging,,,,1,,,,,,"Right now we publish to two locations for each major RedHat version - ""5"" and ""5Server""; ""6"" and ""6Server"" etc. 

[RedHat's repo|http://ftp.redhat.com/pub/redhat/linux/enterprise/] includes additional ""Workstation"" and ""ComputeNode"" variations that we should consider publishing as well. ",,,,,,,,,,,SERVER-24472,FREE-146996,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2018-05-11 20:42:21.0,87436800,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,ian.whalen(ian@10gen.com),Fri May 11 20:42:21 UTC 2018,,,,,,,,,,,,,,backlog-server-build(backlog-server-build),chengas123(chengas123),ernie.hershey(ernie.hershey@10gen.com),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i25sc7:",,,,,,,"0|i00nmu:zzzzzzzzzzzzzzzzzzzzzzzzzzzzzzw",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i25qfz:","May 11 2018 08:42:21 PM UTC;chengas123;Duplicate of https://jira.mongodb.org/browse/SERVER-24472",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Add configuration options to /etc/sysconfig/mongod for easier configuration mongod,SERVER-5094,31549,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Minor - P4,,backlog-server-build,tomassrnka,tomassrnka,Feb 25 2012 10:38:02 AM UTC,Feb 12 2021 12:07:31 AM UTC,Feb 17 2021 11:15:25 AM UTC,,2.0.0,2.0.1,2.0.2,2.1.0,Backlog,Packaging,,,,0,build-later,build-needs-definition,configuration,packages,replicaset,"Hi,

I would like to see some options for easier configuration of mongo replica-sets. That's why I've modified the init script and configuration files to do so. Also, I have created a simple shell script for generating keyfile.

You can find the patch on github: https://github.com/mongodb/mongo/pull/174",RHEL 6 compatible systems,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,283392000,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,ian.whalen(ian@10gen.com),2012-02-25 10:38:02.0,,,,,,,,No,,,,,,backlog-server-build(backlog-server-build),tomassrnka(tomassrnka),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i061dj:",,,,,,,"0|i00nmu:zzzzzzzzzzzzzzzzzzzzzw",6425,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Unneeded,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i0skon:",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Support Capped Collection Size Increase,SERVER-1864,13205,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Minor - P4,,backlog-server-execution,nadahalli,nadahalli,Sep 27 2010 09:43:17 PM UTC,Feb 11 2021 11:44:08 PM UTC,Feb 17 2021 11:15:25 AM UTC,,1.7.0,,,,Backlog,Storage,,,,62,,,,,,"Pre-allocating capped collection sizes is quite hard. Most estimates turn out right; but once in a while, I regret a production-used cap-size. Right now, the only(?) way to increase size of a capped collection is to allocate space on disk by piping zeros, creating a new capped collection, copy elements from src. to dest. and finally, rename dest. to src.

If there are better ways to do this, please let me know.

If this becomes a feature in the server; that'd be great.

",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2011-03-03 20:52:40.0,314323200,,,,,,,,PM-223,,,,,,,,,,,,,,,,,,,,true,ian.whalen(ian@10gen.com),Thu Mar 03 20:52:40 UTC 2011,,,,,,,,No,,,,,,backlog-server-execution(backlog-server-execution),jsmestad(jsmestad),nadahalli(nadahalli),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i073cv:",,,,,,,"0|i00cdr:",6219,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i1izr3:","Mar 03 2011 08:52:40 PM UTC;jsmestad;We would love to see this feature make it into MongoDB 1.9 if possible. Capped collections are somewhat crippled until then since they are possibly the only limit in MongoDB with regards to effective changing of schema design/implementation.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
create db.exists() and collections.exists(),SERVER-1938,13361,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Minor - P4,,massimiliano.marcon,brennan,brennan,Oct 13 2010 06:50:30 PM UTC,Feb 11 2021 04:11:41 PM UTC,Feb 17 2021 11:15:25 AM UTC,,,,,,Backlog,Shell,,,,32,,,,,,Add a db.exists() and collections.exists() so that it is easy to check whether a database or a collection exists.  This will help to reduce the propensity to inadvertently create new dbs and collections when running a script due to typos.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,14.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2010-12-07 23:10:54.0,432000,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,massimiliano.marcon(massimiliano.marcon),Thu Feb 11 16:11:41 UTC 2021,,,,,,,,No,,,,,,asya(asya),brennan(brennan),ctonhaeuser(ctonhaeuser),fgm@osinet.fr(fgm@osinet.fr),sunrize531@gmail.com(sunrize531@gmail.com),pcheese(pcheese),jak@ucop.edu(jak@ucop.edu),jonatanb@misterbit.co.il(jonatanb@misterbit.co.il),massimiliano.marcon(massimiliano.marcon),nvolynets(nvolynets),nipra(nipra),smilesrg(smilesrg),wernfried.domscheit@sunrise.net(JIRAUSER1257089),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i072hb:",,,,,,,"0|i05plj:",4715,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i0fo5b:","Dec 07 2010 11:10:54 PM UTC;pcheese;We would also find it useful to have a shortcut to check whether a collection exists. Currently (using the PHP driver) we're checking whether the collection is present in system.namespaces, similar to how the MongoCollection class in the PHP driver implements listCollections.","Apr 26 2011 10:19:24 AM UTC;nipra;MapReduce operation throws error if collection doesn't exist. Need a quick way to check whether coll exists or not before starting MapReduce operation.","Apr 01 2013 08:01:47 AM UTC;smilesrg;This can be a great feature. While it still doesn't exists, programmers have to use db.collection.find().limit(1) to check if the document exists. See this article:
http://blog.serverdensity.com/checking-if-a-document-exists-mongodb-slow-findone-vs-find/","Feb 12 2014 09:31:02 AM UTC;nvolynets;Moreover in case of Mongo Security ""readWrite"" role - there is no way of checking db existence that doesn't lead to its creation.
Please increase priority of this issue.","Jan 03 2016 01:56:13 AM UTC;jak@ucop.edu;Yes, please increase priority of this issue.  ","Feb 25 2016 08:28:40 AM UTC;ctonhaeuser;+1 for increasing the priority of this feature.
We need to do a lot of stupid things in our code in order to make sure a DB exists without accidently creating it.
Would be perfect if we could do without that...

An even better alternative would be that getDB() and getCollection() calls get an optional flag to prevent automatic creation of DBs/collections and rather let the call fail.","Aug 16 2018 10:16:36 PM UTC;asya;{noformat}
db.getSiblingDB(""foobar"").xxx.stats()
{
   ""ns"" : ""foobar.xxx"",
   ""ok"" : 0,
   ""errmsg"" : ""Database [foobar] not found.""
}
db.xxxxxxxxxxx.stats()
{
   ""ns"" : ""test.xxxxxxxxxxx"",
   ""ok"" : 0,
   ""errmsg"" : ""Collection [test.xxxxxxxxxxx] not found.""
} {noformat}","Nov 30 2018 03:00:01 PM UTC;sunrize531@gmail.com;I get I'm supposed to call {{listCollections}} with a query to do this, but it places DB lock for some reason. I have a database with a 1000s of collections and i need to check if new ones were added quite often, from different processes. Also I can't have them accidentally created because of indexing stuff, so I need to run {{listCollections}} basically on every connection attempt. As a result I'm having queues building up. 

I've worked around that by caching the results of {{listCollections}} calls in memory for specific collections, but it would break as soon as I decided to drop some of those collection for any reason (in fact i actually want to do this).

I could also do {{collStat}}, and there's nothing in docs that suggests locks (though there still might be some that were not documented), but there's a different problem with it. When it fails because the collection doesn't exist - it fails fast, which is fine. But when the collection exists it gets predictably slow, cause it does need some time to gather all the data it returns.

So yeah, +1 please.","Jan 22 2020 05:00:35 PM UTC;jonatanb@misterbit.co.il;Adding another idea,
collection.insertOne / insertMany could return a flag on whether the collection exists or did this operation created the collection in the process.
We need to perform multiple operations whenever a new collection is created, and checking for listCollection on every insert is bad...
We're currently  caching the collection list like Ivan does but still

so +1 as well. thanks...","Apr 18 2020 08:01:37 PM UTC;fgm@osinet.fr;The solution suggested by @asya does work with current versions (4.2). With a non existent database, we no longer get an error:


{noformat}
> db.getSiblingDB('logger').xxx.stats()
{ 
  ""ns"" : ""logger.xxx"", 
  ""size"" : 0, 
  ""count"" : 0, 
  ""storageSize"" : 0, 
  ""nindexes"" : 0, 
  ""totalIndexSize"" : 0, 
  ""indexSizes"" : { 

  }, 
  ""scaleFactor"" : 1, 
  ""ok"" : 1
}
> db.xxxxxxx.stats()
{ 
  ""ns"" : ""logger.xxxxxxx"", 
  ""size"" : 0, 
  ""count"" : 0, 
  ""storageSize"" : 0, 
  ""nindexes"" : 0, 
  ""totalIndexSize"" : 0, 
  ""indexSizes"" : {

  }, 
  ""scaleFactor"" : 1, 
  ""ok"" : 1
}{noformat}
 ","Apr 20 2020 12:40:37 AM UTC;asya;[~fgm@osinet.fr] I assume you mean it no longer works...

In fact, it does work but it's changed.

If the database does not exist, then stats shows 
{noformat}
	""collections"" : 0,
	""views"" : 0,
	""objects"" : 0,
	""avgObjSize"" : 0,
	""dataSize"" : 0,
	""storageSize"" : 0,
	""numExtents"" : 0,
	""indexes"" : 0,
	""indexSize"" : 0,
{noformat}

Once anything is created in the DB, you would see:
{noformat}
	""collections"" : 1,
etc.
{noformat}

To be honest I don't really understand what it means for the database to exist - if it has nothing in it.
Or for a collection for that matter.   

Maybe someone can explain why they need this functionality with some examples.
","Apr 20 2020 10:06:52 AM UTC;fgm@osinet.fr;In the specific case I need this for, the need arises when checking the schema for one specific collection which needs to be capped. But if I just ""create"" the collection then run ""convertToCapped"", the convertion command fails with an error reporting the database does not exist. I don't won't to touch the collection if it already exists, which I can't know if it is empty.

The problem is that ""createCollection"" does not actually create the collection, so does not create the database. But then the convertToCapped fails because of that.

Workaround: before running the conversion command, I insert a dummy row in the collection, which this time actually creates the database to hold the collection, then the collection. After which I can remove the document, then run the conversion works, and finally get the fresh new empty capped collection.

 ","Feb 11 2021 10:30:54 AM UTC;wernfried.domscheit@sunrise.net;Would this workaround be sufficient? 
{code:java}( db.adminCommand( { listDatabases: 1, nameOnly: true, filter: { name: ""database_name"" } } ).databases.length ) > 0
(db.getCollectionNames().indexOf(""collection_name"") > -1)
{code}
 ","Feb 11 2021 04:11:41 PM UTC;massimiliano.marcon;Tracking this request in our feedback portal to be considered for the new [MongoDB Shell|https://www.mongodb.com/products/shell]: https://feedback.mongodb.com/forums/929233-mongodb-shell/suggestions/42686618-add-support-for-db-exists-and-collections-exists",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
new feature to consider: low priority operations / graceful degradation,SERVER-3783,22000,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Minor - P4,,backlog-server-execution,dwight_10gen,dwight_10gen,Sep 08 2011 04:19:15 PM UTC,Feb 10 2021 07:47:56 PM UTC,Feb 17 2021 11:15:25 AM UTC,,,,,,Backlog,Querying,Stability,Storage,,4,,,,,,"concept is to tag operations (queries or writes) as ""optional"" so that the server can drop them when under excessive load.  under normal circumstances they all occur; however if utilization is 100% they are dropped so that graceful degradation is achieved.  MMS would graph the number of drops and thus one could alert off of that.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,297993600,,,,,,,,PM-1723,,,,,,,,,,,,,,,,,,,,false,ian.whalen(ian@10gen.com),2011-09-08 16:19:15.0,,,,,,,,No,,,,,,backlog-server-execution(backlog-server-execution),dwight_10gen(dwight_10gen),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i06gqn:",,,,,,,"0|i00byv:",5103,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i1i37r:",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
ninja tool should process content signatures for subst expansions,SERVER-54253,1610644,New Feature,Backlog,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Minor - P4,,backlog-server-devplatform,daniel.moody,daniel.moody,Feb 03 2021 05:14:10 PM UTC,Feb 09 2021 03:23:18 PM UTC,Feb 17 2021 11:15:25 AM UTC,,,,,,,,,,,0,,,,,,"The ninja tool ignores content signatures generated by subst expansions. Normally this is not a problem because most subst expansions don't produce a different content signature from their own expansion, but in some cases (like SERVER-49299) the user will provide an alternate content signature from the expansion. 

 

This means ninja will incorrectly not rebuild certain items because it lacks information regarding a subst expansion. Possibly ninja could re-perform the subst expansion for signature checking to determine if it needs to rebuild by extracting the python code in some form and running it in a scons context. It would be hard.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,1123200,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,acm(acm),2021-02-03 17:14:10.0,,,,,,,,,,,,,,backlog-server-devplatform(backlog-server-devplatform),daniel.moody(JIRAUSER1253549),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i7h4rr:",,,,,,,"0|i3f1fb:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i7h2vb:",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Memory policy update from the mongod process,SERVER-24133,286243,New Feature,Investigating,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Minor - P4,,michael.gargiulo,ricardo.lorenzo,ricardo.lorenzo,May 12 2016 08:41:42 AM UTC,Feb 05 2021 03:55:47 PM UTC,Feb 17 2021 11:15:25 AM UTC,,,,,,,Admin,Internal Code,,,3,,,,,,"As per the [Linux kernel documentation|https://www.kernel.org/doc/Documentation/vm/numa_memory_policy.txt], there are three different system calls to control the memory policy. These calls always affect only the calling task, the calling task's address space, or some shared object mapped into the calling task's address space.

- [set_mempolicy|http://linux.die.net/man/2/set_mempolicy]
- [get_mempolicy|http://linux.die.net/man/2/get_mempolicy]
- [mbind|http://linux.die.net/man/2/mbind]

The {{MPOL_INTERLEAVED}} mode specifies that page allocations be interleaved, on a page granularity, across the nodes specified in the policy. As mentioned before, those calls always affect only the calling task, so there is no way to invoke them outside of the specific process.

The {{numactl}} tool is packaged with the run-time version of the library containing the memory policy system call wrappers. This tool is convenient and flexible in order to run {{mongod}} and modify the memory policy for the process.

However, is there any chance for {{mongod}} to use the API calls to set the policy without requiring {{numactl}}? It will be easier for the users if this can be done in a transparent way.",,,,,,,,,,,,SERVER-18763,,,,,,,,,,,,,,,,,,,,1.0,3.0,,,,,,,,,,,,,,,,,,,,5002K00000hvU1YQAU,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2016-05-12 14:19:13.0,16156800,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,michael.gargiulo(michael.gargiulo),Thu Aug 13 19:50:14 UTC 2020,,,,,,,,,,,,,,connie.chen(connie.chen),michael.gargiulo(michael.gargiulo),ricardo.lorenzo(ricardo.lorenzo),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i01x9j:",,,,,,,"0|i00csn:",9223372036854775807,,,,,,,,,,,,Execution Team 2020-11-16,Execution Team 2020-11-30,Execution Team 2021-03-22,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i0x3s7:","Aug 13 2020 07:50:14 PM UTC;connie.chen;[~michael.gargiulo] to review if this is still needed. ",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Collation for Maori,SERVER-51229,1495491,New Feature,Investigating,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Minor - P4,,kateryna.kamenieva,blair@dataventures.nz,blair@dataventures.nz,Sep 30 2020 12:32:56 AM UTC,Feb 05 2021 01:35:13 PM UTC,Feb 17 2021 11:15:25 AM UTC,,,,,,,Querying,,,,0,,,,,,"I'm happy to supply the information for collation in any form you want.

If you have a native form, and documentation around that, I am happy to do the work to get it into that form, so you don't have to do a lot of heavy lifting.

Māori is the one of the 2 official languages for New Zealand (English being the other).

It is in relative common usage, and Atlas has finally been approved for Government use here. So, now is the time to add it.

I am happy to create whatever files you need in whatever form you need for it.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,3.0,3.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2020-09-30 00:50:43.0,12009600,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,ana.meza(JIRAUSER1257467),Wed Sep 30 15:05:14 UTC 2020,,,,,,,,,,,,,,blair@dataventures.nz(JIRAUSER1257098),pasette(dan@10gen.com),kateryna.kamenieva(kateryna.kamenieva),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i6xezz:",,,,,,,"0|i72vfb:",9223372036854775807,,,,,,,,,,,,Query 2021-01-11,Query 2021-01-25,Query Execution 2021-02-22,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i6xd3j:","Sep 30 2020 12:50:43 AM UTC;pasette;Thanks for filing this. MongoDB vendors collation data from ICU and is currently using [version 57.|http://site.icu-project.org/download/57]

Support for Māori was introduced in [version 63|http://site.icu-project.org/download/63]. We will have to undertake an upgrade to the new ICU package to incorporate new languages. I'll send this to the query product team for evaluation.","Sep 30 2020 01:22:40 AM UTC;blair@dataventures.nz;Thank you so much!

This means a lot to us.","Sep 30 2020 03:05:14 PM UTC;pasette;[~kateryna.kamenieva], I was chatting with [~david.storch] about this. Mechanically it's easy to upgrade, but there are questions about whether there is a guarantee that for a given collation, ICU 57 and ICU 63 give you the same collation key since we store those in the index so there is an index compatibility concern that needs to be investigated",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Implement a switch over between local master encryption key and KMIP master encryption key,SERVER-54060,1601200,New Feature,Investigating,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Minor - P4,,salman.baset,andrey.brindeyev,andrey.brindeyev,Jan 26 2021 09:00:59 PM UTC,Feb 01 2021 07:10:42 PM UTC,Feb 17 2021 11:15:25 AM UTC,,,,,,,,,,,3,,,,,,"The existing procedure for the switch over from a local master encryption key to a KMIP master encryption key for the Encryption-at-Rest feature requires a wipe-out of the dbPath in the server, followed by a resync.

Given the size of replica sets in the field, it makes sense to extend the existing KMIP key rotation feature (SERVER-19845), so the customers can move between KMIP and local encryption keys back and forth, avoiding the initial sync procedure. This will save time and data transfer costs.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,5002K00000s2JRMQA2,5002K00000sahutQAA,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,1814400,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,sara.williamson(sara.williamson),2021-01-26 21:00:59.0,,,,,,,,,,,,,,andrey.brindeyev(andrey.brindeyev),salman.baset(salman.baset),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i7fijr:",,,,,,,"0|i799en:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i7fgnb:",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Don't truncate 'comment' command parameter in the slow query logs,SERVER-36441,583224,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Minor - P4,,backlog-query-execution,harshad.dhavale,harshad.dhavale,Aug 03 2018 06:34:56 PM UTC,Jan 29 2021 05:47:29 PM UTC,Feb 17 2021 11:15:25 AM UTC,,,,,,Backlog,Diagnostics,Querying,,,3,,,,,,"*ISSUE DESCRIPTION*

 

Currently, the following behavior is observed for the $comment field displayed in the mongodb logs.
 * The $comment field's length gets truncated to 150 characters, when it is captured in the logs.
 * Increasing the value for maxLogSizeKB, makes no difference. The $comment field length still gets truncated in the logs at 150 characters.

----
*REPRODUCER*

 

1. The following command can be run in the _mongo shell_ - note the `AB` at the end of the $comment string:

 
{code:java}
replset:PRIMARY> db.<collectionName>.aggregate([ { $match: { $comment: ""XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXAB""} } ]){code}
 

2. In the logs it will be observed that the $comment field gets truncated (note the `...` and no `AB` at the end):
{code:java}
command test.<collectionName> appName: ""MongoDB Shell"" command: aggregate { aggregate: ""<collectionName>"", pipeline: [ { $match: { $comment: ""XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX..."" } } ]{code}
3. Performing a character count on the length of the $comment field (the ""XXXX..."") will show they are `150 `characters.

 
----
*FEATURE REQUEST*

Requesting for a feature that allows for changing the length of the $comment field displayed in the logs.

 ",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,8.0,,,,,,,,,,,,,,,,,,,,,500A000000bUiSRIA0,5002K00000cyKRdQAM,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2018-08-03 20:33:34.0,59270400,,,,,,,,PM-2154,,,,,,,,,,,,,,,,,,,,true,craig.homa(craig.homa),Tue Apr 02 17:06:20 UTC 2019,,,,,,,,,,,,,,acm(acm),asya(asya),backlog-query-execution(JIRAUSER1257109),bartle(bartle),david.storch(david.storch),harshad.dhavale(harshad.dhavale),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i2n0qv:",,,,,,,"0|i00rkv:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i2myun:","Sep 06 2018 05:27:52 PM UTC;david.storch;Hi [~harshad.dhavale],

Thanks for the improvement request. We made a similar improvement to the output of {{$currentOp}} under SERVER-27439, but these changes did not apply to the slow query log. Note that we also improved the aggregate command to accept a top-level comment parameter (SERVER-28128).

When we [log CurOp::_opDescription|https://github.com/mongodb/mongo/blob/dfca02c17d430b7b983157154055a58939b22372/src/mongo/db/curop.cpp#L518-L538], we end up invoking [BSONObj's operator<< overload for StringBuilder|https://github.com/mongodb/mongo/blob/dfca02c17d430b7b983157154055a58939b22372/src/mongo/bson/bsonobj.h#L582]. The default behavior of this overload is to [truncate long strings to 150 bytes|https://github.com/mongodb/mongo/blob/dfca02c17d430b7b983157154055a58939b22372/src/mongo/bson/bsonelement.cpp#L778-L787]. This is true anywhere that we dump a BSONObj to a string (without explicitly specifying to print the entire object). This is important to ensure that long strings from user input do not cause other relevant information to be truncated from log lines or other debug output. Therefore, we would not make a general change to the stringification of BSONObj, but rather would fix this by writing special code to avoid the truncation of the {{comment}} field.

The most likely fix would apply to the {{comment}} find and aggregate command parameter, but not to the [$comment match expression operator|https://docs.mongodb.com/manual/reference/operator/meta/comment/]. For this reason, I would strongly encourage users who rely on {{$comment}} to switch over to the comment command parameter. Currently, only find and aggregate support the comment parameter, but SERVER-29794 would add support for all commands.","Sep 06 2018 06:59:35 PM UTC;harshad.dhavale;Hi [~david.storch],

Thanks for the detailed explanation of why the comment field gets truncated at 150 characters and the related details. That makes sense. A fix for the _comment_ _parameter_ (instead of _$comment_) would definitely help as well, cause it will help achieve the end-goal of recording the full comment-string in the logs.

Thanks again.

Regards,
Harshad","Jan 07 2019 07:50:33 PM UTC;asya;This ticket tracks two related issues:
- when log line exceeds the maximum the entire comment can be lost/missing
- when log line does not exceed maximum the comment still gets truncated
","Mar 22 2019 02:51:16 AM UTC;bartle;I think this is a bit more difficult to change now, since logs are now run through output redaction first.  In {{OpDebug::report}} we may just want to iterate over {{query}} and/or {{cmdToLog.getObject()}}, looking for top-level {{comment}} fields, and for those, ultimately call {{toString}} with {{full=true}}?","Mar 22 2019 06:14:33 AM UTC;bartle;The following simple patch fixes this (verified against 3.4):
{code:java}
diff --git a/src/mongo/bson/bsonobj.cpp b/src/mongo/bson/bsonobj.cpp
index bc0045f568..2a048c26f9 100644
--- a/src/mongo/bson/bsonobj.cpp
+++ b/src/mongo/bson/bsonobj.cpp
@@ -612,7 +612,10 @@ void BSONObj::toString(
             first = false;
         else
             s << "", "";
-        e.toString(s, !isArray, full, redactValues, depth);
+        if (!full && !isArray && (str::equals(e.fieldName(), ""comment"") || str::equals(e.fieldName(), ""$comment"")))
+            e.toString(s, !isArray, true, redactValues, depth);
+        else
+            e.toString(s, !isArray, full, redactValues, depth);
     }
     s << (isArray ? "" ]"" : "" }"");
 } {code}
If this seems like a reasonable approach, I can add some tests and send out a PR.","Mar 28 2019 10:54:02 PM UTC;david.storch;Hi [~bartle],

Thanks for looking into this! I'd be a bit worried about writing code deep in the BSONObj library that has logic specific to ""comment"" or ""$comment"". The BSONObj code itself should be agnostic as to what its contents are in order to present a generic interface to all callers. I think a preferable approach would be to add a new parameter to BSONObj::toString() so that the caller can describe which fields should not be truncated. My team doesn't actually own this code, so I'm not sure if [~acm] has different thoughts on how we should achieve this. Once we agree on the broad strokes of the fix, a pull request would be awesome!

Best,
Dave","Mar 29 2019 02:35:22 AM UTC;bartle;I'd be fine adding a ""{{const set<string>& alwaysFull}}"" argument to {{toString}}, or even just a string argument {{topLevelAlwaysFull}} if we only want to support ""comment"" (depending on how https://jira.mongodb.org/browse/SERVER-29794 turns out).","Apr 02 2019 05:06:20 PM UTC;acm;I would definitely agree that introducing knowledge of {{comment}} and {{$comment}} into the BSON library is a layer violation. I do worry about adding yet another parameter to {{BSONObj::toString}} and {{BSONElement::toString}} (the latter being where the limit is actually enforced). There are already too many options. Another concern is whether the {{alwaysFull}} set would eventually come to include dotted paths, which would be another layer violation, I think. This discussion has me once again wishing that we had a generic BSON visitation framework. That would allow customization of behavior at the point of use, rather than plumbing additional context into the heavily overworked {{::toString}} methods. However, the visitor would need to be implemented without stack based recursion, making it somewhat tricky to implement.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Provide a non-isolating non-consistent transaction mode for BASE applications,SERVER-43248,922595,New Feature,Investigating,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Minor - P4,,evin.roesle,ralf.strobel,ralf.strobel,Sep 10 2019 05:42:05 PM UTC,Dec 01 2020 03:49:08 PM UTC,Feb 17 2021 11:15:25 AM UTC,,,,,,,Replication,,,,0,,,,,,"I have been reviewing the multi-document transactions introduced in 4.0 for our data aggregation framework, which is very fundamentally rooted in the BASE consistency model. Not surprisingly, the supported ACID transactions are proving too restrictive for us in their current form. This is not meant as a complaint, but merely as a suggestion that the ability to relax some of the constraints of the transaction model may actually may make it more useful for some projects.

Our application could still very much benefit from transactions which are Atomic and Durable. In fact our typical write events consist of batches of commands, which should be executed in an all-or-nothing fashion. We currently solve this in our database transaction layer, by writing all commands to be executed to a journal first, so that we can replay them in case of an unexpected interruption during the write process.

However, Isolation and causal Consistency checks are not required. Our application design already guarantees that concurrent writes to same objects are commutative and/or idempotent, and that potential read-write conflicts are eventually resolved (as long as the order of write operations within each transaction is guaranteed). Using ACID transactions to perform our writes would lead to countless WriteConflict exceptions and retries (similar to the reports in SERVER-36428).

It's probably worth pointing out that it would be perfectly acceptable for each command during such a transaction to have write concern \{""w"" : 0\}, as long as the eventual commit does not return until all writes are durable. This way the server could defer the actual writes instead of performing them immediately, which would require locks on the modified documents for a potential rollback. The goal for a mode like this should be to stay as closely as possible to the performance and flexibility of single document writes as possible.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2020-02-05 15:56:05.0,31190400,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,steven.vannelli(steven.vannelli),Fri Feb 21 21:00:11 UTC 2020,,,,,,,,,,,,,,evin.roesle(evin.roesle),ralf.strobel(ralf.strobel),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i48kpz:",,,,,,,"0|i4aep3:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i48itr:","Feb 21 2020 09:00:11 PM UTC;evin.roesle;Hi [~ralf.strobel],

I am a Product Manager for the server team at MongoDB. Thank you for reaching out to us with your suggestion, we greatly appreciate all user feedback. There are actually two possible projects that we have been discussing in the past that fall into the bucket that you're describing here with transactions so that they may have more flexibility. At this point, we do not have a timeline for beginning work on these projects but I have taken note of your use case and will include that in the justification for these projects. 

Thank you and please feel free to reach out to me if you have any other use cases that would benefit from this type of functionality.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Allow users to set specify a password validation policy,SERVER-7363,53240,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Minor - P4,,backlog-server-security,ian.whalen,ian.whalen,Oct 15 2012 11:49:49 PM UTC,Nov 27 2020 03:45:45 PM UTC,Feb 17 2021 11:15:25 AM UTC,,,,,,features we're not sure of,Security,,,,19,,,,,,"Things like password length, strength, etc.",,,,,,,,SERVER-10855,,,,CS-20698,CS-20740,FREE-127031,TSWRITING-1414,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,500A000000XVdkSIAT,500A000000ZOweiIAD,500A000000ZPMZbIAP,500A000000bTv3PIAS,500A000000bVJ83IAG,500A000000bw0CSIAY,500A000000ccYBRIA2,5002K00000csxncQAA,5002K00000dGq2UQAS,5002K00000eALqSQAW,5002K00000f2AUsQAM,5002K00000gk5JIQAY,5002K00000hR8omQAC,5002K00000iPkzBQAS,5002K00000jahzJQAQ,5002K00000jdlIJQAY,5002K00000lmsqMQAQ,5002K00000noT7KQAU,5002K00000npgGcQAI,5002K00000pDGlJQAW,5002K00000r3DmQQAU,,,,,,,,,,,,,,,,,,,,,,,,2013-05-24 17:14:55.0,156384000,<s><a href='https://jira.mongodb.org/browse/SERVER-10855'>SERVER-10855</a></s>,,,,,,,,,,,,,,,,,,,,,,,,,,,true,,Fri Mar 04 19:44:27 UTC 2016,,,,,,,,No,,,,,,andreas.nilsson(andreas.nilsson@10gen.com),backlog-server-security(backlog-server-security),ian.whalen(ian@10gen.com),narges.ghaedi@tecnotree.com(narges.ghaedi@tecnotree.com),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i05ab3:",,,,,,,"0|i05rqf:",6646,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i0sm1z:","Mar 04 2016 07:34:47 PM UTC;narges.ghaedi@tecnotree.com;Hi Team
For system which migrating from other RDBMS like oracle to Mongodb covering Security items is important.Please share Mongodb Plan to support enforce Policy like below items.
Password complexity : Ensure password combination of letters, numbers and special characters 
Password History: Do not allow last 3 passwords in password change process
Expiration for individual usernames :fx. 60 days
Account lockout Policy for individual usernames: username lockout after 5 failed login","Mar 04 2016 07:44:27 PM UTC;andreas.nilsson;Thanks for your question [~narges.ghaedi@tecnotree.com].

We have no plan to enforce password requirements on the database level in the near future. Our general best practice recommendation is to use x.509 client certificates, or to integrate with existing user catalogs in the organization via LDAP or Kerberos authentication. A centralized user administration and life cycle has several security benefits.

We currently don't support expiry date on user accounts but we are considering this as a feature.

Account lockouts it is a tricky topic for any service-service architecture since it allows for trivial DoS attacks.

Let me know if this answers your questions.

Regards,
Andreas Nilsson",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Support sorting by expressions other than field references,SERVER-46298,1169571,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Minor - P4,,backlog-query-execution,thomas.zembowicz,thomas.zembowicz,Feb 21 2020 04:13:03 PM UTC,Nov 24 2020 11:45:31 PM UTC,Feb 17 2021 11:15:25 AM UTC,,,,,,Backlog,Querying,,,,0,qexec-team,,,,,"The {{$sort}} stage currently only supports sorting on field references. It would be useful to be able to sort on other user-defined expressions applied to each document, whether in {{$sort}} or a new stage like {{$sortByExpression.}}

The only way to emulate this behavior now is to add {{$project}} stages on either side of a {{$sort}} to compute a new field using an expression, sort on that field, and remove the field. However, this trick isn't well-documented documented and it would probably be better if users could do this without having to modify the documents in the pipeline.

Possible syntax:
{noformat}{ $sortByExpr: <aggregation expression>  }
{noformat}
Sort by {{salesAmount}} ascending:
{noformat}db.users.aggregate( [ { $sortByExpr : { $sum: { $multiply: [ ""$price"", ""$quantity"" ] } } } ] )
{noformat}",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2020-11-24 23:45:31.0,7257600,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,david.percy(david.percy),Tue Nov 24 23:45:31 UTC 2020,,,,,,,,,,,,,,backlog-query-execution(JIRAUSER1257109),david.percy(david.percy),thomas.zembowicz(thomas.zembowicz),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i5e8pb:",,,,,,,"0|i00zjb:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i5e6sv:","Nov 24 2020 11:45:31 PM UTC;david.percy;Another syntax idea:
{code}
{$sort: {$expr: <expression>}}
{code}

This would be similar to {$match: {$expr: <expression>}}.  It would also let you sort by an expression in find()-style queries:
{code}
db.c.find().sort({$expr: <expression>})
{code}
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
should check commands_lib.js against listCommands output,SERVER-24159,286949,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Minor - P4,,backlog-server-security,geert.bosch,geert.bosch,May 16 2016 05:48:32 PM UTC,Nov 18 2020 06:14:00 PM UTC,Feb 17 2021 11:15:25 AM UTC,,,,,,Backlog,Security,,,,0,,,,,,"In order to avoid forgetting authentication checks to new commands, we should add a test that verifies that for each command listed in listCommands, the {{jstests/auth/lib/commands_lib.js}} contains an entry, if necessary with an explicit list of known excluded commands.",,,,,,,,,,,,SERVER-16203,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,150076800,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,sara.williamson(sara.williamson),2016-05-16 17:48:32.0,,,,,,,,,,,,,,backlog-server-security(backlog-server-security),geert.bosch(geert.bosch),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i01x4n:",,,,,,,"0|i05o1j:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i0x3mf:",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Add named month placeholder to $dateFromString format,SERVER-32863,486433,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Minor - P4,,backlog-query-execution,justin.seyster,justin.seyster,Jan 23 2018 10:00:13 PM UTC,Nov 17 2020 07:48:19 PM UTC,Feb 17 2021 11:15:25 AM UTC,,,,,,Backlog,,,,,0,neweng,,,,,"The first implementation of the format string will not support specifying the month by its name (Jan/January, Feb/February, etc.). We should add a % placeholder for this purpose.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2018-07-11 10:21:25.0,82252800,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,arun.banala(arun.banala),Wed Jul 11 10:21:25 UTC 2018,,,,,,,,,,,,,,backlog-query-execution(JIRAUSER1257109),justin.seyster(justin.seyster),ravi.k.nagireddy@gmail.com(ravi.k.nagireddy@gmail.com),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i26n5b:",,,,,,,"0|i00y2f:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i26l93:","Jul 11 2018 10:21:25 AM UTC;ravi.k.nagireddy@gmail.com;Any ETA on this feature?",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Function to get Center Point for a set of Geospatial Data,SERVER-33810,509620,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Minor - P4,,backlog-query-execution,Roman Borysenko,Roman Borysenko,Mar 12 2018 10:19:33 AM UTC,Nov 14 2020 07:26:50 PM UTC,Feb 17 2021 11:15:25 AM UTC,,,,,,Backlog,Aggregation Framework,Geo,,,1,expression,,,,,It would be nice to have a function to get a center point for a set of Geospatial Data.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2018-03-12 12:35:46.0,88473600,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,craig.homa(craig.homa),Mon Apr 30 10:34:54 UTC 2018,,,,,,,,,,,,,,asya(asya),backlog-query-execution(JIRAUSER1257109),derick(derick),Roman Borysenko(roman borysenko),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i2akr3:",,,,,,,"0|i00y53:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i2aiuv:","Apr 28 2018 08:10:11 PM UTC;asya;Is this a duplicate of SERVER-27248?
","Apr 30 2018 10:34:54 AM UTC;derick;[~asya] — it looks like it. However, there are two possible interpretations:

1. Return a centroid for *each* GeoJSON element in the result set — which is what I think this issue is.
2. Return a centroid (and radius) for *all* the GeoJSON elements in all returned documents from the result set — which is what I think SERVER-27248 means.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Return information if new collection is created in WriteResult,SERVER-19718,223727,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Minor - P4,,backlog-query-execution,SteffenBrauns,SteffenBrauns,Aug 01 2015 01:30:49 PM UTC,Nov 14 2020 07:22:28 PM UTC,Feb 17 2021 11:15:25 AM UTC,,,,,,Backlog,Write Ops,,,,1,,,,,,It would be helpful if WriteResult could contain the information if a new collection was created within the write operation.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,3.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2015-08-01 20:54:51.0,88300800,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,craig.homa(craig.homa),Tue May 01 16:26:53 UTC 2018,,,,,,,,,,,,,,asya(asya),backlog-query-execution(JIRAUSER1257109),jeff.yemin(jeff.yemin),SteffenBrauns(steffenbrauns),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i02nxj:",,,,,,,"0|i00xrj:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i0xxpj:","Aug 01 2015 08:54:51 PM UTC;jeff.yemin;Thanks for the suggestion.  But the server does not provide that information in the response so the driver can not report it. ","Aug 01 2015 11:19:19 PM UTC;SteffenBrauns;Maybe server response can be improved / extended then, too? Thanks in advance!","May 01 2018 04:26:53 PM UTC;asya;Not clear if this may leak some information to a user who is allowed to write to a collection but not to see information about collection metadata.

 ",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Add server command for validation of a document without insert or update,SERVER-22901,268887,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Minor - P4,,backlog-query-execution,ruben.terceno,ruben.terceno,Feb 29 2016 09:44:45 PM UTC,Nov 14 2020 07:21:34 PM UTC,Feb 17 2021 11:15:25 AM UTC,,,,,,Backlog,Storage,,,,0,,,,,,"Expose the [document validation|https://docs.mongodb.org/manual/core/document-validation/] mechanism to allow validating a provided BSON document without the need of a document insert or update.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2016-02-29 23:13:55.0,128217600,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,craig.homa(craig.homa),Tue Jan 24 15:47:23 UTC 2017,,,,,,,,,,,,,,backlog-query-execution(JIRAUSER1257109),ian.whalen(ian@10gen.com),ruben.terceno(ruben.terceno),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i0241b:",,,,,,,"0|i00xtz:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i03ryn:","Jan 24 2017 03:47:23 PM UTC;ian.whalen;Ruben, we don't quite understand why this is desirable - could you please add a bit more detail about what you want and the rationale?",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Allow multiple clients to use a single cursor.,SERVER-8602,65598,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Minor - P4,,backlog-query-execution,robert.j.moore@allanbank.com,robert.j.moore@allanbank.com,Feb 18 2013 03:11:56 AM UTC,Nov 14 2020 07:20:33 PM UTC,Feb 17 2021 11:15:25 AM UTC,,2.2.3,,,,features we're not sure of,Querying,,,,2,,,,,,"Currently the mongod server upon seeing a cursor that is already locked returns a empty result to the client with a cursor id of zero.  This will cause the client to consider the cursor exhausted and stop any active iteration.

There are cases where having multiple threads/processes reading from the same cursor is advantageous. The current processing makes handling those situations more difficult as the client cannot tell if the cursor is really exhausted or was just being actively read by another process.

Implementing this functionality would be a component of allowing clients to use a cursor as a shared work queue.",All,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,10.0,,,,,,,,,,,,,,,,,Fully Compatible,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2013-05-23 22:58:54.0,239414400,,,,,,,,,,,,,,,,,,,,,,,,,,,,false,craig.homa(craig.homa),Wed Jul 17 14:50:49 UTC 2013,,,,,,,,No,,,,,,schwerin(schwerin),backlog-query-execution(JIRAUSER1257109),robert.j.moore@allanbank.com(robert.j.moore@allanbank.com),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i04v9r:",,,,,,,"0|i0107b:",6683,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i0ip5j:","Feb 18 2013 05:34:02 AM UTC;robert.j.moore@allanbank.com;See https://github.com/mongodb/mongo/pull/381","May 31 2013 06:22:07 PM UTC;schwerin;[~robert.j.moore@allanbank.com], can you describe your use case a little more?  The implementation in your pull request appears to give multiple getmore requests on the same cursor a ""try"" semantics, useful for polling.  This is a reasonable and straightforward extension of the existing implementation, but I wonder if applications would be better served by a ""wait"" semantics, where the second getmore waits to return until the first getmore unpins the cursor.","Jun 02 2013 02:14:50 AM UTC;robert.j.moore@allanbank.com;I agree that the wait semantics (especially if the query/cursor has the ""await data"" bit set) would be more desirable.  I'm willing to do the work to add that ability but would need a few pointers and/or a recommend method for implementing.

Rob","Jun 08 2013 12:26:29 AM UTC;schwerin;I think the wait semantics may be a substantial undertaking, and I don't have the time to give it the attention it needs, at present.  I'm going to consult with a few other engineers at 10gen, to see if the polling-semantics solution would stand in the way of other future work, and either [~kangas] or I will respond on this ticket.","Jun 10 2013 07:26:52 PM UTC;schwerin;[~robert.j.moore@allanbank.com], can you describe your goal from this change in a little more detail?  I'm somewhat nervous of the polling semantics, and am also concerned about the complexity of a wait semantics implementation.

This proposal suggests that you're trying to improve the utilization of some resource, either available network bandwidth or available client-side computational resources.  If it's network bandwidth, setting the ""Exhaust"" flag in queries (http://docs.mongodb.org/meta-driver/latest/legacy/mongodb-wire-protocol/#op-query) will remove the latency of getmore round trips.  If it's client-side CPU utilization, client or driver changes might be more appropriate.  If it's some other resource, can you describe it?","Jun 10 2013 08:13:51 PM UTC;robert.j.moore@allanbank.com;Sure - basically I am trying to turn MongoDB into a work/queue broker.

I am inserting the ""job"" documents into a capped collection and then have multiple processes pulling the documents out of the capped collection via a single shared tailable cursor (across multiple threads and processes).  

I am not worried about bandwidth as much a simple, fast work distribution model. (And yes I realize that some work might get lost in the case of a fault but that is OK in my use case.)

Currently, I am using a cursor with await data set to false and all the clients are ""spinning"" on the cursor/getmore requests and dealing with occasional getmore response with a cursor id zero. 

With this change the await data can be changed to true and things will not have to spin as much. Again, ideally there would be wait semantics for all of the cursor consumers but I'm happy to get what I can get.


","Jun 10 2013 08:58:07 PM UTC;schwerin;Ah, yes, alternative number 3, thing I didn't think of.  I'll mull this over.","Jul 17 2013 01:39:56 AM UTC;robert.j.moore@allanbank.com;Bump - Any thoughts?

Rob.","Jul 17 2013 01:58:12 PM UTC;schwerin;While there's nothing difficult with this patch, per se, we're not comfortable ensuring this client-synchronizing behavior going forward.  I'm going to close the pull request, but leave the associated ticket open as a feature request.","Jul 17 2013 02:50:49 PM UTC;schwerin;The approach we'd prefer, rather than having multiple clients share a cursor, is to make the findAndModify process more useful for this kind of work queuing.  Suppose that findAndModify() could return a tailable cursor.  Clients would then each establish their own tailable findAndModify cursor with the match pattern in the find including a ""consumed: 0"" match and the update setting ""consumed: 1"".  You can do this with polling today, and it is the preferred approach over sharing cursors.  Extending fAndM to support tailing would be a natural extension.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
$allOrdered / $contains query operations for arrays,SERVER-737,11484,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Minor - P4,,backlog-query-execution,hmarr,hmarr,Mar 11 2010 02:07:07 PM UTC,Nov 14 2020 07:18:38 PM UTC,Feb 17 2021 11:15:25 AM UTC,,,,,,Backlog,Querying,,,,1,,,,,,"It could be helpful to provide a new operator, similar to $all for arrays, that matches an ordered subset of items:

db.test.insert({'actions': [2, 6, 3, 8, 5, 3]});
db.test.insert({'actions': [6, 4, 2, 8, 4, 3]});
// This should find the first document, but not the second as only the first contains [6, 3, 8] in order
db.test.find({'actions': {'$contains': [6, 3, 8]}});
{ ""_id"" : ObjectId(""4b993df679e2022d6d0086f3""), 'actions' : [2, 6, 3, 8, 5, 3] }

A couple of use cases:
- Phrase matching in full-text search (storing stemmed terms as strings in an array)
- Finding users on a website that have performed a certain sequence of actions

Also, allowing it to be optionally anchored to the start or end of an array would open up more possibilities:
- Storing paths to files as individual segments of the path (by splitting the path by '/'), then finding files under a certain directory
(or more generically, querying on items that have a list that is a path in a tree/hierarchy or a graph).",,,,,,,,,,,,SERVER-974,,,,,,,,,,,,,,,,,,,,3.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2017-06-29 16:36:12.0,92880000,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,craig.homa(craig.homa),Fri Mar 09 19:25:47 UTC 2018,,,,,,,,No,,,,,,asya(asya),backlog-query-execution(JIRAUSER1257109),hmarr(hmarr),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i07fzb:",,,,,,,"0|i00xef:",6312,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i1f1sn:","Jun 29 2017 04:36:12 PM UTC;asya;This is possible to do in aggregation framework using array expressions, but that's only helpful if this use case is for analytics.
","Jun 29 2017 04:43:31 PM UTC;asya;For the record, this is how:
{noformat}
db.test.aggregate([
  {$match:{actions:{$all:[6,3,8]}}},
  {$addFields:{actions638:{$map:{
        input:{$range:[0,{$subtract:[{$size:""$actions""},2]}]},
        in:{$slice:[""$actions"",""$$this"",3]}
  }}}},
  {$match:{actions638:[6,3,8]}}
])
{noformat}
","Mar 09 2018 07:25:47 PM UTC;asya;There's a blog post explaining how the above works and showing how to do non-strict ordered subset match also: http://www.kamsky.org/stupid-tricks-with-mongodb/how-to-match-a-strict-subset-of-an-array-in-order
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
document level stats,SERVER-7549,55257,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Minor - P4,,backlog-query-execution,mattcampbell,mattcampbell,Nov 05 2012 06:00:37 AM UTC,Nov 14 2020 07:18:26 PM UTC,Feb 17 2021 11:15:26 AM UTC,,2.3.0,,,,Backlog,Admin,Storage,,,1,document,stats,,,,"Implement stats similar to those found on the db and col levels.

Currently there is no efficient way of obtaining stats such as the size of a document without sending the document down the wire to the client and bson encoding the document.

Suggest storing document stats as meta data beside each document in a collection but only return such stats data when requested as shown in the following examples.

Return a summary (aggregation of stats):

db.col.findOne({}).stats();
db.col.find({}).stats();
* would return a document similar to db.stats() and col.stats() and contain an aggregation of all documents in the server cursor
* in the case of findOne it would represent the stats of a single document because only one document in the cursor (thus by implementing it at the cursor level it covers both single document and aggregation scenarios)

Return documents and stats embedded using a flag on the find() operation:

db.col.find({}, {stats:true});
* stats could be attached as an embedded document in the _stats key on each document
* as the stats would be located beside the document on disk it should be a quick and efficient operation to perform

As you can see from the examples above this would be best implemented on the server cursor. I would suggest storing stats meta data beside documents on disk as opposed to storing them in a separate hash table or other data structure. This is to ensure efficient retrievals of both documents and stats in a flexible manner and to ensure writes remain fast.",,,,,,,,,,,,SERVER-33582,,,,,,,,,,,,,,,,,,,,3.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2012-11-08 06:00:55.0,62899200,,,,,,,,,,,,,,,,,,,,,,,,,,,,false,craig.homa(craig.homa),Tue Feb 19 21:47:08 UTC 2019,,,,,,,,No,,,,,,backlog-query-execution(JIRAUSER1257109),eliot(eliot),milkie(milkie),mattcampbell(mattcampbell),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i0587j:",,,,,,,"0|i00ym7:",6669,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i01hfr:","Nov 08 2012 06:00:55 AM UTC;eliot;Besides size, what stats are you looking for?","Nov 08 2012 07:09:45 AM UTC;mattcampbell;For both single and aggregated doc stats:

ns (collection which document is stored in - useful if you are passing objects around a system without being context bound or have a wrapper)
dataSize/size (size of the document data)
storageSize (size of storage allocated to document, ie includes overheads like padding - as close as possible to physical disk usage)

For aggregated doc stats:

count (number docs in cursor / stats aggregate)
avgDocSize (datasize divided by count)


Possible ideas (not considered core):

count of keys per doc (could be top level or drilldown into embedded docs)
Indexes used by a document (purely a match of collection indexes to document keys)

RATIONALE:

ns - allows a document to traverse through an application knowing its 'home' and having identity

dataSize - useful for clients which may be bandwidth aware and want to know the size of set of document before choosing to pull them down the wire (ie think mobile or other bandwidth constrain or resource constrained device). This would allow them to make decisions on how much data to pull down.

storageSize - in multi-tenant environments this would allow us to quickly report the physical disk used by a set of documents belonging to a client (contained in a single shared collection). Eg a multi-tenant collection of products we would be able to quickly report the disk usage in a dashboard to each user for that type of object

count - simple - number docs in cursor
avgDocSize - again useful for bandwidth aware clients when looking at a set of documents in a cursor as opposed to a single document where dataSize would make more sense. The client could calculate this using dataSize and count on a set of documents.
","Feb 19 2019 09:47:08 PM UTC;milkie;The aggregation pipeline could provide this sort of information with new operators.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Find Points near LineString,SERVER-14948,153450,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Minor - P4,,backlog-query-execution,nevi_me,nevi_me,Aug 18 2014 09:04:12 PM UTC,Nov 14 2020 07:18:20 PM UTC,Feb 17 2021 11:15:26 AM UTC,,2.4.10,2.6.4,,,features we're not sure of,Geo,,,,3,,,,,,"I couldn't find an existing ticket, so let me try my luck.

I would like the ability to search for GeoJSON points that are within x meters of a GeoJSON Polyline. This is currently a costly query to implement outside of a database server, as I either have to; build a Polygon from a Polyline before using a $geoWithin, or hit Mongo multiple times using a $near, then filter all results for a distinct list of Points.

An approach that could be achieved in the server would be (likely a naive implementation):
1. make a  LineString into a 'complex' LineString by reducing the distance between each point to a small distance. JS example: https://github.com/rwt-to/GeoJSON-Tools#complexify
2. convert the LineString into a Polygon by creating a circle out of each point in the LineString, then merging them (haven't found an effective way of doing that yet, my Polygons become huge)
3. use $geoWithin internally to find Points in the Polygon.

The second approach would be to perform step 1. above, then just use a $near for each point in the LineString, then filtering all the Points before returning a result.

In case I haven't explained it clearly, here's a SO question explaining the issue: http://stackoverflow.com/questions/19015861/find-points-near-linestring-in-mongodb-sorted-by-distance

There is likely a more efficient way, but I haven't had the time to try find it. I think the query would still perform decently if ran internally on Mongo, as either method above would use indices while avoiding round-trips.

Lastly, just for control, it seems like this is easily achievable in PostgreSQL :) : http://stackoverflow.com/questions/10286899/find-the-nearest-points-along-the-linestring-in-specified-distance-limit-and-ord

",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,5.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2014-08-20 13:31:13.0,65404800,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,craig.homa(craig.homa),Mon Jan 21 17:12:50 UTC 2019,,,,,,,,,,,,,,backlog-query-execution(JIRAUSER1257109),greg_10gen(greg_10gen),jtuskan@usxpress.com(jtuskan@usxpress.com),nevi_me(nevi_me),siyuan.zhou(siyuan.zhou@10gen.com),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i03etr:",,,,,,,"0|i0107r:",133212,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i012on:","Aug 20 2014 01:31:13 PM UTC;greg_10gen;Generalized near-to-shape isn't a bad idea, but would require some significant work (and potentially some changes to the $near interface).","Aug 20 2014 04:08:14 PM UTC;nevi_me;Understandable.

It's something I've wanted to efficiently implement, so I'll keep working on it in JavaScript and see how efficient I can make it. C++ isn't my forte so maybe if someone else is interested in doing that on Mongo they could then port the implementation and submit a pull request.

In terms of the $near interface, there shouldn't be significant/any change to how the API works externally. I reckon that the user should be able to specify a valid GeoJSON object, then Mongo should apply the existing logic for Points, and whatever the potential implementation would be for other types.

Logically, all of this is possible, the pain is just in implementing it outside of the server as one can't enforce query limits properly, and the roundtrip cost. If I want to select 100 closest points, but I pull 120 from Mongo, and 30 of them are duplicates, I would end up with 90. Similarly, if
I construct a Polygon out of the LineString range, I'd still need to calculate each Point's distance to the nearest boundary so I can filter by distance before applying limits.

Finally, to reduce the frequency of ""I want this feature now or else ..."" comments on issues that we follow, more work could be done on server-side scripting so that interested parties could roll out our own enhancements to Mongo without pulling a TokuTek. Probably something to consider for 2.10 or 3.0.","Jul 18 2015 11:57:31 AM UTC;nevi_me;This looks fixed in 3.0. I was able to query a point against a polyline using `$near` successfully. I think the issue can be closed. The last time I tried it I was still using 2.6.","Jul 21 2015 06:45:16 PM UTC;siyuan.zhou;[~nevi_me], I don't think MongoDB supports this feature currently. The following query gives an error of {{""invalid point in geo near query $geometry argument""}}.

{code}
coll.find({loc: {$near : {$geometry: {type: ""LineString"", coordinates: [[0,0],[1,1],[2,2]]}}}});
{code}

The functions mentioned in the description and its references on StackOverflow are actually different. To my understanding, there are at least 3 different queries.
1. Find points $within a buffer of line, where a buffer means the area that's within a certain distance from the line.
2. Find points $within a buffer of line, then sort the results according to the distance from the line.
3. Find points $within a buffer of line, then sort the results along the driving order along the road.

The first is a $within query, the second looks like a $near query and MongoDB doesn't have a counterpart of the third function. Could you please talk more about your use cases?

Thanks,
Siyuan","Jan 21 2019 05:12:50 PM UTC;jtuskan@usxpress.com;@Siyuan Zhou My use case is having a collection of line strings representing vehicle routes. A vehicle's driver may only be able to complete the next 4 hours of driving along their current route, Route A. Route A is time critical. I need to find another vehicle route, Route B (non-critical), that is close to Route A in order to fulfill Route A.

Using linear referencing, I slice the route into time segments of say 30 minutes. Then perform a $near query on each valid time segment point. But this does not match my use case. Because a circular or spherical distance without an excessively large query will have gaps without having a lot of overlapping $near queries. As well as, linear referencing being resource expensive. My query is not returning the entire data set.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Various update() operators for Binary Data,SERVER-8716,66342,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Minor - P4,,backlog-query-execution,richard.kreuter,richard.kreuter,Feb 25 2013 05:12:41 PM UTC,Nov 14 2020 07:17:32 PM UTC,Feb 17 2021 11:15:26 AM UTC,,,,,,Backlog,Write Ops,,,,5,,,,,,"There are a few update operations that it might be nice to offer on binary data objects in documents:

* append/concatenate (maybe this could be an overload to $push?)
* slice/subsequence
* replace







",,,,,,,,SERVER-6399,,,,SERVER-3281,SERVER-4362,SERVER-9380,,,,,,,,,,,,,,,,,,3.0,,,,,,,,,,,,,,,,,,,,,5002K00000nmLSOQA2,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2013-04-03 20:53:06.0,206755200,<s><a href='https://jira.mongodb.org/browse/SERVER-6399'>SERVER-6399</a></s>,,,,,,,,,,,,,,,,,,,,,,,,,,,true,craig.homa(craig.homa),Thu Jul 31 04:30:52 UTC 2014,,,,,,,,No,,,,,,backlog-query-execution(JIRAUSER1257109),craig.leyshan(craig.leyshan),justanyone(justanyone),richard.kreuter(richard@10gen.com),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i04trz:",,,,,,,"0|i00xk7:",7047,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i0u4a7:","Apr 03 2013 08:53:06 PM UTC;justanyone;This would allow much tighter packing of data for us.  instead of $push onto { ... 'arrayName': [ [1,2], [3,4], ...} I could use python's struct to binary-encode 5 and 6 into a 2-byte number (or in our case, two doubles), bson.Binary() -encode them, then append them to an existing { ... 'arrayName' : BinaryObj(...) } object.  This would change from 30 bytes per datapoint pair to 16 bytes per datapoint pair.

I'm presuming there's BSON project support for append binary data to binary object.  Likewise, we'd need to be able to resize (remove data from the front or end) of binary data.","Aug 20 2013 02:46:34 PM UTC;justanyone;To be very specific, we can significantly reduce our data footprint (and thus increase performance) by replacing our data model of:

{noformat}
{ ...  'vals' : [   [1,2], [3,4], [5,6], ... ],...}
{noformat}

with one where we have vals packed in a bit field, and we just append bits to the front/end, and remove bits from the front/end.  Our immediate need is appending to one end, and removing from the other, to keep a specific maximum length of time-series data in the bitfield.  Appending and removing from the same end is nearly useless in our use case, as we need a queue, not a stack.  Though, I can readily see how some people would need a stack.

{noformat}
{ ...  'vals' : BinaryObject ...}
{noformat}

Due to the way that MongoDB's BSON format has to encode the values as [ [1,2], [2,3] ], each bracket and comma in this is functionally encoded to a byte, consuming (for floats) 30 bytes per numeric pair.  With this bitfield packing, the size per point would reduce to even down to 8 bytes per numeric pair (2 x 32-bit floats).  This is a HUGE savings in size consumed per datapoint, and would thus mean we could keep more in memory at once for faster data access and faster updating as well given it's more likely to be in memory.

I would wager that this is a common need among many MongoDB users - the ability to pack data more tightly to optimize (reduce) data storage sizes.

These bit-field operators should be fairly low level operators, and thus (on the surface) would seem to be fairly easy to implement.  

Any other use cases out there?

","Jul 31 2014 04:30:52 AM UTC;craig.leyshan;I have a use case that would benefit greatly by using a binary (byte array) and being able to manipulate individual bytes in updates atomically: Hyperloglog.  In this case, the size of the array is fixed, and updates need to be able to make use of the $max operator on individual bytes.  Right now it is *very* space inefficient to put these in mongo in a way that allows safe parallel updates (using a so-called ""array"" of Integers, i'm look at this thing taking up about 7 bytes for each byte of real information).  I think one way this could work is for 'byte' to be a valid type in BSON, and for arrays in BSON to be encoded as an element type, length and then a dense packing of the elements.  Lastly, the update semantics in mongo would need to support arrays better.  rather than the existing ""key.n"" syntax, a ""key[n]"" syntax (or similar) could be adopted to be able to address individual positions in the array.  For example in upserts, with the current syntax, mongo thinks you want a document, not an array, if an insert is required.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Add a createGridFS bucket command,SERVER-10020,80245,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Minor - P4,,backlog-query-execution,richard.kreuter,richard.kreuter,Jun 25 2013 03:29:45 PM UTC,Nov 14 2020 07:16:41 PM UTC,Feb 17 2021 11:15:26 AM UTC,,,,,,Backlog,GridFS,,,,0,,,,,,"In 2.6 we'll have customizable roles, and so not every user who will be able to insert documents into a GridFS bucket will have permission to create the prerequisite unique index on {files_id:1, n:1}.

Proposed fix: add a createGridFS bucket command, so that admins can give users the ability to create GridFS buckets without having privileges to build indexes generally.

Driver changes needed: drivers should be changed to use createGridFS, then maybe fail over to trying the ensureIndex. (Eventually, the ensureIndex call could be dropped from drivers, too.)

Docs changes needed: document the new command, maybe add a release note that taking away createIndex from a user will require upgrading drivers in order to use GridFS.

Tools changes needed: mongofiles, I guess.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2016-04-22 19:32:57.0,241315200,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,craig.homa(craig.homa),2013-06-25 15:29:45.0,,,,,,,,No,,,,,,backlog-query-execution(JIRAUSER1257109),richard.kreuter(richard@10gen.com),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i04ef3:",,,,,,,"0|i00xl3:",7180,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i1iwdb:",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Update map reduce collections ,SERVER-508,11043,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Minor - P4,,backlog-query-execution,ankit,ankit,Dec 23 2009 11:00:19 AM UTC,Nov 14 2020 07:16:01 PM UTC,Feb 17 2021 11:15:26 AM UTC,,,,,,Backlog,MapReduce,,,,4,map-reduce,,,,,"It would be great if Mongo could update a Map Reduce Collection every x minutes. This was M/P functions that would be slightly inefficient to run on the fly, could be run in the background and the application itself would just need to read the map reduce result collection. This would work tremendously well for Map Reduce results that dont change in real time, but more so in pseudo-real time.

e.g. authors -> name, books_per_year, avg_pages_per_book, foo_metric, bar_metric, ..
       book -> name, author , ..., subject, date_published
 Assuming 1 million authors and 10 million books

M/R to get ""all authors whose foo_metric is between x & y and books_per_year is between x' & y' and date_publihsed is after 1-1-1990"" would be very inefficient currently, but could be ""refreshed"" every x mins. by mongo.",All,,,,,,,,,,,SERVER-17354,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,500A000000UaTfAIAV,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2010-03-10 15:22:32.0,345254400,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,craig.homa(craig.homa),Wed Mar 10 15:22:32 UTC 2010,,,,,,,,No,,,,,,ankit(ankit),backlog-query-execution(JIRAUSER1257109),colinmollenhour(colinmollenhour),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i07imv:",,,,,,,"0|i00xdz:",6346,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i1i213:","Mar 10 2010 03:22:32 PM UTC;colinmollenhour;Or perhaps a map/reduce that exists as a sort of index, a.la. Couch.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Capture last accessed datetime in $indexStats,SERVER-43373,932253,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Minor - P4,,backlog-query-execution,stephen.tunney,stephen.tunney,Sep 18 2019 04:11:24 PM UTC,Nov 14 2020 07:14:46 PM UTC,Feb 17 2021 11:15:26 AM UTC,,,,,,Backlog,Aggregation Framework,,,,2,,,,,,"The {{$indexStats}} aggregation stage does not return the datetime when an index was last accessed. 

Having this extra context could be useful when determining if an index is actually worth keeping. 

",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,5002K00000gklGUQAY,5002K00000mtXlLQAU,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,44668800,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,craig.homa(craig.homa),2019-09-18 16:11:24.0,,,,,,,,,,,,,,backlog-query-execution(JIRAUSER1257109),stephen.tunney(stephen.tunney),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i4a8cn:",,,,,,,"0|i00z4f:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i4a6gf:",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Explain Plan: show regex performance (nr of steps),SERVER-42574,881955,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Minor - P4,,backlog-query-execution,massimiliano.marcon,massimiliano.marcon,Aug 01 2019 12:18:23 PM UTC,Nov 14 2020 07:14:37 PM UTC,Feb 17 2021 11:15:26 AM UTC,,,,,,Backlog,Querying,,,,0,,,,,,"The Explain Plan is quite interesting. Maybe use a regex debugging library to compute the number of steps a regex takes to complete. For example: https://metacpan.org/pod/Regexp::Debugger

The idea is to give the users the awareness of performance penalties for regular expression queries, especially complex ones that backtrack a lot.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,48816000,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,craig.homa(craig.homa),2019-08-01 12:18:23.0,,,,,,,,,,,,,,backlog-query-execution(JIRAUSER1257109),massimiliano.marcon(massimiliano.marcon),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i41mqn:",,,,,,,"0|i00z0f:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i41kuf:",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
$bit update operator should support BinData type,SERVER-15680,163873,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Minor - P4,,backlog-query-execution,jtv4k,jtv4k,Oct 16 2014 12:10:52 AM UTC,Nov 14 2020 07:11:06 PM UTC,Feb 17 2021 11:15:26 AM UTC,,,,,,Backlog,Write Ops,,,,2,,,,,,"The $bit update bitwise operator currently supports 32- and 64-byte data integers. It would be helpful to allow bitwise operations for BinData types as well.

The existing operators AND, OR, and XOR could be extended to take in a BinData type and modify the original BinData as appropriate.

An additional SET or CLEAR operator might also be useful in addition to or as a replacement for the AND, OR, and XOR operators when operating on BinData. This would allow the server to avoid converting chunks of data by simply updating the appropriate byte. For example, the following would set the 124th bit in the field ""bloom"" of type BinData.

{ $bin: { bloom: { set: 124 } } }",,,,,,,,,,,,PRODUCT-574,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,200102400,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,craig.homa(craig.homa),Thu Oct 16 00:15:01 UTC 2014,,,,,,,,,,,,,,backlog-query-execution(JIRAUSER1257109),jtv4k(jtv4k),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i03arz:",,,,,,,"0|i00xon:",142928,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i025pj:","Oct 16 2014 12:15:01 AM UTC;jtv4k;This functionality would be especially useful for keeping bloom filters within documents. For example, if a document exists with a large series of arrays and a bloom filter, I can query the bloom field instead of the entire document to avoid retrieving excess data. It would further allow performing inserts into an array and updating the bloom filter simultaneously by using $addToSet in conjunction with $bit (though this would require allowing an array of [ SET: bit ]). ",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
GeoJSON Circle,SERVER-13667,132344,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Minor - P4,,backlog-query-execution,Logioniz,Logioniz,Apr 21 2014 10:56:47 AM UTC,Nov 14 2020 07:10:45 PM UTC,Feb 17 2021 11:15:26 AM UTC,,,,,,Backlog,Geo,,,,2,,,,,,"I want to have new GeoJSON object with type circle (sphere).

I have a task to intersect circles (spheres) in my work. 
Now i intersect polygon (square). This is not true for my task.

I hope, that this feature will be added.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,5.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2014-04-21 23:28:38.0,32486400,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,craig.homa(craig.homa),Thu Feb 06 19:51:54 UTC 2020,,,,,,,,No,,,,,,Logioniz(logioniz),backlog-query-execution(JIRAUSER1257109),pasette(dan@10gen.com),greg_10gen(greg_10gen),saras_arya(saras_arya),ugur.ayan@gmail.com(ugur.ayan@gmail.com),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i03lmf:",,,,,,,"0|i00ys7:",113679,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i0z40v:","Apr 21 2014 11:28:38 PM UTC;pasette;The GeoJSON spec does not account for circles: http://geojson.org/geojson-spec.html.  Do you need to see points which or GeoJSON shapes which are found in the intersection of two circles or do you need to store the circles themselves?","Apr 22 2014 06:15:54 AM UTC;Logioniz;I have a point and many circles (point + radius). Circles are stored in collection. I want to find a circles that intersect this point. 
","Apr 28 2014 03:35:41 PM UTC;greg_10gen;We're currently focused on implementing better support for basic GeoJSON across all indexes.  Successors to GeoJSON like TopoJSON support these kind of arcs (and I believe there were enhanced GeoJSON proposals for arc'd shapes) but this adds complexity and accuracy issues that may be better handled at the application side for now.","Feb 18 2016 08:25:44 AM UTC;saras_arya;Even I would like a GeoJSON property to store a circle and then we run queries like $geoIntersects with it so that we can find out if the point lies inside a stored circle. Is this possible in the current scenario?If yes, How? If now. Will this be added in later versions?

I have hacked it and done it like [this](https://github.com/SarasArya/mongoose_geofence/tree/master). But would definitely love to have some more support in this regard.","Feb 06 2020 07:51:54 PM UTC;ugur.ayan@gmail.com;It can better for now to convert circle to polynom then accuracy can be handled for now.

 ",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Enable larger result sets within $facet stage,SERVER-24804,296809,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Minor - P4,,backlog-query-execution,profesor79,profesor79,Jun 27 2016 07:31:06 AM UTC,Nov 14 2020 07:10:09 PM UTC,Feb 17 2021 11:15:26 AM UTC,,,,,,Backlog,Aggregation Framework,,,,3,,,,,,"SERVER-23654 introduced the {{$facet}} stage, which combines all outputs of the sub-pipelines into one result document. This is a request to enable some mechanism for returning more than 16MB of results, while still being able to process the same initial result set in multiple ways.

h5. Original Request
I have several similar aggregation operations at the same time, for example

{noformat}
db.cases.aggregate([
   {$match : query},
   {$unwind : ""factors""},

   //operation 1 of the above result
   // ...
])

db.cases.aggregate([
   {$match : query},
   {$unwind : ""factors""},

   //operation 2 of the above result
   // ...
])
{noformat}

The first two stages of aggregation( $match, $unwind ) are the same, and I think it would be a waste to repeat the duplicate stages. So I am asking if there exists a way to forking the pipeline, so that it can share the result from the first two stages, as follows,

{noformat}
db.cases.aggregation([
   {$match : query},
   {$unwind : ""factors""},
   forks : [
      {... operation 1},
      {... operation 2}
   ]
])
{noformat}

http://stackoverflow.com/questions/38047527/fork-the-pipeline-of-aggregation",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,7.0,,,,,,,,,,,,,,,,,Fully Compatible,,,,500A000000bBH66IAG,5002K00000ocM49QAE,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2016-06-27 13:32:14.0,146448000,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,craig.homa(craig.homa),Mon Jun 27 20:56:36 UTC 2016,,,,,,,,,,,,,,backlog-query-execution(JIRAUSER1257109),charlie.swanson(charlie.swanson),profesor79(profesor79),ramon.fernandez(ramon.fernandez),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i01t9j:",,,,,,,"0|i00xv3:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i0rzfb:","Jun 27 2016 01:32:14 PM UTC;ramon.fernandez;[~profesor79], I'm sending this to the Query team for consideration. I think more details/discussion will be needed around how to distinguish the output of each operation, so if you have thought about this and could provide further details of the behavior you have in mind that will be helpful.

Thanks,
Ramón.","Jun 27 2016 01:38:31 PM UTC;charlie.swanson;Hi [~profesor79], this looks like the {{$facet}} stage we just introduced! I'm closing it as a duplicate of that ticket. Please re-open if you feel like this is a distinct request, and clarify what you would like that is not covered by SERVER-23654. Thanks!","Jun 27 2016 01:38:58 PM UTC;profesor79;As we have only one cursor, my idea was to have a kind of for pipe where we could tag forked results

{$fork:{
[tag1] :[stages],
[tag2] :[stages],
[tagn] :[stages],
}} 

 then result documents will have a field fork:tag1 - to distinguish from which  forked pipe document  was added to main cursor.

makes this sense?


","Jun 27 2016 01:42:43 PM UTC;profesor79;[~charlie.swanson] ($facet) will the output array work with document size >16MB","Jun 27 2016 01:46:05 PM UTC;charlie.swanson;[~profesor79] no, {{$facet}} will error if the resulting document exceeds 16MB. It is thought to be unlikely for this to happen, although that is a legitimate request. What is your use case where you expect a large number of documents output within the $facet stage?","Jun 27 2016 02:46:31 PM UTC;profesor79;[~charlie.swanson] I'm using mongo as log persistence, so sometimes weekly results are having more than 60-70MB... per query","Jun 27 2016 08:56:36 PM UTC;charlie.swanson;[~profesor79] OK. In that case, I'm re-opening this ticket as a feature request to support larger result sets within the $facet stage.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Implement $nand Logical Query Operator,SERVER-15577,162721,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Minor - P4,,backlog-query-optimization,zamnuts,zamnuts,Oct 09 2014 02:10:52 AM UTC,Nov 14 2020 07:02:24 PM UTC,Feb 17 2021 11:15:26 AM UTC,,,,,,Backlog,Querying,,,,1,,,,,,"The following logical query operators exist: {{$and}}, {{$or}}, and {{$nor}}. There also exists {{$not}}, however this is a field-level operator, while the aforementioned are not field-specific.

I propose the introduction of a {{$nand}} operator as a compliment to {{$and}}, {{$or}}, and {{$nor}}.

Given the following query:
{code:javascript}
{
	$and: [
		{a: 1},
		{b: 2}
	]
}
{code}

The current way to implement NAND logic:
{code:javascript}
{
	$or: [
		{'a': { $ne: 1} },
		{'b': { $ne: 2} }
	]
}
{code}

This is problematic when an existing complex query exists (read: nested operators, mixed notation, etc.) and must be transformed. Before sending the query to MongoDB, it would have to be interpreted and the {{$ne}} operator strategically placed. It would be easier and less error-prone to use the existing query and wrap it in a {{$nand}}:
{code:javascript}
{
	$nand: [
		{a: 1},
		{b: 2}
	]
}
{code}

Existing use cases are on [Google Groups|https://groups.google.com/d/topic/mongoose-orm/2UnZf2LtKkk/discussion] and [StackOverflow|http://stackoverflow.com/a/20954390/1481489].",,,,,,,,,,,,FREE-122623,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2016-10-10 19:41:17.0,137376000,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,craig.homa(craig.homa),Mon Oct 10 19:41:17 UTC 2016,,,,,,,,,,,,,,zamnuts(zamnuts),asya(asya),backlog-query-optimization(JIRAUSER1257108),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i03bc7:",,,,,,,"0|i00xof:",141810,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i0yqen:","Oct 10 2016 07:41:17 PM UTC;asya;The exact equivalent can be achieved by just adding [""$nor""|https://docs.mongodb.com/manual/reference/operator/query/nor/] around the ""$and"" expression:

{noformat}
{
     $nor: [
       {
         $and: [
             {a: 1},
             {b: 2}
         ]
       }
    ]
}
{noformat}
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Nice to have bson fields returned in determined order to making loading into data type / object faster.,SERVER-2991,16296,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Minor - P4,,backlog-query-optimization,tonyh,tonyh,Apr 23 2011 10:06:28 PM UTC,Nov 14 2020 07:01:26 PM UTC,Feb 17 2021 11:15:26 AM UTC,,1.8.1,,,,features we're not sure of,Querying,,,,3,,,,,,"If the bson fields are in a known order then they can be mapped/loaded into the data type directly. Otherwise, you have to use a dictionary to map bson fields to object fields. Mongo could specify the order (eg. sorted) and the data type could be made to match that. Alternatively, a query with a projection (subset of fields to retrieve) can return documents with fields ordered the same as the projection.",,,,,,,,,,,,SERVER-2592,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2011-04-23 22:32:26.0,309916800,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,craig.homa(craig.homa),Sat Apr 23 22:32:26 UTC 2011,,,,,,,,No,,,,,,backlog-query-optimization(JIRAUSER1257108),gregweber(gregweber),tonyh(tonyh),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i06q6v:",,,,,,,"0|i0108v:",6583,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i095xj:","Apr 23 2011 10:32:26 PM UTC;gregweber;Just to clarify, we have an ""ORM"" with a MongoDB backend: http://www.yesodweb.com/book/persistent. Many other ORMs will lazily access MongoDB fields from a hash so they don't care as much about ordering. In our case, we are immediately instantiating a data structure. So we need to match up all the mongo fields with the data structure fields. The fastest way is to have a guarantee on the ordering of the fields returned from the server. This could come from a guarantee that they won't change on update as part of addressing SERVER-2592. Technically we could rely on the state of 2592 now to maintain an alphabetical ordering, but that seems ugly and could change with a new version of mongodb. Another solution would be to get the fields back in the same order in which a projection is specified.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Cross collection batch operation,SERVER-20211,227755,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Minor - P4,,backlog-query-optimization,nick@innsenroute.com,nick@innsenroute.com,Aug 31 2015 04:07:59 PM UTC,Nov 14 2020 07:00:28 PM UTC,Feb 17 2021 11:15:26 AM UTC,,,,,,Backlog,Performance,Usability,,,0,,,,,,"It may be useful to allow bulk operations to span collections. I have found that bulk operations tend to be significantly more performant (than multiple discreet operations). In my workflow I have come across several scenarios which would benefit from this feature.

For example, upon completion of a certain program operation, I need to update one table and insert a summary document in another. These two operations are always tied together but it doesn't make sense for them to be within the same collection.

By extension, being able to batch multiple operations across multiple databases would also be useful in my workload. In my case I have 1 insertion thread per collection (and can have many hundreds of threads per collections). A cross-database batch operation may allow me to use a small thread pool to perform the same operation in a more efficient manner.",,,,,,,,SERVER-2172,,,,,,,,,,,,,,,,,,,,,,,,3.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2015-09-08 12:57:04.0,118627200,<a href='https://jira.mongodb.org/browse/SERVER-2172'>SERVER-2172</a>,,,,,,,,,,,,,,,,,,,,,,,,,,,true,craig.homa(craig.homa),Mon May 15 16:02:37 UTC 2017,,,,,,,,,,,,,,asya(asya),backlog-query-optimization(JIRAUSER1257108),nick@innsenroute.com(nick@innsenroute.com),ramon.fernandez(ramon.fernandez),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i02l2v:",,,,,,,"0|i00xsf:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i0mkpr:","Sep 08 2015 12:57:04 PM UTC;ramon.fernandez;[~nick@innsenroute.com], if I understand your request correctly I think this ticket is a duplicate of SERVER-2172, so I'm going to mark this ticket as such.

Regards,
Ramón.","Sep 08 2015 03:20:35 PM UTC;nick@innsenroute.com;@Ramon Fernandez - Yes - thank you.","May 15 2017 04:02:37 PM UTC;asya;This feature depends on being able to send different commands in the same batch, tracked by SERVER-2172.
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Fast approximate count with predicate,SERVER-23017,270985,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Minor - P4,,backlog-query-optimization,thestick613,thestick613,Mar 08 2016 11:07:17 PM UTC,Nov 14 2020 06:59:39 PM UTC,Feb 17 2021 11:15:26 AM UTC,,,,,,Backlog,Querying,,,,7,,,,,,"I've indexed the queried fields, which makes the count works very fast when nobody is updating documents in the collection, but whenever i start more workers, or whenever there is some load, the output is very slow:

{noformat}
2016-03-09T00:58:22.805+0200 I COMMAND  [conn2451] command squeue.in_auth command: count { count: ""in_auth"", query: { payload.group: ""group1"" } } planSummary: COUNT_SCAN { payload.group: 1.0, payload.customer: 1.0 } keyUpdates:0 writeConflicts:0 numYields:8125 reslen:122 locks:{ Global: { acquireCount: { r: 16252 } }, Database: { acquireCount: { r: 8126 } }, Collection: { acquireCount: { r: 8126 } } } protocol:op_query 511ms
{noformat}

Is there any way to make an approximative, but FAST count which ignores the updates? It doesn't matter if it displays a few hundred more or less items in a collection with 10 million docs.

I'm on a sharded cluster btw (8 rs).",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,3.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2016-03-09 17:10:25.0,124848000,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,craig.homa(craig.homa),Sun Mar 05 08:33:26 UTC 2017,,,,,,,,,,,,,,backlog-query-optimization(JIRAUSER1257108),kelsey.schubert(thomas.schubert),thestick613(thestick613),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i023fj:",,,,,,,"0|i00xu7:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i0xbdr:","Mar 10 2016 07:50:11 PM UTC;kelsey.schubert;Hi [~thestick613],

Thank you for opening this improvement request. I am marking this ticket to be considered during the next round of planning. Please continue to watch this ticket for updates.

Kind regards,
Thomas","Oct 02 2016 08:48:56 AM UTC;thestick613;Any update on this? Most people who use mongo just store a large amount of rows in a collection, then create some indexes on the fields and expect a reasonable fast count. When you insert, update or delete data in those rows the counts become very sluggish. Just google for ""mongo slow count"" and you'll find lots of reports.","Mar 05 2017 08:33:26 AM UTC;thestick613;How difficult is this feature? Does it take more than a few hours of work?",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Support for inequalities when retrieving subset of fields,SERVER-3246,18173,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Minor - P4,,backlog-query-optimization,nakamura,nakamura,Jun 12 2011 06:27:10 PM UTC,Nov 14 2020 06:58:08 PM UTC,Feb 17 2021 11:15:26 AM UTC,,,,,,Backlog,Querying,,,,0,,,,,,"It would be useful to be able to only retrieve embedded documents in an array that match certain inequalities, e.g. {pairs:{time:{$gt:0,$lt:3}}}",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,305596800,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,craig.homa(craig.homa),2011-06-12 18:27:10.0,,,,,,,,No,,,,,,backlog-query-optimization(JIRAUSER1257108),nakamura(nakamura),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i06n87:",,,,,,,"0|i00xfb:",6285,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i1i1pz:",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Allow projection of one or multiple ObjectID sub-components.,SERVER-29596,393173,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Minor - P4,,backlog-query-optimization,amcgregor,amcgregor,Jun 12 2017 10:32:56 PM UTC,Nov 14 2020 06:57:46 PM UTC,Feb 17 2021 11:15:26 AM UTC,,,,,,Backlog,Aggregation Framework,,,,0,,,,,,"In a similar, though more generalized vein to SERVER-9406 (treating ObjectIDs as dates) and SERVER-24947 (to- typecasting mechanisms), allowing for the projection of any (or all) sub-component(s) of an ObjectId into discrete fields would allow for easy additional processing on these values.  Practical use case: aggregate group results based on machine (hardware ID ± PID) that generated the record, useful for log or other hardware-dependent statistical analysis.

The syntax recommendation comes in two forms, short single-component, or multi-component embedded document:

{code:js}
{$project: {parts: {$decomposeId: {_id: true}}}
{code}

This would project all components from an ObjectId into an embedded document named parts:

{code:js}
{parts: {ts: ISODate, host: int, pid: int, counter: int}
{code}

To retrieve specific values, pass a document instead of true:

{code:js}
{$project: {parts: {$decomposeId: {_id: {host: true, pid: true}}}
{code}

{code:js}
{parts: {host: int, pid: int}
{code}

To retrieve a specific singular value, pass just its name instead of true:

{code:js}
{$project: {created: {$decomposeId: {_id: ""ts""}}}
{code}

{code:js}
{created: ISODate(...)}
{code}

As mentioned in the first paragraph, this is to facilitate use of group operations on ObjectID components.  As a side-effect, this would have also resolved SERVER-9406.  (Though automatic casting is nice, explicit is better than implicit.)",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,3.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2017-06-18 18:46:13.0,115171200,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,craig.homa(craig.homa),Sun Jun 25 06:58:25 UTC 2017,,,,,,,,,,,,,,asya(asya),backlog-query-optimization(JIRAUSER1257108),amcgregor(amcgregor),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i1qwxr:",,,,,,,"0|i00ts7:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i1qv1j:","Jun 12 2017 10:36:43 PM UTC;amcgregor;To throw in a solution for SERVER-29512 as well, passing false instead of true could totally return the ID as a hex-encoded string… four tickets, one solution.  ;P","Jun 25 2017 03:54:40 AM UTC;asya;[~amcgregor] thanks for the suggestion.  We would need to figure out syntax that accepts the expression for the field to be decomposed.   While it's most common for ""_id"" to be of type ObjectId, any expression to convert ObjectId to another type would have to work on any arbitrary field that happens to be ObjectId type as well.
","Jun 25 2017 06:58:25 AM UTC;amcgregor;{quote}While it's most common for ""_id"" to be of type ObjectId, any expression to convert ObjectId to another type would have to work on any arbitrary field that happens to be ObjectId type as well.{quote}

I continue to set my expectations too high.  Not sure what part of this offers the restriction you seem to imagine is present:

{code:js}
{$project: {created: {$decomposeId: {_id: ""ts""}}}
{code}

It's literally:

{code:js}
{$project: {TARGET: {$decomposeId: {SOURCE: COMPONENTS}}}
{code}

This means that no, it's not restricted to the _id field:

{code:js}
{$project: {created: {$decomposeId: {someid: true}}}
{code}

Pretend ""someid"" there is ""$someid"" (…an arbitrary expression…) if need be.  After the _fourth time failing to read_, but still commenting, I just have to assume you're trolling; which is *amazing*.  Edited to add: unwatched.  Do what you will.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Support Batching Mixed Operations Against Same Collection,SERVER-2172,13848,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Minor - P4,,backlog-query-optimization,scotthernandez,scotthernandez,Dec 02 2010 04:09:49 PM UTC,Nov 14 2020 06:57:37 PM UTC,Feb 17 2021 11:15:26 AM UTC,,,,,,Backlog,Usability,,,,61,oneshottxn,,,,,"Allow mixed operations (insert, update, delete) on the same collection to be sent to the server in a single write command.",,,,,,,,SERVER-4004,,,,,,,,,,,,,,,,,,,,,,,,7.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2012-07-24 16:56:59.0,118627200,<s><a href='https://jira.mongodb.org/browse/SERVER-4004'>SERVER-4004</a></s>,,,,,,,,,,,,,,,,,,,,,,,,,,,true,craig.homa(craig.homa),Mon May 15 16:14:55 UTC 2017,,,,,,,,No,,,,,,asya(asya),backlog-query-optimization(JIRAUSER1257108),calebjones(calebjones),dbot77(dbot77),maverin(maverin),justanyone(justanyone),zippoxer(zippoxer),nick@innsenroute.com(nick@innsenroute.com),scotthernandez(scotthernandez),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i06zxb:",,,,,,,"0|i00xen:",6072,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i0ear3:","Jul 24 2012 04:56:59 PM UTC;calebjones;I disagree with the ""Minor"" Priority. This would be a *huge* feature add similar in impact to the aggregation framework.

Probably the #1 complaint or deterrent people cite with MongoDB is the lack of JOINs. Yes, that is part of the trade-offs with the solution. But when de-normalization is undesirable, being able to perform a batch of operations would avoid the bursting of one-by-one commands in loops and could overcome some of the reservations people have in adopting MongoDB.

Another use case impacted by this:
I'm currently working on processing a stream of data to convert into mongo insert/update/delete commands. I was disappointed that I have to fire off the commands one at at time instead of queuing them up into batches to reduce round-trips to the server.

Hopefully this can get a bump in priority.","Aug 12 2012 11:22:16 AM UTC;zippoxer;@Caleb, I agree. Fail-safe systems are a nightmare to build with MongoDB. [Here|https://groups.google.com/forum/?fromgroups#!topic/mongodb-user/ENpMJXEUJnE%5B1-25%5D] described a problem that is similar to mine: can't roll back a set of writes (insertions/updates) when one failed. I needed this in several applications, but I gave up and left them non-fail-safe. I imagine that's what most people do when they encounter this problem, but they don't when the worst possible failure is a disaster (like a payment that was not properly rewarded). Then they do a workaround.

The workarounds are terrible. The most complex part of the application becomes the database, which was the simplest before.

Why won't you admit that's a serious problem?","Sep 13 2012 03:22:45 PM UTC;maverin;Allowing batch queries would also resolve SERVER-432 (server side expansion of DbRefs), and make it much easier to create a query preprocessor that would efficiently allow for more complex queries and eliminate some limitations (eg. SERVER-5937 (splitting documents to overcome size limitations)).

I can imagine it would be hard because you would need to support multiple cursors per connection, but even if initially you just limited it to returning all the data in one BSON it would still reap a lot of benefits.","Feb 25 2013 04:10:08 PM UTC;justanyone;I would like to vote for a simple version of this:  BATCH UPDATES.  That is, I'm issuing thousands of update statements a second.  I would like to send them as a list of updates rather than do them one by one, with the latency involved in that.  

Currently there is support for batch inserts.  This feature may tie-in with that functionality.

Playing devil's advocate to my own argument, I can see a possible complication.  I have a sharded, replicated collection.  So, let's say I send in a list of updates (each of a single separate document indexed by _id).  The router (mongos) would have to split the updates to separate lists to go to their respective shards. 

Other than that, it seems a straightforward performance increaser.

Re: failures, handle it the same as batch inserts, insert all possible records/documents and return data on which ones failed, or whatever is the easiest functionality to implement and I'll cope with the downsides.

","Sep 05 2015 08:13:31 PM UTC;dbot77;For me this is the most needed feature in mongodb. To be unable to do transactions forces you to write complex transactions yourself or switch to SQL.","Sep 08 2015 03:20:08 PM UTC;nick@innsenroute.com;Adding my name to the list who would find this useful.","May 15 2017 04:14:55 PM UTC;asya;There are multiple things that are discussed in the comments of this ticket, some of which are already implemented, and others may be tracked by different tickets.   I'm attempting to summarize the state of it here:

- Sending batches of same operations against a single collection: implemented in 2.6 SERVER-4004
- Sending batches of mixed operations against same collection: tracked in this ticket
- Batched operations against separate collections: SERVER-20211 
   this was initially marked as duplicate of this ticket.  I re-opened it to track that feature separately, and made it dependent on this ticket being implemented/resolved
- All-or-nothing batches of operations, also known as transactions are out of scope for this ticket and are tracked separately by SERVER-2804.

I updated description of this ticket to clarify that it's only tracking sending batches of mixed operations for a single collection (inserts, updates and removes).",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
TTL support for Timestamp object (not just BSON Date),SERVER-32495,477387,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Minor - P4,,backlog-query-optimization,tpneumat,tpneumat,Dec 31 2017 05:29:24 PM UTC,Nov 14 2020 06:57:06 PM UTC,Feb 17 2021 11:15:26 AM UTC,,,,,,Backlog,Querying,Storage,,,0,,,,,,Our system uses BSON Timestamp type objects for creation times & update times.  We'd really like it if the TTL expireAfterSeconds could be used with this date/time format.   Thanks in advance.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2018-01-02 16:56:28.0,98582400,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,craig.homa(craig.homa),Tue Jan 02 16:56:28 UTC 2018,,,,,,,,,,,,,,backlog-query-optimization(JIRAUSER1257108),tpneumat(tpneumat),kelsey.schubert(thomas.schubert),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i253vr:",,,,,,,"0|i00xxz:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i251zj:","Jan 02 2018 04:56:28 PM UTC;kelsey.schubert;Thank you for the feature request, [~tpneumat]. I've marked this ticket for consideration – please continue to watch for updates.

Kind regards,
Kelsey",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Add an operator that matches an entire document,SERVER-12199,103678,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Minor - P4,,backlog-query-optimization,richard.kreuter,richard.kreuter,Dec 24 2013 04:12:03 PM UTC,Nov 14 2020 06:56:51 PM UTC,Feb 17 2021 11:15:26 AM UTC,,,,,,Backlog,Querying,,,,1,,,,,,"Problem: it's occasionally desirable to be able to specify query that matches a whole document, but the query language doesn't support it (anyway, I can't think of one).

Proposal: add a query operator that matches if and only if a document has all the fields and no extra ones. For example, it might look like this:

{code}
db.foo.find({ ""$whole"" : { ""_id"" : 123 , ""a"" : ""hello"" , ""b"" : ""world"" } });
{code}

This would match only documents having the fields ""_id"", ""a"", and ""b"", but no other fields; and presumably it would match only if the document had those three fields in that order.

Note that this would make certain updates easier to express, e.g., for the update-if-current idiom.


",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,4.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2013-12-24 21:39:07.0,112838400,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,craig.homa(craig.homa),Fri Jul 21 15:56:52 UTC 2017,,,,,,,,No,,,,,,asya(asya),backlog-query-optimization(JIRAUSER1257108),david.storch(david.storch),karo(karo),richard.kreuter(richard@10gen.com),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i03u2n:",,,,,,,"0|i00xlz:",5046,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i176kn:","Jul 17 2017 10:43:17 PM UTC;karo;If I am not mistaken it is still not possible to express this. For arrays we can use $size, but for objects there is no way to ensure that there are no extra values?","Jul 18 2017 03:22:36 PM UTC;david.storch;[~karo], assuming that you do not consider the ordering of the fields significant, this will be possible to express using JSON Schema. We are currently working on adding support for a {{$jsonSchema}} operator in the match language under SERVER-30191.","Jul 18 2017 03:33:24 PM UTC;karo;@David: Awesome. Thanks!","Jul 21 2017 03:56:52 PM UTC;asya;Noting here that this is possible using aggregation by comparing ""$$ROOT"" and specified object.  Similar to a workaround described in SERVER-30197:

{noformat}
db.foo.aggregate([
    {""$match"" : { ""_id"" : 123 , ""a"" : ""hello"" , ""b"" : ""world"" } },
    {""$addFields"" : {__keep:{$eq:[ {$literal: { ""_id"" : 123 , ""a"" : ""hello"" , ""b"" : ""world"" } }, ""$$ROOT""]}}},
    {""$match"" : {__keep:true}}
]);
{noformat}

",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
query $operators should be composable,SERVER-589,11223,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Minor - P4,,backlog-query-optimization,dwight_10gen,dwight_10gen,Jan 30 2010 02:00:34 PM UTC,Nov 14 2020 06:56:42 PM UTC,Feb 17 2021 11:15:26 AM UTC,,,,,,Backlog,Querying,,,,17,,,,,,"e.g. { $size : { $gt : 2 } }.  likewise things with $in and $ne.

may apply on some update operators too?

should only be done when can be done efficiently and when it won't break query optimizer intelligence.
",,,,,,,,,,,,PM-35,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2014-12-19 15:26:23.0,194486400,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,craig.homa(craig.homa),Fri Dec 19 15:26:23 UTC 2014,,,,,,,,No,,,,,,backlog-query-optimization(JIRAUSER1257108),dwight_10gen(dwight_10gen),syzer(syzer),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i07hif:",,,,,,,"0|i00xe7:",6268,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i1hzh3:","Dec 19 2014 03:26:23 PM UTC;syzer;+1",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"New explain mode ""listPlans""",SERVER-17009,180259,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Minor - P4,,backlog-query-optimization,david.storch,david.storch,Jan 22 2015 10:30:42 PM UTC,Nov 14 2020 06:55:17 PM UTC,Feb 17 2021 11:15:26 AM UTC,,,,,,Backlog,Querying,,,,5,,,,,,"Currently there are three explain modes:
* queryPlanner - generates plans, selects the best one
* executionStats - generates plans, selects the best one, runs the winner and reports on its execution
* allPlansExecution - generates plans, selects the best one, runs the winner, reports on the execution of the winner and the losing candidate plans

I propose adding a fourth mode called ""listPlans"". This mode would generate candidate plans, but do nothing more. It will not perform plan selection, and therefore cannot tell you which plan will be executed. However, it would run almost instantaneously because it does not need to use the query execution machinery at all.

Example:
{code}
> db.test.find({a: 1}).explain(""listPlans"")
{
	""queryPlanner"" : {
		""plannerVersion"" : 1,
		""namespace"" : ""test.test"",
		""indexFilterSet"" : false,
		""parsedQuery"" : {
			""a"" : {
				""$eq"" : 1
			}
		},
		""plans"" : [
         {
			""stage"" : ""FETCH"",
			""inputStage"" : {
				""stage"" : ""IXSCAN"",
				""keyPattern"" : {
					""a"" : 1
				},
				""indexName"" : ""a_1"",
				""isMultiKey"" : false,
				""direction"" : ""forward"",
				""indexBounds"" : {
					""a"" : [
						""[1.0, 1.0]""
					]
				}
			}
		},
        {
			""stage"" : ""FETCH"",
			""inputStage"" : {
				""stage"" : ""IXSCAN"",
				""keyPattern"" : {
					""a"" : 1, 
                    ""b"":  1
				},
				""indexName"" : ""a_1_b_1"",
				""isMultiKey"" : false,
				""direction"" : ""forward"",
				""indexBounds"" : {
					""a"" : [
						""[1.0, 1.0]""
					],
					""b"" : [
						""[MinKey, MaxKey]""
					]
				}
			}
		}]
	},
	""serverInfo"" : {
		""host"" : ""dstorch-desktop"",
		""port"" : 27017,
		""version"" : ""2.8.0-rc6-pre-"",
		""gitVersion"" : ""89ddf2d90625a7738b8e48dce1a5776942603d27""
	},
	""ok"" : 1
}
{code}",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,191548800,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,craig.homa(craig.homa),2015-01-22 22:30:42.0,,,,,,,,,,,,,,backlog-query-optimization(JIRAUSER1257108),david.storch(david.storch),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i0333z:",,,,,,,"0|i00xpb:",158273,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i0yfz3:",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Support base conversion in $convert,SERVER-35013,544810,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Minor - P4,,backlog-query-optimization,adinoyi.omuya,adinoyi.omuya,May 16 2018 03:08:09 PM UTC,Nov 14 2020 06:54:18 PM UTC,Feb 17 2021 11:15:26 AM UTC,,,,,,Backlog,Aggregation Framework,Querying,,,0,BIC,expression,,,,"CONV()	Convert numbers between different number bases (add as modes to `$convert`)
See https://dev.mysql.com/doc/refman/8.0/en/mathematical-functions.html for reference.",,,,,,,,,,,,SERVER-32930,,,,,,,,,,,,,,,,,,,,6.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2018-05-17 18:56:08.0,73267200,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,craig.homa(craig.homa),Mon Oct 22 22:38:58 UTC 2018,,,,,,,,,,,,,,adinoyi.omuya(adinoyi.omuya@10gen.com),asya(asya),backlog-query-optimization(JIRAUSER1257108),patrick.meredith(patrick.meredith),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i2gk6f:",,,,,,,"0|i00tmf:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i2gia7:","May 17 2018 06:56:08 PM UTC;asya;Removed 
RAND()	Return a random floating-point value
as that's already tracked in SERVER-30405
","May 17 2018 06:58:30 PM UTC;asya;Removed ROUND() as that's tracked in SERVER-15926
","May 17 2018 06:59:36 PM UTC;asya;Of the others, there are simple workarounds in agg available for SIGN and TRUNCATE.
","Oct 09 2018 04:03:52 PM UTC;asya;CONV is ""convert number to string providing from_base and to_base""
","Oct 22 2018 02:32:03 PM UTC;patrick.meredith;DEGREES and RADIANS were folded into SERVER-32930","Oct 22 2018 10:38:58 PM UTC;patrick.meredith;$round and $trunc (with precision argument) will be handled under SERVER-15926. Ticket description changed to reflect that this ticket is now only adding base conversion to $convert.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Multikeys (indexing keys in a hash) for ranged queries,SERVER-2675,14989,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Minor - P4,,backlog-query-optimization,mlanza,mlanza,Mar 04 2011 04:30:20 AM UTC,Nov 14 2020 06:54:00 PM UTC,Feb 17 2021 11:15:26 AM UTC,,features we're not sure of,,,,features we're not sure of,Internal Client,,,,3,,,,,,"Mongo currently supports multikey indexing (where we index values in an array).  I suggest a feature for specifying an index on the keys and values of a given hash.  This would be synonymous to the common property bag pattern which is sometimes implemented in SQL datastores. 

properties (table)
==============
id (int, PK)
entity_id (int, FK)
key (varchar)
value (varchar)

Sample data (date of birth for several different entities);
INSERT INTO properties (entity_id, key, value) VALUES (101, 'dob', '12/15/1980')
INSERT INTO properties (entity_id, key, value) VALUES (276, 'dob', '11/05/1973')
INSERT INTO properties (entity_id, key, value) VALUES (333, 'dob', '11/05/1944')

Index: key, value

With an index in place we can find everyone born in the 70's.

In Mongo, to accomplish the same you have to add an index directly to the 'dob' attribute of the document.  This is undesirable as our goal is to allow our documents (of any type) to share the same collection.  (This is ideal for topic maps and social CMSes and many other use case, I'm sure.)  It would be more useful if we could instead index the keys/values of a hash and perform ranged queries against those keys.  Any property added to the property bag would be indexed.  Powerful!

INSERT INTO properties (entity_id, key, value) VALUES (101, 'iq', 83)
INSERT INTO properties (entity_id, key, value) VALUES (276, 'iq', 120)
INSERT INTO properties (entity_id, key, value) VALUES (333, 'iq', 103)

Now we've added ""IQ"" to our entities.  We can just as easily perform a greater-than query to grab the smartest people from our collection of whatevers.

I believe this approach is superior to the current multikey approach suggested on:

http://www.mongodb.org/display/DOCS/Using+Multikeys+to+Simulate+a+Large+Number+of+Indexes

The future seems to be all about schema-less DBs.  Indexing a hash of keys/values seems totally in tune with what it means to be schema-less.  Also, you should be able to use hash indexing as part of a compound index.  This would be especially important as one of the indexables would probably be type.

db.whatevers.index({type: 1, attributes: { $hidx: 1}) // $hidx = hash (key/value) index
db.whatevers.find({'type': 'person', 'attributes.iq': {$gt: 100}}) //uses index (not scan)
db.whatevers.find({'type': 'person', 'attributes.dob': {$gte: '1/1/1970', $lte: '12/31/1970'}}) //uses the same index

The document might look like:
{
  type: ""Person"",
  attributes: {
    name: ""Jason"",
    dob: '12/01/1950',
    iq: 99
  }
}

Attributes expressed in this manner seems more natural than:

{
  type: ""Person"",
  attributes: [
    {name: ""Jason""},
    {dob: '12/01/1950'},
    {iq: 99}
  ]
}

Futhermore, as far as I can tell, the multikey style doesn't support ranged queries.

Thanks for reading.  MongoDB is a great work!",,,,,,,,,,,,SERVER-267,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,Fully Compatible,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2017-12-04 19:58:24.0,314323200,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,craig.homa(craig.homa),Fri Mar 04 04:39:40 UTC 2011,,,,,,,,No,,,,,,backlog-query-optimization(JIRAUSER1257108),mlanza(mlanza),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i06tw7:",,,,,,,"0|i0106v:",6587,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i134zz:","Mar 04 2011 04:39:40 AM UTC;mlanza;One potential issue: I suppose there could be attributes that could be extremely lengthy (e.g. the ""body"" property of an essay, the equivalent of the SQL text datatype).  In this case you might have to limit how many characters are indexed.

db.whatevers.index({type: 1, attributes: { $hidx: 1, $max_chars: 200}) 

Of course, this would only be applicable on text values and there would be an implied upper limit if the option was omitted.

Also, this might be a better way of expressing the index:

db.whatevers.index({'type': 1, 'attributes.*': 1})",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Read access to internal GeoHash values,SERVER-12504,107945,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Minor - P4,,backlog-query-optimization,jerdlmrh,jerdlmrh,Jan 28 2014 10:24:38 AM UTC,Nov 14 2020 06:53:57 PM UTC,Feb 17 2021 11:15:26 AM UTC,,,,,,Backlog,Geo,Querying,,,5,,,,,,"I have to manage 1 million geo-points localized all over the earth.
For performance reason, I need to group the points which are in the same ""cells"". I have implemented an algorithm wich computes for each point, its geohash value, so that it is quite easy, using the aggregate framework and functions like $substr, to group and count the points which are in the same cell.

But the documentation says Mongo already computes geoHash values from geo points given as [lon, lat]. 

It would be nice if this internally computed geoHash value could be returned (as a readonly attribute ?) with the documents.

",all,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,4.0,,,,,,,,,,,,,,,,,Fully Compatible,,,,5002K00000czIncQAE,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2014-01-28 14:03:53.0,68342400,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,craig.homa(craig.homa),Wed Dec 19 02:30:14 UTC 2018,,,,,,,,No,,,,,,backlog-query-optimization(JIRAUSER1257108),pasette(dan@10gen.com),jerdlmrh(jerdlmrh),tom.hollander(tom.hollander),wmachugh@i.farm(wmachugh@i.farm),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i03s1b:",,,,,,,"0|i00ylz:",6461,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i01i0v:","Jan 28 2014 02:03:53 PM UTC;pasette;I believe this actually works (not really intentionally, so not a good idea to have any application depend on it).  see: SERVER-8592","Jan 28 2014 10:04:12 PM UTC;jerdlmrh;It seems it does not work on v2.4.9. Anyway, since it is not supported, this kind of trick would not be used for production.
Since ""2d"" indexes are faster than ""2dsphere"" indexes, I would be nice to have this ""feature"" work with ""2d"" indexes...","Dec 18 2018 10:40:37 PM UTC;wmachugh@i.farm;We also have an application with millions of points of data that need to be processed with a geohash. I believe that MongoDB is working on a charting application that will include some maps. It would seem like a natural thing that they would want to rely on internal MongoDB data instead of pushing people to add an additional hash to each record. ","Dec 19 2018 02:30:14 AM UTC;tom.hollander;Yes this would be very useful for Charts to create geo heatmaps and geo clusters.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Feature request: after {criteria}, from {criteria} to {criteria} support",SERVER-8468,64554,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Minor - P4,,backlog-query-optimization,jonathanong,jonathanong,Feb 07 2013 08:30:27 PM UTC,Nov 14 2020 06:52:15 PM UTC,Feb 17 2021 11:15:26 AM UTC,,,,,,Backlog,Querying,,,,0,,,,,,"Many sites have ""infinite scroll"" where pagination doesn't make sense with just ""skips"". Instead, people usually have ""after ID"" or ""from ID1 to ID2"". This report is for this feature, but I am pushing more for the ""after"" feature.

Currently, this can all be done very easily on the client, but it costs extra network bandwidth and CPU. It would thus be much better if done on the server.

The database should check to make sure the `after`, `from`, and `to` parameters are valid (ie those documents exist in the collection). If they don't, it is an invalid query. I'm not sure whether it should return ""no documents found"" or an actual error. Since most likely these parameters are just `_id` parameters, it should not be expensive. This is a check that is relatively more costly on the client.

There should be a ""seek limit"" option, meaning if you have both an `after` and `seek` parameter, if `seek` documents have been checked and skipped for one that matches `after`, give up. This is so the query doesn't check the entire database, specifically when the `sort` parameters are not indexed.

Thus, a query might look like so:

{noformat}

db.things.find({
  deleted: false,
  type: 'great'
}).sort({
  'date.created': -1
}).after({
  _id: ObjectId(""123412341234123412341234"")
}).seek(1000).limit(15)

{noformat}

Where `.after` could just take `ObjectId()` as well.
In fact, an `ObjectId`-only restriction is welcome.

Thus, for the aforementioned query, all ""things"" will be sorted by newest, and the next (at most) 15 documents created after (but not including) ObjectId(""123412341234123412341234"") will be returned.

Hopefully I covered the specifications pretty well. Let me know if you want clarification.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,3.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2016-12-27 20:21:36.0,253238400,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,craig.homa(craig.homa),Fri Feb 08 01:01:03 UTC 2013,,,,,,,,No,,,,,,backlog-query-optimization(JIRAUSER1257108),jonathanong(jonathanong),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i04xd3:",,,,,,,"0|i00xjz:",7033,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i1iu4n:","Feb 07 2013 08:57:17 PM UTC;jonathanong;Okay, just realized that the `seek` option is completely unnecessary on the database, but required if done on the client (since you don't want to return half the collection unnecessarily). However, there should be an extra restriction that `after`, `from`, and `to` parameters are unique.","Feb 07 2013 09:07:39 PM UTC;jonathanong;These parameters can also be considered as implicit sort range values. ","Feb 08 2013 01:01:03 AM UTC;jonathanong;Also require that a `sort` parameter is present.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
sort query results by distance to a point,SERVER-5751,37692,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Minor - P4,,backlog-query-optimization,matulef,matulef,May 02 2012 10:04:43 PM UTC,Nov 14 2020 06:51:17 PM UTC,Feb 17 2021 11:15:26 AM UTC,,,,,,Backlog,Geo,Indexing,Querying,,5,,,,,,"Would be nice to be able to sort the results of a geo query according to their distance to another point.  Syntax would be something like:
db.foo.find(...).sort({loc : {$near : [lat,long]}})",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,277516800,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,craig.homa(craig.homa),2012-05-02 22:04:43.0,,,,,,,,No,,,,,,backlog-query-optimization(JIRAUSER1257108),matulef(matulef),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i05tcf:",,,,,,,"0|i00xin:",6265,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i1ivhb:",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Add columns to covering index without indexing them,SERVER-14570,147319,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Minor - P4,,backlog-server-execution,igor,igor,Jul 15 2014 07:35:23 PM UTC,Nov 10 2020 03:40:14 AM UTC,Feb 17 2021 11:15:26 AM UTC,,,,,,Backlog,Indexing,Storage,,,0,,,,,,"Your support for covering indexes requires that all columns in the covering index are indexed (i.e. part of key in a column family). In some cases, it might make sense to add columns to the covering index without indexing them. In RocksDB (and other key-value storage engines), those columns could be stored as values (with key containing the indexed columns).",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2020-11-09 19:16:07.0,208051200,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,dbeng-pm-bot(dbeng-pm-bot),2014-07-15 19:35:23.0,,,,,,,,,,,,,,backlog-server-execution(backlog-server-execution),igor(igor),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i03gtb:",,,,,,,"0|i00d6v:",127510,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i0yy3r:",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Access an Index as a collection.,SERVER-13987,137117,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Minor - P4,,backlog-query-execution,john.page,john.page,May 19 2014 12:54:21 PM UTC,Oct 21 2020 06:32:02 PM UTC,Feb 17 2021 11:15:26 AM UTC,,,,,,features we're not sure of,Querying,,,,3,,,,,,"I would like the ability to query an index, specifically FTS indexes but also normal ones.

Whilst covered indexes resolve some use cases - I'd like the ability to run a regular expression query over an index, and also get a set of unique values back. For example - to query for all words in the FTS index matching a regex  (and skipping over the index values with the same entry) so a REGEX for /.*one.*/ on the index to get Jones,Bones,Phones and then that can become a FTS query to enable fuzzy search.

",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,3.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2014-09-09 11:27:54.0,203212800,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,craig.homa(craig.homa),Tue Sep 09 11:27:54 UTC 2014,,,,,,,,,,,,,,backlog-query-execution(JIRAUSER1257109),john.page(john.page),Laszlo Balogh(laszlo balogh),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i02o8f:",,,,,,,"0|i010mn:",118046,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i0z1w7:","May 20 2014 08:55:53 AM UTC;john.page;You could alos think of it as a poor mans column store - especially if we had some way of run-lenght encoding key runs

So if the first node in the tree with Value X has a count (counting indexes) and a pointer to the last node with that value we can walk the tree way faster - would coudl also !! compact the indexes by not storing the key value where it's identical, have a special (use previous) value that was only a byte long.","May 20 2014 08:56:38 AM UTC;john.page;Pluggable indexing would be good for this too - although that's probably a big job.","Sep 09 2014 11:27:54 AM UTC;Laszlo Balogh;From the UX perspective,  ""Did you mean""/fuzzy search feature is an absolute must have. One way to make a user leave a website, if she can see no result on the search results page because of a spelling error. (According to Greg Nudleman's book http://www.amazon.co.uk/Designing-Search-Strategies-Ecommerce-UXmatters/dp/0470942231)

We are considering to stop using MongoDB for full text search and adding ElasticSearch to our stack, just because its fuzzy search capability. Obviously this move will add extra complexity to our system, we have to store data two places, we have to deal with network latency, etc.

However by having access to the terms in the inverted index, one can easily implement fuzzy search with MongoDB.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Add let bounds to $project and $addFields (or new versions thereof),SERVER-36524,585460,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Minor - P4,,backlog-query-optimization,patrick.meredith,patrick.meredith,Aug 08 2018 02:39:15 PM UTC,Oct 21 2020 06:25:20 PM UTC,Feb 17 2021 11:15:26 AM UTC,,,,,,Backlog,Aggregation Framework,,,,0,,,,,,"Currently, there is no way to share a computed expression between different fields of a $project or $addFields other than using a previous $project or $addFields. This proposes adding a let bound to precompute shared expressions.  Due to the current syntax of $project and $addFields it seems we will need new pipeline stage names (or perhaps name let and projection $let and $projection?). 


{code: json}
{$addFieldsShared: 
   {
    let: {var1: expr1, var2: expr2, ...},
    projection: {field1: expr3, field2: expr4, ...}
   }
}
{code}

Where expr3 and expr4 can reference var1 and var2. ",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,79747200,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,craig.homa(craig.homa),2018-08-08 14:39:15.0,,,,,,,,,,,,,,backlog-query-optimization(JIRAUSER1257108),patrick.meredith(patrick.meredith),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i2nejj:",,,,,,,"0|i00ydj:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i2ncnb:",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Add $lookup.excludeLocalField to exclude local field from output,SERVER-22787,267181,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Minor - P4,,backlog-query-optimization,joseaio,joseaio,Feb 22 2016 03:37:32 PM UTC,Oct 21 2020 06:25:00 PM UTC,Feb 17 2021 11:15:26 AM UTC,,,,,,Backlog,Aggregation Framework,,,,0,eng-s,,,,,"{noformat}
{ $lookup: {
       from: <collection to join>,
       localField: <field from the input documents>,
       excludeLocalField: <boolean>
       foreignField: <field from the documents of the ""from"" collection>,
       as: <output array field>
} }
{noformat}

If excludeLocalField = true then localField is removed from output 
  IMHO: excludeLocalField must be default to true (excludedd by default)",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,6.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2016-02-22 21:37:25.0,147657600,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,craig.homa(craig.homa),Mon Jun 13 20:27:54 UTC 2016,,,,,,,,,,,,,,backlog-query-optimization(JIRAUSER1257108),charlie.swanson(charlie.swanson),amcgregor(amcgregor),joseaio(joseaio),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i024o7:",,,,,,,"0|i00xtr:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i0j0tj:","Feb 23 2016 05:53:48 PM UTC;charlie.swanson;[~jalvarez_madrigal@hotmail.com], If I understand the request correctly, you're looking for this change in behavior:
h6. Example Schema
|| test.foo || test.bar ||
| {noformat}
{_id: 0, bar_id: 1}
{_id: 1, bar_id: 42}
{noformat} | {noformat}
{_id: 1}
{_id: 42}
{noformat} |

h6. Example Pipeline
{code:js}
db.foo.aggregate([
  {$lookup: {
    from: ""bar"",
    localField: ""bar_id"",
    foreignField: ""_id"",
    as: ""bars""
  }}
])
{code}

h6. Example Results, current behavior
{noformat}
{_id: 0, bar_id: 1, bars: [{_id: 1}]}
{_id: 1, bar_id: 42, bars: [{_id: 42}]}
{noformat}
h6. Example Results, desired behavior
{noformat}
{_id: 0, bars: [{_id: 1}]}
{_id: 1, bars: [{_id: 42}]}
{noformat}

If the {{$lookup}} stage had included {{excludeLocalField: false}}, then the output would match the current behavior? Can you confirm?","Feb 24 2016 12:00:48 PM UTC;joseaio;Yes, its correct (but I think that <excludeLocalField: true> must hide/remove local fields)","Feb 24 2016 03:17:46 PM UTC;charlie.swanson;Oh, I'm sorry. You want it to remove *all* local fields? Can you provide an example of what you mean?","Feb 24 2016 03:57:33 PM UTC;joseaio;No, sorry for my poor explanation:
In your example:

db.foo.aggregate([
  {$lookup: {
    from: ""bar"",
    localField: ""bar_id"",
    foreignField: ""_id"",
    excludeLocalField: true,
    as: ""bars""
  }}
])
 if the $lookup stage had included excludeLocalField: true (instead of false) then remove referenced localField (""bar_id"" in your example)","Apr 23 2016 10:18:49 AM UTC;joseaio;A possible workaround for this: SERVER-18966 (""allow exclusion in $project stage"")","Jun 13 2016 08:27:54 PM UTC;amcgregor;To date I have resolved this by simply having the $lookup use the same field name for both {{from}} and {{as}} keys.  This replaces the reference with an array of objects matching the reference, often used with projection.  As an example:

{code:json}
db.foo.aggregate([
    {""$group"": {""_id"": ""$division"", ""latest"": {""$first"": ""$invoice""}},
    {""$lookup"": {""localField"": ""latest"", ""from"": ""Invoices"", ""foreignField"": ""_id"", ""as"": ""latest""}},
    {""$unwind"": ""$latest""}
])
{code}

The immediate unwind step is a fairly common pattern, too.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Allow $cond to accept longer arrays,SERVER-20284,228366,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Minor - P4,,backlog-query-optimization,kperry,kperry,Sep 03 2015 08:26:19 PM UTC,Oct 21 2020 06:24:01 PM UTC,Feb 17 2021 11:15:26 AM UTC,,,,,,Backlog,Aggregation Framework,,,,0,expression,,,,,"Why not allow the array form of $cond to accept longer arrays of if-then-elseif-then conditions?  Instead of restricting it to only accepting arrays of length 3, it could accept any array of length 2*n + 1, with obvious interpretation: { ""$cond"": [ if, then, elseif, then, elseif, then, ..., else ] }.  This is clearer and simpler than having to nest multiple $cond terms.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,5.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2016-01-20 20:18:37.0,113011200,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,craig.homa(craig.homa),Wed Jul 19 17:52:33 UTC 2017,,,,,,,,,,,,,,asya(asya),backlog-query-optimization(JIRAUSER1257108),kperry(kperry),perry@princeton.edu(perry@princeton.edu),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i02knz:",,,,,,,"0|i00xsn:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i0pltr:","Jan 04 2017 07:01:00 PM UTC;asya;SERVER-10689 resolves this ticket, yes?
","Jan 05 2017 03:43:28 PM UTC;perry@princeton.edu;Well, sort of.  Using $switch is certainly cleaner than the alternative of using multiple embedded $conds.  But extending $cond as I've suggested would give an even cleaner, more compact way of writing the same statements, if desired.   Most languages do implement both ""switch"" and ""elseif"" constructs.  Unless you have some particular reason not to, it still seems like this would be a nice feature to consider adding.","Jan 05 2017 07:18:28 PM UTC;asya;I think if we leave it open we would have to make it clear what the desired syntax for $cond could be.

Currently $cond accepts one of the following syntax:
{noformat}
{$cond: [ <if-expression>, <then-expression>, <else-expressions> ] }

or

{$cond:  { if: <if-expression>, then: <then-expression>, else: <else-expressions> } }
{noformat}

Adding to array would raise an ambiguity of what each subsequent array element means (if there's a 4th element, what is it? In your example is would be last else but third element would be different than in the 3-element array case vs 4-array case which is confusing to read).

Using named keys is problematic because you cannot have the same keyname twice (so you can't have multiple 'else-if' etc).

","Jan 05 2017 08:58:07 PM UTC;perry@princeton.edu;Yes, it's true the ""meaning"" of the ""3rd element"" is different for a 3-element array than for a longer array, because there is always the trailing ""else"" element.  But if you know you're writing an if-then-else, there's really only one reasonable decoding of what an array of any particular length means: the 2*n + 1 terms are used as n ""if-else"" pairs, plus a trailing ""else"" expression.  This, along with the fact that the array length must be odd, can be made clear in the doc.  The behavior would actually be somewhat similar to that of Oracle's DECODE() function, which has been in use for decades (https://docs.oracle.com/cd/B19306_01/server.102/b14200/functions040.htm).","Jul 19 2017 05:52:33 PM UTC;asya;I think this is more a request for terser version of switch when the same value is being compared to different possible values.

For the record, DECODE is something like this:
{noformat}
DECODE (warehouse_id, 1, 'Southlake', 
                      2, 'San Francisco', 
                      3, 'New Jersey', 
                      4, 'Seattle',
                      'Non domestic')  --default value
{noformat}

This is like a C switch statement, rather than $switch/$case we implemented already which evaluates completely independent case statements.
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
$toUpper / $toLower should support locale-aware case mappings,SERVER-36429,581780,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Minor - P4,,backlog-query-optimization,ashevchuk,ashevchuk,Aug 03 2018 12:18:10 PM UTC,Oct 21 2020 06:23:05 PM UTC,Feb 17 2021 11:15:26 AM UTC,,,,,,Backlog,Aggregation Framework,,,,0,,,,,,"$toUpper / $toLower currently only have defined behavior for ASCII characters. Users should be able to perform case folding / case mapping for all Unicode code points, according to locale-specific rules. It looks like ICU has support for this: http://userguide.icu-project.org/transforms/casemappings.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2018-08-03 14:08:03.0,80179200,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,craig.homa(craig.homa),Fri Aug 03 14:26:07 UTC 2018,,,,,,,,,,,,,,ashevchuk(ashevchuk),backlog-query-optimization(JIRAUSER1257108),david.storch(david.storch),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i2mrtz:",,,,,,,"0|i00ydb:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i2mpxr:","Aug 03 2018 02:08:03 PM UTC;david.storch;Hi [~ashevchuk],

Thanks for filing this report! A collation is nothing more than a comparator between two strings. Therefore, a collation does not specify case mapping rules. Our documentation specifies that [$toUpper only has well-defined behavior for ASCII characters|https://docs.mongodb.com/manual/reference/operator/aggregation/toUpper/#behavior] (and [same for $toLower|https://docs.mongodb.com/manual/reference/operator/aggregation/toLower/#behavior]). This is working as designed.

I am going to convert this into a feature request to permit locale-aware case folding in the MongoDB aggregation framework.

Best,
 Dave","Aug 03 2018 02:26:07 PM UTC;ashevchuk;Yes, locale-aware case folding would be nice.
Thanks.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
aggregation framework should have a $find expression,SERVER-44441,990456,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Minor - P4,,backlog-query-optimization,ben@ethika.com,ben@ethika.com,Nov 05 2019 07:43:21 PM UTC,Oct 20 2020 07:02:41 PM UTC,Feb 17 2021 11:15:26 AM UTC,,4.2.1,,,,Backlog,Aggregation Framework,,,,2,expression,qopt-team,,,,"Aggregation framework has a filter, which filters an array (and returns an array).

I wish there was an equivalent to do a javascript Array.find(), where the filter would return the first match inside of the array
{code:java}
db.test.insert({people: [{name: 'bob', value: 1}, {name: 'fred', value: 2}]});

db.test.aggregate([{$addFields: {
  person: {
    $find: {
      input: '$people',
      cond: {$eq: ['$$this.name', 'fred']}
    }
  },
  people: '$$REMOVE'
}}]);

##returns
{person: {name: 'fred', value: 2}}{code}
 ",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,3.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2019-11-05 21:17:36.0,40521600,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,craig.homa(craig.homa),Tue Nov 05 23:16:10 UTC 2019,,,,,,,,,,,,,,asya(asya),backlog-query-optimization(JIRAUSER1257108),ben@ethika.com(ben@ethika.com),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i4jzxr:",,,,,,,"0|i00z9b:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i4jy1j:","Nov 05 2019 07:44:39 PM UTC;ben@ethika.com;Oops, the return should obviously be `\{person: {name: 'fred', value: 2}}`","Nov 05 2019 09:17:36 PM UTC;asya;You can always use $arrayElemAt expression to select the first element from array (whether it has one element or not).  But it makes sense to have a simple way to pick out first element that matches a particular condition.  I’ll check if there’s already a ticket for this. ","Nov 05 2019 11:16:10 PM UTC;asya;[~ben@ethika.com] you can do it already with this combination of expressions:

{noformat}
db.test.aggregate({$addFields:{
   person:{
      $arrayElemAt:[ 
         ""$people"", 
         {$indexOfArray:[""$people.name"",""fred""]}
      ]
   }
}})
{noformat}

I'm not sure ""$find"" is a preferred term due to possible confusion with find command, but I will set this to be considered by the query team.
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Describe collection schema or explain validation to get current schema,SERVER-51519,1512846,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Minor - P4,,backlog-query-optimization,jhemphill@tecnicocorp.com,jhemphill@tecnicocorp.com,Oct 13 2020 04:14:19 PM UTC,Oct 20 2020 07:01:29 PM UTC,Feb 17 2021 11:15:26 AM UTC,,,,,,Backlog,Querying,Tools,,,0,qopt-team,,,,,"There's not a good way currently to get Mongo's bson types for every field that exists in a collection. Trying to use external tools to sample and guess at the bson types has proved difficult. 

This would be especially helpful when creating validators to give a starting point, or for creating documentation.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,"Oct 19 2020 07:29:05 PM UTC;edwin.zhou;Screen Shot 2020-10-19 at 2.55.19 PM.png;https://jira.mongodb.org/secure/attachment/283529/Screen+Shot+2020-10-19+at+2.55.19+PM.png",,,5.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2020-10-16 23:43:06.0,10281600,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,craig.homa(craig.homa),Tue Oct 20 15:33:02 UTC 2020,,,,,,,,,,,,,,backlog-query-optimization(JIRAUSER1257108),edwin.zhou(JIRAUSER1257066),jhemphill@tecnicocorp.com(JIRAUSER1257252),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i70e2v:",,,,,,,"0|i6ut5b:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i70c6f:","Oct 19 2020 06:56:36 PM UTC;edwin.zhou;Hi [~jhemphill@tecnicocorp.com],

Thank you for your request. We'd like some additional information about your use case. Are you looking to produce a list of fields given a smaller sample of your collection? In this case, you can use [MongoDB Compass|https://www.mongodb.com/products/compass], a GUI for MongoDB to provide a schema with the types of each field in your collection. I've attached an image as an example of the output. 

 !Screen Shot 2020-10-19 at 2.55.19 PM.png|width=100%! 

Please let me know if this is adequate for your use case.","Oct 19 2020 08:00:09 PM UTC;jhemphill@tecnicocorp.com;Hello, 

No I'm talking about programmatic access. Compass is fine for looking at the database for manual review, but there's no way to export that schema or consume it with other applications to make it actionable. Having some way to collect the schema from a record would let an external program determine both the widest and narrowest schema that exist on a collection and would allow for point-in-time documentation to be maintained externally.

For example, if the schema is also being tracked in the consuming codebase, it can only document the JSON types since that's all it has the ability to obtain, and if that's the case, it wouldn't be possible to generate new collections derived from that documentation and still be able to guarantee compatibility with the one it was documenting.","Oct 19 2020 09:04:37 PM UTC;edwin.zhou;[~jhemphill@tecnicocorp.com], does your use case need to also query nested documents?

Edwin","Oct 19 2020 10:10:12 PM UTC;jhemphill@tecnicocorp.com;@edwin.zhou , if you mean directly query for only the schema of a nested document, no; but get the schema of the nested documents when retrieving the whole document schema, yes.

Although I see the issue. That would have to be configurable, since I'm sure use-case by use-case some people would either want to ignore them, sample some number, or analyze all of them.

It might make sense as available in the aggregation pipeline, and have it ignore or provide some property/hook by default to let that behavior be configured or consumed in user space.  ","Oct 20 2020 03:33:02 PM UTC;edwin.zhou;[~jhemphill@tecnicocorp.com],
 Thank you for further clarifying your use-case. We're assigning this ticket to the appropriate team to be evaluated against our currently planned work. Updates will be posted on this ticket as they happen.

In the meantime, you can attempt to create an aggregation pipeline using {{$objectToArray}} and {{$map}}. Here is a snippet that will flatly display the types of each field as a starting point.
{noformat}db.collection.aggregate(
  [{
    $project: {
      types: {
        $arrayToObject: {
          $map: {
            input: {
              $objectToArray: ""$$ROOT""
            },
            in: {
              v: {
                $type: ""$$this.v""
              },
              k: ""$$this.k""
            }
          }
        }
      }
    }
  }]
)
{noformat}
Which outputs:

{noformat}
_id:ObjectId(""5f74b4200885de90a48fd57e""),
types: {
  _id:""objectId"",
  title:""string"",
  year:""double"",
  rated:""string"",
  runtime:""double"",
  countries:""array"",
  genres:""array"",
  director:""string"",
  writers:""array"",
  actors:""array"",
  plot:""string"",
  poster:""string"",
  imdb:""object"",
  tomato:""object"",
  metacritic:""double"",
  awards:""object"",
  type:""string""
}
{noformat}


Best,

Edwin",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"support the equivalent of ""select for update""",SERVER-44054,971613,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Minor - P4,,backlog-query-execution,mdcallag,mdcallag,Oct 16 2019 10:51:06 PM UTC,Oct 20 2020 06:56:41 PM UTC,Feb 17 2021 11:15:26 AM UTC,,,,,,Backlog,,,,,0,qexec-team,,,,,"The approach suggested [here|https://www.mongodb.com/blog/post/how-to-select--for-update-inside-mongodb-transactions] forces the server to do extra work by committing and replicating changes to objects that are otherwise only being read.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,3.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2019-10-21 19:56:03.0,41644800,,,,,,,,,,,,,,,,,,,,,,,,,,,,false,craig.homa(craig.homa),Wed Oct 23 14:52:13 UTC 2019,,,,,,,,,,,,,,backlog-query-execution(JIRAUSER1257109),carl.champain(carl.champain),mdcallag(mdcallag),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i4gyd3:",,,,,,,"0|i00zan:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i4gwgv:","Oct 17 2019 03:56:14 PM UTC;mdcallag;Modifying the selected document to prevent it from being modified by others increases the chance for write conflict errors. Since this would be done in a conversational transaction (start, modify ""read"" doc, modify other doc, commit) then the retry can't be hidden and the app developer must catch/retry. So the benefit for this feature request is performance, efficiency and making life easier for a developer.

I asked about this [on mongo-user|[https://groups.google.com/forum/#!topic/mongodb-user/IsqqJwaH9sk]

|https://groups.google.com/forum/#!topic/mongodb-user/IsqqJwaH9sk]","Oct 21 2019 07:56:03 PM UTC;carl.champain;Hi [~mdcallag],

Thanks for taking the time to submit this request.
We're assigning this ticket to the Query team to be evaluated against our currently planned work. Updates will be posted on this ticket as they happen.

Kind regards,
Carl","Oct 23 2019 02:52:13 PM UTC;mdcallag;The case I am concerned about is ""select for update"" from document A, then modify document B where modifying doc A to get a lock on it is extra work. 

When the user does ""select for update"" from doc A, then modifies doc A there isn't extra work using the approach suggested by the blog.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Enforce schema on system collections,SERVER-39122,675999,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Minor - P4,,backlog-server-sharding,mark.baker-munton,mark.baker-munton,Jan 22 2019 05:52:46 PM UTC,Oct 16 2020 08:27:05 AM UTC,Feb 17 2021 11:15:26 AM UTC,,,,,,Backlog,Usability,,,,1,ShardingRoughEdges,,,,,"Enforce schema on system collections to prevent erroneous configurations being allowed.

Specifically, the {{_secondaryThrottle}} field in the {{config.settings}} collection was set incorrectly due to [DOCS-11936|https://jira.mongodb.org/browse/DOCS-11936]. If the schema was enforced, the erroneous config could have been prevented.

",,,,,,,,,,,,SERVER-25446,SERVER-43286,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,500A000000cSDsbIAG,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2019-01-24 16:25:58.0,64022400,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,nuno.costa(nuno.costa),Wed Feb 06 23:27:30 UTC 2019,,,,,,,,,,,,,,asya(asya),backlog-server-sharding(backlog-server-sharding),mark.baker-munton(mark.baker-munton),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i32u7b:",,,,,,,"0|i362vr:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i32sb3:","Feb 06 2019 05:23:45 PM UTC;asya;[~mark.baker-munton] is this ticket fundamentally same as  SERVER-25446?   In either case, I'm re-assigning it to the sharding team to triage as these system collections belong to them.","Feb 06 2019 11:27:30 PM UTC;mark.baker-munton;[~asya] fundamentally the same request as SERVER-25446 just extending out the schema validation functionality to include the {{config.settings}} collection (and possibly other system collections).",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Native types for IP Address and MAC Address,SERVER-2413,14321,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Minor - P4,,backlog-server-platform,dnevil,dnevil,Jan 26 2011 11:54:24 PM UTC,Jul 17 2020 03:18:33 PM UTC,Feb 17 2021 11:15:26 AM UTC,,,,,,features we're not sure of,JavaScript,,,,13,,,,,,"I am porting a network-oriented application from PostgreSQL to MongoDB.  The application makes heavy use of the 'inet' and 'mac' data types, especially when searching for IP addresses in a netblock.

One could argue that IP Addresses can simply be stored and searched as strings, which is true.  However, it becomes increasingly difficult when you throw in netmasks and IPv6.  For example, the IPv6 address ""FFAB::1234"" is really ""FFAB:0000:0000:0000:0000:0000:0000:1234"", and both forms are acceptable string representations.

I could not find any plans for including this feature in MongoDB, so I decided to tackle it myself.  The resulting work can be found at:

https://github.com/redmeadowman/mongo

The change involves adding the new types to BSON, and adding new classes to the JavaScript shell.  I've added two new types, IpAddr() and MacAddr().

IpAddr - Contains an IPv4 or IPv6 address along with a netmask
    Examples to try in the shell:
    var ip4 = IpAddr(""192.168.1.1"")
    ip4.mask
    ip4.version
    ip4.mask = 16
    ip4.mask
    ip4 = IpAddr(""192.168.1.1/24"")
    ip4.mask
    ip4.network
    ip4.broadcast
    var ip6 = IpAddr(""1234::abcd"");
    ip6.mask
    ip6.version
    ip6.mask = 64
    ip6.mask
    var ip6 = IpAddr(""1234::abcd/32"");
    ip6.network
    ip6.broadcast
    ip6 = IpAddr(""::192.168.1.1/16"");
    db.test.insert({ip: IpAddr(""192.168.1.1"")})
    db.test.insert({ip: IpAddr(""1234::"")})
    db.test.find()

MacAddr - Contains a 6-octet Media Access Control Address (Ethernet hardware address)
    var mac = MacAddr(""00:23:45:ab:cd:ef"");
    db.test.insert({mac: MacAddr(""1:2:3:4:5:6"")})
    db.test.find()

The application I'm porting also makes heavy use of UUIDs, so I've modified the Shell UUID type so it is now a native type of JavaScript.  This now works (no need to say 'new UUID(...'
    var uuid = UUID(""123456789abcdef12345678901234567"");
    db.test.insert({uuid: UUID(""123456789abcdef12345678901234567"")})

The branch listed above includes the code changes against the latest master (as of 24 Jan 2011), plus unit tests in both dbtests/ and jstests/.

",Fedora 14 x86_64,,,,,,,,,,,SERVER-2242,,,,,,,,,,,,,,,,,,,,9.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2011-09-02 05:37:59.0,118627200,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,jessica.sigafoos(jessica.sigafoos),Tue May 16 01:10:58 UTC 2017,,,,,,,,No,,,,,,sallgeud(sallgeud),dnevil(dnevil),backlog-server-platform(backlog-server-platform),eliot(eliot),ramnes(ramnes),dev.meghraj(dev.meghraj),bra@fsn.hu(bra@fsn.hu),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i06x4n:",,,,,,,"0|i05ro7:",6546,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i08fk7:","Sep 02 2011 05:37:59 AM UTC;eliot;Trying not to add too many types to BSON, but might be worth it at some point.","Sep 05 2012 10:49:57 PM UTC;dnevil;The lack of support for native IP and MAC addresses has prevented me from using MongoDB.  Any possibility of the main branch picking up the code?  I'd be willing to port these features from 1.8 to the latest branch.","Feb 10 2014 07:30:10 PM UTC;bra@fsn.hu;I haven't touched mongodb since the 1.4->1.6 upgrade (which runs in an isolated environment happily since then :), but for a new project, I started to re-evaluate possible solutions and I sadly discovered that mongodb still doesn't have native IP address support.
This is a must everywhere where the task is not only to store and search a single IP address, but handle subnetting, or IPv6.
","Feb 10 2014 07:45:59 PM UTC;sallgeud;Have you considered, at least in the short term, storing the data as a 64bit integer and writing your own serializer/deserializer to convert? I'm not sure which language you're writing in, but this seems like it would get you at least a portion of what you want. I wish the bsonspec supported unsigned integers so we could use a 32bit, but 64 works well enough.  When you want to search for all IPs in a range in your app, you just calculate the start and finish integer equiv of the IP.  Given that an ipv4 address is just a 32bit object, any data type that supports range queries (gt, lt, etc) would work just fine.  You could even use hex strings if you were so inclined. Though, I would wager that an int would search faster because of its fixed scope [vs text, etc]","Feb 10 2014 08:05:27 PM UTC;bra@fsn.hu;Sure, but it quickly starts getting ugly.
Like when I'd like to store CIDR format addresses and want to check whether a given address (/32 or /128), or a subnet is in any of them.
Yes, it can be solved by math (of course, that's the same the DB does with supporting these kind of addresses), but it's so hackish.","Jan 29 2016 05:36:12 PM UTC;ramnes;I just discovered there's no BSON type to deal with IP adresses, bummer! I'd love to see that feature implemented.","Jan 29 2016 07:16:52 PM UTC;sallgeud;I think mongo could add support for IP Address searching, ranges, etc, without having to change BSON to add it as a feature.  Addresses themselves are just a set of bytes. They could use standard binary storage and do searching based on bit masking (which would actually index incredibly well).  You could also, in theory do some CIDR type searches.  Really, you're talking about wiring up something to interpret the string forms of an IP into binary, and then wiring up something to allow you to search those.

CIDR search: db.Collection.find({IPAddress; { $in: Network('192.168.0.0/16') } });

Then when entering the data, you'd just need something to convert it to binary properly... but that could be done in drivers.
","May 16 2017 01:03:03 AM UTC;dev.meghraj;+1

MondoDB is known for scalable and big database and performance.

so quering IP address sholud also be faster, in my app i also want to store list of IP Addresses in v4 and v6 including CIDR notations then for every client i need to check weather client's ip listed in blacklist or not.

Someone has already done work please check, merge and doc it.","May 16 2017 01:10:58 AM UTC;sallgeud;It's actually insanely fast to do in your code... Just wire it up as binary and search ranges. Would be neat to see in drivers. ",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Allow to access BinData binary value from MR,SERVER-3794,22042,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Minor - P4,,backlog-server-platform,s.podkowinski,s.podkowinski,Sep 09 2011 09:08:47 AM UTC,Apr 09 2020 02:23:24 AM UTC,Feb 17 2021 11:15:26 AM UTC,,1.8.3,,,,Backlog,JavaScript,MapReduce,,,3,bson,"mapreduce,",move-sa,platforms-re-triaged,,"Synopsis: please add BinData.getBytes() to be able to deal with BinData value easily from MR

Currently the only way to access the value from a BinData object in your javascript map/reduce job seems to call base64() and decode the value using a custom js function. This is especially inconvenient in cases where you have certain fields packed in your _id (such as customerId, year, month, day in my case) and want to mask out parts of the _id to derive a new key for MR. This would be really easy to do if there was a BinData.getBytes() function returning an array of numbers. 

",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2012-09-05 10:41:56.0,297993600,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,sara.williamson(sara.williamson),2011-09-09 09:08:47.0,,,,,,,,No,,,,,,backlog-server-platform(backlog-server-platform),s.podkowinski(s.podkowinski),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i06gm7:",,,,,,,"0|i05pn3:",6037,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i1iwhb:",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Windows package containing only the mongo shell,SERVER-38908,667616,New Feature,Waiting For User Input,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Minor - P4,,kelsey.schubert,cory.waddingham,cory.waddingham,Jan 08 2019 06:17:13 PM UTC,Feb 21 2020 10:42:29 PM UTC,Feb 17 2021 11:15:26 AM UTC,,,,,,,Packaging,,,,2,,,,,,"We have a request for a build on Windows that contains only the {{mongo}} shell and whatever libraries it requires, the same as we provide for Linux distributions. The key requirement of the request is that the package:
* Be able to be installed without admin access (eg, by a lone developer)
* Include the {{mongo}} shell and be fully usable after install
* Not include the {{mongod}} or {{mongos}} server binaries
* Not include the {{mongodump}} and related tools

Please let me know if you need any additional information. ",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,1.0,,,,,,,,,,,,,,,,,,,,5002K00000d89v7QAA,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2019-01-09 04:24:48.0,66528000,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,acm(acm),2019-01-08 18:17:13.0,,,,,,,,,,,,,,cory.waddingham(cory.waddingham),kelsey.schubert(thomas.schubert),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i31ehr:",,,,,,,"0|i01sjz:",9223372036854775807,,,,,,,,,,,,Dev Platform 2020-02-10,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i31clj:",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Add noexcept specifier to TaskExecutor::schedule functions,SERVER-46228,1157528,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Minor - P4,,backlog-server-servicearch,ben.caimano,ben.caimano,Feb 18 2020 05:55:40 PM UTC,Feb 18 2020 06:23:46 PM UTC,Feb 17 2021 11:15:26 AM UTC,,,,,,Backlog,,,,,0,,,,,,"The [schedule*() family of functions|https://github.com/mongodb/mongo/blob/master/src/mongo/executor/task_executor.h#L212-L267] always return {{StatusWith<Handle>}}. We should liberally apply the noexcept specifier and function try-catch to these functions so that we can trust the StatusWith and avoid try-catches around the function itself.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,31449600,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,ben.caimano(ben.caimano),2020-02-18 17:55:40.0,,,,,,,,,,,,,,backlog-server-servicearch(backlog-server-servicearch),ben.caimano(ben.caimano),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i5c6dz:",,,,,,,"0|i5boaf:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i5c4hj:",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
SNMP opens low order port in master mode,SERVER-16433,172945,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Minor - P4,,backlog-server-security,greg.mckeon,michael.grundy,Dec 05 2014 04:25:51 PM UTC,Jan 21 2020 06:23:23 PM UTC,Feb 17 2021 11:15:26 AM UTC,,2.8.0-rc1,,,,Backlog,Networking,,,,0,28qa,,,,,"Start mongod (enterprise) with the --snmp-master flag. The net-snmp code opens a port for smux on 199. Unless mongod is launched as root (bad) or has permission to open the low port, the follwing confusing message is logged.
{code}[SnmpAgent] [init_smux] bind failed: Permission denied{code}

The message, or that we're opening another port isn't mentioned in the documentation.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2014-12-05 16:30:39.0,195696000,,,,,,,,,,,,,,,,,,,,,,,,,,,,false,sara.williamson(sara.williamson),Fri Dec 05 16:30:39 UTC 2014,,,,,,,,,,,,,,backlog-server-security(backlog-server-security),milkie(milkie),greg.mckeon(greg.mckeon),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i036hr:",,,,,,,"0|i05o0v:",151438,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i033rr:","Dec 05 2014 04:30:39 PM UTC;milkie;The documentation does recommend that master mode only be used for testing and not for production, so I am putting this as minor.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
--keyFile /dev/stdin does not work,SERVER-26565,322657,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Minor - P4,,backlog-server-security,jfcg,jfcg,Oct 11 2016 07:04:17 AM UTC,Jan 21 2020 06:12:56 PM UTC,Feb 17 2021 11:15:26 AM UTC,,3.2.10,,,,Backlog,Security,,,,1,,,,,,"I would like to type the shared secret between members of a replica set on my terminal, and not leave a trace of it in a file on hard disk. So trying to read it from standard input does not work.
Reading from stdin solves my problem? I don't know.
Maybe a new option to read it from users in terminal would be better.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2016-10-13 22:34:15.0,137116800,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,sara.williamson(sara.williamson),Thu Oct 13 22:34:15 UTC 2016,,,,,,,,,,,,,,backlog-server-security(backlog-server-security),jfcg(jfcg),spencer.jackson(spencer.jackson@10gen.com),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i01iu7:",,,,,,,"0|i05qkf:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i0wlz3:","Oct 13 2016 10:34:15 PM UTC;spencer.jackson;Hi! This does seem like it could be useful. Something that might work for you in the meantime, is using x509 cluster authentication with encrypted keys. If you then start your server without --sslPEMKeyPassword, you will be prompted to enter the password used to encrypt the keys. There is a known issue, SERVER-10346, which will cause you to be prompted multiple times. Enter your password each time you're prompted, and the server will start normally.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Check that setFeatureCompatibilityVersion is run on mongos in sharded environments.,SERVER-43833,959521,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Minor - P4,,backlog-server-servicearch,james.phelan,james.phelan,Oct 04 2019 03:40:13 PM UTC,Jan 06 2020 03:34:38 PM UTC,Feb 17 2021 11:15:26 AM UTC,,,,,,Backlog,Sharding,Upgrade/Downgrade,,,0,neweng,,,,,In a sharded cluster the {{setFeatureCompatibilityVersion}} command should be run only on a {{mongos}} it might be a good idea to reject this command if it is run on a {{mongod}} started with either the {{configsvr}} or {{shardsvr}} options.,,,,,,,,,,,,HELP-11015,,,,,,,,,,,,,,,,,,,,0.0,1.0,,,,,,,,,,,,,,,,,,,,5002K00000fM3XyQAK,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2019-11-18 20:55:38.0,43286400,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,haley.connelly(haley.connelly),2019-10-04 15:40:13.0,,,,,,,,,,,,,,backlog-server-servicearch(backlog-server-servicearch),james.phelan(james.phelan),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i4evxr:",,,,,,,"0|i4gju7:",9223372036854775807,,,,,,,,,,,,Sharding 2019-12-16,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i4eu1j:",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Kerberos Login Mapping Functionality,SERVER-14906,152742,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Minor - P4,,backlog-server-security,osmar.olivo,osmar.olivo,Aug 14 2014 10:27:43 PM UTC,Nov 22 2019 12:48:08 PM UTC,Feb 17 2021 11:15:27 AM UTC,,,,,,features we're not sure of,Security,,,,0,,,,,,"Allow for custom mappings to be defined between Kerberos accounts and mongodb users. 

The idea here being that the mongodb account names do not precisely match up with the kerberos account username and the kerberos account has the possibility to log in to any account out of the subset it is mapped to. 

The reason this feature would be useful is for limiting the permissions/privileges a user runs with that user being able to temporarily elevate privileges  during emergencies. The key here is to  have all of these actions be audited appropriately.  ",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,500A000000UaYr5IAF,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2015-10-29 15:33:48.0,205459200,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,,2014-08-14 22:27:43.0,,,,,,,,,,,,,,backlog-server-security(backlog-server-security),osmar.olivo(osmar.olivo@10gen.com),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i03f1b:",,,,,,,"0|i05rrj:",6654,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i0yvqn:",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Secondaries (priority=0) able to specify filter criteria for the data they receive from the primary,SERVER-9780,76548,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Minor - P4,,backlog-server-repl,matt.kalan,matt.kalan,May 24 2013 06:51:35 PM UTC,Jul 17 2019 01:43:59 PM UTC,Feb 17 2021 11:15:27 AM UTC,,,,,,Backlog,Replication,,,,4,tertiary,,,,,"This is useful in cases in which Mongo is being used for distributing data, not just using replication for high-availability.  

One way of doing this would be that secondaries can specify a query for the data they want to receive from the primary.  

This is an extension and further refinement of SERVER-1559.  ",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,4.0,,,,,,,,,,,,,,,,,,,,,5002K00000f12GFQAY,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2013-05-24 21:22:43.0,54432000,,,,,,,,PM-1148,,,,,,,,,,,,,,,,,,,,true,,Wed May 29 07:01:54 UTC 2019,,,,,,,,No,,,,,,tibwiz(tibwiz),backlog-server-repl(backlog-server-repl),joe.enzminger(joe.enzminger),matt.kalan(matt.kalan@10gen.com),tess.avitabile(tess.avitabile),venkata.vishwanath.reddy.kothakapu@hsbc.co.in(venkata.vishwanath.reddy.kothakapu@hsbc.co.in),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i04h4n:",,,,,,,"0|i0c25z:",6417,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i1i0wn:","Oct 08 2018 09:51:28 AM UTC;venkata.vishwanath.reddy.kothakapu@hsbc.co.in;Any updates on this issue please ?

This feature will remove unnecessary manual coding/testing and makes it much simpler in use cases, where there may be restrictions applied as the data belongs to a different countries than the country hosting the replicaset nodes..","Oct 08 2018 02:57:59 PM UTC;tess.avitabile;Hi [~venkata.vishwanath.reddy.kothakapu@hsbc.co.in],

This is not something we are currently actively working on, in lieu of other higher priority projects, but it is something we would like to do in the future. To help us understand your pain and to ensure the appropriate priority of this ticket for future releases, can you expand on your use case? Why is this feature valuable to you?

Regards,

Tess","Apr 10 2019 07:50:07 PM UTC;joe.enzminger;There are three use cases where this would be highly desirable:

1)  Backups - in a disaster recovery scenario, we often don't need to recover our larger collections quickly.  We need our ""state"" data up and running fast, and then we can come in behind and rebuild transaction information.  Being able to set up a hidden node for backups that doesn't replicate the entire database enables this nicely.  It also allows us to get this node ""up"" more quickly since it doesn't have to replicate the large collections during the initial sync.  We current

 

2)  Reporting/Business Intelligence - same scenario.  It allows us to get new nodes built for reporting/BI that don't have to necessarily replicate data that isn't used for reporting.  

 

3)  Event Generation - using streams or the oplog to generate events is a fantastic side effect of the Mongo architecture.  However, using a secondary that is being used for fault tolerance is somewhat dangerous.  We typically use a hidden, priority 0 node for this in our architecture.  For these nodes, the applications using them generally only use a very small amount of the data.  Being able to blacklist collections would be desirable.

 

 ","May 29 2019 07:01:54 AM UTC;tibwiz;Any updates on this issue?

We have a use case where we want to replicate only portion of the data to a disaster recovery site. In the absence of this, its forced to run separate instances where the locally significant data is written to one instance(s) and globally significant data is written to another instance, which is replicated to a disaster recovery site.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Add support for bulk loading (with WiredTiger),SERVER-16087,168570,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Minor - P4,,backlog-server-repl,scotthernandez,scotthernandez,Nov 11 2014 06:03:09 PM UTC,May 23 2019 01:52:10 PM UTC,Feb 17 2021 11:15:27 AM UTC,,,,,,Needs Further Definition,Replication,Sharding,Storage,,0,bulk,load,storage,wiredtiger,,"Since some storage engines, like WiredTiger, have special bulk loading options it would be good if the server supported them.

http://source.wiredtiger.com/2.4.1/tune_bulk_load.html

*Note*:
This may be more complicated in sharding and with replication but in the standalone case it should be straight-forward. Even through that is true, unless support exists for all deployment types it is probably best not to support any.",,,,,,,,,,,,SERVER-16206,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2015-01-17 13:20:57.0,197769600,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,milkie(milkie),2014-11-11 18:03:09.0,,,,,,,,Cannot,,,,,,backlog-server-repl(backlog-server-repl),scotthernandez(scotthernandez),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i00vzb:",,,,,,,"0|i0c2qv:",147419,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i03ph3:",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Fast, thread-safe counters for statistics.",SERVER-5026,31123,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Minor - P4,,backlog-server-servicearch,schwerin,schwerin,Feb 21 2012 05:25:08 PM UTC,Mar 25 2019 03:26:56 PM UTC,Feb 17 2021 11:15:27 AM UTC,,,,,,Backlog,Concurrency,Performance,,,1,,,,,,"For performance measurement, we should have a system of counters that are not lossy, and whose writes do not impact performance (i.e., increase cache misses or lock contention).",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,Fully Compatible,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2016-03-24 16:27:34.0,154656000,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,greg.mckeon(greg.mckeon),Thu Mar 24 16:27:34 UTC 2016,,,,,,,,No,,,,,,schwerin(schwerin),backlog-server-servicearch(backlog-server-servicearch),kyle.suarez(kyle.suarez),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i0621j:",,,,,,,"0|i05qlr:",6730,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i1iwaf:","Mar 24 2016 04:27:34 PM UTC;kyle.suarez;I'm assuming we're talking about operation counters like the OpCounters? If so, it would be nice if the counters were 64-bit integers, which would then kill SERVER-14364 with one stone.

Another related issue that affects the current OpCounters is that all of the counters fit on the same cache line, which could lead to contention. (This is just a ""what-if"" and should be something we keep in mind when doing performance tests.)",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Introduce a collection type that is replicated to all shards in a cluster,SERVER-11506,96618,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Minor - P4,,backlog-server-sharding,matt.kalan,matt.kalan,Oct 31 2013 07:17:35 PM UTC,Nov 15 2018 03:53:29 PM UTC,Feb 17 2021 11:15:27 AM UTC,,,,,,Backlog,Sharding,,,,0,,,,,,This is more important if we add joins to a collection within a shard so that small collections can be stored with other data to join together ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2013-10-31 22:03:23.0,230169600,,,,,,,,PM-836,,,,,,,,,,,,,,,,,,,,false,greg.mckeon(greg.mckeon),Fri Nov 01 14:37:09 UTC 2013,,,,,,,,No,,,,,,schwerin(schwerin),backlog-server-sharding(backlog-server-sharding),matt.kalan(matt.kalan@10gen.com),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i03xtr:",,,,,,,"0|i0c6ef:",7283,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i17btj:","Oct 31 2013 10:03:23 PM UTC;schwerin;[~matt.kalan@10gen.com], I've updated the description to what I think you're requesting.  Can you confirm?","Nov 01 2013 02:37:09 PM UTC;matt.kalan;That sounds a bit more accurate.  ",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Builtin role which only has INSERT/UPDATE/DELETE/FIND/STATs (Not create/drop collection & index),SERVER-36141,571841,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Minor - P4,,backlog-server-security,matt.lee,matt.lee,Jul 16 2018 04:16:17 AM UTC,Oct 15 2018 06:41:55 PM UTC,Feb 17 2021 11:15:27 AM UTC,,3.4.16,,,,Backlog,Security,,,,0,,,,,,"A lot of companies has their own DBA team,

And schema modification like create/drop index & collection task is responsible for DBA team. And DBA wants that schema change will be done by DBA only not Developer.

 

But current implementation of MongoDB, All CRUD(INSERT & UPDATE & DELETE & FIND) and schema change actions are included ""readWrite"" role. So CRUD and Schema-change action can not be separated when use builtin-role. We can make it with user-defined role, but user-defined role has some issues like https://jira.mongodb.org/browse/SERVER-17513 (we should make user defined role for each database).

 

I think make another builtin-role is easy. so what do you think make pureReadWriteRole for this use case.

```

// Read-write role
 readWriteRoleActions += readRoleActions;
 readWriteRoleActions
 << ActionType::convertToCapped // db admin gets this also
 << ActionType::createCollection // db admin gets this also
 << ActionType::dropCollection
 << ActionType::dropIndex
 << ActionType::emptycapped
 << ActionType::createIndex
 << ActionType::insert
 << ActionType::remove
 << ActionType::renameCollectionSameDB // db admin gets this also
 << ActionType::update;

// Pure read-write role (only contains READ and insert & remote & update)
 pureReadWriteRoleActions += readRoleActions;
 pureReadWriteRoleActions
 << ActionType::emptycapped
 << ActionType::insert
 << ActionType::remove
 << ActionType::update;

```",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2018-09-30 21:32:19.0,81820800,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,spencer.jackson(spencer.jackson@10gen.com),2018-07-16 04:16:17.0,,,,,,,,,,,,,,backlog-server-security(backlog-server-security),matt.lee(matt.lee),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i2l2of:",,,,,,,"0|i053hj:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i2l0s7:",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Allow adding custom data to roles,SERVER-21731,241859,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Minor - P4,,backlog-server-security,jozefdobos,jozefdobos,Dec 02 2015 12:37:48 PM UTC,Sep 10 2018 05:59:18 PM UTC,Feb 17 2021 11:15:27 AM UTC,,,,,,Backlog,Security,,,,0,,,,,,"User entries in MongoDB allow storage of custom data field. It would be very handy to add the same functionality also to custom roles (for instance, we'd like to store color and description with the roles at 3D Repo).

Thus I propose the addition of 
{noformat}
customData: { <any information> }
{noformat}
field into custom roles as shown here: https://docs.mongodb.org/manual/reference/method/db.createUser/",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,164419200,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,greg.mckeon(greg.mckeon),2015-12-02 12:37:48.0,,,,,,,,,,,,,,backlog-server-security(backlog-server-security),jozefdobos(jozefdobos),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i02cdz:",,,,,,,"0|i05qgf:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i0xjin:",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Security (write-only setting for database key),SERVER-3537,20515,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Minor - P4,,backlog-server-security,khabok,khabok,Aug 04 2011 09:00:16 PM UTC,Sep 10 2018 05:21:20 PM UTC,Feb 17 2021 11:15:27 AM UTC,,,,,,features we're not sure of,Security,,,,0,query,security,,,,"Obviously Mongo isn't vulnerable to the sorts of injection that haul sensitive data off SQL databases all day, every day.  However, SQL injection attacks raise a significant and broad security question: why do application servers have access to sensitive data that they don't need?  Proposal:

* Allow the user to declare a database key as ""write only""
* Queries against this key behave as normal
* Optionally raise an error or return null on attempts to read the restricted key

This would create a strong layer of security around data such as passwords that must be written and compared but never ever read.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,5.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2014-03-13 18:55:56.0,191203200,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,sara.williamson(sara.williamson),Mon Jan 26 21:29:21 UTC 2015,,,,,,,,No,,,,,,andreas.nilsson(andreas.nilsson@10gen.com),backlog-server-security(backlog-server-security),khabok(khabok),Schmidty(schmidty),ramon.fernandez(ramon.fernandez),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i06jqn:",,,,,,,"0|i05ron:",6709,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i1i59r:","Mar 13 2014 06:55:56 PM UTC;andreas.nilsson;We are going through some old SERVER security tickets and I came across this one. [~khabok] would you mind clarifying what you mean with database key in this context? I am not sure exactly what you are asking for.

Thanks Andreas","Jul 24 2014 07:31:09 PM UTC;ramon.fernandez;[~khabok], we haven't heard back from you for a while. Are you still interested in following up with this proposal? If so, can you please review Andreas' questions above and get back to us?

Thanks,
Ramón.","Jan 24 2015 07:06:13 AM UTC;Schmidty;Sorry, I kept back-burner-ing this because I couldn't get into the account I created this issue from.

I mean a document path. Say you have a collection Users that contains a few records:
{code}
{
    name: ""Dude McManus"",
    passwordHash: ""gu890ew4rkj8934tkjd""
}
{
    name: ""Charlie Chaplin"",
    passwordHash: ""phu9ft6ujrtd6igv""
}
{
    name: ""Jim Jeffries"",
    passwordHash: ""vq3ywehiulogse""
}
{code}

Declare the ""passwordHash"" path as secure.
{code}
Users.ensureIndex ({ passwordHash:'secure' })
{code}
Alternately index by ""passwordHash"" with the secure option, to get a proper index under the constraint.
{code}
Users.ensureIndex ({ passwordHash:1 }, { secure:[ ""passwordHash"" ]})
{code}
Either of those options done, the secure field is projected out by default. Attempting to project it *in* results in a MongoError.
{code}
Users.findOne ({ name:""Charlie Chaplin"", passwordHash:""phu9ft6ujrtd6igv"" })
> { name:""Charlie Chaplin"" }
Users.findOne ({ name:""Charlie Chaplin"", passwordHash:""phu9ft6ujrtd6igv"" }, { passwordHash:true })
> MongoError
{code}","Jan 26 2015 04:38:00 PM UTC;andreas.nilsson;Ok I get it. We've been having discussions around different types of field-level protection mechanisms. 

One clarification, what would the secure field be used for if you cannot access it from a find cursor?","Jan 26 2015 09:29:21 PM UTC;Schmidty;For selecting and excluding documents from queries. In the example, findOne would not return a document if the provided passwordHash didn't match. Or: imagine documents containing an Array of User role names.
{code}
{
    title: ""final expenditure report"",
    permissions:[ ""admin"", ""clerical"", ""accounting"" ]
}
{code}
With a secure index on ""permissions"" you could query for recent documents accessible to a specific role but not list available roles on any document.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Non-production options shall generate startup warnings,SERVER-9887,78422,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Minor - P4,,backlog-server-platform,alex.komyagin,alex.komyagin,Jun 10 2013 02:19:23 AM UTC,Feb 26 2018 03:22:09 PM UTC,Feb 17 2021 11:15:27 AM UTC,,,,,,Backlog,Usability,,,,0,,,,,,"For instance, I would like the --diaglog option to generate a start up warning, so we can easily check in logs if the setup is not optimal. (And also MMS will highlight this as well)",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2014-09-09 22:45:09.0,203212800,,,,,,,,,,,,,,,,,,,,,,,,,,,,false,ian.whalen(ian@10gen.com),Tue Sep 09 22:45:09 UTC 2014,,,,,,,,No,,,,,,alex.komyagin(alex.komyagin@10gen.com),backlog-server-platform(backlog-server-platform),thomasr(thomasr),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i04fwf:",,,,,,,"0|i05pwv:",7165,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i1iuuv:","Sep 09 2014 10:45:09 PM UTC;thomasr;probably same with single config server. ",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Ability to store JavaScript libraries server-side,SERVER-2936,16085,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Minor - P4,,backlog-server-platform,eedrummer,eedrummer,Apr 12 2011 07:38:31 PM UTC,Feb 26 2018 03:21:36 PM UTC,Feb 17 2021 11:15:27 AM UTC,,,,,,Backlog,JavaScript,,,,20,,,,,,"It would be nice to have the ability to store JavaScript libraries server-side for use in MapReduce jobs or aggregation queries. While the system.js collection is handy for storing functions, it does not seem capable of handling a full library like the Underscore.js.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,3.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2012-09-07 09:09:50.0,219369600,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,ian.whalen(ian@10gen.com),Thu Mar 06 13:08:03 UTC 2014,,,,,,,,No,,,,,,eedrummer(eedrummer),arieljake(arieljake),backlog-server-platform(backlog-server-platform),mathias.kluba@fastconnect.fr(mathias.kluba@fastconnect.fr),senfo(senfo),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i06qp3:",,,,,,,"0|i05plz:",6053,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i0rzpz:","Sep 07 2012 09:09:50 AM UTC;mathias.kluba@fastconnect.fr;Loading a JS file thanks to db.system.js is possible (but we have to store it in all shards).
But a better solution will be to load dynamically Node.JS packages.
Now that mongo 2.2 has a better JS engine, it makes sens to do some complex MapReduce jobs.
Why not embed the NodeJS engine in this case?","Sep 07 2012 11:06:26 AM UTC;arieljake;Yes! Great idea.","Mar 06 2014 01:08:03 PM UTC;senfo;Is there still interest in developing this feature? It doesn't seem to be getting a lot of attention, but I think it would be incredibly helpful.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Publish/Subscribe (Message queue) functionality,SERVER-3385,19212,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Minor - P4,,backlog-server-sharding,vboivie,vboivie,Jul 07 2011 06:00:05 AM UTC,Jun 15 2017 02:58:40 PM UTC,Feb 17 2021 11:15:27 AM UTC,,,,,,features we're not sure of,Usability,,,,30,message.queue,pub.sub,publish.subscribe,,,"Message queue functionality is something that is/was traditionally handled by a dedicated message broker, i.e. RabbitMQ when using AMQP as protocol.

A growing trend is to use solutions that are easier to setup and maintain, such as pub/sub solutions (quite many of them). There are also NoSQL databases that have added such extensions, and the most common example is Redis.

MongoDB could fit very well in this world. (Capped) collections with polling subscribers can already today be used to simulate a message queue, but this is just a workaround. Having native support for publish/subscribe in MongoDB (with blocking readers, for example) can be used to add message queues without having to setup and maintain separate solutions and keep the same concepts as the application developers have grown used to, like the rich expressiveness of documents as messages. The advantages of replica sets can be used to add reliability and durability of messages in a queue (well, this would rule out capped collections).

An API would have to be created, and the concepts would have to be defined.",,,,,,,,,,,,SERVER-5042,FREE-10132,,,,,,,,,,,,,,,,,,,7.0,,,,,,,,,,,,,,,,,Fully Compatible,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2011-07-17 01:23:03.0,279244800,,,,,,,,,,,,,,,,,,,,,,,,,,,,false,ian.whalen(ian@10gen.com),Thu Apr 12 12:34:15 UTC 2012,,,,,,,,No,,,,,,ejsmont.artur(ejsmont.artur),backlog-server-sharding(backlog-server-sharding),digitalronin(digitalronin),fbjork(fbjork),hmexx007(hmexx007),yookoala(yookoala),vboivie(vboivie),vingrad(vingrad),wtpayne(wtpayne),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i06ljj:",,,,,,,"0|i0c42v:",6572,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i03ohz:","Jul 17 2011 01:23:03 AM UTC;fbjork;+1 for Pub/Sub support in MongoDB!","Aug 17 2011 12:15:00 PM UTC;hmexx007;+1 as well

Submitted the same request before seeing this.","Sep 16 2011 11:07:26 AM UTC;digitalronin;+1 this would be really helpful for me. I'm planning to use multiple (around 300) MongoDB instances partially as a distributed smart cache. pub/sub support would make it much easier to keep all the nodes in sync.","Jan 15 2012 03:36:13 PM UTC;vingrad;+1","Feb 01 2012 01:27:20 PM UTC;wtpayne;+1; I am currently using tailing & capped collections. Pub/sub would help me to improve the testability of my logic.","Apr 06 2012 01:15:55 AM UTC;ejsmont.artur;+1 YES yes and one more time yes. This would be an awesome tandem and plus for MongoDB if it could replace simple 1-1 / 1-n persistent queues.","Apr 12 2012 12:34:15 PM UTC;yookoala;This will be a really awesome feature! I don't really want to run both Redis and MongoDB in my stack but I need Redis's Pubsub to scale my service. I hope MongoDB will have pubsub soon.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Allow $votes/special-tags to be used in custom write concerns,SERVER-16088,168593,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Minor - P4,,backlog-server-repl,scotthernandez,scotthernandez,Nov 11 2014 07:43:56 PM UTC,Jan 20 2017 10:01:30 PM UTC,Feb 17 2021 11:15:27 AM UTC,,2.7.8,,,,Backlog,Replication,,,,0,,,,,,"Currently users can't represent the ""majority"" write concern because it depends on synthetic tags ($votes). We should allow using these in custom write concern defined in the replica set config (under the getLastErrorModes option).",,,,,,,,,,,,SERVER-16089,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,197769600,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,ian.whalen(ian@10gen.com),2014-11-11 19:43:56.0,,,,,,,,,,,,,,backlog-server-repl(backlog-server-repl),scotthernandez(scotthernandez),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i038f3:",,,,,,,"0|i0btav:",147436,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i0ympb:",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
"Add ""arbiter"" option to mongod",SERVER-15578,162745,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Minor - P4,,backlog-server-repl,northbear,northbear,Oct 09 2014 11:07:25 AM UTC,Jul 09 2016 10:23:44 PM UTC,Feb 17 2021 11:15:27 AM UTC,,,,,,Backlog,Replication,,,,0,,,,,,"Add  an ""arbiter"" option to mongod to force the arbiter role; this will ensure that it cannot accidentally be added as a regular data-holding member later. The node may be added to replSet with rs.add(..) command. rs.addArb(..) will be not required since there is no question about its role... 

The mongod --arbiter option may also imply --smallfiles option.
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,Major Change,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,200707200,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,ramon.fernandez(ramon.fernandez),2014-10-09 11:07:25.0,,,,,,,,Cannot,,,,,,backlog-server-repl(backlog-server-repl),northbear(northbear),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i03bbz:",,,,,,,"0|i0c26v:",141841,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Not Needed,,,,,,,,,,,,,,,,,,,"0|i0yqe7:",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
allow sharing of config servers between clusters,SERVER-3426,19477,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Minor - P4,,backlog-server-sharding,antoine,antoine,Jul 13 2011 05:50:55 PM UTC,Nov 12 2015 05:56:05 PM UTC,Feb 17 2021 11:15:27 AM UTC,,,,,,features we're not sure of,Sharding,,,,4,,,,,,"many users have more than 1 db cluster because they process data with different requirements (small &
very reliable vs big & transient).
In one instance a user has 7 clusters, which means they need to spawn 21 config servers, which is pain for admin and backup.
It would be beneficial to be able to share config servers between clusters since the data & rps requirement is low.
For example instead of the ""config"" db name, the name could include the cluster name and each cluster would have its own db.
Cluster name can be passed to mongos command along the configdb hostnames.
",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,302918400,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,crystal.horn(crystal.horn@10gen.com),2011-07-13 17:50:55.0,,,,,,,,No,,,,,,antoine(antoine),backlog-server-sharding(backlog-server-sharding),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i06l07:",,,,,,,"0|i0c3vz:",6483,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i1i2j3:",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Order of responses to a MongoDB $in query,SERVER-7528,54978,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Trivial - P5,,backlog-query-execution,jonathanong,jonathanong,Nov 01 2012 06:31:57 AM UTC,Nov 14 2020 07:23:19 PM UTC,Feb 17 2021 11:15:27 AM UTC,,,,,,features we're not sure of,Querying,,,,25,query,,,,,"I have a use-case where I am querying an array of ObjectIDs. For example:

db.things.find({
  _id: {
    $in: [
      ObjectID(...),
      ObjectID(...),
      ObjectID(...),
      ObjectID(...)
    ]
  }
})

I'd like the results to be ordered by `_id.$in`. Right now I'm resorting to client-side sorting, which kind of sucks since it requires converting between ObjectIDs and strings among other hacks.

A special sorting option like this would be awesome (similar to $natural):

db.things.find({}).sort({
  $in: {
    '_ids'
  }
})

Although the attribute being `$in`ed need not be `_id`, it should be unique (and thus indexed).

Some related questions on StackOverflow:

http://stackoverflow.com/questions/3142260/order-of-responses-to-mongodb-in-query
http://stackoverflow.com/questions/11839515/comparing-and-sorting-mongodb-objectids-in-node-convert-to-string",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,22.0,,,,,,,,,,,,,,,,,Fully Compatible,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2012-11-01 18:19:33.0,8294400,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,craig.homa(craig.homa),Thu Nov 12 22:21:09 UTC 2020,,,,,,,,No,,,,,,aaron(aaron),rahbari(rahbari),asya(asya),backlog-query-execution(JIRAUSER1257109),gembin@gmail.com(gembin@gmail.com),amcgregor(amcgregor),jonathanong(jonathanong),mitar(mitar),meson10(meson10),vivekgounder(vivekgounder),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i058gv:",,,,,,,"0|i0108f:",6632,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i0s4rr:","Nov 01 2012 06:19:33 PM UTC;aaron;Hi Jonathan,

As a workaround for now, if you instead make your query

db.things.find( { $or:[ { _id:ObjectId( … ) }, { _id:ObjectId( … ) } … ] } )

all existing versions of mongo will give you the order you want assuming you have an index on _id.  This behavior may not be guaranteed in future versions of mongo, so it might be considered a bit of a hack.  Also, keep in mind that $or will not scale as well for large numbers of ids in your list as $in would.  Here is a test example:

{code}
c = db.c;
c.drop();

c.save( { _id:0 } );
c.save( { _id:2 } );
c.save( { _id:1 } );

printjson( c.find( { _id:{ $in:[ 1, 2, 0 ] } } ).toArray() );
printjson( c.find( { $or:[ { _id:1 }, { _id:2 }, { _id:0 } ] } ).toArray() );
{code}
","Nov 01 2012 06:21:59 PM UTC;aaron;Alternatively, if you want to use the aggregation framework, you could create a custom field based on the position of an id in your array and then sort by that field.","Nov 01 2012 06:31:47 PM UTC;jonathanong;Thanks for that. Using $or is a much better hack. I generally have a limited number of ids so I don't think scaling would be a problem, assuming 1000 is not large. 

Most of all, thanks for the quick reply!","Nov 01 2012 08:36:13 PM UTC;meson10;Would really help to have this functionality. +1","Nov 02 2012 05:55:39 AM UTC;aaron;Here are a few different ways to do this with the aggregation framework.  Might become simpler as we add additional aggregation operators:

{code}
c = db.c;
c.drop();

c.save( { _id:'a' } );
c.save( { _id:'c' } );
c.save( { _id:'b' } );

printjson( c.aggregate( { $match:{ _id:{ $in:[ 'b', 'c', 'a' ] } } },
                        { $project:{ _id:1, rank:{ $cond:[ { $eq:[ '$_id', 'b' ] }, 0,
                                                 { $cond:[ { $eq:[ '$_id', 'c' ] }, 1,
                                                 { $cond:[ { $eq:[ '$_id', 'a' ] }, 2, null ] } ] } ] } } },
                        { $sort:{ rank:1 } },
                        { $project:{ _id:1 } }
) );

printjson( c.aggregate( { $match:{ _id:{ $in:[ 'b', 'c', 'a' ] } } },
                        { $group:{ _id:null, id:{ $push:'$_id' }, ordered:{ $first:{ $const:[ 'b', 'c', 'a' ] } } } },
                        { $unwind:'$ordered' },
                        { $unwind:'$id' },
                        { $project:{ _id:'$id', matches:{ $eq:[ '$ordered', '$id' ] } } },
                        { $match:{ matches:true } },
                        { $project:{ _id:1 } }
) );

printjson( c.aggregate( { $match:{ _id:{ $in:[ 'b', 'c', 'a' ] } } },
                        { $project:{ _id:1, ranks:{ $const:[ { k:'b', v:0 }, { k:'c', v:1 }, { k:'a', v:2 } ] } } },
                        { $unwind:'$ranks' },
                        { $project:{ _id:1, rank:'$ranks.v', matches:{ $eq:[ '$_id', '$ranks.k' ] } } },
                        { $match:{ matches:true } },
                        { $sort:{ rank:1 } },
                        { $project:{ _id:1 } }
) );
{code}","Nov 02 2012 09:42:10 AM UTC;meson10;Solution 1 and 3 are non Generic. I will have to Embed the calculated ranks rather than seek Array Index. Since there is no way to provide a lazy function, which can be evaluated later.

Solution 2: Yeah it does the Job, although i doubt its THE optimal way to achieve it.","Nov 02 2012 01:20:28 PM UTC;meson10;To my surprise even this seems to work in pymongo:

c.aggregate(
        {'$match':{'_id': {'$in': array}},
        {'$project': {'_id': 1}}
)

Odd ?","Nov 02 2012 04:39:25 PM UTC;aaron;Hi Piyush,

Can you send a full test script as I have above?","Nov 02 2012 06:01:19 PM UTC;meson10;Hey Aaron,
try this.

{code: python}
import pymongo
import random

array = range(1, 20)
random.shuffle(array)

con = pymongo.Connection(safe=True)
con.drop_database('test')
for i in array:
    con.test.test.insert({'_id': i})

test = con.test.test

_map = {}
for x in test.find({'_id': {'$in': array}}):
    _map[x['_id']] = x

normal = [_map[i] for i in array]

aggregate = test.aggregate({
    '$match':{'_id': {'$in': array}},
    '$project': {'_id': 1}
    })

print normal
print aggregate.get('result')
{code}","Nov 02 2012 06:03:25 PM UTC;meson10;Ah I get it, where i was going wrong.
The Order of Insertion is what the order of output document is while using aggregate. Whereas when you do find the order is _id. Never mind.
Ignore the earlier comments.","May 29 2014 07:11:08 PM UTC;asya;The $or work-around hack no longer works starting with 2.6.x - it was a side effect of implementation which has changed.
","May 30 2014 02:59:14 AM UTC;jonathanong;What's the recommended way to do this now?


","Aug 19 2015 06:11:26 AM UTC;vivekgounder;Doing it in the client makes it very odd and strange indeed. It would be lovely if we had the server side implementation for the clients to have a sorting option while using the in query.","Aug 20 2016 08:09:05 AM UTC;amcgregor;I, too, am looking forward to this.  Sure, I could batch retrieve the document set and assign to a dictionary (in Python), then re-iterate the value I passed to {{$in}}, but this is a poor solution for anything but trivial numbers of results.  A streaming solution (since I typically use generators for my {{$in}} values, too) is greatly superior.

Due to the existing sorting syntax, I'd recommend the following form:

{code:js}
{'$in': 1}
{code}

With potentially mixed usage:

{code:js}
{age: -1, '$in': 1}
{code}

This would imply a limitation of only one {{$in}} filter to satisfy the query in this way, similar to the current {{$}} limitation.  This is acceptable to me, possibly not to others, but importantly, does conform to the existing syntax.

Edited to add: explicit lookup of documents by ID in the pre-arranged order is a specialization of the general form I suggest.  Because it's so specialized (single, automatic index, no other possible ordering) it may be worthwhile to implement as a distinct find command.  {{findSpecific}} or {{findById}} or similar.  Also likely easier to implement as such.","Aug 27 2016 03:14:14 PM UTC;rahbari;This is really a necessary feature. For example in a system where user can feature items, they must see them in the order they featured them.  In SQL days this was done using a join so you wouldn't actually care about in. I believe Mongodb must preserve the $in order unless an order by clause is present. Doing this client side would be so frustrating considering we must do the sort as well as paging! ","Oct 24 2016 08:23:42 PM UTC;asya;In upcoming 3.4 this is possible to do with an aggregation pipeline.

I write it up here:  http://www.kamsky.org/stupid-tricks-with-mongodb/using-34-aggregation-to-return-documents-in-same-order-as-in-expression

Basically, it's a matter of adding a field with order of matched field in the array that specified sort order.

Using initial example from this ticket:
{noformat}
order=[ ObjectID(...), ObjectID(...), ObjectID(...), ObjectID(...) ];
db.things.aggregate({$match:{_id:{$in:order}}}, {$addFields:{__order: { $indexOfArray : [ order, ""$name"" ]}}}, {$sort:{ ""__order"":1}});
{noformat}
","Dec 04 2017 07:20:20 PM UTC;asya;Given there is a way to get results in the order specified in $in as of 3.4 is there a reason to keep this ticket open?  

In other words, are there scenarios that would not be satisfied with aggregation sorting of resulting documents?
","Dec 04 2017 07:57:50 PM UTC;mitar;I mean, the issue is where we draw a line of what all we have to do in aggregation pipelines, and what we can do as a normal query. While it is great to see that it is possible to do this in aggregation, it would be much cooler if a simple query could be sorted by an array, without having to do aggregation.","Dec 05 2017 12:37:00 AM UTC;asya;The direction we are heading is bringing the ""normal"" query and aggregation closer together, so I'm not sure the distinction between ""normal"" and not normal is as big as it used to be...
","Jun 28 2020 05:02:24 AM UTC;gembin@gmail.com;Any plan to implement this feature? It's useful to keep the original order in case the original input ids are already sorted.
{quote}db.things.aggregate(\{$match:{_id:{$in:order}}}
{quote}
 ","Nov 12 2020 10:19:51 PM UTC;mitar;I again hit this issue when I wanted to use ElasticSearch for full-text search, which then returns 100k result IDs, I want then to query MongoDB using such long list of result IDs, getting them batch by batch in same order from the database, potentially filtering it further. I think it is problematic that a) I have to include the whole list in the query itself (no prepared statements like SQL) b) the order does not match. I have to pass whole 100k IDs in because if further filter, I want each batch/page to be the same size, not that I first pass 100 by 100 IDs into the query, just to get back a subset of those, having then batch/page of uneven sizes.","Nov 12 2020 10:21:09 PM UTC;mitar;Also, using $indexOfArray approach is O(n^2), isn't it? Which becomes prohibitive with large arrays of IDs as well.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Consider support for field renaming in $unwind stage,SERVER-38454,647363,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Trivial - P5,,backlog-query-optimization,jeffm24,jeffm24,Dec 07 2018 04:50:38 PM UTC,Nov 14 2020 06:57:00 PM UTC,Feb 17 2021 11:15:27 AM UTC,,,,,,Backlog,Aggregation Framework,,,,1,,,,,,"In my experience, array fields in documents are usually labeled as plural (e.g. items: ['item']). This becomes a little confusing to read once they are past the $unwind stage because the value will become singular but the field name remains plural.  This can be alleviated via an $addFields stage directly after the $unwind, but that seems inefficient.

 

A potential solution here could be to add an 'as' option to the $unwind stage like the following:

 
{code:java}
{ $unwind: { path: '$items', as: 'item' } }{code}
 

This would $unwind and rename the unwound field to the specified name in a single stage, and it is consistent with the naming conventions of expressions like $filter.

 ",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,69292800,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,craig.homa(craig.homa),2018-12-07 16:50:38.0,,,,,,,,,,,,,,backlog-query-optimization(JIRAUSER1257108),jeffm24(jeffm24),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i2xxj3:",,,,,,,"0|i00yk7:",9223372036854775807,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i2xvmv:",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Syntax highlighting in shell,SERVER-2767,15128,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Trivial - P5,,massimiliano.marcon,mkeranen,mkeranen,Mar 16 2011 02:21:17 AM UTC,Jul 17 2020 03:10:32 PM UTC,Feb 17 2021 11:15:27 AM UTC,,,,,,Backlog,Shell,,,,6,,,,,,"Basic javascript syntax highlighting with bracket matching would be useful in the console, especially when entering nested braces. Of all the colorization various text editors perform, highlighting the current matched brace or paren can be one of the more timesaving features in resolving syntax errors.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,10.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2011-03-16 03:10:28.0,201744000,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,jessica.sigafoos(jessica.sigafoos),Fri Sep 26 15:05:37 UTC 2014,,,,,,,,No,,,,,,AlexCzar(alexczar),plasma(plasma),massimiliano.marcon(massimiliano.marcon),redbeard0531(redbeard0531),mkeranen(mkeranen),Pavel.Sprogis(pavel.sprogis),tad(tad),tianon(tianon),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i02ovr:",,,,,,,"0|i05qmn:",4548,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i1iu1z:","Mar 16 2011 03:10:28 AM UTC;plasma;Agreed. One extra minor feature too would be nested indenting when you type { and go to a new line. Currently you only indent at most one level (even if you then open another brace), it would be neat if it kept indenting as expected.","Jul 12 2011 01:55:48 AM UTC;tianon;I noticed some commits in https://github.com/mongodb/mongo/commits/master recently that addressed some issues with bracket highlighting; does that mean this is at least partially in-progress?","Aug 04 2011 04:44:48 PM UTC;redbeard0531;Yes, but there is a chance it will get pulled before 2.0. in the 1.9 shells we already highlight matching braces.","Mar 06 2012 08:56:05 PM UTC;tad;We do limited brace matching now ... move the cursor over a brace or parenthesis and it will color the matching one ... but I'm not sure what people are looking for here.  Syntax coloring of JavaScript keywords is probably not a quick feature if that is what this ticket means.  Indenting based on counting unmatched braces is probably doable.","Mar 06 2012 09:02:02 PM UTC;mkeranen;Brace matching was the motivation behind the request. Keyword highlighting would be a nice feature as well, but not as important as pairing braces visually.","Mar 06 2012 10:09:22 PM UTC;tad;Have you tried what we have in current versions -- 2.0.3 and 2.1.0?  It highlights the matching brace as you move the cursor left and right.  It highlights only the matching one when the cursor is over a brace/bracket/parenthesis ... Visual Studio highlights both the one you are on and the matching one.  Is the current feature good, should we add the Visual Studio behavior, or is there something else you are looking for?

Thanks!","Mar 06 2012 10:15:29 PM UTC;mkeranen;I have not had the chance to test the new versions yet, nor am I a Visual Studio user (any more), but highlighting both sounds useful. IIRC when entering this issue, I was working with nested docs, and matching braces on the shell was the source of more than one error on my part.","Apr 16 2012 01:10:39 PM UTC;tad;The current brace-matching logic is too generous in highlighting ""matching"" braces and will highlight a ""("" when you move the cursor over a ""]"".  The code should highlight only correct matches.  For extra credit, it could also highlight incorrect matches in a different color, e.g. red.","Aug 28 2014 08:16:05 AM UTC;AlexCzar;There is an interesting [mongo-hacker project|https://github.com/TylerBrock/mongo-hacker] which extends mongo shell. Among other features it provides json highlighting of documents. You may try to post a request for this feature there or fork and extend the project yourself.","Sep 26 2014 03:05:37 PM UTC;Pavel.Sprogis;It would be great to add syntax highlighting in mongo shell as soon as possible. mongo-hacker has nice highlighting but they add a lot of trash: change default methods behaviour, change prototypes, add a lot of methods in global scope, etc. And all I need is just colorizer. Is it possible to increase priority/severity of this improvment ?",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Support a 'sort' field in ops array for JS Benchmarking Harness,SERVER-5722,37465,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Trivial - P5,,backlog-server-stm,jesse,jesse,Apr 30 2012 04:20:33 PM UTC,Nov 05 2019 08:48:22 PM UTC,Feb 17 2021 11:15:27 AM UTC,,,,,,Backlog,Testing Infrastructure,,,,2,benchRun,neweng,tig-benchrun,,,"benchRun supports limit, skip, and batchSize, but not sort:

http://www.mongodb.org/display/DOCS/JS+Benchmarking+Harness

https://github.com/mongodb/mongo/blob/master/src/mongo/scripting/bench.cpp#L455

",,,,,,,,,,,,PERF-1930,,,,,,,,,,,,,,,,,,,,6.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2015-06-16 22:57:33.0,106531200,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,david.storch(david.storch),Mon Oct 02 20:16:40 UTC 2017,,,,,,,,No,,,,,,jesse(jesse),backlog-server-stm(backlog-server-stm),pasette(dan@10gen.com),david.daly(david.daly),david.storch(david.storch),kyle.suarez(kyle.suarez),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i05tov:",,,,,,,"0|i066rb:",5873,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i1iznb:","Jun 18 2015 03:23:28 PM UTC;pasette;You can add a sort by adding an orderBy clause into the query document.
{code}
{ op: ""find"",
         query: { $query: {x: { $gte : 0 }}, $orderby : {""x"" : 1} }
}
{code}
","Oct 07 2016 08:59:03 PM UTC;david.storch;Despite the workaround above for legacy OP_QUERY find, my reading of the shell's implementation of {{benchRun}} in the master branch suggests that neither a ""sort"" nor an ""orderby"" field is supported when find command is enabled via the {{readCmd}} option. It would be useful to support this option in a general way for both find command and legacy OP_QUERY, so I am re-opening this ticket for consideration by the performance infrastructure team.","Nov 17 2016 09:29:59 PM UTC;kyle.suarez;Having this would be especially helpful for the views project. They require {{--readCmd true}} to work properly, so we cannot apply a views passthrough to existing query tests that rely on the {{$query}} example that Dan mentioned, since that's not supported in read commands.","Nov 18 2016 04:26:20 PM UTC;david.daly;[~david.storch] [~kyle.suarez] Would the addition fit [here|https://github.com/mongodb/mongo/blob/master/src/mongo/shell/bench.cpp#L719] (that's FindOne. Also for find) for the readCmd path, and create something similar to our current work around for the non readCmd path? ","Nov 18 2016 04:28:03 PM UTC;david.storch;[~david.daly], yep, that sounds right to me.","Oct 02 2017 08:16:40 PM UTC;david.daly;Updating the link I put before to tie it to a commit. I said it would fit [here|https://github.com/mongodb/mongo/blob/fd300c0c05c1e057a7c5f24e7599d26e383234d0/src/mongo/shell/bench.cpp#L719]. ",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
Current sys info,SERVER-2606,14843,New Feature,Open,SERVER,Core Server,software,pasette,"MongoDB Server<br>
Odd version numbers are unstable dev branches (3.1, 3.3, 3.5)<br>
Even numbers are stable branches and only get bug fixes, etc... (3.2, 3.4, 3.6)<br>
We aim to do a stable release every 12 months.<br>

File any potential security issues at <a href=""https://jira.mongodb.org/browse/SECURITY"">Security</a>.<br>",https://github.com/mongodb/mongo/wiki,Trivial - P5,,backlog-server-platform,gawin,gawin,Feb 22 2011 02:25:09 PM UTC,Feb 26 2018 03:23:32 PM UTC,Feb 17 2021 11:15:27 AM UTC,,1.6.5,,,,Backlog,Usability,,,,0,,,,,,"The current mongod and webinterface show information about the current MongoDB version.
I would like to suggest to split the current details into information about the build, and information about the current system (using uname -a).
For example:

build
  db version v1.6.5, pdfile version 4.5
  git hash: 0eb017e9b2828155a67c5612183337b89e12e291
  sys info: SunOS fhm8e4dc.joyent.us 5.11 snv_89 i86pc BOOST_LIB_VERSION=1_38
system
  uptime: 4696 seconds
  sys info: SunOS mongodb.example.com 5.11 oi_148 i86pc i386 i86pc BOOST_LIB_VERSION=1_46

In the current version, I would expect 'sys info' to be the system that runs the daemon, since also uptime is mentioned. But it actually shows the 'sys info' of the system it was built on, which was kind of confusing.

An other option would be to change 'sys info' into 'sys built'",SunOS 5.11 oi_148 i86pc i386 i86pc,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,315100800,,,,,,,,,,,,,,,,,,,,,,,,,,,,true,ian.whalen(ian@10gen.com),2011-02-22 14:25:09.0,,,,,,,,No,,,,,,backlog-server-platform(backlog-server-platform),gawin(gawin),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i06uqn:",,,,,,,"0|i05qmf:",6170,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"0|i1i1tr:",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
